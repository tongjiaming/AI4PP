{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN6bdzEgKCQYCDtFoIjW6TE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Origin"],"metadata":{"id":"GJfFKPUawFkD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zagu0TH9vasW"},"outputs":[],"source":["@staticmethod\n","def load_data():\n","    # parser = get_parser()\n","    # args = parser.parse_args()\n","\n","    human_eval = load_dataset(\"humaneval_infilling\", \"HumanEval-MultiLineInfilling\")\n","    # human_eval = load_dataset(\"humaneval_infilling\", \"HumanEval-SingleLineInfilling\")\n","    # human_eval = load_dataset(\"humaneval_infilling\", \"HumanEval-RandomSpanInfilling\")\n","    # human_eval = load_dataset(\"humaneval_infilling\", \"HumanEval-RandomSpanInfillingLight\")\n","    # Generate completions for evaluation set\n","    n_tasks = len(human_eval[\"test\"])\n","\n","    prefixes = []\n","    suffixes = []\n","    solutions = []\n","    for task in range(n_tasks):\n","        prefixes.append(human_eval[\"test\"][task][\"prompt\"])\n","        suffixes.append(human_eval[\"test\"][task][\"suffix\"])\n","        solutions.append(human_eval[\"test\"][task][\"canonical_solution\"])\n","\n","    jsonl_file = 'codegen.jsonl'  # args.jsonl_file\n","    num_samples = 1  # args.num_samples\n","\n","    print(\"build the LLM\")\n","    SIZE = '350M'  # 350M 2B 6B\n","    MODEL_NAME = f\"Salesforce/codegen-{SIZE}-mono\"\n","    tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n","    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(\"cuda\")\n","    tok.pad_token = tok.eos_token\n","\n","    print(\"build generations\")\n","    completed_codes = list()\n","    for idx, (prompt, suffix) in tqdm(enumerate(zip(prompts, suffixes))):\n","        # prompt = prompt.replace(\"\\n\\n\\n\", \"\\n\\n\")\n","        # print('---' * 19)\n","        # print(f'+++{idx}', prompt)\n","        completed_code = infill_code(prompt, num_samples=num_samples)\n","        completed_codes.append(completed_code)\n","        print(f'###{idx}', completed_code)\n","\n","    print(\"save generations\")\n","    with open(jsonl_file, 'w') as file:\n","        for completed_code in completed_codes:\n","            file.write(json.dumps(completed_code) + '\\n')\n","\n","    TEMPLATE_TO_INFILL = \"\"\"\n","Leading context: \"{leading_context}\"\n","Trailing context: \"{trailing_context}\"\n","Given the leading and trailing context as above, what code to infill?\n","Code to infill: \"\"\"\n","\n","TEMPLATE_TO_INFILL.format(leading_context=leading_context, trailing_context=trailing_context)"]},{"cell_type":"markdown","source":["# My"],"metadata":{"id":"s1lBLNM6wD_J"}},{"cell_type":"code","source":["#@title Library\n","!pip install datasets\n","!pip install transformers"],"metadata":{"cellView":"form","id":"PAo6WSS4wDbx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675983498938,"user_tz":-60,"elapsed":4284,"user":{"displayName":"Jiaming Tong","userId":"08738272112358727425"}},"outputId":"97d91d41-05a9-45ca-cc2c-4fd138917b0c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n"]}]},{"cell_type":"code","source":["#@title Pip\n","import json\n","import torch\n","\n","from datasets import load_dataset, load_metric\n","from tqdm import tqdm\n","from transformers import AutoTokenizer, AutoModelForCausalLM"],"metadata":{"cellView":"form","id":"Lsyh7dMNwL_i","executionInfo":{"status":"ok","timestamp":1675983517851,"user_tz":-60,"elapsed":18916,"user":{"displayName":"Jiaming Tong","userId":"08738272112358727425"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#@title Arguments\n","jsonl_file = 'codegen.jsonl'  # args.jsonl_file\n","num_samples = 1  # args.num_samples\n","\n","dataset = \"loubnabnl/humaneval_infilling\"\n","subset = \"HumanEval-MultiLineInfilling\" #@param [\"HumanEval-MultiLineInfilling\", \"HumanEval-SingleLineInfilling\", \"HumanEval-RandomSpanInfilling\", \"HumanEval-RandomSpanInfillingLight\"]\n","specified_data_size = 1 #@param {allow-input: true}\n","\n","model_name = \"bigcode/santacoder\""],"metadata":{"id":"T4iyvM3pythT","executionInfo":{"status":"ok","timestamp":1675983517852,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jiaming Tong","userId":"08738272112358727425"}},"cellView":"form"},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#@title Data\n","human_eval = load_dataset(dataset, subset)\n","\n","# Generate completions for evaluation set\n","prefixes = []\n","suffixes = []\n","solutions = []\n","\n","data_size = min(specified_data_size, len(human_eval[\"test\"]))\n","for task in range(data_size):\n","    prefixes.append(human_eval[\"test\"][task][\"prompt\"])\n","    suffixes.append(human_eval[\"test\"][task][\"suffix\"])\n","    solutions.append(human_eval[\"test\"][task][\"canonical_solution\"])"],"metadata":{"cellView":"form","id":"XX0mCZ4Ux-yZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Model\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name, revision=\"fim\", trust_remote_code=True)\n","if torch.cuda.is_available():\n","  model.to(\"cuda\")\n","tokenizer.pad_token = tokenizer.eos_token"],"metadata":{"id":"N6GIlIwByzdr","executionInfo":{"status":"ok","timestamp":1675983576645,"user_tz":-60,"elapsed":53523,"user":{"displayName":"Jiaming Tong","userId":"08738272112358727425"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["input_text = \"<fim-prefix>def print_hello_world():\\n    <fim-suffix>\\n    print('Hello world!')<fim-middle>\"\n","inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n","outputs = model.generate(inputs, max_length=100, pad_token_id=tokenizer.eos_token_id)\n","print(tokenizer.decode(outputs[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FVBvHrY4T4TH","executionInfo":{"status":"ok","timestamp":1675983744133,"user_tz":-60,"elapsed":67116,"user":{"displayName":"Jiaming Tong","userId":"08738272112358727425"}},"outputId":"99c3b769-cd34-4117-e9ef-11fe9a74c300"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["<fim-prefix>def print_hello_world():\n","    <fim-suffix>\n","    print('Hello world!')<fim-middle>print('Hello world!')\n","\n","if __name__ == '__main__':<|endoftext|><fim-prefix><fim-suffix>e.log(err);\n","    }\n","}\n","\n","module.exports = {\n","    get: get,\n","    post: post\n","}<fim-middle>const axios = require('axios');\n","\n","const get = async (url) => {\n","    try {\n","        const response = await axios.get(url);\n","        return response.\n"]}]},{"cell_type":"code","source":["#@title Generation\n","completed_codes = list()\n","for idx, (prefix, suffix) in tqdm(enumerate(zip(prefixes, suffixes))):\n","  completed_code = model.generate(prefix)\n","  completed_codes.append(completed_code)\n","  print(f'###{idx}', completed_code)"],"metadata":{"id":"P9azppt70bcK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prefixes"],"metadata":{"id":"UsK1FPQi3XOJ"},"execution_count":null,"outputs":[]}]}