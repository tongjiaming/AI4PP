{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1b3iQ91besxaJ54dW4U5ahvrgZduMdeBe","authorship_tag":"ABX9TyOvI45mENIHHMR2IVzTYkvw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Simple in-context learning"],"metadata":{"id":"NEhYhgzTlTV1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -U sentence-transformers\n","!pip install transformers"],"metadata":{"id":"RTf74QyN3I9K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import heapq\n","import warnings\n","\n","from sentence_transformers import SentenceTransformer, util\n","from transformers import AutoTokenizer, AutoModelForCausalLM"],"metadata":{"id":"hl3PRN3Lkhpj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_code = 100\n","filename = '/content/drive/MyDrive/UZH/AI4PP/function_call_prefix.json'\n","warnings.filterwarnings(\"ignore\", message=\"The attention mask and the pad token id were not set.\")"],"metadata":{"id":"OikIBSblr45I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer_codegen = AutoTokenizer.from_pretrained('Salesforce/codegen-350M-mono', pad_token='<pad>')\n","model_codegen = AutoModelForCausalLM.from_pretrained('Salesforce/codegen-350M-mono', pad_token_id=50256)\n","# tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-mono\")\n","# model = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-350M-mono\")"],"metadata":{"id":"s25DdxlO-sUj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678912681263,"user_tz":-60,"elapsed":8304,"user":{"displayName":"Jiaming Tong","userId":"08738272112358727425"}},"outputId":"57079901-b35f-4b4b-8823-114ab18838e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["def json_to_list(filename, num_code=-1):\n","  # input: \n","  #   filename: pytorrent dataset filename\n","  #   num_code: number of smaples wanted, -1 means getting all\n","  # return: code_list, truncated_code_list(code without the last token)\n","  prefix_list = []\n","  gt_list = [] # ground truth\n","  emb_list = []\n","  model_ST = SentenceTransformer('all-mpnet-base-v2')\n","\n","  with open(filename, 'r') as f:\n","    for idx,line in enumerate(f):\n","      if idx == num_code:\n","        break\n","      json_obj = json.loads(line)\n","\n","      prefix = json_obj['input'].replace('<mask0>','')\n","      prefix_list.append(prefix)\n","\n","      gt = json_obj['gt'].split(' ')[0].lower()\n","      gt_list.append(gt)\n","\n","      embeddings = model_ST.encode(prefix, convert_to_tensor=True)\n","      emb_list.append(embeddings)\n","\n","    return prefix_list, gt_list, emb_list"],"metadata":{"id":"_gPxFcPi8abc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def split_data(prefix_list, gt_list, emb_list, ratio):\n","  # Calculate the size of the training set\n","  train_size = int(len(prefix_list) * ratio)\n","\n","  prefix_train = prefix_list[:train_size]\n","  prefix_test = prefix_list[train_size:]\n","  gt_train = gt_list[:train_size]\n","  gt_test = gt_list[train_size:]\n","  emb_train = emb_list[:train_size]\n","  emb_test = emb_list[train_size:]\n","\n","  return prefix_train, prefix_test, gt_train, gt_test, emb_train, emb_test"],"metadata":{"id":"AbbEgjdPJg62"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prefix_train, prefix_test, gt_train, gt_test, emb_train, emb_test = split_data(*json_to_list(filename), 0.8)"],"metadata":{"id":"ncM2FrGo-iFU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_semantic_similarity(object_embeddings, sample_embeddings):\n","  cosine_scores = util.cos_sim(object_embeddings, sample_embeddings)\n","  return cosine_scores.item()"],"metadata":{"id":"_Lt6zfFE2Idl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_prompt(input, prefix_list, gt_list, emb_list, num_prompts=3):\n","  # generate prompt based on input\n","  # by finding similar input/output pair and add them befor the input\n","  similarities = []\n","  model_ST = SentenceTransformer('all-mpnet-base-v2')\n","  input_emb = model_ST.encode(input, convert_to_tensor=True)\n","  for i in range(len(emb_list)):\n","    similarity = compute_semantic_similarity(input_emb, emb_list[i])\n","    similarities.append({'index': i, 'similarity': similarity})\n","\n","  n_largest_scores = heapq.nlargest(num_prompts, similarities, key=lambda s: s['similarity'])\n","\n","  prompt = ''\n","  for item in n_largest_scores:\n","    prompt += '##############################\\n'\n","    prompt += prefix_list[item['index']]\n","    prompt += gt_list[item['index']]\n","  \n","  prompt += '\\n##############################\\n'\n","  prompt += input\n","  prompt += '\\n'\n","\n","  return prompt"],"metadata":{"id":"yOzAKmLU42bT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, tokenizer, prefix_train, prefix_test, gt_train, gt_test, emb_train, emb_test, num_prompts=1, in_context=False):\n","  total = 0\n","  correct = 0\n","  for idx in range(len(prefix_test)):\n","    if in_context:\n","      text = generate_prompt(prefix_test[idx], prefix_train, gt_train, emb_train, num_prompts=num_prompts)\n","    else:\n","      text = prefix_test[idx]\n","\n","    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n","\n","    generated_ids = model.generate(input_ids, max_new_tokens=1)\n","    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","    predicted_token = generated_text.split()[-1].lower()\n","\n","    total = total + 1\n","    print(predicted_token)\n","    print(gt_test[idx])\n","    if predicted_token == gt_test[idx] or gt_test[idx].startswith(predicted_token):\n","      correct = correct + 1\n","    \n","    EM = correct / total\n","    print(\"EM: \", EM)\n","\n","  return EM"],"metadata":{"id":"bFIcNubq7J1j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate(model_codegen, tokenizer_codegen, prefix_train, prefix_test, gt_train, gt_test, emb_train, emb_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q6pei8Hf8bn7","executionInfo":{"status":"ok","timestamp":1678913898218,"user_tz":-60,"elapsed":85205,"user":{"displayName":"Jiaming Tong","userId":"08738272112358727425"}},"outputId":"fb2f3355-63ee-4054-a4b0-8d04d55f2a7b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["def\n","easter\n","EM:  0.0\n","=\n","get_fixture_path\n","EM:  0.0\n","=\n","get_fixture_path\n","EM:  0.0\n","=\n","scopelinker\n","EM:  0.0\n",":\n","super\n","EM:  0.0\n","assert\n","str\n","EM:  0.0\n","raise\n","attributeerror\n","EM:  0.0\n","*\n","satvapor\n","EM:  0.0\n",":\n","glbegin\n","EM:  0.0\n","=\n","dummyfungen\n","EM:  0.0\n","[\n","type\n","EM:  0.0\n",":\n","print\n","EM:  0.0\n","=\n","problem\n","EM:  0.0\n","if\n","isinstance\n","EM:  0.0\n","assert\n","autocrop_array_shapes\n","EM:  0.0\n","=\n","websocketclient\n","EM:  0.0\n","is\n","isinstance\n","EM:  0.058823529411764705\n","=\n","lock\n","EM:  0.05555555555555555\n","=\n","celery\n","EM:  0.05263157894736842\n","=\n","create_app\n","EM:  0.05\n","\"\"\"<str_lit>\"\"\"\n","print\n","EM:  0.047619047619047616\n","index_pages\n","configure_logging\n","EM:  0.045454545454545456\n","class\n","toobusymiddleware\n","EM:  0.043478260869565216\n","dir\n","join\n","EM:  0.041666666666666664\n","def\n","load_image_list\n","EM:  0.04\n","=\n","zeromqmedium\n","EM:  0.038461538461538464\n","=\n","config\n","EM:  0.037037037037037035\n","return\n","ord\n","EM:  0.03571428571428571\n","raise\n","notimplementederror\n","EM:  0.034482758620689655\n","),\n","open\n","EM:  0.03333333333333333\n","=\n","dependencydecoder\n","EM:  0.03225806451612903\n","=\n","labeldictionary\n","EM:  0.03125\n","in\n","range\n","EM:  0.030303030303030304\n"]},{"output_type":"execute_result","data":{"text/plain":["0.030303030303030304"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["run(model_codegen, tokenizer_codegen, prefix_train, prefix_test, gt_train, gt_test, emb_train, emb_test, in_context=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VJVehZgM9eZS","executionInfo":{"status":"ok","timestamp":1678914167871,"user_tz":-60,"elapsed":269664,"user":{"displayName":"Jiaming Tong","userId":"08738272112358727425"}},"outputId":"eeeee1fa-c4e7-4f0e-ab62-44ee0fe0907b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["e\n","easter\n","EM:  1.0\n","path\n","get_fixture_path\n","EM:  0.5\n","fix\n","get_fixture_path\n","EM:  0.3333333333333333\n","def\n","scopelinker\n","EM:  0.25\n","super\n","super\n","EM:  0.4\n","assert\n","str\n","EM:  0.3333333333333333\n","def\n","attributeerror\n","EM:  0.2857142857142857\n","(\n","satvapor\n","EM:  0.25\n",":\n","glbegin\n","EM:  0.2222222222222222\n","sh\n","dummyfungen\n","EM:  0.2\n","b\n","type\n","EM:  0.18181818181818182\n","from\n","print\n","EM:  0.16666666666666666\n","from\n","problem\n","EM:  0.15384615384615385\n","def\n","isinstance\n","EM:  0.14285714285714285\n","aut\n","autocrop_array_shapes\n","EM:  0.2\n","web\n","websocketclient\n","EM:  0.25\n","self\n","isinstance\n","EM:  0.23529411764705882\n","lock\n","lock\n","EM:  0.2777777777777778\n","cel\n","celery\n","EM:  0.3157894736842105\n","################\n","create_app\n","EM:  0.3\n","def\n","print\n","EM:  0.2857142857142857\n","class\n","configure_logging\n","EM:  0.2727272727272727\n","def\n","toobusymiddleware\n","EM:  0.2608695652173913\n","################\n","join\n","EM:  0.25\n","train\n","load_image_list\n","EM:  0.24\n","#\n","zeromqmedium\n","EM:  0.23076923076923078\n","################\n","config\n","EM:  0.2222222222222222\n","def\n","ord\n","EM:  0.21428571428571427\n","def\n","notimplementederror\n","EM:  0.20689655172413793\n","path\n","open\n","EM:  0.2\n","self\n","dependencydecoder\n","EM:  0.1935483870967742\n","{\n","labeldictionary\n","EM:  0.1875\n","layer\n","range\n","EM:  0.18181818181818182\n"]},{"output_type":"execute_result","data":{"text/plain":["0.18181818181818182"]},"metadata":{},"execution_count":47}]}]}