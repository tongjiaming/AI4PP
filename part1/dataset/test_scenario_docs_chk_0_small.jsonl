{"repo":"abilian","path":"abilian\/\/web\/forms\/fields.pyclass:ModelFieldList\/__call__","language":"python","sha":"fe642b0f60c914e3db79b32130e4283b4696f185","url":"abilian\/\/web\/forms\/fields.pyclass:ModelFieldList\/__call__","partition":"test","code":"def __call__(self, **kwargs):\n    Refill with default min_entry, which were possibly removed by\n        FilterFieldListMixin.\n\n        Mandatory for proper function of DynamicRowWidget which clones\n        an existing field\n        \"\"\"\n    while len(self) < self.min_entries:\n        self.append_entry()\n    return super().__call__(**kwargs)\n","original_string":"def __call__(self, **kwargs):\n    \"\"\"Refill with default min_entry, which were possibly removed by\n        FilterFieldListMixin.\n\n        Mandatory for proper function of DynamicRowWidget which clones\n        an existing field\n        \"\"\"\n    while len(self) < self.min_entries:\n        self.append_entry()\n    return super().__call__(**kwargs)\n","code_tokens":["def","__call__(self,","**kwargs):\n","","","","Refill","with","default","min_entry,","which","were","possibly","removed","by\n","","","","","","","","FilterFieldListMixin.\n\n","","","","","","","","Mandatory","for","proper","function","of","DynamicRowWidget","which","clones\n","","","","","","","","an","existing","field\n","","","","","","","","\"\"\"\n","","","","while","len(self)","<","self.min_entries:\n","","","","","","","","self.append_entry()\n","","","","return","super().__call__(**kwargs)\n"],"func_name":"abilian\/class:ModelFieldList\/__call__","docstring":"Refill with default min_entry, which were possibly removed by\nFilterFieldListMixin.\n\nMandatory for proper function of DynamicRowWidget which clones\nan existing field","docstring_tokens":["Refill","with","default","min_entry",",","which","were","possibly","removed","by","FilterFieldListMixin",".","Mandatory","for","proper","function","of","DynamicRowWidget","which","clones","an","existing","field"],"summary":"Refill with default min_entry, which were possibly removed by","code_with_docstring":"def __call__(self, **kwargs):\n    \"\"\"Refill with default min_entry, which were possibly removed by\n        FilterFieldListMixin.\n\n        Mandatory for proper function of DynamicRowWidget which clones\n        an existing field\n        \"\"\"\n    while len(self) < self.min_entries:\n        self.append_entry()\n    return super().__call__(**kwargs)\n","code_tokens_py":[]}
{"repo":"onegov.user-0.22.5","path":"onegov.user-0.22.5\/\/onegov\/user\/collections\/user.pyclass:UserCollection\/by_username_and_password","language":"python","sha":"2a49b74a86678d3b31b51c2fac8f64f210337664","url":"onegov.user-0.22.5\/\/onegov\/user\/collections\/user.pyclass:UserCollection\/by_username_and_password","partition":"test","code":"def by_username_and_password(self, username, password):\n     Returns the user by username and password.\n\n        Note that although the password can be empty on the user, this function\n        will not query for empty passwords as an added security measure.\n\n        Apart from that everything is fair game though, as it is not the job\n        of onegov.user to enforce a password policy.\n\n        \"\"\"\n    user = self.by_username(username)\n    if user and password and user.is_matching_password(password):\n        return user\n    else:\n        return None\n","original_string":"def by_username_and_password(self, username, password):\n    \"\"\" Returns the user by username and password.\n\n        Note that although the password can be empty on the user, this function\n        will not query for empty passwords as an added security measure.\n\n        Apart from that everything is fair game though, as it is not the job\n        of onegov.user to enforce a password policy.\n\n        \"\"\"\n    user = self.by_username(username)\n    if user and password and user.is_matching_password(password):\n        return user\n    else:\n        return None\n","code_tokens":["def","by_username_and_password(self,","username,","password):\n","","","","","Returns","the","user","by","username","and","password.\n\n","","","","","","","","Note","that","although","the","password","can","be","empty","on","the","user,","this","function\n","","","","","","","","will","not","query","for","empty","passwords","as","an","added","security","measure.\n\n","","","","","","","","Apart","from","that","everything","is","fair","game","though,","as","it","is","not","the","job\n","","","","","","","","of","onegov.user","to","enforce","a","password","policy.\n\n","","","","","","","","\"\"\"\n","","","","user","=","self.by_username(username)\n","","","","if","user","and","password","and","user.is_matching_password(password):\n","","","","","","","","return","user\n","","","","else:\n","","","","","","","","return","None\n"],"func_name":"onegov.user-0.22.5\/class:UserCollection\/by_username_and_password","docstring":"Returns the user by username and password.\n\nNote that although the password can be empty on the user, this function\nwill not query for empty passwords as an added security measure.\n\nApart from that everything is fair game though, as it is not the job\nof onegov.user to enforce a password policy.","docstring_tokens":["Returns","the","user","by","username","and","password",".","Note","that","although","the","password","can","be","empty","on","the","user",",","this","function","will","not","query","for","empty","passwords","as","an","added","security","measure",".","Apart","from","that","everything","is","fair","game","though",",","as","it","is","not","the","job","of","onegov.user","to","enforce","a","password","policy","."],"summary":"Returns the user by username and password.","code_with_docstring":"def by_username_and_password(self, username, password):\n    \"\"\" Returns the user by username and password.\n\n        Note that although the password can be empty on the user, this function\n        will not query for empty passwords as an added security measure.\n\n        Apart from that everything is fair game though, as it is not the job\n        of onegov.user to enforce a password policy.\n\n        \"\"\"\n    user = self.by_username(username)\n    if user and password and user.is_matching_password(password):\n        return user\n    else:\n        return None\n","code_tokens_py":[]}
{"repo":"ipatok","path":"ipatok\/\/ipa.pyclass:Chart\/load_ipa","language":"python","sha":"0c188605511d7b1707870a722ab48d3c81aa071e","url":"ipatok\/\/ipa.pyclass:Chart\/load_ipa","partition":"test","code":"def load_ipa(self, file_path):\n    \n\t\t\n\t\t\"\"\"\n    sections = {'# consonants (pulmonic)': self.consonants,\n        '# consonants (non-pulmonic)': self.consonants, '# other symbols':\n        self.consonants, '# tie bars': self.tie_bars, '# vowels': self.\n        vowels, '# diacritics': self.diacritics, '# suprasegmentals': self.\n        suprasegmentals, '# lengths': self.lengths,\n        '# tones and word accents': self.tones}\n    curr_section = None\n    with open(file_path, encoding='utf-8') as f:\n        for line in map(lambda x: x.strip(), f):\n            if line.startswith('#'):\n                if line in sections:\n                    curr_section = sections[line]\n                else:\n                    curr_section = None\n            elif line:\n                if curr_section is not None:\n                    curr_section.add(line.split('\\t')[0])\n","original_string":"def load_ipa(self, file_path):\n    \"\"\"\n\t\tPopulate the instance's set properties using the specified file.\n\t\t\"\"\"\n    sections = {'# consonants (pulmonic)': self.consonants,\n        '# consonants (non-pulmonic)': self.consonants, '# other symbols':\n        self.consonants, '# tie bars': self.tie_bars, '# vowels': self.\n        vowels, '# diacritics': self.diacritics, '# suprasegmentals': self.\n        suprasegmentals, '# lengths': self.lengths,\n        '# tones and word accents': self.tones}\n    curr_section = None\n    with open(file_path, encoding='utf-8') as f:\n        for line in map(lambda x: x.strip(), f):\n            if line.startswith('#'):\n                if line in sections:\n                    curr_section = sections[line]\n                else:\n                    curr_section = None\n            elif line:\n                if curr_section is not None:\n                    curr_section.add(line.split('\\t')[0])\n","code_tokens":["def","load_ipa(self,","file_path):\n","","","","\n\t\t\n\t\t\"\"\"\n","","","","sections","=","{'#","consonants","(pulmonic)':","self.consonants,\n","","","","","","","","'#","consonants","(non-pulmonic)':","self.consonants,","'#","other","symbols':\n","","","","","","","","self.consonants,","'#","tie","bars':","self.tie_bars,","'#","vowels':","self.\n","","","","","","","","vowels,","'#","diacritics':","self.diacritics,","'#","suprasegmentals':","self.\n","","","","","","","","suprasegmentals,","'#","lengths':","self.lengths,\n","","","","","","","","'#","tones","and","word","accents':","self.tones}\n","","","","curr_section","=","None\n","","","","with","open(file_path,","encoding='utf-8')","as","f:\n","","","","","","","","for","line","in","map(lambda","x:","x.strip(),","f):\n","","","","","","","","","","","","if","line.startswith('#'):\n","","","","","","","","","","","","","","","","if","line","in","sections:\n","","","","","","","","","","","","","","","","","","","","curr_section","=","sections[line]\n","","","","","","","","","","","","","","","","else:\n","","","","","","","","","","","","","","","","","","","","curr_section","=","None\n","","","","","","","","","","","","elif","line:\n","","","","","","","","","","","","","","","","if","curr_section","is","not","None:\n","","","","","","","","","","","","","","","","","","","","curr_section.add(line.split('\\t')[0])\n"],"func_name":"ipatok\/class:Chart\/load_ipa","docstring":"Populate the instance's set properties using the specified file.","docstring_tokens":["Populate","the","instance","'s","set","properties","using","the","specified","file","."],"summary":"Populate the instance's set properties using the specified file.","code_with_docstring":"def load_ipa(self, file_path):\n    \"\"\"\n\t\tPopulate the instance's set properties using the specified file.\n\t\t\"\"\"\n    sections = {'# consonants (pulmonic)': self.consonants,\n        '# consonants (non-pulmonic)': self.consonants, '# other symbols':\n        self.consonants, '# tie bars': self.tie_bars, '# vowels': self.\n        vowels, '# diacritics': self.diacritics, '# suprasegmentals': self.\n        suprasegmentals, '# lengths': self.lengths,\n        '# tones and word accents': self.tones}\n    curr_section = None\n    with open(file_path, encoding='utf-8') as f:\n        for line in map(lambda x: x.strip(), f):\n            if line.startswith('#'):\n                if line in sections:\n                    curr_section = sections[line]\n                else:\n                    curr_section = None\n            elif line:\n                if curr_section is not None:\n                    curr_section.add(line.split('\\t')[0])\n","code_tokens_py":[]}
{"repo":"mxnet","path":"mxnet\/\/numpy\/multiarray.pyclass:ndarray\/reshape_view","language":"python","sha":"fae53edeee2d9b2d6755c6896ded0aed4b208962","url":"mxnet\/\/numpy\/multiarray.pyclass:ndarray\/reshape_view","partition":"test","code":"def reshape_view(self, *shape, **kwargs):\n    Returns a **view** of this array with a new shape without altering any data.\n        Inheritated from NDArray.reshape.\n        \"\"\"\n    return super(ndarray, self).reshape(*shape, **kwargs)\n","original_string":"def reshape_view(self, *shape, **kwargs):\n    \"\"\"Returns a **view** of this array with a new shape without altering any data.\n        Inheritated from NDArray.reshape.\n        \"\"\"\n    return super(ndarray, self).reshape(*shape, **kwargs)\n","code_tokens":["def","reshape_view(self,","*shape,","**kwargs):\n","","","","Returns","a","**view**","of","this","array","with","a","new","shape","without","altering","any","data.\n","","","","","","","","Inheritated","from","NDArray.reshape.\n","","","","","","","","\"\"\"\n","","","","return","super(ndarray,","self).reshape(*shape,","**kwargs)\n"],"func_name":"mxnet\/class:ndarray\/reshape_view","docstring":"Returns a **view** of this array with a new shape without altering any data.\nInheritated from NDArray.reshape.","docstring_tokens":["Returns","a","*","*","view","*","*","of","this","array","with","a","new","shape","without","altering","any","data",".","Inheritated","from","NDArray.reshape","."],"summary":"Returns a **view** of this array with a new shape without altering any data.","code_with_docstring":"def reshape_view(self, *shape, **kwargs):\n    \"\"\"Returns a **view** of this array with a new shape without altering any data.\n        Inheritated from NDArray.reshape.\n        \"\"\"\n    return super(ndarray, self).reshape(*shape, **kwargs)\n","code_tokens_py":[]}
{"repo":"wagtail_modeltranslation","path":"wagtail_modeltranslation\/\/patch_wagtailadmin.pyclass:WagtailTranslator\/_patch_panels","language":"python","sha":"532f7663343ef8e0e43410cb86596bd9805e0bf2","url":"wagtail_modeltranslation\/\/patch_wagtailadmin.pyclass:WagtailTranslator\/_patch_panels","partition":"test","code":"def _patch_panels(self, panels_list, related_model=None):\n    \n            Patching of the admin panels. If we're patching an InlinePanel panels we must provide\n             the related model for that class, otherwise its used the model passed on init.\n        \"\"\"\n    patched_panels = []\n    current_patching_model = related_model or self.patched_model\n    for panel in panels_list:\n        if panel.__class__ in SIMPLE_PANEL_CLASSES:\n            patched_panels += self._patch_simple_panel(current_patching_model,\n                panel)\n        elif panel.__class__ in COMPOSED_PANEL_CLASSES:\n            patched_panels.append(self._patch_composed_panel(panel,\n                related_model))\n        elif panel.__class__ == InlinePanel:\n            patched_panels.append(self._patch_inline_panel(panel))\n        else:\n            patched_panels.append(panel)\n    return patched_panels\n","original_string":"def _patch_panels(self, panels_list, related_model=None):\n    \"\"\"\n            Patching of the admin panels. If we're patching an InlinePanel panels we must provide\n             the related model for that class, otherwise its used the model passed on init.\n        \"\"\"\n    patched_panels = []\n    current_patching_model = related_model or self.patched_model\n    for panel in panels_list:\n        if panel.__class__ in SIMPLE_PANEL_CLASSES:\n            patched_panels += self._patch_simple_panel(current_patching_model,\n                panel)\n        elif panel.__class__ in COMPOSED_PANEL_CLASSES:\n            patched_panels.append(self._patch_composed_panel(panel,\n                related_model))\n        elif panel.__class__ == InlinePanel:\n            patched_panels.append(self._patch_inline_panel(panel))\n        else:\n            patched_panels.append(panel)\n    return patched_panels\n","code_tokens":["def","_patch_panels(self,","panels_list,","related_model=None):\n","","","","\n","","","","","","","","","","","","Patching","of","the","admin","panels.","If","we're","patching","an","InlinePanel","panels","we","must","provide\n","","","","","","","","","","","","","the","related","model","for","that","class,","otherwise","its","used","the","model","passed","on","init.\n","","","","","","","","\"\"\"\n","","","","patched_panels","=","[]\n","","","","current_patching_model","=","related_model","or","self.patched_model\n","","","","for","panel","in","panels_list:\n","","","","","","","","if","panel.__class__","in","SIMPLE_PANEL_CLASSES:\n","","","","","","","","","","","","patched_panels","+=","self._patch_simple_panel(current_patching_model,\n","","","","","","","","","","","","","","","","panel)\n","","","","","","","","elif","panel.__class__","in","COMPOSED_PANEL_CLASSES:\n","","","","","","","","","","","","patched_panels.append(self._patch_composed_panel(panel,\n","","","","","","","","","","","","","","","","related_model))\n","","","","","","","","elif","panel.__class__","==","InlinePanel:\n","","","","","","","","","","","","patched_panels.append(self._patch_inline_panel(panel))\n","","","","","","","","else:\n","","","","","","","","","","","","patched_panels.append(panel)\n","","","","return","patched_panels\n"],"func_name":"wagtail_modeltranslation\/class:WagtailTranslator\/_patch_panels","docstring":"Patching of the admin panels. If we're patching an InlinePanel panels we must provide\n the related model for that class, otherwise its used the model passed on init.","docstring_tokens":["Patching","of","the","admin","panels",".","If","we","'re","patching","an","InlinePanel","panels","we","must","provide","the","related","model","for","that","class",",","otherwise","its","used","the","model","passed","on","init","."],"summary":"Patching of the admin panels. If we're patching an InlinePanel panels we must provide","code_with_docstring":"def _patch_panels(self, panels_list, related_model=None):\n    \"\"\"\n            Patching of the admin panels. If we're patching an InlinePanel panels we must provide\n             the related model for that class, otherwise its used the model passed on init.\n        \"\"\"\n    patched_panels = []\n    current_patching_model = related_model or self.patched_model\n    for panel in panels_list:\n        if panel.__class__ in SIMPLE_PANEL_CLASSES:\n            patched_panels += self._patch_simple_panel(current_patching_model,\n                panel)\n        elif panel.__class__ in COMPOSED_PANEL_CLASSES:\n            patched_panels.append(self._patch_composed_panel(panel,\n                related_model))\n        elif panel.__class__ == InlinePanel:\n            patched_panels.append(self._patch_inline_panel(panel))\n        else:\n            patched_panels.append(panel)\n    return patched_panels\n","code_tokens_py":[]}
{"repo":"nbxmpp-0.6.10","path":"nbxmpp-0.6.10\/\/nbxmpp\/client_nb.pyclass:NonBlockingClient\/getRoster","language":"python","sha":"1e1000d312f1762edf6c63894f0e87caa08e685c","url":"nbxmpp-0.6.10\/\/nbxmpp\/client_nb.pyclass:NonBlockingClient\/getRoster","partition":"test","code":"def getRoster(self, on_ready=None, force=False):\n    \n        Return the Roster instance, previously plugging it in and requesting\n        roster from server if needed\n        \"\"\"\n    if 'NonBlockingRoster' in self.__dict__:\n        return self.NonBlockingRoster.getRoster(on_ready, force)\n    return None\n","original_string":"def getRoster(self, on_ready=None, force=False):\n    \"\"\"\n        Return the Roster instance, previously plugging it in and requesting\n        roster from server if needed\n        \"\"\"\n    if 'NonBlockingRoster' in self.__dict__:\n        return self.NonBlockingRoster.getRoster(on_ready, force)\n    return None\n","code_tokens":["def","getRoster(self,","on_ready=None,","force=False):\n","","","","\n","","","","","","","","Return","the","Roster","instance,","previously","plugging","it","in","and","requesting\n","","","","","","","","roster","from","server","if","needed\n","","","","","","","","\"\"\"\n","","","","if","'NonBlockingRoster'","in","self.__dict__:\n","","","","","","","","return","self.NonBlockingRoster.getRoster(on_ready,","force)\n","","","","return","None\n"],"func_name":"nbxmpp-0.6.10\/class:NonBlockingClient\/getRoster","docstring":"Return the Roster instance, previously plugging it in and requesting\nroster from server if needed","docstring_tokens":["Return","the","Roster","instance",",","previously","plugging","it","in","and","requesting","roster","from","server","if","needed"],"summary":"Return the Roster instance, previously plugging it in and requesting","code_with_docstring":"def getRoster(self, on_ready=None, force=False):\n    \"\"\"\n        Return the Roster instance, previously plugging it in and requesting\n        roster from server if needed\n        \"\"\"\n    if 'NonBlockingRoster' in self.__dict__:\n        return self.NonBlockingRoster.getRoster(on_ready, force)\n    return None\n","code_tokens_py":[]}
{"repo":"comet","path":"comet\/\/metrics\/utils.pyfile:\/metrics\/utils.py:function:temp_to_energy\/temp_to_energy","language":"python","sha":"91e00f9248bb46c07e32a765f505b769ec6fc00b","url":"comet\/\/metrics\/utils.pyfile:\/metrics\/utils.py:function:temp_to_energy\/temp_to_energy","partition":"test","code":"@curry\ndef temp_to_energy(t):\n    Calculate the amount of heat energy in an air parcel\n    using the specific heat capacity\n    \n    Parameters\n    ----------\n    t : float\n        dry bulb temperature [Kelvin]\n\n    Return\n    ------\n    float\n        heat energy [J\/kg]\n    \"\"\"\n    return cnts.cp.value * t\n","original_string":"@curry\ndef temp_to_energy(t):\n    \"\"\"Calculate the amount of heat energy in an air parcel\n    using the specific heat capacity\n    \n    Parameters\n    ----------\n    t : float\n        dry bulb temperature [Kelvin]\n\n    Return\n    ------\n    float\n        heat energy [J\/kg]\n    \"\"\"\n    return cnts.cp.value * t\n","code_tokens":["@curry\ndef","temp_to_energy(t):\n","","","","Calculate","the","amount","of","heat","energy","in","an","air","parcel\n","","","","using","the","specific","heat","capacity\n","","","","\n","","","","Parameters\n","","","","----------\n","","","","t",":","float\n","","","","","","","","dry","bulb","temperature","[Kelvin]\n\n","","","","Return\n","","","","------\n","","","","float\n","","","","","","","","heat","energy","[J\/kg]\n","","","","\"\"\"\n","","","","return","cnts.cp.value","*","t\n"],"func_name":"comet\/file:\/metrics\/utils.py:function:temp_to_energy\/temp_to_energy","docstring":"Calculate the amount of heat energy in an air parcel\nusing the specific heat capacity\n\nParameters\n----------\nt : float\n    dry bulb temperature [Kelvin]\n\nReturn\n------\nfloat\n    heat energy [J\/kg]","docstring_tokens":["Calculate","the","amount","of","heat","energy","in","an","air","parcel","using","the","specific","heat","capacity","Parameters","----------","t",":","float","dry","bulb","temperature","[","Kelvin","]","Return","------","float","heat","energy","[","J","\/","kg","]"],"summary":"Calculate the amount of heat energy in an air parcel","code_with_docstring":"@curry\ndef temp_to_energy(t):\n    \"\"\"Calculate the amount of heat energy in an air parcel\n    using the specific heat capacity\n    \n    Parameters\n    ----------\n    t : float\n        dry bulb temperature [Kelvin]\n\n    Return\n    ------\n    float\n        heat energy [J\/kg]\n    \"\"\"\n    return cnts.cp.value * t\n","code_tokens_py":[]}
{"repo":"ceilosca","path":"ceilosca\/\/ceilometer\/publisher\/monasca.pyclass:MonascaPublisher\/publish_events","language":"python","sha":"69ab47e3f31d1b41458fe5f03caa98089ca6e2ee","url":"ceilosca\/\/ceilometer\/publisher\/monasca.pyclass:MonascaPublisher\/publish_events","partition":"test","code":"def publish_events(self, events):\n    Send an event message for publishing\n\n        :param events: events from pipeline after transformation\n        \"\"\"\n    raise ceilometer.NotImplementedError\n","original_string":"def publish_events(self, events):\n    \"\"\"Send an event message for publishing\n\n        :param events: events from pipeline after transformation\n        \"\"\"\n    raise ceilometer.NotImplementedError\n","code_tokens":["def","publish_events(self,","events):\n","","","","Send","an","event","message","for","publishing\n\n","","","","","","","",":param","events:","events","from","pipeline","after","transformation\n","","","","","","","","\"\"\"\n","","","","raise","ceilometer.NotImplementedError\n"],"func_name":"ceilosca\/class:MonascaPublisher\/publish_events","docstring":"Send an event message for publishing\n\n:param events: events from pipeline after transformation","docstring_tokens":["Send","an","event","message","for","publishing",":","param","events",":","events","from","pipeline","after","transformation"],"summary":"Send an event message for publishing","code_with_docstring":"def publish_events(self, events):\n    \"\"\"Send an event message for publishing\n\n        :param events: events from pipeline after transformation\n        \"\"\"\n    raise ceilometer.NotImplementedError\n","code_tokens_py":[]}
{"repo":"libarchive","path":"libarchive\/\/entry.pyfile:\/entry.py:function:format_time\/format_time","language":"python","sha":"8020a5ea513cd38240dcb37bea56e684fbe3624d","url":"libarchive\/\/entry.pyfile:\/entry.py:function:format_time\/format_time","partition":"test","code":"def format_time(seconds, nanos):\n     \"\"\"\n    if nanos:\n        return float(seconds) + float(nanos) \/ 1000000000.0\n    return int(seconds)\n","original_string":"def format_time(seconds, nanos):\n    \"\"\" return float of seconds.nanos when nanos set, or seconds when not \"\"\"\n    if nanos:\n        return float(seconds) + float(nanos) \/ 1000000000.0\n    return int(seconds)\n","code_tokens":["def","format_time(seconds,","nanos):\n","","","","","\"\"\"\n","","","","if","nanos:\n","","","","","","","","return","float(seconds)","+","float(nanos)","\/","1000000000.0\n","","","","return","int(seconds)\n"],"func_name":"libarchive\/file:\/entry.py:function:format_time\/format_time","docstring":"return float of seconds.nanos when nanos set, or seconds when not ","docstring_tokens":["return","float","of","seconds.nanos","when","nanos","set",",","or","seconds","when","not"],"summary":"return float of seconds.nanos when nanos set, or seconds when not ","code_with_docstring":"def format_time(seconds, nanos):\n    \"\"\" return float of seconds.nanos when nanos set, or seconds when not \"\"\"\n    if nanos:\n        return float(seconds) + float(nanos) \/ 1000000000.0\n    return int(seconds)\n","code_tokens_py":[]}
{"repo":"image-titler-2.1.1","path":"image-titler-2.1.1\/\/image_titler\/utilities.pyfile:\/image_titler\/utilities.py:function:_draw_overlay\/_draw_overlay","language":"python","sha":"04396f17622315707fa4e1f9c7af868950e8076d","url":"image-titler-2.1.1\/\/image_titler\/utilities.pyfile:\/image_titler\/utilities.py:function:_draw_overlay\/_draw_overlay","partition":"test","code":"def _draw_overlay(image: Image.Image, title: str, tier: str, color: tuple=\n    RECTANGLE_FILL, font: str=FONT) ->Image:\n    \n    Draws text over an image.\n\n    :param color: the color of the overlay bar\n    :param image: an image\n    :param title: the image title\n    :param tier: the image tier\n    :return: the updated image\n    \"\"\"\n    draw = ImageDraw.Draw(image)\n    font = ImageFont.truetype(font, FONT_SIZE)\n    if len(title.split()) > 1:\n        top_half_text, bottom_half_text = split_string_by_nearest_middle_space(\n            title)\n    else:\n        top_half_text, bottom_half_text = title, None\n    width, top_offset, height, _ = _get_text_metrics(top_half_text, font)\n    top_position = _get_text_position(width, height, top_offset,\n        TOP_RECTANGLE_Y)\n    _draw_rectangle(draw, TOP_RECTANGLE_Y, width, tier, color)\n    _draw_text(draw, top_position, top_half_text, font)\n    if bottom_half_text:\n        width, top_offset, height, _ = _get_text_metrics(bottom_half_text, font\n            )\n        bottom_position = _get_text_position(width, height, top_offset,\n            BOTTOM_RECTANGLE_Y)\n        _draw_rectangle(draw, BOTTOM_RECTANGLE_Y, width, tier, color)\n        _draw_text(draw, bottom_position, bottom_half_text, font)\n    return image\n","original_string":"def _draw_overlay(image: Image.Image, title: str, tier: str, color: tuple=\n    RECTANGLE_FILL, font: str=FONT) ->Image:\n    \"\"\"\n    Draws text over an image.\n\n    :param color: the color of the overlay bar\n    :param image: an image\n    :param title: the image title\n    :param tier: the image tier\n    :return: the updated image\n    \"\"\"\n    draw = ImageDraw.Draw(image)\n    font = ImageFont.truetype(font, FONT_SIZE)\n    if len(title.split()) > 1:\n        top_half_text, bottom_half_text = split_string_by_nearest_middle_space(\n            title)\n    else:\n        top_half_text, bottom_half_text = title, None\n    width, top_offset, height, _ = _get_text_metrics(top_half_text, font)\n    top_position = _get_text_position(width, height, top_offset,\n        TOP_RECTANGLE_Y)\n    _draw_rectangle(draw, TOP_RECTANGLE_Y, width, tier, color)\n    _draw_text(draw, top_position, top_half_text, font)\n    if bottom_half_text:\n        width, top_offset, height, _ = _get_text_metrics(bottom_half_text, font\n            )\n        bottom_position = _get_text_position(width, height, top_offset,\n            BOTTOM_RECTANGLE_Y)\n        _draw_rectangle(draw, BOTTOM_RECTANGLE_Y, width, tier, color)\n        _draw_text(draw, bottom_position, bottom_half_text, font)\n    return image\n","code_tokens":["def","_draw_overlay(image:","Image.Image,","title:","str,","tier:","str,","color:","tuple=\n","","","","RECTANGLE_FILL,","font:","str=FONT)","->Image:\n","","","","\n","","","","Draws","text","over","an","image.\n\n","","","",":param","color:","the","color","of","the","overlay","bar\n","","","",":param","image:","an","image\n","","","",":param","title:","the","image","title\n","","","",":param","tier:","the","image","tier\n","","","",":return:","the","updated","image\n","","","","\"\"\"\n","","","","draw","=","ImageDraw.Draw(image)\n","","","","font","=","ImageFont.truetype(font,","FONT_SIZE)\n","","","","if","len(title.split())",">","1:\n","","","","","","","","top_half_text,","bottom_half_text","=","split_string_by_nearest_middle_space(\n","","","","","","","","","","","","title)\n","","","","else:\n","","","","","","","","top_half_text,","bottom_half_text","=","title,","None\n","","","","width,","top_offset,","height,","_","=","_get_text_metrics(top_half_text,","font)\n","","","","top_position","=","_get_text_position(width,","height,","top_offset,\n","","","","","","","","TOP_RECTANGLE_Y)\n","","","","_draw_rectangle(draw,","TOP_RECTANGLE_Y,","width,","tier,","color)\n","","","","_draw_text(draw,","top_position,","top_half_text,","font)\n","","","","if","bottom_half_text:\n","","","","","","","","width,","top_offset,","height,","_","=","_get_text_metrics(bottom_half_text,","font\n","","","","","","","","","","","",")\n","","","","","","","","bottom_position","=","_get_text_position(width,","height,","top_offset,\n","","","","","","","","","","","","BOTTOM_RECTANGLE_Y)\n","","","","","","","","_draw_rectangle(draw,","BOTTOM_RECTANGLE_Y,","width,","tier,","color)\n","","","","","","","","_draw_text(draw,","bottom_position,","bottom_half_text,","font)\n","","","","return","image\n"],"func_name":"image-titler-2.1.1\/file:\/image_titler\/utilities.py:function:_draw_overlay\/_draw_overlay","docstring":"Draws text over an image.\n\n:param color: the color of the overlay bar\n:param image: an image\n:param title: the image title\n:param tier: the image tier\n:return: the updated image","docstring_tokens":["Draws","text","over","an","image",".",":","param","color",":","the","color","of","the","overlay","bar",":","param","image",":","an","image",":","param","title",":","the","image","title",":","param","tier",":","the","image","tier",":","return",":","the","updated","image"],"summary":"Draws text over an image.","code_with_docstring":"def _draw_overlay(image: Image.Image, title: str, tier: str, color: tuple=\n    RECTANGLE_FILL, font: str=FONT) ->Image:\n    \"\"\"\n    Draws text over an image.\n\n    :param color: the color of the overlay bar\n    :param image: an image\n    :param title: the image title\n    :param tier: the image tier\n    :return: the updated image\n    \"\"\"\n    draw = ImageDraw.Draw(image)\n    font = ImageFont.truetype(font, FONT_SIZE)\n    if len(title.split()) > 1:\n        top_half_text, bottom_half_text = split_string_by_nearest_middle_space(\n            title)\n    else:\n        top_half_text, bottom_half_text = title, None\n    width, top_offset, height, _ = _get_text_metrics(top_half_text, font)\n    top_position = _get_text_position(width, height, top_offset,\n        TOP_RECTANGLE_Y)\n    _draw_rectangle(draw, TOP_RECTANGLE_Y, width, tier, color)\n    _draw_text(draw, top_position, top_half_text, font)\n    if bottom_half_text:\n        width, top_offset, height, _ = _get_text_metrics(bottom_half_text, font\n            )\n        bottom_position = _get_text_position(width, height, top_offset,\n            BOTTOM_RECTANGLE_Y)\n        _draw_rectangle(draw, BOTTOM_RECTANGLE_Y, width, tier, color)\n        _draw_text(draw, bottom_position, bottom_half_text, font)\n    return image\n","code_tokens_py":[]}
{"repo":"pyBTK-0.1.1","path":"pyBTK-0.1.1\/\/pyBTK\/btk.pyclass:btkXMOVEFileIO\/GetStorageFormat","language":"python","sha":"d72fa51ae5d50f8b534ad150c048911087b1ba78","url":"pyBTK-0.1.1\/\/pyBTK\/btk.pyclass:btkXMOVEFileIO\/GetStorageFormat","partition":"test","code":"def GetStorageFormat(self):\n    \n        GetStorageFormat(self) -> btkAcquisitionFileIO_impl::StorageFormat\n\n        Return the format used to store points and analog channels.\n        \"\"\"\n    return _btk.btkXMOVEFileIO_GetStorageFormat(self)\n","original_string":"def GetStorageFormat(self):\n    \"\"\"\n        GetStorageFormat(self) -> btkAcquisitionFileIO_impl::StorageFormat\n\n        Return the format used to store points and analog channels.\n        \"\"\"\n    return _btk.btkXMOVEFileIO_GetStorageFormat(self)\n","code_tokens":["def","GetStorageFormat(self):\n","","","","\n","","","","","","","","GetStorageFormat(self)","->","btkAcquisitionFileIO_impl::StorageFormat\n\n","","","","","","","","Return","the","format","used","to","store","points","and","analog","channels.\n","","","","","","","","\"\"\"\n","","","","return","_btk.btkXMOVEFileIO_GetStorageFormat(self)\n"],"func_name":"pyBTK-0.1.1\/class:btkXMOVEFileIO\/GetStorageFormat","docstring":"GetStorageFormat(self) -> btkAcquisitionFileIO_impl::StorageFormat\n\nReturn the format used to store points and analog channels.","docstring_tokens":["GetStorageFormat(self",")","-",">","btkAcquisitionFileIO_impl::StorageFormat","Return","the","format","used","to","store","points","and","analog","channels","."],"summary":"GetStorageFormat(self) -> btkAcquisitionFileIO_impl::StorageFormat","code_with_docstring":"def GetStorageFormat(self):\n    \"\"\"\n        GetStorageFormat(self) -> btkAcquisitionFileIO_impl::StorageFormat\n\n        Return the format used to store points and analog channels.\n        \"\"\"\n    return _btk.btkXMOVEFileIO_GetStorageFormat(self)\n","code_tokens_py":[]}
{"repo":"blitzdb-0.4.4","path":"blitzdb-0.4.4\/\/blitzdb\/backends\/file\/index.pyclass:Index\/save_to_data","language":"python","sha":"748b7b4406e41d24d995b137f954a7e46328bf69","url":"blitzdb-0.4.4\/\/blitzdb\/backends\/file\/index.pyclass:Index\/save_to_data","partition":"test","code":"def save_to_data(self, in_place=False):\n    Save index to data structure.\n\n        :param in_place: Do not copy index value to a new list object\n        :type in_place: bool\n        :return: Index data structure\n        :rtype: list\n\n        \"\"\"\n    if in_place:\n        return [list(self._index.items()), list(self._undefined_keys.keys())]\n    return [(key, values[:]) for key, values in self._index.items()], list(self\n        ._undefined_keys.keys())\n","original_string":"def save_to_data(self, in_place=False):\n    \"\"\"Save index to data structure.\n\n        :param in_place: Do not copy index value to a new list object\n        :type in_place: bool\n        :return: Index data structure\n        :rtype: list\n\n        \"\"\"\n    if in_place:\n        return [list(self._index.items()), list(self._undefined_keys.keys())]\n    return [(key, values[:]) for key, values in self._index.items()], list(self\n        ._undefined_keys.keys())\n","code_tokens":["def","save_to_data(self,","in_place=False):\n","","","","Save","index","to","data","structure.\n\n","","","","","","","",":param","in_place:","Do","not","copy","index","value","to","a","new","list","object\n","","","","","","","",":type","in_place:","bool\n","","","","","","","",":return:","Index","data","structure\n","","","","","","","",":rtype:","list\n\n","","","","","","","","\"\"\"\n","","","","if","in_place:\n","","","","","","","","return","[list(self._index.items()),","list(self._undefined_keys.keys())]\n","","","","return","[(key,","values[:])","for","key,","values","in","self._index.items()],","list(self\n","","","","","","","","._undefined_keys.keys())\n"],"func_name":"blitzdb-0.4.4\/class:Index\/save_to_data","docstring":"Save index to data structure.\n\n:param in_place: Do not copy index value to a new list object\n:type in_place: bool\n:return: Index data structure\n:rtype: list","docstring_tokens":["Save","index","to","data","structure",".",":","param","in_place",":","Do","not","copy","index","value","to","a","new","list","object",":","type","in_place",":","bool",":","return",":","Index","data","structure",":","rtype",":","list"],"summary":"Save index to data structure.","code_with_docstring":"def save_to_data(self, in_place=False):\n    \"\"\"Save index to data structure.\n\n        :param in_place: Do not copy index value to a new list object\n        :type in_place: bool\n        :return: Index data structure\n        :rtype: list\n\n        \"\"\"\n    if in_place:\n        return [list(self._index.items()), list(self._undefined_keys.keys())]\n    return [(key, values[:]) for key, values in self._index.items()], list(self\n        ._undefined_keys.keys())\n","code_tokens_py":[]}
{"repo":"psd-tools-1.9.11","path":"psd-tools-1.9.11\/\/src\/psd_tools\/composite\/blend.pyfile:\/src\/psd_tools\/composite\/blend.py:function:pin_light\/pin_light","language":"python","sha":"bd05486e18c29d29da6933c66c6f5ea5a51a48b8","url":"psd-tools-1.9.11\/\/src\/psd_tools\/composite\/blend.pyfile:\/src\/psd_tools\/composite\/blend.py:function:pin_light\/pin_light","partition":"test","code":"def pin_light(Cb, Cs):\n    \n    Replaces the colors, depending on the blend color. If the blend color\n    (light source) is lighter than 50% gray, pixels darker than the blend color\n    are replaced, and pixels lighter than the blend color do not change. If the\n    blend color is darker than 50% gray, pixels lighter than the blend color\n    are replaced, and pixels darker than the blend color do not change. This is\n    useful for adding special effects to an image.\n    \"\"\"\n    index = Cs > 0.5\n    B = darken(Cb, 2 * Cs)\n    B[index] = lighten(Cb, 2 * Cs - 1)[index]\n    return B\n","original_string":"def pin_light(Cb, Cs):\n    \"\"\"\n    Replaces the colors, depending on the blend color. If the blend color\n    (light source) is lighter than 50% gray, pixels darker than the blend color\n    are replaced, and pixels lighter than the blend color do not change. If the\n    blend color is darker than 50% gray, pixels lighter than the blend color\n    are replaced, and pixels darker than the blend color do not change. This is\n    useful for adding special effects to an image.\n    \"\"\"\n    index = Cs > 0.5\n    B = darken(Cb, 2 * Cs)\n    B[index] = lighten(Cb, 2 * Cs - 1)[index]\n    return B\n","code_tokens":["def","pin_light(Cb,","Cs):\n","","","","\n","","","","Replaces","the","colors,","depending","on","the","blend","color.","If","the","blend","color\n","","","","(light","source)","is","lighter","than","50%","gray,","pixels","darker","than","the","blend","color\n","","","","are","replaced,","and","pixels","lighter","than","the","blend","color","do","not","change.","If","the\n","","","","blend","color","is","darker","than","50%","gray,","pixels","lighter","than","the","blend","color\n","","","","are","replaced,","and","pixels","darker","than","the","blend","color","do","not","change.","This","is\n","","","","useful","for","adding","special","effects","to","an","image.\n","","","","\"\"\"\n","","","","index","=","Cs",">","0.5\n","","","","B","=","darken(Cb,","2","*","Cs)\n","","","","B[index]","=","lighten(Cb,","2","*","Cs","-","1)[index]\n","","","","return","B\n"],"func_name":"psd-tools-1.9.11\/file:\/src\/psd_tools\/composite\/blend.py:function:pin_light\/pin_light","docstring":"Replaces the colors, depending on the blend color. If the blend color\n(light source) is lighter than 50% gray, pixels darker than the blend color\nare replaced, and pixels lighter than the blend color do not change. If the\nblend color is darker than 50% gray, pixels lighter than the blend color\nare replaced, and pixels darker than the blend color do not change. This is\nuseful for adding special effects to an image.","docstring_tokens":["Replaces","the","colors",",","depending","on","the","blend","color",".","If","the","blend","color","(","light","source",")","is","lighter","than","50","%","gray",",","pixels","darker","than","the","blend","color","are","replaced",",","and","pixels","lighter","than","the","blend","color","do","not","change",".","If","the","blend","color","is","darker","than","50","%","gray",",","pixels","lighter","than","the","blend","color","are","replaced",",","and","pixels","darker","than","the","blend","color","do","not","change",".","This","is","useful","for","adding","special","effects","to","an","image","."],"summary":"Replaces the colors, depending on the blend color. If the blend color","code_with_docstring":"def pin_light(Cb, Cs):\n    \"\"\"\n    Replaces the colors, depending on the blend color. If the blend color\n    (light source) is lighter than 50% gray, pixels darker than the blend color\n    are replaced, and pixels lighter than the blend color do not change. If the\n    blend color is darker than 50% gray, pixels lighter than the blend color\n    are replaced, and pixels darker than the blend color do not change. This is\n    useful for adding special effects to an image.\n    \"\"\"\n    index = Cs > 0.5\n    B = darken(Cb, 2 * Cs)\n    B[index] = lighten(Cb, 2 * Cs - 1)[index]\n    return B\n","code_tokens_py":[]}
{"repo":"ibmsecurity","path":"ibmsecurity\/\/isam\/aac\/scim.pyfile:\/isam\/aac\/scim.py:function:update_user_profile\/update_user_profile","language":"python","sha":"efbb335b0491d4aa5978ba6a46fafdf7ef5eb29e","url":"ibmsecurity\/\/isam\/aac\/scim.pyfile:\/isam\/aac\/scim.py:function:update_user_profile\/update_user_profile","partition":"test","code":"def update_user_profile(isamAppliance, ldap_connection, user_suffix,\n    search_suffix, check_mode=False, force=False):\n    \n    \n    \"\"\"\n    ret_obj = get_user_profile(isamAppliance)\n    del ret_obj['ldap_connection']\n    del ret_obj['user_suffix']\n    del ret_obj['search_suffix']\n    ret_obj['ldap_connection'] = ldap_connection\n    ret_obj['user_suffix'] = user_suffix\n    ret_obj['search_suffix'] = search_suffix\n    return isamAppliance.invoke_put('',\n        '\/mga\/scim\/configuration\/urn:ietf:params:scim:schemas:core:2.0:User',\n        ret_obj)\n","original_string":"def update_user_profile(isamAppliance, ldap_connection, user_suffix,\n    search_suffix, check_mode=False, force=False):\n    \"\"\"\n    Update SCIM user profile settings\n    \"\"\"\n    ret_obj = get_user_profile(isamAppliance)\n    del ret_obj['ldap_connection']\n    del ret_obj['user_suffix']\n    del ret_obj['search_suffix']\n    ret_obj['ldap_connection'] = ldap_connection\n    ret_obj['user_suffix'] = user_suffix\n    ret_obj['search_suffix'] = search_suffix\n    return isamAppliance.invoke_put('Update SCIM user profile settings',\n        '\/mga\/scim\/configuration\/urn:ietf:params:scim:schemas:core:2.0:User',\n        ret_obj)\n","code_tokens":["def","update_user_profile(isamAppliance,","ldap_connection,","user_suffix,\n","","","","search_suffix,","check_mode=False,","force=False):\n","","","","\n","","","","\n","","","","\"\"\"\n","","","","ret_obj","=","get_user_profile(isamAppliance)\n","","","","del","ret_obj['ldap_connection']\n","","","","del","ret_obj['user_suffix']\n","","","","del","ret_obj['search_suffix']\n","","","","ret_obj['ldap_connection']","=","ldap_connection\n","","","","ret_obj['user_suffix']","=","user_suffix\n","","","","ret_obj['search_suffix']","=","search_suffix\n","","","","return","isamAppliance.invoke_put('',\n","","","","","","","","'\/mga\/scim\/configuration\/urn:ietf:params:scim:schemas:core:2.0:User',\n","","","","","","","","ret_obj)\n"],"func_name":"ibmsecurity\/file:\/isam\/aac\/scim.py:function:update_user_profile\/update_user_profile","docstring":"Update SCIM user profile settings","docstring_tokens":["Update","SCIM","user","profile","settings"],"summary":"Update SCIM user profile settings","code_with_docstring":"def update_user_profile(isamAppliance, ldap_connection, user_suffix,\n    search_suffix, check_mode=False, force=False):\n    \"\"\"\n    Update SCIM user profile settings\n    \"\"\"\n    ret_obj = get_user_profile(isamAppliance)\n    del ret_obj['ldap_connection']\n    del ret_obj['user_suffix']\n    del ret_obj['search_suffix']\n    ret_obj['ldap_connection'] = ldap_connection\n    ret_obj['user_suffix'] = user_suffix\n    ret_obj['search_suffix'] = search_suffix\n    return isamAppliance.invoke_put('Update SCIM user profile settings',\n        '\/mga\/scim\/configuration\/urn:ietf:params:scim:schemas:core:2.0:User',\n        ret_obj)\n","code_tokens_py":[]}
{"repo":"looker_sdk-0.1.3b10","path":"looker_sdk-0.1.3b10\/\/looker_sdk\/sdk\/api31\/methods.pyclass:Looker31SDK\/legacy_feature","language":"python","sha":"cdde4c4d3f3ce164f14dfde66090c8fe3613998d","url":"looker_sdk-0.1.3b10\/\/looker_sdk\/sdk\/api31\/methods.pyclass:Looker31SDK\/legacy_feature","partition":"test","code":"def legacy_feature(self, legacy_feature_id: int, transport_options:\n    Optional[transport.PTransportSettings]=None) ->models.LegacyFeature:\n    \"\"\"\n    response = self.get(f'\/legacy_features\/{legacy_feature_id}', models.\n        LegacyFeature, transport_options=transport_options)\n    assert isinstance(response, models.LegacyFeature)\n    return response\n","original_string":"def legacy_feature(self, legacy_feature_id: int, transport_options:\n    Optional[transport.PTransportSettings]=None) ->models.LegacyFeature:\n    \"\"\"Get Legacy Feature\"\"\"\n    response = self.get(f'\/legacy_features\/{legacy_feature_id}', models.\n        LegacyFeature, transport_options=transport_options)\n    assert isinstance(response, models.LegacyFeature)\n    return response\n","code_tokens":["def","legacy_feature(self,","legacy_feature_id:","int,","transport_options:\n","","","","Optional[transport.PTransportSettings]=None)","->models.LegacyFeature:\n","","","","\"\"\"\n","","","","response","=","self.get(f'\/legacy_features\/{legacy_feature_id}',","models.\n","","","","","","","","LegacyFeature,","transport_options=transport_options)\n","","","","assert","isinstance(response,","models.LegacyFeature)\n","","","","return","response\n"],"func_name":"looker_sdk-0.1.3b10\/class:Looker31SDK\/legacy_feature","docstring":"Get Legacy Feature","docstring_tokens":["Get","Legacy","Feature"],"summary":"Get Legacy Feature","code_with_docstring":"def legacy_feature(self, legacy_feature_id: int, transport_options:\n    Optional[transport.PTransportSettings]=None) ->models.LegacyFeature:\n    \"\"\"Get Legacy Feature\"\"\"\n    response = self.get(f'\/legacy_features\/{legacy_feature_id}', models.\n        LegacyFeature, transport_options=transport_options)\n    assert isinstance(response, models.LegacyFeature)\n    return response\n","code_tokens_py":[]}
{"repo":"pylbc","path":"pylbc\/\/pylbc.pyclass:Search\/__enable_results","language":"python","sha":"2de58cdc9999831f12cc926c1084602c92c84756","url":"pylbc\/\/pylbc.pyclass:Search\/__enable_results","partition":"test","code":"def __enable_results(self):\n    \n        \n        \"\"\"\n    self.__limit_alu = 1\n    self.__limit = 100\n    self.__prepare_payload()\n","original_string":"def __enable_results(self):\n    \"\"\"\n        Enable the results in teh response.\n        \"\"\"\n    self.__limit_alu = 1\n    self.__limit = 100\n    self.__prepare_payload()\n","code_tokens":["def","__enable_results(self):\n","","","","\n","","","","","","","","\n","","","","","","","","\"\"\"\n","","","","self.__limit_alu","=","1\n","","","","self.__limit","=","100\n","","","","self.__prepare_payload()\n"],"func_name":"pylbc\/class:Search\/__enable_results","docstring":"Enable the results in teh response.","docstring_tokens":["Enable","the","results","in","teh","response","."],"summary":"Enable the results in teh response.","code_with_docstring":"def __enable_results(self):\n    \"\"\"\n        Enable the results in teh response.\n        \"\"\"\n    self.__limit_alu = 1\n    self.__limit = 100\n    self.__prepare_payload()\n","code_tokens_py":[]}
{"repo":"pyblp-0.9.0","path":"pyblp-0.9.0\/\/pyblp\/configurations\/formulation.pyfile:\/pyblp\/configurations\/formulation.py:function:parse_terms\/parse_terms","language":"python","sha":"7020095a2ff47eec3b6973843c7125959d0e03cf","url":"pyblp-0.9.0\/\/pyblp\/configurations\/formulation.pyfile:\/pyblp\/configurations\/formulation.py:function:parse_terms\/parse_terms","partition":"test","code":"def parse_terms(formula: str) ->List[patsy.desc.Term]:\n    \"\"\"\n    description = patsy.highlevel.ModelDesc.from_formula(formula)\n    if description.lhs_termlist:\n        end = formula.index('~') + 1 if '~' in formula else len(formula)\n        raise patsy.PatsyError('Formulas should not have left-hand sides.',\n            patsy.origin.Origin(formula, 0, end))\n    return description.rhs_termlist\n","original_string":"def parse_terms(formula: str) ->List[patsy.desc.Term]:\n    \"\"\"Parse patsy terms from a string. Validate that the string contains only right-hand side terms.\"\"\"\n    description = patsy.highlevel.ModelDesc.from_formula(formula)\n    if description.lhs_termlist:\n        end = formula.index('~') + 1 if '~' in formula else len(formula)\n        raise patsy.PatsyError('Formulas should not have left-hand sides.',\n            patsy.origin.Origin(formula, 0, end))\n    return description.rhs_termlist\n","code_tokens":["def","parse_terms(formula:","str)","->List[patsy.desc.Term]:\n","","","","\"\"\"\n","","","","description","=","patsy.highlevel.ModelDesc.from_formula(formula)\n","","","","if","description.lhs_termlist:\n","","","","","","","","end","=","formula.index('~')","+","1","if","'~'","in","formula","else","len(formula)\n","","","","","","","","raise","patsy.PatsyError('Formulas","should","not","have","left-hand","sides.',\n","","","","","","","","","","","","patsy.origin.Origin(formula,","0,","end))\n","","","","return","description.rhs_termlist\n"],"func_name":"pyblp-0.9.0\/file:\/pyblp\/configurations\/formulation.py:function:parse_terms\/parse_terms","docstring":"Parse patsy terms from a string. Validate that the string contains only right-hand side terms.","docstring_tokens":["Parse","patsy","terms","from","a","string",".","Validate","that","the","string","contains","only","right","-","hand","side","terms","."],"summary":"Parse patsy terms from a string. Validate that the string contains only right-hand side terms.","code_with_docstring":"def parse_terms(formula: str) ->List[patsy.desc.Term]:\n    \"\"\"Parse patsy terms from a string. Validate that the string contains only right-hand side terms.\"\"\"\n    description = patsy.highlevel.ModelDesc.from_formula(formula)\n    if description.lhs_termlist:\n        end = formula.index('~') + 1 if '~' in formula else len(formula)\n        raise patsy.PatsyError('Formulas should not have left-hand sides.',\n            patsy.origin.Origin(formula, 0, end))\n    return description.rhs_termlist\n","code_tokens_py":[]}
{"repo":"z3","path":"z3\/\/z3.pyfile:\/z3.py:function:append_log\/append_log","language":"python","sha":"50f7efd7250a9d40e498116ceb28f0879777eb1b","url":"z3\/\/z3.pyfile:\/z3.py:function:append_log\/append_log","partition":"test","code":"def append_log(s):\n    \"\"\"\n    Z3_append_log(s)\n","original_string":"def append_log(s):\n    \"\"\"Append user-defined string to interaction log. \"\"\"\n    Z3_append_log(s)\n","code_tokens":["def","append_log(s):\n","","","","\"\"\"\n","","","","Z3_append_log(s)\n"],"func_name":"z3\/file:\/z3.py:function:append_log\/append_log","docstring":"Append user-defined string to interaction log. ","docstring_tokens":["Append","user","-","defined","string","to","interaction","log","."],"summary":"Append user-defined string to interaction log. ","code_with_docstring":"def append_log(s):\n    \"\"\"Append user-defined string to interaction log. \"\"\"\n    Z3_append_log(s)\n","code_tokens_py":[]}
{"repo":"sfftk-0.5.2.dev3","path":"sfftk-0.5.2.dev3\/\/sfftk\/readers\/stlreader.pyfile:\/sfftk\/readers\/stlreader.py:function:get_data\/get_data","language":"python","sha":"ec68d92d37d1ab3beda65f839007ee6c20273223","url":"sfftk-0.5.2.dev3\/\/sfftk\/readers\/stlreader.pyfile:\/sfftk\/readers\/stlreader.py:function:get_data\/get_data","partition":"test","code":"def get_data(fn):\n    Get data from an StL file\n\n    :param str fn: filename\n    :return: a `generator` of meshes; each mesh is a `tuple` of a name, a `dict` of vertices indexed by `vertex_id` and a `dict` of polygons referring to vertices by `vertex_id`\n    :rtype: tuple\n    \"\"\"\n    from stl import mesh\n    meshes = list()\n    stl_meshes = mesh.Mesh.from_multi_file(fn)\n    mesh_id = 0\n    for stl_mesh in stl_meshes:\n        vertex_ids = _dict()\n        polygons = _dict()\n        vertex_id = 0\n        polygon_id = 0\n        for facet in stl_mesh.vectors:\n            v0, v1, v2 = facet\n            if tuple(v0) not in vertex_ids:\n                vertex_ids[tuple(v0)] = vertex_id\n                vertex_id += 1\n            if tuple(v1) not in vertex_ids:\n                vertex_ids[tuple(v1)] = vertex_id\n                vertex_id += 1\n            if tuple(v2) not in vertex_ids:\n                vertex_ids[tuple(v2)] = vertex_id\n                vertex_id += 1\n            polygons[polygon_id] = vertex_ids[tuple(v0)], vertex_ids[tuple(v1)\n                ], vertex_ids[tuple(v2)]\n            polygon_id += 1\n        \"\"\"\n        :TODO: transform vertices to image space!!! \n        \n        the transformation matrices are at http:\/\/www.tribe43.net\/blog\/article-33\/        \n        \"\"\"\n        vertices = _dict(zip(vertex_ids.values(), vertex_ids.keys()))\n        name = '{}#{}'.format(os.path.basename(fn), mesh_id)\n        meshes.append((name, vertices, polygons))\n    return meshes\n","original_string":"def get_data(fn):\n    \"\"\"Get data from an StL file\n\n    :param str fn: filename\n    :return: a `generator` of meshes; each mesh is a `tuple` of a name, a `dict` of vertices indexed by `vertex_id` and a `dict` of polygons referring to vertices by `vertex_id`\n    :rtype: tuple\n    \"\"\"\n    from stl import mesh\n    meshes = list()\n    stl_meshes = mesh.Mesh.from_multi_file(fn)\n    mesh_id = 0\n    for stl_mesh in stl_meshes:\n        vertex_ids = _dict()\n        polygons = _dict()\n        vertex_id = 0\n        polygon_id = 0\n        for facet in stl_mesh.vectors:\n            v0, v1, v2 = facet\n            if tuple(v0) not in vertex_ids:\n                vertex_ids[tuple(v0)] = vertex_id\n                vertex_id += 1\n            if tuple(v1) not in vertex_ids:\n                vertex_ids[tuple(v1)] = vertex_id\n                vertex_id += 1\n            if tuple(v2) not in vertex_ids:\n                vertex_ids[tuple(v2)] = vertex_id\n                vertex_id += 1\n            polygons[polygon_id] = vertex_ids[tuple(v0)], vertex_ids[tuple(v1)\n                ], vertex_ids[tuple(v2)]\n            polygon_id += 1\n        \"\"\"\n        :TODO: transform vertices to image space!!! \n        \n        the transformation matrices are at http:\/\/www.tribe43.net\/blog\/article-33\/        \n        \"\"\"\n        vertices = _dict(zip(vertex_ids.values(), vertex_ids.keys()))\n        name = '{}#{}'.format(os.path.basename(fn), mesh_id)\n        meshes.append((name, vertices, polygons))\n    return meshes\n","code_tokens":["def","get_data(fn):\n","","","","Get","data","from","an","StL","file\n\n","","","",":param","str","fn:","filename\n","","","",":return:","a","`generator`","of","meshes;","each","mesh","is","a","`tuple`","of","a","name,","a","`dict`","of","vertices","indexed","by","`vertex_id`","and","a","`dict`","of","polygons","referring","to","vertices","by","`vertex_id`\n","","","",":rtype:","tuple\n","","","","\"\"\"\n","","","","from","stl","import","mesh\n","","","","meshes","=","list()\n","","","","stl_meshes","=","mesh.Mesh.from_multi_file(fn)\n","","","","mesh_id","=","0\n","","","","for","stl_mesh","in","stl_meshes:\n","","","","","","","","vertex_ids","=","_dict()\n","","","","","","","","polygons","=","_dict()\n","","","","","","","","vertex_id","=","0\n","","","","","","","","polygon_id","=","0\n","","","","","","","","for","facet","in","stl_mesh.vectors:\n","","","","","","","","","","","","v0,","v1,","v2","=","facet\n","","","","","","","","","","","","if","tuple(v0)","not","in","vertex_ids:\n","","","","","","","","","","","","","","","","vertex_ids[tuple(v0)]","=","vertex_id\n","","","","","","","","","","","","","","","","vertex_id","+=","1\n","","","","","","","","","","","","if","tuple(v1)","not","in","vertex_ids:\n","","","","","","","","","","","","","","","","vertex_ids[tuple(v1)]","=","vertex_id\n","","","","","","","","","","","","","","","","vertex_id","+=","1\n","","","","","","","","","","","","if","tuple(v2)","not","in","vertex_ids:\n","","","","","","","","","","","","","","","","vertex_ids[tuple(v2)]","=","vertex_id\n","","","","","","","","","","","","","","","","vertex_id","+=","1\n","","","","","","","","","","","","polygons[polygon_id]","=","vertex_ids[tuple(v0)],","vertex_ids[tuple(v1)\n","","","","","","","","","","","","","","","","],","vertex_ids[tuple(v2)]\n","","","","","","","","","","","","polygon_id","+=","1\n","","","","","","","","\"\"\"\n","","","","","","","",":TODO:","transform","vertices","to","image","space!!!","\n","","","","","","","","\n","","","","","","","","the","transformation","matrices","are","at","http:\/\/www.tribe43.net\/blog\/article-33\/","","","","","","","","\n","","","","","","","","\"\"\"\n","","","","","","","","vertices","=","_dict(zip(vertex_ids.values(),","vertex_ids.keys()))\n","","","","","","","","name","=","'{}#{}'.format(os.path.basename(fn),","mesh_id)\n","","","","","","","","meshes.append((name,","vertices,","polygons))\n","","","","return","meshes\n"],"func_name":"sfftk-0.5.2.dev3\/file:\/sfftk\/readers\/stlreader.py:function:get_data\/get_data","docstring":"Get data from an StL file\n\n:param str fn: filename\n:return: a `generator` of meshes; each mesh is a `tuple` of a name, a `dict` of vertices indexed by `vertex_id` and a `dict` of polygons referring to vertices by `vertex_id`\n:rtype: tuple","docstring_tokens":["Get","data","from","an","StL","file",":","param","str","fn",":","filename",":","return",":","a","`","generator","`","of","meshes",";","each","mesh","is","a","`","tuple","`","of","a","name",",","a","`","dict","`","of","vertices","indexed","by","`","vertex_id","`","and","a","`","dict","`","of","polygons","referring","to","vertices","by","`","vertex_id","`",":","rtype",":","tuple"],"summary":"Get data from an StL file","code_with_docstring":"def get_data(fn):\n    \"\"\"Get data from an StL file\n\n    :param str fn: filename\n    :return: a `generator` of meshes; each mesh is a `tuple` of a name, a `dict` of vertices indexed by `vertex_id` and a `dict` of polygons referring to vertices by `vertex_id`\n    :rtype: tuple\n    \"\"\"\n    from stl import mesh\n    meshes = list()\n    stl_meshes = mesh.Mesh.from_multi_file(fn)\n    mesh_id = 0\n    for stl_mesh in stl_meshes:\n        vertex_ids = _dict()\n        polygons = _dict()\n        vertex_id = 0\n        polygon_id = 0\n        for facet in stl_mesh.vectors:\n            v0, v1, v2 = facet\n            if tuple(v0) not in vertex_ids:\n                vertex_ids[tuple(v0)] = vertex_id\n                vertex_id += 1\n            if tuple(v1) not in vertex_ids:\n                vertex_ids[tuple(v1)] = vertex_id\n                vertex_id += 1\n            if tuple(v2) not in vertex_ids:\n                vertex_ids[tuple(v2)] = vertex_id\n                vertex_id += 1\n            polygons[polygon_id] = vertex_ids[tuple(v0)], vertex_ids[tuple(v1)\n                ], vertex_ids[tuple(v2)]\n            polygon_id += 1\n        \"\"\"\n        :TODO: transform vertices to image space!!! \n        \n        the transformation matrices are at http:\/\/www.tribe43.net\/blog\/article-33\/        \n        \"\"\"\n        vertices = _dict(zip(vertex_ids.values(), vertex_ids.keys()))\n        name = '{}#{}'.format(os.path.basename(fn), mesh_id)\n        meshes.append((name, vertices, polygons))\n    return meshes\n","code_tokens_py":[]}
{"repo":"SeisLoc","path":"SeisLoc\/\/signal\/scan.pyclass:SeisScan\/_GaussianTrigger","language":"python","sha":"8e4cf92b509bb3687e892fbc9fd8303728275f05","url":"SeisLoc\/\/signal\/scan.pyclass:SeisScan\/_GaussianTrigger","partition":"test","code":"def _GaussianTrigger(self, SNR, PHASE, cstart, eventTP, eventTS, Name, ttp, tts\n    ):\n    \n            Function to fit gaussian to onset function, based on knowledge of approximate trigger index, \n            lowest freq within signal and signal sampling rate. Will fit gaussian and return standard \n            deviation of gaussian, representative of timing error.\n    \n        \"\"\"\n    sampling_rate = self.sample_rate\n    trig_idx_P = int(((eventTP - cstart).seconds + (eventTP - cstart).\n        microseconds \/ 10.0 ** 6) * sampling_rate)\n    trig_idx_S = int(((eventTS - cstart).seconds + (eventTS - cstart).\n        microseconds \/ 10.0 ** 6) * sampling_rate)\n    P_idxmin = int(trig_idx_P - (trig_idx_S - trig_idx_P) \/ 2)\n    P_idxmax = int(trig_idx_P + (trig_idx_S - trig_idx_P) \/ 2)\n    S_idxmin = int(trig_idx_S - (trig_idx_S - trig_idx_P) \/ 2)\n    S_idxmax = int(trig_idx_S + (trig_idx_S - trig_idx_P) \/ 2)\n    for ii in [P_idxmin, P_idxmax, S_idxmin, S_idxmax]:\n        if ii < 0:\n            ii = 0\n        if ii > len(SNR):\n            ii = len(SNR)\n    if PHASE == 'P':\n        lowfreq = self.bp_filter_p1[0]\n        win_min = P_idxmin\n        win_max = P_idxmax\n    if PHASE == 'S':\n        lowfreq = self.bp_filter_s1[0]\n        win_min = S_idxmin\n        win_max = S_idxmax\n    fit = stats.norm.fit(SNR[win_min:win_max])\n    if fit[0] != 0.0 and fit[1] != 0.0:\n        cdf = stats.norm.cdf(np.arange(0, 100, 0.01), fit[0], fit[1])\n        exceedence_value = np.arange(0, 100, 0.01)[np.where(cdf >= self.\n            PickThreshold)[0][0]]\n        std_SNR = np.arange(0, 100, 0.01)[np.where(cdf >= 0.688)[0][0]]\n        P_idxmin_new = int(trig_idx_P - int((self.MarginalWindow + ttp *\n            self.PercentageTT) * sampling_rate))\n        P_idxmax_new = int(trig_idx_P + int((self.MarginalWindow + ttp *\n            self.PercentageTT) * sampling_rate))\n        S_idxmin_new = int(trig_idx_S - int((self.MarginalWindow + tts *\n            self.PercentageTT) * sampling_rate))\n        S_idxmax_new = int(trig_idx_S + int((self.MarginalWindow + tts *\n            self.PercentageTT) * sampling_rate))\n        P_idxmin = np.max([P_idxmin, P_idxmin_new])\n        P_idxmax = np.min([P_idxmax, P_idxmax_new])\n        S_idxmin = np.max([S_idxmin, S_idxmin_new])\n        S_idxmax = np.min([S_idxmax, S_idxmax_new])\n        Pidx = np.argmax(SNR[P_idxmin:P_idxmax]) + P_idxmin\n        Sidx = np.argmax(SNR[S_idxmin:S_idxmax]) + S_idxmin\n        if PHASE == 'P':\n            maxSNR = Pidx\n        if PHASE == 'S':\n            maxSNR = Sidx\n        if SNR[maxSNR] >= exceedence_value:\n            ppf = np.where(SNR <= std_SNR)[0] - maxSNR\n            ppf_min = int(maxSNR - np.min(abs(ppf[np.where(ppf < 0)])))\n            ppf_max = int(maxSNR + np.min(abs(ppf[np.where(ppf > 0)])))\n            data_half_range = int(1.25 * sampling_rate \/ lowfreq)\n            x_data = np.arange(ppf_min, ppf_max, dtype=float) \/ sampling_rate\n            y_data = SNR[ppf_min:ppf_max]\n            p0 = [np.amax(y_data), float(ppf_min + 1) \/ sampling_rate, 1.0 \/\n                (lowfreq \/ 4.0)]\n            d = 0\n            for jj in range(len(x_data)):\n                if d == 0:\n                    XDATA = cstart + timedelta(seconds=x_data[jj])\n                    d += 1\n                else:\n                    XDATA = np.hstack((XDATA, cstart + timedelta(seconds=\n                        x_data[jj])))\n            try:\n                popt, pcov = curve_fit(gaussian_func, x_data, y_data, p0)\n                sigma = np.absolute(popt[2])\n                mean = cstart + timedelta(seconds=float(popt[1]))\n                maxSNR = popt[0]\n                GAU_FITS = {}\n                GAU_FITS['popt'] = popt\n                GAU_FITS['xdata'] = x_data\n                GAU_FITS['xdata_dt'] = XDATA\n                GAU_FITS['PickValue'] = maxSNR\n                GAU_FITS['PickThreshold'] = exceedence_value\n            except:\n                GAU_FITS = {}\n                GAU_FITS['popt'] = 0\n                GAU_FITS['xdata'] = 0\n                GAU_FITS['xdata_dt'] = 0\n                GAU_FITS['PickValue'] = -1\n                GAU_FITS['PickThreshold'] = -1\n                sigma = -1\n                mean = -1\n                maxSNR = -1\n        else:\n            GAU_FITS = {}\n            GAU_FITS['popt'] = 0\n            GAU_FITS['xdata'] = 0\n            GAU_FITS['xdata_dt'] = 0\n            GAU_FITS['PickValue'] = -1\n            GAU_FITS['PickThreshold'] = exceedence_value\n            sigma = -1\n            mean = -1\n            maxSNR = -1\n    else:\n        GAU_FITS = {}\n        GAU_FITS['popt'] = 0\n        GAU_FITS['xdata'] = 0\n        GAU_FITS['xdata_dt'] = 0\n        GAU_FITS['PickValue'] = -1\n        GAU_FITS['PickThreshold'] = -1\n        sigma = -1\n        mean = -1\n        maxSNR = -1\n    return GAU_FITS, maxSNR, sigma, mean\n","original_string":"def _GaussianTrigger(self, SNR, PHASE, cstart, eventTP, eventTS, Name, ttp, tts\n    ):\n    \"\"\"\n            Function to fit gaussian to onset function, based on knowledge of approximate trigger index, \n            lowest freq within signal and signal sampling rate. Will fit gaussian and return standard \n            deviation of gaussian, representative of timing error.\n    \n        \"\"\"\n    sampling_rate = self.sample_rate\n    trig_idx_P = int(((eventTP - cstart).seconds + (eventTP - cstart).\n        microseconds \/ 10.0 ** 6) * sampling_rate)\n    trig_idx_S = int(((eventTS - cstart).seconds + (eventTS - cstart).\n        microseconds \/ 10.0 ** 6) * sampling_rate)\n    P_idxmin = int(trig_idx_P - (trig_idx_S - trig_idx_P) \/ 2)\n    P_idxmax = int(trig_idx_P + (trig_idx_S - trig_idx_P) \/ 2)\n    S_idxmin = int(trig_idx_S - (trig_idx_S - trig_idx_P) \/ 2)\n    S_idxmax = int(trig_idx_S + (trig_idx_S - trig_idx_P) \/ 2)\n    for ii in [P_idxmin, P_idxmax, S_idxmin, S_idxmax]:\n        if ii < 0:\n            ii = 0\n        if ii > len(SNR):\n            ii = len(SNR)\n    if PHASE == 'P':\n        lowfreq = self.bp_filter_p1[0]\n        win_min = P_idxmin\n        win_max = P_idxmax\n    if PHASE == 'S':\n        lowfreq = self.bp_filter_s1[0]\n        win_min = S_idxmin\n        win_max = S_idxmax\n    fit = stats.norm.fit(SNR[win_min:win_max])\n    if fit[0] != 0.0 and fit[1] != 0.0:\n        cdf = stats.norm.cdf(np.arange(0, 100, 0.01), fit[0], fit[1])\n        exceedence_value = np.arange(0, 100, 0.01)[np.where(cdf >= self.\n            PickThreshold)[0][0]]\n        std_SNR = np.arange(0, 100, 0.01)[np.where(cdf >= 0.688)[0][0]]\n        P_idxmin_new = int(trig_idx_P - int((self.MarginalWindow + ttp *\n            self.PercentageTT) * sampling_rate))\n        P_idxmax_new = int(trig_idx_P + int((self.MarginalWindow + ttp *\n            self.PercentageTT) * sampling_rate))\n        S_idxmin_new = int(trig_idx_S - int((self.MarginalWindow + tts *\n            self.PercentageTT) * sampling_rate))\n        S_idxmax_new = int(trig_idx_S + int((self.MarginalWindow + tts *\n            self.PercentageTT) * sampling_rate))\n        P_idxmin = np.max([P_idxmin, P_idxmin_new])\n        P_idxmax = np.min([P_idxmax, P_idxmax_new])\n        S_idxmin = np.max([S_idxmin, S_idxmin_new])\n        S_idxmax = np.min([S_idxmax, S_idxmax_new])\n        Pidx = np.argmax(SNR[P_idxmin:P_idxmax]) + P_idxmin\n        Sidx = np.argmax(SNR[S_idxmin:S_idxmax]) + S_idxmin\n        if PHASE == 'P':\n            maxSNR = Pidx\n        if PHASE == 'S':\n            maxSNR = Sidx\n        if SNR[maxSNR] >= exceedence_value:\n            ppf = np.where(SNR <= std_SNR)[0] - maxSNR\n            ppf_min = int(maxSNR - np.min(abs(ppf[np.where(ppf < 0)])))\n            ppf_max = int(maxSNR + np.min(abs(ppf[np.where(ppf > 0)])))\n            data_half_range = int(1.25 * sampling_rate \/ lowfreq)\n            x_data = np.arange(ppf_min, ppf_max, dtype=float) \/ sampling_rate\n            y_data = SNR[ppf_min:ppf_max]\n            p0 = [np.amax(y_data), float(ppf_min + 1) \/ sampling_rate, 1.0 \/\n                (lowfreq \/ 4.0)]\n            d = 0\n            for jj in range(len(x_data)):\n                if d == 0:\n                    XDATA = cstart + timedelta(seconds=x_data[jj])\n                    d += 1\n                else:\n                    XDATA = np.hstack((XDATA, cstart + timedelta(seconds=\n                        x_data[jj])))\n            try:\n                popt, pcov = curve_fit(gaussian_func, x_data, y_data, p0)\n                sigma = np.absolute(popt[2])\n                mean = cstart + timedelta(seconds=float(popt[1]))\n                maxSNR = popt[0]\n                GAU_FITS = {}\n                GAU_FITS['popt'] = popt\n                GAU_FITS['xdata'] = x_data\n                GAU_FITS['xdata_dt'] = XDATA\n                GAU_FITS['PickValue'] = maxSNR\n                GAU_FITS['PickThreshold'] = exceedence_value\n            except:\n                GAU_FITS = {}\n                GAU_FITS['popt'] = 0\n                GAU_FITS['xdata'] = 0\n                GAU_FITS['xdata_dt'] = 0\n                GAU_FITS['PickValue'] = -1\n                GAU_FITS['PickThreshold'] = -1\n                sigma = -1\n                mean = -1\n                maxSNR = -1\n        else:\n            GAU_FITS = {}\n            GAU_FITS['popt'] = 0\n            GAU_FITS['xdata'] = 0\n            GAU_FITS['xdata_dt'] = 0\n            GAU_FITS['PickValue'] = -1\n            GAU_FITS['PickThreshold'] = exceedence_value\n            sigma = -1\n            mean = -1\n            maxSNR = -1\n    else:\n        GAU_FITS = {}\n        GAU_FITS['popt'] = 0\n        GAU_FITS['xdata'] = 0\n        GAU_FITS['xdata_dt'] = 0\n        GAU_FITS['PickValue'] = -1\n        GAU_FITS['PickThreshold'] = -1\n        sigma = -1\n        mean = -1\n        maxSNR = -1\n    return GAU_FITS, maxSNR, sigma, mean\n","code_tokens":["def","_GaussianTrigger(self,","SNR,","PHASE,","cstart,","eventTP,","eventTS,","Name,","ttp,","tts\n","","","","):\n","","","","\n","","","","","","","","","","","","Function","to","fit","gaussian","to","onset","function,","based","on","knowledge","of","approximate","trigger","index,","\n","","","","","","","","","","","","lowest","freq","within","signal","and","signal","sampling","rate.","Will","fit","gaussian","and","return","standard","\n","","","","","","","","","","","","deviation","of","gaussian,","representative","of","timing","error.\n","","","","\n","","","","","","","","\"\"\"\n","","","","sampling_rate","=","self.sample_rate\n","","","","trig_idx_P","=","int(((eventTP","-","cstart).seconds","+","(eventTP","-","cstart).\n","","","","","","","","microseconds","\/","10.0","**","6)","*","sampling_rate)\n","","","","trig_idx_S","=","int(((eventTS","-","cstart).seconds","+","(eventTS","-","cstart).\n","","","","","","","","microseconds","\/","10.0","**","6)","*","sampling_rate)\n","","","","P_idxmin","=","int(trig_idx_P","-","(trig_idx_S","-","trig_idx_P)","\/","2)\n","","","","P_idxmax","=","int(trig_idx_P","+","(trig_idx_S","-","trig_idx_P)","\/","2)\n","","","","S_idxmin","=","int(trig_idx_S","-","(trig_idx_S","-","trig_idx_P)","\/","2)\n","","","","S_idxmax","=","int(trig_idx_S","+","(trig_idx_S","-","trig_idx_P)","\/","2)\n","","","","for","ii","in","[P_idxmin,","P_idxmax,","S_idxmin,","S_idxmax]:\n","","","","","","","","if","ii","<","0:\n","","","","","","","","","","","","ii","=","0\n","","","","","","","","if","ii",">","len(SNR):\n","","","","","","","","","","","","ii","=","len(SNR)\n","","","","if","PHASE","==","'P':\n","","","","","","","","lowfreq","=","self.bp_filter_p1[0]\n","","","","","","","","win_min","=","P_idxmin\n","","","","","","","","win_max","=","P_idxmax\n","","","","if","PHASE","==","'S':\n","","","","","","","","lowfreq","=","self.bp_filter_s1[0]\n","","","","","","","","win_min","=","S_idxmin\n","","","","","","","","win_max","=","S_idxmax\n","","","","fit","=","stats.norm.fit(SNR[win_min:win_max])\n","","","","if","fit[0]","!=","0.0","and","fit[1]","!=","0.0:\n","","","","","","","","cdf","=","stats.norm.cdf(np.arange(0,","100,","0.01),","fit[0],","fit[1])\n","","","","","","","","exceedence_value","=","np.arange(0,","100,","0.01)[np.where(cdf",">=","self.\n","","","","","","","","","","","","PickThreshold)[0][0]]\n","","","","","","","","std_SNR","=","np.arange(0,","100,","0.01)[np.where(cdf",">=","0.688)[0][0]]\n","","","","","","","","P_idxmin_new","=","int(trig_idx_P","-","int((self.MarginalWindow","+","ttp","*\n","","","","","","","","","","","","self.PercentageTT)","*","sampling_rate))\n","","","","","","","","P_idxmax_new","=","int(trig_idx_P","+","int((self.MarginalWindow","+","ttp","*\n","","","","","","","","","","","","self.PercentageTT)","*","sampling_rate))\n","","","","","","","","S_idxmin_new","=","int(trig_idx_S","-","int((self.MarginalWindow","+","tts","*\n","","","","","","","","","","","","self.PercentageTT)","*","sampling_rate))\n","","","","","","","","S_idxmax_new","=","int(trig_idx_S","+","int((self.MarginalWindow","+","tts","*\n","","","","","","","","","","","","self.PercentageTT)","*","sampling_rate))\n","","","","","","","","P_idxmin","=","np.max([P_idxmin,","P_idxmin_new])\n","","","","","","","","P_idxmax","=","np.min([P_idxmax,","P_idxmax_new])\n","","","","","","","","S_idxmin","=","np.max([S_idxmin,","S_idxmin_new])\n","","","","","","","","S_idxmax","=","np.min([S_idxmax,","S_idxmax_new])\n","","","","","","","","Pidx","=","np.argmax(SNR[P_idxmin:P_idxmax])","+","P_idxmin\n","","","","","","","","Sidx","=","np.argmax(SNR[S_idxmin:S_idxmax])","+","S_idxmin\n","","","","","","","","if","PHASE","==","'P':\n","","","","","","","","","","","","maxSNR","=","Pidx\n","","","","","","","","if","PHASE","==","'S':\n","","","","","","","","","","","","maxSNR","=","Sidx\n","","","","","","","","if","SNR[maxSNR]",">=","exceedence_value:\n","","","","","","","","","","","","ppf","=","np.where(SNR","<=","std_SNR)[0]","-","maxSNR\n","","","","","","","","","","","","ppf_min","=","int(maxSNR","-","np.min(abs(ppf[np.where(ppf","<","0)])))\n","","","","","","","","","","","","ppf_max","=","int(maxSNR","+","np.min(abs(ppf[np.where(ppf",">","0)])))\n","","","","","","","","","","","","data_half_range","=","int(1.25","*","sampling_rate","\/","lowfreq)\n","","","","","","","","","","","","x_data","=","np.arange(ppf_min,","ppf_max,","dtype=float)","\/","sampling_rate\n","","","","","","","","","","","","y_data","=","SNR[ppf_min:ppf_max]\n","","","","","","","","","","","","p0","=","[np.amax(y_data),","float(ppf_min","+","1)","\/","sampling_rate,","1.0","\/\n","","","","","","","","","","","","","","","","(lowfreq","\/","4.0)]\n","","","","","","","","","","","","d","=","0\n","","","","","","","","","","","","for","jj","in","range(len(x_data)):\n","","","","","","","","","","","","","","","","if","d","==","0:\n","","","","","","","","","","","","","","","","","","","","XDATA","=","cstart","+","timedelta(seconds=x_data[jj])\n","","","","","","","","","","","","","","","","","","","","d","+=","1\n","","","","","","","","","","","","","","","","else:\n","","","","","","","","","","","","","","","","","","","","XDATA","=","np.hstack((XDATA,","cstart","+","timedelta(seconds=\n","","","","","","","","","","","","","","","","","","","","","","","","x_data[jj])))\n","","","","","","","","","","","","try:\n","","","","","","","","","","","","","","","","popt,","pcov","=","curve_fit(gaussian_func,","x_data,","y_data,","p0)\n","","","","","","","","","","","","","","","","sigma","=","np.absolute(popt[2])\n","","","","","","","","","","","","","","","","mean","=","cstart","+","timedelta(seconds=float(popt[1]))\n","","","","","","","","","","","","","","","","maxSNR","=","popt[0]\n","","","","","","","","","","","","","","","","GAU_FITS","=","{}\n","","","","","","","","","","","","","","","","GAU_FITS['popt']","=","popt\n","","","","","","","","","","","","","","","","GAU_FITS['xdata']","=","x_data\n","","","","","","","","","","","","","","","","GAU_FITS['xdata_dt']","=","XDATA\n","","","","","","","","","","","","","","","","GAU_FITS['PickValue']","=","maxSNR\n","","","","","","","","","","","","","","","","GAU_FITS['PickThreshold']","=","exceedence_value\n","","","","","","","","","","","","except:\n","","","","","","","","","","","","","","","","GAU_FITS","=","{}\n","","","","","","","","","","","","","","","","GAU_FITS['popt']","=","0\n","","","","","","","","","","","","","","","","GAU_FITS['xdata']","=","0\n","","","","","","","","","","","","","","","","GAU_FITS['xdata_dt']","=","0\n","","","","","","","","","","","","","","","","GAU_FITS['PickValue']","=","-1\n","","","","","","","","","","","","","","","","GAU_FITS['PickThreshold']","=","-1\n","","","","","","","","","","","","","","","","sigma","=","-1\n","","","","","","","","","","","","","","","","mean","=","-1\n","","","","","","","","","","","","","","","","maxSNR","=","-1\n","","","","","","","","else:\n","","","","","","","","","","","","GAU_FITS","=","{}\n","","","","","","","","","","","","GAU_FITS['popt']","=","0\n","","","","","","","","","","","","GAU_FITS['xdata']","=","0\n","","","","","","","","","","","","GAU_FITS['xdata_dt']","=","0\n","","","","","","","","","","","","GAU_FITS['PickValue']","=","-1\n","","","","","","","","","","","","GAU_FITS['PickThreshold']","=","exceedence_value\n","","","","","","","","","","","","sigma","=","-1\n","","","","","","","","","","","","mean","=","-1\n","","","","","","","","","","","","maxSNR","=","-1\n","","","","else:\n","","","","","","","","GAU_FITS","=","{}\n","","","","","","","","GAU_FITS['popt']","=","0\n","","","","","","","","GAU_FITS['xdata']","=","0\n","","","","","","","","GAU_FITS['xdata_dt']","=","0\n","","","","","","","","GAU_FITS['PickValue']","=","-1\n","","","","","","","","GAU_FITS['PickThreshold']","=","-1\n","","","","","","","","sigma","=","-1\n","","","","","","","","mean","=","-1\n","","","","","","","","maxSNR","=","-1\n","","","","return","GAU_FITS,","maxSNR,","sigma,","mean\n"],"func_name":"SeisLoc\/class:SeisScan\/_GaussianTrigger","docstring":"Function to fit gaussian to onset function, based on knowledge of approximate trigger index, \nlowest freq within signal and signal sampling rate. Will fit gaussian and return standard \ndeviation of gaussian, representative of timing error.","docstring_tokens":["Function","to","fit","gaussian","to","onset","function",",","based","on","knowledge","of","approximate","trigger","index",",","lowest","freq","within","signal","and","signal","sampling","rate",".","Will","fit","gaussian","and","return","standard","deviation","of","gaussian",",","representative","of","timing","error","."],"summary":"Function to fit gaussian to onset function, based on knowledge of approximate trigger index, ","code_with_docstring":"def _GaussianTrigger(self, SNR, PHASE, cstart, eventTP, eventTS, Name, ttp, tts\n    ):\n    \"\"\"\n            Function to fit gaussian to onset function, based on knowledge of approximate trigger index, \n            lowest freq within signal and signal sampling rate. Will fit gaussian and return standard \n            deviation of gaussian, representative of timing error.\n    \n        \"\"\"\n    sampling_rate = self.sample_rate\n    trig_idx_P = int(((eventTP - cstart).seconds + (eventTP - cstart).\n        microseconds \/ 10.0 ** 6) * sampling_rate)\n    trig_idx_S = int(((eventTS - cstart).seconds + (eventTS - cstart).\n        microseconds \/ 10.0 ** 6) * sampling_rate)\n    P_idxmin = int(trig_idx_P - (trig_idx_S - trig_idx_P) \/ 2)\n    P_idxmax = int(trig_idx_P + (trig_idx_S - trig_idx_P) \/ 2)\n    S_idxmin = int(trig_idx_S - (trig_idx_S - trig_idx_P) \/ 2)\n    S_idxmax = int(trig_idx_S + (trig_idx_S - trig_idx_P) \/ 2)\n    for ii in [P_idxmin, P_idxmax, S_idxmin, S_idxmax]:\n        if ii < 0:\n            ii = 0\n        if ii > len(SNR):\n            ii = len(SNR)\n    if PHASE == 'P':\n        lowfreq = self.bp_filter_p1[0]\n        win_min = P_idxmin\n        win_max = P_idxmax\n    if PHASE == 'S':\n        lowfreq = self.bp_filter_s1[0]\n        win_min = S_idxmin\n        win_max = S_idxmax\n    fit = stats.norm.fit(SNR[win_min:win_max])\n    if fit[0] != 0.0 and fit[1] != 0.0:\n        cdf = stats.norm.cdf(np.arange(0, 100, 0.01), fit[0], fit[1])\n        exceedence_value = np.arange(0, 100, 0.01)[np.where(cdf >= self.\n            PickThreshold)[0][0]]\n        std_SNR = np.arange(0, 100, 0.01)[np.where(cdf >= 0.688)[0][0]]\n        P_idxmin_new = int(trig_idx_P - int((self.MarginalWindow + ttp *\n            self.PercentageTT) * sampling_rate))\n        P_idxmax_new = int(trig_idx_P + int((self.MarginalWindow + ttp *\n            self.PercentageTT) * sampling_rate))\n        S_idxmin_new = int(trig_idx_S - int((self.MarginalWindow + tts *\n            self.PercentageTT) * sampling_rate))\n        S_idxmax_new = int(trig_idx_S + int((self.MarginalWindow + tts *\n            self.PercentageTT) * sampling_rate))\n        P_idxmin = np.max([P_idxmin, P_idxmin_new])\n        P_idxmax = np.min([P_idxmax, P_idxmax_new])\n        S_idxmin = np.max([S_idxmin, S_idxmin_new])\n        S_idxmax = np.min([S_idxmax, S_idxmax_new])\n        Pidx = np.argmax(SNR[P_idxmin:P_idxmax]) + P_idxmin\n        Sidx = np.argmax(SNR[S_idxmin:S_idxmax]) + S_idxmin\n        if PHASE == 'P':\n            maxSNR = Pidx\n        if PHASE == 'S':\n            maxSNR = Sidx\n        if SNR[maxSNR] >= exceedence_value:\n            ppf = np.where(SNR <= std_SNR)[0] - maxSNR\n            ppf_min = int(maxSNR - np.min(abs(ppf[np.where(ppf < 0)])))\n            ppf_max = int(maxSNR + np.min(abs(ppf[np.where(ppf > 0)])))\n            data_half_range = int(1.25 * sampling_rate \/ lowfreq)\n            x_data = np.arange(ppf_min, ppf_max, dtype=float) \/ sampling_rate\n            y_data = SNR[ppf_min:ppf_max]\n            p0 = [np.amax(y_data), float(ppf_min + 1) \/ sampling_rate, 1.0 \/\n                (lowfreq \/ 4.0)]\n            d = 0\n            for jj in range(len(x_data)):\n                if d == 0:\n                    XDATA = cstart + timedelta(seconds=x_data[jj])\n                    d += 1\n                else:\n                    XDATA = np.hstack((XDATA, cstart + timedelta(seconds=\n                        x_data[jj])))\n            try:\n                popt, pcov = curve_fit(gaussian_func, x_data, y_data, p0)\n                sigma = np.absolute(popt[2])\n                mean = cstart + timedelta(seconds=float(popt[1]))\n                maxSNR = popt[0]\n                GAU_FITS = {}\n                GAU_FITS['popt'] = popt\n                GAU_FITS['xdata'] = x_data\n                GAU_FITS['xdata_dt'] = XDATA\n                GAU_FITS['PickValue'] = maxSNR\n                GAU_FITS['PickThreshold'] = exceedence_value\n            except:\n                GAU_FITS = {}\n                GAU_FITS['popt'] = 0\n                GAU_FITS['xdata'] = 0\n                GAU_FITS['xdata_dt'] = 0\n                GAU_FITS['PickValue'] = -1\n                GAU_FITS['PickThreshold'] = -1\n                sigma = -1\n                mean = -1\n                maxSNR = -1\n        else:\n            GAU_FITS = {}\n            GAU_FITS['popt'] = 0\n            GAU_FITS['xdata'] = 0\n            GAU_FITS['xdata_dt'] = 0\n            GAU_FITS['PickValue'] = -1\n            GAU_FITS['PickThreshold'] = exceedence_value\n            sigma = -1\n            mean = -1\n            maxSNR = -1\n    else:\n        GAU_FITS = {}\n        GAU_FITS['popt'] = 0\n        GAU_FITS['xdata'] = 0\n        GAU_FITS['xdata_dt'] = 0\n        GAU_FITS['PickValue'] = -1\n        GAU_FITS['PickThreshold'] = -1\n        sigma = -1\n        mean = -1\n        maxSNR = -1\n    return GAU_FITS, maxSNR, sigma, mean\n","code_tokens_py":[]}
{"repo":"ProDy-1.10.11","path":"ProDy-1.10.11\/\/prody\/dynamics\/mode.pyclass:Vector\/numAtoms","language":"python","sha":"2b603c855db52d05ac09609c02e5e95e155c1d8a","url":"ProDy-1.10.11\/\/prody\/dynamics\/mode.pyclass:Vector\/numAtoms","partition":"test","code":"def numAtoms(self):\n    Returns number of atoms.  For a 3-dimensional vector, returns length\n        of the vector divided by 3.\"\"\"\n    if self._is3d:\n        return len(self._array) \/\/ 3\n    else:\n        return len(self._array)\n","original_string":"def numAtoms(self):\n    \"\"\"Returns number of atoms.  For a 3-dimensional vector, returns length\n        of the vector divided by 3.\"\"\"\n    if self._is3d:\n        return len(self._array) \/\/ 3\n    else:\n        return len(self._array)\n","code_tokens":["def","numAtoms(self):\n","","","","Returns","number","of","atoms.","","For","a","3-dimensional","vector,","returns","length\n","","","","","","","","of","the","vector","divided","by","3.\"\"\"\n","","","","if","self._is3d:\n","","","","","","","","return","len(self._array)","\/\/","3\n","","","","else:\n","","","","","","","","return","len(self._array)\n"],"func_name":"ProDy-1.10.11\/class:Vector\/numAtoms","docstring":"Returns number of atoms.  For a 3-dimensional vector, returns length\nof the vector divided by 3.","docstring_tokens":["Returns","number","of","atoms",".","For","a","3-dimensional","vector",",","returns","length","of","the","vector","divided","by","3","."],"summary":"Returns number of atoms.  For a 3-dimensional vector, returns length","code_with_docstring":"def numAtoms(self):\n    \"\"\"Returns number of atoms.  For a 3-dimensional vector, returns length\n        of the vector divided by 3.\"\"\"\n    if self._is3d:\n        return len(self._array) \/\/ 3\n    else:\n        return len(self._array)\n","code_tokens_py":[]}
{"repo":"delphixpy-1.11.1.0","path":"delphixpy-1.11.1.0\/\/delphixpy\/v1_9_2\/web\/objects\/MSSqlSourceConnectionInfo.pyclass:MSSqlSourceConnectionInfo\/host","language":"python","sha":"083b6bf16e29e385c7c9ca779ae891899eda5940","url":"delphixpy-1.11.1.0\/\/delphixpy\/v1_9_2\/web\/objects\/MSSqlSourceConnectionInfo.pyclass:MSSqlSourceConnectionInfo\/host","partition":"test","code":"@property\ndef host(self):\n    \n        The hostname or IP address of the host where the source resides.\n\n        :rtype: ``TEXT_TYPE``\n        \"\"\"\n    return self._host[0]\n","original_string":"@property\ndef host(self):\n    \"\"\"\n        The hostname or IP address of the host where the source resides.\n\n        :rtype: ``TEXT_TYPE``\n        \"\"\"\n    return self._host[0]\n","code_tokens":["@property\ndef","host(self):\n","","","","\n","","","","","","","","The","hostname","or","IP","address","of","the","host","where","the","source","resides.\n\n","","","","","","","",":rtype:","``TEXT_TYPE``\n","","","","","","","","\"\"\"\n","","","","return","self._host[0]\n"],"func_name":"delphixpy-1.11.1.0\/class:MSSqlSourceConnectionInfo\/host","docstring":"The hostname or IP address of the host where the source resides.\n\n:rtype: ``TEXT_TYPE``","docstring_tokens":["The","hostname","or","IP","address","of","the","host","where","the","source","resides",".",":","rtype",":","`","`","TEXT_TYPE","`","`"],"summary":"The hostname or IP address of the host where the source resides.","code_with_docstring":"@property\ndef host(self):\n    \"\"\"\n        The hostname or IP address of the host where the source resides.\n\n        :rtype: ``TEXT_TYPE``\n        \"\"\"\n    return self._host[0]\n","code_tokens_py":[]}
{"repo":"delphixpy-1.11.1.0","path":"delphixpy-1.11.1.0\/\/delphixpy\/v1_5_3\/web\/objects\/ASELinkedSource.pyclass:ASELinkedSource\/monitor_location","language":"python","sha":"b55efd0fd9c655ed5de899faf074af1fdf45fe94","url":"delphixpy-1.11.1.0\/\/delphixpy\/v1_5_3\/web\/objects\/ASELinkedSource.pyclass:ASELinkedSource\/monitor_location","partition":"test","code":"@property\ndef monitor_location(self):\n    \n        Location of backup server used by the source.\n\n        :rtype: :py:class:`v1_5_3.web.vo.ASEBackupLocation`\n        \"\"\"\n    return self._monitor_location[0]\n","original_string":"@property\ndef monitor_location(self):\n    \"\"\"\n        Location of backup server used by the source.\n\n        :rtype: :py:class:`v1_5_3.web.vo.ASEBackupLocation`\n        \"\"\"\n    return self._monitor_location[0]\n","code_tokens":["@property\ndef","monitor_location(self):\n","","","","\n","","","","","","","","Location","of","backup","server","used","by","the","source.\n\n","","","","","","","",":rtype:",":py:class:`v1_5_3.web.vo.ASEBackupLocation`\n","","","","","","","","\"\"\"\n","","","","return","self._monitor_location[0]\n"],"func_name":"delphixpy-1.11.1.0\/class:ASELinkedSource\/monitor_location","docstring":"Location of backup server used by the source.\n\n:rtype: :py:class:`v1_5_3.web.vo.ASEBackupLocation`","docstring_tokens":["Location","of","backup","server","used","by","the","source",".",":","rtype",":",":","py",":","class:`v1_5_3.web.vo",".","ASEBackupLocation","`"],"summary":"Location of backup server used by the source.","code_with_docstring":"@property\ndef monitor_location(self):\n    \"\"\"\n        Location of backup server used by the source.\n\n        :rtype: :py:class:`v1_5_3.web.vo.ASEBackupLocation`\n        \"\"\"\n    return self._monitor_location[0]\n","code_tokens_py":[]}
{"repo":"radiomanager_sdk","path":"radiomanager_sdk\/\/models\/broadcast_epg_result.pyclass:BroadcastEPGResult\/title","language":"python","sha":"caa5938f4e7c729c7592071f47eb65a5f5b9cf42","url":"radiomanager_sdk\/\/models\/broadcast_epg_result.pyclass:BroadcastEPGResult\/title","partition":"test","code":"@property\ndef title(self):\n    \n        Gets the title of this BroadcastEPGResult.\n\n        :return: The title of this BroadcastEPGResult.\n        :rtype: str\n        \"\"\"\n    return self._title\n","original_string":"@property\ndef title(self):\n    \"\"\"\n        Gets the title of this BroadcastEPGResult.\n\n        :return: The title of this BroadcastEPGResult.\n        :rtype: str\n        \"\"\"\n    return self._title\n","code_tokens":["@property\ndef","title(self):\n","","","","\n","","","","","","","","Gets","the","title","of","this","BroadcastEPGResult.\n\n","","","","","","","",":return:","The","title","of","this","BroadcastEPGResult.\n","","","","","","","",":rtype:","str\n","","","","","","","","\"\"\"\n","","","","return","self._title\n"],"func_name":"radiomanager_sdk\/class:BroadcastEPGResult\/title","docstring":"Gets the title of this BroadcastEPGResult.\n\n:return: The title of this BroadcastEPGResult.\n:rtype: str","docstring_tokens":["Gets","the","title","of","this","BroadcastEPGResult",".",":","return",":","The","title","of","this","BroadcastEPGResult",".",":","rtype",":","str"],"summary":"Gets the title of this BroadcastEPGResult.","code_with_docstring":"@property\ndef title(self):\n    \"\"\"\n        Gets the title of this BroadcastEPGResult.\n\n        :return: The title of this BroadcastEPGResult.\n        :rtype: str\n        \"\"\"\n    return self._title\n","code_tokens_py":[]}
{"repo":"TwitterSearch-1.0.2","path":"TwitterSearch-1.0.2\/\/TwitterSearch\/TwitterUserOrder.pyclass:TwitterUserOrder\/set_include_rts","language":"python","sha":"f9107109fff61b7537f0690212cffbdffd66655f","url":"TwitterSearch-1.0.2\/\/TwitterSearch\/TwitterUserOrder.pyclass:TwitterUserOrder\/set_include_rts","partition":"test","code":"def set_include_rts(self, rts):\n     Sets 'include_rts' parameter. When set to False,         the timeline will strip any native retweets from the returned timeline\n\n        :param rts: Boolean triggering the usage of the parameter\n        :raises: TwitterSearchException\n        \"\"\"\n    if not isinstance(rts, bool):\n        raise TwitterSearchException(1008)\n    self.arguments.update({'include_rts': 'true' if rts else 'false'})\n","original_string":"def set_include_rts(self, rts):\n    \"\"\" Sets 'include_rts' parameter. When set to False,         the timeline will strip any native retweets from the returned timeline\n\n        :param rts: Boolean triggering the usage of the parameter\n        :raises: TwitterSearchException\n        \"\"\"\n    if not isinstance(rts, bool):\n        raise TwitterSearchException(1008)\n    self.arguments.update({'include_rts': 'true' if rts else 'false'})\n","code_tokens":["def","set_include_rts(self,","rts):\n","","","","","Sets","'include_rts'","parameter.","When","set","to","False,","","","","","","","","","the","timeline","will","strip","any","native","retweets","from","the","returned","timeline\n\n","","","","","","","",":param","rts:","Boolean","triggering","the","usage","of","the","parameter\n","","","","","","","",":raises:","TwitterSearchException\n","","","","","","","","\"\"\"\n","","","","if","not","isinstance(rts,","bool):\n","","","","","","","","raise","TwitterSearchException(1008)\n","","","","self.arguments.update({'include_rts':","'true'","if","rts","else","'false'})\n"],"func_name":"TwitterSearch-1.0.2\/class:TwitterUserOrder\/set_include_rts","docstring":"Sets 'include_rts' parameter. When set to False,         the timeline will strip any native retweets from the returned timeline\n\n:param rts: Boolean triggering the usage of the parameter\n:raises: TwitterSearchException","docstring_tokens":["Sets","'","include_rts","'","parameter",".","When","set","to","False",",","the","timeline","will","strip","any","native","retweets","from","the","returned","timeline",":","param","rts",":","Boolean","triggering","the","usage","of","the","parameter",":","raises",":","TwitterSearchException"],"summary":"Sets 'include_rts' parameter. When set to False,         the timeline will strip any native retweets from the returned timeline","code_with_docstring":"def set_include_rts(self, rts):\n    \"\"\" Sets 'include_rts' parameter. When set to False,         the timeline will strip any native retweets from the returned timeline\n\n        :param rts: Boolean triggering the usage of the parameter\n        :raises: TwitterSearchException\n        \"\"\"\n    if not isinstance(rts, bool):\n        raise TwitterSearchException(1008)\n    self.arguments.update({'include_rts': 'true' if rts else 'false'})\n","code_tokens_py":[]}
{"repo":"wxPython-4.1.0","path":"wxPython-4.1.0\/\/wx\/lib\/agw\/infobar.pyclass:AutoWrapStaticText\/OnSize","language":"python","sha":"ba2c823e7500d07d736e92bac975c3aacb42bfc5","url":"wxPython-4.1.0\/\/wx\/lib\/agw\/infobar.pyclass:AutoWrapStaticText\/OnSize","partition":"test","code":"def OnSize(self, event):\n    \n        Handles the ``wx.EVT_SIZE`` event for :class:`AutoWrapStaticText`.\n\n        :param `event`: a :class:`wx.SizeEvent` event to be processed.\n        \"\"\"\n    event.Skip()\n    self.Wrap(event.GetSize().width)\n","original_string":"def OnSize(self, event):\n    \"\"\"\n        Handles the ``wx.EVT_SIZE`` event for :class:`AutoWrapStaticText`.\n\n        :param `event`: a :class:`wx.SizeEvent` event to be processed.\n        \"\"\"\n    event.Skip()\n    self.Wrap(event.GetSize().width)\n","code_tokens":["def","OnSize(self,","event):\n","","","","\n","","","","","","","","Handles","the","``wx.EVT_SIZE``","event","for",":class:`AutoWrapStaticText`.\n\n","","","","","","","",":param","`event`:","a",":class:`wx.SizeEvent`","event","to","be","processed.\n","","","","","","","","\"\"\"\n","","","","event.Skip()\n","","","","self.Wrap(event.GetSize().width)\n"],"func_name":"wxPython-4.1.0\/class:AutoWrapStaticText\/OnSize","docstring":"Handles the ``wx.EVT_SIZE`` event for :class:`AutoWrapStaticText`.\n\n:param `event`: a :class:`wx.SizeEvent` event to be processed.","docstring_tokens":["Handles","the","`","`","wx",".","EVT_SIZE","`","`","event","for",":","class:`AutoWrapStaticText","`",".",":","param","`","event","`",":","a",":","class:`wx",".","SizeEvent","`","event","to","be","processed","."],"summary":"Handles the ``wx.EVT_SIZE`` event for :class:`AutoWrapStaticText`.","code_with_docstring":"def OnSize(self, event):\n    \"\"\"\n        Handles the ``wx.EVT_SIZE`` event for :class:`AutoWrapStaticText`.\n\n        :param `event`: a :class:`wx.SizeEvent` event to be processed.\n        \"\"\"\n    event.Skip()\n    self.Wrap(event.GetSize().width)\n","code_tokens_py":[]}
{"repo":"mimic-2.2.0","path":"mimic-2.2.0\/\/mimic\/rest\/fastly_api.pyclass:FastlyApi\/create_version","language":"python","sha":"c64ce5a89d8e4cafeba28582bb02a8432164f45a","url":"mimic-2.2.0\/\/mimic\/rest\/fastly_api.pyclass:FastlyApi\/create_version","partition":"test","code":"@app.route('\/service\/<string:service_id>\/version', methods=['POST'])\ndef create_version(self, request, service_id):\n    \n        Returns POST Service.\n\n        https:\/\/docs.fastly.com\/api\/config#version_2\n        \"\"\"\n    response = self.fastly_response.create_version(service_id)\n    return json.dumps(response)\n","original_string":"@app.route('\/service\/<string:service_id>\/version', methods=['POST'])\ndef create_version(self, request, service_id):\n    \"\"\"\n        Returns POST Service.\n\n        https:\/\/docs.fastly.com\/api\/config#version_2\n        \"\"\"\n    response = self.fastly_response.create_version(service_id)\n    return json.dumps(response)\n","code_tokens":["@app.route('\/service\/<string:service_id>\/version',","methods=['POST'])\ndef","create_version(self,","request,","service_id):\n","","","","\n","","","","","","","","Returns","POST","Service.\n\n","","","","","","","","https:\/\/docs.fastly.com\/api\/config#version_2\n","","","","","","","","\"\"\"\n","","","","response","=","self.fastly_response.create_version(service_id)\n","","","","return","json.dumps(response)\n"],"func_name":"mimic-2.2.0\/class:FastlyApi\/create_version","docstring":"Returns POST Service.\n\nhttps:\/\/docs.fastly.com\/api\/config#version_2","docstring_tokens":["Returns","POST","Service",".","https:\/\/docs.fastly.com\/api\/config#version_2"],"summary":"Returns POST Service.","code_with_docstring":"@app.route('\/service\/<string:service_id>\/version', methods=['POST'])\ndef create_version(self, request, service_id):\n    \"\"\"\n        Returns POST Service.\n\n        https:\/\/docs.fastly.com\/api\/config#version_2\n        \"\"\"\n    response = self.fastly_response.create_version(service_id)\n    return json.dumps(response)\n","code_tokens_py":[]}
{"repo":"osbot_jupyter","path":"osbot_jupyter\/\/kernels\/PlotKernel.pyfile:\/kernels\/PlotKernel.py:function:_parse_function\/_parse_function","language":"python","sha":"c01cf66c83eac8dcff028468058d8cf51b51c3e1","url":"osbot_jupyter\/\/kernels\/PlotKernel.pyfile:\/kernels\/PlotKernel.py:function:_parse_function\/_parse_function","partition":"test","code":"def _parse_function(code):\n    Return a NumPy function from a\n    string 'y=f(x)'.\"\"\"\n    return lambda x: eval(code.split('=')[1].strip(), _numpy_namespace, {\n        'x': x})\n","original_string":"def _parse_function(code):\n    \"\"\"Return a NumPy function from a\n    string 'y=f(x)'.\"\"\"\n    return lambda x: eval(code.split('=')[1].strip(), _numpy_namespace, {\n        'x': x})\n","code_tokens":["def","_parse_function(code):\n","","","","Return","a","NumPy","function","from","a\n","","","","string","'y=f(x)'.\"\"\"\n","","","","return","lambda","x:","eval(code.split('=')[1].strip(),","_numpy_namespace,","{\n","","","","","","","","'x':","x})\n"],"func_name":"osbot_jupyter\/file:\/kernels\/PlotKernel.py:function:_parse_function\/_parse_function","docstring":"Return a NumPy function from a\nstring 'y=f(x)'.","docstring_tokens":["Return","a","NumPy","function","from","a","string","'","y","=","f(x",")","'","."],"summary":"Return a NumPy function from a","code_with_docstring":"def _parse_function(code):\n    \"\"\"Return a NumPy function from a\n    string 'y=f(x)'.\"\"\"\n    return lambda x: eval(code.split('=')[1].strip(), _numpy_namespace, {\n        'x': x})\n","code_tokens_py":[]}
{"repo":"dhcpkit","path":"dhcpkit\/\/ipv6\/server\/statistics.pyfile:\/ipv6\/server\/statistics.py:function:create_update_dict_method\/create_update_dict_method","language":"python","sha":"6cba3b7fadc64f3ec65f54e0b11c49fb08f39728","url":"dhcpkit\/\/ipv6\/server\/statistics.pyfile:\/ipv6\/server\/statistics.py:function:create_update_dict_method\/create_update_dict_method","partition":"test","code":"def create_update_dict_method(counter_name):\n    \n    Create a counting method for a counter in a dictionary on the Statistics class\n\n    :param counter_name: The name of the counter to update\n    :return: The generated method\n    \"\"\"\n\n    def count_method(self, key):\n        \"\"\"\n        Update the counter for the given key\n        \"\"\"\n        counter_dict = getattr(self, counter_name)\n        if key in counter_dict:\n            counter = counter_dict[key]\n            with counter.get_lock():\n                counter.value += 1\n    return count_method\n","original_string":"def create_update_dict_method(counter_name):\n    \"\"\"\n    Create a counting method for a counter in a dictionary on the Statistics class\n\n    :param counter_name: The name of the counter to update\n    :return: The generated method\n    \"\"\"\n\n    def count_method(self, key):\n        \"\"\"\n        Update the counter for the given key\n        \"\"\"\n        counter_dict = getattr(self, counter_name)\n        if key in counter_dict:\n            counter = counter_dict[key]\n            with counter.get_lock():\n                counter.value += 1\n    return count_method\n","code_tokens":["def","create_update_dict_method(counter_name):\n","","","","\n","","","","Create","a","counting","method","for","a","counter","in","a","dictionary","on","the","Statistics","class\n\n","","","",":param","counter_name:","The","name","of","the","counter","to","update\n","","","",":return:","The","generated","method\n","","","","\"\"\"\n\n","","","","def","count_method(self,","key):\n","","","","","","","","\"\"\"\n","","","","","","","","Update","the","counter","for","the","given","key\n","","","","","","","","\"\"\"\n","","","","","","","","counter_dict","=","getattr(self,","counter_name)\n","","","","","","","","if","key","in","counter_dict:\n","","","","","","","","","","","","counter","=","counter_dict[key]\n","","","","","","","","","","","","with","counter.get_lock():\n","","","","","","","","","","","","","","","","counter.value","+=","1\n","","","","return","count_method\n"],"func_name":"dhcpkit\/file:\/ipv6\/server\/statistics.py:function:create_update_dict_method\/create_update_dict_method","docstring":"Create a counting method for a counter in a dictionary on the Statistics class\n\n:param counter_name: The name of the counter to update\n:return: The generated method","docstring_tokens":["Create","a","counting","method","for","a","counter","in","a","dictionary","on","the","Statistics","class",":","param","counter_name",":","The","name","of","the","counter","to","update",":","return",":","The","generated","method"],"summary":"Create a counting method for a counter in a dictionary on the Statistics class","code_with_docstring":"def create_update_dict_method(counter_name):\n    \"\"\"\n    Create a counting method for a counter in a dictionary on the Statistics class\n\n    :param counter_name: The name of the counter to update\n    :return: The generated method\n    \"\"\"\n\n    def count_method(self, key):\n        \"\"\"\n        Update the counter for the given key\n        \"\"\"\n        counter_dict = getattr(self, counter_name)\n        if key in counter_dict:\n            counter = counter_dict[key]\n            with counter.get_lock():\n                counter.value += 1\n    return count_method\n","code_tokens_py":[]}
{"repo":"influxdb_client","path":"influxdb_client\/\/domain\/label_update.pyclass:LabelUpdate\/__repr__","language":"python","sha":"8d9a279a743453f992d61a65f87cf2bb331dc353","url":"influxdb_client\/\/domain\/label_update.pyclass:LabelUpdate\/__repr__","partition":"test","code":"def __repr__(self):\n    \"\"\"\n    return self.to_str()\n","original_string":"def __repr__(self):\n    \"\"\"For `print` and `pprint`\"\"\"\n    return self.to_str()\n","code_tokens":["def","__repr__(self):\n","","","","\"\"\"\n","","","","return","self.to_str()\n"],"func_name":"influxdb_client\/class:LabelUpdate\/__repr__","docstring":"For `print` and `pprint`","docstring_tokens":["For","`","print","`","and","`","pprint","`"],"summary":"For `print` and `pprint`","code_with_docstring":"def __repr__(self):\n    \"\"\"For `print` and `pprint`\"\"\"\n    return self.to_str()\n","code_tokens_py":[]}
{"repo":"hackedit-1.0a2","path":"hackedit-1.0a2\/\/hackedit\/vendor\/pyqode\/core\/api\/code_edit.pyclass:CodeEdit\/insert_action","language":"python","sha":"46e1a4856c33c05c043c57f1813a9f64dfd7a1d4","url":"hackedit-1.0a2\/\/hackedit\/vendor\/pyqode\/core\/api\/code_edit.pyclass:CodeEdit\/insert_action","partition":"test","code":"def insert_action(self, action, prev_action):\n    \n        Inserts an action to the editor's context menu.\n\n        :param action: action to insert\n        :param prev_action: the action after which the new action must be\n            inserted or the insert index\n        \"\"\"\n    if isinstance(prev_action, QtWidgets.QAction):\n        index = self._actions.index(prev_action)\n    else:\n        index = prev_action\n    action.setShortcutContext(QtCore.Qt.WidgetShortcut)\n    self._actions.insert(index, action)\n","original_string":"def insert_action(self, action, prev_action):\n    \"\"\"\n        Inserts an action to the editor's context menu.\n\n        :param action: action to insert\n        :param prev_action: the action after which the new action must be\n            inserted or the insert index\n        \"\"\"\n    if isinstance(prev_action, QtWidgets.QAction):\n        index = self._actions.index(prev_action)\n    else:\n        index = prev_action\n    action.setShortcutContext(QtCore.Qt.WidgetShortcut)\n    self._actions.insert(index, action)\n","code_tokens":["def","insert_action(self,","action,","prev_action):\n","","","","\n","","","","","","","","Inserts","an","action","to","the","editor's","context","menu.\n\n","","","","","","","",":param","action:","action","to","insert\n","","","","","","","",":param","prev_action:","the","action","after","which","the","new","action","must","be\n","","","","","","","","","","","","inserted","or","the","insert","index\n","","","","","","","","\"\"\"\n","","","","if","isinstance(prev_action,","QtWidgets.QAction):\n","","","","","","","","index","=","self._actions.index(prev_action)\n","","","","else:\n","","","","","","","","index","=","prev_action\n","","","","action.setShortcutContext(QtCore.Qt.WidgetShortcut)\n","","","","self._actions.insert(index,","action)\n"],"func_name":"hackedit-1.0a2\/class:CodeEdit\/insert_action","docstring":"Inserts an action to the editor's context menu.\n\n:param action: action to insert\n:param prev_action: the action after which the new action must be\n    inserted or the insert index","docstring_tokens":["Inserts","an","action","to","the","editor","'s","context","menu",".",":","param","action",":","action","to","insert",":","param","prev_action",":","the","action","after","which","the","new","action","must","be","inserted","or","the","insert","index"],"summary":"Inserts an action to the editor's context menu.","code_with_docstring":"def insert_action(self, action, prev_action):\n    \"\"\"\n        Inserts an action to the editor's context menu.\n\n        :param action: action to insert\n        :param prev_action: the action after which the new action must be\n            inserted or the insert index\n        \"\"\"\n    if isinstance(prev_action, QtWidgets.QAction):\n        index = self._actions.index(prev_action)\n    else:\n        index = prev_action\n    action.setShortcutContext(QtCore.Qt.WidgetShortcut)\n    self._actions.insert(index, action)\n","code_tokens_py":[]}
{"repo":"qhist-0.1.2","path":"qhist-0.1.2\/\/qhist\/v3\/anchors.pyclass:Anchors\/__setattr__","language":"python","sha":"101983e8dcf3499e4a567d7ae66a4432abbe7893","url":"qhist-0.1.2\/\/qhist\/v3\/anchors.pyclass:Anchors\/__setattr__","partition":"test","code":"def __setattr__(self, key, obj):\n    \n    Two possibilities:\n\n    If obj is False\/None, this will explicitly disable this anchor and thus the\n    respective object will not be shown.\n\n    If it's ROOT.TObject, then bind it normally.\n\n    \"\"\"\n    assert isinstance(obj, ROOT.TObject)\n    if not key.startswith('_staticprop_'):\n        ROOT.SetOwnership(obj, False)\n        if isinstance(obj, ROOT.TPad):\n            obj.Draw()\n    return super(Anchors, self).__setattr__(key, obj)\n","original_string":"def __setattr__(self, key, obj):\n    \"\"\"\n    Two possibilities:\n\n    If obj is False\/None, this will explicitly disable this anchor and thus the\n    respective object will not be shown.\n\n    If it's ROOT.TObject, then bind it normally.\n\n    \"\"\"\n    assert isinstance(obj, ROOT.TObject)\n    if not key.startswith('_staticprop_'):\n        ROOT.SetOwnership(obj, False)\n        if isinstance(obj, ROOT.TPad):\n            obj.Draw()\n    return super(Anchors, self).__setattr__(key, obj)\n","code_tokens":["def","__setattr__(self,","key,","obj):\n","","","","\n","","","","Two","possibilities:\n\n","","","","If","obj","is","False\/None,","this","will","explicitly","disable","this","anchor","and","thus","the\n","","","","respective","object","will","not","be","shown.\n\n","","","","If","it's","ROOT.TObject,","then","bind","it","normally.\n\n","","","","\"\"\"\n","","","","assert","isinstance(obj,","ROOT.TObject)\n","","","","if","not","key.startswith('_staticprop_'):\n","","","","","","","","ROOT.SetOwnership(obj,","False)\n","","","","","","","","if","isinstance(obj,","ROOT.TPad):\n","","","","","","","","","","","","obj.Draw()\n","","","","return","super(Anchors,","self).__setattr__(key,","obj)\n"],"func_name":"qhist-0.1.2\/class:Anchors\/__setattr__","docstring":"Two possibilities:\n\nIf obj is False\/None, this will explicitly disable this anchor and thus the\nrespective object will not be shown.\n\nIf it's ROOT.TObject, then bind it normally.","docstring_tokens":["Two","possibilities",":","If","obj","is","False","\/","None",",","this","will","explicitly","disable","this","anchor","and","thus","the","respective","object","will","not","be","shown",".","If","it","'s","ROOT.TObject",",","then","bind","it","normally","."],"summary":"Two possibilities:","code_with_docstring":"def __setattr__(self, key, obj):\n    \"\"\"\n    Two possibilities:\n\n    If obj is False\/None, this will explicitly disable this anchor and thus the\n    respective object will not be shown.\n\n    If it's ROOT.TObject, then bind it normally.\n\n    \"\"\"\n    assert isinstance(obj, ROOT.TObject)\n    if not key.startswith('_staticprop_'):\n        ROOT.SetOwnership(obj, False)\n        if isinstance(obj, ROOT.TPad):\n            obj.Draw()\n    return super(Anchors, self).__setattr__(key, obj)\n","code_tokens_py":[]}
{"repo":"delphixpy","path":"delphixpy\/\/v1_10_3\/web\/maskingjob\/maskingjob.pyfile:\/v1_10_3\/web\/maskingjob\/maskingjob.py:function:update\/update","language":"python","sha":"d41f4981b098b0a1f347488613159cd2c955b73f","url":"delphixpy\/\/v1_10_3\/web\/maskingjob\/maskingjob.pyfile:\/v1_10_3\/web\/maskingjob\/maskingjob.py:function:update\/update","partition":"test","code":"def update(engine, ref, masking_job=None):\n    \n    Update the specified MaskingJob object.\n\n    :param engine: The Delphix Engine\n    :type engine: :py:class:`delphixpy.v1_10_3.delphix_engine.DelphixEngine`\n    :param ref: Reference to a\n        :py:class:`delphixpy.v1_10_3.web.objects.MaskingJob.MaskingJob` object\n    :type ref: ``str``\n    :param masking_job: Payload object.\n    :type masking_job: :py:class:`v1_10_3.web.vo.MaskingJob`\n    \"\"\"\n    assert API_VERSION == engine.API_VERSION, \"Wrong API version (%s) for parameter 'engine' (%s)\" % (\n        API_VERSION, engine.API_VERSION)\n    url = '\/resources\/json\/delphix\/maskingjob\/%s' % ref\n    response = engine.post(url, masking_job.to_dict(dirty=True) if\n        masking_job else None)\n    result = response_validator.validate(response, engine)\n    raw_result = getattr(engine, 'raw_result', False)\n    return response_validator.parse_result(result, undef_enabled=True,\n        return_types=None, returns_list=None, raw_result=raw_result)\n","original_string":"def update(engine, ref, masking_job=None):\n    \"\"\"\n    Update the specified MaskingJob object.\n\n    :param engine: The Delphix Engine\n    :type engine: :py:class:`delphixpy.v1_10_3.delphix_engine.DelphixEngine`\n    :param ref: Reference to a\n        :py:class:`delphixpy.v1_10_3.web.objects.MaskingJob.MaskingJob` object\n    :type ref: ``str``\n    :param masking_job: Payload object.\n    :type masking_job: :py:class:`v1_10_3.web.vo.MaskingJob`\n    \"\"\"\n    assert API_VERSION == engine.API_VERSION, \"Wrong API version (%s) for parameter 'engine' (%s)\" % (\n        API_VERSION, engine.API_VERSION)\n    url = '\/resources\/json\/delphix\/maskingjob\/%s' % ref\n    response = engine.post(url, masking_job.to_dict(dirty=True) if\n        masking_job else None)\n    result = response_validator.validate(response, engine)\n    raw_result = getattr(engine, 'raw_result', False)\n    return response_validator.parse_result(result, undef_enabled=True,\n        return_types=None, returns_list=None, raw_result=raw_result)\n","code_tokens":["def","update(engine,","ref,","masking_job=None):\n","","","","\n","","","","Update","the","specified","MaskingJob","object.\n\n","","","",":param","engine:","The","Delphix","Engine\n","","","",":type","engine:",":py:class:`delphixpy.v1_10_3.delphix_engine.DelphixEngine`\n","","","",":param","ref:","Reference","to","a\n","","","","","","","",":py:class:`delphixpy.v1_10_3.web.objects.MaskingJob.MaskingJob`","object\n","","","",":type","ref:","``str``\n","","","",":param","masking_job:","Payload","object.\n","","","",":type","masking_job:",":py:class:`v1_10_3.web.vo.MaskingJob`\n","","","","\"\"\"\n","","","","assert","API_VERSION","==","engine.API_VERSION,","\"Wrong","API","version","(%s)","for","parameter","'engine'","(%s)\"","%","(\n","","","","","","","","API_VERSION,","engine.API_VERSION)\n","","","","url","=","'\/resources\/json\/delphix\/maskingjob\/%s'","%","ref\n","","","","response","=","engine.post(url,","masking_job.to_dict(dirty=True)","if\n","","","","","","","","masking_job","else","None)\n","","","","result","=","response_validator.validate(response,","engine)\n","","","","raw_result","=","getattr(engine,","'raw_result',","False)\n","","","","return","response_validator.parse_result(result,","undef_enabled=True,\n","","","","","","","","return_types=None,","returns_list=None,","raw_result=raw_result)\n"],"func_name":"delphixpy\/file:\/v1_10_3\/web\/maskingjob\/maskingjob.py:function:update\/update","docstring":"Update the specified MaskingJob object.\n\n:param engine: The Delphix Engine\n:type engine: :py:class:`delphixpy.v1_10_3.delphix_engine.DelphixEngine`\n:param ref: Reference to a\n    :py:class:`delphixpy.v1_10_3.web.objects.MaskingJob.MaskingJob` object\n:type ref: ``str``\n:param masking_job: Payload object.\n:type masking_job: :py:class:`v1_10_3.web.vo.MaskingJob`","docstring_tokens":["Update","the","specified","MaskingJob","object",".",":","param","engine",":","The","Delphix","Engine",":","type","engine",":",":","py",":","class:`delphixpy.v1_10_3.delphix_engine",".","DelphixEngine","`",":","param","ref",":","Reference","to","a",":","py",":","class:`delphixpy.v1_10_3.web.objects",".","MaskingJob",".","MaskingJob","`","object",":","type","ref",":","`","`","str","`","`",":","param","masking_job",":","Payload","object",".",":","type","masking_job",":",":","py",":","class:`v1_10_3.web.vo",".","MaskingJob","`"],"summary":"Update the specified MaskingJob object.","code_with_docstring":"def update(engine, ref, masking_job=None):\n    \"\"\"\n    Update the specified MaskingJob object.\n\n    :param engine: The Delphix Engine\n    :type engine: :py:class:`delphixpy.v1_10_3.delphix_engine.DelphixEngine`\n    :param ref: Reference to a\n        :py:class:`delphixpy.v1_10_3.web.objects.MaskingJob.MaskingJob` object\n    :type ref: ``str``\n    :param masking_job: Payload object.\n    :type masking_job: :py:class:`v1_10_3.web.vo.MaskingJob`\n    \"\"\"\n    assert API_VERSION == engine.API_VERSION, \"Wrong API version (%s) for parameter 'engine' (%s)\" % (\n        API_VERSION, engine.API_VERSION)\n    url = '\/resources\/json\/delphix\/maskingjob\/%s' % ref\n    response = engine.post(url, masking_job.to_dict(dirty=True) if\n        masking_job else None)\n    result = response_validator.validate(response, engine)\n    raw_result = getattr(engine, 'raw_result', False)\n    return response_validator.parse_result(result, undef_enabled=True,\n        return_types=None, returns_list=None, raw_result=raw_result)\n","code_tokens_py":[]}
{"repo":"lftools-0.33.0","path":"lftools-0.33.0\/\/lftools\/cli\/deploy.pyfile:\/lftools\/cli\/deploy.py:function:copy_archives\/copy_archives","language":"python","sha":"0e93ff6b1d8667605bffdda73444c1d1613e368f","url":"lftools-0.33.0\/\/lftools\/cli\/deploy.pyfile:\/lftools\/cli\/deploy.py:function:copy_archives\/copy_archives","partition":"test","code":"@click.command(name='copy-archives')\n@click.argument('workspace', envvar='WORKSPACE')\n@click.argument('pattern', nargs=-1, default=None, required=False)\n@click.pass_context\ndef copy_archives(ctx, workspace, pattern):\n    Copy files for archiving.\n\n    Arguments:\n\n        workspace: Typically a Jenkins WORKSPACE to copy files from.\n        pattern: Space-separated list of Unix style glob patterns of files to\n            copy for archiving. (default: false)\n    \"\"\"\n    deploy_sys.copy_archives(workspace, pattern)\n","original_string":"@click.command(name='copy-archives')\n@click.argument('workspace', envvar='WORKSPACE')\n@click.argument('pattern', nargs=-1, default=None, required=False)\n@click.pass_context\ndef copy_archives(ctx, workspace, pattern):\n    \"\"\"Copy files for archiving.\n\n    Arguments:\n\n        workspace: Typically a Jenkins WORKSPACE to copy files from.\n        pattern: Space-separated list of Unix style glob patterns of files to\n            copy for archiving. (default: false)\n    \"\"\"\n    deploy_sys.copy_archives(workspace, pattern)\n","code_tokens":["@click.command(name='copy-archives')\n@click.argument('workspace',","envvar='WORKSPACE')\n@click.argument('pattern',","nargs=-1,","default=None,","required=False)\n@click.pass_context\ndef","copy_archives(ctx,","workspace,","pattern):\n","","","","Copy","files","for","archiving.\n\n","","","","Arguments:\n\n","","","","","","","","workspace:","Typically","a","Jenkins","WORKSPACE","to","copy","files","from.\n","","","","","","","","pattern:","Space-separated","list","of","Unix","style","glob","patterns","of","files","to\n","","","","","","","","","","","","copy","for","archiving.","(default:","false)\n","","","","\"\"\"\n","","","","deploy_sys.copy_archives(workspace,","pattern)\n"],"func_name":"lftools-0.33.0\/file:\/lftools\/cli\/deploy.py:function:copy_archives\/copy_archives","docstring":"Copy files for archiving.\n\nArguments:\n\n    workspace: Typically a Jenkins WORKSPACE to copy files from.\n    pattern: Space-separated list of Unix style glob patterns of files to\n        copy for archiving. (default: false)","docstring_tokens":["Copy","files","for","archiving",".","Arguments",":","workspace",":","Typically","a","Jenkins","WORKSPACE","to","copy","files","from",".","pattern",":","Space","-","separated","list","of","Unix","style","glob","patterns","of","files","to","copy","for","archiving",".","(","default",":","false",")"],"summary":"Copy files for archiving.","code_with_docstring":"@click.command(name='copy-archives')\n@click.argument('workspace', envvar='WORKSPACE')\n@click.argument('pattern', nargs=-1, default=None, required=False)\n@click.pass_context\ndef copy_archives(ctx, workspace, pattern):\n    \"\"\"Copy files for archiving.\n\n    Arguments:\n\n        workspace: Typically a Jenkins WORKSPACE to copy files from.\n        pattern: Space-separated list of Unix style glob patterns of files to\n            copy for archiving. (default: false)\n    \"\"\"\n    deploy_sys.copy_archives(workspace, pattern)\n","code_tokens_py":[]}
{"repo":"pulumi_vault-2.1.0","path":"pulumi_vault-2.1.0\/\/pulumi_vault\/rabbitMq\/secret_backend_role.pyclass:SecretBackendRole\/get","language":"python","sha":"87d3e5efd1762679e8a090f4973327dad2338405","url":"pulumi_vault-2.1.0\/\/pulumi_vault\/rabbitMq\/secret_backend_role.pyclass:SecretBackendRole\/get","partition":"test","code":"@staticmethod\ndef get(resource_name, id, opts=None, backend=None, name=None, tags=None,\n    vhosts=None):\n    \n        Get an existing SecretBackendRole resource's state with the given name, id, and optional extra\n        properties used to qualify the lookup.\n\n        :param str resource_name: The unique name of the resulting resource.\n        :param str id: The unique provider ID of the resource to lookup.\n        :param pulumi.ResourceOptions opts: Options for the resource.\n        :param pulumi.Input[str] backend: The path the RabbitMQ secret backend is mounted at,\n               with no leading or trailing `\/`s.\n        :param pulumi.Input[str] name: The name to identify this role within the backend.\n               Must be unique within the backend.\n        :param pulumi.Input[str] tags: Specifies a comma-separated RabbitMQ management tags.\n        :param pulumi.Input[list] vhosts: Specifies a map of virtual hosts to permissions.\n\n        The **vhosts** object supports the following:\n\n          * `configure` (`pulumi.Input[str]`)\n          * `host` (`pulumi.Input[str]`)\n          * `read` (`pulumi.Input[str]`)\n          * `write` (`pulumi.Input[str]`)\n        \"\"\"\n    opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))\n    __props__ = dict()\n    __props__['backend'] = backend\n    __props__['name'] = name\n    __props__['tags'] = tags\n    __props__['vhosts'] = vhosts\n    return SecretBackendRole(resource_name, opts=opts, __props__=__props__)\n","original_string":"@staticmethod\ndef get(resource_name, id, opts=None, backend=None, name=None, tags=None,\n    vhosts=None):\n    \"\"\"\n        Get an existing SecretBackendRole resource's state with the given name, id, and optional extra\n        properties used to qualify the lookup.\n\n        :param str resource_name: The unique name of the resulting resource.\n        :param str id: The unique provider ID of the resource to lookup.\n        :param pulumi.ResourceOptions opts: Options for the resource.\n        :param pulumi.Input[str] backend: The path the RabbitMQ secret backend is mounted at,\n               with no leading or trailing `\/`s.\n        :param pulumi.Input[str] name: The name to identify this role within the backend.\n               Must be unique within the backend.\n        :param pulumi.Input[str] tags: Specifies a comma-separated RabbitMQ management tags.\n        :param pulumi.Input[list] vhosts: Specifies a map of virtual hosts to permissions.\n\n        The **vhosts** object supports the following:\n\n          * `configure` (`pulumi.Input[str]`)\n          * `host` (`pulumi.Input[str]`)\n          * `read` (`pulumi.Input[str]`)\n          * `write` (`pulumi.Input[str]`)\n        \"\"\"\n    opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))\n    __props__ = dict()\n    __props__['backend'] = backend\n    __props__['name'] = name\n    __props__['tags'] = tags\n    __props__['vhosts'] = vhosts\n    return SecretBackendRole(resource_name, opts=opts, __props__=__props__)\n","code_tokens":["@staticmethod\ndef","get(resource_name,","id,","opts=None,","backend=None,","name=None,","tags=None,\n","","","","vhosts=None):\n","","","","\n","","","","","","","","Get","an","existing","SecretBackendRole","resource's","state","with","the","given","name,","id,","and","optional","extra\n","","","","","","","","properties","used","to","qualify","the","lookup.\n\n","","","","","","","",":param","str","resource_name:","The","unique","name","of","the","resulting","resource.\n","","","","","","","",":param","str","id:","The","unique","provider","ID","of","the","resource","to","lookup.\n","","","","","","","",":param","pulumi.ResourceOptions","opts:","Options","for","the","resource.\n","","","","","","","",":param","pulumi.Input[str]","backend:","The","path","the","RabbitMQ","secret","backend","is","mounted","at,\n","","","","","","","","","","","","","","","with","no","leading","or","trailing","`\/`s.\n","","","","","","","",":param","pulumi.Input[str]","name:","The","name","to","identify","this","role","within","the","backend.\n","","","","","","","","","","","","","","","Must","be","unique","within","the","backend.\n","","","","","","","",":param","pulumi.Input[str]","tags:","Specifies","a","comma-separated","RabbitMQ","management","tags.\n","","","","","","","",":param","pulumi.Input[list]","vhosts:","Specifies","a","map","of","virtual","hosts","to","permissions.\n\n","","","","","","","","The","**vhosts**","object","supports","the","following:\n\n","","","","","","","","","","*","`configure`","(`pulumi.Input[str]`)\n","","","","","","","","","","*","`host`","(`pulumi.Input[str]`)\n","","","","","","","","","","*","`read`","(`pulumi.Input[str]`)\n","","","","","","","","","","*","`write`","(`pulumi.Input[str]`)\n","","","","","","","","\"\"\"\n","","","","opts","=","pulumi.ResourceOptions.merge(opts,","pulumi.ResourceOptions(id=id))\n","","","","__props__","=","dict()\n","","","","__props__['backend']","=","backend\n","","","","__props__['name']","=","name\n","","","","__props__['tags']","=","tags\n","","","","__props__['vhosts']","=","vhosts\n","","","","return","SecretBackendRole(resource_name,","opts=opts,","__props__=__props__)\n"],"func_name":"pulumi_vault-2.1.0\/class:SecretBackendRole\/get","docstring":"Get an existing SecretBackendRole resource's state with the given name, id, and optional extra\nproperties used to qualify the lookup.\n\n:param str resource_name: The unique name of the resulting resource.\n:param str id: The unique provider ID of the resource to lookup.\n:param pulumi.ResourceOptions opts: Options for the resource.\n:param pulumi.Input[str] backend: The path the RabbitMQ secret backend is mounted at,\n       with no leading or trailing `\/`s.\n:param pulumi.Input[str] name: The name to identify this role within the backend.\n       Must be unique within the backend.\n:param pulumi.Input[str] tags: Specifies a comma-separated RabbitMQ management tags.\n:param pulumi.Input[list] vhosts: Specifies a map of virtual hosts to permissions.\n\nThe **vhosts** object supports the following:\n\n  * `configure` (`pulumi.Input[str]`)\n  * `host` (`pulumi.Input[str]`)\n  * `read` (`pulumi.Input[str]`)\n  * `write` (`pulumi.Input[str]`)","docstring_tokens":["Get","an","existing","SecretBackendRole","resource","'s","state","with","the","given","name",",","i","d",",","and","optional","extra","properties","used","to","qualify","the","lookup",".",":","param","str","resource_name",":","The","unique","name","of","the","resulting","resource",".",":","param","str","i","d",":","The","unique","provider","ID","of","the","resource","to","lookup",".",":","param","pulumi",".","ResourceOptions","opts",":","Options","for","the","resource",".",":","param","pulumi",".","Input[str","]","backend",":","The","path","the","RabbitMQ","secret","backend","is","mounted","at",",","with","no","leading","or","trailing","`","\/`s",".",":","param","pulumi",".","Input[str","]","name",":","The","name","to","identify","this","role","within","the","backend",".","Must","be","unique","within","the","backend",".",":","param","pulumi",".","Input[str","]","tags",":","Specifies","a","comma","-","separated","RabbitMQ","management","tags",".",":","param","pulumi",".","Input[list","]","vhosts",":","Specifies","a","map","of","virtual","hosts","to","permissions",".","The","*","*","vhosts","*","*","object","supports","the","following",":","*","`","configure","`","(","`","pulumi",".","Input[str","]","`",")","*","`","host","`","(","`","pulumi",".","Input[str","]","`",")","*","`","read","`","(","`","pulumi",".","Input[str","]","`",")","*","`","write","`","(","`","pulumi",".","Input[str","]","`",")"],"summary":"Get an existing SecretBackendRole resource's state with the given name, id, and optional extra","code_with_docstring":"@staticmethod\ndef get(resource_name, id, opts=None, backend=None, name=None, tags=None,\n    vhosts=None):\n    \"\"\"\n        Get an existing SecretBackendRole resource's state with the given name, id, and optional extra\n        properties used to qualify the lookup.\n\n        :param str resource_name: The unique name of the resulting resource.\n        :param str id: The unique provider ID of the resource to lookup.\n        :param pulumi.ResourceOptions opts: Options for the resource.\n        :param pulumi.Input[str] backend: The path the RabbitMQ secret backend is mounted at,\n               with no leading or trailing `\/`s.\n        :param pulumi.Input[str] name: The name to identify this role within the backend.\n               Must be unique within the backend.\n        :param pulumi.Input[str] tags: Specifies a comma-separated RabbitMQ management tags.\n        :param pulumi.Input[list] vhosts: Specifies a map of virtual hosts to permissions.\n\n        The **vhosts** object supports the following:\n\n          * `configure` (`pulumi.Input[str]`)\n          * `host` (`pulumi.Input[str]`)\n          * `read` (`pulumi.Input[str]`)\n          * `write` (`pulumi.Input[str]`)\n        \"\"\"\n    opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))\n    __props__ = dict()\n    __props__['backend'] = backend\n    __props__['name'] = name\n    __props__['tags'] = tags\n    __props__['vhosts'] = vhosts\n    return SecretBackendRole(resource_name, opts=opts, __props__=__props__)\n","code_tokens_py":[]}
{"repo":"lookerapi","path":"lookerapi\/\/models\/whitelabel_configuration.pyclass:WhitelabelConfiguration\/allow_looker_mentions","language":"python","sha":"a8e4282f64f935d6488323a461558c8cf5af38a4","url":"lookerapi\/\/models\/whitelabel_configuration.pyclass:WhitelabelConfiguration\/allow_looker_mentions","partition":"test","code":"@property\ndef allow_looker_mentions(self):\n    \n        Gets the allow_looker_mentions of this WhitelabelConfiguration.\n        Boolean to toggle mentions of Looker in emails\n\n        :return: The allow_looker_mentions of this WhitelabelConfiguration.\n        :rtype: bool\n        \"\"\"\n    return self._allow_looker_mentions\n","original_string":"@property\ndef allow_looker_mentions(self):\n    \"\"\"\n        Gets the allow_looker_mentions of this WhitelabelConfiguration.\n        Boolean to toggle mentions of Looker in emails\n\n        :return: The allow_looker_mentions of this WhitelabelConfiguration.\n        :rtype: bool\n        \"\"\"\n    return self._allow_looker_mentions\n","code_tokens":["@property\ndef","allow_looker_mentions(self):\n","","","","\n","","","","","","","","Gets","the","allow_looker_mentions","of","this","WhitelabelConfiguration.\n","","","","","","","","Boolean","to","toggle","mentions","of","Looker","in","emails\n\n","","","","","","","",":return:","The","allow_looker_mentions","of","this","WhitelabelConfiguration.\n","","","","","","","",":rtype:","bool\n","","","","","","","","\"\"\"\n","","","","return","self._allow_looker_mentions\n"],"func_name":"lookerapi\/class:WhitelabelConfiguration\/allow_looker_mentions","docstring":"Gets the allow_looker_mentions of this WhitelabelConfiguration.\nBoolean to toggle mentions of Looker in emails\n\n:return: The allow_looker_mentions of this WhitelabelConfiguration.\n:rtype: bool","docstring_tokens":["Gets","the","allow_looker_mentions","of","this","WhitelabelConfiguration",".","Boolean","to","toggle","mentions","of","Looker","in","emails",":","return",":","The","allow_looker_mentions","of","this","WhitelabelConfiguration",".",":","rtype",":","bool"],"summary":"Gets the allow_looker_mentions of this WhitelabelConfiguration.","code_with_docstring":"@property\ndef allow_looker_mentions(self):\n    \"\"\"\n        Gets the allow_looker_mentions of this WhitelabelConfiguration.\n        Boolean to toggle mentions of Looker in emails\n\n        :return: The allow_looker_mentions of this WhitelabelConfiguration.\n        :rtype: bool\n        \"\"\"\n    return self._allow_looker_mentions\n","code_tokens_py":[]}
{"repo":"argus_api","path":"argus_api\/\/api\/componentadmin\/v1\/lookup.pyfile:\/api\/componentadmin\/v1\/lookup.py:function:get_properties_2\/get_properties_2","language":"python","sha":"3533e95b2b40c03128fff12a5f38a5b347e7b052","url":"argus_api\/\/api\/componentadmin\/v1\/lookup.pyfile:\/api\/componentadmin\/v1\/lookup.py:function:get_properties_2\/get_properties_2","partition":"test","code":"@register_command(extending=('componentadmin', 'v1', 'lookup'), module=\n    argus_cli_module)\ndef get_properties_2(pattern: dict=None, type: str=None, json: bool=True,\n    verify: bool=True, apiKey: str=None, authentication: dict={}) ->dict:\n    Lookup runtime components (INTERNAL)\n    :param dict pattern: \n    :param str type: \n    :raises AuthenticationFailedException: on 401\n    :raises AccessDeniedException: on 403\n    :raises RemoteInvocationFailedException: on 409\n    :returns: A requests object or JSON object\n    \"\"\"\n    from os import getenv\n    from requests import post\n    from argus_api.exceptions import http\n    from argus_cli.settings import settings\n    url = '{}\/componentadmin\/v1\/lookup'.format(settings['api']['api_url'])\n    headers = {'User-Agent': 'ArgusToolbelt\/'}\n    if not apiKey and 'api_key' in settings['api']:\n        apiKey = settings['api']['api_key']\n    if apiKey:\n        headers['Argus-API-Key'] = apiKey\n    elif authentication and isinstance(authentication, dict):\n        headers.update(authentication)\n    elif callable(authentication):\n        headers.update(authentication(url))\n    body = {}\n    if pattern is not None:\n        body.update({'pattern': pattern})\n    if type is not None:\n        body.update({'type': type})\n    query_parameters = {}\n    log.debug('POST %s (headers: %s, body: %s)' % (url, str(headers), str(\n        body) or ''))\n    response = post(url, params=query_parameters or None, json=body or None,\n        verify=getenv('REQUESTS_CA_BUNDLE', verify), headers=headers)\n    if response.status_code == 401:\n        raise http.AuthenticationFailedException(response)\n    elif response.status_code == 403:\n        raise http.AccessDeniedException(response)\n    elif response.status_code == 412:\n        raise http.ValidationErrorException(response)\n    elif response.status_code == 404:\n        raise http.ObjectNotFoundException(response)\n    return response.json() if json else response\n","original_string":"@register_command(extending=('componentadmin', 'v1', 'lookup'), module=\n    argus_cli_module)\ndef get_properties_2(pattern: dict=None, type: str=None, json: bool=True,\n    verify: bool=True, apiKey: str=None, authentication: dict={}) ->dict:\n    \"\"\"Lookup runtime components (INTERNAL)\n    :param dict pattern: \n    :param str type: \n    :raises AuthenticationFailedException: on 401\n    :raises AccessDeniedException: on 403\n    :raises RemoteInvocationFailedException: on 409\n    :returns: A requests object or JSON object\n    \"\"\"\n    from os import getenv\n    from requests import post\n    from argus_api.exceptions import http\n    from argus_cli.settings import settings\n    url = '{}\/componentadmin\/v1\/lookup'.format(settings['api']['api_url'])\n    headers = {'User-Agent': 'ArgusToolbelt\/'}\n    if not apiKey and 'api_key' in settings['api']:\n        apiKey = settings['api']['api_key']\n    if apiKey:\n        headers['Argus-API-Key'] = apiKey\n    elif authentication and isinstance(authentication, dict):\n        headers.update(authentication)\n    elif callable(authentication):\n        headers.update(authentication(url))\n    body = {}\n    if pattern is not None:\n        body.update({'pattern': pattern})\n    if type is not None:\n        body.update({'type': type})\n    query_parameters = {}\n    log.debug('POST %s (headers: %s, body: %s)' % (url, str(headers), str(\n        body) or ''))\n    response = post(url, params=query_parameters or None, json=body or None,\n        verify=getenv('REQUESTS_CA_BUNDLE', verify), headers=headers)\n    if response.status_code == 401:\n        raise http.AuthenticationFailedException(response)\n    elif response.status_code == 403:\n        raise http.AccessDeniedException(response)\n    elif response.status_code == 412:\n        raise http.ValidationErrorException(response)\n    elif response.status_code == 404:\n        raise http.ObjectNotFoundException(response)\n    return response.json() if json else response\n","code_tokens":["@register_command(extending=('componentadmin',","'v1',","'lookup'),","module=\n","","","","argus_cli_module)\ndef","get_properties_2(pattern:","dict=None,","type:","str=None,","json:","bool=True,\n","","","","verify:","bool=True,","apiKey:","str=None,","authentication:","dict={})","->dict:\n","","","","Lookup","runtime","components","(INTERNAL)\n","","","",":param","dict","pattern:","\n","","","",":param","str","type:","\n","","","",":raises","AuthenticationFailedException:","on","401\n","","","",":raises","AccessDeniedException:","on","403\n","","","",":raises","RemoteInvocationFailedException:","on","409\n","","","",":returns:","A","requests","object","or","JSON","object\n","","","","\"\"\"\n","","","","from","os","import","getenv\n","","","","from","requests","import","post\n","","","","from","argus_api.exceptions","import","http\n","","","","from","argus_cli.settings","import","settings\n","","","","url","=","'{}\/componentadmin\/v1\/lookup'.format(settings['api']['api_url'])\n","","","","headers","=","{'User-Agent':","'ArgusToolbelt\/'}\n","","","","if","not","apiKey","and","'api_key'","in","settings['api']:\n","","","","","","","","apiKey","=","settings['api']['api_key']\n","","","","if","apiKey:\n","","","","","","","","headers['Argus-API-Key']","=","apiKey\n","","","","elif","authentication","and","isinstance(authentication,","dict):\n","","","","","","","","headers.update(authentication)\n","","","","elif","callable(authentication):\n","","","","","","","","headers.update(authentication(url))\n","","","","body","=","{}\n","","","","if","pattern","is","not","None:\n","","","","","","","","body.update({'pattern':","pattern})\n","","","","if","type","is","not","None:\n","","","","","","","","body.update({'type':","type})\n","","","","query_parameters","=","{}\n","","","","log.debug('POST","%s","(headers:","%s,","body:","%s)'","%","(url,","str(headers),","str(\n","","","","","","","","body)","or","''))\n","","","","response","=","post(url,","params=query_parameters","or","None,","json=body","or","None,\n","","","","","","","","verify=getenv('REQUESTS_CA_BUNDLE',","verify),","headers=headers)\n","","","","if","response.status_code","==","401:\n","","","","","","","","raise","http.AuthenticationFailedException(response)\n","","","","elif","response.status_code","==","403:\n","","","","","","","","raise","http.AccessDeniedException(response)\n","","","","elif","response.status_code","==","412:\n","","","","","","","","raise","http.ValidationErrorException(response)\n","","","","elif","response.status_code","==","404:\n","","","","","","","","raise","http.ObjectNotFoundException(response)\n","","","","return","response.json()","if","json","else","response\n"],"func_name":"argus_api\/file:\/api\/componentadmin\/v1\/lookup.py:function:get_properties_2\/get_properties_2","docstring":"Lookup runtime components (INTERNAL)\n:param dict pattern: \n:param str type: \n:raises AuthenticationFailedException: on 401\n:raises AccessDeniedException: on 403\n:raises RemoteInvocationFailedException: on 409\n:returns: A requests object or JSON object","docstring_tokens":["Lookup","runtime","components","(","INTERNAL",")",":","param","dict","pattern",":",":","param","str","type",":",":","raises","AuthenticationFailedException",":","on","401",":","raises","AccessDeniedException",":","on","403",":","raises","RemoteInvocationFailedException",":","on","409",":","returns",":","A","requests","object","or","JSON","object"],"summary":"Lookup runtime components (INTERNAL)","code_with_docstring":"@register_command(extending=('componentadmin', 'v1', 'lookup'), module=\n    argus_cli_module)\ndef get_properties_2(pattern: dict=None, type: str=None, json: bool=True,\n    verify: bool=True, apiKey: str=None, authentication: dict={}) ->dict:\n    \"\"\"Lookup runtime components (INTERNAL)\n    :param dict pattern: \n    :param str type: \n    :raises AuthenticationFailedException: on 401\n    :raises AccessDeniedException: on 403\n    :raises RemoteInvocationFailedException: on 409\n    :returns: A requests object or JSON object\n    \"\"\"\n    from os import getenv\n    from requests import post\n    from argus_api.exceptions import http\n    from argus_cli.settings import settings\n    url = '{}\/componentadmin\/v1\/lookup'.format(settings['api']['api_url'])\n    headers = {'User-Agent': 'ArgusToolbelt\/'}\n    if not apiKey and 'api_key' in settings['api']:\n        apiKey = settings['api']['api_key']\n    if apiKey:\n        headers['Argus-API-Key'] = apiKey\n    elif authentication and isinstance(authentication, dict):\n        headers.update(authentication)\n    elif callable(authentication):\n        headers.update(authentication(url))\n    body = {}\n    if pattern is not None:\n        body.update({'pattern': pattern})\n    if type is not None:\n        body.update({'type': type})\n    query_parameters = {}\n    log.debug('POST %s (headers: %s, body: %s)' % (url, str(headers), str(\n        body) or ''))\n    response = post(url, params=query_parameters or None, json=body or None,\n        verify=getenv('REQUESTS_CA_BUNDLE', verify), headers=headers)\n    if response.status_code == 401:\n        raise http.AuthenticationFailedException(response)\n    elif response.status_code == 403:\n        raise http.AccessDeniedException(response)\n    elif response.status_code == 412:\n        raise http.ValidationErrorException(response)\n    elif response.status_code == 404:\n        raise http.ObjectNotFoundException(response)\n    return response.json() if json else response\n","code_tokens_py":[]}
{"repo":"ec2mc","path":"ec2mc\/\/aws_setup_src\/ip_handlers\/mc_handler.pyfile:\/aws_setup_src\/ip_handlers\/mc_handler.py:function:update_servers_dat\/update_servers_dat","language":"python","sha":"74b7ed98760ee5e1ebf5af0cdafbd74fbc3911c4","url":"ec2mc\/\/aws_setup_src\/ip_handlers\/mc_handler.pyfile:\/aws_setup_src\/ip_handlers\/mc_handler.py:function:update_servers_dat\/update_servers_dat","partition":"test","code":"def update_servers_dat(servers_dat_path, server_name, new_ip):\n    update IP of server_name in server list with new_ip\n\n    Args:\n        servers_dat_path (str): File path for MC client's servers.dat.\n        server_name (str): Name of the server within client's server list.\n        new_ip (str): Instance's new IP to update client's server list with.\n    \"\"\"\n    servers_dat_nbt = load(servers_dat_path, gzipped=False)\n    for server_list_entry in servers_dat_nbt.root['servers']:\n        if server_name == server_list_entry['name']:\n            server_list_entry['ip'] = String(new_ip)\n            print(f'  IP for \"{server_name}\" entry in server list updated.')\n            break\n    else:\n        if not servers_dat_nbt.root['servers']:\n            servers_dat_nbt.root['servers'] = List[Compound]()\n        servers_dat_nbt.root['servers'].append(Compound({'ip': String(\n            new_ip), 'name': String(server_name)}))\n        print(\n            f'  \"{server_name}\" entry with instance\\'s IP added to server list.'\n            )\n    servers_dat_nbt.save(gzipped=False)\n","original_string":"def update_servers_dat(servers_dat_path, server_name, new_ip):\n    \"\"\"update IP of server_name in server list with new_ip\n\n    Args:\n        servers_dat_path (str): File path for MC client's servers.dat.\n        server_name (str): Name of the server within client's server list.\n        new_ip (str): Instance's new IP to update client's server list with.\n    \"\"\"\n    servers_dat_nbt = load(servers_dat_path, gzipped=False)\n    for server_list_entry in servers_dat_nbt.root['servers']:\n        if server_name == server_list_entry['name']:\n            server_list_entry['ip'] = String(new_ip)\n            print(f'  IP for \"{server_name}\" entry in server list updated.')\n            break\n    else:\n        if not servers_dat_nbt.root['servers']:\n            servers_dat_nbt.root['servers'] = List[Compound]()\n        servers_dat_nbt.root['servers'].append(Compound({'ip': String(\n            new_ip), 'name': String(server_name)}))\n        print(\n            f'  \"{server_name}\" entry with instance\\'s IP added to server list.'\n            )\n    servers_dat_nbt.save(gzipped=False)\n","code_tokens":["def","update_servers_dat(servers_dat_path,","server_name,","new_ip):\n","","","","update","IP","of","server_name","in","server","list","with","new_ip\n\n","","","","Args:\n","","","","","","","","servers_dat_path","(str):","File","path","for","MC","client's","servers.dat.\n","","","","","","","","server_name","(str):","Name","of","the","server","within","client's","server","list.\n","","","","","","","","new_ip","(str):","Instance's","new","IP","to","update","client's","server","list","with.\n","","","","\"\"\"\n","","","","servers_dat_nbt","=","load(servers_dat_path,","gzipped=False)\n","","","","for","server_list_entry","in","servers_dat_nbt.root['servers']:\n","","","","","","","","if","server_name","==","server_list_entry['name']:\n","","","","","","","","","","","","server_list_entry['ip']","=","String(new_ip)\n","","","","","","","","","","","","print(f'","","IP","for","\"{server_name}\"","entry","in","server","list","updated.')\n","","","","","","","","","","","","break\n","","","","else:\n","","","","","","","","if","not","servers_dat_nbt.root['servers']:\n","","","","","","","","","","","","servers_dat_nbt.root['servers']","=","List[Compound]()\n","","","","","","","","servers_dat_nbt.root['servers'].append(Compound({'ip':","String(\n","","","","","","","","","","","","new_ip),","'name':","String(server_name)}))\n","","","","","","","","print(\n","","","","","","","","","","","","f'","","\"{server_name}\"","entry","with","instance\\'s","IP","added","to","server","list.'\n","","","","","","","","","","","",")\n","","","","servers_dat_nbt.save(gzipped=False)\n"],"func_name":"ec2mc\/file:\/aws_setup_src\/ip_handlers\/mc_handler.py:function:update_servers_dat\/update_servers_dat","docstring":"update IP of server_name in server list with new_ip\n\nArgs:\n    servers_dat_path (str): File path for MC client's servers.dat.\n    server_name (str): Name of the server within client's server list.\n    new_ip (str): Instance's new IP to update client's server list with.","docstring_tokens":["update","IP","of","server_name","in","server","list","with","new_ip","Args",":","servers_dat_path","(","str",")",":","File","path","for","MC","client","'s","servers.dat",".","server_name","(","str",")",":","Name","of","the","server","within","client","'s","server","list",".","new_ip","(","str",")",":","Instance","'s","new","IP","to","update","client","'s","server","list","with","."],"summary":"update IP of server_name in server list with new_ip","code_with_docstring":"def update_servers_dat(servers_dat_path, server_name, new_ip):\n    \"\"\"update IP of server_name in server list with new_ip\n\n    Args:\n        servers_dat_path (str): File path for MC client's servers.dat.\n        server_name (str): Name of the server within client's server list.\n        new_ip (str): Instance's new IP to update client's server list with.\n    \"\"\"\n    servers_dat_nbt = load(servers_dat_path, gzipped=False)\n    for server_list_entry in servers_dat_nbt.root['servers']:\n        if server_name == server_list_entry['name']:\n            server_list_entry['ip'] = String(new_ip)\n            print(f'  IP for \"{server_name}\" entry in server list updated.')\n            break\n    else:\n        if not servers_dat_nbt.root['servers']:\n            servers_dat_nbt.root['servers'] = List[Compound]()\n        servers_dat_nbt.root['servers'].append(Compound({'ip': String(\n            new_ip), 'name': String(server_name)}))\n        print(\n            f'  \"{server_name}\" entry with instance\\'s IP added to server list.'\n            )\n    servers_dat_nbt.save(gzipped=False)\n","code_tokens_py":[]}
{"repo":"eric6","path":"eric6\/\/WebBrowser\/WebBrowserWindow.pyclass:WebBrowserWindow\/__cut","language":"python","sha":"b7b8e5d559c2f25a2664d5c05269e8b6fb1e66f0","url":"eric6\/\/WebBrowser\/WebBrowserWindow.pyclass:WebBrowserWindow\/__cut","partition":"test","code":"def __cut(self):\n    \n        \n        \"\"\"\n    self.currentBrowser().cut()\n","original_string":"def __cut(self):\n    \"\"\"\n        Private slot called to handle the cut action.\n        \"\"\"\n    self.currentBrowser().cut()\n","code_tokens":["def","__cut(self):\n","","","","\n","","","","","","","","\n","","","","","","","","\"\"\"\n","","","","self.currentBrowser().cut()\n"],"func_name":"eric6\/class:WebBrowserWindow\/__cut","docstring":"Private slot called to handle the cut action.","docstring_tokens":["Private","slot","called","to","handle","the","cut","action","."],"summary":"Private slot called to handle the cut action.","code_with_docstring":"def __cut(self):\n    \"\"\"\n        Private slot called to handle the cut action.\n        \"\"\"\n    self.currentBrowser().cut()\n","code_tokens_py":[]}
{"repo":"epifx","path":"epifx\/\/cmd\/scan.pyfile:\/cmd\/scan.py:function:main\/main","language":"python","sha":"8d6dcfa0374a000a00f5277aebca9a51b0a8bff0","url":"epifx\/\/cmd\/scan.pyfile:\/cmd\/scan.py:function:main\/main","partition":"test","code":"def main(args=None):\n    \"\"\"\n    p = parser()\n    if args is None:\n        args = vars(p.parse_args())\n    else:\n        args = vars(p.parse_args(args))\n    logging.basicConfig(level=args['loglevel'])\n    try:\n        valid_locns = settings.locations()\n    except settings.NoLocalSettings as e:\n        print(e)\n        return 2\n    if len(args['location']) == 0:\n        p.print_help()\n        return 2\n    else:\n        invalid = [l for l in args['location'] if l not in valid_locns]\n        if invalid:\n            msg = 'ERROR: invalid location(s): {}'.format(', '.join(invalid))\n            print(msg)\n            return 2\n    if args['sets'] == 1:\n        if args['subset'] is not None and args['subset'] != 1:\n            p.error('subset cannot exceed the number of sets')\n        elif args['subset'] is None:\n            args['subset'] = 1\n    elif args['sets'] < 1:\n        p.error('the number of sets must be positive')\n    elif args['subset'] is None:\n        p.error('the subset must be defined when there are multiple sets')\n    elif args['subset'] < 1:\n        p.error('the subset must be positive')\n    elif args['subset'] > args['sets']:\n        p.error('the subset cannot exceed the number of sets')\n    n_proc = args['spawn']\n    if n_proc < 1:\n        p.error('must use at least one process')\n    elif n_proc == 1:\n        for details in scan_iter(args):\n            run(*details)\n    else:\n        cmd.run_in_parallel(run, scan_iter(args), n_proc)\n","original_string":"def main(args=None):\n    \"\"\"Perform a scan of observation models over retrospective data.\"\"\"\n    p = parser()\n    if args is None:\n        args = vars(p.parse_args())\n    else:\n        args = vars(p.parse_args(args))\n    logging.basicConfig(level=args['loglevel'])\n    try:\n        valid_locns = settings.locations()\n    except settings.NoLocalSettings as e:\n        print(e)\n        return 2\n    if len(args['location']) == 0:\n        p.print_help()\n        return 2\n    else:\n        invalid = [l for l in args['location'] if l not in valid_locns]\n        if invalid:\n            msg = 'ERROR: invalid location(s): {}'.format(', '.join(invalid))\n            print(msg)\n            return 2\n    if args['sets'] == 1:\n        if args['subset'] is not None and args['subset'] != 1:\n            p.error('subset cannot exceed the number of sets')\n        elif args['subset'] is None:\n            args['subset'] = 1\n    elif args['sets'] < 1:\n        p.error('the number of sets must be positive')\n    elif args['subset'] is None:\n        p.error('the subset must be defined when there are multiple sets')\n    elif args['subset'] < 1:\n        p.error('the subset must be positive')\n    elif args['subset'] > args['sets']:\n        p.error('the subset cannot exceed the number of sets')\n    n_proc = args['spawn']\n    if n_proc < 1:\n        p.error('must use at least one process')\n    elif n_proc == 1:\n        for details in scan_iter(args):\n            run(*details)\n    else:\n        cmd.run_in_parallel(run, scan_iter(args), n_proc)\n","code_tokens":["def","main(args=None):\n","","","","\"\"\"\n","","","","p","=","parser()\n","","","","if","args","is","None:\n","","","","","","","","args","=","vars(p.parse_args())\n","","","","else:\n","","","","","","","","args","=","vars(p.parse_args(args))\n","","","","logging.basicConfig(level=args['loglevel'])\n","","","","try:\n","","","","","","","","valid_locns","=","settings.locations()\n","","","","except","settings.NoLocalSettings","as","e:\n","","","","","","","","print(e)\n","","","","","","","","return","2\n","","","","if","len(args['location'])","==","0:\n","","","","","","","","p.print_help()\n","","","","","","","","return","2\n","","","","else:\n","","","","","","","","invalid","=","[l","for","l","in","args['location']","if","l","not","in","valid_locns]\n","","","","","","","","if","invalid:\n","","","","","","","","","","","","msg","=","'ERROR:","invalid","location(s):","{}'.format(',","'.join(invalid))\n","","","","","","","","","","","","print(msg)\n","","","","","","","","","","","","return","2\n","","","","if","args['sets']","==","1:\n","","","","","","","","if","args['subset']","is","not","None","and","args['subset']","!=","1:\n","","","","","","","","","","","","p.error('subset","cannot","exceed","the","number","of","sets')\n","","","","","","","","elif","args['subset']","is","None:\n","","","","","","","","","","","","args['subset']","=","1\n","","","","elif","args['sets']","<","1:\n","","","","","","","","p.error('the","number","of","sets","must","be","positive')\n","","","","elif","args['subset']","is","None:\n","","","","","","","","p.error('the","subset","must","be","defined","when","there","are","multiple","sets')\n","","","","elif","args['subset']","<","1:\n","","","","","","","","p.error('the","subset","must","be","positive')\n","","","","elif","args['subset']",">","args['sets']:\n","","","","","","","","p.error('the","subset","cannot","exceed","the","number","of","sets')\n","","","","n_proc","=","args['spawn']\n","","","","if","n_proc","<","1:\n","","","","","","","","p.error('must","use","at","least","one","process')\n","","","","elif","n_proc","==","1:\n","","","","","","","","for","details","in","scan_iter(args):\n","","","","","","","","","","","","run(*details)\n","","","","else:\n","","","","","","","","cmd.run_in_parallel(run,","scan_iter(args),","n_proc)\n"],"func_name":"epifx\/file:\/cmd\/scan.py:function:main\/main","docstring":"Perform a scan of observation models over retrospective data.","docstring_tokens":["Perform","a","scan","of","observation","models","over","retrospective","data","."],"summary":"Perform a scan of observation models over retrospective data.","code_with_docstring":"def main(args=None):\n    \"\"\"Perform a scan of observation models over retrospective data.\"\"\"\n    p = parser()\n    if args is None:\n        args = vars(p.parse_args())\n    else:\n        args = vars(p.parse_args(args))\n    logging.basicConfig(level=args['loglevel'])\n    try:\n        valid_locns = settings.locations()\n    except settings.NoLocalSettings as e:\n        print(e)\n        return 2\n    if len(args['location']) == 0:\n        p.print_help()\n        return 2\n    else:\n        invalid = [l for l in args['location'] if l not in valid_locns]\n        if invalid:\n            msg = 'ERROR: invalid location(s): {}'.format(', '.join(invalid))\n            print(msg)\n            return 2\n    if args['sets'] == 1:\n        if args['subset'] is not None and args['subset'] != 1:\n            p.error('subset cannot exceed the number of sets')\n        elif args['subset'] is None:\n            args['subset'] = 1\n    elif args['sets'] < 1:\n        p.error('the number of sets must be positive')\n    elif args['subset'] is None:\n        p.error('the subset must be defined when there are multiple sets')\n    elif args['subset'] < 1:\n        p.error('the subset must be positive')\n    elif args['subset'] > args['sets']:\n        p.error('the subset cannot exceed the number of sets')\n    n_proc = args['spawn']\n    if n_proc < 1:\n        p.error('must use at least one process')\n    elif n_proc == 1:\n        for details in scan_iter(args):\n            run(*details)\n    else:\n        cmd.run_in_parallel(run, scan_iter(args), n_proc)\n","code_tokens_py":[]}
{"repo":"pyensae","path":"pyensae\/\/datasource\/convert.pyfile:\/datasource\/convert.py:function:dBase2df\/dBase2df","language":"python","sha":"4c8dd18f5ad583b47e367bdb97c5cb45e3e93bd2","url":"pyensae\/\/datasource\/convert.pyfile:\/datasource\/convert.py:function:dBase2df\/dBase2df","partition":"test","code":"def dBase2df(file, encoding='cp437'):\n    \n    converts a dBase file into a list of dataframe (one per table)\n\n    @param      file        file name\n    @param      encoding    table encoding\n    @return                 list of dataframes (pandas)\n\n    The module relies on `dbfread <https:\/\/pypi.python.org\/pypi\/dbfread\/>`_.\n    \"\"\"\n    import dbfread\n    table = dbfread.DBF(file, load=False, encoding=encoding)\n    res = list(table)\n    return pandas.DataFrame(res)\n","original_string":"def dBase2df(file, encoding='cp437'):\n    \"\"\"\n    converts a dBase file into a list of dataframe (one per table)\n\n    @param      file        file name\n    @param      encoding    table encoding\n    @return                 list of dataframes (pandas)\n\n    The module relies on `dbfread <https:\/\/pypi.python.org\/pypi\/dbfread\/>`_.\n    \"\"\"\n    import dbfread\n    table = dbfread.DBF(file, load=False, encoding=encoding)\n    res = list(table)\n    return pandas.DataFrame(res)\n","code_tokens":["def","dBase2df(file,","encoding='cp437'):\n","","","","\n","","","","converts","a","dBase","file","into","a","list","of","dataframe","(one","per","table)\n\n","","","","@param","","","","","","file","","","","","","","","file","name\n","","","","@param","","","","","","encoding","","","","table","encoding\n","","","","@return","","","","","","","","","","","","","","","","","list","of","dataframes","(pandas)\n\n","","","","The","module","relies","on","`dbfread","<https:\/\/pypi.python.org\/pypi\/dbfread\/>`_.\n","","","","\"\"\"\n","","","","import","dbfread\n","","","","table","=","dbfread.DBF(file,","load=False,","encoding=encoding)\n","","","","res","=","list(table)\n","","","","return","pandas.DataFrame(res)\n"],"func_name":"pyensae\/file:\/datasource\/convert.py:function:dBase2df\/dBase2df","docstring":"converts a dBase file into a list of dataframe (one per table)\n\n@param      file        file name\n@param      encoding    table encoding\n@return                 list of dataframes (pandas)\n\nThe module relies on `dbfread <https:\/\/pypi.python.org\/pypi\/dbfread\/>`_.","docstring_tokens":["converts","a","dBase","file","into","a","list","of","dataframe","(","one","per","table",")","@param","file","file","name","@param","encoding","table","encoding","@return","list","of","dataframes","(","pandas",")","The","module","relies","on","`","dbfread","<","https:\/\/pypi.python.org\/pypi\/dbfread\/",">","`","_","."],"summary":"converts a dBase file into a list of dataframe (one per table)","code_with_docstring":"def dBase2df(file, encoding='cp437'):\n    \"\"\"\n    converts a dBase file into a list of dataframe (one per table)\n\n    @param      file        file name\n    @param      encoding    table encoding\n    @return                 list of dataframes (pandas)\n\n    The module relies on `dbfread <https:\/\/pypi.python.org\/pypi\/dbfread\/>`_.\n    \"\"\"\n    import dbfread\n    table = dbfread.DBF(file, load=False, encoding=encoding)\n    res = list(table)\n    return pandas.DataFrame(res)\n","code_tokens_py":[]}
{"repo":"jubakit-0.6.2","path":"jubakit-0.6.2\/\/jubakit\/_cli\/service\/recommender.pyclass:RecommenderCLI\/do_complete_row_from_id","language":"python","sha":"7709a1c5f9128ed4f6c8d73fdd76835a8cddfdde","url":"jubakit-0.6.2\/\/jubakit\/_cli\/service\/recommender.pyclass:RecommenderCLI\/do_complete_row_from_id","partition":"test","code":"@Arguments(str)\ndef do_complete_row_from_id(self, row_id):\n    Syntax: complete_row_from_id id\n    Complete row from the given ID.\n    \"\"\"\n    d = self.client.complete_row_from_id(row_id)\n    print(d)\n","original_string":"@Arguments(str)\ndef do_complete_row_from_id(self, row_id):\n    \"\"\"Syntax: complete_row_from_id id\n    Complete row from the given ID.\n    \"\"\"\n    d = self.client.complete_row_from_id(row_id)\n    print(d)\n","code_tokens":["@Arguments(str)\ndef","do_complete_row_from_id(self,","row_id):\n","","","","Syntax:","complete_row_from_id","id\n","","","","Complete","row","from","the","given","ID.\n","","","","\"\"\"\n","","","","d","=","self.client.complete_row_from_id(row_id)\n","","","","print(d)\n"],"func_name":"jubakit-0.6.2\/class:RecommenderCLI\/do_complete_row_from_id","docstring":"Syntax: complete_row_from_id id\nComplete row from the given ID.","docstring_tokens":["Syntax",":","complete_row_from_id","i","d","Complete","row","from","the","given","ID","."],"summary":"Syntax: complete_row_from_id id","code_with_docstring":"@Arguments(str)\ndef do_complete_row_from_id(self, row_id):\n    \"\"\"Syntax: complete_row_from_id id\n    Complete row from the given ID.\n    \"\"\"\n    d = self.client.complete_row_from_id(row_id)\n    print(d)\n","code_tokens_py":[]}
{"repo":"raincloudy-0.0.7","path":"raincloudy-0.0.7\/\/raincloudy\/controller.pyclass:RainCloudyController\/faucet","language":"python","sha":"ac148d3108cf3d3988d96ff3a8e167a31444f2fd","url":"raincloudy-0.0.7\/\/raincloudy\/controller.pyclass:RainCloudyController\/faucet","partition":"test","code":"@property\ndef faucet(self):\n    \"\"\"\n    if hasattr(self, 'faucets'):\n        if len(self.faucets) > 1:\n            raise TypeError('Only one faucet per account.')\n        return self.faucets[0]\n    raise AttributeError('There is no faucet assigned.')\n","original_string":"@property\ndef faucet(self):\n    \"\"\"Show current linked faucet.\"\"\"\n    if hasattr(self, 'faucets'):\n        if len(self.faucets) > 1:\n            raise TypeError('Only one faucet per account.')\n        return self.faucets[0]\n    raise AttributeError('There is no faucet assigned.')\n","code_tokens":["@property\ndef","faucet(self):\n","","","","\"\"\"\n","","","","if","hasattr(self,","'faucets'):\n","","","","","","","","if","len(self.faucets)",">","1:\n","","","","","","","","","","","","raise","TypeError('Only","one","faucet","per","account.')\n","","","","","","","","return","self.faucets[0]\n","","","","raise","AttributeError('There","is","no","faucet","assigned.')\n"],"func_name":"raincloudy-0.0.7\/class:RainCloudyController\/faucet","docstring":"Show current linked faucet.","docstring_tokens":["Show","current","linked","faucet","."],"summary":"Show current linked faucet.","code_with_docstring":"@property\ndef faucet(self):\n    \"\"\"Show current linked faucet.\"\"\"\n    if hasattr(self, 'faucets'):\n        if len(self.faucets) > 1:\n            raise TypeError('Only one faucet per account.')\n        return self.faucets[0]\n    raise AttributeError('There is no faucet assigned.')\n","code_tokens_py":[]}
{"repo":"temboardagent","path":"temboardagent\/\/httpd.pyclass:RequestHandler\/do_POST","language":"python","sha":"9e27c707534311920d5ff59506ff829f8520e9bd","url":"temboardagent\/\/httpd.pyclass:RequestHandler\/do_POST","partition":"test","code":"def do_POST(self):\n    \n        \n        \"\"\"\n    self.http_method = 'POST'\n    self.response()\n","original_string":"def do_POST(self):\n    \"\"\"\n        Handle HTTP POST requests.\n        \"\"\"\n    self.http_method = 'POST'\n    self.response()\n","code_tokens":["def","do_POST(self):\n","","","","\n","","","","","","","","\n","","","","","","","","\"\"\"\n","","","","self.http_method","=","'POST'\n","","","","self.response()\n"],"func_name":"temboardagent\/class:RequestHandler\/do_POST","docstring":"Handle HTTP POST requests.","docstring_tokens":["Handle","HTTP","POST","requests","."],"summary":"Handle HTTP POST requests.","code_with_docstring":"def do_POST(self):\n    \"\"\"\n        Handle HTTP POST requests.\n        \"\"\"\n    self.http_method = 'POST'\n    self.response()\n","code_tokens_py":[]}
{"repo":"xyalign","path":"xyalign\/\/reftools.pyclass:RefFasta\/index_fai","language":"python","sha":"af8784d33e08742b4802ba8f35a8572dbe305f7e","url":"xyalign\/\/reftools.pyclass:RefFasta\/index_fai","partition":"test","code":"def index_fai(self):\n    \n\t\tCreate fai index for reference using samtools ('samtools faidx ref.fa')\n\n\t\tReturns\n\t\t-------\n\n\t\tbool\n\t\t\tTrue if successful\n\n\t\tRaises\n\t\t------\n\n\t\tRuntimeError\n\t\t\tIf return code from external call is not 0\n\n\t\t\"\"\"\n    self.logger.info('Creating fai index for: {}'.format(self.filepath))\n    idx_start = time.time()\n    rc = subprocess.call([self.samtools, 'faidx', self.filepath])\n    if rc == 0:\n        self.logger.info('Fai indexing complete. Elapsed time: {} seconds'.\n            format(time.time() - idx_start))\n        return True\n    else:\n        self.logger.error('Unable to create fai index for {}. Exiting'.\n            format(self.filepath))\n        logging.shutdown()\n        raise RuntimeError('Unable to create faidx. Exiting')\n","original_string":"def index_fai(self):\n    \"\"\"\n\t\tCreate fai index for reference using samtools ('samtools faidx ref.fa')\n\n\t\tReturns\n\t\t-------\n\n\t\tbool\n\t\t\tTrue if successful\n\n\t\tRaises\n\t\t------\n\n\t\tRuntimeError\n\t\t\tIf return code from external call is not 0\n\n\t\t\"\"\"\n    self.logger.info('Creating fai index for: {}'.format(self.filepath))\n    idx_start = time.time()\n    rc = subprocess.call([self.samtools, 'faidx', self.filepath])\n    if rc == 0:\n        self.logger.info('Fai indexing complete. Elapsed time: {} seconds'.\n            format(time.time() - idx_start))\n        return True\n    else:\n        self.logger.error('Unable to create fai index for {}. Exiting'.\n            format(self.filepath))\n        logging.shutdown()\n        raise RuntimeError('Unable to create faidx. Exiting')\n","code_tokens":["def","index_fai(self):\n","","","","\n\t\tCreate","fai","index","for","reference","using","samtools","('samtools","faidx","ref.fa')\n\n\t\tReturns\n\t\t-------\n\n\t\tbool\n\t\t\tTrue","if","successful\n\n\t\tRaises\n\t\t------\n\n\t\tRuntimeError\n\t\t\tIf","return","code","from","external","call","is","not","0\n\n\t\t\"\"\"\n","","","","self.logger.info('Creating","fai","index","for:","{}'.format(self.filepath))\n","","","","idx_start","=","time.time()\n","","","","rc","=","subprocess.call([self.samtools,","'faidx',","self.filepath])\n","","","","if","rc","==","0:\n","","","","","","","","self.logger.info('Fai","indexing","complete.","Elapsed","time:","{}","seconds'.\n","","","","","","","","","","","","format(time.time()","-","idx_start))\n","","","","","","","","return","True\n","","","","else:\n","","","","","","","","self.logger.error('Unable","to","create","fai","index","for","{}.","Exiting'.\n","","","","","","","","","","","","format(self.filepath))\n","","","","","","","","logging.shutdown()\n","","","","","","","","raise","RuntimeError('Unable","to","create","faidx.","Exiting')\n"],"func_name":"xyalign\/class:RefFasta\/index_fai","docstring":"Create fai index for reference using samtools ('samtools faidx ref.fa')\n\nReturns\n-------\n\nbool\n        True if successful\n\nRaises\n------\n\nRuntimeError\n        If return code from external call is not 0","docstring_tokens":["Create","fai","index","for","reference","using","samtools","(","'","samtools","faidx","ref.fa","'",")","Returns","-------","bool","True","if","successful","Raises","------","RuntimeError","If","return","code","from","external","call","is","not","0"],"summary":"Create fai index for reference using samtools ('samtools faidx ref.fa')","code_with_docstring":"def index_fai(self):\n    \"\"\"\n\t\tCreate fai index for reference using samtools ('samtools faidx ref.fa')\n\n\t\tReturns\n\t\t-------\n\n\t\tbool\n\t\t\tTrue if successful\n\n\t\tRaises\n\t\t------\n\n\t\tRuntimeError\n\t\t\tIf return code from external call is not 0\n\n\t\t\"\"\"\n    self.logger.info('Creating fai index for: {}'.format(self.filepath))\n    idx_start = time.time()\n    rc = subprocess.call([self.samtools, 'faidx', self.filepath])\n    if rc == 0:\n        self.logger.info('Fai indexing complete. Elapsed time: {} seconds'.\n            format(time.time() - idx_start))\n        return True\n    else:\n        self.logger.error('Unable to create fai index for {}. Exiting'.\n            format(self.filepath))\n        logging.shutdown()\n        raise RuntimeError('Unable to create faidx. Exiting')\n","code_tokens_py":[]}
{"repo":"lib5c","path":"lib5c\/\/core\/interactions.pyclass:InteractionMatrix\/flatten","language":"python","sha":"0800a7100c3d68262aa269833f49e41ac832315a","url":"lib5c\/\/core\/interactions.pyclass:InteractionMatrix\/flatten","partition":"test","code":"def flatten(self, discard_nan=True):\n    \n        Flattens the interaction values in this InteractionMatrix into a flat,\n        non-redundant array.\n\n        Parameters\n        ----------\n        discard_nan : bool, optional\n            If True, nan's will not be filtered out of the returned array.\n\n        Returns\n        -------\n        1d numpy array\n            A flat, nonredundant array of the interaction values. The\n            :math:`(i, j)` th element of this InteractionMatrix's ``matrix``\n            attribute (for :math:`i >= j` ) ends up at the\n            :math:`(i\\\\times(i+1)\/2 + j)` th index of the flattened array. If\n            ``discard_nan`` was True, these indices will not necessarily match\n            up and it will not be possible to unflatten the array.\n\n        Notes\n        -----\n        A more intuitive way to think about the ordering is to read down the\n        columns of ``matrix`` from left to right, going to the next column\n        whenever you reach the diagonal.\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> from lib5c.core.interactions import InteractionMatrix\n        >>> im = InteractionMatrix(np.matrix([[   3.0, np.nan,    5.0],\n        ...                                   [np.nan,    6.0, np.nan],\n        ...                                   [   5.0, np.nan,    8.0]]))\n        ...\n        >>> im.flatten()\n        array([3., 6., 5., 8.])\n        >>> im.flatten(discard_nan=False)\n        array([  3.,  nan,   6.,   5.,  nan,   8.])\n        \"\"\"\n    return flatten_regional_counts(np.asarray(self.matrix), discard_nan=\n        discard_nan)\n","original_string":"def flatten(self, discard_nan=True):\n    \"\"\"\n        Flattens the interaction values in this InteractionMatrix into a flat,\n        non-redundant array.\n\n        Parameters\n        ----------\n        discard_nan : bool, optional\n            If True, nan's will not be filtered out of the returned array.\n\n        Returns\n        -------\n        1d numpy array\n            A flat, nonredundant array of the interaction values. The\n            :math:`(i, j)` th element of this InteractionMatrix's ``matrix``\n            attribute (for :math:`i >= j` ) ends up at the\n            :math:`(i\\\\times(i+1)\/2 + j)` th index of the flattened array. If\n            ``discard_nan`` was True, these indices will not necessarily match\n            up and it will not be possible to unflatten the array.\n\n        Notes\n        -----\n        A more intuitive way to think about the ordering is to read down the\n        columns of ``matrix`` from left to right, going to the next column\n        whenever you reach the diagonal.\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> from lib5c.core.interactions import InteractionMatrix\n        >>> im = InteractionMatrix(np.matrix([[   3.0, np.nan,    5.0],\n        ...                                   [np.nan,    6.0, np.nan],\n        ...                                   [   5.0, np.nan,    8.0]]))\n        ...\n        >>> im.flatten()\n        array([3., 6., 5., 8.])\n        >>> im.flatten(discard_nan=False)\n        array([  3.,  nan,   6.,   5.,  nan,   8.])\n        \"\"\"\n    return flatten_regional_counts(np.asarray(self.matrix), discard_nan=\n        discard_nan)\n","code_tokens":["def","flatten(self,","discard_nan=True):\n","","","","\n","","","","","","","","Flattens","the","interaction","values","in","this","InteractionMatrix","into","a","flat,\n","","","","","","","","non-redundant","array.\n\n","","","","","","","","Parameters\n","","","","","","","","----------\n","","","","","","","","discard_nan",":","bool,","optional\n","","","","","","","","","","","","If","True,","nan's","will","not","be","filtered","out","of","the","returned","array.\n\n","","","","","","","","Returns\n","","","","","","","","-------\n","","","","","","","","1d","numpy","array\n","","","","","","","","","","","","A","flat,","nonredundant","array","of","the","interaction","values.","The\n","","","","","","","","","","","",":math:`(i,","j)`","th","element","of","this","InteractionMatrix's","``matrix``\n","","","","","","","","","","","","attribute","(for",":math:`i",">=","j`",")","ends","up","at","the\n","","","","","","","","","","","",":math:`(i\\\\times(i+1)\/2","+","j)`","th","index","of","the","flattened","array.","If\n","","","","","","","","","","","","``discard_nan``","was","True,","these","indices","will","not","necessarily","match\n","","","","","","","","","","","","up","and","it","will","not","be","possible","to","unflatten","the","array.\n\n","","","","","","","","Notes\n","","","","","","","","-----\n","","","","","","","","A","more","intuitive","way","to","think","about","the","ordering","is","to","read","down","the\n","","","","","","","","columns","of","``matrix``","from","left","to","right,","going","to","the","next","column\n","","","","","","","","whenever","you","reach","the","diagonal.\n\n","","","","","","","","Examples\n","","","","","","","","--------\n","","","","","","","",">>>","import","numpy","as","np\n","","","","","","","",">>>","from","lib5c.core.interactions","import","InteractionMatrix\n","","","","","","","",">>>","im","=","InteractionMatrix(np.matrix([[","","","3.0,","np.nan,","","","","5.0],\n","","","","","","","","...","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","[np.nan,","","","","6.0,","np.nan],\n","","","","","","","","...","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","[","","","5.0,","np.nan,","","","","8.0]]))\n","","","","","","","","...\n","","","","","","","",">>>","im.flatten()\n","","","","","","","","array([3.,","6.,","5.,","8.])\n","","","","","","","",">>>","im.flatten(discard_nan=False)\n","","","","","","","","array([","","3.,","","nan,","","","6.,","","","5.,","","nan,","","","8.])\n","","","","","","","","\"\"\"\n","","","","return","flatten_regional_counts(np.asarray(self.matrix),","discard_nan=\n","","","","","","","","discard_nan)\n"],"func_name":"lib5c\/class:InteractionMatrix\/flatten","docstring":"Flattens the interaction values in this InteractionMatrix into a flat,\nnon-redundant array.\n\nParameters\n----------\ndiscard_nan : bool, optional\n    If True, nan's will not be filtered out of the returned array.\n\nReturns\n-------\n1d numpy array\n    A flat, nonredundant array of the interaction values. The\n    :math:`(i, j)` th element of this InteractionMatrix's ``matrix``\n    attribute (for :math:`i >= j` ) ends up at the\n    :math:`(i\\times(i+1)\/2 + j)` th index of the flattened array. If\n    ``discard_nan`` was True, these indices will not necessarily match\n    up and it will not be possible to unflatten the array.\n\nNotes\n-----\nA more intuitive way to think about the ordering is to read down the\ncolumns of ``matrix`` from left to right, going to the next column\nwhenever you reach the diagonal.\n\nExamples\n--------\n>>> import numpy as np\n>>> from lib5c.core.interactions import InteractionMatrix\n>>> im = InteractionMatrix(np.matrix([[   3.0, np.nan,    5.0],\n...                                   [np.nan,    6.0, np.nan],\n...                                   [   5.0, np.nan,    8.0]]))\n...\n>>> im.flatten()\narray([3., 6., 5., 8.])\n>>> im.flatten(discard_nan=False)\narray([  3.,  nan,   6.,   5.,  nan,   8.])","docstring_tokens":["Flattens","the","interaction","values","in","this","InteractionMatrix","into","a","flat",",","non","-","redundant","array",".","Parameters","----------","discard_nan",":","bool",",","optional","If","True",",","nan","'s","will","not","be","filtered","out","of","the","returned","array",".","Returns","-------","1d","numpy","array","A","flat",",","nonredundant","array","of","the","interaction","values",".","The",":","math:`(i",",","j",")","`","th","element","of","this","InteractionMatrix","'s","`","`","matrix","`","`","attribute","(","for",":","math:`i",">","=","j","`",")","ends","up","at","the",":","math:`(i\\times(i+1)\/2","+","j",")","`","th","index","of","the","flattened","array",".","If","`","`","discard_nan","`","`","was","True",",","these","indices","will","not","necessarily","match","up","and","it","will","not","be","possible","to","unflatten","the","array",".","Notes","-----","A","more","intuitive","way","to","think","about","the","ordering","is","to","read","down","the","columns","of","`","`","matrix","`","`","from","left","to","right",",","going","to","the","next","column","whenever","you","reach","the","diagonal",".","Examples","--------",">",">",">","import","numpy","as","np",">",">",">","from","lib5c.core.interactions","import","InteractionMatrix",">",">",">","i","m","=","InteractionMatrix(np.matrix","(","[","[","3.0",",","np.nan",",","5.0","]",",","...","[","np.nan",",","6.0",",","np.nan","]",",","...","[","5.0",",","np.nan",",","8.0","]","]",")",")","...",">",">",">","im.flatten","(",")","array([3",".",",","6",".",",","5",".",",","8",".","]",")",">",">",">","im.flatten(discard_nan","=","False",")","array","(","[","3",".",",","nan",",","6",".",",","5",".",",","nan",",","8",".","]",")"],"summary":"Flattens the interaction values in this InteractionMatrix into a flat,","code_with_docstring":"def flatten(self, discard_nan=True):\n    \"\"\"\n        Flattens the interaction values in this InteractionMatrix into a flat,\n        non-redundant array.\n\n        Parameters\n        ----------\n        discard_nan : bool, optional\n            If True, nan's will not be filtered out of the returned array.\n\n        Returns\n        -------\n        1d numpy array\n            A flat, nonredundant array of the interaction values. The\n            :math:`(i, j)` th element of this InteractionMatrix's ``matrix``\n            attribute (for :math:`i >= j` ) ends up at the\n            :math:`(i\\\\times(i+1)\/2 + j)` th index of the flattened array. If\n            ``discard_nan`` was True, these indices will not necessarily match\n            up and it will not be possible to unflatten the array.\n\n        Notes\n        -----\n        A more intuitive way to think about the ordering is to read down the\n        columns of ``matrix`` from left to right, going to the next column\n        whenever you reach the diagonal.\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> from lib5c.core.interactions import InteractionMatrix\n        >>> im = InteractionMatrix(np.matrix([[   3.0, np.nan,    5.0],\n        ...                                   [np.nan,    6.0, np.nan],\n        ...                                   [   5.0, np.nan,    8.0]]))\n        ...\n        >>> im.flatten()\n        array([3., 6., 5., 8.])\n        >>> im.flatten(discard_nan=False)\n        array([  3.,  nan,   6.,   5.,  nan,   8.])\n        \"\"\"\n    return flatten_regional_counts(np.asarray(self.matrix), discard_nan=\n        discard_nan)\n","code_tokens_py":[]}
{"repo":"ga4gh_client-0.0.5","path":"ga4gh_client-0.0.5\/\/ga4gh\/client\/client.pyclass:AbstractClient\/get_reference_set","language":"python","sha":"84d951ae5a802b840dd7f9011dd74a92ed0b74d0","url":"ga4gh_client-0.0.5\/\/ga4gh\/client\/client.pyclass:AbstractClient\/get_reference_set","partition":"test","code":"def get_reference_set(self, reference_set_id):\n    \n        Returns the ReferenceSet with the specified ID from the server.\n\n        :param str reference_set_id: The ID of the ReferenceSet of interest.\n        :return: The ReferenceSet of interest.\n        :rtype: :class:`ga4gh.protocol.ReferenceSet`\n        \"\"\"\n    return self._run_get_request('referencesets', protocol.ReferenceSet,\n        reference_set_id)\n","original_string":"def get_reference_set(self, reference_set_id):\n    \"\"\"\n        Returns the ReferenceSet with the specified ID from the server.\n\n        :param str reference_set_id: The ID of the ReferenceSet of interest.\n        :return: The ReferenceSet of interest.\n        :rtype: :class:`ga4gh.protocol.ReferenceSet`\n        \"\"\"\n    return self._run_get_request('referencesets', protocol.ReferenceSet,\n        reference_set_id)\n","code_tokens":["def","get_reference_set(self,","reference_set_id):\n","","","","\n","","","","","","","","Returns","the","ReferenceSet","with","the","specified","ID","from","the","server.\n\n","","","","","","","",":param","str","reference_set_id:","The","ID","of","the","ReferenceSet","of","interest.\n","","","","","","","",":return:","The","ReferenceSet","of","interest.\n","","","","","","","",":rtype:",":class:`ga4gh.protocol.ReferenceSet`\n","","","","","","","","\"\"\"\n","","","","return","self._run_get_request('referencesets',","protocol.ReferenceSet,\n","","","","","","","","reference_set_id)\n"],"func_name":"ga4gh_client-0.0.5\/class:AbstractClient\/get_reference_set","docstring":"Returns the ReferenceSet with the specified ID from the server.\n\n:param str reference_set_id: The ID of the ReferenceSet of interest.\n:return: The ReferenceSet of interest.\n:rtype: :class:`ga4gh.protocol.ReferenceSet`","docstring_tokens":["Returns","the","ReferenceSet","with","the","specified","ID","from","the","server",".",":","param","str","reference_set_id",":","The","ID","of","the","ReferenceSet","of","interest",".",":","return",":","The","ReferenceSet","of","interest",".",":","rtype",":",":","class:`ga4gh.protocol",".","ReferenceSet","`"],"summary":"Returns the ReferenceSet with the specified ID from the server.","code_with_docstring":"def get_reference_set(self, reference_set_id):\n    \"\"\"\n        Returns the ReferenceSet with the specified ID from the server.\n\n        :param str reference_set_id: The ID of the ReferenceSet of interest.\n        :return: The ReferenceSet of interest.\n        :rtype: :class:`ga4gh.protocol.ReferenceSet`\n        \"\"\"\n    return self._run_get_request('referencesets', protocol.ReferenceSet,\n        reference_set_id)\n","code_tokens_py":[]}
{"repo":"django-url-robots-2.0","path":"django-url-robots-2.0\/\/url_robots\/utils.pyfile:\/url_robots\/utils.py:function:create_rule_list\/create_rule_list","language":"python","sha":"678970d43c68f1d7154562ddfcd4fa66d30f8b0d","url":"django-url-robots-2.0\/\/url_robots\/utils.pyfile:\/url_robots\/utils.py:function:create_rule_list\/create_rule_list","partition":"test","code":"def create_rule_list(parent_resolver, abs_pattern):\n    \n    \n    \"\"\"\n    rule_list = []\n    for resolver in parent_resolver.url_patterns:\n        pattern = join_patterns(abs_pattern, resolver.regex.pattern)\n        rule = ''\n        robots_allow = getattr(resolver, 'robots_allow', None)\n        if robots_allow is None:\n            pass\n        elif robots_allow:\n            rule = 'Allow: '\n        else:\n            rule = 'Disallow: '\n        if rule:\n            path = clean_pattern(pattern)\n            rule += path\n            rule_list.append(rule)\n        if isinstance(resolver, RegexURLResolver):\n            rule_list += create_rule_list(resolver, pattern)\n    return rule_list\n","original_string":"def create_rule_list(parent_resolver, abs_pattern):\n    \"\"\"\n    Creates usable rule list\n    \"\"\"\n    rule_list = []\n    for resolver in parent_resolver.url_patterns:\n        pattern = join_patterns(abs_pattern, resolver.regex.pattern)\n        rule = ''\n        robots_allow = getattr(resolver, 'robots_allow', None)\n        if robots_allow is None:\n            pass\n        elif robots_allow:\n            rule = 'Allow: '\n        else:\n            rule = 'Disallow: '\n        if rule:\n            path = clean_pattern(pattern)\n            rule += path\n            rule_list.append(rule)\n        if isinstance(resolver, RegexURLResolver):\n            rule_list += create_rule_list(resolver, pattern)\n    return rule_list\n","code_tokens":["def","create_rule_list(parent_resolver,","abs_pattern):\n","","","","\n","","","","\n","","","","\"\"\"\n","","","","rule_list","=","[]\n","","","","for","resolver","in","parent_resolver.url_patterns:\n","","","","","","","","pattern","=","join_patterns(abs_pattern,","resolver.regex.pattern)\n","","","","","","","","rule","=","''\n","","","","","","","","robots_allow","=","getattr(resolver,","'robots_allow',","None)\n","","","","","","","","if","robots_allow","is","None:\n","","","","","","","","","","","","pass\n","","","","","","","","elif","robots_allow:\n","","","","","","","","","","","","rule","=","'Allow:","'\n","","","","","","","","else:\n","","","","","","","","","","","","rule","=","'Disallow:","'\n","","","","","","","","if","rule:\n","","","","","","","","","","","","path","=","clean_pattern(pattern)\n","","","","","","","","","","","","rule","+=","path\n","","","","","","","","","","","","rule_list.append(rule)\n","","","","","","","","if","isinstance(resolver,","RegexURLResolver):\n","","","","","","","","","","","","rule_list","+=","create_rule_list(resolver,","pattern)\n","","","","return","rule_list\n"],"func_name":"django-url-robots-2.0\/file:\/url_robots\/utils.py:function:create_rule_list\/create_rule_list","docstring":"Creates usable rule list","docstring_tokens":["Creates","usable","rule","list"],"summary":"Creates usable rule list","code_with_docstring":"def create_rule_list(parent_resolver, abs_pattern):\n    \"\"\"\n    Creates usable rule list\n    \"\"\"\n    rule_list = []\n    for resolver in parent_resolver.url_patterns:\n        pattern = join_patterns(abs_pattern, resolver.regex.pattern)\n        rule = ''\n        robots_allow = getattr(resolver, 'robots_allow', None)\n        if robots_allow is None:\n            pass\n        elif robots_allow:\n            rule = 'Allow: '\n        else:\n            rule = 'Disallow: '\n        if rule:\n            path = clean_pattern(pattern)\n            rule += path\n            rule_list.append(rule)\n        if isinstance(resolver, RegexURLResolver):\n            rule_list += create_rule_list(resolver, pattern)\n    return rule_list\n","code_tokens_py":[]}
{"repo":"gdalhelpers-0.1.7","path":"gdalhelpers-0.1.7\/\/gdalhelpers\/checks\/geometry_checks.pyfile:\/gdalhelpers\/checks\/geometry_checks.py:function:check_is_wkt_geometry\/check_is_wkt_geometry","language":"python","sha":"351e04ea4709ae4303f32a0fcba9c1f3d816d374","url":"gdalhelpers-0.1.7\/\/gdalhelpers\/checks\/geometry_checks.pyfile:\/gdalhelpers\/checks\/geometry_checks.py:function:check_is_wkt_geometry\/check_is_wkt_geometry","partition":"test","code":"def check_is_wkt_geometry(string: str, variable_name: str) ->None:\n    \n    Checks if the provided `string` is a valid WKT. Raises `TypeError` otherwise.\n\n    Parameters\n    ----------\n    string : str\n        String to check if it is WKT.\n\n    variable_name : str\n        Variable name for error message.\n\n    Returns\n    -------\n    None\n\n    Raises\n    ------\n    ValueError\n        If `string` is not valid WKT.\n    \"\"\"\n    if ogr.CreateGeometryFromWkt(string) is None:\n        raise ValueError(\n            '`{0}` is not a valid WKT. `{1}` cannot be loaded as geometry.'\n            .format(variable_name, string))\n","original_string":"def check_is_wkt_geometry(string: str, variable_name: str) ->None:\n    \"\"\"\n    Checks if the provided `string` is a valid WKT. Raises `TypeError` otherwise.\n\n    Parameters\n    ----------\n    string : str\n        String to check if it is WKT.\n\n    variable_name : str\n        Variable name for error message.\n\n    Returns\n    -------\n    None\n\n    Raises\n    ------\n    ValueError\n        If `string` is not valid WKT.\n    \"\"\"\n    if ogr.CreateGeometryFromWkt(string) is None:\n        raise ValueError(\n            '`{0}` is not a valid WKT. `{1}` cannot be loaded as geometry.'\n            .format(variable_name, string))\n","code_tokens":["def","check_is_wkt_geometry(string:","str,","variable_name:","str)","->None:\n","","","","\n","","","","Checks","if","the","provided","`string`","is","a","valid","WKT.","Raises","`TypeError`","otherwise.\n\n","","","","Parameters\n","","","","----------\n","","","","string",":","str\n","","","","","","","","String","to","check","if","it","is","WKT.\n\n","","","","variable_name",":","str\n","","","","","","","","Variable","name","for","error","message.\n\n","","","","Returns\n","","","","-------\n","","","","None\n\n","","","","Raises\n","","","","------\n","","","","ValueError\n","","","","","","","","If","`string`","is","not","valid","WKT.\n","","","","\"\"\"\n","","","","if","ogr.CreateGeometryFromWkt(string)","is","None:\n","","","","","","","","raise","ValueError(\n","","","","","","","","","","","","'`{0}`","is","not","a","valid","WKT.","`{1}`","cannot","be","loaded","as","geometry.'\n","","","","","","","","","","","",".format(variable_name,","string))\n"],"func_name":"gdalhelpers-0.1.7\/file:\/gdalhelpers\/checks\/geometry_checks.py:function:check_is_wkt_geometry\/check_is_wkt_geometry","docstring":"Checks if the provided `string` is a valid WKT. Raises `TypeError` otherwise.\n\nParameters\n----------\nstring : str\n    String to check if it is WKT.\n\nvariable_name : str\n    Variable name for error message.\n\nReturns\n-------\nNone\n\nRaises\n------\nValueError\n    If `string` is not valid WKT.","docstring_tokens":["Checks","if","the","provided","`","string","`","is","a","valid","WKT",".","Raises","`","TypeError","`","otherwise",".","Parameters","----------","string",":","str","String","to","check","if","it","is","WKT",".","variable_name",":","str","Variable","name","for","error","message",".","Returns","-------","None","Raises","------","ValueError","If","`","string","`","is","not","valid","WKT","."],"summary":"Checks if the provided `string` is a valid WKT. Raises `TypeError` otherwise.","code_with_docstring":"def check_is_wkt_geometry(string: str, variable_name: str) ->None:\n    \"\"\"\n    Checks if the provided `string` is a valid WKT. Raises `TypeError` otherwise.\n\n    Parameters\n    ----------\n    string : str\n        String to check if it is WKT.\n\n    variable_name : str\n        Variable name for error message.\n\n    Returns\n    -------\n    None\n\n    Raises\n    ------\n    ValueError\n        If `string` is not valid WKT.\n    \"\"\"\n    if ogr.CreateGeometryFromWkt(string) is None:\n        raise ValueError(\n            '`{0}` is not a valid WKT. `{1}` cannot be loaded as geometry.'\n            .format(variable_name, string))\n","code_tokens_py":[]}
{"repo":"datadog_checks","path":"datadog_checks\/\/dev\/tooling\/config_validator\/validator.pyfile:\/dev\/tooling\/config_validator\/validator.py:function:_parse_init_config\/_parse_init_config","language":"python","sha":"d3a2e7616799d60b48ffc7daec5cbc412f1d73df","url":"datadog_checks\/\/dev\/tooling\/config_validator\/validator.pyfile:\/dev\/tooling\/config_validator\/validator.py:function:_parse_init_config\/_parse_init_config","partition":"test","code":"def _parse_init_config(config_lines, init_config_start_line, errors):\n    Function used to parse the init_config section and return the list of 'ConfigBlock'\n    It first checks if the section contains data or not. If not, it returns an empty list. Otherwise\n    it will use the _parse_for_config_blocks function to parse it between the beginning and the end of the part\n    \"\"\"\n    blocks = []\n    idx = init_config_start_line + 1\n    while idx < len(config_lines):\n        current_line = config_lines[idx]\n        if is_blank(current_line):\n            idx += 1\n            continue\n        elif is_at_least_indented(current_line, 1):\n            break\n        else:\n            return blocks\n    end = get_end_of_part(config_lines, init_config_start_line)\n    if end is None:\n        errors.append(ValidatorError(\n            \"Malformed file, cannot find end of part 'init_config'\",\n            init_config_start_line))\n        return blocks\n    return _parse_for_config_blocks(config_lines, init_config_start_line + \n        1, end, errors)\n","original_string":"def _parse_init_config(config_lines, init_config_start_line, errors):\n    \"\"\"Function used to parse the init_config section and return the list of 'ConfigBlock'\n    It first checks if the section contains data or not. If not, it returns an empty list. Otherwise\n    it will use the _parse_for_config_blocks function to parse it between the beginning and the end of the part\n    \"\"\"\n    blocks = []\n    idx = init_config_start_line + 1\n    while idx < len(config_lines):\n        current_line = config_lines[idx]\n        if is_blank(current_line):\n            idx += 1\n            continue\n        elif is_at_least_indented(current_line, 1):\n            break\n        else:\n            return blocks\n    end = get_end_of_part(config_lines, init_config_start_line)\n    if end is None:\n        errors.append(ValidatorError(\n            \"Malformed file, cannot find end of part 'init_config'\",\n            init_config_start_line))\n        return blocks\n    return _parse_for_config_blocks(config_lines, init_config_start_line + \n        1, end, errors)\n","code_tokens":["def","_parse_init_config(config_lines,","init_config_start_line,","errors):\n","","","","Function","used","to","parse","the","init_config","section","and","return","the","list","of","'ConfigBlock'\n","","","","It","first","checks","if","the","section","contains","data","or","not.","If","not,","it","returns","an","empty","list.","Otherwise\n","","","","it","will","use","the","_parse_for_config_blocks","function","to","parse","it","between","the","beginning","and","the","end","of","the","part\n","","","","\"\"\"\n","","","","blocks","=","[]\n","","","","idx","=","init_config_start_line","+","1\n","","","","while","idx","<","len(config_lines):\n","","","","","","","","current_line","=","config_lines[idx]\n","","","","","","","","if","is_blank(current_line):\n","","","","","","","","","","","","idx","+=","1\n","","","","","","","","","","","","continue\n","","","","","","","","elif","is_at_least_indented(current_line,","1):\n","","","","","","","","","","","","break\n","","","","","","","","else:\n","","","","","","","","","","","","return","blocks\n","","","","end","=","get_end_of_part(config_lines,","init_config_start_line)\n","","","","if","end","is","None:\n","","","","","","","","errors.append(ValidatorError(\n","","","","","","","","","","","","\"Malformed","file,","cannot","find","end","of","part","'init_config'\",\n","","","","","","","","","","","","init_config_start_line))\n","","","","","","","","return","blocks\n","","","","return","_parse_for_config_blocks(config_lines,","init_config_start_line","+","\n","","","","","","","","1,","end,","errors)\n"],"func_name":"datadog_checks\/file:\/dev\/tooling\/config_validator\/validator.py:function:_parse_init_config\/_parse_init_config","docstring":"Function used to parse the init_config section and return the list of 'ConfigBlock'\nIt first checks if the section contains data or not. If not, it returns an empty list. Otherwise\nit will use the _parse_for_config_blocks function to parse it between the beginning and the end of the part","docstring_tokens":["Function","used","to","parse","the","init_config","section","and","return","the","list","of","'","ConfigBlock","'","It","first","checks","if","the","section","contains","data","or","not",".","If","not",",","it","returns","an","empty","list",".","Otherwise","it","will","use","the","_","parse_for_config_blocks","function","to","parse","it","between","the","beginning","and","the","end","of","the","part"],"summary":"Function used to parse the init_config section and return the list of 'ConfigBlock'","code_with_docstring":"def _parse_init_config(config_lines, init_config_start_line, errors):\n    \"\"\"Function used to parse the init_config section and return the list of 'ConfigBlock'\n    It first checks if the section contains data or not. If not, it returns an empty list. Otherwise\n    it will use the _parse_for_config_blocks function to parse it between the beginning and the end of the part\n    \"\"\"\n    blocks = []\n    idx = init_config_start_line + 1\n    while idx < len(config_lines):\n        current_line = config_lines[idx]\n        if is_blank(current_line):\n            idx += 1\n            continue\n        elif is_at_least_indented(current_line, 1):\n            break\n        else:\n            return blocks\n    end = get_end_of_part(config_lines, init_config_start_line)\n    if end is None:\n        errors.append(ValidatorError(\n            \"Malformed file, cannot find end of part 'init_config'\",\n            init_config_start_line))\n        return blocks\n    return _parse_for_config_blocks(config_lines, init_config_start_line + \n        1, end, errors)\n","code_tokens_py":[]}
{"repo":"eric-ide-20.5","path":"eric-ide-20.5\/\/eric6\/Plugins\/VcsPlugins\/vcsGit\/ProjectHelper.pyclass:GitProjectHelper\/__gitDeleteBranch","language":"python","sha":"2440250e3fe125e7f41f69bc30bc51d6140f5989","url":"eric-ide-20.5\/\/eric6\/Plugins\/VcsPlugins\/vcsGit\/ProjectHelper.pyclass:GitProjectHelper\/__gitDeleteBranch","partition":"test","code":"def __gitDeleteBranch(self):\n    \n        \n        \"\"\"\n    self.vcs.gitDeleteRemoteBranch(self.project.getProjectPath())\n","original_string":"def __gitDeleteBranch(self):\n    \"\"\"\n        Private slot used to delete a branch from a remote repository.\n        \"\"\"\n    self.vcs.gitDeleteRemoteBranch(self.project.getProjectPath())\n","code_tokens":["def","__gitDeleteBranch(self):\n","","","","\n","","","","","","","","\n","","","","","","","","\"\"\"\n","","","","self.vcs.gitDeleteRemoteBranch(self.project.getProjectPath())\n"],"func_name":"eric-ide-20.5\/class:GitProjectHelper\/__gitDeleteBranch","docstring":"Private slot used to delete a branch from a remote repository.","docstring_tokens":["Private","slot","used","to","delete","a","branch","from","a","remote","repository","."],"summary":"Private slot used to delete a branch from a remote repository.","code_with_docstring":"def __gitDeleteBranch(self):\n    \"\"\"\n        Private slot used to delete a branch from a remote repository.\n        \"\"\"\n    self.vcs.gitDeleteRemoteBranch(self.project.getProjectPath())\n","code_tokens_py":[]}
{"repo":"qmk-0.0.34","path":"qmk-0.0.34\/\/qmk_cli\/script_qmk.pyfile:\/qmk_cli\/script_qmk.py:function:find_qmk_firmware\/find_qmk_firmware","language":"python","sha":"43bff2745ce3a9049af41ff46c186d3a95d11135","url":"qmk-0.0.34\/\/qmk_cli\/script_qmk.pyfile:\/qmk_cli\/script_qmk.py:function:find_qmk_firmware\/find_qmk_firmware","partition":"test","code":"def find_qmk_firmware():\n    Look for qmk_firmware in the usual places.\n\n    This function returns the path to qmk_firmware, or the default location if one does not exist.\n    \"\"\"\n    if in_qmk_firmware():\n        return in_qmk_firmware()\n    if milc.cli.config.user.qmk_home:\n        return Path(milc.cli.config.user.qmk_home).expanduser().resolve()\n    if 'QMK_HOME' in os.environ:\n        path = Path(os.environ['QMK_HOME']).expanduser()\n        if path.exists():\n            return path.resolve()\n        return path\n    return Path.home() \/ 'qmk_firmware'\n","original_string":"def find_qmk_firmware():\n    \"\"\"Look for qmk_firmware in the usual places.\n\n    This function returns the path to qmk_firmware, or the default location if one does not exist.\n    \"\"\"\n    if in_qmk_firmware():\n        return in_qmk_firmware()\n    if milc.cli.config.user.qmk_home:\n        return Path(milc.cli.config.user.qmk_home).expanduser().resolve()\n    if 'QMK_HOME' in os.environ:\n        path = Path(os.environ['QMK_HOME']).expanduser()\n        if path.exists():\n            return path.resolve()\n        return path\n    return Path.home() \/ 'qmk_firmware'\n","code_tokens":["def","find_qmk_firmware():\n","","","","Look","for","qmk_firmware","in","the","usual","places.\n\n","","","","This","function","returns","the","path","to","qmk_firmware,","or","the","default","location","if","one","does","not","exist.\n","","","","\"\"\"\n","","","","if","in_qmk_firmware():\n","","","","","","","","return","in_qmk_firmware()\n","","","","if","milc.cli.config.user.qmk_home:\n","","","","","","","","return","Path(milc.cli.config.user.qmk_home).expanduser().resolve()\n","","","","if","'QMK_HOME'","in","os.environ:\n","","","","","","","","path","=","Path(os.environ['QMK_HOME']).expanduser()\n","","","","","","","","if","path.exists():\n","","","","","","","","","","","","return","path.resolve()\n","","","","","","","","return","path\n","","","","return","Path.home()","\/","'qmk_firmware'\n"],"func_name":"qmk-0.0.34\/file:\/qmk_cli\/script_qmk.py:function:find_qmk_firmware\/find_qmk_firmware","docstring":"Look for qmk_firmware in the usual places.\n\nThis function returns the path to qmk_firmware, or the default location if one does not exist.","docstring_tokens":["Look","for","qmk_firmware","in","the","usual","places",".","This","function","returns","the","path","to","qmk_firmware",",","or","the","default","location","if","one","does","not","exist","."],"summary":"Look for qmk_firmware in the usual places.","code_with_docstring":"def find_qmk_firmware():\n    \"\"\"Look for qmk_firmware in the usual places.\n\n    This function returns the path to qmk_firmware, or the default location if one does not exist.\n    \"\"\"\n    if in_qmk_firmware():\n        return in_qmk_firmware()\n    if milc.cli.config.user.qmk_home:\n        return Path(milc.cli.config.user.qmk_home).expanduser().resolve()\n    if 'QMK_HOME' in os.environ:\n        path = Path(os.environ['QMK_HOME']).expanduser()\n        if path.exists():\n            return path.resolve()\n        return path\n    return Path.home() \/ 'qmk_firmware'\n","code_tokens_py":[]}
{"repo":"PyCO2SYS","path":"PyCO2SYS\/\/equilibria\/pcx.pyfile:\/equilibria\/pcx.py:function:KWfac\/KWfac","language":"python","sha":"d3421dae1d7b031bda9d7488b867230408e887af","url":"PyCO2SYS\/\/equilibria\/pcx.pyfile:\/equilibria\/pcx.py:function:KWfac\/KWfac","partition":"test","code":"def KWfac(TempK, Pbar, WhichKs):\n    \"\"\"\n    TempC = convert.TempK2C(TempK)\n    deltaV = full(size(TempK), nan)\n    Kappa = full(size(TempK), nan)\n    F = WhichKs == 8\n    if any(F):\n        deltaV = where(F, -25.6 + 0.2324 * TempC - 0.0036246 * TempC ** 2,\n            deltaV)\n        Kappa = where(F, (-7.33 + 0.1368 * TempC - 0.001233 * TempC ** 2) \/\n            1000, Kappa)\n    F = WhichKs != 8\n    if any(F):\n        deltaV = where(F, -20.02 + 0.1119 * TempC - 0.001409 * TempC ** 2,\n            deltaV)\n        Kappa = where(F, (-5.13 + 0.0794 * TempC) \/ 1000, Kappa)\n    return Kfac(deltaV, Kappa, Pbar, TempK)\n","original_string":"def KWfac(TempK, Pbar, WhichKs):\n    \"\"\"Calculate pressure correction factor for KW.\"\"\"\n    TempC = convert.TempK2C(TempK)\n    deltaV = full(size(TempK), nan)\n    Kappa = full(size(TempK), nan)\n    F = WhichKs == 8\n    if any(F):\n        deltaV = where(F, -25.6 + 0.2324 * TempC - 0.0036246 * TempC ** 2,\n            deltaV)\n        Kappa = where(F, (-7.33 + 0.1368 * TempC - 0.001233 * TempC ** 2) \/\n            1000, Kappa)\n    F = WhichKs != 8\n    if any(F):\n        deltaV = where(F, -20.02 + 0.1119 * TempC - 0.001409 * TempC ** 2,\n            deltaV)\n        Kappa = where(F, (-5.13 + 0.0794 * TempC) \/ 1000, Kappa)\n    return Kfac(deltaV, Kappa, Pbar, TempK)\n","code_tokens":["def","KWfac(TempK,","Pbar,","WhichKs):\n","","","","\"\"\"\n","","","","TempC","=","convert.TempK2C(TempK)\n","","","","deltaV","=","full(size(TempK),","nan)\n","","","","Kappa","=","full(size(TempK),","nan)\n","","","","F","=","WhichKs","==","8\n","","","","if","any(F):\n","","","","","","","","deltaV","=","where(F,","-25.6","+","0.2324","*","TempC","-","0.0036246","*","TempC","**","2,\n","","","","","","","","","","","","deltaV)\n","","","","","","","","Kappa","=","where(F,","(-7.33","+","0.1368","*","TempC","-","0.001233","*","TempC","**","2)","\/\n","","","","","","","","","","","","1000,","Kappa)\n","","","","F","=","WhichKs","!=","8\n","","","","if","any(F):\n","","","","","","","","deltaV","=","where(F,","-20.02","+","0.1119","*","TempC","-","0.001409","*","TempC","**","2,\n","","","","","","","","","","","","deltaV)\n","","","","","","","","Kappa","=","where(F,","(-5.13","+","0.0794","*","TempC)","\/","1000,","Kappa)\n","","","","return","Kfac(deltaV,","Kappa,","Pbar,","TempK)\n"],"func_name":"PyCO2SYS\/file:\/equilibria\/pcx.py:function:KWfac\/KWfac","docstring":"Calculate pressure correction factor for KW.","docstring_tokens":["Calculate","pressure","correction","factor","for","KW","."],"summary":"Calculate pressure correction factor for KW.","code_with_docstring":"def KWfac(TempK, Pbar, WhichKs):\n    \"\"\"Calculate pressure correction factor for KW.\"\"\"\n    TempC = convert.TempK2C(TempK)\n    deltaV = full(size(TempK), nan)\n    Kappa = full(size(TempK), nan)\n    F = WhichKs == 8\n    if any(F):\n        deltaV = where(F, -25.6 + 0.2324 * TempC - 0.0036246 * TempC ** 2,\n            deltaV)\n        Kappa = where(F, (-7.33 + 0.1368 * TempC - 0.001233 * TempC ** 2) \/\n            1000, Kappa)\n    F = WhichKs != 8\n    if any(F):\n        deltaV = where(F, -20.02 + 0.1119 * TempC - 0.001409 * TempC ** 2,\n            deltaV)\n        Kappa = where(F, (-5.13 + 0.0794 * TempC) \/ 1000, Kappa)\n    return Kfac(deltaV, Kappa, Pbar, TempK)\n","code_tokens_py":[]}
{"repo":"qisrc","path":"qisrc\/\/actions\/log.pyfile:\/actions\/log.py:function:do\/do","language":"python","sha":"88f75977016630553509dccd77e513603584915f","url":"qisrc\/\/actions\/log.pyfile:\/actions\/log.py:function:do\/do","partition":"test","code":"def do(args):\n     \"\"\"\n    branch = args.branch\n    short = args.short\n    if short:\n        log_cmd = ['shortlog']\n    else:\n        log_format = (\n            '%Cgreen%h%Creset -%C(yellow)%d%Creset %s %C(bold blue)<%an>%Creset'\n            )\n        log_cmd = ['log', '--pretty=format:%s' % log_format]\n    git_worktree = qisrc.parsers.get_git_worktree(args)\n    git_projects = qisrc.parsers.get_git_projects(git_worktree, args,\n        default_all=False, use_build_deps=True)\n    qisrc.diff.diff_worktree(git_worktree, git_projects, branch, log_cmd)\n","original_string":"def do(args):\n    \"\"\" Main Entry Point \"\"\"\n    branch = args.branch\n    short = args.short\n    if short:\n        log_cmd = ['shortlog']\n    else:\n        log_format = (\n            '%Cgreen%h%Creset -%C(yellow)%d%Creset %s %C(bold blue)<%an>%Creset'\n            )\n        log_cmd = ['log', '--pretty=format:%s' % log_format]\n    git_worktree = qisrc.parsers.get_git_worktree(args)\n    git_projects = qisrc.parsers.get_git_projects(git_worktree, args,\n        default_all=False, use_build_deps=True)\n    qisrc.diff.diff_worktree(git_worktree, git_projects, branch, log_cmd)\n","code_tokens":["def","do(args):\n","","","","","\"\"\"\n","","","","branch","=","args.branch\n","","","","short","=","args.short\n","","","","if","short:\n","","","","","","","","log_cmd","=","['shortlog']\n","","","","else:\n","","","","","","","","log_format","=","(\n","","","","","","","","","","","","'%Cgreen%h%Creset","-%C(yellow)%d%Creset","%s","%C(bold","blue)<%an>%Creset'\n","","","","","","","","","","","",")\n","","","","","","","","log_cmd","=","['log',","'--pretty=format:%s'","%","log_format]\n","","","","git_worktree","=","qisrc.parsers.get_git_worktree(args)\n","","","","git_projects","=","qisrc.parsers.get_git_projects(git_worktree,","args,\n","","","","","","","","default_all=False,","use_build_deps=True)\n","","","","qisrc.diff.diff_worktree(git_worktree,","git_projects,","branch,","log_cmd)\n"],"func_name":"qisrc\/file:\/actions\/log.py:function:do\/do","docstring":"Main Entry Point ","docstring_tokens":["Main","Entry","Point"],"summary":"Main Entry Point ","code_with_docstring":"def do(args):\n    \"\"\" Main Entry Point \"\"\"\n    branch = args.branch\n    short = args.short\n    if short:\n        log_cmd = ['shortlog']\n    else:\n        log_format = (\n            '%Cgreen%h%Creset -%C(yellow)%d%Creset %s %C(bold blue)<%an>%Creset'\n            )\n        log_cmd = ['log', '--pretty=format:%s' % log_format]\n    git_worktree = qisrc.parsers.get_git_worktree(args)\n    git_projects = qisrc.parsers.get_git_projects(git_worktree, args,\n        default_all=False, use_build_deps=True)\n    qisrc.diff.diff_worktree(git_worktree, git_projects, branch, log_cmd)\n","code_tokens_py":[]}
{"repo":"galini-io-0.4.0","path":"galini-io-0.4.0\/\/galini_io\/logging.pyclass:LogManager\/file_path","language":"python","sha":"df18cee77749656ac03077285ea21945be74b777","url":"galini-io-0.4.0\/\/galini_io\/logging.pyclass:LogManager\/file_path","partition":"test","code":"def file_path(self, filename):\n    Full path for filename inside logger output dir.\n\n        Parameters\n        ----------\n        filename : string\n            file name\n\n        Returns\n        -------\n        path or None\n            Returns None if rich logging is disabled\n        \"\"\"\n    if not self.has_rich_logging:\n        return None\n    path = self.directory \/ filename\n    return str(path)\n","original_string":"def file_path(self, filename):\n    \"\"\"Full path for filename inside logger output dir.\n\n        Parameters\n        ----------\n        filename : string\n            file name\n\n        Returns\n        -------\n        path or None\n            Returns None if rich logging is disabled\n        \"\"\"\n    if not self.has_rich_logging:\n        return None\n    path = self.directory \/ filename\n    return str(path)\n","code_tokens":["def","file_path(self,","filename):\n","","","","Full","path","for","filename","inside","logger","output","dir.\n\n","","","","","","","","Parameters\n","","","","","","","","----------\n","","","","","","","","filename",":","string\n","","","","","","","","","","","","file","name\n\n","","","","","","","","Returns\n","","","","","","","","-------\n","","","","","","","","path","or","None\n","","","","","","","","","","","","Returns","None","if","rich","logging","is","disabled\n","","","","","","","","\"\"\"\n","","","","if","not","self.has_rich_logging:\n","","","","","","","","return","None\n","","","","path","=","self.directory","\/","filename\n","","","","return","str(path)\n"],"func_name":"galini-io-0.4.0\/class:LogManager\/file_path","docstring":"Full path for filename inside logger output dir.\n\nParameters\n----------\nfilename : string\n    file name\n\nReturns\n-------\npath or None\n    Returns None if rich logging is disabled","docstring_tokens":["Full","path","for","filename","inside","logger","output","dir",".","Parameters","----------","filename",":","string","file","name","Returns","-------","path","or","None","Returns","None","if","rich","logging","is","disabled"],"summary":"Full path for filename inside logger output dir.","code_with_docstring":"def file_path(self, filename):\n    \"\"\"Full path for filename inside logger output dir.\n\n        Parameters\n        ----------\n        filename : string\n            file name\n\n        Returns\n        -------\n        path or None\n            Returns None if rich logging is disabled\n        \"\"\"\n    if not self.has_rich_logging:\n        return None\n    path = self.directory \/ filename\n    return str(path)\n","code_tokens_py":[]}
{"repo":"pas.plugins.headers-1.3.1","path":"pas.plugins.headers-1.3.1\/\/src\/pas\/plugins\/headers\/plugins.pyclass:HeaderPlugin\/_parse_memberdata_to_header","language":"python","sha":"57c57b5c54012baa04ecff7cedb7b076efd729a7","url":"pas.plugins.headers-1.3.1\/\/src\/pas\/plugins\/headers\/plugins.pyclass:HeaderPlugin\/_parse_memberdata_to_header","partition":"test","code":"def _parse_memberdata_to_header(self):\n    Parse the memberdata_to_header property.\n\n        Everything must be text (unicode), otherwise various things break,\n        like calling request.getHeader, and creating a memberdata property sheet.\n        At least on Plone 5.2 Python 3.\n        \"\"\"\n    result = []\n    for line in self.memberdata_to_header:\n        line = line.strip()\n        if not line:\n            continue\n        if isinstance(line, bytes):\n            line = line.decode('utf-8')\n        if line.startswith('#'):\n            continue\n        pipes = line.count('|')\n        if pipes == 1:\n            member_prop, headers = line.split('|')\n            parser = None\n        elif pipes == 2:\n            member_prop, headers, parser = line.split('|')\n        else:\n            continue\n        member_prop = member_prop.strip()\n        if not member_prop:\n            continue\n        headers = headers.split()\n        if not headers:\n            continue\n        result.append((member_prop, headers, parser))\n    return result\n","original_string":"def _parse_memberdata_to_header(self):\n    \"\"\"Parse the memberdata_to_header property.\n\n        Everything must be text (unicode), otherwise various things break,\n        like calling request.getHeader, and creating a memberdata property sheet.\n        At least on Plone 5.2 Python 3.\n        \"\"\"\n    result = []\n    for line in self.memberdata_to_header:\n        line = line.strip()\n        if not line:\n            continue\n        if isinstance(line, bytes):\n            line = line.decode('utf-8')\n        if line.startswith('#'):\n            continue\n        pipes = line.count('|')\n        if pipes == 1:\n            member_prop, headers = line.split('|')\n            parser = None\n        elif pipes == 2:\n            member_prop, headers, parser = line.split('|')\n        else:\n            continue\n        member_prop = member_prop.strip()\n        if not member_prop:\n            continue\n        headers = headers.split()\n        if not headers:\n            continue\n        result.append((member_prop, headers, parser))\n    return result\n","code_tokens":["def","_parse_memberdata_to_header(self):\n","","","","Parse","the","memberdata_to_header","property.\n\n","","","","","","","","Everything","must","be","text","(unicode),","otherwise","various","things","break,\n","","","","","","","","like","calling","request.getHeader,","and","creating","a","memberdata","property","sheet.\n","","","","","","","","At","least","on","Plone","5.2","Python","3.\n","","","","","","","","\"\"\"\n","","","","result","=","[]\n","","","","for","line","in","self.memberdata_to_header:\n","","","","","","","","line","=","line.strip()\n","","","","","","","","if","not","line:\n","","","","","","","","","","","","continue\n","","","","","","","","if","isinstance(line,","bytes):\n","","","","","","","","","","","","line","=","line.decode('utf-8')\n","","","","","","","","if","line.startswith('#'):\n","","","","","","","","","","","","continue\n","","","","","","","","pipes","=","line.count('|')\n","","","","","","","","if","pipes","==","1:\n","","","","","","","","","","","","member_prop,","headers","=","line.split('|')\n","","","","","","","","","","","","parser","=","None\n","","","","","","","","elif","pipes","==","2:\n","","","","","","","","","","","","member_prop,","headers,","parser","=","line.split('|')\n","","","","","","","","else:\n","","","","","","","","","","","","continue\n","","","","","","","","member_prop","=","member_prop.strip()\n","","","","","","","","if","not","member_prop:\n","","","","","","","","","","","","continue\n","","","","","","","","headers","=","headers.split()\n","","","","","","","","if","not","headers:\n","","","","","","","","","","","","continue\n","","","","","","","","result.append((member_prop,","headers,","parser))\n","","","","return","result\n"],"func_name":"pas.plugins.headers-1.3.1\/class:HeaderPlugin\/_parse_memberdata_to_header","docstring":"Parse the memberdata_to_header property.\n\nEverything must be text (unicode), otherwise various things break,\nlike calling request.getHeader, and creating a memberdata property sheet.\nAt least on Plone 5.2 Python 3.","docstring_tokens":["Parse","the","memberdata_to_header","property",".","Everything","must","be","text","(","unicode",")",",","otherwise","various","things","break",",","like","calling","request.getHeader",",","and","creating","a","memberdata","property","sheet",".","At","least","on","Plone","5.2","Python","3","."],"summary":"Parse the memberdata_to_header property.","code_with_docstring":"def _parse_memberdata_to_header(self):\n    \"\"\"Parse the memberdata_to_header property.\n\n        Everything must be text (unicode), otherwise various things break,\n        like calling request.getHeader, and creating a memberdata property sheet.\n        At least on Plone 5.2 Python 3.\n        \"\"\"\n    result = []\n    for line in self.memberdata_to_header:\n        line = line.strip()\n        if not line:\n            continue\n        if isinstance(line, bytes):\n            line = line.decode('utf-8')\n        if line.startswith('#'):\n            continue\n        pipes = line.count('|')\n        if pipes == 1:\n            member_prop, headers = line.split('|')\n            parser = None\n        elif pipes == 2:\n            member_prop, headers, parser = line.split('|')\n        else:\n            continue\n        member_prop = member_prop.strip()\n        if not member_prop:\n            continue\n        headers = headers.split()\n        if not headers:\n            continue\n        result.append((member_prop, headers, parser))\n    return result\n","code_tokens_py":[]}
{"repo":"menpowidgets-0.3.0","path":"menpowidgets-0.3.0\/\/menpowidgets\/utils.pyfile:\/menpowidgets\/utils.py:function:lists_are_the_same\/lists_are_the_same","language":"python","sha":"01531d761fab7a64d6b58075647d5b1e2477a1d2","url":"menpowidgets-0.3.0\/\/menpowidgets\/utils.pyfile:\/menpowidgets\/utils.py:function:lists_are_the_same\/lists_are_the_same","partition":"test","code":"def lists_are_the_same(a, b):\n    \n    Function that checks if two `lists` have the same elements in the same\n    order.\n\n    Returns\n    -------\n    _lists_are_the_same : `bool`\n        ``True`` if the lists are the same.\n    \"\"\"\n    if len(a) == len(b):\n        for i, j in zip(a, b):\n            if i != j:\n                return False\n        return True\n    else:\n        return False\n","original_string":"def lists_are_the_same(a, b):\n    \"\"\"\n    Function that checks if two `lists` have the same elements in the same\n    order.\n\n    Returns\n    -------\n    _lists_are_the_same : `bool`\n        ``True`` if the lists are the same.\n    \"\"\"\n    if len(a) == len(b):\n        for i, j in zip(a, b):\n            if i != j:\n                return False\n        return True\n    else:\n        return False\n","code_tokens":["def","lists_are_the_same(a,","b):\n","","","","\n","","","","Function","that","checks","if","two","`lists`","have","the","same","elements","in","the","same\n","","","","order.\n\n","","","","Returns\n","","","","-------\n","","","","_lists_are_the_same",":","`bool`\n","","","","","","","","``True``","if","the","lists","are","the","same.\n","","","","\"\"\"\n","","","","if","len(a)","==","len(b):\n","","","","","","","","for","i,","j","in","zip(a,","b):\n","","","","","","","","","","","","if","i","!=","j:\n","","","","","","","","","","","","","","","","return","False\n","","","","","","","","return","True\n","","","","else:\n","","","","","","","","return","False\n"],"func_name":"menpowidgets-0.3.0\/file:\/menpowidgets\/utils.py:function:lists_are_the_same\/lists_are_the_same","docstring":"Function that checks if two `lists` have the same elements in the same\norder.\n\nReturns\n-------\n_lists_are_the_same : `bool`\n    ``True`` if the lists are the same.","docstring_tokens":["Function","that","checks","if","two","`","lists","`","have","the","same","elements","in","the","same","order",".","Returns","-------","_","lists_are_the_same",":","`","bool","`","`","`","True","`","`","if","the","lists","are","the","same","."],"summary":"Function that checks if two `lists` have the same elements in the same","code_with_docstring":"def lists_are_the_same(a, b):\n    \"\"\"\n    Function that checks if two `lists` have the same elements in the same\n    order.\n\n    Returns\n    -------\n    _lists_are_the_same : `bool`\n        ``True`` if the lists are the same.\n    \"\"\"\n    if len(a) == len(b):\n        for i, j in zip(a, b):\n            if i != j:\n                return False\n        return True\n    else:\n        return False\n","code_tokens_py":[]}
{"repo":"squareconnect-2.20190724.1","path":"squareconnect-2.20190724.1\/\/squareconnect\/models\/v1_fee.pyclass:V1Fee\/inclusion_type","language":"python","sha":"e3ce7a37512062a4385c81f3ce88b8c5c80e92ae","url":"squareconnect-2.20190724.1\/\/squareconnect\/models\/v1_fee.pyclass:V1Fee\/inclusion_type","partition":"test","code":"@property\ndef inclusion_type(self):\n    \n        Gets the inclusion_type of this V1Fee.\n        Whether the fee is ADDITIVE or INCLUSIVE. See [V1FeeInclusionType](#type-v1feeinclusiontype) for possible values\n\n        :return: The inclusion_type of this V1Fee.\n        :rtype: str\n        \"\"\"\n    return self._inclusion_type\n","original_string":"@property\ndef inclusion_type(self):\n    \"\"\"\n        Gets the inclusion_type of this V1Fee.\n        Whether the fee is ADDITIVE or INCLUSIVE. See [V1FeeInclusionType](#type-v1feeinclusiontype) for possible values\n\n        :return: The inclusion_type of this V1Fee.\n        :rtype: str\n        \"\"\"\n    return self._inclusion_type\n","code_tokens":["@property\ndef","inclusion_type(self):\n","","","","\n","","","","","","","","Gets","the","inclusion_type","of","this","V1Fee.\n","","","","","","","","Whether","the","fee","is","ADDITIVE","or","INCLUSIVE.","See","[V1FeeInclusionType](#type-v1feeinclusiontype)","for","possible","values\n\n","","","","","","","",":return:","The","inclusion_type","of","this","V1Fee.\n","","","","","","","",":rtype:","str\n","","","","","","","","\"\"\"\n","","","","return","self._inclusion_type\n"],"func_name":"squareconnect-2.20190724.1\/class:V1Fee\/inclusion_type","docstring":"Gets the inclusion_type of this V1Fee.\nWhether the fee is ADDITIVE or INCLUSIVE. See [V1FeeInclusionType](#type-v1feeinclusiontype) for possible values\n\n:return: The inclusion_type of this V1Fee.\n:rtype: str","docstring_tokens":["Gets","the","inclusion_type","of","this","V1Fee",".","Whether","the","fee","is","ADDITIVE","or","INCLUSIVE",".","See","[","V1FeeInclusionType](#type","-","v1feeinclusiontype",")","for","possible","values",":","return",":","The","inclusion_type","of","this","V1Fee",".",":","rtype",":","str"],"summary":"Gets the inclusion_type of this V1Fee.","code_with_docstring":"@property\ndef inclusion_type(self):\n    \"\"\"\n        Gets the inclusion_type of this V1Fee.\n        Whether the fee is ADDITIVE or INCLUSIVE. See [V1FeeInclusionType](#type-v1feeinclusiontype) for possible values\n\n        :return: The inclusion_type of this V1Fee.\n        :rtype: str\n        \"\"\"\n    return self._inclusion_type\n","code_tokens_py":[]}
{"repo":"tensorframes","path":"tensorframes\/\/core.pyfile:\/core.py:function:_add_inputs\/_add_inputs","language":"python","sha":"42a34a08873de16537416da16b0cbdbe5eef8503","url":"tensorframes\/\/core.pyfile:\/core.py:function:_add_inputs\/_add_inputs","partition":"test","code":"def _add_inputs(builder, start_dct, ph_names):\n    \n    \n    \"\"\"\n    if start_dct is None:\n        start_dct = {}\n    dct = dict(**start_dct)\n    for ph_name in ph_names:\n        if ph_name not in dct:\n            dct[ph_name] = ph_name\n    dct_items = dct.items()\n    input_names = [ph_name for ph_name, field_name in dct_items]\n    field_names = [field_name for ph_name, field_name in dct_items]\n    logger.info('inputs: %s %s', str(input_names), str(field_names))\n    builder.inputs(input_names, field_names)\n","original_string":"def _add_inputs(builder, start_dct, ph_names):\n    \"\"\"\n    Combines a dictionary (supplied by the user) with some extra placeholder names.\n    \"\"\"\n    if start_dct is None:\n        start_dct = {}\n    dct = dict(**start_dct)\n    for ph_name in ph_names:\n        if ph_name not in dct:\n            dct[ph_name] = ph_name\n    dct_items = dct.items()\n    input_names = [ph_name for ph_name, field_name in dct_items]\n    field_names = [field_name for ph_name, field_name in dct_items]\n    logger.info('inputs: %s %s', str(input_names), str(field_names))\n    builder.inputs(input_names, field_names)\n","code_tokens":["def","_add_inputs(builder,","start_dct,","ph_names):\n","","","","\n","","","","\n","","","","\"\"\"\n","","","","if","start_dct","is","None:\n","","","","","","","","start_dct","=","{}\n","","","","dct","=","dict(**start_dct)\n","","","","for","ph_name","in","ph_names:\n","","","","","","","","if","ph_name","not","in","dct:\n","","","","","","","","","","","","dct[ph_name]","=","ph_name\n","","","","dct_items","=","dct.items()\n","","","","input_names","=","[ph_name","for","ph_name,","field_name","in","dct_items]\n","","","","field_names","=","[field_name","for","ph_name,","field_name","in","dct_items]\n","","","","logger.info('inputs:","%s","%s',","str(input_names),","str(field_names))\n","","","","builder.inputs(input_names,","field_names)\n"],"func_name":"tensorframes\/file:\/core.py:function:_add_inputs\/_add_inputs","docstring":"Combines a dictionary (supplied by the user) with some extra placeholder names.","docstring_tokens":["Combines","a","dictionary","(","supplied","by","the","user",")","with","some","extra","placeholder","names","."],"summary":"Combines a dictionary (supplied by the user) with some extra placeholder names.","code_with_docstring":"def _add_inputs(builder, start_dct, ph_names):\n    \"\"\"\n    Combines a dictionary (supplied by the user) with some extra placeholder names.\n    \"\"\"\n    if start_dct is None:\n        start_dct = {}\n    dct = dict(**start_dct)\n    for ph_name in ph_names:\n        if ph_name not in dct:\n            dct[ph_name] = ph_name\n    dct_items = dct.items()\n    input_names = [ph_name for ph_name, field_name in dct_items]\n    field_names = [field_name for ph_name, field_name in dct_items]\n    logger.info('inputs: %s %s', str(input_names), str(field_names))\n    builder.inputs(input_names, field_names)\n","code_tokens_py":[]}
{"repo":"infi.storagemodel-0.4.32","path":"infi.storagemodel-0.4.32\/\/src\/infi\/storagemodel\/base\/mount.pyclass:MountManager\/get_recommended_file_system","language":"python","sha":"6c1bd96de4952b948976b2861fe2dfc259e22b16","url":"infi.storagemodel-0.4.32\/\/src\/infi\/storagemodel\/base\/mount.pyclass:MountManager\/get_recommended_file_system","partition":"test","code":"@cached_method\ndef get_recommended_file_system(self):\n    \"\"\"\n    raise NotImplementedError()\n","original_string":"@cached_method\ndef get_recommended_file_system(self):\n    \"\"\"Returns a `infi.storagemodel.base.filesystem.FileSystem` objects\"\"\"\n    raise NotImplementedError()\n","code_tokens":["@cached_method\ndef","get_recommended_file_system(self):\n","","","","\"\"\"\n","","","","raise","NotImplementedError()\n"],"func_name":"infi.storagemodel-0.4.32\/class:MountManager\/get_recommended_file_system","docstring":"Returns a `infi.storagemodel.base.filesystem.FileSystem` objects","docstring_tokens":["Returns","a","`","infi.storagemodel.base.filesystem",".","FileSystem","`","objects"],"summary":"Returns a `infi.storagemodel.base.filesystem.FileSystem` objects","code_with_docstring":"@cached_method\ndef get_recommended_file_system(self):\n    \"\"\"Returns a `infi.storagemodel.base.filesystem.FileSystem` objects\"\"\"\n    raise NotImplementedError()\n","code_tokens_py":[]}
{"repo":"py2jdbc-0.0.6","path":"py2jdbc-0.0.6\/\/py2jdbc\/wrap.pyclass:JStaticMethod\/__call__","language":"python","sha":"db5636115aa7da0db2820fa6809b5663b4aac48c","url":"py2jdbc-0.0.6\/\/py2jdbc\/wrap.pyclass:JStaticMethod\/__call__","partition":"test","code":"def __call__(self, *args):\n    \n        Call the static method on the class with Python arguments.\n\n        :param args: Python value arguments\n        :return: the result value, or None for Void static methods.\n        \"\"\"\n    try:\n        value = self.restype.call_static(self.cls.cls, self.mid, self.\n            argtypes, *args)\n        self.restype.release(value)\n        return value\n    except py2jdbc.jni.JavaException as e:\n        raise self.cls.env.exception(e)\n","original_string":"def __call__(self, *args):\n    \"\"\"\n        Call the static method on the class with Python arguments.\n\n        :param args: Python value arguments\n        :return: the result value, or None for Void static methods.\n        \"\"\"\n    try:\n        value = self.restype.call_static(self.cls.cls, self.mid, self.\n            argtypes, *args)\n        self.restype.release(value)\n        return value\n    except py2jdbc.jni.JavaException as e:\n        raise self.cls.env.exception(e)\n","code_tokens":["def","__call__(self,","*args):\n","","","","\n","","","","","","","","Call","the","static","method","on","the","class","with","Python","arguments.\n\n","","","","","","","",":param","args:","Python","value","arguments\n","","","","","","","",":return:","the","result","value,","or","None","for","Void","static","methods.\n","","","","","","","","\"\"\"\n","","","","try:\n","","","","","","","","value","=","self.restype.call_static(self.cls.cls,","self.mid,","self.\n","","","","","","","","","","","","argtypes,","*args)\n","","","","","","","","self.restype.release(value)\n","","","","","","","","return","value\n","","","","except","py2jdbc.jni.JavaException","as","e:\n","","","","","","","","raise","self.cls.env.exception(e)\n"],"func_name":"py2jdbc-0.0.6\/class:JStaticMethod\/__call__","docstring":"Call the static method on the class with Python arguments.\n\n:param args: Python value arguments\n:return: the result value, or None for Void static methods.","docstring_tokens":["Call","the","static","method","on","the","class","with","Python","arguments",".",":","param","args",":","Python","value","arguments",":","return",":","the","result","value",",","or","None","for","Void","static","methods","."],"summary":"Call the static method on the class with Python arguments.","code_with_docstring":"def __call__(self, *args):\n    \"\"\"\n        Call the static method on the class with Python arguments.\n\n        :param args: Python value arguments\n        :return: the result value, or None for Void static methods.\n        \"\"\"\n    try:\n        value = self.restype.call_static(self.cls.cls, self.mid, self.\n            argtypes, *args)\n        self.restype.release(value)\n        return value\n    except py2jdbc.jni.JavaException as e:\n        raise self.cls.env.exception(e)\n","code_tokens_py":[]}
{"repo":"itk","path":"itk\/\/itkNeighborhoodOperatorImageFilterPython.pyclass:itkNeighborhoodOperatorImageFilterSS2SS2SS\/SetOperator","language":"python","sha":"aa542f74faa5499886f9de2447e0658aa1144024","url":"itk\/\/itkNeighborhoodOperatorImageFilterPython.pyclass:itkNeighborhoodOperatorImageFilterSS2SS2SS\/SetOperator","partition":"test","code":"def SetOperator(self, p: 'itkNeighborhoodSS2') ->'void':\n    \n        SetOperator(itkNeighborhoodOperatorImageFilterSS2SS2SS self, itkNeighborhoodSS2 p)\n\n        Sets the operator that\n        is used to filter the image. Note that the operator is stored as an\n        internal COPY (it is not part of the pipeline). \n        \"\"\"\n    return (_itkNeighborhoodOperatorImageFilterPython.\n        itkNeighborhoodOperatorImageFilterSS2SS2SS_SetOperator(self, p))\n","original_string":"def SetOperator(self, p: 'itkNeighborhoodSS2') ->'void':\n    \"\"\"\n        SetOperator(itkNeighborhoodOperatorImageFilterSS2SS2SS self, itkNeighborhoodSS2 p)\n\n        Sets the operator that\n        is used to filter the image. Note that the operator is stored as an\n        internal COPY (it is not part of the pipeline). \n        \"\"\"\n    return (_itkNeighborhoodOperatorImageFilterPython.\n        itkNeighborhoodOperatorImageFilterSS2SS2SS_SetOperator(self, p))\n","code_tokens":["def","SetOperator(self,","p:","'itkNeighborhoodSS2')","->'void':\n","","","","\n","","","","","","","","SetOperator(itkNeighborhoodOperatorImageFilterSS2SS2SS","self,","itkNeighborhoodSS2","p)\n\n","","","","","","","","Sets","the","operator","that\n","","","","","","","","is","used","to","filter","the","image.","Note","that","the","operator","is","stored","as","an\n","","","","","","","","internal","COPY","(it","is","not","part","of","the","pipeline).","\n","","","","","","","","\"\"\"\n","","","","return","(_itkNeighborhoodOperatorImageFilterPython.\n","","","","","","","","itkNeighborhoodOperatorImageFilterSS2SS2SS_SetOperator(self,","p))\n"],"func_name":"itk\/class:itkNeighborhoodOperatorImageFilterSS2SS2SS\/SetOperator","docstring":"SetOperator(itkNeighborhoodOperatorImageFilterSS2SS2SS self, itkNeighborhoodSS2 p)\n\nSets the operator that\nis used to filter the image. Note that the operator is stored as an\ninternal COPY (it is not part of the pipeline). ","docstring_tokens":["SetOperator(itkNeighborhoodOperatorImageFilterSS2SS2SS","self",",","itkNeighborhoodSS2","p",")","Sets","the","operator","that","is","used","to","filter","the","image",".","Note","that","the","operator","is","stored","as","an","internal","COPY","(","it","is","not","part","of","the","pipeline",")","."],"summary":"SetOperator(itkNeighborhoodOperatorImageFilterSS2SS2SS self, itkNeighborhoodSS2 p)","code_with_docstring":"def SetOperator(self, p: 'itkNeighborhoodSS2') ->'void':\n    \"\"\"\n        SetOperator(itkNeighborhoodOperatorImageFilterSS2SS2SS self, itkNeighborhoodSS2 p)\n\n        Sets the operator that\n        is used to filter the image. Note that the operator is stored as an\n        internal COPY (it is not part of the pipeline). \n        \"\"\"\n    return (_itkNeighborhoodOperatorImageFilterPython.\n        itkNeighborhoodOperatorImageFilterSS2SS2SS_SetOperator(self, p))\n","code_tokens_py":[]}
{"repo":"turbustat-1.1.0","path":"turbustat-1.1.0\/\/turbustat\/statistics\/threeD_to_twoD.pyfile:\/turbustat\/statistics\/threeD_to_twoD.py:function:intensity_data\/intensity_data","language":"python","sha":"22826fccf3849430085cf0b91d4724cd7386e121","url":"turbustat-1.1.0\/\/turbustat\/statistics\/threeD_to_twoD.pyfile:\/turbustat\/statistics\/threeD_to_twoD.py:function:intensity_data\/intensity_data","partition":"test","code":"def intensity_data(cube, p=0.2, noise_lim=-np.inf, norm=True):\n    \n    Clips off channels below the given noise limit and keep the\n    upper percentile specified.\n\n    Parameters\n    ----------\n    cube : numpy.ndarray\n        Data cube.\n    p : float, optional\n        Sets the fraction of data to keep in each channel.\n    noise_lim : float, optional\n        The noise limit used to reject channels in the cube.\n\n    Returns\n    -------\n\n    intensity_vecs : numpy.ndarray\n        2D dataset of size (# channels, p * cube.shape[1] * cube.shape[2]).\n    \"\"\"\n    vec_length = int(round(p * cube.shape[1] * cube.shape[2]))\n    intensity_vecs = np.empty((cube.shape[0], vec_length))\n    delete_channels = []\n    if norm:\n        maxval = np.nanmax(cube)\n    else:\n        maxval = 1.0\n    for dv in range(cube.shape[0]):\n        vec_vec = cube[(dv), :, :]\n        vel_vec = vec_vec[np.isfinite(vec_vec)]\n        vel_vec = vel_vec[vel_vec > noise_lim]\n        vel_vec = np.sort(vel_vec)[::-1]\n        if len(vel_vec) < vec_length:\n            diff = vec_length - len(vel_vec)\n            vel_vec = np.append(vel_vec, [0.0] * diff)\n        else:\n            vel_vec = vel_vec[:vec_length]\n        if maxval != 0.0:\n            intensity_vecs[(dv), :] = vel_vec \/ maxval\n        else:\n            delete_channels.append(dv)\n    intensity_vecs = np.delete(intensity_vecs, delete_channels, axis=0)\n    return intensity_vecs\n","original_string":"def intensity_data(cube, p=0.2, noise_lim=-np.inf, norm=True):\n    \"\"\"\n    Clips off channels below the given noise limit and keep the\n    upper percentile specified.\n\n    Parameters\n    ----------\n    cube : numpy.ndarray\n        Data cube.\n    p : float, optional\n        Sets the fraction of data to keep in each channel.\n    noise_lim : float, optional\n        The noise limit used to reject channels in the cube.\n\n    Returns\n    -------\n\n    intensity_vecs : numpy.ndarray\n        2D dataset of size (# channels, p * cube.shape[1] * cube.shape[2]).\n    \"\"\"\n    vec_length = int(round(p * cube.shape[1] * cube.shape[2]))\n    intensity_vecs = np.empty((cube.shape[0], vec_length))\n    delete_channels = []\n    if norm:\n        maxval = np.nanmax(cube)\n    else:\n        maxval = 1.0\n    for dv in range(cube.shape[0]):\n        vec_vec = cube[(dv), :, :]\n        vel_vec = vec_vec[np.isfinite(vec_vec)]\n        vel_vec = vel_vec[vel_vec > noise_lim]\n        vel_vec = np.sort(vel_vec)[::-1]\n        if len(vel_vec) < vec_length:\n            diff = vec_length - len(vel_vec)\n            vel_vec = np.append(vel_vec, [0.0] * diff)\n        else:\n            vel_vec = vel_vec[:vec_length]\n        if maxval != 0.0:\n            intensity_vecs[(dv), :] = vel_vec \/ maxval\n        else:\n            delete_channels.append(dv)\n    intensity_vecs = np.delete(intensity_vecs, delete_channels, axis=0)\n    return intensity_vecs\n","code_tokens":["def","intensity_data(cube,","p=0.2,","noise_lim=-np.inf,","norm=True):\n","","","","\n","","","","Clips","off","channels","below","the","given","noise","limit","and","keep","the\n","","","","upper","percentile","specified.\n\n","","","","Parameters\n","","","","----------\n","","","","cube",":","numpy.ndarray\n","","","","","","","","Data","cube.\n","","","","p",":","float,","optional\n","","","","","","","","Sets","the","fraction","of","data","to","keep","in","each","channel.\n","","","","noise_lim",":","float,","optional\n","","","","","","","","The","noise","limit","used","to","reject","channels","in","the","cube.\n\n","","","","Returns\n","","","","-------\n\n","","","","intensity_vecs",":","numpy.ndarray\n","","","","","","","","2D","dataset","of","size","(#","channels,","p","*","cube.shape[1]","*","cube.shape[2]).\n","","","","\"\"\"\n","","","","vec_length","=","int(round(p","*","cube.shape[1]","*","cube.shape[2]))\n","","","","intensity_vecs","=","np.empty((cube.shape[0],","vec_length))\n","","","","delete_channels","=","[]\n","","","","if","norm:\n","","","","","","","","maxval","=","np.nanmax(cube)\n","","","","else:\n","","","","","","","","maxval","=","1.0\n","","","","for","dv","in","range(cube.shape[0]):\n","","","","","","","","vec_vec","=","cube[(dv),",":,",":]\n","","","","","","","","vel_vec","=","vec_vec[np.isfinite(vec_vec)]\n","","","","","","","","vel_vec","=","vel_vec[vel_vec",">","noise_lim]\n","","","","","","","","vel_vec","=","np.sort(vel_vec)[::-1]\n","","","","","","","","if","len(vel_vec)","<","vec_length:\n","","","","","","","","","","","","diff","=","vec_length","-","len(vel_vec)\n","","","","","","","","","","","","vel_vec","=","np.append(vel_vec,","[0.0]","*","diff)\n","","","","","","","","else:\n","","","","","","","","","","","","vel_vec","=","vel_vec[:vec_length]\n","","","","","","","","if","maxval","!=","0.0:\n","","","","","","","","","","","","intensity_vecs[(dv),",":]","=","vel_vec","\/","maxval\n","","","","","","","","else:\n","","","","","","","","","","","","delete_channels.append(dv)\n","","","","intensity_vecs","=","np.delete(intensity_vecs,","delete_channels,","axis=0)\n","","","","return","intensity_vecs\n"],"func_name":"turbustat-1.1.0\/file:\/turbustat\/statistics\/threeD_to_twoD.py:function:intensity_data\/intensity_data","docstring":"Clips off channels below the given noise limit and keep the\nupper percentile specified.\n\nParameters\n----------\ncube : numpy.ndarray\n    Data cube.\np : float, optional\n    Sets the fraction of data to keep in each channel.\nnoise_lim : float, optional\n    The noise limit used to reject channels in the cube.\n\nReturns\n-------\n\nintensity_vecs : numpy.ndarray\n    2D dataset of size (# channels, p * cube.shape[1] * cube.shape[2]).","docstring_tokens":["Clips","off","channels","below","the","given","noise","limit","and","keep","the","upper","percentile","specified",".","Parameters","----------","cube",":","numpy.ndarray","Data","cube",".","p",":","float",",","optional","Sets","the","fraction","of","data","to","keep","in","each","channel",".","noise_lim",":","float",",","optional","The","noise","limit","used","to","reject","channels","in","the","cube",".","Returns","-------","intensity_vecs",":","numpy.ndarray","2D","dataset","of","size","(","#","channels",",","p","*","cube.shape[1","]","*","cube.shape[2","]",")","."],"summary":"Clips off channels below the given noise limit and keep the","code_with_docstring":"def intensity_data(cube, p=0.2, noise_lim=-np.inf, norm=True):\n    \"\"\"\n    Clips off channels below the given noise limit and keep the\n    upper percentile specified.\n\n    Parameters\n    ----------\n    cube : numpy.ndarray\n        Data cube.\n    p : float, optional\n        Sets the fraction of data to keep in each channel.\n    noise_lim : float, optional\n        The noise limit used to reject channels in the cube.\n\n    Returns\n    -------\n\n    intensity_vecs : numpy.ndarray\n        2D dataset of size (# channels, p * cube.shape[1] * cube.shape[2]).\n    \"\"\"\n    vec_length = int(round(p * cube.shape[1] * cube.shape[2]))\n    intensity_vecs = np.empty((cube.shape[0], vec_length))\n    delete_channels = []\n    if norm:\n        maxval = np.nanmax(cube)\n    else:\n        maxval = 1.0\n    for dv in range(cube.shape[0]):\n        vec_vec = cube[(dv), :, :]\n        vel_vec = vec_vec[np.isfinite(vec_vec)]\n        vel_vec = vel_vec[vel_vec > noise_lim]\n        vel_vec = np.sort(vel_vec)[::-1]\n        if len(vel_vec) < vec_length:\n            diff = vec_length - len(vel_vec)\n            vel_vec = np.append(vel_vec, [0.0] * diff)\n        else:\n            vel_vec = vel_vec[:vec_length]\n        if maxval != 0.0:\n            intensity_vecs[(dv), :] = vel_vec \/ maxval\n        else:\n            delete_channels.append(dv)\n    intensity_vecs = np.delete(intensity_vecs, delete_channels, axis=0)\n    return intensity_vecs\n","code_tokens_py":[]}
{"repo":"arnica-1.5.7","path":"arnica-1.5.7\/\/src\/arnica\/utils\/axishell.pyclass:AxiShell\/__init__","language":"python","sha":"812462ca539e1eed21d8dfdb3d21dad5589edf66","url":"arnica-1.5.7\/\/src\/arnica\/utils\/axishell.pyclass:AxiShell\/__init__","partition":"test","code":"def __init__(self, n_longi, n_azi):\n    \n        \n        \"\"\"\n    self.shape = n_azi, n_longi\n    self.geom = {}\n    self.matrix = {}\n    self.cake = {}\n","original_string":"def __init__(self, n_longi, n_azi):\n    \"\"\"\n        *Initialize an AxiShell object*\n        \"\"\"\n    self.shape = n_azi, n_longi\n    self.geom = {}\n    self.matrix = {}\n    self.cake = {}\n","code_tokens":["def","__init__(self,","n_longi,","n_azi):\n","","","","\n","","","","","","","","\n","","","","","","","","\"\"\"\n","","","","self.shape","=","n_azi,","n_longi\n","","","","self.geom","=","{}\n","","","","self.matrix","=","{}\n","","","","self.cake","=","{}\n"],"func_name":"arnica-1.5.7\/class:AxiShell\/__init__","docstring":"*Initialize an AxiShell object*","docstring_tokens":["*","Initialize","an","AxiShell","object","*"],"summary":"*Initialize an AxiShell object*","code_with_docstring":"def __init__(self, n_longi, n_azi):\n    \"\"\"\n        *Initialize an AxiShell object*\n        \"\"\"\n    self.shape = n_azi, n_longi\n    self.geom = {}\n    self.matrix = {}\n    self.cake = {}\n","code_tokens_py":[]}
{"repo":"bioservices-1.7.4","path":"bioservices-1.7.4\/\/src\/bioservices\/reactome.pyclass:ReactomeOld\/bioservices_get_reactants_from_reaction_identifier","language":"python","sha":"7f6fa83c9dcadc2055c882c92fa09dcb567e7fbc","url":"bioservices-1.7.4\/\/src\/bioservices\/reactome.pyclass:ReactomeOld\/bioservices_get_reactants_from_reaction_identifier","partition":"test","code":"def bioservices_get_reactants_from_reaction_identifier(self, reaction):\n    Fetch information from the reaction HTML page\n\n        .. note:: draft version\n        \"\"\"\n    res = self.http_get('http:\/\/www.reactome.org\/content\/detail\/%s' % reaction)\n    res = res.content\n    try:\n        reactants = [x for x in res.split('\\n') if '<title>' in x]\n        reactants = reactants[0].split('|')[1].strip().strip('<\/title>')\n    except Exception as err:\n        print('Could not interpret title', file=sys.stderr)\n        return res\n    if reactants.count(':') == 1:\n        reactants = reactants.split(':')\n    else:\n        pass\n    return reactants\n","original_string":"def bioservices_get_reactants_from_reaction_identifier(self, reaction):\n    \"\"\"Fetch information from the reaction HTML page\n\n        .. note:: draft version\n        \"\"\"\n    res = self.http_get('http:\/\/www.reactome.org\/content\/detail\/%s' % reaction)\n    res = res.content\n    try:\n        reactants = [x for x in res.split('\\n') if '<title>' in x]\n        reactants = reactants[0].split('|')[1].strip().strip('<\/title>')\n    except Exception as err:\n        print('Could not interpret title', file=sys.stderr)\n        return res\n    if reactants.count(':') == 1:\n        reactants = reactants.split(':')\n    else:\n        pass\n    return reactants\n","code_tokens":["def","bioservices_get_reactants_from_reaction_identifier(self,","reaction):\n","","","","Fetch","information","from","the","reaction","HTML","page\n\n","","","","","","","","..","note::","draft","version\n","","","","","","","","\"\"\"\n","","","","res","=","self.http_get('http:\/\/www.reactome.org\/content\/detail\/%s'","%","reaction)\n","","","","res","=","res.content\n","","","","try:\n","","","","","","","","reactants","=","[x","for","x","in","res.split('\\n')","if","'<title>'","in","x]\n","","","","","","","","reactants","=","reactants[0].split('|')[1].strip().strip('<\/title>')\n","","","","except","Exception","as","err:\n","","","","","","","","print('Could","not","interpret","title',","file=sys.stderr)\n","","","","","","","","return","res\n","","","","if","reactants.count(':')","==","1:\n","","","","","","","","reactants","=","reactants.split(':')\n","","","","else:\n","","","","","","","","pass\n","","","","return","reactants\n"],"func_name":"bioservices-1.7.4\/class:ReactomeOld\/bioservices_get_reactants_from_reaction_identifier","docstring":"Fetch information from the reaction HTML page\n\n.. note:: draft version","docstring_tokens":["Fetch","information","from","the","reaction","HTML","page","..","note",":",":","draft","version"],"summary":"Fetch information from the reaction HTML page","code_with_docstring":"def bioservices_get_reactants_from_reaction_identifier(self, reaction):\n    \"\"\"Fetch information from the reaction HTML page\n\n        .. note:: draft version\n        \"\"\"\n    res = self.http_get('http:\/\/www.reactome.org\/content\/detail\/%s' % reaction)\n    res = res.content\n    try:\n        reactants = [x for x in res.split('\\n') if '<title>' in x]\n        reactants = reactants[0].split('|')[1].strip().strip('<\/title>')\n    except Exception as err:\n        print('Could not interpret title', file=sys.stderr)\n        return res\n    if reactants.count(':') == 1:\n        reactants = reactants.split(':')\n    else:\n        pass\n    return reactants\n","code_tokens_py":[]}
{"repo":"raccoon","path":"raccoon\/\/series.pyclass:Series\/_insert_row","language":"python","sha":"e9f3888d8611fd60f42b07cae203f03e45a391ce","url":"raccoon\/\/series.pyclass:Series\/_insert_row","partition":"test","code":"def _insert_row(self, i, index):\n    \n        Insert a new row in the Series.\n\n        :param i: index location to insert\n        :param index: index value to insert into the index list\n        :return: nothing\n        \"\"\"\n    if i == len(self._index):\n        self._add_row(index)\n    else:\n        self._index.insert(i, index)\n        self._data.insert(i, None)\n","original_string":"def _insert_row(self, i, index):\n    \"\"\"\n        Insert a new row in the Series.\n\n        :param i: index location to insert\n        :param index: index value to insert into the index list\n        :return: nothing\n        \"\"\"\n    if i == len(self._index):\n        self._add_row(index)\n    else:\n        self._index.insert(i, index)\n        self._data.insert(i, None)\n","code_tokens":["def","_insert_row(self,","i,","index):\n","","","","\n","","","","","","","","Insert","a","new","row","in","the","Series.\n\n","","","","","","","",":param","i:","index","location","to","insert\n","","","","","","","",":param","index:","index","value","to","insert","into","the","index","list\n","","","","","","","",":return:","nothing\n","","","","","","","","\"\"\"\n","","","","if","i","==","len(self._index):\n","","","","","","","","self._add_row(index)\n","","","","else:\n","","","","","","","","self._index.insert(i,","index)\n","","","","","","","","self._data.insert(i,","None)\n"],"func_name":"raccoon\/class:Series\/_insert_row","docstring":"Insert a new row in the Series.\n\n:param i: index location to insert\n:param index: index value to insert into the index list\n:return: nothing","docstring_tokens":["Insert","a","new","row","in","the","Series",".",":","param","i",":","index","location","to","insert",":","param","index",":","index","value","to","insert","into","the","index","list",":","return",":","nothing"],"summary":"Insert a new row in the Series.","code_with_docstring":"def _insert_row(self, i, index):\n    \"\"\"\n        Insert a new row in the Series.\n\n        :param i: index location to insert\n        :param index: index value to insert into the index list\n        :return: nothing\n        \"\"\"\n    if i == len(self._index):\n        self._add_row(index)\n    else:\n        self._index.insert(i, index)\n        self._data.insert(i, None)\n","code_tokens_py":[]}
{"repo":"salmagundi-0.12.0","path":"salmagundi-0.12.0\/\/src\/salmagundi\/utils.pyfile:\/src\/salmagundi\/utils.py:function:sys_exit\/sys_exit","language":"python","sha":"12857a1d5833bb56a613b57f307748aa7d9f1d9a","url":"salmagundi-0.12.0\/\/src\/salmagundi\/utils.pyfile:\/src\/salmagundi\/utils.py:function:sys_exit\/sys_exit","partition":"test","code":"def sys_exit(arg=None, code=None, *, logger=None):\n    Exit from Python.\n\n    If ``code`` is not an integer, this function calls :func:`sys.exit` with\n    ``arg`` as its argument. Otherwise ``arg`` will be printed to\n    :data:`sys.stderr` if it is not ``None`` and :func:`sys.exit`\n    will be called with ``code`` as its argument.\n\n    If ``logger`` is set, the message, if any, will be logged with level\n    ``CRITICAL`` instead of printing it to :data:`sys.stderr`.\n\n    :param arg: see: :func:`sys.exit`\n    :param code: exit code (ignored if not an :class:`int`)\n    :type code: int or None\n    :param logger: a logger\n    :type logger: logging.Logger\n    :raises SystemExit:\n\n    .. versionadded:: 0.11.0\n    \"\"\"\n    if not isinstance(code, int):\n        code = None\n    if code is None:\n        if logger and arg is not None and not isinstance(arg, int):\n            logger.critical(str(arg))\n            sys.exit(1)\n        else:\n            sys.exit(arg)\n    elif arg is not None:\n        if logger:\n            logger.critical(str(arg))\n        else:\n            print(arg, file=sys.stderr)\n    sys.exit(code)\n","original_string":"def sys_exit(arg=None, code=None, *, logger=None):\n    \"\"\"Exit from Python.\n\n    If ``code`` is not an integer, this function calls :func:`sys.exit` with\n    ``arg`` as its argument. Otherwise ``arg`` will be printed to\n    :data:`sys.stderr` if it is not ``None`` and :func:`sys.exit`\n    will be called with ``code`` as its argument.\n\n    If ``logger`` is set, the message, if any, will be logged with level\n    ``CRITICAL`` instead of printing it to :data:`sys.stderr`.\n\n    :param arg: see: :func:`sys.exit`\n    :param code: exit code (ignored if not an :class:`int`)\n    :type code: int or None\n    :param logger: a logger\n    :type logger: logging.Logger\n    :raises SystemExit:\n\n    .. versionadded:: 0.11.0\n    \"\"\"\n    if not isinstance(code, int):\n        code = None\n    if code is None:\n        if logger and arg is not None and not isinstance(arg, int):\n            logger.critical(str(arg))\n            sys.exit(1)\n        else:\n            sys.exit(arg)\n    elif arg is not None:\n        if logger:\n            logger.critical(str(arg))\n        else:\n            print(arg, file=sys.stderr)\n    sys.exit(code)\n","code_tokens":["def","sys_exit(arg=None,","code=None,","*,","logger=None):\n","","","","Exit","from","Python.\n\n","","","","If","``code``","is","not","an","integer,","this","function","calls",":func:`sys.exit`","with\n","","","","``arg``","as","its","argument.","Otherwise","``arg``","will","be","printed","to\n","","","",":data:`sys.stderr`","if","it","is","not","``None``","and",":func:`sys.exit`\n","","","","will","be","called","with","``code``","as","its","argument.\n\n","","","","If","``logger``","is","set,","the","message,","if","any,","will","be","logged","with","level\n","","","","``CRITICAL``","instead","of","printing","it","to",":data:`sys.stderr`.\n\n","","","",":param","arg:","see:",":func:`sys.exit`\n","","","",":param","code:","exit","code","(ignored","if","not","an",":class:`int`)\n","","","",":type","code:","int","or","None\n","","","",":param","logger:","a","logger\n","","","",":type","logger:","logging.Logger\n","","","",":raises","SystemExit:\n\n","","","","..","versionadded::","0.11.0\n","","","","\"\"\"\n","","","","if","not","isinstance(code,","int):\n","","","","","","","","code","=","None\n","","","","if","code","is","None:\n","","","","","","","","if","logger","and","arg","is","not","None","and","not","isinstance(arg,","int):\n","","","","","","","","","","","","logger.critical(str(arg))\n","","","","","","","","","","","","sys.exit(1)\n","","","","","","","","else:\n","","","","","","","","","","","","sys.exit(arg)\n","","","","elif","arg","is","not","None:\n","","","","","","","","if","logger:\n","","","","","","","","","","","","logger.critical(str(arg))\n","","","","","","","","else:\n","","","","","","","","","","","","print(arg,","file=sys.stderr)\n","","","","sys.exit(code)\n"],"func_name":"salmagundi-0.12.0\/file:\/src\/salmagundi\/utils.py:function:sys_exit\/sys_exit","docstring":"Exit from Python.\n\nIf ``code`` is not an integer, this function calls :func:`sys.exit` with\n``arg`` as its argument. Otherwise ``arg`` will be printed to\n:data:`sys.stderr` if it is not ``None`` and :func:`sys.exit`\nwill be called with ``code`` as its argument.\n\nIf ``logger`` is set, the message, if any, will be logged with level\n``CRITICAL`` instead of printing it to :data:`sys.stderr`.\n\n:param arg: see: :func:`sys.exit`\n:param code: exit code (ignored if not an :class:`int`)\n:type code: int or None\n:param logger: a logger\n:type logger: logging.Logger\n:raises SystemExit:\n\n.. versionadded:: 0.11.0","docstring_tokens":["Exit","from","Python",".","If","`","`","code","`","`","is","not","an","integer",",","this","function","calls",":","func:`sys.exit","`","with","`","`","arg","`","`","as","its","argument",".","Otherwise","`","`","arg","`","`","will","be","printed","to",":","data:`sys.stderr","`","if","it","is","not","`","`","None","`","`","and",":","func:`sys.exit","`","will","be","called","with","`","`","code","`","`","as","its","argument",".","If","`","`","logger","`","`","is","set",",","the","message",",","if","any",",","will","be","logged","with","level","`","`","CRITICAL","`","`","instead","of","printing","it","to",":","data:`sys.stderr","`",".",":","param","arg",":","see",":",":","func:`sys.exit","`",":","param","code",":","exit","code","(","ignored","if","not","an",":","class:`int","`",")",":","type","code",":","int","or","None",":","param","logger",":","a","logger",":","type","logger",":","logging",".","Logger",":","raises","SystemExit",":","..","versionadded",":",":","0.11.0"],"summary":"Exit from Python.","code_with_docstring":"def sys_exit(arg=None, code=None, *, logger=None):\n    \"\"\"Exit from Python.\n\n    If ``code`` is not an integer, this function calls :func:`sys.exit` with\n    ``arg`` as its argument. Otherwise ``arg`` will be printed to\n    :data:`sys.stderr` if it is not ``None`` and :func:`sys.exit`\n    will be called with ``code`` as its argument.\n\n    If ``logger`` is set, the message, if any, will be logged with level\n    ``CRITICAL`` instead of printing it to :data:`sys.stderr`.\n\n    :param arg: see: :func:`sys.exit`\n    :param code: exit code (ignored if not an :class:`int`)\n    :type code: int or None\n    :param logger: a logger\n    :type logger: logging.Logger\n    :raises SystemExit:\n\n    .. versionadded:: 0.11.0\n    \"\"\"\n    if not isinstance(code, int):\n        code = None\n    if code is None:\n        if logger and arg is not None and not isinstance(arg, int):\n            logger.critical(str(arg))\n            sys.exit(1)\n        else:\n            sys.exit(arg)\n    elif arg is not None:\n        if logger:\n            logger.critical(str(arg))\n        else:\n            print(arg, file=sys.stderr)\n    sys.exit(code)\n","code_tokens_py":[]}
{"repo":"poisson_approval","path":"poisson_approval\/\/utils\/Util.pyfile:\/utils\/Util.py:function:product_dict\/product_dict","language":"python","sha":"f20540e481bcb5e04136c26bb648d10ee3c9c5d9","url":"poisson_approval\/\/utils\/Util.pyfile:\/utils\/Util.py:function:product_dict\/product_dict","partition":"test","code":"def product_dict(d_key_possible_values):\n    Iterable: product of dictionaries.\n\n    Source: https:\/\/stackoverflow.com\/questions\/5228158\/cartesian-product-of-a-dictionary-of-lists.\n\n    Parameters\n    ----------\n    d_key_possible_values\n        To each key, associate a list of possible values (cf. example below).\n\n    Yields\n    ------\n    dict\n        A dictionary that, to each key, associates one of its possible values. All elements of the Cartesian product\n        are returned this way.\n\n    Examples\n    --------\n        >>> d_key_possible_values = {'foo': [0, 1], 'bar': ['a', 'b', 'c']}\n        >>> for d_key_value in product_dict(d_key_possible_values):\n        ...     print(d_key_value)\n        {'foo': 0, 'bar': 'a'}\n        {'foo': 0, 'bar': 'b'}\n        {'foo': 0, 'bar': 'c'}\n        {'foo': 1, 'bar': 'a'}\n        {'foo': 1, 'bar': 'b'}\n        {'foo': 1, 'bar': 'c'}\n    \"\"\"\n    keys = d_key_possible_values.keys()\n    vals = d_key_possible_values.values()\n    for instance in itertools.product(*vals):\n        yield dict(zip(keys, instance))\n","original_string":"def product_dict(d_key_possible_values):\n    \"\"\"Iterable: product of dictionaries.\n\n    Source: https:\/\/stackoverflow.com\/questions\/5228158\/cartesian-product-of-a-dictionary-of-lists.\n\n    Parameters\n    ----------\n    d_key_possible_values\n        To each key, associate a list of possible values (cf. example below).\n\n    Yields\n    ------\n    dict\n        A dictionary that, to each key, associates one of its possible values. All elements of the Cartesian product\n        are returned this way.\n\n    Examples\n    --------\n        >>> d_key_possible_values = {'foo': [0, 1], 'bar': ['a', 'b', 'c']}\n        >>> for d_key_value in product_dict(d_key_possible_values):\n        ...     print(d_key_value)\n        {'foo': 0, 'bar': 'a'}\n        {'foo': 0, 'bar': 'b'}\n        {'foo': 0, 'bar': 'c'}\n        {'foo': 1, 'bar': 'a'}\n        {'foo': 1, 'bar': 'b'}\n        {'foo': 1, 'bar': 'c'}\n    \"\"\"\n    keys = d_key_possible_values.keys()\n    vals = d_key_possible_values.values()\n    for instance in itertools.product(*vals):\n        yield dict(zip(keys, instance))\n","code_tokens":["def","product_dict(d_key_possible_values):\n","","","","Iterable:","product","of","dictionaries.\n\n","","","","Source:","https:\/\/stackoverflow.com\/questions\/5228158\/cartesian-product-of-a-dictionary-of-lists.\n\n","","","","Parameters\n","","","","----------\n","","","","d_key_possible_values\n","","","","","","","","To","each","key,","associate","a","list","of","possible","values","(cf.","example","below).\n\n","","","","Yields\n","","","","------\n","","","","dict\n","","","","","","","","A","dictionary","that,","to","each","key,","associates","one","of","its","possible","values.","All","elements","of","the","Cartesian","product\n","","","","","","","","are","returned","this","way.\n\n","","","","Examples\n","","","","--------\n","","","","","","","",">>>","d_key_possible_values","=","{'foo':","[0,","1],","'bar':","['a',","'b',","'c']}\n","","","","","","","",">>>","for","d_key_value","in","product_dict(d_key_possible_values):\n","","","","","","","","...","","","","","print(d_key_value)\n","","","","","","","","{'foo':","0,","'bar':","'a'}\n","","","","","","","","{'foo':","0,","'bar':","'b'}\n","","","","","","","","{'foo':","0,","'bar':","'c'}\n","","","","","","","","{'foo':","1,","'bar':","'a'}\n","","","","","","","","{'foo':","1,","'bar':","'b'}\n","","","","","","","","{'foo':","1,","'bar':","'c'}\n","","","","\"\"\"\n","","","","keys","=","d_key_possible_values.keys()\n","","","","vals","=","d_key_possible_values.values()\n","","","","for","instance","in","itertools.product(*vals):\n","","","","","","","","yield","dict(zip(keys,","instance))\n"],"func_name":"poisson_approval\/file:\/utils\/Util.py:function:product_dict\/product_dict","docstring":"Iterable: product of dictionaries.\n\nSource: https:\/\/stackoverflow.com\/questions\/5228158\/cartesian-product-of-a-dictionary-of-lists.\n\nParameters\n----------\nd_key_possible_values\n    To each key, associate a list of possible values (cf. example below).\n\nYields\n------\ndict\n    A dictionary that, to each key, associates one of its possible values. All elements of the Cartesian product\n    are returned this way.\n\nExamples\n--------\n    >>> d_key_possible_values = {'foo': [0, 1], 'bar': ['a', 'b', 'c']}\n    >>> for d_key_value in product_dict(d_key_possible_values):\n    ...     print(d_key_value)\n    {'foo': 0, 'bar': 'a'}\n    {'foo': 0, 'bar': 'b'}\n    {'foo': 0, 'bar': 'c'}\n    {'foo': 1, 'bar': 'a'}\n    {'foo': 1, 'bar': 'b'}\n    {'foo': 1, 'bar': 'c'}","docstring_tokens":["Iterable",":","product","of","dictionaries",".","Source",":","https:\/\/stackoverflow.com\/questions\/5228158\/cartesian-product-of-a-dictionary-of-lists",".","Parameters","----------","d_key_possible_values","To","each","key",",","associate","a","list","of","possible","values","(","cf",".","example","below",")",".","Yields","------","dict","A","dictionary","that",",","to","each","key",",","associates","one","of","its","possible","values",".","All","elements","of","the","Cartesian","product","are","returned","this","way",".","Examples","--------",">",">",">","d_key_possible_values","=","{","'","foo","'",":","[","0",",","1","]",",","'","bar","'",":","[","'","a","'",",","'","b","'",",","'","c","'","]","}",">",">",">","for","d_key_value","in","product_dict(d_key_possible_values",")",":","...","print(d_key_value",")","{","'","foo","'",":","0",",","'","bar","'",":","'","a","'","}","{","'","foo","'",":","0",",","'","bar","'",":","'","b","'","}","{","'","foo","'",":","0",",","'","bar","'",":","'","c","'","}","{","'","foo","'",":","1",",","'","bar","'",":","'","a","'","}","{","'","foo","'",":","1",",","'","bar","'",":","'","b","'","}","{","'","foo","'",":","1",",","'","bar","'",":","'","c","'","}"],"summary":"Iterable: product of dictionaries.","code_with_docstring":"def product_dict(d_key_possible_values):\n    \"\"\"Iterable: product of dictionaries.\n\n    Source: https:\/\/stackoverflow.com\/questions\/5228158\/cartesian-product-of-a-dictionary-of-lists.\n\n    Parameters\n    ----------\n    d_key_possible_values\n        To each key, associate a list of possible values (cf. example below).\n\n    Yields\n    ------\n    dict\n        A dictionary that, to each key, associates one of its possible values. All elements of the Cartesian product\n        are returned this way.\n\n    Examples\n    --------\n        >>> d_key_possible_values = {'foo': [0, 1], 'bar': ['a', 'b', 'c']}\n        >>> for d_key_value in product_dict(d_key_possible_values):\n        ...     print(d_key_value)\n        {'foo': 0, 'bar': 'a'}\n        {'foo': 0, 'bar': 'b'}\n        {'foo': 0, 'bar': 'c'}\n        {'foo': 1, 'bar': 'a'}\n        {'foo': 1, 'bar': 'b'}\n        {'foo': 1, 'bar': 'c'}\n    \"\"\"\n    keys = d_key_possible_values.keys()\n    vals = d_key_possible_values.values()\n    for instance in itertools.product(*vals):\n        yield dict(zip(keys, instance))\n","code_tokens_py":[]}
{"repo":"mongosql","path":"mongosql\/\/bag.pyfile:\/bag.py:function:_get_model_properties\/_get_model_properties","language":"python","sha":"76ff82853bc688ec261f4d2e64caf39fb46d372b","url":"mongosql\/\/bag.pyfile:\/bag.py:function:_get_model_properties\/_get_model_properties","partition":"test","code":"def _get_model_properties(model, ins):\n     \"\"\"\n    return {name: None for name in dir(model) if not name.startswith('_') and\n        isinstance(getattr(model, name), property)}\n","original_string":"def _get_model_properties(model, ins):\n    \"\"\" Get a dict of model properties (calculated properties) \"\"\"\n    return {name: None for name in dir(model) if not name.startswith('_') and\n        isinstance(getattr(model, name), property)}\n","code_tokens":["def","_get_model_properties(model,","ins):\n","","","","","\"\"\"\n","","","","return","{name:","None","for","name","in","dir(model)","if","not","name.startswith('_')","and\n","","","","","","","","isinstance(getattr(model,","name),","property)}\n"],"func_name":"mongosql\/file:\/bag.py:function:_get_model_properties\/_get_model_properties","docstring":"Get a dict of model properties (calculated properties) ","docstring_tokens":["Get","a","dict","of","model","properties","(","calculated","properties",")"],"summary":"Get a dict of model properties (calculated properties) ","code_with_docstring":"def _get_model_properties(model, ins):\n    \"\"\" Get a dict of model properties (calculated properties) \"\"\"\n    return {name: None for name in dir(model) if not name.startswith('_') and\n        isinstance(getattr(model, name), property)}\n","code_tokens_py":[]}
{"repo":"ds100-6.0.0.dev0","path":"ds100-6.0.0.dev0\/\/notebook\/base\/zmqhandlers.pyclass:WebSocketMixin\/send_ping","language":"python","sha":"8978b20976393b2082868f6bc37e51b3a7f24ed8","url":"ds100-6.0.0.dev0\/\/notebook\/base\/zmqhandlers.pyclass:WebSocketMixin\/send_ping","partition":"test","code":"def send_ping(self):\n    \"\"\"\n    if self.stream.closed() and self.ping_callback is not None:\n        self.ping_callback.stop()\n        return\n    now = ioloop.IOLoop.current().time()\n    since_last_pong = 1000.0 * (now - self.last_pong)\n    since_last_ping = 1000.0 * (now - self.last_ping)\n    if (since_last_ping < 2 * self.ping_interval and since_last_pong > self\n        .ping_timeout):\n        self.log.warning('WebSocket ping timeout after %i ms.', since_last_pong\n            )\n        self.close()\n        return\n    self.ping(b'')\n    self.last_ping = now\n","original_string":"def send_ping(self):\n    \"\"\"send a ping to keep the websocket alive\"\"\"\n    if self.stream.closed() and self.ping_callback is not None:\n        self.ping_callback.stop()\n        return\n    now = ioloop.IOLoop.current().time()\n    since_last_pong = 1000.0 * (now - self.last_pong)\n    since_last_ping = 1000.0 * (now - self.last_ping)\n    if (since_last_ping < 2 * self.ping_interval and since_last_pong > self\n        .ping_timeout):\n        self.log.warning('WebSocket ping timeout after %i ms.', since_last_pong\n            )\n        self.close()\n        return\n    self.ping(b'')\n    self.last_ping = now\n","code_tokens":["def","send_ping(self):\n","","","","\"\"\"\n","","","","if","self.stream.closed()","and","self.ping_callback","is","not","None:\n","","","","","","","","self.ping_callback.stop()\n","","","","","","","","return\n","","","","now","=","ioloop.IOLoop.current().time()\n","","","","since_last_pong","=","1000.0","*","(now","-","self.last_pong)\n","","","","since_last_ping","=","1000.0","*","(now","-","self.last_ping)\n","","","","if","(since_last_ping","<","2","*","self.ping_interval","and","since_last_pong",">","self\n","","","","","","","",".ping_timeout):\n","","","","","","","","self.log.warning('WebSocket","ping","timeout","after","%i","ms.',","since_last_pong\n","","","","","","","","","","","",")\n","","","","","","","","self.close()\n","","","","","","","","return\n","","","","self.ping(b'')\n","","","","self.last_ping","=","now\n"],"func_name":"ds100-6.0.0.dev0\/class:WebSocketMixin\/send_ping","docstring":"send a ping to keep the websocket alive","docstring_tokens":["send","a","ping","to","keep","the","websocket","alive"],"summary":"send a ping to keep the websocket alive","code_with_docstring":"def send_ping(self):\n    \"\"\"send a ping to keep the websocket alive\"\"\"\n    if self.stream.closed() and self.ping_callback is not None:\n        self.ping_callback.stop()\n        return\n    now = ioloop.IOLoop.current().time()\n    since_last_pong = 1000.0 * (now - self.last_pong)\n    since_last_ping = 1000.0 * (now - self.last_ping)\n    if (since_last_ping < 2 * self.ping_interval and since_last_pong > self\n        .ping_timeout):\n        self.log.warning('WebSocket ping timeout after %i ms.', since_last_pong\n            )\n        self.close()\n        return\n    self.ping(b'')\n    self.last_ping = now\n","code_tokens_py":[]}
{"repo":"kivy","path":"kivy\/\/core\/image\/img_gif.pyfile:\/core\/image\/img_gif.py:function:get_bits\/get_bits","language":"python","sha":"4dd4a7d8c84c44dd4b45705850bcbd6272862872","url":"kivy\/\/core\/image\/img_gif.pyfile:\/core\/image\/img_gif.py:function:get_bits\/get_bits","partition":"test","code":"def get_bits(flags, reverse=False, bits=8):\n    \"\"\"\n    mybits = (1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048)[:bits]\n    rev_num = 1\n    if reverse:\n        rev_num = -1\n    ret = array('B')\n    ret_append = ret.append\n    for bit in mybits[::rev_num]:\n        ret_append(flags & bit != 0)\n    return ret\n","original_string":"def get_bits(flags, reverse=False, bits=8):\n    \"\"\"return a list with $bits items, one for each enabled bit\"\"\"\n    mybits = (1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048)[:bits]\n    rev_num = 1\n    if reverse:\n        rev_num = -1\n    ret = array('B')\n    ret_append = ret.append\n    for bit in mybits[::rev_num]:\n        ret_append(flags & bit != 0)\n    return ret\n","code_tokens":["def","get_bits(flags,","reverse=False,","bits=8):\n","","","","\"\"\"\n","","","","mybits","=","(1,","2,","4,","8,","16,","32,","64,","128,","256,","512,","1024,","2048)[:bits]\n","","","","rev_num","=","1\n","","","","if","reverse:\n","","","","","","","","rev_num","=","-1\n","","","","ret","=","array('B')\n","","","","ret_append","=","ret.append\n","","","","for","bit","in","mybits[::rev_num]:\n","","","","","","","","ret_append(flags","&","bit","!=","0)\n","","","","return","ret\n"],"func_name":"kivy\/file:\/core\/image\/img_gif.py:function:get_bits\/get_bits","docstring":"return a list with $bits items, one for each enabled bit","docstring_tokens":["return","a","list","with","$","bits","items",",","one","for","each","enabled","bit"],"summary":"return a list with $bits items, one for each enabled bit","code_with_docstring":"def get_bits(flags, reverse=False, bits=8):\n    \"\"\"return a list with $bits items, one for each enabled bit\"\"\"\n    mybits = (1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048)[:bits]\n    rev_num = 1\n    if reverse:\n        rev_num = -1\n    ret = array('B')\n    ret_append = ret.append\n    for bit in mybits[::rev_num]:\n        ret_append(flags & bit != 0)\n    return ret\n","code_tokens_py":[]}
{"repo":"delphixpy-1.11.1.0","path":"delphixpy-1.11.1.0\/\/delphixpy\/v1_11_0\/web\/objects\/Action.pyclass:Action\/origin_ip","language":"python","sha":"c505d7ab7013d6f28cd9d11f02a144827725c315","url":"delphixpy-1.11.1.0\/\/delphixpy\/v1_11_0\/web\/objects\/Action.pyclass:Action\/origin_ip","partition":"test","code":"@property\ndef origin_ip(self):\n    \n        Network address used to initiate the action.\n\n        :rtype: ``TEXT_TYPE``\n        \"\"\"\n    return self._origin_ip[0]\n","original_string":"@property\ndef origin_ip(self):\n    \"\"\"\n        Network address used to initiate the action.\n\n        :rtype: ``TEXT_TYPE``\n        \"\"\"\n    return self._origin_ip[0]\n","code_tokens":["@property\ndef","origin_ip(self):\n","","","","\n","","","","","","","","Network","address","used","to","initiate","the","action.\n\n","","","","","","","",":rtype:","``TEXT_TYPE``\n","","","","","","","","\"\"\"\n","","","","return","self._origin_ip[0]\n"],"func_name":"delphixpy-1.11.1.0\/class:Action\/origin_ip","docstring":"Network address used to initiate the action.\n\n:rtype: ``TEXT_TYPE``","docstring_tokens":["Network","address","used","to","initiate","the","action",".",":","rtype",":","`","`","TEXT_TYPE","`","`"],"summary":"Network address used to initiate the action.","code_with_docstring":"@property\ndef origin_ip(self):\n    \"\"\"\n        Network address used to initiate the action.\n\n        :rtype: ``TEXT_TYPE``\n        \"\"\"\n    return self._origin_ip[0]\n","code_tokens_py":[]}
{"repo":"inkamusic","path":"inkamusic\/\/settings.pyclass:Settings\/__set_selected_instrumentation","language":"python","sha":"8a58e9d56cf24c392a2f51fc0525df9db7ecc0f1","url":"inkamusic\/\/settings.pyclass:Settings\/__set_selected_instrumentation","partition":"test","code":"def __set_selected_instrumentation(self, txt):\n    \"\"\"\n    self.comp_data['selected_instrumentation'] = get_instrumentation(txt)\n","original_string":"def __set_selected_instrumentation(self, txt):\n    \"\"\"sets instrument id list of selected instrumentation\"\"\"\n    self.comp_data['selected_instrumentation'] = get_instrumentation(txt)\n","code_tokens":["def","__set_selected_instrumentation(self,","txt):\n","","","","\"\"\"\n","","","","self.comp_data['selected_instrumentation']","=","get_instrumentation(txt)\n"],"func_name":"inkamusic\/class:Settings\/__set_selected_instrumentation","docstring":"sets instrument id list of selected instrumentation","docstring_tokens":["sets","instrument","i","d","list","of","selected","instrumentation"],"summary":"sets instrument id list of selected instrumentation","code_with_docstring":"def __set_selected_instrumentation(self, txt):\n    \"\"\"sets instrument id list of selected instrumentation\"\"\"\n    self.comp_data['selected_instrumentation'] = get_instrumentation(txt)\n","code_tokens_py":[]}
{"repo":"strkernel","path":"strkernel\/\/lib\/MismatchTrie.pyclass:MismatchTrie\/__init__","language":"python","sha":"2017262aa2d38f512348e1c07437de82e519c5c1","url":"strkernel\/\/lib\/MismatchTrie.pyclass:MismatchTrie\/__init__","partition":"test","code":"def __init__(self, label=None, parent=None):\n    \n        label: int, optional (default None), node label\n        parent: `Trie` instance, optional (default None), node's parent\n        \"\"\"\n    self.label = label\n    self.level = 0\n    self.children = {}\n    self.full_label = ''\n    self.kmers = {}\n    self.parent = parent\n    if not parent is None:\n        parent.add_child(self)\n","original_string":"def __init__(self, label=None, parent=None):\n    \"\"\"\n        label: int, optional (default None), node label\n        parent: `Trie` instance, optional (default None), node's parent\n        \"\"\"\n    self.label = label\n    self.level = 0\n    self.children = {}\n    self.full_label = ''\n    self.kmers = {}\n    self.parent = parent\n    if not parent is None:\n        parent.add_child(self)\n","code_tokens":["def","__init__(self,","label=None,","parent=None):\n","","","","\n","","","","","","","","label:","int,","optional","(default","None),","node","label\n","","","","","","","","parent:","`Trie`","instance,","optional","(default","None),","node's","parent\n","","","","","","","","\"\"\"\n","","","","self.label","=","label\n","","","","self.level","=","0\n","","","","self.children","=","{}\n","","","","self.full_label","=","''\n","","","","self.kmers","=","{}\n","","","","self.parent","=","parent\n","","","","if","not","parent","is","None:\n","","","","","","","","parent.add_child(self)\n"],"func_name":"strkernel\/class:MismatchTrie\/__init__","docstring":"label: int, optional (default None), node label\nparent: `Trie` instance, optional (default None), node's parent","docstring_tokens":["label",":","int",",","optional","(","default","None",")",",","node","label","parent",":","`","Trie","`","instance",",","optional","(","default","None",")",",","node","'s","parent"],"summary":"label: int, optional (default None), node label","code_with_docstring":"def __init__(self, label=None, parent=None):\n    \"\"\"\n        label: int, optional (default None), node label\n        parent: `Trie` instance, optional (default None), node's parent\n        \"\"\"\n    self.label = label\n    self.level = 0\n    self.children = {}\n    self.full_label = ''\n    self.kmers = {}\n    self.parent = parent\n    if not parent is None:\n        parent.add_child(self)\n","code_tokens_py":[]}
{"repo":"monero_glue","path":"monero_glue\/\/protocol\/tsx_sign_builder.pyclass:TTransactionBuilder\/_s6_serialize_ecdh","language":"python","sha":"80dadfeda43f50245b1ffe0ee8d497bf0a69695f","url":"monero_glue\/\/protocol\/tsx_sign_builder.pyclass:TTransactionBuilder\/_s6_serialize_ecdh","partition":"test","code":"def _s6_serialize_ecdh(self, ecdh_info, v2=False):\n    \n        Serializes ECDH according to the current format defined by the hard fork version\n        or the signature format respectively.\n        \"\"\"\n    if v2:\n        ecdh_info_bin = bytearray(8)\n        ecdh_info_bin[:] = ecdh_info.amount[0:8]\n        return ecdh_info_bin\n    else:\n        ecdh_info_bin = bytearray(64)\n        utils.memcpy(ecdh_info_bin, 0, ecdh_info.mask, 0, 32)\n        utils.memcpy(ecdh_info_bin, 32, ecdh_info.amount, 0, 32)\n        return ecdh_info_bin\n","original_string":"def _s6_serialize_ecdh(self, ecdh_info, v2=False):\n    \"\"\"\n        Serializes ECDH according to the current format defined by the hard fork version\n        or the signature format respectively.\n        \"\"\"\n    if v2:\n        ecdh_info_bin = bytearray(8)\n        ecdh_info_bin[:] = ecdh_info.amount[0:8]\n        return ecdh_info_bin\n    else:\n        ecdh_info_bin = bytearray(64)\n        utils.memcpy(ecdh_info_bin, 0, ecdh_info.mask, 0, 32)\n        utils.memcpy(ecdh_info_bin, 32, ecdh_info.amount, 0, 32)\n        return ecdh_info_bin\n","code_tokens":["def","_s6_serialize_ecdh(self,","ecdh_info,","v2=False):\n","","","","\n","","","","","","","","Serializes","ECDH","according","to","the","current","format","defined","by","the","hard","fork","version\n","","","","","","","","or","the","signature","format","respectively.\n","","","","","","","","\"\"\"\n","","","","if","v2:\n","","","","","","","","ecdh_info_bin","=","bytearray(8)\n","","","","","","","","ecdh_info_bin[:]","=","ecdh_info.amount[0:8]\n","","","","","","","","return","ecdh_info_bin\n","","","","else:\n","","","","","","","","ecdh_info_bin","=","bytearray(64)\n","","","","","","","","utils.memcpy(ecdh_info_bin,","0,","ecdh_info.mask,","0,","32)\n","","","","","","","","utils.memcpy(ecdh_info_bin,","32,","ecdh_info.amount,","0,","32)\n","","","","","","","","return","ecdh_info_bin\n"],"func_name":"monero_glue\/class:TTransactionBuilder\/_s6_serialize_ecdh","docstring":"Serializes ECDH according to the current format defined by the hard fork version\nor the signature format respectively.","docstring_tokens":["Serializes","ECDH","according","to","the","current","format","defined","by","the","hard","fork","version","or","the","signature","format","respectively","."],"summary":"Serializes ECDH according to the current format defined by the hard fork version","code_with_docstring":"def _s6_serialize_ecdh(self, ecdh_info, v2=False):\n    \"\"\"\n        Serializes ECDH according to the current format defined by the hard fork version\n        or the signature format respectively.\n        \"\"\"\n    if v2:\n        ecdh_info_bin = bytearray(8)\n        ecdh_info_bin[:] = ecdh_info.amount[0:8]\n        return ecdh_info_bin\n    else:\n        ecdh_info_bin = bytearray(64)\n        utils.memcpy(ecdh_info_bin, 0, ecdh_info.mask, 0, 32)\n        utils.memcpy(ecdh_info_bin, 32, ecdh_info.amount, 0, 32)\n        return ecdh_info_bin\n","code_tokens_py":[]}
{"repo":"eric6","path":"eric6\/\/VCS\/StatusMonitorThread.pyclass:VcsStatusMonitorThread\/getInterval","language":"python","sha":"dcab4784dee53ee28c80460808d78a2f3214de74","url":"eric6\/\/VCS\/StatusMonitorThread.pyclass:VcsStatusMonitorThread\/getInterval","partition":"test","code":"def getInterval(self):\n    \n        Public method to get the monitor interval.\n        \n        @return interval in seconds (integer)\n        \"\"\"\n    return self.interval\n","original_string":"def getInterval(self):\n    \"\"\"\n        Public method to get the monitor interval.\n        \n        @return interval in seconds (integer)\n        \"\"\"\n    return self.interval\n","code_tokens":["def","getInterval(self):\n","","","","\n","","","","","","","","Public","method","to","get","the","monitor","interval.\n","","","","","","","","\n","","","","","","","","@return","interval","in","seconds","(integer)\n","","","","","","","","\"\"\"\n","","","","return","self.interval\n"],"func_name":"eric6\/class:VcsStatusMonitorThread\/getInterval","docstring":"Public method to get the monitor interval.\n\n@return interval in seconds (integer)","docstring_tokens":["Public","method","to","get","the","monitor","interval",".","@return","interval","in","seconds","(","integer",")"],"summary":"Public method to get the monitor interval.","code_with_docstring":"def getInterval(self):\n    \"\"\"\n        Public method to get the monitor interval.\n        \n        @return interval in seconds (integer)\n        \"\"\"\n    return self.interval\n","code_tokens_py":[]}
{"repo":"atalaya","path":"atalaya\/\/parameters.pyclass:Parameters\/update","language":"python","sha":"69a1c338bd1916a1523d26368c1fa1e04f90b6b9","url":"atalaya\/\/parameters.pyclass:Parameters\/update","partition":"test","code":"def update(self, path):\n    \"\"\"\n    with open(pjoin(path, 'params.json')) as f:\n        params = json.load(f)\n        params[list(self.__dict__.keys())[list(self.__dict__.values()).\n            index(path)]] = path\n        self.__dict__.update(params)\n","original_string":"def update(self, path):\n    \"\"\"Loads parameters from json file\"\"\"\n    with open(pjoin(path, 'params.json')) as f:\n        params = json.load(f)\n        params[list(self.__dict__.keys())[list(self.__dict__.values()).\n            index(path)]] = path\n        self.__dict__.update(params)\n","code_tokens":["def","update(self,","path):\n","","","","\"\"\"\n","","","","with","open(pjoin(path,","'params.json'))","as","f:\n","","","","","","","","params","=","json.load(f)\n","","","","","","","","params[list(self.__dict__.keys())[list(self.__dict__.values()).\n","","","","","","","","","","","","index(path)]]","=","path\n","","","","","","","","self.__dict__.update(params)\n"],"func_name":"atalaya\/class:Parameters\/update","docstring":"Loads parameters from json file","docstring_tokens":["Loads","parameters","from","json","file"],"summary":"Loads parameters from json file","code_with_docstring":"def update(self, path):\n    \"\"\"Loads parameters from json file\"\"\"\n    with open(pjoin(path, 'params.json')) as f:\n        params = json.load(f)\n        params[list(self.__dict__.keys())[list(self.__dict__.values()).\n            index(path)]] = path\n        self.__dict__.update(params)\n","code_tokens_py":[]}
{"repo":"PyNaCl-1.3.0","path":"PyNaCl-1.3.0\/\/src\/nacl\/signing.pyclass:SignedMessage\/message","language":"python","sha":"ad17e808eb7f251de94b4c5417860a753895d0bb","url":"PyNaCl-1.3.0\/\/src\/nacl\/signing.pyclass:SignedMessage\/message","partition":"test","code":"@property\ndef message(self):\n    \n        \n        \"\"\"\n    return self._message\n","original_string":"@property\ndef message(self):\n    \"\"\"\n        The message contained within the :class:`SignedMessage`.\n        \"\"\"\n    return self._message\n","code_tokens":["@property\ndef","message(self):\n","","","","\n","","","","","","","","\n","","","","","","","","\"\"\"\n","","","","return","self._message\n"],"func_name":"PyNaCl-1.3.0\/class:SignedMessage\/message","docstring":"The message contained within the :class:`SignedMessage`.","docstring_tokens":["The","message","contained","within","the",":","class:`SignedMessage","`","."],"summary":"The message contained within the :class:`SignedMessage`.","code_with_docstring":"@property\ndef message(self):\n    \"\"\"\n        The message contained within the :class:`SignedMessage`.\n        \"\"\"\n    return self._message\n","code_tokens_py":[]}
{"repo":"lawu","path":"lawu\/\/util\/flags.pyclass:Flags\/unpack","language":"python","sha":"7833d2b71a7b6b8671b3375fe04e4c5d6af35062","url":"lawu\/\/util\/flags.pyclass:Flags\/unpack","partition":"test","code":"def unpack(self, source):\n    \n        \n        \"\"\"\n    self._value = self._cache.unpack(source)[0]\n","original_string":"def unpack(self, source):\n    \"\"\"\n        A shortcut for `struct.unpack(flag.binary_format, <bytes>)`.\n        \"\"\"\n    self._value = self._cache.unpack(source)[0]\n","code_tokens":["def","unpack(self,","source):\n","","","","\n","","","","","","","","\n","","","","","","","","\"\"\"\n","","","","self._value","=","self._cache.unpack(source)[0]\n"],"func_name":"lawu\/class:Flags\/unpack","docstring":"A shortcut for `struct.unpack(flag.binary_format, <bytes>)`.","docstring_tokens":["A","shortcut","for","`","struct.unpack(flag.binary_format",",","<","bytes",">",")","`","."],"summary":"A shortcut for `struct.unpack(flag.binary_format, <bytes>)`.","code_with_docstring":"def unpack(self, source):\n    \"\"\"\n        A shortcut for `struct.unpack(flag.binary_format, <bytes>)`.\n        \"\"\"\n    self._value = self._cache.unpack(source)[0]\n","code_tokens_py":[]}
{"repo":"legend_assistant-1.0.0","path":"legend_assistant-1.0.0\/\/legendassistant\/legend_assistant.pyfile:\/legendassistant\/legend_assistant.py:function:set_single\/set_single","language":"python","sha":"f8971be570afc3d40062b4460b53685e804d7a57","url":"legend_assistant-1.0.0\/\/legendassistant\/legend_assistant.pyfile:\/legendassistant\/legend_assistant.py:function:set_single\/set_single","partition":"test","code":"def set_single(func):\n    \n    \u88c5\u9970\u5668\uff0c\u9501\u5b9a\u6bcf\u4e2a\u52a8\u4f5c\uff0c\u9632\u6b62\u5e76\u53d1\u6267\u884c\n    :param func: \u63a5\u6536\u52a8\u4f5c\u51fd\u6570\n    :return: \u8fd4\u56de\u52a0\u9501\u540e\u7684\u52a8\u4f5c\n    \"\"\"\n\n    def wrapper(*args, **kwargs):\n        global action_name2, action_lock2\n        now = datetime.datetime.now()\n        time_consuming = (now - action_lock2[2]).seconds\n        if time_consuming < 300:\n            for n in range(3):\n                if action_lock2[0]:\n                    print('\u6b63\u5728\u6267\u884c:%s\uff0c1\u79d2\u540e\u518d\u6b21\u5c1d\u8bd5%d:%s' % (action_lock2[1], n + 1,\n                        func.__name__))\n                    if n == 2:\n                        print('%s\u6b63\u5728\u6267\u884c\uff0c\u653e\u5f03\u6267\u884c:%s' % (action_lock2[1], func.\n                            __name__))\n                        return None\n                    time.sleep(1)\n                else:\n                    break\n        action_lock2[0] = True\n        action_lock2[1] = func.__name__\n        action_lock2[2] = now\n        inner = func(*args, **kwargs)\n        action_lock2[0] = False\n        wrapper.__name__ = func.__name__\n        return inner\n    return wrapper\n","original_string":"def set_single(func):\n    \"\"\"\n    \u88c5\u9970\u5668\uff0c\u9501\u5b9a\u6bcf\u4e2a\u52a8\u4f5c\uff0c\u9632\u6b62\u5e76\u53d1\u6267\u884c\n    :param func: \u63a5\u6536\u52a8\u4f5c\u51fd\u6570\n    :return: \u8fd4\u56de\u52a0\u9501\u540e\u7684\u52a8\u4f5c\n    \"\"\"\n\n    def wrapper(*args, **kwargs):\n        global action_name2, action_lock2\n        now = datetime.datetime.now()\n        time_consuming = (now - action_lock2[2]).seconds\n        if time_consuming < 300:\n            for n in range(3):\n                if action_lock2[0]:\n                    print('\u6b63\u5728\u6267\u884c:%s\uff0c1\u79d2\u540e\u518d\u6b21\u5c1d\u8bd5%d:%s' % (action_lock2[1], n + 1,\n                        func.__name__))\n                    if n == 2:\n                        print('%s\u6b63\u5728\u6267\u884c\uff0c\u653e\u5f03\u6267\u884c:%s' % (action_lock2[1], func.\n                            __name__))\n                        return None\n                    time.sleep(1)\n                else:\n                    break\n        action_lock2[0] = True\n        action_lock2[1] = func.__name__\n        action_lock2[2] = now\n        inner = func(*args, **kwargs)\n        action_lock2[0] = False\n        wrapper.__name__ = func.__name__\n        return inner\n    return wrapper\n","code_tokens":["def","set_single(func):\n","","","","\n","","","","\u88c5\u9970\u5668\uff0c\u9501\u5b9a\u6bcf\u4e2a\u52a8\u4f5c\uff0c\u9632\u6b62\u5e76\u53d1\u6267\u884c\n","","","",":param","func:","\u63a5\u6536\u52a8\u4f5c\u51fd\u6570\n","","","",":return:","\u8fd4\u56de\u52a0\u9501\u540e\u7684\u52a8\u4f5c\n","","","","\"\"\"\n\n","","","","def","wrapper(*args,","**kwargs):\n","","","","","","","","global","action_name2,","action_lock2\n","","","","","","","","now","=","datetime.datetime.now()\n","","","","","","","","time_consuming","=","(now","-","action_lock2[2]).seconds\n","","","","","","","","if","time_consuming","<","300:\n","","","","","","","","","","","","for","n","in","range(3):\n","","","","","","","","","","","","","","","","if","action_lock2[0]:\n","","","","","","","","","","","","","","","","","","","","print('\u6b63\u5728\u6267\u884c:%s\uff0c1\u79d2\u540e\u518d\u6b21\u5c1d\u8bd5%d:%s'","%","(action_lock2[1],","n","+","1,\n","","","","","","","","","","","","","","","","","","","","","","","","func.__name__))\n","","","","","","","","","","","","","","","","","","","","if","n","==","2:\n","","","","","","","","","","","","","","","","","","","","","","","","print('%s\u6b63\u5728\u6267\u884c\uff0c\u653e\u5f03\u6267\u884c:%s'","%","(action_lock2[1],","func.\n","","","","","","","","","","","","","","","","","","","","","","","","","","","","__name__))\n","","","","","","","","","","","","","","","","","","","","","","","","return","None\n","","","","","","","","","","","","","","","","","","","","time.sleep(1)\n","","","","","","","","","","","","","","","","else:\n","","","","","","","","","","","","","","","","","","","","break\n","","","","","","","","action_lock2[0]","=","True\n","","","","","","","","action_lock2[1]","=","func.__name__\n","","","","","","","","action_lock2[2]","=","now\n","","","","","","","","inner","=","func(*args,","**kwargs)\n","","","","","","","","action_lock2[0]","=","False\n","","","","","","","","wrapper.__name__","=","func.__name__\n","","","","","","","","return","inner\n","","","","return","wrapper\n"],"func_name":"legend_assistant-1.0.0\/file:\/legendassistant\/legend_assistant.py:function:set_single\/set_single","docstring":"\u88c5\u9970\u5668\uff0c\u9501\u5b9a\u6bcf\u4e2a\u52a8\u4f5c\uff0c\u9632\u6b62\u5e76\u53d1\u6267\u884c\n:param func: \u63a5\u6536\u52a8\u4f5c\u51fd\u6570\n:return: \u8fd4\u56de\u52a0\u9501\u540e\u7684\u52a8\u4f5c","docstring_tokens":["\u88c5\u9970\u5668\uff0c\u9501\u5b9a\u6bcf\u4e2a\u52a8\u4f5c\uff0c\u9632\u6b62\u5e76\u53d1\u6267\u884c",":","param","func",":","\u63a5\u6536\u52a8\u4f5c\u51fd\u6570",":","return",":","\u8fd4\u56de\u52a0\u9501\u540e\u7684\u52a8\u4f5c"],"summary":"\u88c5\u9970\u5668\uff0c\u9501\u5b9a\u6bcf\u4e2a\u52a8\u4f5c\uff0c\u9632\u6b62\u5e76\u53d1\u6267\u884c","code_with_docstring":"def set_single(func):\n    \"\"\"\n    \u88c5\u9970\u5668\uff0c\u9501\u5b9a\u6bcf\u4e2a\u52a8\u4f5c\uff0c\u9632\u6b62\u5e76\u53d1\u6267\u884c\n    :param func: \u63a5\u6536\u52a8\u4f5c\u51fd\u6570\n    :return: \u8fd4\u56de\u52a0\u9501\u540e\u7684\u52a8\u4f5c\n    \"\"\"\n\n    def wrapper(*args, **kwargs):\n        global action_name2, action_lock2\n        now = datetime.datetime.now()\n        time_consuming = (now - action_lock2[2]).seconds\n        if time_consuming < 300:\n            for n in range(3):\n                if action_lock2[0]:\n                    print('\u6b63\u5728\u6267\u884c:%s\uff0c1\u79d2\u540e\u518d\u6b21\u5c1d\u8bd5%d:%s' % (action_lock2[1], n + 1,\n                        func.__name__))\n                    if n == 2:\n                        print('%s\u6b63\u5728\u6267\u884c\uff0c\u653e\u5f03\u6267\u884c:%s' % (action_lock2[1], func.\n                            __name__))\n                        return None\n                    time.sleep(1)\n                else:\n                    break\n        action_lock2[0] = True\n        action_lock2[1] = func.__name__\n        action_lock2[2] = now\n        inner = func(*args, **kwargs)\n        action_lock2[0] = False\n        wrapper.__name__ = func.__name__\n        return inner\n    return wrapper\n","code_tokens_py":[]}
{"repo":"delphixpy-1.11.1.0","path":"delphixpy-1.11.1.0\/\/delphixpy\/v1_7_0\/web\/objects\/JSUsageData.pyclass:JSUsageData\/start_date","language":"python","sha":"92be91a01207967ecd86e90d13cfff703f85423f","url":"delphixpy-1.11.1.0\/\/delphixpy\/v1_7_0\/web\/objects\/JSUsageData.pyclass:JSUsageData\/start_date","partition":"test","code":"@property\ndef start_date(self):\n    \n        The date at the beginning of the time period this datapoint corresponds\n        to. The time period itself varies between datapoint types.\n\n        :rtype: ``TEXT_TYPE``\n        \"\"\"\n    return self._start_date[0]\n","original_string":"@property\ndef start_date(self):\n    \"\"\"\n        The date at the beginning of the time period this datapoint corresponds\n        to. The time period itself varies between datapoint types.\n\n        :rtype: ``TEXT_TYPE``\n        \"\"\"\n    return self._start_date[0]\n","code_tokens":["@property\ndef","start_date(self):\n","","","","\n","","","","","","","","The","date","at","the","beginning","of","the","time","period","this","datapoint","corresponds\n","","","","","","","","to.","The","time","period","itself","varies","between","datapoint","types.\n\n","","","","","","","",":rtype:","``TEXT_TYPE``\n","","","","","","","","\"\"\"\n","","","","return","self._start_date[0]\n"],"func_name":"delphixpy-1.11.1.0\/class:JSUsageData\/start_date","docstring":"The date at the beginning of the time period this datapoint corresponds\nto. The time period itself varies between datapoint types.\n\n:rtype: ``TEXT_TYPE``","docstring_tokens":["The","date","at","the","beginning","of","the","time","period","this","datapoint","corresponds","to",".","The","time","period","itself","varies","between","datapoint","types",".",":","rtype",":","`","`","TEXT_TYPE","`","`"],"summary":"The date at the beginning of the time period this datapoint corresponds","code_with_docstring":"@property\ndef start_date(self):\n    \"\"\"\n        The date at the beginning of the time period this datapoint corresponds\n        to. The time period itself varies between datapoint types.\n\n        :rtype: ``TEXT_TYPE``\n        \"\"\"\n    return self._start_date[0]\n","code_tokens_py":[]}
{"repo":"cloudsmith_cli","path":"cloudsmith_cli\/\/core\/utils.pyfile:\/core\/utils.py:function:get_query_kwargs\/get_query_kwargs","language":"python","sha":"dace4f6265a1be39c23aa93a6baa86c86ba18c10","url":"cloudsmith_cli\/\/core\/utils.pyfile:\/core\/utils.py:function:get_query_kwargs\/get_query_kwargs","partition":"test","code":"def get_query_kwargs(**kwargs):\n    \"\"\"\n    query_kwargs = {}\n    query = kwargs.pop('query')\n    if query:\n        query_kwargs['query'] = query\n    return query_kwargs\n","original_string":"def get_query_kwargs(**kwargs):\n    \"\"\"Construct page and page size kwargs (if present).\"\"\"\n    query_kwargs = {}\n    query = kwargs.pop('query')\n    if query:\n        query_kwargs['query'] = query\n    return query_kwargs\n","code_tokens":["def","get_query_kwargs(**kwargs):\n","","","","\"\"\"\n","","","","query_kwargs","=","{}\n","","","","query","=","kwargs.pop('query')\n","","","","if","query:\n","","","","","","","","query_kwargs['query']","=","query\n","","","","return","query_kwargs\n"],"func_name":"cloudsmith_cli\/file:\/core\/utils.py:function:get_query_kwargs\/get_query_kwargs","docstring":"Construct page and page size kwargs (if present).","docstring_tokens":["Construct","page","and","page","size","kwargs","(","if","present",")","."],"summary":"Construct page and page size kwargs (if present).","code_with_docstring":"def get_query_kwargs(**kwargs):\n    \"\"\"Construct page and page size kwargs (if present).\"\"\"\n    query_kwargs = {}\n    query = kwargs.pop('query')\n    if query:\n        query_kwargs['query'] = query\n    return query_kwargs\n","code_tokens_py":[]}
{"repo":"GetDist-1.1.1","path":"GetDist-1.1.1\/\/getdist\/plots.pyclass:GetDistPlotter\/plots_2d","language":"python","sha":"742abfd5781dc88fda48fadd08a34e1daf3ea6d7","url":"GetDist-1.1.1\/\/getdist\/plots.pyclass:GetDistPlotter\/plots_2d","partition":"test","code":"def plots_2d(self, roots, param1=None, params2=None, param_pairs=None, nx=\n    None, legend_labels=None, legend_ncol=None, label_order=None, filled=\n    False, shaded=False, **kwargs):\n    \n        Make an array of 2D line, filled or contour plots.\n\n        :param roots: root name or :class:`~.mcsamples.MCSamples` instance (or list of either of these) for the\n                      samples to plot\n        :param param1: x parameter to plot\n        :param params2: list of y parameters to plot against x\n        :param param_pairs: list of [x,y] parameter pairs to plot; either specify param1, param2, or param_pairs\n        :param nx: number of subplots per row\n        :param legend_labels: The labels used for the legend.\n        :param legend_ncol: The amount of columns in the legend.\n        :param label_order: minus one to show legends in reverse order that lines were added, or a list giving\n                            specific order of line indices\n        :param filled: True to plot filled contours\n        :param shaded: True to shade by the density for the first root plotted\n        :param kwargs: optional keyword arguments for :func:`~GetDistPlotter.plot_2d`\n        :return: The plot_col, plot_row subplot dimensions of the new figure\n\n        .. plot::\n           :include-source:\n\n            from getdist import plots, gaussian_mixtures\n            samples1, samples2 = gaussian_mixtures.randomTestMCSamples(ndim=4, nMCSamples=2)\n            g = plots.get_subplot_plotter(subplot_size=4)\n            g.settings.legend_frac_subplot_margin = 0.05\n            g.plots_2d([samples1, samples2], param_pairs=[['x0', 'x1'], ['x1', 'x2']],\n                                    nx=2, legend_ncol=2, colors=['blue', 'red'])\n        \"\"\"\n    pairs = []\n    roots = makeList(roots)\n    if isinstance(param1, (list, tuple)) and len(param1) == 2:\n        params2 = [param1[1]]\n        param1 = param1[0]\n    if param_pairs is None:\n        if param1 is not None:\n            param1 = self._check_param(roots[0], param1)\n            params2 = self.get_param_array(roots[0], params2)\n            for param in params2:\n                if param.name != param1.name:\n                    pairs.append((param1, param))\n        else:\n            raise GetDistPlotError(\n                'No parameter or parameter pairs for 2D plot')\n    else:\n        for pair in param_pairs:\n            pairs.append((self._check_param(roots[0], pair[0]), self.\n                _check_param(roots[0], pair[1])))\n    if filled and shaded:\n        raise GetDistPlotError('Plots cannot be both filled and shaded')\n    plot_col, plot_row = self.make_figure(len(pairs), nx=nx)\n    for i, pair in enumerate(pairs):\n        ax = self._subplot_number(i, pars=pair)\n        self.plot_2d(roots, param_pair=pair, filled=filled, shaded=not\n            filled and shaded, add_legend_proxy=i == 0, ax=ax, _no_finish=\n            True, **kwargs)\n    self.finish_plot(self._default_legend_labels(legend_labels, roots),\n        legend_ncol=legend_ncol, label_order=label_order)\n    return plot_col, plot_row\n","original_string":"def plots_2d(self, roots, param1=None, params2=None, param_pairs=None, nx=\n    None, legend_labels=None, legend_ncol=None, label_order=None, filled=\n    False, shaded=False, **kwargs):\n    \"\"\"\n        Make an array of 2D line, filled or contour plots.\n\n        :param roots: root name or :class:`~.mcsamples.MCSamples` instance (or list of either of these) for the\n                      samples to plot\n        :param param1: x parameter to plot\n        :param params2: list of y parameters to plot against x\n        :param param_pairs: list of [x,y] parameter pairs to plot; either specify param1, param2, or param_pairs\n        :param nx: number of subplots per row\n        :param legend_labels: The labels used for the legend.\n        :param legend_ncol: The amount of columns in the legend.\n        :param label_order: minus one to show legends in reverse order that lines were added, or a list giving\n                            specific order of line indices\n        :param filled: True to plot filled contours\n        :param shaded: True to shade by the density for the first root plotted\n        :param kwargs: optional keyword arguments for :func:`~GetDistPlotter.plot_2d`\n        :return: The plot_col, plot_row subplot dimensions of the new figure\n\n        .. plot::\n           :include-source:\n\n            from getdist import plots, gaussian_mixtures\n            samples1, samples2 = gaussian_mixtures.randomTestMCSamples(ndim=4, nMCSamples=2)\n            g = plots.get_subplot_plotter(subplot_size=4)\n            g.settings.legend_frac_subplot_margin = 0.05\n            g.plots_2d([samples1, samples2], param_pairs=[['x0', 'x1'], ['x1', 'x2']],\n                                    nx=2, legend_ncol=2, colors=['blue', 'red'])\n        \"\"\"\n    pairs = []\n    roots = makeList(roots)\n    if isinstance(param1, (list, tuple)) and len(param1) == 2:\n        params2 = [param1[1]]\n        param1 = param1[0]\n    if param_pairs is None:\n        if param1 is not None:\n            param1 = self._check_param(roots[0], param1)\n            params2 = self.get_param_array(roots[0], params2)\n            for param in params2:\n                if param.name != param1.name:\n                    pairs.append((param1, param))\n        else:\n            raise GetDistPlotError(\n                'No parameter or parameter pairs for 2D plot')\n    else:\n        for pair in param_pairs:\n            pairs.append((self._check_param(roots[0], pair[0]), self.\n                _check_param(roots[0], pair[1])))\n    if filled and shaded:\n        raise GetDistPlotError('Plots cannot be both filled and shaded')\n    plot_col, plot_row = self.make_figure(len(pairs), nx=nx)\n    for i, pair in enumerate(pairs):\n        ax = self._subplot_number(i, pars=pair)\n        self.plot_2d(roots, param_pair=pair, filled=filled, shaded=not\n            filled and shaded, add_legend_proxy=i == 0, ax=ax, _no_finish=\n            True, **kwargs)\n    self.finish_plot(self._default_legend_labels(legend_labels, roots),\n        legend_ncol=legend_ncol, label_order=label_order)\n    return plot_col, plot_row\n","code_tokens":["def","plots_2d(self,","roots,","param1=None,","params2=None,","param_pairs=None,","nx=\n","","","","None,","legend_labels=None,","legend_ncol=None,","label_order=None,","filled=\n","","","","False,","shaded=False,","**kwargs):\n","","","","\n","","","","","","","","Make","an","array","of","2D","line,","filled","or","contour","plots.\n\n","","","","","","","",":param","roots:","root","name","or",":class:`~.mcsamples.MCSamples`","instance","(or","list","of","either","of","these)","for","the\n","","","","","","","","","","","","","","","","","","","","","","samples","to","plot\n","","","","","","","",":param","param1:","x","parameter","to","plot\n","","","","","","","",":param","params2:","list","of","y","parameters","to","plot","against","x\n","","","","","","","",":param","param_pairs:","list","of","[x,y]","parameter","pairs","to","plot;","either","specify","param1,","param2,","or","param_pairs\n","","","","","","","",":param","nx:","number","of","subplots","per","row\n","","","","","","","",":param","legend_labels:","The","labels","used","for","the","legend.\n","","","","","","","",":param","legend_ncol:","The","amount","of","columns","in","the","legend.\n","","","","","","","",":param","label_order:","minus","one","to","show","legends","in","reverse","order","that","lines","were","added,","or","a","list","giving\n","","","","","","","","","","","","","","","","","","","","","","","","","","","","specific","order","of","line","indices\n","","","","","","","",":param","filled:","True","to","plot","filled","contours\n","","","","","","","",":param","shaded:","True","to","shade","by","the","density","for","the","first","root","plotted\n","","","","","","","",":param","kwargs:","optional","keyword","arguments","for",":func:`~GetDistPlotter.plot_2d`\n","","","","","","","",":return:","The","plot_col,","plot_row","subplot","dimensions","of","the","new","figure\n\n","","","","","","","","..","plot::\n","","","","","","","","","","",":include-source:\n\n","","","","","","","","","","","","from","getdist","import","plots,","gaussian_mixtures\n","","","","","","","","","","","","samples1,","samples2","=","gaussian_mixtures.randomTestMCSamples(ndim=4,","nMCSamples=2)\n","","","","","","","","","","","","g","=","plots.get_subplot_plotter(subplot_size=4)\n","","","","","","","","","","","","g.settings.legend_frac_subplot_margin","=","0.05\n","","","","","","","","","","","","g.plots_2d([samples1,","samples2],","param_pairs=[['x0',","'x1'],","['x1',","'x2']],\n","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","nx=2,","legend_ncol=2,","colors=['blue',","'red'])\n","","","","","","","","\"\"\"\n","","","","pairs","=","[]\n","","","","roots","=","makeList(roots)\n","","","","if","isinstance(param1,","(list,","tuple))","and","len(param1)","==","2:\n","","","","","","","","params2","=","[param1[1]]\n","","","","","","","","param1","=","param1[0]\n","","","","if","param_pairs","is","None:\n","","","","","","","","if","param1","is","not","None:\n","","","","","","","","","","","","param1","=","self._check_param(roots[0],","param1)\n","","","","","","","","","","","","params2","=","self.get_param_array(roots[0],","params2)\n","","","","","","","","","","","","for","param","in","params2:\n","","","","","","","","","","","","","","","","if","param.name","!=","param1.name:\n","","","","","","","","","","","","","","","","","","","","pairs.append((param1,","param))\n","","","","","","","","else:\n","","","","","","","","","","","","raise","GetDistPlotError(\n","","","","","","","","","","","","","","","","'No","parameter","or","parameter","pairs","for","2D","plot')\n","","","","else:\n","","","","","","","","for","pair","in","param_pairs:\n","","","","","","","","","","","","pairs.append((self._check_param(roots[0],","pair[0]),","self.\n","","","","","","","","","","","","","","","","_check_param(roots[0],","pair[1])))\n","","","","if","filled","and","shaded:\n","","","","","","","","raise","GetDistPlotError('Plots","cannot","be","both","filled","and","shaded')\n","","","","plot_col,","plot_row","=","self.make_figure(len(pairs),","nx=nx)\n","","","","for","i,","pair","in","enumerate(pairs):\n","","","","","","","","ax","=","self._subplot_number(i,","pars=pair)\n","","","","","","","","self.plot_2d(roots,","param_pair=pair,","filled=filled,","shaded=not\n","","","","","","","","","","","","filled","and","shaded,","add_legend_proxy=i","==","0,","ax=ax,","_no_finish=\n","","","","","","","","","","","","True,","**kwargs)\n","","","","self.finish_plot(self._default_legend_labels(legend_labels,","roots),\n","","","","","","","","legend_ncol=legend_ncol,","label_order=label_order)\n","","","","return","plot_col,","plot_row\n"],"func_name":"GetDist-1.1.1\/class:GetDistPlotter\/plots_2d","docstring":"Make an array of 2D line, filled or contour plots.\n\n:param roots: root name or :class:`~.mcsamples.MCSamples` instance (or list of either of these) for the\n              samples to plot\n:param param1: x parameter to plot\n:param params2: list of y parameters to plot against x\n:param param_pairs: list of [x,y] parameter pairs to plot; either specify param1, param2, or param_pairs\n:param nx: number of subplots per row\n:param legend_labels: The labels used for the legend.\n:param legend_ncol: The amount of columns in the legend.\n:param label_order: minus one to show legends in reverse order that lines were added, or a list giving\n                    specific order of line indices\n:param filled: True to plot filled contours\n:param shaded: True to shade by the density for the first root plotted\n:param kwargs: optional keyword arguments for :func:`~GetDistPlotter.plot_2d`\n:return: The plot_col, plot_row subplot dimensions of the new figure\n\n.. plot::\n   :include-source:\n\n    from getdist import plots, gaussian_mixtures\n    samples1, samples2 = gaussian_mixtures.randomTestMCSamples(ndim=4, nMCSamples=2)\n    g = plots.get_subplot_plotter(subplot_size=4)\n    g.settings.legend_frac_subplot_margin = 0.05\n    g.plots_2d([samples1, samples2], param_pairs=[['x0', 'x1'], ['x1', 'x2']],\n                            nx=2, legend_ncol=2, colors=['blue', 'red'])","docstring_tokens":["Make","an","array","of","2D","line",",","filled","or","contour","plots",".",":","param","roots",":","root","name","or",":","class:`~.mcsamples",".","MCSamples","`","instance","(","or","list","of","either","of","these",")","for","the","samples","to","plot",":","param","param1",":","x","parameter","to","plot",":","param","params2",":","list","of","y","parameters","to","plot","against","x",":","param","param_pairs",":","list","of","[","x",",","y","]","parameter","pairs","to","plot",";","either","specify","param1",",","param2",",","or","param_pairs",":","param","nx",":","number","of","subplots","per","row",":","param","legend_labels",":","The","labels","used","for","the","legend",".",":","param","legend_ncol",":","The","amount","of","columns","in","the","legend",".",":","param","label_order",":","minus","one","to","show","legends","in","reverse","order","that","lines","were","added",",","or","a","list","giving","specific","order","of","line","indices",":","param","filled",":","True","to","plot","filled","contours",":","param","shaded",":","True","to","shade","by","the","density","for","the","first","root","plotted",":","param","kwargs",":","optional","keyword","arguments","for",":","func:`~GetDistPlotter.plot_2d","`",":","return",":","The","plot_col",",","plot_row","subplot","dimensions","of","the","new","figure","..","plot",":",":",":","include","-","source",":","from","getdist","import","plots",",","gaussian_mixtures","samples1",",","samples2","=","gaussian_mixtures.randomTestMCSamples(ndim=4",",","nMCSamples=2",")","g","=","plots.get_subplot_plotter(subplot_size=4",")","g.settings.legend_frac_subplot_margin","=","0.05","g.plots_2d([samples1",",","samples2","]",",","param_pairs=[['x0","'",",","'","x1","'","]",",","[","'","x1","'",",","'","x2","'","]","]",",","nx=2",",","legend_ncol=2",",","colors=['blue","'",",","'","red","'","]",")"],"summary":"Make an array of 2D line, filled or contour plots.","code_with_docstring":"def plots_2d(self, roots, param1=None, params2=None, param_pairs=None, nx=\n    None, legend_labels=None, legend_ncol=None, label_order=None, filled=\n    False, shaded=False, **kwargs):\n    \"\"\"\n        Make an array of 2D line, filled or contour plots.\n\n        :param roots: root name or :class:`~.mcsamples.MCSamples` instance (or list of either of these) for the\n                      samples to plot\n        :param param1: x parameter to plot\n        :param params2: list of y parameters to plot against x\n        :param param_pairs: list of [x,y] parameter pairs to plot; either specify param1, param2, or param_pairs\n        :param nx: number of subplots per row\n        :param legend_labels: The labels used for the legend.\n        :param legend_ncol: The amount of columns in the legend.\n        :param label_order: minus one to show legends in reverse order that lines were added, or a list giving\n                            specific order of line indices\n        :param filled: True to plot filled contours\n        :param shaded: True to shade by the density for the first root plotted\n        :param kwargs: optional keyword arguments for :func:`~GetDistPlotter.plot_2d`\n        :return: The plot_col, plot_row subplot dimensions of the new figure\n\n        .. plot::\n           :include-source:\n\n            from getdist import plots, gaussian_mixtures\n            samples1, samples2 = gaussian_mixtures.randomTestMCSamples(ndim=4, nMCSamples=2)\n            g = plots.get_subplot_plotter(subplot_size=4)\n            g.settings.legend_frac_subplot_margin = 0.05\n            g.plots_2d([samples1, samples2], param_pairs=[['x0', 'x1'], ['x1', 'x2']],\n                                    nx=2, legend_ncol=2, colors=['blue', 'red'])\n        \"\"\"\n    pairs = []\n    roots = makeList(roots)\n    if isinstance(param1, (list, tuple)) and len(param1) == 2:\n        params2 = [param1[1]]\n        param1 = param1[0]\n    if param_pairs is None:\n        if param1 is not None:\n            param1 = self._check_param(roots[0], param1)\n            params2 = self.get_param_array(roots[0], params2)\n            for param in params2:\n                if param.name != param1.name:\n                    pairs.append((param1, param))\n        else:\n            raise GetDistPlotError(\n                'No parameter or parameter pairs for 2D plot')\n    else:\n        for pair in param_pairs:\n            pairs.append((self._check_param(roots[0], pair[0]), self.\n                _check_param(roots[0], pair[1])))\n    if filled and shaded:\n        raise GetDistPlotError('Plots cannot be both filled and shaded')\n    plot_col, plot_row = self.make_figure(len(pairs), nx=nx)\n    for i, pair in enumerate(pairs):\n        ax = self._subplot_number(i, pars=pair)\n        self.plot_2d(roots, param_pair=pair, filled=filled, shaded=not\n            filled and shaded, add_legend_proxy=i == 0, ax=ax, _no_finish=\n            True, **kwargs)\n    self.finish_plot(self._default_legend_labels(legend_labels, roots),\n        legend_ncol=legend_ncol, label_order=label_order)\n    return plot_col, plot_row\n","code_tokens_py":[]}
{"repo":"oceanwaves","path":"oceanwaves\/\/oceanwaves.pyclass:OceanWaves\/as_directional","language":"python","sha":"59afaadf2b21334a18f2d27c8d3ea95661a49629","url":"oceanwaves\/\/oceanwaves.pyclass:OceanWaves\/as_directional","partition":"test","code":"def as_directional(self, direction, direction_units='deg', theta_peak=None,\n    s=None, normalize=True):\n    Convert omnidirectional spectrum to a directional spectrum\n\n        Spreads total wave energy over a given set of directions\n        according to a spreading factor ``s``.\n\n        See :func:`oceanwaves.spectral.directional_spreading` for options.\n\n        Returns\n        -------\n        OceanWaves\n            New OceanWaves object\n\n        \"\"\"\n    if self.has_dimension('direction'):\n        return self\n    direction = np.asarray(direction, dtype=np.float)\n    k = self._key_lookup('_energy')\n    energy = self.variables[k].values\n    energy_units = self.variables[k].attrs['units']\n    ix_direction = energy.ndim\n    if theta_peak is None:\n        k = self._key_lookup('_direction')\n        if k in self.variables.keys():\n            theta_peak = self.variables[k].values\n        else:\n            theta_peak = 0.0\n    if isinstance(theta_peak, (int, float)):\n        theta_peak = theta_peak * np.ones(energy.shape)\n    if s is None:\n        k = self._key_lookup('_spreading')\n        if k in self.variables.keys():\n            s = self.variables[k].values\n        else:\n            s = 20.0\n    if isinstance(s, (int, float)):\n        s = s * np.ones(energy.shape)\n    energy = expand_and_repeat(energy, repeat=len(direction), expand_dims=\n        ix_direction)\n    theta_mtx = expand_and_repeat(direction, shape=energy.shape, exist_dims\n        =ix_direction)\n    thetap_mtx = expand_and_repeat(theta_peak, shape=energy.shape,\n        expand_dims=ix_direction)\n    s_mtx = expand_and_repeat(s, shape=energy.shape, expand_dims=ix_direction)\n    spreading = directional_spreading(theta_mtx, units=direction_units,\n        theta_peak=thetap_mtx, s=s_mtx, normalize=False)\n    if normalize:\n        spreading \/= trapz_and_repeat(spreading, theta_mtx, axis=ix_direction)\n    energy = np.multiply(energy, spreading)\n    units = '(%s)\/(%s)' % (energy_units, direction_units)\n    return self.reinitialize(direction=direction, direction_units=\n        direction_units, energy=energy, energy_units=simplify(units))\n","original_string":"def as_directional(self, direction, direction_units='deg', theta_peak=None,\n    s=None, normalize=True):\n    \"\"\"Convert omnidirectional spectrum to a directional spectrum\n\n        Spreads total wave energy over a given set of directions\n        according to a spreading factor ``s``.\n\n        See :func:`oceanwaves.spectral.directional_spreading` for options.\n\n        Returns\n        -------\n        OceanWaves\n            New OceanWaves object\n\n        \"\"\"\n    if self.has_dimension('direction'):\n        return self\n    direction = np.asarray(direction, dtype=np.float)\n    k = self._key_lookup('_energy')\n    energy = self.variables[k].values\n    energy_units = self.variables[k].attrs['units']\n    ix_direction = energy.ndim\n    if theta_peak is None:\n        k = self._key_lookup('_direction')\n        if k in self.variables.keys():\n            theta_peak = self.variables[k].values\n        else:\n            theta_peak = 0.0\n    if isinstance(theta_peak, (int, float)):\n        theta_peak = theta_peak * np.ones(energy.shape)\n    if s is None:\n        k = self._key_lookup('_spreading')\n        if k in self.variables.keys():\n            s = self.variables[k].values\n        else:\n            s = 20.0\n    if isinstance(s, (int, float)):\n        s = s * np.ones(energy.shape)\n    energy = expand_and_repeat(energy, repeat=len(direction), expand_dims=\n        ix_direction)\n    theta_mtx = expand_and_repeat(direction, shape=energy.shape, exist_dims\n        =ix_direction)\n    thetap_mtx = expand_and_repeat(theta_peak, shape=energy.shape,\n        expand_dims=ix_direction)\n    s_mtx = expand_and_repeat(s, shape=energy.shape, expand_dims=ix_direction)\n    spreading = directional_spreading(theta_mtx, units=direction_units,\n        theta_peak=thetap_mtx, s=s_mtx, normalize=False)\n    if normalize:\n        spreading \/= trapz_and_repeat(spreading, theta_mtx, axis=ix_direction)\n    energy = np.multiply(energy, spreading)\n    units = '(%s)\/(%s)' % (energy_units, direction_units)\n    return self.reinitialize(direction=direction, direction_units=\n        direction_units, energy=energy, energy_units=simplify(units))\n","code_tokens":["def","as_directional(self,","direction,","direction_units='deg',","theta_peak=None,\n","","","","s=None,","normalize=True):\n","","","","Convert","omnidirectional","spectrum","to","a","directional","spectrum\n\n","","","","","","","","Spreads","total","wave","energy","over","a","given","set","of","directions\n","","","","","","","","according","to","a","spreading","factor","``s``.\n\n","","","","","","","","See",":func:`oceanwaves.spectral.directional_spreading`","for","options.\n\n","","","","","","","","Returns\n","","","","","","","","-------\n","","","","","","","","OceanWaves\n","","","","","","","","","","","","New","OceanWaves","object\n\n","","","","","","","","\"\"\"\n","","","","if","self.has_dimension('direction'):\n","","","","","","","","return","self\n","","","","direction","=","np.asarray(direction,","dtype=np.float)\n","","","","k","=","self._key_lookup('_energy')\n","","","","energy","=","self.variables[k].values\n","","","","energy_units","=","self.variables[k].attrs['units']\n","","","","ix_direction","=","energy.ndim\n","","","","if","theta_peak","is","None:\n","","","","","","","","k","=","self._key_lookup('_direction')\n","","","","","","","","if","k","in","self.variables.keys():\n","","","","","","","","","","","","theta_peak","=","self.variables[k].values\n","","","","","","","","else:\n","","","","","","","","","","","","theta_peak","=","0.0\n","","","","if","isinstance(theta_peak,","(int,","float)):\n","","","","","","","","theta_peak","=","theta_peak","*","np.ones(energy.shape)\n","","","","if","s","is","None:\n","","","","","","","","k","=","self._key_lookup('_spreading')\n","","","","","","","","if","k","in","self.variables.keys():\n","","","","","","","","","","","","s","=","self.variables[k].values\n","","","","","","","","else:\n","","","","","","","","","","","","s","=","20.0\n","","","","if","isinstance(s,","(int,","float)):\n","","","","","","","","s","=","s","*","np.ones(energy.shape)\n","","","","energy","=","expand_and_repeat(energy,","repeat=len(direction),","expand_dims=\n","","","","","","","","ix_direction)\n","","","","theta_mtx","=","expand_and_repeat(direction,","shape=energy.shape,","exist_dims\n","","","","","","","","=ix_direction)\n","","","","thetap_mtx","=","expand_and_repeat(theta_peak,","shape=energy.shape,\n","","","","","","","","expand_dims=ix_direction)\n","","","","s_mtx","=","expand_and_repeat(s,","shape=energy.shape,","expand_dims=ix_direction)\n","","","","spreading","=","directional_spreading(theta_mtx,","units=direction_units,\n","","","","","","","","theta_peak=thetap_mtx,","s=s_mtx,","normalize=False)\n","","","","if","normalize:\n","","","","","","","","spreading","\/=","trapz_and_repeat(spreading,","theta_mtx,","axis=ix_direction)\n","","","","energy","=","np.multiply(energy,","spreading)\n","","","","units","=","'(%s)\/(%s)'","%","(energy_units,","direction_units)\n","","","","return","self.reinitialize(direction=direction,","direction_units=\n","","","","","","","","direction_units,","energy=energy,","energy_units=simplify(units))\n"],"func_name":"oceanwaves\/class:OceanWaves\/as_directional","docstring":"Convert omnidirectional spectrum to a directional spectrum\n\nSpreads total wave energy over a given set of directions\naccording to a spreading factor ``s``.\n\nSee :func:`oceanwaves.spectral.directional_spreading` for options.\n\nReturns\n-------\nOceanWaves\n    New OceanWaves object","docstring_tokens":["Convert","omnidirectional","spectrum","to","a","directional","spectrum","Spreads","total","wave","energy","over","a","given","set","of","directions","according","to","a","spreading","factor","`","`","s","`","`",".","See",":","func:`oceanwaves.spectral.directional_spreading","`","for","options",".","Returns","-------","OceanWaves","New","OceanWaves","object"],"summary":"Convert omnidirectional spectrum to a directional spectrum","code_with_docstring":"def as_directional(self, direction, direction_units='deg', theta_peak=None,\n    s=None, normalize=True):\n    \"\"\"Convert omnidirectional spectrum to a directional spectrum\n\n        Spreads total wave energy over a given set of directions\n        according to a spreading factor ``s``.\n\n        See :func:`oceanwaves.spectral.directional_spreading` for options.\n\n        Returns\n        -------\n        OceanWaves\n            New OceanWaves object\n\n        \"\"\"\n    if self.has_dimension('direction'):\n        return self\n    direction = np.asarray(direction, dtype=np.float)\n    k = self._key_lookup('_energy')\n    energy = self.variables[k].values\n    energy_units = self.variables[k].attrs['units']\n    ix_direction = energy.ndim\n    if theta_peak is None:\n        k = self._key_lookup('_direction')\n        if k in self.variables.keys():\n            theta_peak = self.variables[k].values\n        else:\n            theta_peak = 0.0\n    if isinstance(theta_peak, (int, float)):\n        theta_peak = theta_peak * np.ones(energy.shape)\n    if s is None:\n        k = self._key_lookup('_spreading')\n        if k in self.variables.keys():\n            s = self.variables[k].values\n        else:\n            s = 20.0\n    if isinstance(s, (int, float)):\n        s = s * np.ones(energy.shape)\n    energy = expand_and_repeat(energy, repeat=len(direction), expand_dims=\n        ix_direction)\n    theta_mtx = expand_and_repeat(direction, shape=energy.shape, exist_dims\n        =ix_direction)\n    thetap_mtx = expand_and_repeat(theta_peak, shape=energy.shape,\n        expand_dims=ix_direction)\n    s_mtx = expand_and_repeat(s, shape=energy.shape, expand_dims=ix_direction)\n    spreading = directional_spreading(theta_mtx, units=direction_units,\n        theta_peak=thetap_mtx, s=s_mtx, normalize=False)\n    if normalize:\n        spreading \/= trapz_and_repeat(spreading, theta_mtx, axis=ix_direction)\n    energy = np.multiply(energy, spreading)\n    units = '(%s)\/(%s)' % (energy_units, direction_units)\n    return self.reinitialize(direction=direction, direction_units=\n        direction_units, energy=energy, energy_units=simplify(units))\n","code_tokens_py":[]}
{"repo":"openprovider.py-0.11.1","path":"openprovider.py-0.11.1\/\/openprovider\/modules\/ssl.pyclass:SSLModule\/retrieve_product","language":"python","sha":"805b13c77e5bf1192820a37618dc56897b24f054","url":"openprovider.py-0.11.1\/\/openprovider\/modules\/ssl.pyclass:SSLModule\/retrieve_product","partition":"test","code":"def retrieve_product(self, product_id):\n    \"\"\"\n    response = self.request(E.retrieveProductSslCertRequest(E.id(product_id)))\n    return response.as_model(SSLProduct)\n","original_string":"def retrieve_product(self, product_id):\n    \"\"\"Retrieve details on a single product.\"\"\"\n    response = self.request(E.retrieveProductSslCertRequest(E.id(product_id)))\n    return response.as_model(SSLProduct)\n","code_tokens":["def","retrieve_product(self,","product_id):\n","","","","\"\"\"\n","","","","response","=","self.request(E.retrieveProductSslCertRequest(E.id(product_id)))\n","","","","return","response.as_model(SSLProduct)\n"],"func_name":"openprovider.py-0.11.1\/class:SSLModule\/retrieve_product","docstring":"Retrieve details on a single product.","docstring_tokens":["Retrieve","details","on","a","single","product","."],"summary":"Retrieve details on a single product.","code_with_docstring":"def retrieve_product(self, product_id):\n    \"\"\"Retrieve details on a single product.\"\"\"\n    response = self.request(E.retrieveProductSslCertRequest(E.id(product_id)))\n    return response.as_model(SSLProduct)\n","code_tokens_py":[]}
{"repo":"daskperiment-0.5.0","path":"daskperiment-0.5.0\/\/daskperiment\/core\/metric\/nosql.pyclass:RedisMetricManager\/keys","language":"python","sha":"6894224dab8e3f33e75601e4e44e4e37bc4f7d03","url":"daskperiment-0.5.0\/\/daskperiment\/core\/metric\/nosql.pyclass:RedisMetricManager\/keys","partition":"test","code":"def keys(self):\n    \n        \n        \"\"\"\n    key = self.backend.get_metric_key('*', '*')\n    keys = self.backend.keys(key)\n    sep = self.backend._SEP\n    keys = [k.split(sep)[2] for k in keys]\n    keys = sorted(list(set(keys)))\n    return keys\n","original_string":"def keys(self):\n    \"\"\"\n        Find metric names from previous trial ids\n        \"\"\"\n    key = self.backend.get_metric_key('*', '*')\n    keys = self.backend.keys(key)\n    sep = self.backend._SEP\n    keys = [k.split(sep)[2] for k in keys]\n    keys = sorted(list(set(keys)))\n    return keys\n","code_tokens":["def","keys(self):\n","","","","\n","","","","","","","","\n","","","","","","","","\"\"\"\n","","","","key","=","self.backend.get_metric_key('*',","'*')\n","","","","keys","=","self.backend.keys(key)\n","","","","sep","=","self.backend._SEP\n","","","","keys","=","[k.split(sep)[2]","for","k","in","keys]\n","","","","keys","=","sorted(list(set(keys)))\n","","","","return","keys\n"],"func_name":"daskperiment-0.5.0\/class:RedisMetricManager\/keys","docstring":"Find metric names from previous trial ids","docstring_tokens":["Find","metric","names","from","previous","trial","ids"],"summary":"Find metric names from previous trial ids","code_with_docstring":"def keys(self):\n    \"\"\"\n        Find metric names from previous trial ids\n        \"\"\"\n    key = self.backend.get_metric_key('*', '*')\n    keys = self.backend.keys(key)\n    sep = self.backend._SEP\n    keys = [k.split(sep)[2] for k in keys]\n    keys = sorted(list(set(keys)))\n    return keys\n","code_tokens_py":[]}
{"repo":"tinie","path":"tinie\/\/systems\/read_write\/system.pyclass:System\/get_center_energies","language":"python","sha":"6c998d2a778dfe90043a2c48602c07a222db88f3","url":"tinie\/\/systems\/read_write\/system.pyclass:System\/get_center_energies","partition":"test","code":"@abstractmethod\ndef get_center_energies(self):\n    \n        \n        \"\"\"\n    ...\n","original_string":"@abstractmethod\ndef get_center_energies(self):\n    \"\"\"\n        Returns energies of the central region in the transport setup.\n        \"\"\"\n    ...\n","code_tokens":["@abstractmethod\ndef","get_center_energies(self):\n","","","","\n","","","","","","","","\n","","","","","","","","\"\"\"\n","","","","...\n"],"func_name":"tinie\/class:System\/get_center_energies","docstring":"Returns energies of the central region in the transport setup.","docstring_tokens":["Returns","energies","of","the","central","region","in","the","transport","setup","."],"summary":"Returns energies of the central region in the transport setup.","code_with_docstring":"@abstractmethod\ndef get_center_energies(self):\n    \"\"\"\n        Returns energies of the central region in the transport setup.\n        \"\"\"\n    ...\n","code_tokens_py":[]}
{"repo":"forumsentry","path":"forumsentry\/\/serialization.pyclass:Serialization\/__deserialize_object","language":"python","sha":"068d40949e78ce5c97f60c8571f5f17244bb0311","url":"forumsentry\/\/serialization.pyclass:Serialization\/__deserialize_object","partition":"test","code":"def __deserialize_object(self, value):\n    Return a original value.\n\n        :return: object.\n        \"\"\"\n    return value\n","original_string":"def __deserialize_object(self, value):\n    \"\"\"Return a original value.\n\n        :return: object.\n        \"\"\"\n    return value\n","code_tokens":["def","__deserialize_object(self,","value):\n","","","","Return","a","original","value.\n\n","","","","","","","",":return:","object.\n","","","","","","","","\"\"\"\n","","","","return","value\n"],"func_name":"forumsentry\/class:Serialization\/__deserialize_object","docstring":"Return a original value.\n\n:return: object.","docstring_tokens":["Return","a","original","value",".",":","return",":","object","."],"summary":"Return a original value.","code_with_docstring":"def __deserialize_object(self, value):\n    \"\"\"Return a original value.\n\n        :return: object.\n        \"\"\"\n    return value\n","code_tokens_py":[]}
{"repo":"dataclass_builder","path":"dataclass_builder\/\/_common.pyfile:\/_common.py:function:_is_required\/_is_required","language":"python","sha":"d3d3fec9280ae8a0cd88eae9c7f00020536a3b85","url":"dataclass_builder\/\/_common.pyfile:\/_common.py:function:_is_required\/_is_required","partition":"test","code":"def _is_required(field: 'dataclasses.Field[Any]') ->bool:\n    Determine if the given :class:`dataclasses.Field` is required.\n\n    :param field:\n        Field to determine if it is required.\n\n    :return:\n        True if the `field` is required, otherwise False.\n    \"\"\"\n    return (field.init and field.default is dataclasses.MISSING and field.\n        default_factory is dataclasses.MISSING)\n","original_string":"def _is_required(field: 'dataclasses.Field[Any]') ->bool:\n    \"\"\"Determine if the given :class:`dataclasses.Field` is required.\n\n    :param field:\n        Field to determine if it is required.\n\n    :return:\n        True if the `field` is required, otherwise False.\n    \"\"\"\n    return (field.init and field.default is dataclasses.MISSING and field.\n        default_factory is dataclasses.MISSING)\n","code_tokens":["def","_is_required(field:","'dataclasses.Field[Any]')","->bool:\n","","","","Determine","if","the","given",":class:`dataclasses.Field`","is","required.\n\n","","","",":param","field:\n","","","","","","","","Field","to","determine","if","it","is","required.\n\n","","","",":return:\n","","","","","","","","True","if","the","`field`","is","required,","otherwise","False.\n","","","","\"\"\"\n","","","","return","(field.init","and","field.default","is","dataclasses.MISSING","and","field.\n","","","","","","","","default_factory","is","dataclasses.MISSING)\n"],"func_name":"dataclass_builder\/file:\/_common.py:function:_is_required\/_is_required","docstring":"Determine if the given :class:`dataclasses.Field` is required.\n\n:param field:\n    Field to determine if it is required.\n\n:return:\n    True if the `field` is required, otherwise False.","docstring_tokens":["Determine","if","the","given",":","class:`dataclasses",".","Field","`","is","required",".",":","param","field",":","Field","to","determine","if","it","is","required",".",":","return",":","True","if","the","`","field","`","is","required",",","otherwise","False","."],"summary":"Determine if the given :class:`dataclasses.Field` is required.","code_with_docstring":"def _is_required(field: 'dataclasses.Field[Any]') ->bool:\n    \"\"\"Determine if the given :class:`dataclasses.Field` is required.\n\n    :param field:\n        Field to determine if it is required.\n\n    :return:\n        True if the `field` is required, otherwise False.\n    \"\"\"\n    return (field.init and field.default is dataclasses.MISSING and field.\n        default_factory is dataclasses.MISSING)\n","code_tokens_py":[]}
{"repo":"eppy-0.5.52","path":"eppy-0.5.52\/\/eppy\/useful_scripts\/autosize.pyfile:\/eppy\/useful_scripts\/autosize.py:function:autosize_fieldname\/autosize_fieldname","language":"python","sha":"4d46d1ebd09e832b552ed92afd604a6820215558","url":"eppy-0.5.52\/\/eppy\/useful_scripts\/autosize.pyfile:\/eppy\/useful_scripts\/autosize.py:function:autosize_fieldname\/autosize_fieldname","partition":"test","code":"def autosize_fieldname(idfobject):\n    \"\"\"\n    return [fname for fname, dct in zip(idfobject.objls, idfobject['objidd'\n        ]) if 'autosizable' in dct]\n","original_string":"def autosize_fieldname(idfobject):\n    \"\"\"return autsizeable field names in idfobject\"\"\"\n    return [fname for fname, dct in zip(idfobject.objls, idfobject['objidd'\n        ]) if 'autosizable' in dct]\n","code_tokens":["def","autosize_fieldname(idfobject):\n","","","","\"\"\"\n","","","","return","[fname","for","fname,","dct","in","zip(idfobject.objls,","idfobject['objidd'\n","","","","","","","","])","if","'autosizable'","in","dct]\n"],"func_name":"eppy-0.5.52\/file:\/eppy\/useful_scripts\/autosize.py:function:autosize_fieldname\/autosize_fieldname","docstring":"return autsizeable field names in idfobject","docstring_tokens":["return","autsizeable","field","names","in","idfobject"],"summary":"return autsizeable field names in idfobject","code_with_docstring":"def autosize_fieldname(idfobject):\n    \"\"\"return autsizeable field names in idfobject\"\"\"\n    return [fname for fname, dct in zip(idfobject.objls, idfobject['objidd'\n        ]) if 'autosizable' in dct]\n","code_tokens_py":[]}
{"repo":"bpy","path":"bpy\/\/types.pyclass:UILayout\/operator_menu_hold","language":"python","sha":"4c98d0cd3b131cf528618fef549d12266e87c052","url":"bpy\/\/types.pyclass:UILayout\/operator_menu_hold","partition":"test","code":"def operator_menu_hold(self, operator: str, text: str='', text_ctxt: str='',\n    translate: bool=True, icon: typing.Union[int, str]=0, emboss: bool=True,\n    depress: bool=False, icon_value: int=0, menu: str=''\n    ) ->'OperatorProperties':\n    Item. Places a button into the layout to call an Operator \n\n        :param operator: Identifier of the operator \n        :type operator: str\n        :param text: Override automatic text of the item \n        :type text: str\n        :param text_ctxt: Override automatic translation context of the given text \n        :type text_ctxt: str\n        :param translate: Translate the given text, when UI translation is enabled \n        :type translate: bool\n        :param icon: Icon, Override automatic icon of the item \n        :type icon: typing.Union[int, str]\n        :param emboss: Draw the button itself, not just the icon\/text \n        :type emboss: bool\n        :param depress: Draw pressed in \n        :type depress: bool\n        :param icon_value: Icon Value, Override automatic icon of the item \n        :type icon_value: int\n        :param menu: Identifier of the menu \n        :type menu: str\n        :rtype: 'OperatorProperties'\n        :return:  Operator properties to fill in \n        \"\"\"\n    pass\n","original_string":"def operator_menu_hold(self, operator: str, text: str='', text_ctxt: str='',\n    translate: bool=True, icon: typing.Union[int, str]=0, emboss: bool=True,\n    depress: bool=False, icon_value: int=0, menu: str=''\n    ) ->'OperatorProperties':\n    \"\"\"Item. Places a button into the layout to call an Operator \n\n        :param operator: Identifier of the operator \n        :type operator: str\n        :param text: Override automatic text of the item \n        :type text: str\n        :param text_ctxt: Override automatic translation context of the given text \n        :type text_ctxt: str\n        :param translate: Translate the given text, when UI translation is enabled \n        :type translate: bool\n        :param icon: Icon, Override automatic icon of the item \n        :type icon: typing.Union[int, str]\n        :param emboss: Draw the button itself, not just the icon\/text \n        :type emboss: bool\n        :param depress: Draw pressed in \n        :type depress: bool\n        :param icon_value: Icon Value, Override automatic icon of the item \n        :type icon_value: int\n        :param menu: Identifier of the menu \n        :type menu: str\n        :rtype: 'OperatorProperties'\n        :return:  Operator properties to fill in \n        \"\"\"\n    pass\n","code_tokens":["def","operator_menu_hold(self,","operator:","str,","text:","str='',","text_ctxt:","str='',\n","","","","translate:","bool=True,","icon:","typing.Union[int,","str]=0,","emboss:","bool=True,\n","","","","depress:","bool=False,","icon_value:","int=0,","menu:","str=''\n","","","",")","->'OperatorProperties':\n","","","","Item.","Places","a","button","into","the","layout","to","call","an","Operator","\n\n","","","","","","","",":param","operator:","Identifier","of","the","operator","\n","","","","","","","",":type","operator:","str\n","","","","","","","",":param","text:","Override","automatic","text","of","the","item","\n","","","","","","","",":type","text:","str\n","","","","","","","",":param","text_ctxt:","Override","automatic","translation","context","of","the","given","text","\n","","","","","","","",":type","text_ctxt:","str\n","","","","","","","",":param","translate:","Translate","the","given","text,","when","UI","translation","is","enabled","\n","","","","","","","",":type","translate:","bool\n","","","","","","","",":param","icon:","Icon,","Override","automatic","icon","of","the","item","\n","","","","","","","",":type","icon:","typing.Union[int,","str]\n","","","","","","","",":param","emboss:","Draw","the","button","itself,","not","just","the","icon\/text","\n","","","","","","","",":type","emboss:","bool\n","","","","","","","",":param","depress:","Draw","pressed","in","\n","","","","","","","",":type","depress:","bool\n","","","","","","","",":param","icon_value:","Icon","Value,","Override","automatic","icon","of","the","item","\n","","","","","","","",":type","icon_value:","int\n","","","","","","","",":param","menu:","Identifier","of","the","menu","\n","","","","","","","",":type","menu:","str\n","","","","","","","",":rtype:","'OperatorProperties'\n","","","","","","","",":return:","","Operator","properties","to","fill","in","\n","","","","","","","","\"\"\"\n","","","","pass\n"],"func_name":"bpy\/class:UILayout\/operator_menu_hold","docstring":"Item. Places a button into the layout to call an Operator \n\n:param operator: Identifier of the operator \n:type operator: str\n:param text: Override automatic text of the item \n:type text: str\n:param text_ctxt: Override automatic translation context of the given text \n:type text_ctxt: str\n:param translate: Translate the given text, when UI translation is enabled \n:type translate: bool\n:param icon: Icon, Override automatic icon of the item \n:type icon: typing.Union[int, str]\n:param emboss: Draw the button itself, not just the icon\/text \n:type emboss: bool\n:param depress: Draw pressed in \n:type depress: bool\n:param icon_value: Icon Value, Override automatic icon of the item \n:type icon_value: int\n:param menu: Identifier of the menu \n:type menu: str\n:rtype: 'OperatorProperties'\n:return:  Operator properties to fill in ","docstring_tokens":["Item",".","Places","a","button","into","the","layout","to","call","an","Operator",":","param","operator",":","Identifier","of","the","operator",":","type","operator",":","str",":","param","text",":","Override","automatic","text","of","the","item",":","type","text",":","str",":","param","text_ctxt",":","Override","automatic","translation","context","of","the","given","text",":","type","text_ctxt",":","str",":","param","translate",":","Translate","the","given","text",",","when","UI","translation","is","enabled",":","type","translate",":","bool",":","param","icon",":","Icon",",","Override","automatic","icon","of","the","item",":","type","icon",":","typing",".","Union[int",",","str","]",":","param","emboss",":","Draw","the","button","itself",",","not","just","the","icon","\/","text",":","type","emboss",":","bool",":","param","depress",":","Draw","pressed","in",":","type","depress",":","bool",":","param","icon_value",":","Icon","Value",",","Override","automatic","icon","of","the","item",":","type","icon_value",":","int",":","param","menu",":","Identifier","of","the","menu",":","type","menu",":","str",":","rtype",":","'","OperatorProperties","'",":","return",":","Operator","properties","to","fill","in"],"summary":"Item. Places a button into the layout to call an Operator ","code_with_docstring":"def operator_menu_hold(self, operator: str, text: str='', text_ctxt: str='',\n    translate: bool=True, icon: typing.Union[int, str]=0, emboss: bool=True,\n    depress: bool=False, icon_value: int=0, menu: str=''\n    ) ->'OperatorProperties':\n    \"\"\"Item. Places a button into the layout to call an Operator \n\n        :param operator: Identifier of the operator \n        :type operator: str\n        :param text: Override automatic text of the item \n        :type text: str\n        :param text_ctxt: Override automatic translation context of the given text \n        :type text_ctxt: str\n        :param translate: Translate the given text, when UI translation is enabled \n        :type translate: bool\n        :param icon: Icon, Override automatic icon of the item \n        :type icon: typing.Union[int, str]\n        :param emboss: Draw the button itself, not just the icon\/text \n        :type emboss: bool\n        :param depress: Draw pressed in \n        :type depress: bool\n        :param icon_value: Icon Value, Override automatic icon of the item \n        :type icon_value: int\n        :param menu: Identifier of the menu \n        :type menu: str\n        :rtype: 'OperatorProperties'\n        :return:  Operator properties to fill in \n        \"\"\"\n    pass\n","code_tokens_py":[]}
{"repo":"gs_quant-0.8.125","path":"gs_quant-0.8.125\/\/gs_quant\/target\/instrument.pyclass:IRXccySwapFixFix\/payer_day_count_fraction","language":"python","sha":"45f2b90e05e0fcb291c11afef0f171b49678ce9c","url":"gs_quant-0.8.125\/\/gs_quant\/target\/instrument.pyclass:IRXccySwapFixFix\/payer_day_count_fraction","partition":"test","code":"@property\ndef payer_day_count_fraction(self) ->Union[DayCountFraction, str]:\n    \"\"\"\n    return self.__payer_day_count_fraction\n","original_string":"@property\ndef payer_day_count_fraction(self) ->Union[DayCountFraction, str]:\n    \"\"\"The day count fraction for the payer\"\"\"\n    return self.__payer_day_count_fraction\n","code_tokens":["@property\ndef","payer_day_count_fraction(self)","->Union[DayCountFraction,","str]:\n","","","","\"\"\"\n","","","","return","self.__payer_day_count_fraction\n"],"func_name":"gs_quant-0.8.125\/class:IRXccySwapFixFix\/payer_day_count_fraction","docstring":"The day count fraction for the payer","docstring_tokens":["The","day","count","fraction","for","the","payer"],"summary":"The day count fraction for the payer","code_with_docstring":"@property\ndef payer_day_count_fraction(self) ->Union[DayCountFraction, str]:\n    \"\"\"The day count fraction for the payer\"\"\"\n    return self.__payer_day_count_fraction\n","code_tokens_py":[]}
{"repo":"fortiosapi","path":"fortiosapi\/\/fortiosapi.pyclass:FortiOSAPI\/ssh","language":"python","sha":"ffc68c14359c209a3dd31f8e73f7723ae4b9751f","url":"fortiosapi\/\/fortiosapi.pyclass:FortiOSAPI\/ssh","partition":"test","code":"@staticmethod\ndef ssh(cmds, host, user, password=None, port=22):\n     \"\"\"\n    client = paramiko.SSHClient()\n    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n    client.connect(host, port=port, username=user, password=password,\n        allow_agent=False, timeout=10)\n    LOG.debug('ssh login to  %s:%s ', host, port)\n    try:\n        stdin, stdout, stderr = client.exec_command(cmds)\n    except:\n        LOG.debug('exec_command failed')\n        raise subprocess.CalledProcessError(returncode=retcode, cmd=cmds,\n            output=output)\n    LOG.debug('ssh command in:  %s out: %s err: %s ', stdin, stdout, stderr)\n    retcode = stdout.channel.recv_exit_status()\n    LOG.debug('Paramiko return code : %s ', retcode)\n    client.close()\n    if retcode > 0:\n        output = stderr.read().strip()\n        raise subprocess.CalledProcessError(returncode=retcode, cmd=cmds,\n            output=output)\n    results = stdout.read()\n    LOG.debug('ssh cmd %s | out: %s | err: %s ', cmds, results, retcode)\n    if 'Command fail. Return code' in str(results):\n        raise subprocess.CalledProcessError(returncode=retcode, cmd=cmds,\n            output=results)\n    return ''.join(str(results)), ''.join(str(stderr.read().strip()))\n","original_string":"@staticmethod\ndef ssh(cmds, host, user, password=None, port=22):\n    \"\"\" Send a multi line string via ssh to the fortigate \"\"\"\n    client = paramiko.SSHClient()\n    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n    client.connect(host, port=port, username=user, password=password,\n        allow_agent=False, timeout=10)\n    LOG.debug('ssh login to  %s:%s ', host, port)\n    try:\n        stdin, stdout, stderr = client.exec_command(cmds)\n    except:\n        LOG.debug('exec_command failed')\n        raise subprocess.CalledProcessError(returncode=retcode, cmd=cmds,\n            output=output)\n    LOG.debug('ssh command in:  %s out: %s err: %s ', stdin, stdout, stderr)\n    retcode = stdout.channel.recv_exit_status()\n    LOG.debug('Paramiko return code : %s ', retcode)\n    client.close()\n    if retcode > 0:\n        output = stderr.read().strip()\n        raise subprocess.CalledProcessError(returncode=retcode, cmd=cmds,\n            output=output)\n    results = stdout.read()\n    LOG.debug('ssh cmd %s | out: %s | err: %s ', cmds, results, retcode)\n    if 'Command fail. Return code' in str(results):\n        raise subprocess.CalledProcessError(returncode=retcode, cmd=cmds,\n            output=results)\n    return ''.join(str(results)), ''.join(str(stderr.read().strip()))\n","code_tokens":["@staticmethod\ndef","ssh(cmds,","host,","user,","password=None,","port=22):\n","","","","","\"\"\"\n","","","","client","=","paramiko.SSHClient()\n","","","","client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n","","","","client.connect(host,","port=port,","username=user,","password=password,\n","","","","","","","","allow_agent=False,","timeout=10)\n","","","","LOG.debug('ssh","login","to","","%s:%s","',","host,","port)\n","","","","try:\n","","","","","","","","stdin,","stdout,","stderr","=","client.exec_command(cmds)\n","","","","except:\n","","","","","","","","LOG.debug('exec_command","failed')\n","","","","","","","","raise","subprocess.CalledProcessError(returncode=retcode,","cmd=cmds,\n","","","","","","","","","","","","output=output)\n","","","","LOG.debug('ssh","command","in:","","%s","out:","%s","err:","%s","',","stdin,","stdout,","stderr)\n","","","","retcode","=","stdout.channel.recv_exit_status()\n","","","","LOG.debug('Paramiko","return","code",":","%s","',","retcode)\n","","","","client.close()\n","","","","if","retcode",">","0:\n","","","","","","","","output","=","stderr.read().strip()\n","","","","","","","","raise","subprocess.CalledProcessError(returncode=retcode,","cmd=cmds,\n","","","","","","","","","","","","output=output)\n","","","","results","=","stdout.read()\n","","","","LOG.debug('ssh","cmd","%s","|","out:","%s","|","err:","%s","',","cmds,","results,","retcode)\n","","","","if","'Command","fail.","Return","code'","in","str(results):\n","","","","","","","","raise","subprocess.CalledProcessError(returncode=retcode,","cmd=cmds,\n","","","","","","","","","","","","output=results)\n","","","","return","''.join(str(results)),","''.join(str(stderr.read().strip()))\n"],"func_name":"fortiosapi\/class:FortiOSAPI\/ssh","docstring":"Send a multi line string via ssh to the fortigate ","docstring_tokens":["Send","a","multi","line","string","via","ssh","to","the","fortigate"],"summary":"Send a multi line string via ssh to the fortigate ","code_with_docstring":"@staticmethod\ndef ssh(cmds, host, user, password=None, port=22):\n    \"\"\" Send a multi line string via ssh to the fortigate \"\"\"\n    client = paramiko.SSHClient()\n    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n    client.connect(host, port=port, username=user, password=password,\n        allow_agent=False, timeout=10)\n    LOG.debug('ssh login to  %s:%s ', host, port)\n    try:\n        stdin, stdout, stderr = client.exec_command(cmds)\n    except:\n        LOG.debug('exec_command failed')\n        raise subprocess.CalledProcessError(returncode=retcode, cmd=cmds,\n            output=output)\n    LOG.debug('ssh command in:  %s out: %s err: %s ', stdin, stdout, stderr)\n    retcode = stdout.channel.recv_exit_status()\n    LOG.debug('Paramiko return code : %s ', retcode)\n    client.close()\n    if retcode > 0:\n        output = stderr.read().strip()\n        raise subprocess.CalledProcessError(returncode=retcode, cmd=cmds,\n            output=output)\n    results = stdout.read()\n    LOG.debug('ssh cmd %s | out: %s | err: %s ', cmds, results, retcode)\n    if 'Command fail. Return code' in str(results):\n        raise subprocess.CalledProcessError(returncode=retcode, cmd=cmds,\n            output=results)\n    return ''.join(str(results)), ''.join(str(stderr.read().strip()))\n","code_tokens_py":[]}
{"repo":"pyspark","path":"pyspark\/\/ml\/common.pyfile:\/ml\/common.py:function:_py2java\/_py2java","language":"python","sha":"d96010479e147d51cb3cab10339bb4d40cc79427","url":"pyspark\/\/ml\/common.pyfile:\/ml\/common.py:function:_py2java\/_py2java","partition":"test","code":"def _py2java(sc, obj):\n     \"\"\"\n    if isinstance(obj, RDD):\n        obj = _to_java_object_rdd(obj)\n    elif isinstance(obj, DataFrame):\n        obj = obj._jdf\n    elif isinstance(obj, SparkContext):\n        obj = obj._jsc\n    elif isinstance(obj, list):\n        obj = [_py2java(sc, x) for x in obj]\n    elif isinstance(obj, JavaObject):\n        pass\n    elif isinstance(obj, (int, long, float, bool, bytes, unicode)):\n        pass\n    else:\n        data = bytearray(PickleSerializer().dumps(obj))\n        obj = sc._jvm.org.apache.spark.ml.python.MLSerDe.loads(data)\n    return obj\n","original_string":"def _py2java(sc, obj):\n    \"\"\" Convert Python object into Java \"\"\"\n    if isinstance(obj, RDD):\n        obj = _to_java_object_rdd(obj)\n    elif isinstance(obj, DataFrame):\n        obj = obj._jdf\n    elif isinstance(obj, SparkContext):\n        obj = obj._jsc\n    elif isinstance(obj, list):\n        obj = [_py2java(sc, x) for x in obj]\n    elif isinstance(obj, JavaObject):\n        pass\n    elif isinstance(obj, (int, long, float, bool, bytes, unicode)):\n        pass\n    else:\n        data = bytearray(PickleSerializer().dumps(obj))\n        obj = sc._jvm.org.apache.spark.ml.python.MLSerDe.loads(data)\n    return obj\n","code_tokens":["def","_py2java(sc,","obj):\n","","","","","\"\"\"\n","","","","if","isinstance(obj,","RDD):\n","","","","","","","","obj","=","_to_java_object_rdd(obj)\n","","","","elif","isinstance(obj,","DataFrame):\n","","","","","","","","obj","=","obj._jdf\n","","","","elif","isinstance(obj,","SparkContext):\n","","","","","","","","obj","=","obj._jsc\n","","","","elif","isinstance(obj,","list):\n","","","","","","","","obj","=","[_py2java(sc,","x)","for","x","in","obj]\n","","","","elif","isinstance(obj,","JavaObject):\n","","","","","","","","pass\n","","","","elif","isinstance(obj,","(int,","long,","float,","bool,","bytes,","unicode)):\n","","","","","","","","pass\n","","","","else:\n","","","","","","","","data","=","bytearray(PickleSerializer().dumps(obj))\n","","","","","","","","obj","=","sc._jvm.org.apache.spark.ml.python.MLSerDe.loads(data)\n","","","","return","obj\n"],"func_name":"pyspark\/file:\/ml\/common.py:function:_py2java\/_py2java","docstring":"Convert Python object into Java ","docstring_tokens":["Convert","Python","object","into","Java"],"summary":"Convert Python object into Java ","code_with_docstring":"def _py2java(sc, obj):\n    \"\"\" Convert Python object into Java \"\"\"\n    if isinstance(obj, RDD):\n        obj = _to_java_object_rdd(obj)\n    elif isinstance(obj, DataFrame):\n        obj = obj._jdf\n    elif isinstance(obj, SparkContext):\n        obj = obj._jsc\n    elif isinstance(obj, list):\n        obj = [_py2java(sc, x) for x in obj]\n    elif isinstance(obj, JavaObject):\n        pass\n    elif isinstance(obj, (int, long, float, bool, bytes, unicode)):\n        pass\n    else:\n        data = bytearray(PickleSerializer().dumps(obj))\n        obj = sc._jvm.org.apache.spark.ml.python.MLSerDe.loads(data)\n    return obj\n","code_tokens_py":[]}
{"repo":"neuroglancer_scripts","path":"neuroglancer_scripts\/\/scripts\/volume_to_precomputed_pyramid.pyfile:\/scripts\/volume_to_precomputed_pyramid.py:function:main\/main","language":"python","sha":"0f795b7bf8e271ed052d1f8b07d9bc0cc13cba59","url":"neuroglancer_scripts\/\/scripts\/volume_to_precomputed_pyramid.pyfile:\/scripts\/volume_to_precomputed_pyramid.py:function:main\/main","partition":"test","code":"def main(argv=sys.argv):\n    \"\"\"\n    import neuroglancer_scripts.utils\n    neuroglancer_scripts.utils.init_logging_for_cmdline()\n    args = parse_command_line(argv)\n    return volume_to_precomputed_pyramid(args.volume_filename, args.\n        dest_url, downscaling_method=args.downscaling_method,\n        ignore_scaling=args.ignore_scaling, input_min=args.input_min,\n        input_max=args.input_max, load_full_volume=args.load_full_volume,\n        options=vars(args)) or 0\n","original_string":"def main(argv=sys.argv):\n    \"\"\"The script's entry point.\"\"\"\n    import neuroglancer_scripts.utils\n    neuroglancer_scripts.utils.init_logging_for_cmdline()\n    args = parse_command_line(argv)\n    return volume_to_precomputed_pyramid(args.volume_filename, args.\n        dest_url, downscaling_method=args.downscaling_method,\n        ignore_scaling=args.ignore_scaling, input_min=args.input_min,\n        input_max=args.input_max, load_full_volume=args.load_full_volume,\n        options=vars(args)) or 0\n","code_tokens":["def","main(argv=sys.argv):\n","","","","\"\"\"\n","","","","import","neuroglancer_scripts.utils\n","","","","neuroglancer_scripts.utils.init_logging_for_cmdline()\n","","","","args","=","parse_command_line(argv)\n","","","","return","volume_to_precomputed_pyramid(args.volume_filename,","args.\n","","","","","","","","dest_url,","downscaling_method=args.downscaling_method,\n","","","","","","","","ignore_scaling=args.ignore_scaling,","input_min=args.input_min,\n","","","","","","","","input_max=args.input_max,","load_full_volume=args.load_full_volume,\n","","","","","","","","options=vars(args))","or","0\n"],"func_name":"neuroglancer_scripts\/file:\/scripts\/volume_to_precomputed_pyramid.py:function:main\/main","docstring":"The script's entry point.","docstring_tokens":["The","script","'s","entry","point","."],"summary":"The script's entry point.","code_with_docstring":"def main(argv=sys.argv):\n    \"\"\"The script's entry point.\"\"\"\n    import neuroglancer_scripts.utils\n    neuroglancer_scripts.utils.init_logging_for_cmdline()\n    args = parse_command_line(argv)\n    return volume_to_precomputed_pyramid(args.volume_filename, args.\n        dest_url, downscaling_method=args.downscaling_method,\n        ignore_scaling=args.ignore_scaling, input_min=args.input_min,\n        input_max=args.input_max, load_full_volume=args.load_full_volume,\n        options=vars(args)) or 0\n","code_tokens_py":[]}
{"repo":"macro_parser","path":"macro_parser\/\/models.pyclass:MacroParser\/_recurisive_parse","language":"python","sha":"d943460436a92ba1c6a68be1e60190b5f8ee4f84","url":"macro_parser\/\/models.pyclass:MacroParser\/_recurisive_parse","partition":"test","code":"def _recurisive_parse(self, content):\n    Recursive parse.\n\t\t\"\"\"\n    mp = MacroParser(content)\n    mp._macros = self._macros\n    return mp.parse()\n","original_string":"def _recurisive_parse(self, content):\n    \"\"\"Recursive parse.\n\t\t\"\"\"\n    mp = MacroParser(content)\n    mp._macros = self._macros\n    return mp.parse()\n","code_tokens":["def","_recurisive_parse(self,","content):\n","","","","Recursive","parse.\n\t\t\"\"\"\n","","","","mp","=","MacroParser(content)\n","","","","mp._macros","=","self._macros\n","","","","return","mp.parse()\n"],"func_name":"macro_parser\/class:MacroParser\/_recurisive_parse","docstring":"Recursive parse.\n                ","docstring_tokens":["Recursive","parse","."],"summary":"Recursive parse.","code_with_docstring":"def _recurisive_parse(self, content):\n    \"\"\"Recursive parse.\n\t\t\"\"\"\n    mp = MacroParser(content)\n    mp._macros = self._macros\n    return mp.parse()\n","code_tokens_py":[]}
{"repo":"eric6","path":"eric6\/\/VirtualEnv\/VirtualenvConfigurationDialog.pyclass:VirtualenvConfigurationDialog\/on_targetDirectoryPicker_textChanged","language":"python","sha":"d2f5387bd47274d0696d3d55a71663c28a1bfa89","url":"eric6\/\/VirtualEnv\/VirtualenvConfigurationDialog.pyclass:VirtualenvConfigurationDialog\/on_targetDirectoryPicker_textChanged","partition":"test","code":"@pyqtSlot(str)\ndef on_targetDirectoryPicker_textChanged(self, txt):\n    \n        Private slot handling a change of the target directory.\n        \n        @param txt target directory\n        @type str\n        \"\"\"\n    self.__updateOK()\n","original_string":"@pyqtSlot(str)\ndef on_targetDirectoryPicker_textChanged(self, txt):\n    \"\"\"\n        Private slot handling a change of the target directory.\n        \n        @param txt target directory\n        @type str\n        \"\"\"\n    self.__updateOK()\n","code_tokens":["@pyqtSlot(str)\ndef","on_targetDirectoryPicker_textChanged(self,","txt):\n","","","","\n","","","","","","","","Private","slot","handling","a","change","of","the","target","directory.\n","","","","","","","","\n","","","","","","","","@param","txt","target","directory\n","","","","","","","","@type","str\n","","","","","","","","\"\"\"\n","","","","self.__updateOK()\n"],"func_name":"eric6\/class:VirtualenvConfigurationDialog\/on_targetDirectoryPicker_textChanged","docstring":"Private slot handling a change of the target directory.\n\n@param txt target directory\n@type str","docstring_tokens":["Private","slot","handling","a","change","of","the","target","directory",".","@param","txt","target","directory","@type","str"],"summary":"Private slot handling a change of the target directory.","code_with_docstring":"@pyqtSlot(str)\ndef on_targetDirectoryPicker_textChanged(self, txt):\n    \"\"\"\n        Private slot handling a change of the target directory.\n        \n        @param txt target directory\n        @type str\n        \"\"\"\n    self.__updateOK()\n","code_tokens_py":[]}
{"repo":"finapi-0.9.9","path":"finapi-0.9.9\/\/finapi\/models\/client_configuration.pyclass:ClientConfiguration\/__repr__","language":"python","sha":"8d9a279a743453f992d61a65f87cf2bb331dc353","url":"finapi-0.9.9\/\/finapi\/models\/client_configuration.pyclass:ClientConfiguration\/__repr__","partition":"test","code":"def __repr__(self):\n    \"\"\"\n    return self.to_str()\n","original_string":"def __repr__(self):\n    \"\"\"For `print` and `pprint`\"\"\"\n    return self.to_str()\n","code_tokens":["def","__repr__(self):\n","","","","\"\"\"\n","","","","return","self.to_str()\n"],"func_name":"finapi-0.9.9\/class:ClientConfiguration\/__repr__","docstring":"For `print` and `pprint`","docstring_tokens":["For","`","print","`","and","`","pprint","`"],"summary":"For `print` and `pprint`","code_with_docstring":"def __repr__(self):\n    \"\"\"For `print` and `pprint`\"\"\"\n    return self.to_str()\n","code_tokens_py":[]}
{"repo":"common-dibbs-0.1.9.3.7","path":"common-dibbs-0.1.9.3.7\/\/common_dibbs\/clients\/om_client\/models\/user.pyclass:User\/operation_definitions","language":"python","sha":"6b9240f9671270b93df424f1eefc988a66108549","url":"common-dibbs-0.1.9.3.7\/\/common_dibbs\/clients\/om_client\/models\/user.pyclass:User\/operation_definitions","partition":"test","code":"@property\ndef operation_definitions(self):\n    \n        Gets the operation_definitions of this User.\n        Array of IDs of all the process descriptions created by the user\n\n        :return: The operation_definitions of this User.\n        :rtype: list[int]\n        \"\"\"\n    return self._operation_definitions\n","original_string":"@property\ndef operation_definitions(self):\n    \"\"\"\n        Gets the operation_definitions of this User.\n        Array of IDs of all the process descriptions created by the user\n\n        :return: The operation_definitions of this User.\n        :rtype: list[int]\n        \"\"\"\n    return self._operation_definitions\n","code_tokens":["@property\ndef","operation_definitions(self):\n","","","","\n","","","","","","","","Gets","the","operation_definitions","of","this","User.\n","","","","","","","","Array","of","IDs","of","all","the","process","descriptions","created","by","the","user\n\n","","","","","","","",":return:","The","operation_definitions","of","this","User.\n","","","","","","","",":rtype:","list[int]\n","","","","","","","","\"\"\"\n","","","","return","self._operation_definitions\n"],"func_name":"common-dibbs-0.1.9.3.7\/class:User\/operation_definitions","docstring":"Gets the operation_definitions of this User.\nArray of IDs of all the process descriptions created by the user\n\n:return: The operation_definitions of this User.\n:rtype: list[int]","docstring_tokens":["Gets","the","operation_definitions","of","this","User",".","Array","of","IDs","of","all","the","process","descriptions","created","by","the","user",":","return",":","The","operation_definitions","of","this","User",".",":","rtype",":","list[int","]"],"summary":"Gets the operation_definitions of this User.","code_with_docstring":"@property\ndef operation_definitions(self):\n    \"\"\"\n        Gets the operation_definitions of this User.\n        Array of IDs of all the process descriptions created by the user\n\n        :return: The operation_definitions of this User.\n        :rtype: list[int]\n        \"\"\"\n    return self._operation_definitions\n","code_tokens_py":[]}
{"repo":"anonapi-1.1.2","path":"anonapi-1.1.2\/\/anonapi\/responses.pyclass:JobInfo\/as_string","language":"python","sha":"74438866d305f804a40a9f304e3c3684fbb65755","url":"anonapi-1.1.2\/\/anonapi\/responses.pyclass:JobInfo\/as_string","partition":"test","code":"def as_string(self):\n    \"\"\"\n    to_print = {'job_id': self.job_id, 'date': self.date, 'user_name': self\n        .user_name, 'status': self.status, 'error': self.error,\n        'description': self.description, 'project_name': self.project_name,\n        'priority': self.priority, 'files_downloaded': self.\n        files_downloaded, 'files_processed': self.files_processed,\n        'destination_path': self.destination_path, 'source_type': self.\n        source_type, 'source_anonymizedpatientid': self.\n        source_anonymizedpatientid, 'source_anonymizedpatientname': self.\n        source_anonymizedpatientname, 'source_name': self.source_name,\n        'source_path': self.source_path, 'source_pims_keyfile_id': self.\n        source_pims_keyfile_id, 'source_instance_id': self.source_instance_id}\n    return '\\n'.join([str(x) for x in to_print.items()])\n","original_string":"def as_string(self):\n    \"\"\"As human readable  multi-line string\"\"\"\n    to_print = {'job_id': self.job_id, 'date': self.date, 'user_name': self\n        .user_name, 'status': self.status, 'error': self.error,\n        'description': self.description, 'project_name': self.project_name,\n        'priority': self.priority, 'files_downloaded': self.\n        files_downloaded, 'files_processed': self.files_processed,\n        'destination_path': self.destination_path, 'source_type': self.\n        source_type, 'source_anonymizedpatientid': self.\n        source_anonymizedpatientid, 'source_anonymizedpatientname': self.\n        source_anonymizedpatientname, 'source_name': self.source_name,\n        'source_path': self.source_path, 'source_pims_keyfile_id': self.\n        source_pims_keyfile_id, 'source_instance_id': self.source_instance_id}\n    return '\\n'.join([str(x) for x in to_print.items()])\n","code_tokens":["def","as_string(self):\n","","","","\"\"\"\n","","","","to_print","=","{'job_id':","self.job_id,","'date':","self.date,","'user_name':","self\n","","","","","","","",".user_name,","'status':","self.status,","'error':","self.error,\n","","","","","","","","'description':","self.description,","'project_name':","self.project_name,\n","","","","","","","","'priority':","self.priority,","'files_downloaded':","self.\n","","","","","","","","files_downloaded,","'files_processed':","self.files_processed,\n","","","","","","","","'destination_path':","self.destination_path,","'source_type':","self.\n","","","","","","","","source_type,","'source_anonymizedpatientid':","self.\n","","","","","","","","source_anonymizedpatientid,","'source_anonymizedpatientname':","self.\n","","","","","","","","source_anonymizedpatientname,","'source_name':","self.source_name,\n","","","","","","","","'source_path':","self.source_path,","'source_pims_keyfile_id':","self.\n","","","","","","","","source_pims_keyfile_id,","'source_instance_id':","self.source_instance_id}\n","","","","return","'\\n'.join([str(x)","for","x","in","to_print.items()])\n"],"func_name":"anonapi-1.1.2\/class:JobInfo\/as_string","docstring":"As human readable  multi-line string","docstring_tokens":["As","human","readable","multi","-","line","string"],"summary":"As human readable  multi-line string","code_with_docstring":"def as_string(self):\n    \"\"\"As human readable  multi-line string\"\"\"\n    to_print = {'job_id': self.job_id, 'date': self.date, 'user_name': self\n        .user_name, 'status': self.status, 'error': self.error,\n        'description': self.description, 'project_name': self.project_name,\n        'priority': self.priority, 'files_downloaded': self.\n        files_downloaded, 'files_processed': self.files_processed,\n        'destination_path': self.destination_path, 'source_type': self.\n        source_type, 'source_anonymizedpatientid': self.\n        source_anonymizedpatientid, 'source_anonymizedpatientname': self.\n        source_anonymizedpatientname, 'source_name': self.source_name,\n        'source_path': self.source_path, 'source_pims_keyfile_id': self.\n        source_pims_keyfile_id, 'source_instance_id': self.source_instance_id}\n    return '\\n'.join([str(x) for x in to_print.items()])\n","code_tokens_py":[]}
