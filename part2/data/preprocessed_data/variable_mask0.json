{"input": "\n from django . utils . translation import ugettext_lazy as _ \n from horizon import tabs \n class NetworkProfileTab ( tabs . Tab ) : \n <mask0> = _ ( \"<STR_LIT>\" ) \n slug = \"<STR_LIT>\" \n template_name = '<STR_LIT>' \n def get_context_data ( self , request ) : \n return None \n class PolicyProfileTab ( tabs . Tab ) : \n name = _ ( \"<STR_LIT>\" ) \n slug = \"<STR_LIT>\" \n template_name = '<STR_LIT>' \n preload = False \n class IndexTabs ( tabs . TabGroup ) : \n slug = \"<STR_LIT>\" \n tabs = ( NetworkProfileTab , PolicyProfileTab ) \n", "gt": "name"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import weakref \n from eventlet import corolocal \n class WeakLocal ( corolocal . local ) : \n def __getattribute__ ( self , attr ) : \n <mask0> = corolocal . local . __getattribute__ ( self , attr ) \n if rval : \n rval = rval ( ) \n return rval \n def __setattr__ ( self , attr , value ) : \n value = weakref . ref ( value ) \n return corolocal . local . __setattr__ ( self , attr , value ) \n store = WeakLocal ( ) \n weak_store = WeakLocal ( ) \n strong_store = corolocal . local \n", "gt": "rval"}
{"input": "\n import eventlet \n eventlet . monkey_patch ( ) \n import contextlib \n import sys \n from oslo . config import cfg \n from openstack_dashboard . openstack . common import log as logging \n from openstack_dashboard . openstack . common import rpc \n from openstack_dashboard . openstack . common . rpc import impl_zmq \n <mask0> = cfg . CONF \n CONF . register_opts ( rpc . rpc_opts ) \n CONF . register_opts ( impl_zmq . zmq_opts ) \n def main ( ) : \n CONF ( sys . argv [ <NUM_LIT:1> : ] , project = '<STR_LIT>' ) \n logging . setup ( \"<STR_LIT>\" ) \n with contextlib . closing ( impl_zmq . ZmqProxy ( CONF ) ) as reactor : \n reactor . consume_in_thread ( ) \n reactor . wait ( ) \n", "gt": "CONF"}
{"input": "\n from openstack_dashboard import api \n from openstack_dashboard . test import helpers as test \n from neutronclient . v2_0 import client \n <mask0> = client . Client \n class VPNaasApiTests ( test . APITestCase ) : \n @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) \n def test_vpnservice_create ( self ) : \n vpnservice1 = self . api_vpnservices . first ( ) \n form_data = { \n '<STR_LIT:name>' : vpnservice1 [ '<STR_LIT:name>' ] , \n '<STR_LIT:description>' : vpnservice1 [ '<STR_LIT:description>' ] , \n '<STR_LIT>' : vpnservice1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : vpnservice1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : vpnservice1 [ '<STR_LIT>' ] \n } \n vpnservice = { '<STR_LIT>' : self . api_vpnservices . first ( ) } \n neutronclient . create_vpnservice ( \n { '<STR_LIT>' : form_data } ) . AndReturn ( vpnservice ) \n self . mox . ReplayAll ( ) \n ret_val = api . vpn . vpnservice_create ( self . request , ** form_data ) \n self . assertIsInstance ( ret_val , api . vpn . VPNService ) \n @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) \n def test_vpnservices_get ( self ) : \n vpnservices = { '<STR_LIT>' : self . vpnservices . list ( ) } \n vpnservices_dict = { '<STR_LIT>' : self . api_vpnservices . list ( ) } \n neutronclient . list_vpnservices ( ) . AndReturn ( vpnservices_dict ) \n self . mox . ReplayAll ( ) \n ret_val = api . vpn . vpnservices_get ( self . request ) \n for ( v , d ) in zip ( ret_val , vpnservices [ '<STR_LIT>' ] ) : \n self . assertIsInstance ( v , api . vpn . VPNService ) \n self . assertTrue ( v . name , d . name ) \n self . assertTrue ( v . id ) \n @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) \n def test_vpnservice_get ( self ) : \n vpnservice1 = self . api_vpnservices . first ( ) \n vpnservice = { '<STR_LIT>' : vpnservice1 } \n neutronclient . show_vpnservice ( \n vpnservice [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) . AndReturn ( vpnservice ) \n self . mox . ReplayAll ( ) \n ret_val = api . vpn . vpnservice_get ( self . request , \n vpnservice [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) \n self . assertIsInstance ( ret_val , api . vpn . VPNService ) \n @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) \n def test_ikepolicy_create ( self ) : \n ikepolicy1 = self . api_ikepolicies . first ( ) \n form_data = { \n '<STR_LIT:name>' : ikepolicy1 [ '<STR_LIT:name>' ] , \n '<STR_LIT:description>' : ikepolicy1 [ '<STR_LIT:description>' ] , \n '<STR_LIT>' : ikepolicy1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ikepolicy1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ikepolicy1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ikepolicy1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ikepolicy1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ikepolicy1 [ '<STR_LIT>' ] \n } \n ikepolicy = { '<STR_LIT>' : self . api_ikepolicies . first ( ) } \n neutronclient . create_ikepolicy ( \n { '<STR_LIT>' : form_data } ) . AndReturn ( ikepolicy ) \n self . mox . ReplayAll ( ) \n ret_val = api . vpn . ikepolicy_create ( self . request , ** form_data ) \n self . assertIsInstance ( ret_val , api . vpn . IKEPolicy ) \n @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) \n def test_ikepolicies_get ( self ) : \n ikepolicies = { '<STR_LIT>' : self . ikepolicies . list ( ) } \n ikepolicies_dict = { '<STR_LIT>' : self . api_ikepolicies . list ( ) } \n neutronclient . list_ikepolicies ( ) . AndReturn ( ikepolicies_dict ) \n self . mox . ReplayAll ( ) \n ret_val = api . vpn . ikepolicies_get ( self . request ) \n for ( v , d ) in zip ( ret_val , ikepolicies [ '<STR_LIT>' ] ) : \n self . assertIsInstance ( v , api . vpn . IKEPolicy ) \n self . assertTrue ( v . name , d . name ) \n self . assertTrue ( v . id ) \n @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) \n def test_ikepolicy_get ( self ) : \n ikepolicy1 = self . api_ikepolicies . first ( ) \n ikepolicy = { '<STR_LIT>' : ikepolicy1 } \n neutronclient . show_ikepolicy ( \n ikepolicy [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) . AndReturn ( ikepolicy ) \n self . mox . ReplayAll ( ) \n ret_val = api . vpn . ikepolicy_get ( self . request , \n ikepolicy [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) \n self . assertIsInstance ( ret_val , api . vpn . IKEPolicy ) \n @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) \n def test_ipsecpolicy_create ( self ) : \n ipsecpolicy1 = self . api_ipsecpolicies . first ( ) \n form_data = { \n '<STR_LIT:name>' : ipsecpolicy1 [ '<STR_LIT:name>' ] , \n '<STR_LIT:description>' : ipsecpolicy1 [ '<STR_LIT:description>' ] , \n '<STR_LIT>' : ipsecpolicy1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ipsecpolicy1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ipsecpolicy1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ipsecpolicy1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ipsecpolicy1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ipsecpolicy1 [ '<STR_LIT>' ] \n } \n ipsecpolicy = { '<STR_LIT>' : self . api_ipsecpolicies . first ( ) } \n neutronclient . create_ipsecpolicy ( \n { '<STR_LIT>' : form_data } ) . AndReturn ( ipsecpolicy ) \n self . mox . ReplayAll ( ) \n ret_val = api . vpn . ipsecpolicy_create ( self . request , ** form_data ) \n self . assertIsInstance ( ret_val , api . vpn . IPSecPolicy ) \n @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) \n def test_ipsecpolicies_get ( self ) : \n ipsecpolicies = { '<STR_LIT>' : self . ipsecpolicies . list ( ) } \n ipsecpolicies_dict = { '<STR_LIT>' : self . api_ipsecpolicies . list ( ) } \n neutronclient . list_ipsecpolicies ( ) . AndReturn ( ipsecpolicies_dict ) \n self . mox . ReplayAll ( ) \n ret_val = api . vpn . ipsecpolicies_get ( self . request ) \n for ( v , d ) in zip ( ret_val , ipsecpolicies [ '<STR_LIT>' ] ) : \n self . assertIsInstance ( v , api . vpn . IPSecPolicy ) \n self . assertTrue ( v . name , d . name ) \n self . assertTrue ( v . id ) \n @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) \n def test_ipsecpolicy_get ( self ) : \n ipsecpolicy1 = self . api_ipsecpolicies . first ( ) \n ipsecpolicy = { '<STR_LIT>' : ipsecpolicy1 } \n neutronclient . show_ipsecpolicy ( \n ipsecpolicy [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) . AndReturn ( ipsecpolicy ) \n self . mox . ReplayAll ( ) \n ret_val = api . vpn . ipsecpolicy_get ( self . request , \n ipsecpolicy [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) \n self . assertIsInstance ( ret_val , api . vpn . IPSecPolicy ) \n @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) \n def test_ipsecsiteconnection_create ( self ) : \n ipsecsiteconnection1 = self . api_ipsecsiteconnections . first ( ) \n form_data = { \n '<STR_LIT:name>' : ipsecsiteconnection1 [ '<STR_LIT:name>' ] , \n '<STR_LIT:description>' : ipsecsiteconnection1 [ '<STR_LIT:description>' ] , \n '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , \n '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] \n } \n ipsecsiteconnection = { '<STR_LIT>' : \n self . api_ipsecsiteconnections . first ( ) } \n neutronclient . create_ipsec_site_connection ( \n { '<STR_LIT>' : \n form_data } ) . AndReturn ( ipsecsiteconnection ) \n self . mox . ReplayAll ( ) \n ret_val = api . vpn . ipsecsiteconnection_create ( \n self . request , ** form_data ) \n self . assertIsInstance ( ret_val , api . vpn . IPSecSiteConnection ) \n @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) \n def test_ipsecsiteconnections_get ( self ) : \n ipsecsiteconnections = { \n '<STR_LIT>' : self . ipsecsiteconnections . list ( ) } \n ipsecsiteconnections_dict = { \n '<STR_LIT>' : self . api_ipsecsiteconnections . list ( ) } \n neutronclient . list_ipsec_site_connections ( ) . AndReturn ( \n ipsecsiteconnections_dict ) \n self . mox . ReplayAll ( ) \n ret_val = api . vpn . ipsecsiteconnections_get ( self . request ) \n for ( v , d ) in zip ( ret_val , \n ipsecsiteconnections [ '<STR_LIT>' ] ) : \n self . assertIsInstance ( v , api . vpn . IPSecSiteConnection ) \n self . assertTrue ( v . name , d . name ) \n self . assertTrue ( v . id ) \n @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) \n def test_ipsecsiteconnection_get ( self ) : \n ipsecsiteconnection1 = self . api_ipsecsiteconnections . first ( ) \n ipsecsiteconnection = { '<STR_LIT>' : ipsecsiteconnection1 } \n neutronclient . show_ipsec_site_connection ( \n ipsecsiteconnection [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) . AndReturn ( \n ipsecsiteconnection ) \n self . mox . ReplayAll ( ) \n ret_val = api . vpn . ipsecsiteconnection_get ( self . request , \n ipsecsiteconnection [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) \n self . assertIsInstance ( ret_val , api . vpn . IPSecSiteConnection ) \n", "gt": "neutronclient"}
{"input": "\n from horizon import tables \n from openstack_dashboard . usage import base \n class UsageView ( tables . DataTableView ) : \n <mask0> = None \n show_terminated = True \n def __init__ ( self , * args , ** kwargs ) : \n super ( UsageView , self ) . __init__ ( * args , ** kwargs ) \n if not issubclass ( self . usage_class , base . BaseUsage ) : \n raise AttributeError ( \"<STR_LIT>\" \n \"<STR_LIT>\" ) \n def get_template_names ( self ) : \n if self . request . GET . get ( '<STR_LIT>' , '<STR_LIT:html>' ) == '<STR_LIT>' : \n return \"<STR_LIT:.>\" . join ( ( self . template_name . rsplit ( '<STR_LIT:.>' , <NUM_LIT:1> ) [ <NUM_LIT:0> ] , '<STR_LIT>' ) ) \n return self . template_name \n def get_content_type ( self ) : \n if self . request . GET . get ( '<STR_LIT>' , '<STR_LIT:html>' ) == '<STR_LIT>' : \n return \"<STR_LIT>\" \n return \"<STR_LIT>\" \n def get_data ( self ) : \n project_id = self . kwargs . get ( '<STR_LIT>' , self . request . user . tenant_id ) \n self . usage = self . usage_class ( self . request , project_id ) \n self . usage . summarize ( * self . usage . get_date_range ( ) ) \n self . usage . get_limits ( ) \n self . kwargs [ '<STR_LIT>' ] = self . usage \n return self . usage . usage_list \n def get_context_data ( self , ** kwargs ) : \n context = super ( UsageView , self ) . get_context_data ( ** kwargs ) \n context [ '<STR_LIT>' ] . kwargs [ '<STR_LIT>' ] = self . usage \n context [ '<STR_LIT>' ] = self . usage . form \n context [ '<STR_LIT>' ] = self . usage \n return context \n def render_to_response ( self , context , ** response_kwargs ) : \n if self . request . GET . get ( '<STR_LIT>' , '<STR_LIT:html>' ) == '<STR_LIT>' : \n render_class = self . csv_response_class \n response_kwargs . setdefault ( \"<STR_LIT:filename>\" , \"<STR_LIT>\" ) \n else : \n render_class = self . response_class \n resp = render_class ( request = self . request , \n template = self . get_template_names ( ) , \n context = context , \n content_type = self . get_content_type ( ) , \n ** response_kwargs ) \n return resp \n", "gt": "usage_class"}
{"input": "\n from enum import IntEnum \n from . component import Component \n from . object import field \n class ReflectionProbeUsage ( IntEnum ) : \n <mask0> = <NUM_LIT:0> \n BlendProbes = <NUM_LIT:1> \n BlendProbesAndSkybox = <NUM_LIT:2> \n Simple = <NUM_LIT:3> \n class ShadowCastingMode ( IntEnum ) : \n Off = <NUM_LIT:0> \n On = <NUM_LIT:1> \n TwoSided = <NUM_LIT:2> \n ShadowsOnly = <NUM_LIT:3> \n class Renderer ( Component ) : \n enabled = field ( \"<STR_LIT>\" , bool ) \n lightmap_index = field ( \"<STR_LIT>\" ) \n materials = field ( \"<STR_LIT>\" ) \n probe_anchor = field ( \"<STR_LIT>\" ) \n receive_shadows = field ( \"<STR_LIT>\" , bool ) \n reflection_probe_usage = field ( \"<STR_LIT>\" , ReflectionProbeUsage ) \n shadow_casting_mode = field ( \"<STR_LIT>\" , ShadowCastingMode ) \n sorting_layer_id = field ( \"<STR_LIT>\" ) \n sorting_order = field ( \"<STR_LIT>\" ) \n use_light_probes = field ( \"<STR_LIT>\" , bool ) \n lightmap_index_dynamic = field ( \"<STR_LIT>\" ) \n lightmap_tiling_offset = field ( \"<STR_LIT>\" ) \n lightmap_tiling_offset_dynamic = field ( \"<STR_LIT>\" ) \n static_batch_root = field ( \"<STR_LIT>\" ) \n subset_indices = field ( \"<STR_LIT>\" ) \n @ property \n def material ( self ) : \n return self . materials [ <NUM_LIT:0> ] \n class ParticleSystemRenderMode ( IntEnum ) : \n Billboard = <NUM_LIT:0> \n Stretch = <NUM_LIT:1> \n HorizontalBillboard = <NUM_LIT:2> \n VerticalBillboard = <NUM_LIT:3> \n Mesh = <NUM_LIT:4> \n class ParticleSystemSortMode ( IntEnum ) : \n None_ = <NUM_LIT:0> \n Distance = <NUM_LIT:1> \n OldestInFront = <NUM_LIT:2> \n YoungestInFront = <NUM_LIT:3> \n class MeshRenderer ( Component ) : \n pass \n class ParticleRenderer ( Renderer ) : \n camera_velocity_scale = field ( \"<STR_LIT>\" ) \n length_scale = field ( \"<STR_LIT>\" ) \n max_particle_size = field ( \"<STR_LIT>\" ) \n velocity_scale = field ( \"<STR_LIT>\" ) \n stretch_particles = field ( \"<STR_LIT>\" ) \n uv_animation = field ( \"<STR_LIT>\" ) \n class ParticleSystemRenderer ( Renderer ) : \n camera_velocity_scale = field ( \"<STR_LIT>\" ) \n length_scale = field ( \"<STR_LIT>\" ) \n max_particle_size = field ( \"<STR_LIT>\" ) \n mesh = field ( \"<STR_LIT>\" ) \n mesh1 = field ( \"<STR_LIT>\" ) \n mesh2 = field ( \"<STR_LIT>\" ) \n mesh3 = field ( \"<STR_LIT>\" ) \n normal_direction = field ( \"<STR_LIT>\" ) \n render_mode = field ( \"<STR_LIT>\" , ParticleSystemRenderMode ) \n sort_mode = field ( \"<STR_LIT>\" , ParticleSystemSortMode ) \n sorting_fudge = field ( \"<STR_LIT>\" ) \n velocity_scale = field ( \"<STR_LIT>\" ) \n", "gt": "Off"}
{"input": "\n from ConfigParser import * \n from StringIO import * \n from Log import Log \n import datetime \n class Config : \n @ staticmethod \n def LoadConfig ( ) : \n Config . parser = ConfigParser ( ) \n try : \n <mask0> = open ( CONFIG_FILE , \"<STR_LIT:r>\" ) \n except : \n Log . warn ( \"<STR_LIT>\" ) \n return \n sconf = StringIO ( ) \n sconf . write ( \"<STR_LIT>\" ) \n sconf . write ( sconff . read ( ) ) \n sconf . seek ( <NUM_LIT:0> ) \n Config . parser . readfp ( sconf ) \n sconff . close ( ) \n sconf . close ( ) \n return \n @ staticmethod \n def GetBoardsFile ( ) : \n return BOARDS_FILE \n @ staticmethod \n def GetInt ( name , defval ) : \n if ( Config . parser . has_option ( '<STR_LIT>' , name ) ) : \n return Config . parser . getint ( '<STR_LIT>' , name ) \n else : \n return defval \n @ staticmethod \n def GetString ( name , defval ) : \n if ( Config . parser . has_option ( '<STR_LIT>' , name ) ) : \n val = Config . parser . get ( '<STR_LIT>' , name ) \n if ( val [ <NUM_LIT:0> ] == '<STR_LIT:\">' and val . endswith ( '<STR_LIT:\">' ) ) : \n val = val [ <NUM_LIT:1> : - <NUM_LIT:1> ] \n return val . decode ( '<STR_LIT>' ) \n else : \n return defval \n BBS_ROOT = '<STR_LIT>' \n BBS_XMPP_CERT_FILE = BBS_ROOT + \"<STR_LIT>\" \n BBS_XMPP_KEY_FILE = BBS_ROOT + \"<STR_LIT>\" \n BOARDS_FILE = BBS_ROOT + '<STR_LIT>' \n STRLEN = <NUM_LIT> \n ARTICLE_TITLE_LEN = <NUM_LIT> \n BM_LEN = <NUM_LIT> \n MAXBOARD = <NUM_LIT> \n CONFIG_FILE = BBS_ROOT + '<STR_LIT>' \n FILENAME_LEN = <NUM_LIT:20> \n OWNER_LEN = <NUM_LIT:30> \n SESSIONID_LEN = <NUM_LIT:32> \n REFRESH_TOKEN_LEN = <NUM_LIT> \n NAMELEN = <NUM_LIT> \n IDLEN = <NUM_LIT:12> \n MD5PASSLEN = <NUM_LIT:16> \n OLDPASSLEN = <NUM_LIT> \n MOBILE_NUMBER_LEN = <NUM_LIT> \n MAXCLUB = <NUM_LIT> \n MAXUSERS = <NUM_LIT> \n MAX_MSG_SIZE = <NUM_LIT> \n MAXFRIENDS = <NUM_LIT> \n MAXMESSAGE = <NUM_LIT:5> \n MAXSIGLINES = <NUM_LIT:6> \n IPLEN = <NUM_LIT:16> \n DEFAULTBOARD = \"<STR_LIT>\" \n BLESS_BOARD = \"<STR_LIT>\" \n QUOTED_LINES = <NUM_LIT:10> \n MAXACTIVE = <NUM_LIT> \n USHM_SIZE = MAXACTIVE + <NUM_LIT:10> \n UTMP_HASHSIZE = USHM_SIZE * <NUM_LIT:4> \n UCACHE_SEMLOCK = <NUM_LIT:0> \n LEN_FRIEND_EXP = <NUM_LIT:15> \n REFRESH_TIME = <NUM_LIT:30> \n USER_TITLE_LEN = <NUM_LIT> \n SESSION_TIMEOUT = datetime . timedelta ( <NUM_LIT:30> ) \n SESSION_TIMEOUT_SECONDS = <NUM_LIT> * <NUM_LIT:30> \n XMPP_IDLE_TIME = <NUM_LIT> \n XMPP_LONG_IDLE_TIME = <NUM_LIT> \n XMPP_UPDATE_TIME_INTERVAL = <NUM_LIT:10> \n XMPP_PING_TIME_INTERVAL = <NUM_LIT> \n PUBLIC_SHMKEY = <NUM_LIT> \n MAX_ATTACHSIZE = <NUM_LIT:20> * <NUM_LIT> * <NUM_LIT> \n BMDEL_DECREASE = True \n SYSMAIL_BOARD = \"<STR_LIT>\" \n ADD_EDITMARK = True \n SEARCH_COUNT_LIMIT = <NUM_LIT:20> \n MAIL_SIZE_LIMIT = - <NUM_LIT:1> \n SEC_DELETED_OLDHOME = <NUM_LIT> * <NUM_LIT> * <NUM_LIT:3> \n SELF_INTRO_MAX_LEN = <NUM_LIT> \n", "gt": "sconff"}
{"input": "\n import re \n import os \n import stat \n import json \n import struct \n import time \n import Config \n import Board \n import Post \n import BoardManager \n from Util import Util \n from Log import Log \n from errors import * \n <mask0> = <NUM_LIT:20> \n class DigestItem : \n def __init__ ( self , basepath ) : \n self . basepath = basepath \n self . title = '<STR_LIT>' \n self . host = '<STR_LIT>' \n self . port = <NUM_LIT:0> \n self . attachpos = <NUM_LIT:0> \n self . fname = '<STR_LIT>' \n self . mtitle = '<STR_LIT>' \n self . items = [ ] \n self . update_time = <NUM_LIT:0> \n self . id = <NUM_LIT:0> \n self . sysop_only = <NUM_LIT:0> \n self . bms_only = <NUM_LIT:0> \n self . zixia_only = <NUM_LIT:0> \n def IsDir ( self ) : \n try : \n st = os . stat ( self . realpath ( ) ) \n return stat . S_ISDIR ( st . st_mode ) \n except : \n return False \n def IsFile ( self ) : \n try : \n st = os . stat ( self . realpath ( ) ) \n return stat . S_ISREG ( st . st_mode ) \n except : \n return False \n def GetModTime ( self ) : \n try : \n st = os . stat ( self . realpath ( ) ) \n mtime = st . st_mtime \n except : \n mtime = time . time ( ) \n return mtime \n def names_path ( self ) : \n return \"<STR_LIT>\" % self . realpath ( ) \n def realpath ( self ) : \n return \"<STR_LIT>\" % ( Config . BBS_ROOT , self . path ( ) ) \n def path ( self ) : \n if ( self . fname ) : \n return \"<STR_LIT>\" % ( self . basepath , self . fname ) \n else : \n return self . basepath \n def CheckUpdate ( self ) : \n try : \n stat = os . stat ( self . names_path ( ) ) \n if ( stat . st_mtime > self . update_time ) : \n self . LoadNames ( ) \n except : \n return False \n return True \n def LoadNames ( self ) : \n try : \n f = open ( self . names_path ( ) , \"<STR_LIT:r>\" ) \n except IOError : \n return <NUM_LIT:0> \n stat = os . fstat ( f . fileno ( ) ) \n self . update_time = stat . st_mtime \n item = DigestItem ( self . path ( ) ) \n hostname = '<STR_LIT>' \n _id = <NUM_LIT:0> \n bms_only = <NUM_LIT:0> \n sysop_only = <NUM_LIT:0> \n zixia_only = <NUM_LIT:0> \n while ( True ) : \n line = f . readline ( ) \n if ( line == \"<STR_LIT>\" ) : break \n npos = line . find ( \"<STR_LIT:\\n>\" ) \n if ( npos != - <NUM_LIT:1> ) : line = line [ : npos ] \n if ( line [ : <NUM_LIT:1> ] == '<STR_LIT:#>' ) : \n if ( line [ : <NUM_LIT:8> ] == \"<STR_LIT>\" ) : \n if ( not self . mtitle ) : \n self . mtitle = line [ <NUM_LIT:8> : ] \n result = re . match ( '<STR_LIT>' , line ) \n if ( result ) : \n key = result . group ( <NUM_LIT:1> ) \n value = result . group ( <NUM_LIT:2> ) \n if ( key == \"<STR_LIT:Name>\" ) : \n item . title = value \n item . attachpos = <NUM_LIT:0> \n elif ( key == \"<STR_LIT>\" ) : \n if ( value [ : <NUM_LIT:2> ] == \"<STR_LIT>\" ) : \n item . fname = value [ <NUM_LIT:2> : ] \n else : \n item . fname = value \n if ( item . fname . find ( \"<STR_LIT:..>\" ) != - <NUM_LIT:1> ) : \n continue \n if ( item . title . find ( \"<STR_LIT>\" ) != - <NUM_LIT:1> ) : \n bms_only += <NUM_LIT:1> \n elif ( item . title . find ( \"<STR_LIT>\" ) != - <NUM_LIT:1> ) : \n sysop_only += <NUM_LIT:1> \n elif ( item . title . find ( \"<STR_LIT>\" ) != - <NUM_LIT:1> ) : \n zixia_only += <NUM_LIT:1> \n if ( item . fname . find ( \"<STR_LIT>\" ) != - <NUM_LIT:1> ) : \n parts = re . split ( '<STR_LIT>' , item . fname ) \n newparts = [ ] \n for part in parts : \n if ( part ) : \n newparts += [ part ] \n hostname = newparts [ <NUM_LIT:0> ] \n item . fname = newparts [ <NUM_LIT:1> ] \n try : \n item . port = int ( newparts [ <NUM_LIT:2> ] ) \n except : \n item . port = <NUM_LIT:0> \n item . id = _id \n _id += <NUM_LIT:1> \n item . bms_only = bms_only \n item . sysop_only = sysop_only \n item . zixia_only = zixia_only \n item . host = hostname \n self . items += [ item ] \n item = DigestItem ( self . path ( ) ) \n hostname = '<STR_LIT>' \n elif ( key == \"<STR_LIT>\" ) : \n hostname = value \n elif ( key == \"<STR_LIT>\" ) : \n try : \n item . port = int ( value ) \n except : \n item . port = <NUM_LIT:0> \n elif ( key == \"<STR_LIT>\" ) : \n try : \n item . attachpos = int ( value ) \n except : \n item . attachpos = <NUM_LIT:0> \n f . close ( ) \n return <NUM_LIT:1> \n def GetItem ( self , user , route , has_perm = False , need_perm = False ) : \n self . CheckUpdate ( ) \n if ( self . mtitle . find ( \"<STR_LIT>\" ) != - <NUM_LIT:1> ) : \n if ( Board . Board . IsBM ( user , self . mtitle [ <NUM_LIT:4> : ] , ) or user . IsSysop ( ) ) : \n has_perm = True \n elif ( need_perm and not has_perm ) : \n return None \n if ( self . mtitle . find ( \"<STR_LIT>\" ) != - <NUM_LIT:1> \n or self . mtitle . find ( \"<STR_LIT>\" ) != - <NUM_LIT:1> \n or self . mtitle . find ( \"<STR_LIT>\" ) != - <NUM_LIT:1> ) : \n need_perm = True \n if ( len ( route ) == <NUM_LIT:0> ) : \n return self \n target = route [ <NUM_LIT:0> ] - <NUM_LIT:1> \n _id = target \n if ( _id >= len ( self . items ) ) : \n return None \n while ( self . items [ _id ] . EffectiveId ( user ) < target ) : \n _id += <NUM_LIT:1> \n if ( _id >= len ( self . items ) ) : \n return None \n item = self . items [ _id ] \n item . mtitle = item . title \n if ( len ( route ) == <NUM_LIT:1> ) : \n return item \n else : \n if ( item . IsDir ( ) ) : \n if ( not item . CheckUpdate ( ) ) : \n return None \n return item . GetItem ( user , route [ <NUM_LIT:1> : ] , has_perm , need_perm ) \n else : \n return None \n def GetRange ( self , user , route , start , end , has_perm = False , need_perm = False ) : \n self . CheckUpdate ( ) \n firstitem = self . GetItem ( user , route + [ start ] , has_perm , need_perm ) \n if ( not firstitem ) : \n return [ ] \n parent = self . GetItem ( user , route , has_perm , need_perm ) \n if ( not parent ) : \n return [ ] \n if ( not parent . IsDir ( ) ) : \n return [ ] \n result = [ ] \n _id = start - <NUM_LIT:1> \n for i in range ( start , end + <NUM_LIT:1> ) : \n target = i - <NUM_LIT:1> \n if ( _id >= len ( parent . items ) ) : \n return [ ] \n while ( parent . items [ _id ] . EffectiveId ( user ) < target ) : \n _id += <NUM_LIT:1> \n if ( _id >= len ( parent . items ) ) : \n return result \n item = parent . items [ _id ] \n item . mtitle = item . title \n result += [ item ] \n return result \n def EffectiveId ( self , user ) : \n _id = self . id \n if ( user . IsSysop ( ) ) : \n return _id \n if ( not user . IsSysop ( ) ) : \n _id -= self . sysop_only \n if ( not user . IsBM ( ) ) : \n _id -= self . bms_only \n if ( not user . IsSECANC ( ) ) : \n _id -= self . zixia_only \n return _id \n def GetInfo ( self ) : \n info = { } \n info [ '<STR_LIT>' ] = Util . gbkDec ( self . mtitle ) \n info [ '<STR_LIT:title>' ] = Util . gbkDec ( self . title ) \n info [ '<STR_LIT>' ] = self . attachpos \n if ( self . host != '<STR_LIT>' ) : \n info [ '<STR_LIT:host>' ] = self . host \n info [ '<STR_LIT:port>' ] = self . port \n info [ '<STR_LIT:type>' ] = '<STR_LIT>' \n elif ( self . IsDir ( ) ) : \n info [ '<STR_LIT:type>' ] = '<STR_LIT>' \n elif ( self . IsFile ( ) ) : \n info [ '<STR_LIT:type>' ] = '<STR_LIT:file>' \n else : \n info [ '<STR_LIT:type>' ] = '<STR_LIT>' \n info [ '<STR_LIT>' ] = int ( self . GetModTime ( ) ) \n return info \n def GetInfoForUser ( self , user ) : \n info = self . GetInfo ( ) \n info [ '<STR_LIT:id>' ] = self . EffectiveId ( user ) + <NUM_LIT:1> \n return info \n def GetAttachLink ( self , session ) : \n _hash = Util . HashGen ( self . path ( ) , \"<STR_LIT>\" ) \n filename = '<STR_LIT>' \n for i in range ( <NUM_LIT:2> ) : \n filename += \"<STR_LIT>\" % struct . unpack ( '<STR_LIT>' , _hash [ i * <NUM_LIT:4> : ( i + <NUM_LIT:1> ) * <NUM_LIT:4> ] ) \n link = \"<STR_LIT>\" % ( session . GetMirror ( Config . Config . GetInt ( '<STR_LIT>' , <NUM_LIT> ) ) , filename ) \n linkfile = \"<STR_LIT>\" % ( Config . BBS_ROOT , filename ) \n target = \"<STR_LIT>\" % self . path ( ) \n try : \n os . symlink ( target , linkfile ) \n except : \n pass \n return link \n class Digest : \n root = DigestItem ( \"<STR_LIT>\" ) \n def __init__ ( self , board , path ) : \n self . board = board \n self . path = path \n self . root = DigestItem ( self . path ) \n @ staticmethod \n def GET ( svc , session , params , action ) : \n if ( session is None ) : raise Unauthorized ( '<STR_LIT>' ) \n if not session . CheckScope ( '<STR_LIT>' ) : raise NoPerm ( \"<STR_LIT>\" ) \n user = session . GetUser ( ) \n boardname = svc . get_str ( params , '<STR_LIT>' , '<STR_LIT>' ) \n if ( boardname ) : \n board = BoardManager . BoardManager . GetBoard ( boardname ) \n if ( board is None ) : raise NotFound ( '<STR_LIT>' % boardname ) \n if ( not board . CheckReadPerm ( user ) ) : \n raise NoPerm ( '<STR_LIT>' ) \n basenode = board . digest . root \n has_perm = user . IsDigestMgr ( ) or user . IsSysop ( ) or user . IsSuperBM ( ) \n else : \n basenode = Digest . root \n has_perm = user . IsDigestMgr ( ) \n if ( action == \"<STR_LIT:list>\" ) : \n route = svc . get_str ( params , '<STR_LIT>' ) \n start = svc . get_int ( params , '<STR_LIT:start>' , <NUM_LIT:1> ) \n end = svc . get_int ( params , '<STR_LIT:end>' , start + DEFAULT_DIGEST_LIST_COUNT - <NUM_LIT:1> ) \n Digest . List ( svc , basenode , route , start , end , session , has_perm ) \n return \n elif ( action == \"<STR_LIT>\" ) : \n route = svc . get_str ( params , '<STR_LIT>' ) \n start = svc . get_int ( params , '<STR_LIT:start>' , <NUM_LIT:0> ) \n count = svc . get_int ( params , '<STR_LIT:count>' , <NUM_LIT:0> ) \n Digest . View ( svc , basenode , route , session , has_perm , start , count ) \n return \n else : \n raise WrongArgs ( '<STR_LIT>' % action ) \n @ staticmethod \n def ParseRoute ( route ) : \n ret = [ ] \n items = re . split ( '<STR_LIT:->' , route ) \n items = items [ <NUM_LIT:1> : ] \n for item in items : \n try : \n ret += [ int ( item ) ] \n except : \n raise WrongArgs ( '<STR_LIT>' % item ) \n return ret \n @ staticmethod \n def List ( svc , basenode , route , start , end , session , has_perm ) : \n route_array = Digest . ParseRoute ( route ) \n parent = basenode . GetItem ( session . GetUser ( ) , route_array , has_perm ) \n if ( not parent ) : \n raise WrongArgs ( '<STR_LIT>' % route ) \n if ( not parent . IsDir ( ) ) : \n raise WrongArgs ( '<STR_LIT>' % route ) \n items = basenode . GetRange ( session . GetUser ( ) , route_array , start , end , has_perm ) \n result = { } \n result [ '<STR_LIT>' ] = parent . GetInfoForUser ( session . GetUser ( ) ) \n result [ '<STR_LIT:count>' ] = len ( items ) \n result_list = [ ] \n for item in items : \n result_list += [ item . GetInfoForUser ( session . GetUser ( ) ) ] \n result [ '<STR_LIT>' ] = result_list \n svc . writedata ( json . dumps ( result ) ) \n @ staticmethod \n def View ( svc , basenode , route , session , has_perm , start , count ) : \n route_array = Digest . ParseRoute ( route ) \n item = basenode . GetItem ( session . GetUser ( ) , route_array , has_perm ) \n if ( not item ) : \n raise WrongArgs ( '<STR_LIT>' % route ) \n if ( not item . IsFile ( ) ) : \n raise WrongArgs ( '<STR_LIT>' % route ) \n result = { } \n result [ '<STR_LIT>' ] = item . GetInfoForUser ( session . GetUser ( ) ) \n postinfo = Post . Post ( item . realpath ( ) , None ) \n ( result [ '<STR_LIT:content>' ] , result [ '<STR_LIT>' ] ) = postinfo . GetContent ( start , count ) \n attachlist = postinfo . GetAttachListByType ( ) \n result [ '<STR_LIT>' ] = attachlist [ <NUM_LIT:0> ] \n result [ '<STR_LIT>' ] = attachlist [ <NUM_LIT:1> ] \n if ( attachlist [ <NUM_LIT:0> ] or attachlist [ <NUM_LIT:1> ] ) : \n result [ '<STR_LIT>' ] = item . GetAttachLink ( session ) \n svc . writedata ( json . dumps ( result ) ) \n", "gt": "DEFAULT_DIGEST_LIST_COUNT"}
{"input": "\n import time \n import UserManager \n import UserInfo \n from Session import Session \n from Log import Log \n import UCache \n import Config \n import MsgBox \n import xmpp \n import modes \n import Util \n import traceback \n import os \n from xmpp . features import NoRoute \n <mask0> = '<STR_LIT>' \n __disco_items_ns__ = '<STR_LIT>' \n __vcard_ns__ = '<STR_LIT>' \n STEAL_AFTER_SEEN = <NUM_LIT:3> \n def elem_to_str ( elem ) : \n return \"<STR_LIT>\" % ( elem . tag , elem . attrib , elem . text ) \n class XMPPServer ( xmpp . Plugin ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , rosters , host ) : \n self . probed = False \n self . _closed = False \n self . rosters = rosters \n self . _session = None \n self . rosters . set_resources ( self . get_resources ( ) ) \n self . _fixedjid = UCache . UCache . formalize_jid ( unicode ( self . authJID ) ) \n self . _userid = self . _fixedjid . partition ( '<STR_LIT:@>' ) [ <NUM_LIT:0> ] . encode ( \"<STR_LIT>\" ) \n if ( not self . rosters . allow_login ( self . authJID . bare ) ) : \n Log . warn ( \"<STR_LIT>\" % self . _userid ) \n self . stream_error ( '<STR_LIT>' , '<STR_LIT>' ) \n return \n Log . info ( \"<STR_LIT>\" % unicode ( self . authJID ) ) \n if self . authJID . resource [ : - <NUM_LIT:8> ] != \"<STR_LIT>\" and len ( self . authJID . resource ) > <NUM_LIT:8> : \n try : \n routes = self . routes ( self . authJID . bare ) \n for route in routes : \n jid = route [ <NUM_LIT:0> ] \n if jid . resource [ : - <NUM_LIT:8> ] == self . authJID . resource [ : - <NUM_LIT:8> ] : \n if jid . resource != self . authJID . resource : \n Log . info ( \"<STR_LIT>\" % ( jid . full , route [ <NUM_LIT:1> ] ) ) \n route [ <NUM_LIT:1> ] . stream_error ( '<STR_LIT>' , '<STR_LIT>' ) \n else : \n Log . info ( \"<STR_LIT>\" % ( jid . full , route [ <NUM_LIT:1> ] ) ) \n except NoRoute : \n pass \n Log . debug ( \"<STR_LIT>\" % self . authJID . full ) \n self . _user = UserManager . UserManager . LoadUser ( self . _userid ) \n if ( self . _user == None ) : \n raise Exception ( \"<STR_LIT>\" ) \n self . _peer_addr = self . getpeername ( ) \n self . _session = Session ( self . _user , self . _peer_addr [ <NUM_LIT:0> ] ) \n self . _session . RecordLogin ( ) \n self . _userinfo = self . _session . Register ( ) \n self . _loginid = self . _session . utmpent \n self . _hostname = host \n self . bind ( xmpp . ReceivedCloseStream , self . recv_close ) \n self . bind ( xmpp . StreamClosed , self . stream_closed ) \n self . bind ( xmpp . SentCloseStream , self . sent_close ) \n self . rosters . register_conn ( self ) \n msgbox = MsgBox . MsgBox ( self . _userid ) \n if self . rosters . get_xmpp_read ( self . _user . GetUID ( ) ) is None : \n self . rosters . set_xmpp_read ( self . _user . GetUID ( ) , msgbox . GetMsgCount ( all = False ) - msgbox . GetUnreadCount ( ) ) \n self . check_msg ( ) \n def get_loginid ( self ) : \n return self . _loginid \n def recv_close ( self ) : \n Log . debug ( \"<STR_LIT>\" % self . authJID . full ) \n return self . close ( ) \n def stream_closed ( self ) : \n Log . debug ( \"<STR_LIT>\" % self . authJID . full ) \n return self . close ( ) \n def sent_close ( self ) : \n Log . debug ( \"<STR_LIT>\" % self . authJID . full ) \n return self . close ( ) \n def close ( self ) : \n if ( self . _closed ) : \n Log . debug ( \"<STR_LIT>\" ) \n return \n self . _closed = True \n Log . info ( \"<STR_LIT>\" % unicode ( self . authJID ) ) \n if ( self . _session ) : \n self . _session . Unregister ( ) \n self . unbind_res ( ) \n self . rosters . unregister_conn ( self ) \n @ xmpp . iq ( '<STR_LIT>' ) \n def ping ( self , iq ) : \n \"\"\"<STR_LIT>\"\"\" \n self . refresh ( ) \n return self . iq ( '<STR_LIT:result>' , iq ) \n @ xmpp . stanza ( '<STR_LIT:message>' ) \n def message ( self , elem ) : \n \"\"\"<STR_LIT>\"\"\" \n to_jid = elem . get ( '<STR_LIT:to>' ) \n from_jid = elem . get ( '<STR_LIT>' ) \n if ( from_jid == None ) : \n return \n text_body = None \n for child in elem : \n if ( child . tag . endswith ( '<STR_LIT>' ) ) : \n text_body = child . text \n if ( text_body == None ) : \n return \n ret = self . rosters . send_msg ( from_jid , to_jid , text_body ) \n if ( ret <= <NUM_LIT:0> ) : \n Log . warn ( \"<STR_LIT>\" % ( to_jid , from_jid , ret ) ) \n errors = { \n - <NUM_LIT:1> : \"<STR_LIT>\" , \n - <NUM_LIT:11> : \"<STR_LIT>\" , \n - <NUM_LIT:12> : \"<STR_LIT>\" , \n - <NUM_LIT> : \"<STR_LIT>\" , \n - <NUM_LIT> : \"<STR_LIT>\" , \n - <NUM_LIT:2> : \"<STR_LIT>\" , \n - <NUM_LIT> : \"<STR_LIT>\" } \n if ( ret in errors ) : \n elem = self . E . message ( { '<STR_LIT>' : to_jid , \n '<STR_LIT:to>' : from_jid , \n '<STR_LIT:type>' : '<STR_LIT:error>' } , \n self . E . body ( errors [ ret ] ) ) \n self . recv ( from_jid , elem ) \n def make_jid ( self , userid ) : \n return \"<STR_LIT>\" % ( userid , self . _hostname ) \n def refresh ( self ) : \n self . _userinfo . freshtime = int ( time . time ( ) ) \n self . _userinfo . save ( ) \n def ping_result ( self , iq ) : \n self . refresh ( ) \n def ping_client ( self ) : \n try : \n pingelem = self . E . ping ( xmlns = '<STR_LIT>' ) \n return self . iq ( '<STR_LIT>' , self . ping_result , pingelem ) \n except Exception as e : \n Log . debug ( \"<STR_LIT>\" % ( self . authJID , e ) ) \n Log . debug ( traceback . format_exc ( ) ) \n return False \n def get_uid ( self ) : \n return self . _user . GetUID ( ) \n def recv_msg ( self , from_ , msgtext ) : \n elem = self . E . message ( { '<STR_LIT>' : from_ , '<STR_LIT:to>' : unicode ( self . authJID ) } , \n self . E . body ( msgtext ) ) \n self . recv ( unicode ( self . authJID ) , elem ) \n def check_msg ( self ) : \n Log . debug ( \"<STR_LIT>\" % self . _userid ) \n msgbox = MsgBox . MsgBox ( self . _userid ) \n msg_count = msgbox . GetMsgCount ( all = False ) \n my_pid = os . getpid ( ) \n xmpp_read = self . rosters . get_xmpp_read ( self . _user . GetUID ( ) ) \n if xmpp_read > msg_count : \n xmpp_read = <NUM_LIT:0> \n Log . debug ( \"<STR_LIT>\" % ( msg_count , xmpp_read ) ) \n self . rosters . set_xmpp_read ( self . _user . GetUID ( ) , msg_count ) \n if xmpp_read < msg_count : \n return xmpp_read \n else : \n return - <NUM_LIT:1> \n def deliver_msg ( self , start ) : \n Log . debug ( \"<STR_LIT>\" % unicode ( self . authJID ) ) \n msgbox = MsgBox . MsgBox ( self . _userid ) \n msg_count = msgbox . GetMsgCount ( all = False ) \n my_pid = os . getpid ( ) \n for i in range ( start , msg_count ) : \n msghead = msgbox . LoadMsgHead ( i , all = False ) \n if msghead . topid == my_pid : \n msgtext = msgbox . LoadMsgText ( msghead ) \n self . recv_msg ( self . make_jid ( msghead . id ) , msgtext ) \n def steal_msg ( self ) : \n Log . debug ( \"<STR_LIT>\" % self . _userid ) \n msgbox = MsgBox . MsgBox ( self . _userid ) \n msg_count = msgbox . GetMsgCount ( all = False ) \n msg_unread = msgbox . GetUnreadCount ( ) \n read_count = msg_count - msg_unread \n my_pid = os . getpid ( ) \n term_read = self . rosters . get_term_read ( self . get_uid ( ) ) \n term_stealed = self . rosters . get_term_stealed ( self . get_uid ( ) ) \n all_xmpp = True \n new_unread = { } \n for i in range ( read_count - <NUM_LIT:1> , msg_count ) : \n if i < <NUM_LIT:0> : \n continue \n msghead = msgbox . LoadMsgHead ( i , all = False ) \n if i >= read_count and all_xmpp : \n if msghead . topid == my_pid : \n msgbox . GetUnreadMsg ( ) \n else : \n all_xmpp = False \n if msghead . topid == my_pid : \n continue \n if i < read_count : \n session = self . rosters . find_session ( self . authJID . bare , msghead . topid ) \n if session is None or session . get_mode ( ) != modes . MSG : \n continue \n Log . debug ( \"<STR_LIT>\" % i ) \n if msghead . topid not in new_unread : \n Log . debug ( \"<STR_LIT>\" % ( msghead . topid , i ) ) \n new_unread [ msghead . topid ] = i \n final_unread = { } \n to_steal = { } \n to_steal_begin = msg_count \n for pid in term_read : \n if pid in new_unread : \n if new_unread [ pid ] == term_read [ pid ] [ <NUM_LIT:0> ] : \n final_unread [ pid ] = ( term_read [ pid ] [ <NUM_LIT:0> ] , term_read [ pid ] [ <NUM_LIT:1> ] + <NUM_LIT:1> ) \n Log . debug ( \"<STR_LIT>\" % ( new_unread [ pid ] , pid , term_read [ pid ] [ <NUM_LIT:1> ] + <NUM_LIT:1> ) ) \n if final_unread [ pid ] [ <NUM_LIT:1> ] > STEAL_AFTER_SEEN : \n to_steal [ pid ] = final_unread [ pid ] \n Log . debug ( \"<STR_LIT>\" % ( to_steal [ pid ] [ <NUM_LIT:0> ] , pid ) ) \n if pid in term_stealed : \n steal_begin = max ( final_unread [ pid ] [ <NUM_LIT:0> ] , term_stealed [ pid ] + <NUM_LIT:1> ) \n else : \n steal_begin = final_unread [ pid ] [ <NUM_LIT:0> ] \n if steal_begin < to_steal_begin : \n to_steal_begin = steal_begin \n else : \n final_unread [ pid ] = ( new_unread [ pid ] , <NUM_LIT:1> ) \n Log . debug ( \"<STR_LIT>\" % ( term_read [ pid ] [ <NUM_LIT:0> ] , new_unread [ pid ] , pid ) ) \n else : \n Log . debug ( \"<STR_LIT>\" % pid ) \n pass \n for pid in new_unread : \n if pid not in term_read : \n Log . debug ( \"<STR_LIT>\" % ( new_unread [ pid ] , pid ) ) \n final_unread [ pid ] = ( new_unread [ pid ] , <NUM_LIT:1> ) \n if to_steal : \n Log . debug ( \"<STR_LIT>\" % to_steal_begin ) \n for i in range ( to_steal_begin , msg_count ) : \n msghead = msgbox . LoadMsgHead ( i , all = False ) \n if msghead . topid == my_pid : \n Log . debug ( \"<STR_LIT>\" % ( i , msghead . topid ) ) \n msgbox . GetUnreadMsg ( ) \n elif msghead . topid in to_steal : \n if msghead . topid not in term_stealed or i > term_stealed [ msghead . topid ] : \n Log . debug ( \"<STR_LIT>\" % ( i , msghead . topid ) ) \n msgtext = msgbox . LoadMsgText ( msghead ) \n self . recv_msg ( self . make_jid ( msghead . id ) , msgtext ) \n term_stealed [ msghead . topid ] = i \n else : \n Log . debug ( \"<STR_LIT>\" % ( i , msghead . topid ) ) \n self . rosters . set_term_read ( self . get_uid ( ) , final_unread ) \n @ xmpp . stanza ( '<STR_LIT>' ) \n def presence ( self , elem ) : \n \"\"\"<STR_LIT>\"\"\" \n Log . warn ( \"<STR_LIT>\" % ( self . authJID , elem_to_str ( elem ) ) ) \n if self . authJID == elem . get ( '<STR_LIT>' ) : \n if ( elem . get ( '<STR_LIT:to>' ) == None or ( not self . authJID . match_bare ( elem . get ( '<STR_LIT:to>' ) ) ) ) : \n return self . send_presence ( elem ) \n self . recv_presence ( elem ) \n def send_presence ( self , elem ) : \n Log . warn ( \"<STR_LIT>\" % ( self . authJID , elem_to_str ( elem ) ) ) \n direct = elem . get ( '<STR_LIT:to>' ) \n if not direct : \n self . rosters . broadcast ( self , elem ) \n if elem . get ( '<STR_LIT:type>' ) != '<STR_LIT>' : \n self . recv_presence ( elem ) \n if not self . probed : \n self . probed = True \n self . rosters . probe ( self ) \n elif not self . rosters . send ( self , direct , elem ) : \n self . send ( direct , elem ) \n def recv_presence ( self , elem ) : \n Log . warn ( \"<STR_LIT>\" % ( self . authJID , elem_to_str ( elem ) ) ) \n if not self . rosters . recv ( self , elem ) : \n Log . warn ( \"<STR_LIT>\" ) \n self . write ( elem ) \n @ xmpp . iq ( '<STR_LIT>' ) \n def roster ( self , iq ) : \n \"\"\"<STR_LIT>\"\"\" \n roster = self . rosters . get ( self ) \n method = getattr ( self , '<STR_LIT>' % iq . get ( '<STR_LIT:type>' ) ) \n return method and method ( iq , roster ) \n def get_roster ( self , iq , roster ) : \n query = self . E . query ( { '<STR_LIT>' : '<STR_LIT>' } ) \n for item in roster . items ( ) : \n query . append ( item ) \n return self . iq ( '<STR_LIT:result>' , iq , query ) \n def set_roster ( self , iq , roster ) : \n query = self . E . query ( xmlns = '<STR_LIT>' ) \n for item in iq [ <NUM_LIT:0> ] : \n result = roster . set ( item ) \n if result is not None : \n query . append ( result ) \n if len ( query ) > <NUM_LIT:0> : \n self . push ( roster , query ) \n return self . iq ( '<STR_LIT:result>' , iq ) \n def push ( self , roster , query ) : \n \"\"\"<STR_LIT>\"\"\" \n for jid in roster . requests ( ) : \n for ( to , route ) in self . routes ( jid ) : \n route . iq ( '<STR_LIT>' , self . ignore , query ) \n def ignore ( self , iq ) : \n \"\"\"<STR_LIT>\"\"\" \n @ xmpp . iq ( '<STR_LIT>' ) \n def vcard ( self , iq ) : \n \"\"\"<STR_LIT>\"\"\" \n if iq . get ( '<STR_LIT:type>' ) == '<STR_LIT>' : \n if ( iq . get ( '<STR_LIT:to>' ) == None ) : \n target = iq . get ( '<STR_LIT>' ) \n else : \n target = iq . get ( '<STR_LIT:to>' ) \n form_target = UCache . UCache . formalize_jid ( target ) \n name = form_target . partition ( '<STR_LIT:@>' ) [ <NUM_LIT:0> ] \n user = UserManager . UserManager . LoadUser ( name ) \n info = user . GetInfo ( ) \n desc = '''<STR_LIT>''' % ( info [ '<STR_LIT>' ] , info [ '<STR_LIT>' ] , info [ '<STR_LIT>' ] , \n info [ '<STR_LIT>' ] , info [ '<STR_LIT>' ] , info [ '<STR_LIT>' ] , info [ '<STR_LIT>' ] ) \n if ( '<STR_LIT>' in info ) : \n desc += \"<STR_LIT>\" % ( info [ '<STR_LIT>' ] . replace ( '<STR_LIT:\\n>' , '<STR_LIT:\\r\\n>' ) ) \n vcard = self . E . vCard ( { '<STR_LIT>' : '<STR_LIT>' } , \n self . E ( '<STR_LIT>' , name ) , \n self . E ( '<STR_LIT>' , Util . Util . RemoveTags ( info [ '<STR_LIT>' ] ) ) , \n self . E ( '<STR_LIT>' , Util . Util . RemoveTags ( desc ) ) ) \n if ( iq . get ( '<STR_LIT:to>' ) == None ) : \n return self . iq ( '<STR_LIT:result>' , iq , vcard ) \n else : \n return self . iq ( '<STR_LIT:result>' , iq , vcard , { '<STR_LIT>' : iq . get ( '<STR_LIT:to>' ) } ) \n @ xmpp . iq ( '<STR_LIT>' % __disco_info_ns__ ) \n def disco_info ( self , iq ) : \n \"\"\"<STR_LIT>\"\"\" \n target = iq . get ( '<STR_LIT:to>' ) \n if ( target . find ( '<STR_LIT:@>' ) < <NUM_LIT:0> ) : \n query = self . E . query ( { '<STR_LIT>' : __disco_info_ns__ } , \n self . E . identity ( { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT:type>' : '<STR_LIT>' , \n '<STR_LIT:name>' : Config . Config . GetString ( '<STR_LIT>' , '<STR_LIT>' ) , \n } ) ) \n features = [ __disco_info_ns__ , __disco_items_ns__ , __vcard_ns__ ] \n for feature in features : \n query . append ( self . E . feature ( { '<STR_LIT>' : feature } ) ) \n else : \n query = self . E . query ( { '<STR_LIT>' : __disco_info_ns__ } , \n self . E . identity ( { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT:type>' : '<STR_LIT>' , \n '<STR_LIT:name>' : Config . Config . GetString ( '<STR_LIT>' , '<STR_LIT>' ) , \n } ) ) \n features = [ __disco_info_ns__ , __disco_items_ns__ , __vcard_ns__ ] \n for feature in features : \n query . append ( self . E . feature ( { '<STR_LIT>' : feature } ) ) \n return self . iq ( '<STR_LIT:result>' , iq , query , { '<STR_LIT>' : target } ) \n @ xmpp . iq ( '<STR_LIT>' % __disco_items_ns__ ) \n def disco_items ( self , iq ) : \n \"\"\"<STR_LIT>\"\"\" \n target = iq . get ( '<STR_LIT:to>' ) \n if ( target . find ( '<STR_LIT:@>' ) < <NUM_LIT:0> ) : \n query = self . E . query ( { '<STR_LIT>' : __disco_items_ns__ } ) \n else : \n query = self . E . query ( { '<STR_LIT>' : __disco_items_ns__ } ) \n return self . iq ( '<STR_LIT:result>' , iq , query , { '<STR_LIT>' : target } ) \n", "gt": "__disco_info_ns__"}
{"input": "\n from __future__ import print_function \n from __future__ import unicode_literals \n from __future__ import division \n from __future__ import absolute_import \n from builtins import range \n from future import standard_library \n standard_library . install_aliases ( ) \n import sys \n <mask0> = sys . version_info [ : <NUM_LIT:3> ] \n PY2 = ( PYTHON_VERSION [ <NUM_LIT:0> ] == <NUM_LIT:2> ) \n if PY2 : \n if PYTHON_VERSION < ( <NUM_LIT:2> , <NUM_LIT:7> , <NUM_LIT:9> ) : \n raise Exception ( '<STR_LIT>' ) \n elif PYTHON_VERSION < ( <NUM_LIT:3> , <NUM_LIT:4> ) : \n raise Exception ( '<STR_LIT>' ) \n import hpOneView as hpov \n from pprint import pprint \n import json \n from hpOneView . common import uri \n import hpOneView . profile as profile \n def acceptEULA ( con ) : \n con . get_eula_status ( ) \n try : \n if con . get_eula_status ( ) is True : \n print ( '<STR_LIT>' ) \n con . set_eula ( '<STR_LIT>' ) \n except Exception as e : \n print ( '<STR_LIT>' ) \n print ( e ) \n def login ( con , credential ) : \n try : \n con . login ( credential ) \n except : \n print ( '<STR_LIT>' ) \n def get_eg_uri_from_arg ( srv , name ) : \n if srv and name : \n if name . startswith ( '<STR_LIT>' ) and uri [ '<STR_LIT>' ] in name : \n return name \n else : \n egs = srv . get_enclosure_groups ( ) \n for eg in egs : \n if eg [ '<STR_LIT:name>' ] == name : \n return eg [ '<STR_LIT>' ] \n return None \n def get_sht_from_arg ( srv , name ) : \n if srv and name : \n if name . startswith ( '<STR_LIT>' ) and uri [ '<STR_LIT>' ] in name : \n return name \n else : \n shts = srv . get_server_hardware_types ( ) \n for sht in shts : \n if sht [ '<STR_LIT:name>' ] == name : \n return sht \n return None \n def define_profile_template ( \n srv , \n name , \n desc , \n sp_desc , \n server_hwt , \n enc_group , \n affinity , \n hide_flexnics , \n conn_list , \n fw_settings , \n boot , \n bootmode ) : \n if conn_list : \n conn = json . loads ( open ( conn_list ) . read ( ) ) \n else : \n conn = [ ] \n profile_template = srv . create_server_profile_template ( \n name = name , \n description = desc , \n serverProfileDescription = sp_desc , \n serverHardwareTypeUri = server_hwt , \n enclosureGroupUri = enc_group , \n affinity = affinity , \n hideUnusedFlexNics = hide_flexnics , \n profileConnectionV4 = conn , \n firmwareSettingsV3 = fw_settings , \n bootSettings = boot , \n bootModeSetting = bootmode ) \n if '<STR_LIT>' in profile_template : \n print ( '<STR_LIT>' , profile_template [ '<STR_LIT:name>' ] ) \n print ( '<STR_LIT>' , profile_template [ '<STR_LIT:type>' ] ) \n print ( '<STR_LIT>' , profile_template [ '<STR_LIT:description>' ] ) \n print ( '<STR_LIT>' , profile_template [ '<STR_LIT>' ] ) \n print ( '<STR_LIT>' ) \n for connection in profile_template [ '<STR_LIT>' ] : \n print ( '<STR_LIT>' , connection [ '<STR_LIT:name>' ] ) \n print ( '<STR_LIT>' , connection [ '<STR_LIT>' ] ) \n print ( '<STR_LIT>' , connection [ '<STR_LIT>' ] ) \n print ( '<STR_LIT>' ) \n print ( '<STR_LIT>' , profile_template [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) \n print ( '<STR_LIT>' , profile_template [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) \n print ( '<STR_LIT>' , profile_template [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) \n print ( '<STR_LIT>' ) \n print ( '<STR_LIT>' , profile_template [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) \n print ( '<STR_LIT>' , profile_template [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) \n print ( '<STR_LIT>' ) \n print ( '<STR_LIT>' , profile_template [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) \n print ( '<STR_LIT>' , profile_template [ '<STR_LIT>' ] [ '<STR_LIT>' ] , '<STR_LIT:\\n>' ) \n else : \n pprint ( profile_template ) \n def main ( ) : \n parser = argparse . ArgumentParser ( add_help = True , \n formatter_class = argparse . RawTextHelpFormatter , \n description = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:host>' , required = True , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:user>' , required = False , \n default = '<STR_LIT>' , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = True , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT:-c>' , dest = '<STR_LIT>' , required = False , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:name>' , \n required = True , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , \n required = False , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , \n required = False , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = True , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = True , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , \n required = False , choices = [ '<STR_LIT>' , '<STR_LIT>' ] , \n default = '<STR_LIT>' , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , \n required = False , choices = [ '<STR_LIT:true>' , '<STR_LIT:false>' ] , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , \n required = False , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , \n action = '<STR_LIT:store_true>' , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , \n nargs = '<STR_LIT:+>' , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , \n choices = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] , \n default = '<STR_LIT>' , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , \n choices = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' ] , \n default = '<STR_LIT>' , \n help = '''<STR_LIT>''' ) \n args = parser . parse_args ( ) \n credential = { '<STR_LIT>' : args . user , '<STR_LIT:password>' : args . passwd } \n con = hpov . connection ( args . host ) \n srv = hpov . servers ( con ) \n sts = hpov . settings ( con ) \n if args . proxy : \n con . set_proxy ( args . proxy . split ( '<STR_LIT::>' ) [ <NUM_LIT:0> ] , args . proxy . split ( '<STR_LIT::>' ) [ <NUM_LIT:1> ] ) \n if args . cert : \n con . set_trusted_ssl_bundle ( args . cert ) \n login ( con , credential ) \n acceptEULA ( con ) \n eg_uri = get_eg_uri_from_arg ( srv , args . enc_group ) \n sht = get_sht_from_arg ( srv , args . server_hwt ) \n fw_settings = profile . make_firmware_dict ( sts , args . baseline ) \n boot , bootmode = profile . make_boot_settings_dict ( srv , sht , args . disable_manage_boot , \n args . boot_order , args . boot_mode , args . pxe ) \n define_profile_template ( srv , \n args . name , \n args . desc , \n args . sp_desc , \n sht [ '<STR_LIT>' ] , \n eg_uri , \n args . affinity , \n args . hide_flexnics , \n args . conn_list , \n fw_settings , \n boot , \n bootmode ) \n if __name__ == '<STR_LIT:__main__>' : \n import argparse \n sys . exit ( main ( ) ) \n", "gt": "PYTHON_VERSION"}
{"input": "\n from __future__ import print_function \n from __future__ import unicode_literals \n from __future__ import division \n from __future__ import absolute_import \n from builtins import range \n from future import standard_library \n standard_library . install_aliases ( ) \n import sys \n <mask0> = sys . version_info [ : <NUM_LIT:3> ] \n PY2 = ( PYTHON_VERSION [ <NUM_LIT:0> ] == <NUM_LIT:2> ) \n if PY2 : \n if PYTHON_VERSION < ( <NUM_LIT:2> , <NUM_LIT:7> , <NUM_LIT:9> ) : \n raise Exception ( '<STR_LIT>' ) \n elif PYTHON_VERSION < ( <NUM_LIT:3> , <NUM_LIT:4> ) : \n raise Exception ( '<STR_LIT>' ) \n import hpOneView as hpov \n from pprint import pprint \n def acceptEULA ( con ) : \n con . get_eula_status ( ) \n try : \n if con . get_eula_status ( ) is True : \n print ( \"<STR_LIT>\" ) \n con . set_eula ( '<STR_LIT>' ) \n except Exception as e : \n print ( '<STR_LIT>' ) \n print ( e ) \n def login ( con , credential ) : \n try : \n con . login ( credential ) \n except : \n print ( '<STR_LIT>' ) \n def get_address_pools ( con , srv , types ) : \n if types == '<STR_LIT>' or types == '<STR_LIT>' : \n vmac = srv . get_vmac_pool ( ) \n print ( ) \n for key in sorted ( vmac ) : \n print ( '<STR_LIT>' . format ( key , vmac [ key ] ) ) \n if '<STR_LIT>' in vmac : \n for uri in vmac [ '<STR_LIT>' ] : \n ranges = con . get ( uri ) \n print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) \n print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) \n print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) \n if types == '<STR_LIT>' or types == '<STR_LIT>' : \n vwwn = srv . get_vwwn_pool ( ) \n print ( ) \n for key in sorted ( vwwn ) : \n print ( '<STR_LIT>' . format ( key , vwwn [ key ] ) ) \n if '<STR_LIT>' in vwwn : \n for uri in vwwn [ '<STR_LIT>' ] : \n ranges = con . get ( uri ) \n print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) \n print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) \n print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) \n if types == '<STR_LIT>' or types == '<STR_LIT>' : \n vsn = srv . get_vsn_pool ( ) \n print ( ) \n for key in sorted ( vsn ) : \n print ( '<STR_LIT>' . format ( key , vsn [ key ] ) ) \n if '<STR_LIT>' in vsn : \n for uri in vsn [ '<STR_LIT>' ] : \n ranges = con . get ( uri ) \n print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) \n print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) \n print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) \n def main ( ) : \n parser = argparse . ArgumentParser ( add_help = True , \n formatter_class = argparse . RawTextHelpFormatter , \n description = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:host>' , required = True , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:user>' , required = False , \n default = '<STR_LIT>' , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = True , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT:-c>' , dest = '<STR_LIT>' , required = False , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , \n default = '<STR_LIT>' , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , \n choices = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] , default = '<STR_LIT>' , \n help = '''<STR_LIT>''' ) \n args = parser . parse_args ( ) \n credential = { '<STR_LIT>' : args . domain . upper ( ) , '<STR_LIT>' : args . user , '<STR_LIT:password>' : args . passwd } \n con = hpov . connection ( args . host ) \n srv = hpov . servers ( con ) \n if args . proxy : \n con . set_proxy ( args . proxy . split ( '<STR_LIT::>' ) [ <NUM_LIT:0> ] , args . proxy . split ( '<STR_LIT::>' ) [ <NUM_LIT:1> ] ) \n if args . cert : \n con . set_trusted_ssl_bundle ( args . cert ) \n login ( con , credential ) \n acceptEULA ( con ) \n get_address_pools ( con , srv , args . types ) \n if __name__ == '<STR_LIT:__main__>' : \n import sys \n import argparse \n sys . exit ( main ( ) ) \n", "gt": "PYTHON_VERSION"}
{"input": "\n from __future__ import print_function \n from __future__ import unicode_literals \n from __future__ import division \n from __future__ import absolute_import \n from builtins import range \n from future import standard_library \n standard_library . install_aliases ( ) \n import sys \n import re \n <mask0> = sys . version_info [ : <NUM_LIT:3> ] \n PY2 = ( PYTHON_VERSION [ <NUM_LIT:0> ] == <NUM_LIT:2> ) \n if PY2 : \n if PYTHON_VERSION < ( <NUM_LIT:2> , <NUM_LIT:7> , <NUM_LIT:9> ) : \n raise Exception ( '<STR_LIT>' ) \n elif PYTHON_VERSION < ( <NUM_LIT:3> , <NUM_LIT:4> ) : \n raise Exception ( '<STR_LIT>' ) \n import hpOneView as hpov \n from pprint import pprint \n def acceptEULA ( con ) : \n con . get_eula_status ( ) \n try : \n if con . get_eula_status ( ) is True : \n print ( '<STR_LIT>' ) \n con . set_eula ( '<STR_LIT>' ) \n except Exception as e : \n print ( '<STR_LIT>' ) \n print ( e ) \n def login ( con , credential ) : \n try : \n con . login ( credential ) \n except : \n print ( '<STR_LIT>' ) \n def get_managed_sans ( fcs ) : \n sans = fcs . get_managed_sans ( ) \n pprint ( sans ) \n def main ( ) : \n parser = argparse . ArgumentParser ( add_help = True , \n formatter_class = argparse . RawTextHelpFormatter , \n description = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:host>' , required = True , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:user>' , required = False , \n default = '<STR_LIT>' , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = True , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT:-c>' , dest = '<STR_LIT>' , required = False , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , \n default = '<STR_LIT>' , \n help = '''<STR_LIT>''' ) \n args = parser . parse_args ( ) \n credential = { '<STR_LIT>' : args . domain . upper ( ) , '<STR_LIT>' : args . user , '<STR_LIT:password>' : args . passwd } \n con = hpov . connection ( args . host ) \n fcs = hpov . fcsans ( con ) \n if args . proxy : \n con . set_proxy ( args . proxy . split ( '<STR_LIT::>' ) [ <NUM_LIT:0> ] , args . proxy . split ( '<STR_LIT::>' ) [ <NUM_LIT:1> ] ) \n if args . cert : \n con . set_trusted_ssl_bundle ( args . cert ) \n login ( con , credential ) \n acceptEULA ( con ) \n get_managed_sans ( fcs ) \n if __name__ == '<STR_LIT:__main__>' : \n import sys \n import argparse \n sys . exit ( main ( ) ) \n", "gt": "PYTHON_VERSION"}
{"input": "\n from __future__ import print_function \n from __future__ import unicode_literals \n from __future__ import division \n from __future__ import absolute_import \n from builtins import range \n from future import standard_library \n standard_library . install_aliases ( ) \n import sys \n <mask0> = sys . version_info [ : <NUM_LIT:3> ] \n PY2 = ( PYTHON_VERSION [ <NUM_LIT:0> ] == <NUM_LIT:2> ) \n if PY2 : \n if PYTHON_VERSION < ( <NUM_LIT:2> , <NUM_LIT:7> , <NUM_LIT:9> ) : \n raise Exception ( '<STR_LIT>' ) \n elif PYTHON_VERSION < ( <NUM_LIT:3> , <NUM_LIT:4> ) : \n raise Exception ( '<STR_LIT>' ) \n import hpOneView as hpov \n from pprint import pprint \n def acceptEULA ( con ) : \n con . get_eula_status ( ) \n try : \n if con . get_eula_status ( ) is True : \n print ( '<STR_LIT>' ) \n con . set_eula ( '<STR_LIT>' ) \n except Exception as e : \n print ( '<STR_LIT>' ) \n print ( e ) \n def login ( con , credential ) : \n try : \n con . login ( credential ) \n except : \n print ( '<STR_LIT>' ) \n def getpolicy ( sts ) : \n policy = sts . get_storage_vol_template_policy ( ) \n print ( policy [ '<STR_LIT:value>' ] ) \n def main ( ) : \n parser = argparse . ArgumentParser ( add_help = True , \n formatter_class = argparse . RawTextHelpFormatter , \n description = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:host>' , required = True , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:user>' , required = False , \n default = '<STR_LIT>' , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = True , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT:-c>' , dest = '<STR_LIT>' , required = False , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , \n help = '''<STR_LIT>''' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , \n default = '<STR_LIT>' , \n help = '''<STR_LIT>''' ) \n args = parser . parse_args ( ) \n credential = { '<STR_LIT>' : args . domain . upper ( ) , '<STR_LIT>' : args . user , '<STR_LIT:password>' : args . passwd } \n con = hpov . connection ( args . host ) \n sts = hpov . settings ( con ) \n if args . proxy : \n con . set_proxy ( args . proxy . split ( '<STR_LIT::>' ) [ <NUM_LIT:0> ] , args . proxy . split ( '<STR_LIT::>' ) [ <NUM_LIT:1> ] ) \n if args . cert : \n con . set_trusted_ssl_bundle ( args . cert ) \n login ( con , credential ) \n acceptEULA ( con ) \n getpolicy ( sts ) \n if __name__ == '<STR_LIT:__main__>' : \n import sys \n import argparse \n sys . exit ( main ( ) ) \n", "gt": "PYTHON_VERSION"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n from __future__ import unicode_literals \n from __future__ import print_function \n from __future__ import division \n from __future__ import absolute_import \n from future import standard_library \n standard_library . install_aliases ( ) \n from pprint import pprint \n <mask0> = '<STR_LIT>' \n __version__ = '<STR_LIT>' \n __copyright__ = '<STR_LIT>' '<STR_LIT>' \n __license__ = '<STR_LIT>' \n __status__ = '<STR_LIT>' \n from hpOneView . common import * \n from hpOneView . connection import * \n from hpOneView . activity import * \n from hpOneView . exceptions import * \n class servers ( object ) : \n def __init__ ( self , con ) : \n self . _con = con \n self . _activity = activity ( con ) \n def get_connections ( self , filter = '<STR_LIT>' ) : \n \"\"\"<STR_LIT>\"\"\" \n return get_members ( self . _con . get ( uri [ '<STR_LIT>' ] + filter ) ) \n def get_connection ( self , server ) : \n \"\"\"<STR_LIT>\"\"\" \n body = self . _con . get ( server [ '<STR_LIT>' ] ) \n return body \n def get_server_by_bay ( self , baynum ) : \n servers = get_members ( self . _con . get ( uri [ '<STR_LIT>' ] ) ) \n for server in servers : \n if server [ '<STR_LIT>' ] == baynum : \n return server \n def get_server_by_name ( self , name ) : \n servers = get_members ( self . _con . get ( uri [ '<STR_LIT>' ] ) ) \n for server in servers : \n if server [ '<STR_LIT:name>' ] == name : \n return server \n def get_available_servers ( self , server_hardware_type = None , \n enclosure_group = None , server_profile = None ) : \n filters = [ ] \n if server_hardware_type : \n filters . append ( '<STR_LIT>' + server_hardware_type [ '<STR_LIT>' ] ) \n if enclosure_group : \n filters . append ( '<STR_LIT>' + enclosure_group [ '<STR_LIT>' ] ) \n if server_profile : \n filters . append ( '<STR_LIT>' + server_profile [ '<STR_LIT>' ] ) \n query_string = '<STR_LIT>' \n if filters : \n query_string = '<STR_LIT:?>' + '<STR_LIT:&>' . join ( filters ) \n return self . _con . get ( uri [ '<STR_LIT>' ] + query_string ) \n def get_servers ( self ) : \n return get_members ( self . _con . get ( uri [ '<STR_LIT>' ] ) ) \n def get_utilization ( self , server ) : \n \"\"\"<STR_LIT>\"\"\" \n body = self . _con . get ( server [ '<STR_LIT>' ] + '<STR_LIT>' ) \n return body \n def get_env_conf ( self , server ) : \n \"\"\"<STR_LIT>\"\"\" \n body = self . _con . get ( server [ '<STR_LIT>' ] + '<STR_LIT>' ) \n return body \n def set_server_powerstate ( self , server , state , force = False , blocking = True , \n verbose = False ) : \n if state == '<STR_LIT>' and force is True : \n powerRequest = make_powerstate_dict ( '<STR_LIT>' , '<STR_LIT>' ) \n elif state == '<STR_LIT>' and force is False : \n powerRequest = make_powerstate_dict ( '<STR_LIT>' , '<STR_LIT>' ) \n elif state == '<STR_LIT>' : \n powerRequest = make_powerstate_dict ( '<STR_LIT>' , '<STR_LIT>' ) \n elif state == '<STR_LIT>' : \n powerRequest = make_powerstate_dict ( '<STR_LIT>' , '<STR_LIT>' ) \n task , body = self . _con . put ( server [ '<STR_LIT>' ] + '<STR_LIT>' , powerRequest ) \n if blocking is True : \n task = self . _activity . wait4task ( task , tout = <NUM_LIT> , verbose = verbose ) \n return task \n def delete_server ( self , server , force = False , blocking = True , verbose = False ) : \n if force : \n task , body = self . _con . delete ( server [ '<STR_LIT>' ] + '<STR_LIT>' ) \n else : \n task , body = self . _con . delete ( server [ '<STR_LIT>' ] ) \n if blocking is True : \n task = self . _activity . wait4task ( task , tout = <NUM_LIT> , verbose = verbose ) \n return task \n def update_server ( self , server ) : \n task , body = self . _con . put ( server [ '<STR_LIT>' ] , server ) \n return body \n def add_server ( self , server , blocking = True , verbose = False ) : \n task , body = self . _con . post ( uri [ '<STR_LIT>' ] , server ) \n if blocking is True : \n task = self . _activity . wait4task ( task , tout = <NUM_LIT> , verbose = verbose ) \n if '<STR_LIT:type>' in task and task [ '<STR_LIT:type>' ] . startswith ( '<STR_LIT>' ) : \n entity = self . _activity . get_task_associated_resource ( task ) \n server = self . _con . get ( entity [ '<STR_LIT>' ] ) \n return server \n return task \n def get_server_schema ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . _con . get ( uri [ '<STR_LIT>' ] + '<STR_LIT>' ) \n def get_bios ( self , server ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . _con . get ( server [ '<STR_LIT>' ] + '<STR_LIT>' ) \n def get_ilo_sso_url ( self , server ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . _con . get ( server [ '<STR_LIT>' ] + '<STR_LIT>' ) \n def get_java_remote_console_url ( self , server ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . _con . get ( server [ '<STR_LIT>' ] + '<STR_LIT>' ) \n def get_remote_console_url ( self , server ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . _con . get ( server [ '<STR_LIT>' ] + '<STR_LIT>' ) \n def get_server_hardware_types ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n body = self . _con . get ( uri [ '<STR_LIT>' ] ) \n return get_members ( body ) \n def remove_server_hardware_type ( self , server_hardware_type , force = False , blocking = True , verbose = False ) : \n \"\"\"<STR_LIT>\"\"\" \n if force : \n task , body = self . _con . delete ( server_hardware_type [ '<STR_LIT>' ] + '<STR_LIT>' ) \n else : \n task , body = self . _con . delete ( server_hardware_type [ '<STR_LIT>' ] ) \n if blocking is True : \n task = self . _activity . wait4task ( task , tout = <NUM_LIT> , verbose = verbose ) \n return task \n def get_server_type_schema ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . _con . get ( uri [ '<STR_LIT>' ] + '<STR_LIT>' ) \n def get_server_hardware_type ( self , server_type ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . _con . get ( server_type [ '<STR_LIT>' ] ) \n def set_server_hardware_type ( self , server_hardware_type , name , description ) : \n \"\"\"<STR_LIT>\"\"\" \n request = make_server_type_dict ( name , description ) \n task , body = self . _con . put ( server_hardware_type [ '<STR_LIT>' ] , request ) \n return task \n def create_server_profile ( self , \n affinity = '<STR_LIT>' , \n biosSettings = None , \n bootSettings = None , \n bootModeSetting = None , \n profileConnectionV4 = None , \n description = None , \n firmwareSettingsV3 = None , \n hideUnusedFlexNics = True , \n localStorageSettingsV3 = None , \n macType = '<STR_LIT>' , \n name = None , \n sanStorageV3 = None , \n serialNumber = None , \n serialNumberType = '<STR_LIT>' , \n serverHardwareTypeUri = None , \n serverHardwareUri = None , \n serverProfileTemplateUri = None , \n uuid = None , \n wwnType = '<STR_LIT>' , \n blocking = True , verbose = False ) : \n \"\"\"<STR_LIT>\"\"\" \n profile = make_ServerProfileV5 ( affinity , biosSettings , bootSettings , \n bootModeSetting , profileConnectionV4 , \n description , firmwareSettingsV3 , \n hideUnusedFlexNics , \n localStorageSettingsV3 , macType , name , \n sanStorageV3 , serialNumber , \n serialNumberType , serverHardwareTypeUri , \n serverHardwareUri , \n serverProfileTemplateUri , uuid , wwnType ) \n task , body = self . _con . post ( uri [ '<STR_LIT>' ] , profile ) \n if profile [ '<STR_LIT>' ] is None : \n tout = <NUM_LIT> \n else : \n tout = <NUM_LIT> \n if blocking is True : \n task = self . _activity . wait4task ( task , tout , verbose = verbose ) \n if '<STR_LIT:type>' in task and task [ '<STR_LIT:type>' ] . startswith ( '<STR_LIT>' ) : \n entity = self . _activity . get_task_associated_resource ( task ) \n profile = self . _con . get ( entity [ '<STR_LIT>' ] ) \n return profile \n return task \n def post_server_profile ( self , profile , blocking = True , verbose = False ) : \n \"\"\"<STR_LIT>\"\"\" \n task , body = self . _con . post ( uri [ '<STR_LIT>' ] , profile ) \n if profile [ '<STR_LIT>' ] is None : \n tout = <NUM_LIT> \n else : \n tout = <NUM_LIT> \n if blocking is True : \n task = self . _activity . wait4task ( task , tout , verbose = verbose ) \n if '<STR_LIT:type>' in task and task [ '<STR_LIT:type>' ] . startswith ( '<STR_LIT>' ) : \n entity = self . _activity . get_task_associated_resource ( task ) \n profile = self . _con . get ( entity [ '<STR_LIT>' ] ) \n return profile \n return task \n def remove_server_profile ( self , profile , force = False , blocking = True , verbose = False ) : \n if force : \n task , body = self . _con . delete ( profile [ '<STR_LIT>' ] + '<STR_LIT>' ) \n else : \n task , body = self . _con . delete ( profile [ '<STR_LIT>' ] ) \n if blocking is True : \n task = self . _activity . wait4task ( task , tout = <NUM_LIT> , verbose = verbose ) \n return task \n def get_server_profiles ( self ) : \n body = self . _con . get ( uri [ '<STR_LIT>' ] ) \n return get_members ( body ) \n def update_server_profile ( self , profile , blocking = True , verbose = False ) : \n task , body = self . _con . put ( profile [ '<STR_LIT>' ] , profile ) \n try : \n if profile [ '<STR_LIT>' ] [ '<STR_LIT>' ] is None : \n tout = <NUM_LIT> \n else : \n tout = <NUM_LIT> \n except Exception : \n tout = <NUM_LIT> \n if blocking is True : \n task = self . _activity . wait4task ( task , tout = tout , verbose = verbose ) \n profileResource = self . _activity . get_task_associated_resource ( task ) \n profile = self . _con . get ( profileResource [ '<STR_LIT>' ] ) \n return profile \n def update_server_profile_from_template ( self , profile , blocking = True , verbose = False ) : \n patch_request = [ { '<STR_LIT>' : '<STR_LIT:replace>' , '<STR_LIT:path>' : '<STR_LIT>' , '<STR_LIT:value>' : '<STR_LIT>' } ] \n task , body = self . _con . patch ( profile [ '<STR_LIT>' ] , patch_request ) \n try : \n if profile [ '<STR_LIT>' ] [ '<STR_LIT>' ] is None : \n tout = <NUM_LIT> \n else : \n tout = <NUM_LIT> \n except Exception : \n tout = <NUM_LIT> \n if blocking is True : \n task = self . _activity . wait4task ( task , tout = tout , verbose = verbose ) \n profileResource = self . _activity . get_task_associated_resource ( task ) \n profile = self . _con . get ( profileResource [ '<STR_LIT>' ] ) \n return profile \n def get_server_profile_by_name ( self , name ) : \n body = self . _con . get_entity_byfield ( uri [ '<STR_LIT>' ] , '<STR_LIT:name>' , name ) \n return body \n def get_profile_message ( self , profile ) : \n \"\"\"<STR_LIT>\"\"\" \n message = self . _con . get ( profile [ '<STR_LIT>' ] + '<STR_LIT>' ) \n return message \n def get_profile_compliance_preview ( self , profile ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . _con . get ( profile [ '<STR_LIT>' ] + '<STR_LIT>' ) \n def create_server_profile_template ( \n self , \n name = None , \n description = None , \n serverProfileDescription = None , \n serverHardwareTypeUri = None , \n enclosureGroupUri = None , \n affinity = None , \n hideUnusedFlexNics = None , \n profileConnectionV4 = None , \n firmwareSettingsV3 = None , \n bootSettings = None , \n bootModeSetting = None , \n blocking = True , \n verbose = False ) : \n \"\"\"<STR_LIT>\"\"\" \n profile_template = make_ServerProfileTemplateV1 ( name , \n description , \n serverProfileDescription , \n serverHardwareTypeUri , \n enclosureGroupUri , \n affinity , \n hideUnusedFlexNics , \n profileConnectionV4 , \n firmwareSettingsV3 , \n bootSettings , \n bootModeSetting ) \n task , body = self . _con . post ( uri [ '<STR_LIT>' ] , profile_template ) \n tout = <NUM_LIT> \n if blocking is True : \n task = self . _activity . wait4task ( task , tout , verbose = verbose ) \n if '<STR_LIT:type>' in task and task [ '<STR_LIT:type>' ] . startswith ( '<STR_LIT>' ) : \n entity = self . _activity . get_task_associated_resource ( task ) \n profile_template = self . _con . get ( entity [ '<STR_LIT>' ] ) \n return profile_template \n return task \n def remove_server_profile_template ( self , profile_template , blocking = True , verbose = False ) : \n task , body = self . _con . delete ( profile_template [ '<STR_LIT>' ] ) \n if blocking is True : \n task = self . _activity . wait4task ( task , tout = <NUM_LIT> , verbose = verbose ) \n return task \n return body \n def get_server_profile_templates ( self ) : \n body = self . _con . get ( uri [ '<STR_LIT>' ] ) \n return get_members ( body ) \n def get_server_profile_template_by_name ( self , name ) : \n body = self . _con . get_entity_byfield ( uri [ '<STR_LIT>' ] , '<STR_LIT:name>' , name ) \n return body \n def update_server_profile_template ( self , profile_template , blocking = True , verbose = False ) : \n task , body = self . _con . put ( profile_template [ '<STR_LIT>' ] , profile_template ) \n tout = <NUM_LIT> \n if blocking is True : \n task = self . _activity . wait4task ( task , tout = tout , verbose = verbose ) \n profileTemplateResource = self . _activity . get_task_associated_resource ( task ) \n profile = self . _con . get ( profileTemplateResource [ '<STR_LIT>' ] ) \n return profile_template \n def get_server_profile_from_template ( self , profile_template ) : \n profile = self . _con . get ( profile_template [ '<STR_LIT>' ] + '<STR_LIT>' ) \n return profile \n def get_enclosures ( self ) : \n body = self . _con . get ( uri [ '<STR_LIT>' ] ) \n return get_members ( body ) \n def add_enclosure ( self , enclosure , blocking = True , verbose = False ) : \n task , body = self . _con . post ( uri [ '<STR_LIT>' ] , enclosure ) \n if enclosure [ '<STR_LIT:state>' ] is '<STR_LIT>' : \n tout = <NUM_LIT> \n elif enclosure [ '<STR_LIT>' ] is None : \n tout = <NUM_LIT> \n else : \n tout = <NUM_LIT> \n if blocking is True : \n task = self . _activity . wait4task ( task , tout , verbose = verbose ) \n if '<STR_LIT:type>' in task and task [ '<STR_LIT:type>' ] . startswith ( '<STR_LIT>' ) : \n entity = self . _activity . get_task_associated_resource ( task ) \n enclosure = self . _con . get ( entity [ '<STR_LIT>' ] ) \n return enclosure \n return task \n def remove_enclosure ( self , enclosure , force = False , blocking = True , \n verbose = False ) : \n if force : \n task , body = self . _con . delete ( enclosure [ '<STR_LIT>' ] + '<STR_LIT>' ) \n else : \n task , body = self . _con . delete ( enclosure [ '<STR_LIT>' ] ) \n if blocking is True : \n task = self . _activity . wait4task ( task , tout = <NUM_LIT> , verbose = verbose ) \n return task \n def create_enclosure_group ( self , associatedLIGs , name , \n powerMode = '<STR_LIT>' ) : \n \"\"\"<STR_LIT>\"\"\" \n egroup = make_EnclosureGroupV200 ( associatedLIGs , name , powerMode ) \n task , body = self . _con . post ( uri [ '<STR_LIT>' ] , egroup ) \n return body \n def delete_enclosure_group ( self , egroup ) : \n self . _con . delete ( egroup [ '<STR_LIT>' ] ) \n def get_enclosure_groups ( self ) : \n return get_members ( self . _con . get ( uri [ '<STR_LIT>' ] ) ) \n def update_enclosure_group ( self , enclosuregroup ) : \n task , body = self . _con . put ( enclosuregroup [ '<STR_LIT>' ] , enclosuregroup ) \n return body \n def get_pool ( self , pooltype ) : \n body = self . _con . get ( uri [ '<STR_LIT>' ] + '<STR_LIT:/>' + pooltype ) \n return body \n def get_vmac_pool ( self ) : \n body = self . _con . get ( uri [ '<STR_LIT>' ] ) \n return body \n def get_vwwn_pool ( self ) : \n body = self . _con . get ( uri [ '<STR_LIT>' ] ) \n return body \n def get_vsn_pool ( self ) : \n body = self . _con . get ( uri [ '<STR_LIT>' ] ) \n return body \n def get_profile_networks ( self ) : \n body = self . _con . get ( uri [ '<STR_LIT>' ] ) \n return body \n def get_profile_schema ( self ) : \n return self . _con . get ( uri [ '<STR_LIT>' ] ) \n def get_profile_available_servers ( self ) : \n body = self . _con . get ( uri [ '<STR_LIT>' ] ) \n return body \n def get_profile_available_storage_systems ( self ) : \n body = self . _con . get ( uri [ '<STR_LIT>' ] ) \n return body \n def get_profile_ports ( self ) : \n body = self . _con . get ( uri [ '<STR_LIT>' ] ) \n return body \n def allocate_pool_ids ( self , url , count ) : \n allocatorUrl = '<STR_LIT>' % url \n allocatorBody = { '<STR_LIT:count>' : count } \n task , body = self . _con . put ( allocatorUrl , allocatorBody ) \n return body \n def release_pool_ids ( self , url , idList ) : \n collectorUrl = '<STR_LIT>' % url \n collectorBody = { '<STR_LIT>' : idList } \n task , body = self . _con . put ( collectorUrl , collectorBody ) \n return body \n def allocate_range_ids ( self , allocatorUrl , count ) : \n task , body = self . _con . put ( allocatorUrl , { '<STR_LIT:count>' : count } ) \n return body \n def release_range_ids ( self , collectorUrl , idList ) : \n task , body = self . _con . put ( collectorUrl , { '<STR_LIT>' : idList } ) \n return body \n def enable_range ( self , url ) : \n prange = self . _con . get ( url ) \n prange [ '<STR_LIT>' ] = True \n task , body = self . _con . put ( url , prange ) \n return body \n def disable_range ( self , url ) : \n prange = self . _con . get ( url ) \n prange [ '<STR_LIT>' ] = False \n task , body = self . _con . put ( url , prange ) \n return body \n", "gt": "__title__"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import os \n import re \n import sys \n import json \n import locale \n import zipfile \n import logging \n import textwrap \n import validictory \n from . sharedtypes import JSONEncoder \n from ilorest . rest . v1_helper import ( RisObject ) \n <mask0> = logging . getLogger ( __name__ ) \n class ValidationError ( Exception ) : \n \"\"\"<STR_LIT>\"\"\" \n pass \n class SchemaValidationError ( ValidationError ) : \n \"\"\"<STR_LIT>\"\"\" \n pass \n class RegistryValidationError ( ValidationError ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , msg , regentry = None , selector = None ) : \n super ( RegistryValidationError , self ) . __init__ ( msg ) \n self . reg = regentry \n self . sel = selector \n class UnknownValidatorError ( Exception ) : \n \"\"\"<STR_LIT>\"\"\" \n \"\"\"<STR_LIT>\"\"\" \n class ValidationManager ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , local_path , bios_local_path , romfamily = None , biosversion = None , iloversion = None , monolith = None ) : \n super ( ValidationManager , self ) . __init__ ( ) \n defaultilopath = None \n defaultbiospath = None \n schemamainfolder = None \n if float ( iloversion ) < <NUM_LIT> : \n if os . name == '<STR_LIT>' : \n defaultilopath = r\"<STR_LIT>\" \n defaultbiospath = r\"<STR_LIT>\" \n schemamainfolder = os . path . dirname ( sys . executable ) \n else : \n defaultilopath = \"<STR_LIT>\" \n defaultbiospath = \"<STR_LIT>\" \n schemamainfolder = \"<STR_LIT>\" \n if not local_path : \n if not os . path . isdir ( defaultilopath ) : \n ilozip = self . getiloziplocation ( schemamainfolder , iloversion ) \n if ilozip and os . path . exists ( ilozip ) : \n with zipfile . ZipFile ( os . path . join ( schemamainfolder , ilozip ) , \"<STR_LIT:r>\" ) as zfile : \n zfile . extractall ( os . path . join ( schemamainfolder , \"<STR_LIT>\" ) ) \n local_path = os . path . join ( schemamainfolder , u'<STR_LIT>' ) \n else : \n raise SchemaValidationError ( u'<STR_LIT>' '<STR_LIT>' '<STR_LIT>' '<STR_LIT>' ) \n else : \n local_path = defaultilopath \n else : \n if not os . path . isdir ( local_path ) : \n raise SchemaValidationError ( u\"<STR_LIT>\" \n \"<STR_LIT>\" % local_path ) \n if not bios_local_path : \n if not os . path . isdir ( defaultbiospath ) : \n bioszip = self . getbiosziplocation ( romfamily , schemamainfolder , biosversion ) \n if bioszip and os . path . exists ( bioszip ) : \n with zipfile . ZipFile ( \n os . path . join ( schemamainfolder , bioszip ) , \"<STR_LIT:r>\" ) as zfile : \n zfile . extractall ( os . path . join ( schemamainfolder , \"<STR_LIT>\" ) ) \n bios_local_path = os . path . join ( schemamainfolder , u'<STR_LIT>' ) \n else : \n raise SchemaValidationError ( u'<STR_LIT>' '<STR_LIT>' '<STR_LIT>' '<STR_LIT>' ) \n else : \n bios_local_path = defaultbiospath \n else : \n if not os . path . isdir ( bios_local_path ) : \n raise SchemaValidationError ( u\"<STR_LIT>\" \"<STR_LIT>\" % bios_local_path ) \n else : \n if monolith . is_redfish : \n local_path = \"<STR_LIT>\" \n bios_local_path = \"<STR_LIT>\" \n else : \n local_path = \"<STR_LIT>\" \n bios_local_path = \"<STR_LIT>\" \n self . _schema_locations = list ( ) \n self . _classes = list ( ) \n self . _registry_locations = list ( ) \n self . _classes_registry = list ( ) \n self . _bios_schema_locations = list ( ) \n self . _bios_classes = list ( ) \n self . _bios_registry_locations = list ( ) \n self . _bios_classes_registry = list ( ) \n self . _ilo_messages = list ( ) \n self . _base_messages = list ( ) \n self . _hpcommon_messages = list ( ) \n self . _iloevents_messages = list ( ) \n self . _errors = list ( ) \n if monolith . is_redfish : \n self . _schemaid = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] \n self . _regid = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] \n else : \n self . _schemaid = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] \n self . _regid = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] \n if local_path : \n self . add_location ( schema_path = local_path , monolith = monolith ) \n self . add_location ( registry_path = local_path , monolith = monolith ) \n if bios_local_path : \n self . add_location ( schema_path = bios_local_path , biossection = True , monolith = monolith ) \n self . add_location ( registry_path = bios_local_path , biossection = True , monolith = monolith ) \n def getbiosziplocation ( self , romfamily , schemadir , biosversion ) : \n \"\"\"<STR_LIT>\"\"\" \n foundfile = None \n currentver = None \n tempstr = \"<STR_LIT>\" + romfamily + \"<STR_LIT:->\" + biosversion \n for _ , _ , filenames in os . walk ( schemadir ) : \n for filename in filenames : \n if tempstr in filename : \n regentry = re . compile ( '<STR_LIT>' % tempstr ) \n mentry = regentry . search ( filename ) \n if mentry and currentver : \n if currentver < mentry . group ( <NUM_LIT:1> ) : \n foundfile = filename \n currentver = mentry . group ( <NUM_LIT:1> ) \n elif mentry and not currentver : \n foundfile = filename \n currentver = mentry . group ( <NUM_LIT:1> ) \n if foundfile : \n return os . path . join ( schemadir , foundfile ) \n else : \n return None \n def getiloziplocation ( self , schemadir , iloversion ) : \n \"\"\"<STR_LIT>\"\"\" \n if float ( iloversion ) < <NUM_LIT> : \n iloversion = u'<STR_LIT>' \n tempstr = \"<STR_LIT>\" + iloversion . replace ( \"<STR_LIT:.>\" , \"<STR_LIT>\" ) \n for _ , _ , filenames in os . walk ( schemadir ) : \n for filename in filenames : \n if tempstr in filename : \n return os . path . join ( schemadir , filename ) \n return None \n def add_location ( self , schema_path = None , registry_path = None , \n biossection = False , monolith = None ) : \n \"\"\"<STR_LIT>\"\"\" \n \"\"\"<STR_LIT>\"\"\" \n if schema_path : \n if not biossection : \n self . _schema_locations . append ( schema_path ) \n self . _update_location_map ( monolith = monolith ) \n else : \n self . _bios_schema_locations . append ( schema_path ) \n self . _update_location_map ( biossection = True , monolith = monolith ) \n elif registry_path : \n if not biossection : \n self . _registry_locations . append ( registry_path ) \n self . _update_location_map ( registries = True , monolith = monolith ) \n else : \n self . _bios_registry_locations . append ( registry_path ) \n self . _update_location_map ( biossection = True , registries = True , monolith = monolith ) \n else : \n raise ValueError ( u\"<STR_LIT>\" \"<STR_LIT>\" ) \n def _update_location_map ( self , biossection = False , registries = False , \n monolith = None ) : \n \"\"\"<STR_LIT>\"\"\" \n locationslist = list ( ) \n pathjoinstr = None \n if not registries : \n pathjoinstr = \"<STR_LIT>\" \n if not biossection : \n locationslist = self . _schema_locations \n else : \n locationslist = self . _bios_schema_locations \n else : \n pathjoinstr = \"<STR_LIT>\" \n if not biossection : \n locationslist = self . _registry_locations \n else : \n locationslist = self . _bios_registry_locations \n for location in locationslist : \n if monolith : \n self . new_load_file ( monolith , root = location , biossection = biossection , registries = registries ) \n elif self . _is_local ( location ) : \n for root , _ , filenames in os . walk ( os . path . join ( location , \n pathjoinstr ) ) : \n for filename in filenames : \n fqpath = os . path . abspath ( os . path . join ( os . path . normpath ( root ) , filename ) ) \n if self . load_file ( fqpath , root = location , biossection = biossection , registries = registries ) : \n LOGGER . info ( \"<STR_LIT>\" , fqpath ) \n def new_load_file ( self , monolith , root = None , biossection = False , registries = False ) : \n \"\"\"<STR_LIT>\"\"\" \n classesdataholder = [ ] \n for itemtype in monolith . types : \n if itemtype . startswith ( \"<STR_LIT>\" ) or itemtype . startswith ( \"<STR_LIT>\" ) and u'<STR_LIT>' in monolith . types [ itemtype ] : \n for instance in monolith . types [ itemtype ] [ u'<STR_LIT>' ] : \n if self . _schemaid [ <NUM_LIT:0> ] in instance . resp . request . path . lower ( ) or self . _regid [ <NUM_LIT:0> ] in instance . resp . request . path . lower ( ) : \n if not registries and self . _schemaid [ <NUM_LIT:0> ] in instance . resp . request . path . lower ( ) : \n if classesdataholder : \n if self . _schemaid [ <NUM_LIT:1> ] in instance . resp . dict : \n classesdataholder [ <NUM_LIT:0> ] [ self . _schemaid [ <NUM_LIT:1> ] ] . extend ( instance . resp . dict [ self . _schemaid [ <NUM_LIT:1> ] ] ) \n else : \n classesdataholder . append ( instance . resp . dict ) \n elif registries and self . _regid [ <NUM_LIT:0> ] in instance . resp . request . path . lower ( ) : \n if classesdataholder : \n if monolith . is_redfish : \n classesdataholder [ <NUM_LIT:0> ] [ self . _regid [ <NUM_LIT:1> ] ] . extend ( instance . resp . dict [ self . _regid [ <NUM_LIT:1> ] ] ) \n else : \n classesdataholder . append ( instance . resp . dict ) \n if classesdataholder : \n classesdataholder = classesdataholder [ <NUM_LIT:0> ] \n try : \n if monolith . _typestring in classesdataholder and ( '<STR_LIT>' in classesdataholder [ monolith . _typestring ] or ( '<STR_LIT>' in classesdataholder [ monolith . _typestring ] and monolith . is_redfish ) ) : \n newclass = Classes . parse ( classesdataholder ) \n newclass . set_root ( root ) \n if not registries : \n if not biossection : \n self . _classes . append ( newclass ) \n else : \n self . _bios_classes . append ( newclass ) \n else : \n if not biossection : \n self . _classes_registry . append ( newclass ) \n else : \n self . _bios_classes_registry . append ( newclass ) \n except BaseException : \n pass \n else : \n pass \n def load_file ( self , filepath , root = None , biossection = False , \n registries = False , datareturn = False ) : \n \"\"\"<STR_LIT>\"\"\" \n result = False \n if os . path . isfile ( filepath ) : \n try : \n filehand = open ( filepath , '<STR_LIT:r>' ) \n data = json . load ( filehand ) \n if datareturn : \n return data \n if u'<STR_LIT>' in data and data [ u'<STR_LIT>' ] == '<STR_LIT>' : \n if biossection and registries : \n itemsreturn = self . bios_helper_function ( data , root ) \n data [ \"<STR_LIT>\" ] = itemsreturn \n newclass = Classes . parse ( data ) \n newclass . set_root ( root ) \n if not registries : \n if not biossection : \n self . _classes . append ( newclass ) \n else : \n self . _bios_classes . append ( newclass ) \n else : \n if not biossection : \n self . _classes_registry . append ( newclass ) \n else : \n self . _bios_classes_registry . append ( newclass ) \n result = True \n except BaseException : \n pass \n else : \n pass \n finally : \n filehand . close ( ) \n return result \n def bios_helper_function ( self , data , root ) : \n \"\"\"<STR_LIT>\"\"\" \n folderentries = data [ \"<STR_LIT>\" ] \n datareturn = list ( ) \n for entry in folderentries [ \"<STR_LIT>\" ] : \n joinstr = entry [ \"<STR_LIT>\" ] \n if os . name == '<STR_LIT>' and joinstr [ <NUM_LIT:0> ] == \"<STR_LIT:/>\" : \n joinstr = joinstr . replace ( \"<STR_LIT:/>\" , \"<STR_LIT:\\\\>\" ) [ <NUM_LIT:1> : ] \n elif joinstr [ <NUM_LIT:0> ] == \"<STR_LIT:/>\" : \n joinstr = joinstr [ <NUM_LIT:1> : ] \n for root , _ , filenames in os . walk ( os . path . join ( root , joinstr ) ) : \n for filename in filenames : \n fqpath = os . path . abspath ( os . path . join ( os . path . normpath ( root ) , filename ) ) \n datareturn . append ( self . load_file ( fqpath , root = root , biossection = True , registries = True , datareturn = True ) ) \n LOGGER . info ( \"<STR_LIT>\" , fqpath ) \n return datareturn \n def validate ( self , item , selector = None , currdict = None , monolith = None , \n newarg = None , checkall = False , regloc = None ) : \n \"\"\"<STR_LIT>\"\"\" \n \"\"\"<STR_LIT>\"\"\" \n if regloc : \n attrreg = RepoRegistryEntry ( regloc ) \n else : \n attrreg = self . find_schema ( schname = item [ monolith . _typestring ] ) \n if attrreg : \n tempvalue = attrreg . validate ( item , self . _errors , selector = selector , \n currdict = currdict , monolith = monolith , \n newarg = newarg , checkall = checkall ) \n if tempvalue is True : \n return False \n elif tempvalue : \n self . _errors = tempvalue \n return True \n def bios_validate ( self , item , regname , selector = None , currdict = None , \n checkall = False , monolith = None ) : \n \"\"\"<STR_LIT>\"\"\" \n \"\"\"<STR_LIT>\"\"\" \n attrreg = self . find_bios_registry ( regname = regname ) \n if attrreg : \n tempvalue = attrreg . validate_bios_version ( item , self . _errors , selector = selector , currdict = currdict , checkall = checkall , monolith = monolith ) \n if tempvalue == '<STR_LIT>' : \n return tempvalue \n elif tempvalue == '<STR_LIT>' : \n return tempvalue \n elif tempvalue : \n self . _errors = tempvalue \n return True \n def bios_info ( self , item , regname , selector ) : \n \"\"\"<STR_LIT>\"\"\" \n \"\"\"<STR_LIT>\"\"\" \n attrreg = self . find_bios_registry ( regname = regname ) \n if attrreg : \n if attrreg . validate_bios_version ( item , self . _errors , selector = selector ) : \n return False \n return True \n def find_schema ( self , schname ) : \n \"\"\"<STR_LIT>\"\"\" \n \"\"\"<STR_LIT>\"\"\" \n for cls in self . _classes : \n found = cls . find_schema ( schname = schname ) \n if found : \n return found \n return None \n def find_registry ( self , regname ) : \n \"\"\"<STR_LIT>\"\"\" \n \"\"\"<STR_LIT>\"\"\" \n for cls in self . _classes_registry : \n found = cls . find_registry ( regname = regname ) \n if found : \n return found \n return None \n def find_bios_registry ( self , regname ) : \n \"\"\"<STR_LIT>\"\"\" \n \"\"\"<STR_LIT>\"\"\" \n for cls in self . _bios_classes_registry : \n found = cls . find_bios_registry ( regname = regname ) \n if found : \n return found \n return None \n def get_errors ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . _errors \n def _is_local ( self , path ) : \n \"\"\"<STR_LIT>\"\"\" \n if u'<STR_LIT>' in path : \n return False \n return True \n class Classes ( RisObject ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , item ) : \n super ( Classes , self ) . __init__ ( item ) \n self . _root = None \n def set_root ( self , newroot ) : \n \"\"\"<STR_LIT>\"\"\" \n self . _root = newroot \n def find_schema ( self , schname ) : \n \"\"\"<STR_LIT>\"\"\" \n result = None \n if hasattr ( self , '<STR_LIT>' ) and isinstance ( self . Items , list ) : \n for entry in self . Items : \n if entry and u'<STR_LIT>' in entry and entry [ u'<STR_LIT>' ] . lower ( ) == schname . lower ( ) : \n regentry = RepoRegistryEntry . parse ( entry ) \n regentry . set_root ( self . _root ) \n result = regentry \n break \n elif hasattr ( self , '<STR_LIT>' ) and isinstance ( self . Members , list ) : \n schname = schname . split ( '<STR_LIT:.>' ) [ - <NUM_LIT:1> ] \n for entry in self . Members : \n schlink = entry [ u'<STR_LIT>' ] . split ( '<STR_LIT:/>' ) \n schlink = schlink [ len ( schlink ) - <NUM_LIT:2> ] \n if schname . lower ( ) == schlink . lower ( ) : \n result = entry \n break \n return result \n def find_registry ( self , regname ) : \n \"\"\"<STR_LIT>\"\"\" \n result = None \n if hasattr ( self , '<STR_LIT>' ) and isinstance ( self . Items , list ) : \n for entry in self . Items : \n if entry and ( u'<STR_LIT>' in entry and \n entry [ u'<STR_LIT>' ] . lower ( ) . startswith ( regname . lower ( ) ) ) : \n regentry = RepoRegistryEntry . parse ( entry ) \n regentry . set_root ( self . _root ) \n result = regentry \n break \n elif hasattr ( self , '<STR_LIT>' ) and isinstance ( self . Members , list ) : \n regname = regname . split ( '<STR_LIT:.>' ) [ - <NUM_LIT:1> ] \n for entry in self . Members : \n reglink = entry [ u'<STR_LIT>' ] . split ( '<STR_LIT:/>' ) \n reglink = reglink [ len ( reglink ) - <NUM_LIT:2> ] \n if regname . lower ( ) == reglink . lower ( ) : \n result = entry \n break \n return result \n def find_bios_schema ( self , schname ) : \n \"\"\"<STR_LIT>\"\"\" \n result = None \n if hasattr ( self , '<STR_LIT>' ) and isinstance ( self . Items , list ) : \n for entry in self . Items : \n if ( u'<STR_LIT>' in entry and entry [ u'<STR_LIT>' ] . lower ( ) == \n schname . lower ( ) ) : \n regentry = RepoRegistryEntry . parse ( entry ) \n regentry . set_root ( self . _root ) \n result = regentry \n break \n return result \n def find_bios_registry ( self , regname ) : \n \"\"\"<STR_LIT>\"\"\" \n result = None \n if hasattr ( self , '<STR_LIT>' ) and isinstance ( self . Items , list ) : \n for entry in self . Items : \n if entry and ( u'<STR_LIT>' in entry and regname . lower ( ) in entry [ u'<STR_LIT>' ] . lower ( ) ) : \n regentry = RepoRegistryEntry . parse ( entry ) \n regentry . set_root ( self . _root ) \n result = regentry \n break \n return result \n class RepoBaseEntry ( RisObject ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , d ) : \n super ( RepoBaseEntry , self ) . __init__ ( d ) \n self . _root = None \n def set_root ( self , newroot ) : \n \"\"\"<STR_LIT>\"\"\" \n self . _root = newroot \n def _read_location_file ( self , currloc , errlist ) : \n \"\"\"<STR_LIT>\"\"\" \n result = None \n if u'<STR_LIT>' in currloc : \n root = os . path . normpath ( self . _root ) \n xref = os . path . normpath ( currloc . Uri . extref ) . lstrip ( os . path . sep ) \n fqpath = os . path . join ( root , xref ) \n if not os . path . isfile ( fqpath ) : \n errlist . append ( SchemaValidationError ( \n u\"<STR_LIT>\" % fqpath ) ) \n else : \n result = None \n if fqpath . endswith ( '<STR_LIT>' ) : \n result = open ( fqpath ) . read ( ) \n return result \n class RepoRegistryEntry ( RepoBaseEntry ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , d ) : \n super ( RepoRegistryEntry , self ) . __init__ ( d ) \n def validate ( self , tdict , errlist = None , selector = None , currdict = None , checkall = False , monolith = None , newarg = None ) : \n \"\"\"<STR_LIT>\"\"\" \n if not errlist : \n errlist = list ( ) \n reg = self . get_registry_model ( errlist = errlist , currdict = currdict , monolith = monolith , newarg = newarg ) \n if reg and not checkall : \n try : \n if reg [ selector ] . readonly : \n return True \n except BaseException : \n pass \n else : \n pass \n results = reg . validate_attribute_values ( tdict ) \n errlist . extend ( results ) \n elif checkall and selector is None : \n results = reg . validate_attribute_values ( tdict ) \n errlist . extend ( results ) \n else : \n errlist . append ( RegistryValidationError ( u'<STR_LIT>' '<STR_LIT>' ) ) \n if errlist : \n return errlist \n def validate_bios_version ( self , tdict , errlist = None , selector = None , checkall = False , currdict = None , monolith = None ) : \n \"\"\"<STR_LIT>\"\"\" \n if not errlist : \n errlist = list ( ) \n reg = self . get_registry_model_bios_version ( errlist = errlist , currdict = currdict , monolith = monolith ) \n if reg and not checkall : \n for item in reg . Attributes : \n if not item [ \"<STR_LIT:Name>\" ] == selector : \n continue \n if item [ \"<STR_LIT>\" ] is True : \n return '<STR_LIT>' \n try : \n if item [ \"<STR_LIT>\" ] is True : \n return '<STR_LIT>' \n except BaseException : \n continue \n else : \n continue \n results = reg . validate_att_val_bios ( tdict ) \n errlist . extend ( results ) \n elif checkall and selector is None : \n results = reg . validate_att_val_bios ( tdict ) \n errlist . extend ( results ) \n else : \n errlist . append ( RegistryValidationError ( u'<STR_LIT>' '<STR_LIT>' ) ) \n if errlist : \n return errlist \n def validate_deprecated ( self , tdict , errlist = None ) : \n \"\"\"<STR_LIT>\"\"\" \n if not errlist : \n errlist = list ( ) \n if not hasattr ( self , u'<STR_LIT>' ) : \n errlist . append ( RegistryValidationError ( u'<STR_LIT>' '<STR_LIT>' ) ) \n return errlist \n currloc = None \n defloc = None \n langcode = '<STR_LIT>' \n for loc in self . Location : \n for loclang in loc . keys ( ) : \n if loclang . lower ( ) == langcode . lower ( ) : \n currloc = loc [ loclang ] \n break \n elif loclang . lower ( ) == u'<STR_LIT:default>' : \n defloc = loc [ loclang ] \n if not currloc : \n currloc = defloc \n if not currloc : \n errlist . append ( RegistryValidationError ( u'<STR_LIT>' '<STR_LIT>' ) ) \n return \n location_file = self . _read_location_file ( currloc , errlist = errlist ) \n if not location_file : \n errlist . append ( RegistryValidationError ( u'<STR_LIT>' ) ) \n else : \n jsonreg = json . loads ( location_file ) \n if u'<STR_LIT>' in jsonreg : \n if u'<STR_LIT>' in jsonreg and jsonreg [ u'<STR_LIT>' ] == u'<STR_LIT>' : \n reg = HpPropertiesRegistry . parse ( jsonreg [ u'<STR_LIT>' ] ) \n results = reg . validate_attribute_values ( tdict ) \n errlist . extend ( results ) \n def get_registry_model ( self , currdict = None , monolith = None , errlist = None , skipcommit = False , searchtype = None , newarg = None , latestschema = None ) : \n \"\"\"<STR_LIT>\"\"\" \n if not errlist : \n errlist = list ( ) \n if not hasattr ( self , u'<STR_LIT>' ) : \n errlist . append ( RegistryValidationError ( \n u'<STR_LIT>' ) ) \n return None \n currloc = None \n defloc = \"<STR_LIT>\" \n langcode = list ( locale . getdefaultlocale ( ) ) \n if not langcode [ <NUM_LIT:0> ] : \n langcode [ <NUM_LIT:0> ] = \"<STR_LIT>\" \n for loc in self . Location : \n locationlanguage = loc [ \"<STR_LIT>\" ] . lower ( ) \n locationlanguage = locationlanguage . replace ( \"<STR_LIT:->\" , \"<STR_LIT:_>\" ) \n if locationlanguage in langcode [ <NUM_LIT:0> ] . lower ( ) : \n currloc = loc \n break \n if not currloc : \n currloc = defloc \n if not currloc : \n errlist . append ( RegistryValidationError ( u'<STR_LIT>' '<STR_LIT:location>' ) ) \n return None \n if not searchtype : \n searchtype = \"<STR_LIT>\" \n location_file = None \n if currdict and monolith : \n for itemtype in monolith . types : \n if itemtype . lower ( ) . startswith ( searchtype . lower ( ) ) and u'<STR_LIT>' in monolith . types [ itemtype ] : \n for instance in monolith . types [ itemtype ] [ u'<STR_LIT>' ] : \n try : \n if monolith . is_redfish : \n currtype = currdict [ instance . _typestring ] . split ( '<STR_LIT:#>' ) [ - <NUM_LIT:1> ] \n currtype = currtype . split ( '<STR_LIT:.>' ) [ <NUM_LIT:0> ] + '<STR_LIT:.>' \n else : \n currtype = currdict [ instance . _typestring ] \n if latestschema : \n currtype = currdict [ instance . _typestring ] . split ( '<STR_LIT:.>' ) [ : <NUM_LIT:1> ] \n insttype = instance . resp . dict [ \"<STR_LIT:title>\" ] . split ( '<STR_LIT:.>' ) [ : <NUM_LIT:1> ] \n if currtype == insttype or currtype == instance . resp . dict [ \"<STR_LIT>\" ] . split ( '<STR_LIT:.>' ) [ : <NUM_LIT:1> ] : \n location_file = instance . resp . dict \n break \n elif searchtype == \"<STR_LIT>\" and instance . resp . dict [ \"<STR_LIT:title>\" ] . startswith ( currtype ) or \"<STR_LIT>\" in instance . resp . dict . keys ( ) and currdict [ instance . _typestring ] == instance . resp . dict [ \"<STR_LIT>\" ] : \n location_file = instance . resp . dict \n break \n elif searchtype != \"<STR_LIT>\" and currdict [ instance . _typestring ] in instance . resp . dict [ \"<STR_LIT>\" ] : \n location_file = instance . resp . dict \n break \n except BaseException : \n pass \n else : \n pass \n if location_file : \n break \n else : \n location_file = self . _read_location_file ( currloc , errlist = errlist ) \n if not location_file : \n errlist . append ( RegistryValidationError ( u'<STR_LIT>' ) ) \n else : \n if currdict and monolith : \n jsonreg = json . loads ( json . dumps ( location_file , indent = <NUM_LIT:2> , cls = JSONEncoder ) ) \n else : \n jsonreg = json . loads ( location_file ) \n if skipcommit : \n return jsonreg [ \"<STR_LIT>\" ] \n if u'<STR_LIT>' in jsonreg : \n regitem = jsonreg [ u'<STR_LIT>' ] \n reg = HpPropertiesRegistry . parse ( regitem ) \n if newarg : \n regcopy = reg \n for arg in newarg [ : - <NUM_LIT:1> ] : \n try : \n if '<STR_LIT>' in regcopy [ arg ] . iterkeys ( ) and ( '<STR_LIT>' in regcopy [ arg ] . iterkeys ( ) ) : \n regcopy [ arg ] [ '<STR_LIT>' ] . update ( regcopy [ arg ] [ '<STR_LIT>' ] ) \n regcopy = regcopy [ arg ] [ \"<STR_LIT>\" ] \n for pattern in regcopy . iterkeys ( ) : \n test = re . compile ( pattern ) \n nextarg = newarg [ newarg . index ( arg ) + <NUM_LIT:1> ] \n match = test . match ( nextarg ) \n if match : \n regcopy [ nextarg ] = regcopy . pop ( pattern ) \n break \n elif '<STR_LIT>' in regcopy [ arg ] : \n oneof = regcopy [ arg ] [ '<STR_LIT>' ] \n for item in oneof : \n regcopy = item [ '<STR_LIT>' ] \n if not arg == newarg [ - <NUM_LIT:1> ] : \n try : \n nextitem = newarg [ newarg . index ( arg ) + <NUM_LIT:1> ] \n regcopy [ nextitem ] \n break \n except Exception : \n continue \n else : \n regcopy = regcopy [ arg ] [ \"<STR_LIT>\" ] \n except Exception : \n try : \n regcopy = regcopy [ arg ] [ '<STR_LIT>' ] \n for pattern in regcopy . iterkeys ( ) : \n test = re . compile ( pattern ) \n nextarg = newarg [ newarg . index ( arg ) + <NUM_LIT:1> ] \n match = test . match ( nextarg ) \n if match : \n patterninfo = regcopy . pop ( pattern ) \n regcopy [ nextarg ] = patterninfo \n except BaseException : \n return None \n reg = regcopy \n return reg \n return None \n def get_registry_model_bios_version ( self , currdict = None , monolith = None , errlist = None ) : \n \"\"\"<STR_LIT>\"\"\" \n \"\"\"<STR_LIT>\"\"\" \n if not errlist : \n errlist = list ( ) \n if not hasattr ( self , u'<STR_LIT>' ) : \n errlist . append ( RegistryValidationError ( \n u'<STR_LIT>' ) ) \n return None \n currloc = None \n defloc = \"<STR_LIT>\" \n langcode = list ( locale . getdefaultlocale ( ) ) \n if not langcode [ <NUM_LIT:0> ] : \n langcode [ <NUM_LIT:0> ] = \"<STR_LIT>\" \n for loc in self . Location : \n locationlanguage = loc [ \"<STR_LIT>\" ] . lower ( ) \n locationlanguage = locationlanguage . replace ( \"<STR_LIT:->\" , \"<STR_LIT:_>\" ) \n if locationlanguage in langcode [ <NUM_LIT:0> ] . lower ( ) : \n currloc = loc \n break \n if not currloc : \n currloc = defloc \n if not currloc : \n errlist . append ( RegistryValidationError ( \n u'<STR_LIT>' ) ) \n return None \n location_file = None \n if currdict and monolith : \n for itemtype in monolith . types : \n if \"<STR_LIT>\" in itemtype and u'<STR_LIT>' in monolith . types [ itemtype ] : \n for instance in monolith . types [ itemtype ] [ u'<STR_LIT>' ] : \n location_file = instance . resp . dict \n break \n if location_file : \n break \n else : \n location_file = self . _read_location_file ( currloc , errlist = errlist ) \n if not location_file : \n errlist . append ( RegistryValidationError ( u'<STR_LIT>' ) ) \n else : \n if currdict and monolith : \n jsonreg = json . loads ( json . dumps ( location_file , indent = <NUM_LIT:2> , cls = JSONEncoder ) ) \n else : \n jsonreg = json . loads ( location_file ) \n if u'<STR_LIT>' in jsonreg : \n regitem = jsonreg [ u'<STR_LIT>' ] \n reg = HpPropertiesRegistry . parse ( regitem ) \n return reg \n return None \n class RepoSchemaEntry ( RepoBaseEntry ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , item ) : \n super ( RepoSchemaEntry , self ) . __init__ ( item ) \n self . _root = None \n def set_root ( self , newroot ) : \n \"\"\"<STR_LIT>\"\"\" \n self . _root = newroot \n def _read_location_file ( self , currloc , errlist ) : \n \"\"\"<STR_LIT>\"\"\" \n if u'<STR_LIT>' in currloc and u'<STR_LIT>' in currloc : \n fqpath = os . path . join ( self . _root , currloc . ArchiveUri . xref . lstrip ( os . path . sep ) ) \n if not os . path . isfile ( fqpath ) : \n errlist . append ( SchemaValidationError ( u\"<STR_LIT>\" \"<STR_LIT>\" % fqpath ) ) \n else : \n archive_file = currloc . ArchiveFile \n archive_fh = None \n result = None \n if fqpath . endswith ( '<STR_LIT>' ) : \n archive_fh = zipfile . ZipFile ( fqpath ) \n infolist = archive_fh . infolist ( ) \n for i in infolist : \n if i . filename . lower ( ) == archive_file . lower ( ) : \n jsonsch_fh = archive_fh . open ( i ) \n result = jsonsch_fh . read ( ) \n jsonsch_fh . close ( ) \n archive_fh . close ( ) \n return result \n def validate ( self , tdict , errlist = None ) : \n \"\"\"<STR_LIT>\"\"\" \n if not errlist : \n errlist = list ( ) \n result = list ( ) \n if not hasattr ( self , u'<STR_LIT>' ) : \n result . append ( SchemaValidationError ( u'<STR_LIT>' '<STR_LIT>' ) ) \n return result \n currloc = None \n defloc = None \n langcode = '<STR_LIT>' \n for loc in self . Location : \n for loclang in loc . keys ( ) : \n if loclang . lower ( ) == langcode . lower ( ) : \n currloc = loc [ loclang ] \n break \n elif loclang . lower ( ) == u'<STR_LIT:default>' : \n defloc = loc [ loclang ] \n if not currloc : \n currloc = defloc \n if not currloc : \n result . append ( SchemaValidationError ( \n u'<STR_LIT>' ) ) \n return \n location_file = self . _read_location_file ( currloc , errlist = result ) \n if not location_file : \n result . append ( SchemaValidationError ( u'<STR_LIT>' ) ) \n else : \n jsonsch = json . loads ( location_file ) \n validictory . validate ( tdict , jsonsch ) \n class HpPropertiesRegistry ( RisObject ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , d ) : \n super ( HpPropertiesRegistry , self ) . __init__ ( d ) \n def validate_attribute_values ( self , tdict ) : \n \"\"\"<STR_LIT>\"\"\" \n result = list ( ) \n for tkey in tdict : \n try : \n if self [ tkey ] and hasattr ( self [ tkey ] , \"<STR_LIT:type>\" ) : \n temp = self . validate_attribute ( self [ tkey ] , tdict [ tkey ] , tkey ) \n for err in temp : \n if isinstance ( err , RegistryValidationError ) : \n if err . reg : \n err . sel = tkey \n result . extend ( temp ) \n except Exception : \n pass \n return result \n def validate_att_val_bios ( self , tdict ) : \n \"\"\"<STR_LIT>\"\"\" \n result = list ( ) \n for tkey in tdict : \n for item in self . Attributes : \n try : \n if item [ \"<STR_LIT:Name>\" ] == tkey and hasattr ( item , \"<STR_LIT>\" ) : \n temp = self . validate_attribute ( item , tdict [ tkey ] , tkey ) \n for err in temp : \n if isinstance ( err , RegistryValidationError ) : \n if err . reg : \n err . sel = tkey \n result . extend ( temp ) \n break \n except Exception : \n pass \n return result \n def get_validator ( self , attrname , newargs = None , oneof = None ) : \n \"\"\"<STR_LIT>\"\"\" \n if oneof : \n self = oneof \n if newargs : \n for arg in newargs : \n try : \n self = self [ '<STR_LIT>' ] \n except Exception : \n pass \n if not hasattr ( self , arg ) : \n return None \n elif not arg == newargs [ - <NUM_LIT:1> ] : \n self = self [ arg ] \n if not hasattr ( self , attrname ) : \n return None \n validator = None \n if EnumValidator . is_type ( self [ attrname ] ) : \n validator = EnumValidator . parse ( self [ attrname ] ) \n elif StringValidator . is_type ( self [ attrname ] ) : \n validator = StringValidator . parse ( self [ attrname ] ) \n elif ObjectValidator . is_type ( self [ attrname ] ) : \n validator = ObjectValidator . parse ( self [ attrname ] ) \n elif IntegerValidator . is_type ( self [ attrname ] ) : \n validator = IntegerValidator . parse ( self [ attrname ] ) \n elif BoolValidator . is_type ( self [ attrname ] ) : \n validator = BoolValidator . parse ( self [ attrname ] ) \n elif PasswordValidator . is_type ( self [ attrname ] ) : \n validator = PasswordValidator . parse ( self [ attrname ] ) \n elif u'<STR_LIT>' in self [ attrname ] . keys ( ) : \n for item in self [ attrname ] [ '<STR_LIT>' ] : \n validator = self . get_validator ( attrname , newargs , HpPropertiesRegistry ( { attrname : item } ) ) \n if validator : \n break \n return validator \n def get_validator_bios ( self , attrname ) : \n \"\"\"<STR_LIT>\"\"\" \n for item in self . Attributes : \n if item [ \"<STR_LIT:Name>\" ] == attrname : \n validator = None \n if EnumValidator . is_type ( item ) : \n validator = EnumValidator . parse ( item ) \n elif StringValidator . is_type ( item ) : \n validator = StringValidator . parse ( item ) \n elif IntegerValidator . is_type ( item ) : \n validator = IntegerValidator . parse ( item ) \n elif BoolValidator . is_type ( item ) : \n validator = BoolValidator . parse ( item ) \n elif ObjectValidator . is_type ( item ) : \n validator = ObjectValidator . parse ( item ) \n elif PasswordValidator . is_type ( item ) : \n validator = PasswordValidator . parse ( item ) \n return validator \n return None \n def validate_attribute ( self , attrentry , attrval , name ) : \n \"\"\"<STR_LIT>\"\"\" \n result = list ( ) \n validator = None \n if EnumValidator . is_type ( attrentry ) : \n validator = EnumValidator . parse ( attrentry ) \n elif StringValidator . is_type ( attrentry ) : \n validator = StringValidator . parse ( attrentry ) \n elif IntegerValidator . is_type ( attrentry ) : \n validator = IntegerValidator . parse ( attrentry ) \n elif BoolValidator . is_type ( attrentry ) : \n validator = BoolValidator . parse ( attrentry ) \n elif ObjectValidator . is_type ( attrentry ) : \n validator = ObjectValidator . parse ( attrentry ) \n elif PasswordValidator . is_type ( attrentry ) : \n validator = PasswordValidator . parse ( attrentry ) \n else : \n raise UnknownValidatorError ( attrentry ) \n if validator : \n result . extend ( validator . validate ( attrval , name ) ) \n return result \n class BaseValidator ( RisObject ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , d ) : \n super ( BaseValidator , self ) . __init__ ( d ) \n def validate ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n raise RuntimeError ( u'<STR_LIT>' '<STR_LIT:class>' ) \n class EnumValidator ( BaseValidator ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , d ) : \n super ( EnumValidator , self ) . __init__ ( d ) \n @ staticmethod \n def is_type ( attrentry ) : \n \"\"\"<STR_LIT>\"\"\" \n if u'<STR_LIT:type>' in attrentry : \n if isinstance ( attrentry [ u'<STR_LIT:type>' ] , list ) : \n for item in attrentry [ u'<STR_LIT:type>' ] : \n if item . lower ( ) == u'<STR_LIT>' : \n return True \n elif u'<STR_LIT>' in attrentry and item . lower ( ) == u'<STR_LIT:string>' : \n return True \n elif u'<STR_LIT>' in attrentry and attrentry [ u'<STR_LIT:type>' ] == \"<STR_LIT>\" : \n for key , value in attrentry [ u'<STR_LIT>' ] . iteritems ( ) : \n if key . lower ( ) == \"<STR_LIT:type>\" and value . lower ( ) == u'<STR_LIT:string>' : \n return True \n else : \n if attrentry [ u'<STR_LIT:type>' ] . lower ( ) == u'<STR_LIT>' : \n return True \n elif u'<STR_LIT>' in attrentry and attrentry [ u'<STR_LIT:type>' ] . lower ( ) == u'<STR_LIT:string>' : \n return True \n elif u'<STR_LIT>' in attrentry : \n if attrentry [ u'<STR_LIT>' ] . lower ( ) == u'<STR_LIT>' : \n return True \n return False \n def validate ( self , newval , name ) : \n \"\"\"<STR_LIT>\"\"\" \n result = list ( ) \n try : \n for possibleval in self . enum : \n if possibleval . lower ( ) == newval . lower ( ) : \n return result \n except Exception : \n for possibleval in self . Value : \n if possibleval . ValueName . lower ( ) == str ( newval ) . lower ( ) : \n return result \n result . append ( RegistryValidationError ( u\"<STR_LIT>\" \n \"<STR_LIT>\" % ( newval , name ) , \n regentry = self ) ) \n return result \n def print_help ( self , name , out = sys . stdout ) : \n \"\"\"<STR_LIT>\"\"\" \n wrapper = textwrap . TextWrapper ( ) \n wrapper . initial_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> \n wrapper . subsequent_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT:%s>' % name ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT:description>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT:type>' in self and isinstance ( self [ u'<STR_LIT:type>' ] , list ) : \n out . write ( u'<STR_LIT>' ) \n for item in self [ u'<STR_LIT:type>' ] : \n out . write ( '<STR_LIT>' % wrapper . fill ( '<STR_LIT:%s>' % item ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT:type>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n out . write ( u'<STR_LIT>' ) \n try : \n for possibleval in self . enum : \n out . write ( '<STR_LIT>' % possibleval ) \n except Exception : \n for possibleval in self . Value : \n out . write ( '<STR_LIT>' % possibleval ) \n out . write ( '<STR_LIT:\\n>' ) \n class BoolValidator ( BaseValidator ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , d ) : \n super ( BoolValidator , self ) . __init__ ( d ) \n @ staticmethod \n def is_type ( attrentry ) : \n \"\"\"<STR_LIT>\"\"\" \n if u'<STR_LIT:type>' in attrentry : \n if isinstance ( attrentry [ u'<STR_LIT:type>' ] , list ) : \n for item in attrentry [ u'<STR_LIT:type>' ] : \n if item . lower ( ) == u'<STR_LIT>' : \n return True \n elif attrentry [ u'<STR_LIT:type>' ] == \"<STR_LIT>\" : \n for key , value in attrentry [ u'<STR_LIT>' ] . iteritems ( ) : \n if key . lower ( ) == \"<STR_LIT:type>\" and value . lower ( ) == u'<STR_LIT>' : \n return True \n else : \n if attrentry [ u'<STR_LIT:type>' ] . lower ( ) == u'<STR_LIT>' : \n return True \n elif u'<STR_LIT>' in attrentry : \n if attrentry [ u'<STR_LIT>' ] . lower ( ) == u'<STR_LIT>' : \n return True \n return False \n def validate ( self , newval , name ) : \n \"\"\"<STR_LIT>\"\"\" \n result = list ( ) \n if newval is False or newval is True : \n return result \n result . append ( \n RegistryValidationError ( \n u\"<STR_LIT>\" % ( newval , name ) , \n regentry = self \n ) \n ) \n return result \n def print_help ( self , name , out = sys . stdout ) : \n \"\"\"<STR_LIT>\"\"\" \n wrapper = textwrap . TextWrapper ( ) \n wrapper . initial_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> \n wrapper . subsequent_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT:%s>' % name ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT:description>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT:type>' in self and isinstance ( self [ u'<STR_LIT:type>' ] , list ) : \n out . write ( u'<STR_LIT>' ) \n for item in self [ u'<STR_LIT:type>' ] : \n out . write ( '<STR_LIT>' % wrapper . fill ( '<STR_LIT:%s>' % item ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT:type>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT>' ) \n out . write ( '<STR_LIT:\\n>' ) \n class StringValidator ( BaseValidator ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , d ) : \n super ( StringValidator , self ) . __init__ ( d ) \n @ staticmethod \n def is_type ( attrentry ) : \n \"\"\"<STR_LIT>\"\"\" \n if u'<STR_LIT:type>' in attrentry : \n if isinstance ( attrentry [ u'<STR_LIT:type>' ] , list ) : \n for item in attrentry [ u'<STR_LIT:type>' ] : \n if item . lower ( ) == u'<STR_LIT:string>' : \n return True \n elif attrentry [ u'<STR_LIT:type>' ] == \"<STR_LIT>\" : \n for key , value in attrentry [ u'<STR_LIT>' ] . iteritems ( ) : \n if key . lower ( ) == \"<STR_LIT:type>\" and u'<STR_LIT:string>' in value : \n return True \n else : \n if attrentry [ u'<STR_LIT:type>' ] . lower ( ) == u'<STR_LIT:string>' : \n return True \n elif u'<STR_LIT>' in attrentry : \n if attrentry [ u'<STR_LIT>' ] . lower ( ) == u'<STR_LIT:string>' : \n return True \n return False \n def validate ( self , newval , name ) : \n \"\"\"<STR_LIT>\"\"\" \n result = list ( ) \n if u'<STR_LIT>' in self : \n if len ( newval ) < int ( self [ u'<STR_LIT>' ] ) : \n result . append ( RegistryValidationError ( \n u\"<STR_LIT>\" % \n ( self . Name , int ( self [ u'<STR_LIT>' ] ) ) , regentry = self ) ) \n if u'<STR_LIT>' in self : \n if len ( newval ) > int ( self [ u'<STR_LIT>' ] ) : \n result . append ( RegistryValidationError ( \n u\"<STR_LIT>\" % \n ( self . Name , int ( self [ u'<STR_LIT>' ] ) ) , regentry = self ) ) \n if u'<STR_LIT>' in self : \n if self [ u'<STR_LIT>' ] : \n pat = re . compile ( self [ u'<STR_LIT>' ] ) \n if newval and not pat . match ( newval ) : \n result . append ( RegistryValidationError ( \n u\"<STR_LIT>\" \n \"<STR_LIT>\" % ( self ) , regentry = self ) ) \n return result \n def print_help ( self , name , out = sys . stdout ) : \n \"\"\"<STR_LIT>\"\"\" \n wrapper = textwrap . TextWrapper ( ) \n wrapper . initial_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> \n wrapper . subsequent_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT:%s>' % name ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT:description>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT:type>' in self and isinstance ( self [ u'<STR_LIT:type>' ] , list ) : \n out . write ( u'<STR_LIT>' ) \n for item in self [ u'<STR_LIT:type>' ] : \n out . write ( '<STR_LIT>' % wrapper . fill ( '<STR_LIT:%s>' % item ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT:type>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n class IntegerValidator ( BaseValidator ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , d ) : \n super ( IntegerValidator , self ) . __init__ ( d ) \n @ staticmethod \n def is_type ( attrentry ) : \n \"\"\"<STR_LIT>\"\"\" \n if u'<STR_LIT:type>' in attrentry : \n if isinstance ( attrentry [ u'<STR_LIT:type>' ] , list ) : \n for item in attrentry [ u'<STR_LIT:type>' ] : \n if item . lower ( ) == u'<STR_LIT>' or item . lower ( ) == u'<STR_LIT>' : \n return True \n elif attrentry [ u'<STR_LIT:type>' ] == \"<STR_LIT>\" : \n for key , value in attrentry [ u'<STR_LIT>' ] . iteritems ( ) : \n if key . lower ( ) == \"<STR_LIT:type>\" : \n if value . lower ( ) == u'<STR_LIT>' or value . lower ( ) == u'<STR_LIT>' : \n return True \n else : \n if attrentry [ u'<STR_LIT:type>' ] . lower ( ) == u'<STR_LIT>' or attrentry [ u'<STR_LIT:type>' ] . lower ( ) . lower ( ) == u'<STR_LIT>' : \n return True \n elif u'<STR_LIT>' in attrentry : \n if attrentry [ u'<STR_LIT>' ] . lower ( ) == u'<STR_LIT>' : \n return True \n return False \n def validate ( self , newval , name ) : \n \"\"\"<STR_LIT>\"\"\" \n result = list ( ) \n intval = int ( newval ) \n pat = re . compile ( r'<STR_LIT>' ) \n if newval and not pat . match ( intval ) : \n result . append ( \n RegistryValidationError ( \n u\"<STR_LIT>\" % ( self ) , \n regentry = self \n ) \n ) \n return result \n if u'<STR_LIT>' in self : \n if intval < int ( self [ u'<STR_LIT>' ] ) : \n result . append ( RegistryValidationError ( u\"<STR_LIT>\" \"<STR_LIT>\" % ( self . Name , int ( self [ u'<STR_LIT>' ] ) ) , regentry = self ) ) \n if u'<STR_LIT>' in self : \n if intval > int ( self [ u'<STR_LIT>' ] ) : \n result . append ( RegistryValidationError ( u\"<STR_LIT>\" \"<STR_LIT>\" % ( self . Name , int ( self [ u'<STR_LIT>' ] ) ) , regentry = self ) ) \n return result \n def print_help ( self , name , out = sys . stdout ) : \n \"\"\"<STR_LIT>\"\"\" \n wrapper = textwrap . TextWrapper ( ) \n wrapper . initial_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> \n wrapper . subsequent_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT:%s>' % name ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT:description>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT:type>' in self and isinstance ( self [ u'<STR_LIT:type>' ] , list ) : \n out . write ( u'<STR_LIT>' ) \n for item in self [ u'<STR_LIT:type>' ] : \n out . write ( '<STR_LIT>' % wrapper . fill ( '<STR_LIT:%s>' % item ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT:type>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n class ObjectValidator ( BaseValidator ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , d ) : \n super ( ObjectValidator , self ) . __init__ ( d ) \n @ staticmethod \n def is_type ( attrentry ) : \n \"\"\"<STR_LIT>\"\"\" \n if u'<STR_LIT:type>' in attrentry : \n if isinstance ( attrentry [ u'<STR_LIT:type>' ] , list ) : \n for item in attrentry [ u'<STR_LIT:type>' ] : \n if item . lower ( ) == u'<STR_LIT:object>' : \n return True \n elif attrentry [ u'<STR_LIT:type>' ] == \"<STR_LIT>\" : \n for key , value in attrentry [ u'<STR_LIT>' ] . iteritems ( ) : \n if key . lower ( ) == \"<STR_LIT:type>\" and value . lower ( ) == u'<STR_LIT:object>' : \n return True \n elif key . lower ( ) == \"<STR_LIT>\" : \n try : \n if value [ <NUM_LIT:0> ] [ u'<STR_LIT:type>' ] == u'<STR_LIT:object>' : \n return True \n except Exception : \n continue \n else : \n if attrentry [ u'<STR_LIT:type>' ] . lower ( ) == u'<STR_LIT:object>' : \n return True \n elif u'<STR_LIT>' in attrentry : \n if attrentry [ u'<STR_LIT>' ] . lower ( ) == u'<STR_LIT:object>' : \n return True \n return False \n def validate ( self , newval , name ) : \n \"\"\"<STR_LIT>\"\"\" \n result = list ( ) \n return result \n def print_help ( self , name , out = sys . stdout ) : \n \"\"\"<STR_LIT>\"\"\" \n wrapper = textwrap . TextWrapper ( ) \n wrapper . initial_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> \n wrapper . subsequent_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT:%s>' % name ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT:description>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT:type>' in self and isinstance ( self [ u'<STR_LIT:type>' ] , list ) : \n out . write ( u'<STR_LIT>' ) \n for item in self [ u'<STR_LIT:type>' ] : \n out . write ( '<STR_LIT>' % wrapper . fill ( '<STR_LIT:%s>' % item ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT:type>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n class PasswordValidator ( BaseValidator ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , d ) : \n super ( PasswordValidator , self ) . __init__ ( d ) \n @ staticmethod \n def is_type ( attrentry ) : \n \"\"\"<STR_LIT>\"\"\" \n if u'<STR_LIT:type>' in attrentry : \n if isinstance ( attrentry [ u'<STR_LIT:type>' ] , list ) : \n for item in attrentry [ u'<STR_LIT:type>' ] : \n if item . lower ( ) == u'<STR_LIT:password>' : \n return True \n elif attrentry [ u'<STR_LIT:type>' ] == \"<STR_LIT>\" : \n for key , value in attrentry [ u'<STR_LIT>' ] . iteritems ( ) : \n if key . lower ( ) == \"<STR_LIT:type>\" and value . lower ( ) == u'<STR_LIT:password>' : \n return True \n else : \n if attrentry [ u'<STR_LIT:type>' ] . lower ( ) == u'<STR_LIT:password>' : \n return True \n elif u'<STR_LIT>' in attrentry : \n if attrentry [ u'<STR_LIT>' ] . lower ( ) == u'<STR_LIT:password>' : \n return True \n return False \n def validate ( self , newval , name ) : \n \"\"\"<STR_LIT>\"\"\" \n result = list ( ) \n if newval is None : \n return result \n if u'<STR_LIT>' in self : \n if len ( newval ) < int ( self [ u'<STR_LIT>' ] ) : \n result . append ( RegistryValidationError ( u\"<STR_LIT>\" \"<STR_LIT>\" % ( self . Name , int ( self [ u'<STR_LIT>' ] ) ) , regentry = self ) ) \n if u'<STR_LIT>' in self : \n if len ( newval ) > int ( self [ u'<STR_LIT>' ] ) : \n result . append ( RegistryValidationError ( u\"<STR_LIT>\" \"<STR_LIT>\" % ( self . Name , int ( self [ u'<STR_LIT>' ] ) ) , regentry = self ) ) \n if u'<STR_LIT>' in self : \n if self [ u'<STR_LIT>' ] : \n pat = re . compile ( self [ u'<STR_LIT>' ] ) \n if newval and not pat . match ( newval ) : \n result . append ( RegistryValidationError ( u\"<STR_LIT>\" \"<STR_LIT>\" \"<STR_LIT>\" % ( self ) , regentry = self ) ) \n return result \n def print_help ( self , name , out = sys . stdout ) : \n \"\"\"<STR_LIT>\"\"\" \n wrapper = textwrap . TextWrapper ( ) \n wrapper . initial_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> \n wrapper . subsequent_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT:%s>' % name ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT:description>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT:type>' in self and isinstance ( self [ u'<STR_LIT:type>' ] , list ) : \n out . write ( u'<STR_LIT>' ) \n for item in self [ u'<STR_LIT:type>' ] : \n out . write ( '<STR_LIT>' % wrapper . fill ( '<STR_LIT:%s>' % item ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT:type>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n if u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n elif u'<STR_LIT>' in self : \n out . write ( u'<STR_LIT>' ) \n out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) \n out . write ( '<STR_LIT:\\n>' ) \n", "gt": "LOGGER"}
{"input": "\n from . constants import MILLI_MICROS , SECOND_MICROS , MINUTE_MICROS \n import calendar \n from datetime import datetime \n from dateutil import parser \n from dateutil . tz import tzlocal \n from . error import TimeConstructionError \n from . sanedelta import SaneDelta \n import pytz \n <mask0> = ( \n ( ( '<STR_LIT:m>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) , MINUTE_MICROS ) , \n ( ( '<STR_LIT:s>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) , SECOND_MICROS ) , \n ( ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) , MILLI_MICROS ) , \n ( ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) , <NUM_LIT:1> ) ) \n MICROS_TRANSLATION_HASH = dict ( ( alt , v ) for k , v in MICROS_TRANSLATIONS for alt in k ) \n class SaneTime ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , * args , ** kwargs ) : \n \"\"\"<STR_LIT>\"\"\" \n super ( time , self ) . __init__ ( ) \n uss = set ( ) \n tzs = set ( ) \n naive_dt = None \n avoid_localize = False \n for k , v in kwargs . iteritems ( ) : \n if k in ( '<STR_LIT>' , '<STR_LIT>' ) : \n tzs . add ( SaneTime . to_timezone ( v ) ) \n elif k in MICROS_TRANSLATION_HASH : \n uss . add ( MICROS_TRANSLATION_HASH [ k ] * v ) \n else : \n raise TimeConstructionError ( \"<STR_LIT>\" % ( k , v ) ) \n args = list ( args ) \n if len ( args ) > <NUM_LIT:2> and len ( args ) <= <NUM_LIT:8> : \n args = [ datetime ( * args ) ] \n if len ( args ) == <NUM_LIT:2> : \n tzs . add ( SaneTime . to_timezone ( args . pop ( ) ) ) \n if len ( args ) == <NUM_LIT:1> : \n arg = args . pop ( ) \n if hasattr ( arg , '<STR_LIT>' ) : \n uss . add ( int ( arg ) ) \n if hasattr ( arg , '<STR_LIT>' ) : tzs . add ( arg . tz ) \n elif isinstance ( arg , basestring ) : \n parts = arg . strip ( ) . split ( '<STR_LIT:U+0020>' ) \n if len ( parts ) > <NUM_LIT:1> and parts [ - <NUM_LIT:1> ] . startswith ( '<STR_LIT:+>' ) : \n try : \n tzs . add ( SaneTime . to_timezone ( parts [ - <NUM_LIT:1> ] [ <NUM_LIT:1> : ] ) ) \n arg = '<STR_LIT:U+0020>' . join ( parts [ : - <NUM_LIT:1> ] ) \n except : pass \n utc = arg . endswith ( '<STR_LIT>' ) or arg . endswith ( '<STR_LIT>' ) \n arg = parser . parse ( arg ) \n if arg . tzinfo : \n if utc : \n tzs . add ( pytz . utc ) \n arg = arg . replace ( tzinfo = None ) \n elif isinstance ( arg . tzinfo , tzlocal ) : \n arg = arg . replace ( tzinfo = None ) \n else : \n avoid_localize = True \n arg = arg . astimezone ( pytz . utc ) . replace ( tzinfo = None ) \n if type ( arg ) == datetime : \n naive_dt = arg \n if naive_dt . tzinfo : \n tzs . add ( SaneTime . to_timezone ( str ( naive_dt . tzinfo ) ) ) \n naive_dt = naive_dt . replace ( tzinfo = None ) \n if len ( tzs ) > <NUM_LIT:1> : \n raise TimeConstructionError ( \"<STR_LIT>\" % ( tzs ) ) \n self . tz = len ( tzs ) and tzs . pop ( ) or pytz . utc \n if naive_dt : \n if avoid_localize : \n uss . add ( SaneTime . utc_datetime_to_us ( naive_dt ) ) \n else : \n uss . add ( SaneTime . utc_datetime_to_us ( self . tz . localize ( naive_dt ) . astimezone ( pytz . utc ) ) ) \n if len ( uss ) == <NUM_LIT:0> : \n uss . add ( SaneTime . utc_datetime_to_us ( datetime . utcnow ( ) ) ) \n if len ( uss ) > <NUM_LIT:1> : \n raise TimeConstructionError ( \"<STR_LIT>\" % ( uss ) ) \n self . us = uss . pop ( ) \n if len ( args ) > <NUM_LIT:0> : \n raise TimeConstructionError ( \"<STR_LIT>\" ) \n @ property \n def ms ( self ) : return self . us / MILLI_MICROS \n epoch_milliseconds = epoch_millis = milliseconds = millis = ms \n @ property \n def s ( self ) : return self . us / SECOND_MICROS \n epoch_seconds = epoch_secs = seconds = secs = s \n @ property \n def m ( self ) : return self . us / MINUTE_MICROS \n epoch_minutes = epoch_mins = minutes = mins = m \n @ property \n def micros ( self ) : return self . us \n epoch_microseconds = epoch_micros = microseconds = micros \n @ property \n def tz_name ( self ) : return self . tz . zone \n @ property \n def tz_abbr ( self ) : return self . tz . _tzname \n def set_tz ( self , tz ) : \n self . tz = self . __class__ . to_timezone ( tz ) ; return self \n def with_tz ( self , tz ) : \n return self . __class__ ( self . us , tz ) \n @ property \n def _tuple ( self ) : return ( self . us , self . tz ) \n def strftime ( self , * args , ** kwargs ) : return self . datetime . strftime ( * args , ** kwargs ) \n def __cmp__ ( self , other ) : \n if not hasattr ( other , '<STR_LIT>' ) : other = SaneTime ( other ) \n return cmp ( self . us , int ( other ) ) \n def __hash__ ( self ) : return self . us . __hash__ ( ) \n def __add__ ( self , operand ) : \n if not hasattr ( operand , '<STR_LIT>' ) : operand = SaneTime ( operand ) \n return self . __class__ ( self . us + int ( operand ) , tz = self . tz ) \n def __sub__ ( self , operand ) : \n if not hasattr ( operand , '<STR_LIT>' ) : operand = SaneTime ( operand ) \n if isinstance ( operand , SaneTime ) : return SaneDelta ( self . us - int ( operand ) ) \n return self . __add__ ( - int ( operand ) ) \n def __mul__ ( self , operand ) : \n return self . us * int ( operand ) \n def __div__ ( self , operand ) : \n return self . us / int ( operand ) \n def __int__ ( self ) : return int ( self . us ) \n def __long__ ( self ) : return long ( self . us ) \n def __repr__ ( self ) : return u\"<STR_LIT>\" % ( self . us , repr ( self . tz ) ) \n def __str__ ( self ) : return unicode ( self ) . encode ( '<STR_LIT:utf-8>' ) \n def __unicode__ ( self ) : \n dt = self . datetime \n micros = u\"<STR_LIT>\" % dt . microsecond if dt . microsecond else '<STR_LIT>' \n time = u\"<STR_LIT>\" % ( dt . hour , dt . minute , dt . second , micros ) if dt . microsecond or dt . second or dt . minute or dt . hour else '<STR_LIT>' \n return u\"<STR_LIT>\" % ( dt . year , dt . month , dt . day , time , dt . tzinfo . zone ) \n def clone ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . __class__ ( self . us , self . tz ) \n @ property \n def ny_str ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . ny_ndt . strftime ( '<STR_LIT>' ) \n @ property \n def utc_datetime ( self ) : return SaneTime . us_to_utc_datetime ( self . us ) \n utc_dt = utc_datetime \n @ property \n def utc_naive_datetime ( self ) : return self . utc_datetime . replace ( tzinfo = None ) \n utc_ndt = utc_naive_datetime \n def to_timezoned_datetime ( self , tz ) : return self . utc_datetime . astimezone ( SaneTime . to_timezone ( tz ) ) \n def to_timezoned_naive_datetime ( self , tz ) : return self . to_timezoned_datetime ( tz ) . replace ( tzinfo = None ) \n @ property \n def datetime ( self ) : return self . to_timezoned_datetime ( self . tz ) \n dt = datetime \n @ property \n def naive_datetime ( self ) : return self . to_timezoned_naive_datetime ( self . tz ) \n ndt = naive_datetime \n @ property \n def ny_datetime ( self ) : return self . to_timezoned_datetime ( '<STR_LIT>' ) \n ny_dt = ny_datetime \n @ property \n def ny_naive_datetime ( self ) : return self . to_timezoned_naive_datetime ( '<STR_LIT>' ) \n ny_ndt = ny_naive_datetime \n @ property \n def year ( self ) : return self . dt . year \n @ property \n def month ( self ) : return self . dt . month \n @ property \n def day ( self ) : return self . dt . day \n @ property \n def hour ( self ) : return self . dt . hour \n @ property \n def minute ( self ) : return self . dt . minute \n @ property \n def second ( self ) : return self . dt . second \n @ property \n def microsecond ( self ) : return self . dt . microsecond \n @ classmethod \n def utc_datetime_to_us ( kls , dt ) : \n return calendar . timegm ( dt . timetuple ( ) ) * <NUM_LIT:1000> ** <NUM_LIT:2> + dt . microsecond \n @ classmethod \n def us_to_utc_datetime ( kls , us ) : \n return pytz . utc . localize ( datetime . utcfromtimestamp ( us / <NUM_LIT:10> ** <NUM_LIT:6> ) ) . replace ( microsecond = us % <NUM_LIT:10> ** <NUM_LIT:6> ) \n @ classmethod \n def to_timezone ( kls , tz ) : \n if not isinstance ( tz , basestring ) : return tz \n return pytz . timezone ( tz ) \n def ntime ( * args , ** kwargs ) : \n if args : \n if args [ <NUM_LIT:0> ] is None : return None \n elif kwargs : \n if None in [ v for k , v in kwargs . iteritems ( ) if k != '<STR_LIT>' ] : return None \n return SaneTime ( * args , ** kwargs ) \n time = sanetime = SaneTime \n nsanetime = ntime \n", "gt": "MICROS_TRANSLATIONS"}
{"input": "\n from tastypie . authorization import Authorization \n from openpds . authentication import OAuth2Authentication \n from openpds . core . models import Profile , AuditEntry \n import settings \n import pdb \n import traceback \n class PDSAuthorization ( Authorization ) : \n <mask0> = True \n scope = \"<STR_LIT>\" \n requester_uuid = \"<STR_LIT>\" \n def requester ( self ) : \n return self . requester_uuid \n def trustWrapper ( self , datastore_owner ) : \n print \"<STR_LIT>\" \n def is_authorized ( self , request , object = None ) : \n authenticator = OAuth2Authentication ( self . scope ) \n if \"<STR_LIT>\" in request . REQUEST : \n authorized = True \n token = request . REQUEST [ \"<STR_LIT>\" ] if \"<STR_LIT>\" in request . REQUEST else request . META [ \"<STR_LIT>\" ] \n datastore_owner_uuid = request . REQUEST [ \"<STR_LIT>\" ] \n datastore_owner , ds_owner_created = Profile . objects . get_or_create ( uuid = datastore_owner_uuid ) \n self . requester_uuid = authenticator . get_userinfo_from_token ( token , self . scope ) \n if self . requester_uuid is False or self . requester_uuid is None or len ( self . requester_uuid ) == <NUM_LIT:0> : \n self . requester_uuid = \"<STR_LIT>\" \n authorized = False \n self . trustWrapper ( datastore_owner ) \n try : \n if ( self . audit_enabled ) : \n audit_entry = AuditEntry ( token = token ) \n audit_entry . method = request . method \n audit_entry . scope = self . scope \n audit_entry . purpose = request . REQUEST [ \"<STR_LIT>\" ] if \"<STR_LIT>\" in request . REQUEST else \"<STR_LIT>\" \n audit_entry . system_entity_toggle = request . REQUEST [ \"<STR_LIT>\" ] if \"<STR_LIT>\" in request . REQUEST else False \n audit_entry . datastore_owner = datastore_owner \n audit_entry . requester , created = Profile . objects . get_or_create ( uuid = self . requester_uuid ) \n audit_entry . script = request . path \n audit_entry . save ( ) \n except Exception as e : \n print e \n authorized = False \n return authorized \n return False \n def __init__ ( self , scope , audit_enabled = True ) : \n self . scope = scope \n self . audit_enabled = audit_enabled \n", "gt": "audit_enabled"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n from django import template \n <mask0> = template . Library ( ) \n class VerbatimNode ( template . Node ) : \n def __init__ ( self , text ) : \n self . text = text \n def render ( self , context ) : \n return self . text \n @ register . tag \n def verbatim ( parser , token ) : \n text = [ ] \n while <NUM_LIT:1> : \n token = parser . tokens . pop ( <NUM_LIT:0> ) \n if token . contents == '<STR_LIT>' : \n break \n if token . token_type == template . TOKEN_VAR : \n text . append ( '<STR_LIT>' ) \n elif token . token_type == template . TOKEN_BLOCK : \n text . append ( '<STR_LIT>' ) \n text . append ( token . contents ) \n if token . token_type == template . TOKEN_VAR : \n text . append ( '<STR_LIT>' ) \n elif token . token_type == template . TOKEN_BLOCK : \n text . append ( '<STR_LIT>' ) \n return VerbatimNode ( '<STR_LIT>' . join ( text ) ) \n", "gt": "register"}
{"input": "\n from werkzeug . utils import cached_property \n from base import db , Base \n from cluster import Cluster \n class Proxy ( Base ) : \n <mask0> = '<STR_LIT>' \n host = db . Column ( db . String ( <NUM_LIT:255> ) , nullable = False ) \n port = db . Column ( db . Integer , nullable = False ) \n eru_container_id = db . Column ( db . String ( <NUM_LIT:64> ) , index = True ) \n cluster_id = db . Column ( db . ForeignKey ( Cluster . id ) , index = True ) \n suppress_alert = db . Column ( db . Integer , nullable = False , default = <NUM_LIT:1> ) \n __table_args__ = ( db . Index ( '<STR_LIT:address>' , '<STR_LIT:host>' , '<STR_LIT:port>' , unique = True ) , ) \n @ cached_property \n def eru_deployed ( self ) : \n return self . eru_container_id is not None \n @ cached_property \n def eru_info ( self ) : \n import eru_utils \n if eru_utils . eru_client is None or not self . eru_deployed : \n return None \n return eru_utils . eru_client . get_container ( self . eru_container_id ) \n @ cached_property \n def cluster ( self ) : \n return Cluster . query . get ( self . cluster_id ) \n def get_by_host_port ( host , port ) : \n return db . session . query ( Proxy ) . filter ( \n Proxy . host == host , Proxy . port == port ) . first ( ) \n def del_by_host_port ( host , port ) : \n return db . session . query ( Proxy ) . filter ( \n Proxy . host == host , Proxy . port == port ) . delete ( ) \n def get_or_create ( host , port , cluster_id = None ) : \n p = db . session . query ( Proxy ) . filter ( \n Proxy . host == host , Proxy . port == port ) . first ( ) \n if p is None : \n p = Proxy ( host = host , port = port , cluster_id = cluster_id ) \n db . session . add ( p ) \n db . session . flush ( ) \n return p \n def create_eru_instance ( host , port , cluster_id , eru_container_id ) : \n node = Proxy ( host = host , port = port , eru_container_id = eru_container_id , \n cluster_id = cluster_id ) \n db . session . add ( node ) \n db . session . flush ( ) \n return node \n def delete_eru_instance ( eru_container_id ) : \n db . session . query ( Proxy ) . filter ( \n Proxy . eru_container_id == eru_container_id ) . delete ( ) \n def get_eru_by_container_id ( eru_container_id ) : \n return db . session . query ( Proxy ) . filter ( \n Proxy . eru_container_id == eru_container_id ) . first ( ) \n def list_all ( ) : \n return db . session . query ( Proxy ) . all ( ) \n def list_eru_proxies ( offset , limit ) : \n return db . session . query ( Proxy ) . filter ( \n Proxy . eru_container_id != None ) . order_by ( \n Proxy . id . desc ( ) ) . offset ( offset ) . limit ( limit ) . all ( ) \n def list_ip ( ) : \n return db . session . query ( Proxy . host , Proxy . port ) . all ( ) \n", "gt": "__tablename__"}
{"input": "\n from ethereum import tester \n import hydrachain . native_contracts as nc \n from fungible_contract import IOU \n import ethereum . slogging as slogging \n <mask0> = slogging . get_logger ( '<STR_LIT>' ) \n def test_iou_template ( ) : \n \"\"\"<STR_LIT>\"\"\" \n nc . registry . register ( IOU ) \n state = tester . state ( ) \n logs = [ ] \n issuer_address = tester . a0 \n issuer_key = tester . k0 \n for evt_class in IOU . events : \n nc . listen_logs ( state , evt_class , callback = lambda e : logs . append ( e ) ) \n iou_address = nc . tester_create_native_contract_instance ( state , issuer_key , IOU ) \n iou_as_issuer = nc . tester_nac ( state , issuer_key , iou_address ) \n iou_as_issuer . init ( ) \n assert iou_as_issuer . balanceOf ( issuer_address ) == <NUM_LIT:0> \n amount_issued = <NUM_LIT> \n iou_as_issuer . issue_funds ( amount_issued , '<STR_LIT>' ) \n assert iou_as_issuer . balanceOf ( issuer_address ) == amount_issued \n iou_as_issuer . issue_funds ( amount_issued , '<STR_LIT>' ) \n assert iou_as_issuer . balanceOf ( issuer_address ) == <NUM_LIT:2> * amount_issued \n assert iou_as_issuer . get_issued_amount ( issuer_address ) == <NUM_LIT:2> * amount_issued \n print logs \n while logs and logs . pop ( ) : \n pass \n nc . registry . unregister ( IOU ) \n", "gt": "log"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import json \n import time \n import urllib2 \n import logging \n from view_controls . view import DrawingTool , Event \n from game_objects . item import Item \n from game_objects . state import TrackerState , TrackerStateEncoder \n from log_parser import LogParser \n from options import Options \n class IsaacTracker ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , logging_level = logging . INFO , read_timer = <NUM_LIT:1> ) : \n self . read_timer = read_timer \n self . file_prefix = \"<STR_LIT>\" \n self . log = logging . getLogger ( \"<STR_LIT>\" ) \n self . log . addHandler ( logging . FileHandler ( self . file_prefix + \"<STR_LIT>\" , mode = '<STR_LIT:w>' ) ) \n self . log . setLevel ( logging_level ) \n with open ( self . file_prefix + \"<STR_LIT>\" , \"<STR_LIT:r>\" ) as items_file : \n Item . items_info = json . load ( items_file ) \n with open ( self . file_prefix + '<STR_LIT>' , '<STR_LIT:r>' ) as f : \n self . tracker_version = f . read ( ) \n Options ( ) . load_options ( self . file_prefix + \"<STR_LIT>\" ) \n def __del__ ( self ) : \n Options ( ) . save_options ( self . file_prefix + \"<STR_LIT>\" ) \n def check_for_update ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n <mask0> = \"<STR_LIT>\" \n github_info_json = urllib2 . urlopen ( latest ) . read ( ) \n info = json . loads ( github_info_json ) \n latest_version = info [ \"<STR_LIT:name>\" ] \n title_text = \"<STR_LIT>\" + self . tracker_version \n if latest_version != self . tracker_version : \n title_text += \"<STR_LIT>\" \n return title_text \n except Exception as e : \n self . log . debug ( \"<STR_LIT>\" + e . message ) \n return \"<STR_LIT>\" \n def run ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n update_notifier = self . check_for_update ( ) \n framecount = <NUM_LIT:0> \n drawing_tool = DrawingTool ( self . file_prefix ) \n drawing_tool . set_window_title ( update_notifier ) \n parser = LogParser ( self . file_prefix , self . tracker_version ) \n opt = Options ( ) \n log = logging . getLogger ( \"<STR_LIT>\" ) \n event_result = None \n state = None \n read_from_server = opt . read_from_server \n write_to_server = opt . write_to_server \n state_version = - <NUM_LIT:1> \n twitch_username = None \n new_states_queue = [ ] \n screen_error_message = None \n while event_result != Event . DONE : \n event_result = drawing_tool . handle_events ( ) \n if opt . read_from_server != read_from_server or opt . twitch_name != twitch_username : \n twitch_username = opt . twitch_name \n read_from_server = opt . read_from_server \n new_states_queue = [ ] \n if read_from_server : \n state_version = - <NUM_LIT:1> \n state = None \n drawing_tool . set_window_title ( update_notifier , watching_player = twitch_username , updates_queued = len ( new_states_queue ) ) \n else : \n drawing_tool . set_window_title ( update_notifier ) \n if opt . write_to_server and opt . write_to_server != write_to_server : \n write_to_server = True \n drawing_tool . set_window_title ( update_notifier , uploading = True ) \n if not opt . write_to_server : \n write_to_server = False \n if opt . read_from_server : \n update_timer = <NUM_LIT:2> \n else : \n update_timer = self . read_timer \n if event_result == Event . OPTIONS_UPDATE : \n framecount = <NUM_LIT:0> \n screen_error_message = None \n if state is not None : \n state . modified = True \n if ( framecount % int ( Options ( ) . framerate_limit * update_timer ) == <NUM_LIT:0> ) : \n if opt . read_from_server : \n base_url = opt . trackerserver_url + \"<STR_LIT>\" + opt . twitch_name \n json_dict = None \n try : \n json_version = urllib2 . urlopen ( base_url + \"<STR_LIT>\" ) . read ( ) \n if int ( json_version ) > state_version : \n json_state = urllib2 . urlopen ( base_url ) . read ( ) \n json_dict = json . loads ( json_state ) \n new_state = TrackerState . from_json ( json_dict ) \n if new_state is None : \n raise Exception \n state_version = int ( json_version ) \n new_states_queue . append ( ( state_version , new_state ) ) \n drawing_tool . set_window_title ( update_notifier , watching_player = twitch_username , updates_queued = len ( new_states_queue ) , read_delay = opt . read_delay ) \n except Exception : \n state = None \n log . error ( \"<STR_LIT>\" ) \n import traceback \n log . error ( traceback . format_exc ( ) ) \n if json_dict is not None : \n their_version = \"<STR_LIT>\" \n if \"<STR_LIT>\" in json_dict : \n their_version = json_dict [ \"<STR_LIT>\" ] \n else : \n their_version = \"<STR_LIT>\" \n if their_version != self . tracker_version : \n screen_error_message = \"<STR_LIT>\" + their_version + \"<STR_LIT>\" + self . tracker_version \n else : \n force_draw = state and state . modified \n state = parser . parse ( ) \n if force_draw : \n state . modified = True \n if write_to_server and not opt . trackerserver_authkey : \n screen_error_message = \"<STR_LIT>\" \n if state is not None and write_to_server and state . modified and screen_error_message is None : \n opener = urllib2 . build_opener ( urllib2 . HTTPHandler ) \n put_url = opt . trackerserver_url + \"<STR_LIT>\" + opt . trackerserver_authkey \n json_string = json . dumps ( state , cls = TrackerStateEncoder , sort_keys = True ) \n request = urllib2 . Request ( put_url , \n data = json_string ) \n request . add_header ( '<STR_LIT:Content-Type>' , '<STR_LIT:application/json>' ) \n request . get_method = lambda : '<STR_LIT>' \n try : \n result = opener . open ( request ) \n result_json = json . loads ( result . read ( ) ) \n updated_user = result_json [ \"<STR_LIT>\" ] \n if updated_user is None : \n screen_error_message = \"<STR_LIT>\" \n else : \n screen_error_message = None \n except Exception as e : \n import traceback \n errmsg = traceback . format_exc ( ) \n log . error ( \"<STR_LIT>\" ) \n log . error ( errmsg ) \n screen_error_message = \"<STR_LIT>\" \n if len ( new_states_queue ) > <NUM_LIT:0> : \n ( state_timestamp , new_state ) = new_states_queue [ <NUM_LIT:0> ] \n current_timestamp = int ( time . time ( ) ) \n if current_timestamp - state_timestamp >= opt . read_delay or state is None : \n state = new_state \n new_states_queue . pop ( <NUM_LIT:0> ) \n drawing_tool . set_window_title ( update_notifier , watching_player = twitch_username , updates_queued = len ( new_states_queue ) , read_delay = opt . read_delay ) \n if state is None and screen_error_message is None : \n if read_from_server : \n screen_error_message = \"<STR_LIT>\" \n else : \n screen_error_message = \"<STR_LIT>\" \n if screen_error_message is not None : \n drawing_tool . write_error_message ( screen_error_message ) \n else : \n drawing_tool . draw_state ( state ) \n drawing_tool . tick ( ) \n framecount += <NUM_LIT:1> \n drawing_tool . save_window_position ( ) \n def main ( ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n rt = IsaacTracker ( ) \n rt . run ( ) \n except Exception : \n import traceback \n errmsg = traceback . format_exc ( ) \n print ( errmsg ) \n logging . getLogger ( \"<STR_LIT>\" ) . error ( errmsg ) \n if __name__ == \"<STR_LIT:__main__>\" : \n main ( ) \n", "gt": "latest"}
{"input": "\n from __future__ import division , print_function , unicode_literals \n from collections import OrderedDict \n from brainstorm . layers . base_layer import Layer \n from brainstorm . structure . buffer_structure import ( BufferStructure , \n StructureTemplate ) \n from brainstorm . structure . construction import ConstructionWrapper \n from brainstorm . utils import flatten_all_but_last \n def BatchNorm ( name = None , decay = <NUM_LIT> , epsilon = <NUM_LIT> ) : \n \"\"\"<STR_LIT>\"\"\" \n return ConstructionWrapper . create ( BatchNormLayerImpl , \n name = name , \n decay = decay , \n epsilon = epsilon ) \n class BatchNormLayerImpl ( Layer ) : \n <mask0> = { '<STR_LIT:default>' : StructureTemplate ( '<STR_LIT:T>' , '<STR_LIT:B>' , '<STR_LIT>' ) } \n expected_kwargs = { '<STR_LIT>' , '<STR_LIT>' } \n def setup ( self , kwargs , in_shapes ) : \n self . epsilon = kwargs . get ( '<STR_LIT>' , <NUM_LIT> ) \n self . decay = kwargs . get ( '<STR_LIT>' , <NUM_LIT> ) \n assert <NUM_LIT:0.0> <= self . decay <= <NUM_LIT:1.0> , \"<STR_LIT>\" \n outputs = OrderedDict ( ) \n outputs [ '<STR_LIT:default>' ] = in_shapes [ '<STR_LIT:default>' ] \n parameters = OrderedDict ( ) \n buf = BufferStructure ( self . in_shapes [ '<STR_LIT:default>' ] . feature_shape [ - <NUM_LIT:1> ] ) \n parameters [ '<STR_LIT>' ] = buf \n parameters [ '<STR_LIT>' ] = buf \n parameters [ '<STR_LIT>' ] = buf \n parameters [ '<STR_LIT>' ] = buf \n internals = OrderedDict ( ) \n internals [ '<STR_LIT>' ] = buf \n internals [ '<STR_LIT>' ] = self . in_shapes [ '<STR_LIT:default>' ] \n internals [ '<STR_LIT>' ] = self . in_shapes [ '<STR_LIT:default>' ] \n return outputs , parameters , internals \n def forward_pass ( self , buffers , training_pass = True ) : \n _h = self . handler \n sigma_b , centered , x_hat = buffers . internals \n gamma , beta , mu , sigma = buffers . parameters \n inputs = flatten_all_but_last ( buffers . inputs . default ) \n centered = flatten_all_but_last ( centered ) \n x_hat = flatten_all_but_last ( x_hat ) \n out = flatten_all_but_last ( buffers . outputs . default ) \n m = inputs . shape [ <NUM_LIT:0> ] \n if training_pass : \n mu_b = sigma_b \n _h . sum_t ( inputs , <NUM_LIT:0> , mu_b ) \n _h . mult_st ( - <NUM_LIT:1.0> / m , mu_b , mu_b ) \n _h . mult_st ( self . decay , mu , mu ) \n _h . mult_add_st ( <NUM_LIT:1.0> - self . decay , mu_b , mu ) \n mu = mu_b \n _h . add_mv ( inputs , mu . reshape ( ( <NUM_LIT:1> , mu . size ) ) , centered ) \n if training_pass : \n sigma2 = sigma_b \n centered2 = x_hat \n _h . mult_tt ( centered , centered , centered2 ) \n _h . sum_t ( centered2 , <NUM_LIT:0> , sigma2 ) \n _h . mult_st ( <NUM_LIT:1.0> / m , sigma2 , sigma2 ) \n _h . add_st ( self . epsilon , sigma2 , sigma2 ) \n _h . sqrt_t ( sigma2 , sigma_b ) \n _h . mult_st ( self . decay , sigma , sigma ) \n _h . mult_add_st ( <NUM_LIT:1.0> - self . decay , sigma_b , sigma ) \n sigma = sigma_b \n _h . divide_mv ( centered , sigma . reshape ( ( <NUM_LIT:1> , sigma . size ) ) , x_hat ) \n _h . mult_mv ( x_hat , gamma . reshape ( ( <NUM_LIT:1> , gamma . size ) ) , out ) \n _h . add_mv ( out , beta . reshape ( ( <NUM_LIT:1> , beta . size ) ) , out ) \n def backward_pass ( self , buffers ) : \n _h = self . handler \n sigma_b , centered , x_hat = buffers . internals \n gamma = buffers . parameters . gamma \n dgamma = buffers . gradients . gamma \n dbeta = buffers . gradients . beta \n x_hat = flatten_all_but_last ( x_hat ) \n outdeltas = flatten_all_but_last ( buffers . output_deltas . default ) \n indeltas = flatten_all_but_last ( buffers . input_deltas . default ) \n m = outdeltas . shape [ <NUM_LIT:0> ] \n big_tmp = _h . allocate ( x_hat . shape ) \n small_tmp = _h . allocate ( gamma . shape ) \n tmp = big_tmp \n dgamma_tmp = small_tmp \n _h . mult_tt ( outdeltas , x_hat , tmp ) \n _h . sum_t ( tmp , axis = <NUM_LIT:0> , out = dgamma_tmp ) \n _h . add_tt ( dgamma_tmp , dgamma , dgamma ) \n _h . mult_st ( <NUM_LIT:1> / m , dgamma_tmp , dgamma_tmp ) \n term1 = big_tmp \n _h . mult_mv ( x_hat , dgamma_tmp . reshape ( ( <NUM_LIT:1> , gamma . size ) ) , term1 ) \n dbeta_tmp = small_tmp \n _h . sum_t ( outdeltas , axis = <NUM_LIT:0> , out = dbeta_tmp ) \n _h . add_tt ( dbeta_tmp , dbeta , dbeta ) \n _h . mult_st ( <NUM_LIT:1> / m , dbeta_tmp , dbeta_tmp ) \n term2 = big_tmp \n term3 = big_tmp \n _h . subtract_tt ( outdeltas , term1 , term2 ) \n _h . subtract_mv ( term2 , dbeta_tmp . reshape ( ( <NUM_LIT:1> , dbeta . size ) ) , term3 ) \n coeff = small_tmp \n _h . divide_tt ( gamma , sigma_b , coeff ) \n term4 = big_tmp \n _h . mult_mv ( term3 , coeff . reshape ( ( <NUM_LIT:1> , coeff . size ) ) , term4 ) \n _h . add_tt ( term4 , indeltas , indeltas ) \n", "gt": "expected_inputs"}
{"input": "\n from __future__ import division , print_function , unicode_literals \n from collections import OrderedDict \n import numpy as np \n from brainstorm . describable import Describable \n class Scorer ( Describable ) : \n def __init__ ( self , out_name = '<STR_LIT>' , targets_name = '<STR_LIT>' , mask_name = '<STR_LIT>' , \n name = None ) : \n self . out_name = out_name \n self . targets_name = targets_name \n self . mask_name = mask_name \n self . __name__ = name if name is not None else self . __class__ . __name__ \n def __call__ ( self , true_labels , predicted , mask = None ) : \n pass \n @ staticmethod \n def aggregate ( errors ) : \n <mask0> = np . array ( errors ) \n assert errors . ndim == <NUM_LIT:2> and errors . shape [ <NUM_LIT:1> ] == <NUM_LIT:2> \n return np . sum ( errors [ : , <NUM_LIT:1> ] ) / np . sum ( errors [ : , <NUM_LIT:0> ] ) \n def gather_losses_and_scores ( net , scorers , scores , out_name = '<STR_LIT>' , \n targets_name = '<STR_LIT>' , mask_name = '<STR_LIT>' ) : \n ls = net . get_loss_values ( ) \n for name , loss in ls . items ( ) : \n scores [ name ] . append ( ( net . _buffer_manager . batch_size , loss ) ) \n for sc in scorers : \n name = sc . __name__ \n predicted = net . get ( sc . out_name or out_name or net . output_name ) \n true_labels = net . get_input ( sc . targets_name ) if sc . targets_name else net . get_input ( targets_name ) \n mask = net . get_input ( sc . mask_name ) if sc . mask_name else ( net . get_input ( mask_name ) if mask_name else None ) \n predicted = _flatten_all_but_last ( predicted ) \n true_labels = _flatten_all_but_last ( true_labels ) \n mask = _flatten_all_but_last ( mask ) \n weight = mask . sum ( ) if mask is not None else predicted . shape [ <NUM_LIT:0> ] \n scores [ name ] . append ( ( weight , sc ( true_labels , predicted , mask ) ) ) \n def aggregate_losses_and_scores ( scores , net , scorers ) : \n results = OrderedDict ( ) \n for name in net . get_loss_values ( ) : \n results [ name ] = _weighted_average ( scores [ name ] ) \n for sc in scorers : \n results [ sc . __name__ ] = sc . aggregate ( scores [ sc . __name__ ] ) \n return results \n class Accuracy ( Scorer ) : \n def __call__ ( self , true_labels , predicted , mask = None ) : \n if predicted . shape [ <NUM_LIT:1> ] > <NUM_LIT:1> : \n predicted = predicted . argmax ( <NUM_LIT:1> ) . reshape ( - <NUM_LIT:1> , <NUM_LIT:1> ) \n correct = ( predicted == true_labels ) . astype ( np . float ) \n if mask is not None : \n correct *= mask \n return np . sum ( correct ) \n class Hamming ( Scorer ) : \n def __init__ ( self , threshold = <NUM_LIT:0.5> , out_name = '<STR_LIT>' , targets_name = '<STR_LIT>' , \n mask_name = '<STR_LIT>' , name = None ) : \n super ( Hamming , self ) . __init__ ( out_name , targets_name , mask_name , name ) \n self . threshold = threshold \n def __call__ ( self , true_labels , predicted , mask = None ) : \n correct = np . logical_xor ( predicted < self . threshold , \n true_labels ) . astype ( np . float ) \n if mask is not None : \n correct *= mask \n return np . sum ( correct ) / true_labels . shape [ <NUM_LIT:1> ] \n class MeanSquaredError ( Scorer ) : \n def __call__ ( self , true_labels , predicted , mask = None ) : \n errors = ( true_labels - predicted ) ** <NUM_LIT:2> \n if mask is not None : \n errors *= mask \n return <NUM_LIT:0.5> * np . sum ( errors ) \n def _flatten_all_but_last ( a ) : \n if a is None : \n return None \n return a . reshape ( - <NUM_LIT:1> , a . shape [ - <NUM_LIT:1> ] ) \n def _weighted_average ( errors ) : \n errors = np . array ( errors ) \n assert errors . ndim == <NUM_LIT:2> and errors . shape [ <NUM_LIT:1> ] == <NUM_LIT:2> \n return np . sum ( errors [ : , <NUM_LIT:1> ] * errors [ : , <NUM_LIT:0> ] / np . sum ( errors [ : , <NUM_LIT:0> ] ) ) \n", "gt": "errors"}
{"input": "\n from __future__ import division , print_function , unicode_literals \n import pytest \n import six \n from brainstorm . training . schedules import Exponential , Linear , MultiStep \n def test_linear ( ) : \n <mask0> = Linear ( initial_value = <NUM_LIT:1.0> , final_value = <NUM_LIT:0.5> , num_changes = <NUM_LIT:5> ) \n epochs = [ <NUM_LIT:0> ] * <NUM_LIT:2> + [ <NUM_LIT:1> ] * <NUM_LIT:2> + [ <NUM_LIT:2> ] * <NUM_LIT:2> + [ <NUM_LIT:3> ] * <NUM_LIT:2> + [ <NUM_LIT:4> ] * <NUM_LIT:2> \n updates = range ( <NUM_LIT:10> ) \n values = [ sch ( epoch , update , '<STR_LIT>' , <NUM_LIT:1> , None , None , None ) \n for epoch , update in six . moves . zip ( epochs , updates ) ] \n assert values == [ <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] \n values = [ sch ( epoch , update , '<STR_LIT>' , <NUM_LIT:1> , None , None , None ) \n for epoch , update in six . moves . zip ( epochs , updates ) ] \n assert values == [ <NUM_LIT:1.0> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT:0.5> , <NUM_LIT:0.5> , <NUM_LIT:0.5> , <NUM_LIT:0.5> , <NUM_LIT:0.5> ] \n values = [ sch ( epoch , update , '<STR_LIT>' , <NUM_LIT:3> , None , None , None ) \n for epoch , update in six . moves . zip ( epochs , updates ) ] \n assert values == [ <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] \n def test_exponential ( ) : \n sch = Exponential ( initial_value = <NUM_LIT:1.0> , factor = <NUM_LIT> , minimum = <NUM_LIT> ) \n epochs = [ <NUM_LIT:0> ] * <NUM_LIT:4> + [ <NUM_LIT:1> ] * <NUM_LIT:4> + [ <NUM_LIT:2> ] * <NUM_LIT:4> \n updates = range ( <NUM_LIT:12> ) \n values = [ sch ( epoch , update , '<STR_LIT>' , <NUM_LIT:1> , None , None , None ) \n for epoch , update in six . moves . zip ( epochs , updates ) ] \n assert values == [ <NUM_LIT:1.0> ] * <NUM_LIT:4> + [ <NUM_LIT> ] * <NUM_LIT:4> + [ <NUM_LIT> * <NUM_LIT> ] * <NUM_LIT:4> \n values = [ sch ( epoch , update , '<STR_LIT>' , <NUM_LIT:1> , None , None , None ) \n for epoch , update in six . moves . zip ( epochs , updates ) ] \n assert values == [ <NUM_LIT:1.0> * ( <NUM_LIT> ** x ) for x in range ( <NUM_LIT:4> ) ] + [ <NUM_LIT> ] * <NUM_LIT:8> \n values = [ sch ( epoch , update , '<STR_LIT>' , <NUM_LIT:3> , None , None , None ) \n for epoch , update in six . moves . zip ( epochs , updates ) ] \n assert values == [ <NUM_LIT:1.0> ] * <NUM_LIT:3> + [ <NUM_LIT> ] * <NUM_LIT:3> + [ <NUM_LIT> ] * <NUM_LIT:3> + [ <NUM_LIT> ** <NUM_LIT:3> ] * <NUM_LIT:3> \n def test_multistep ( ) : \n sch = MultiStep ( initial_value = <NUM_LIT:1.0> , steps = [ <NUM_LIT:3> , <NUM_LIT:5> , <NUM_LIT:8> ] , \n values = [ <NUM_LIT:0.1> , <NUM_LIT> , <NUM_LIT> ] ) \n epochs = [ <NUM_LIT:0> ] * <NUM_LIT:2> + [ <NUM_LIT:1> ] * <NUM_LIT:2> + [ <NUM_LIT:2> ] * <NUM_LIT:2> + [ <NUM_LIT:3> ] * <NUM_LIT:2> + [ <NUM_LIT:4> ] * <NUM_LIT:2> \n updates = range ( <NUM_LIT:10> ) \n values = [ sch ( epoch , update , '<STR_LIT>' , <NUM_LIT:1> , None , None , None ) \n for epoch , update in six . moves . zip ( epochs , updates ) ] \n assert values == [ <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:0.1> , <NUM_LIT:0.1> , <NUM_LIT:0.1> , <NUM_LIT:0.1> ] \n values = [ sch ( epoch , update , '<STR_LIT>' , <NUM_LIT:1> , None , None , None ) \n for epoch , update in six . moves . zip ( epochs , updates ) ] \n assert values == [ <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:0.1> , <NUM_LIT:0.1> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] \n with pytest . raises ( AssertionError ) : \n _ = sch ( <NUM_LIT:0> , <NUM_LIT:0> , '<STR_LIT>' , <NUM_LIT:3> , None , None , None ) \n", "gt": "sch"}
{"input": "\n import os \n import sys \n try : \n from unittest . mock import MagicMock \n except ImportError : \n from mock import Mock as MagicMock \n class Mock ( MagicMock ) : \n @ classmethod \n def __getattr__ ( cls , name ) : \n return Mock ( ) \n <mask0> = [ '<STR_LIT>' , '<STR_LIT>' ] \n sys . modules . update ( ( mod_name , Mock ( ) ) for mod_name in MOCK_MODULES ) \n cwd = os . getcwd ( ) \n parent = os . path . dirname ( cwd ) \n sys . path . insert ( <NUM_LIT:0> , parent ) \n import brainstorm \n extensions = [ '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' ] \n templates_path = [ '<STR_LIT>' ] \n source_suffix = '<STR_LIT>' \n master_doc = '<STR_LIT:index>' \n project = u'<STR_LIT>' \n copyright = u'<STR_LIT>' \n version = brainstorm . __version__ \n release = brainstorm . __version__ \n exclude_patterns = [ '<STR_LIT>' ] \n pygments_style = '<STR_LIT>' \n on_rtd = os . environ . get ( '<STR_LIT>' , None ) == '<STR_LIT:True>' \n if not on_rtd : \n try : \n import sphinx_rtd_theme \n html_theme = '<STR_LIT>' \n html_theme_path = [ sphinx_rtd_theme . get_html_theme_path ( ) ] \n except ImportError : \n html_theme = '<STR_LIT>' \n html_static_path = [ '<STR_LIT>' ] \n htmlhelp_basename = '<STR_LIT>' \n latex_elements = { \n } \n latex_documents = [ \n ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , \n u'<STR_LIT>' , '<STR_LIT>' ) , \n ] \n man_pages = [ \n ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , \n [ u'<STR_LIT>' ] , <NUM_LIT:1> ) \n ] \n texinfo_documents = [ \n ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , \n u'<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' ) , \n ] \n", "gt": "MOCK_MODULES"}
{"input": "\n from __future__ import division , print_function , unicode_literals \n from sacred . utils import iter_prefixes , join_paths \n class ConfigSummary ( dict ) : \n def __init__ ( self , added = ( ) , modified = ( ) , typechanged = ( ) , \n ignored_fallbacks = ( ) ) : \n super ( ConfigSummary , self ) . __init__ ( ) \n self . added = set ( added ) \n self . modified = set ( modified ) \n self . typechanged = dict ( typechanged ) \n self . ignored_fallbacks = set ( ignored_fallbacks ) \n self . ensure_coherence ( ) \n def update_from ( self , config_mod , path = '<STR_LIT>' ) : \n <mask0> = config_mod . added \n updated = config_mod . modified \n typechanged = config_mod . typechanged \n self . added &= { join_paths ( path , a ) for a in added } \n self . modified |= { join_paths ( path , u ) for u in updated } \n self . typechanged . update ( { join_paths ( path , k ) : v \n for k , v in typechanged . items ( ) } ) \n self . ensure_coherence ( ) \n def update_add ( self , config_mod , path = '<STR_LIT>' ) : \n added = config_mod . added \n updated = config_mod . modified \n typechanged = config_mod . typechanged \n self . added |= { join_paths ( path , a ) for a in added } \n self . modified |= { join_paths ( path , u ) for u in updated } \n self . typechanged . update ( { join_paths ( path , k ) : v \n for k , v in typechanged . items ( ) } ) \n self . ensure_coherence ( ) \n def ensure_coherence ( self ) : \n self . modified |= { p for a in self . added for p in iter_prefixes ( a ) } \n self . modified |= { p for u in self . modified for p in iter_prefixes ( u ) } \n self . modified |= { p for t in self . typechanged \n for p in iter_prefixes ( t ) } \n self . added -= set ( self . typechanged . keys ( ) ) \n self . modified -= set ( self . typechanged . keys ( ) ) \n self . modified -= self . added \n", "gt": "added"}
{"input": "\n from __future__ import division , print_function , unicode_literals \n import pytest \n import sacred . optional as opt \n from sacred . config import ConfigDict \n from sacred . config . custom_containers import DogmaticDict , DogmaticList \n @ pytest . fixture \n def conf_dict ( ) : \n <mask0> = ConfigDict ( { \n \"<STR_LIT:a>\" : <NUM_LIT:1> , \n \"<STR_LIT:b>\" : <NUM_LIT> , \n \"<STR_LIT:c>\" : True , \n \"<STR_LIT:d>\" : '<STR_LIT:string>' , \n \"<STR_LIT:e>\" : [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] , \n \"<STR_LIT:f>\" : { '<STR_LIT:a>' : '<STR_LIT:b>' , '<STR_LIT:c>' : '<STR_LIT:d>' } , \n } ) \n return cfg \n def test_config_dict_returns_dict ( conf_dict ) : \n assert isinstance ( conf_dict ( ) , dict ) \n def test_config_dict_result_contains_keys ( conf_dict ) : \n cfg = conf_dict ( ) \n assert set ( cfg . keys ( ) ) == { '<STR_LIT:a>' , '<STR_LIT:b>' , '<STR_LIT:c>' , '<STR_LIT:d>' , '<STR_LIT:e>' , '<STR_LIT:f>' } \n assert cfg [ '<STR_LIT:a>' ] == <NUM_LIT:1> \n assert cfg [ '<STR_LIT:b>' ] == <NUM_LIT> \n assert cfg [ '<STR_LIT:c>' ] \n assert cfg [ '<STR_LIT:d>' ] == '<STR_LIT:string>' \n assert cfg [ '<STR_LIT:e>' ] == [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] \n assert cfg [ '<STR_LIT:f>' ] == { '<STR_LIT:a>' : '<STR_LIT:b>' , '<STR_LIT:c>' : '<STR_LIT:d>' } \n def test_fixing_values ( conf_dict ) : \n assert conf_dict ( { '<STR_LIT:a>' : <NUM_LIT:100> } ) [ '<STR_LIT:a>' ] == <NUM_LIT:100> \n @ pytest . mark . parametrize ( \"<STR_LIT:key>\" , [ \"<STR_LIT>\" , \"<STR_LIT>\" , <NUM_LIT:12> , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) \n def test_config_dict_raises_on_invalid_keys ( key ) : \n with pytest . raises ( KeyError ) : \n ConfigDict ( { key : True } ) \n @ pytest . mark . parametrize ( \"<STR_LIT:value>\" , [ lambda x : x , pytest , test_fixing_values ] ) \n def test_config_dict_raises_on_invalid_values ( value ) : \n with pytest . raises ( ValueError ) : \n ConfigDict ( { \"<STR_LIT>\" : value } ) \n def test_fixing_nested_dicts ( conf_dict ) : \n cfg = conf_dict ( { '<STR_LIT:f>' : { '<STR_LIT:c>' : '<STR_LIT:t>' } } ) \n assert cfg [ '<STR_LIT:f>' ] [ '<STR_LIT:a>' ] == '<STR_LIT:b>' \n assert cfg [ '<STR_LIT:f>' ] [ '<STR_LIT:c>' ] == '<STR_LIT:t>' \n def test_adding_values ( conf_dict ) : \n cfg = conf_dict ( { '<STR_LIT:g>' : <NUM_LIT> , '<STR_LIT:h>' : { '<STR_LIT:i>' : <NUM_LIT:10> } } ) \n assert cfg [ '<STR_LIT:g>' ] == <NUM_LIT> \n assert cfg [ '<STR_LIT:h>' ] == { '<STR_LIT:i>' : <NUM_LIT:10> } \n assert cfg . added == { '<STR_LIT:g>' , '<STR_LIT:h>' , '<STR_LIT>' } \n def test_typechange ( conf_dict ) : \n cfg = conf_dict ( { '<STR_LIT:a>' : '<STR_LIT:bar>' , '<STR_LIT:b>' : '<STR_LIT:foo>' , '<STR_LIT:c>' : <NUM_LIT:1> } ) \n assert cfg . typechanged == { '<STR_LIT:a>' : ( int , type ( '<STR_LIT:bar>' ) ) , \n '<STR_LIT:b>' : ( float , type ( '<STR_LIT:foo>' ) ) , \n '<STR_LIT:c>' : ( bool , int ) } \n def test_nested_typechange ( conf_dict ) : \n cfg = conf_dict ( { '<STR_LIT:f>' : { '<STR_LIT:a>' : <NUM_LIT:10> } } ) \n assert cfg . typechanged == { '<STR_LIT>' : ( type ( '<STR_LIT:a>' ) , int ) } \n def is_dogmatic ( a ) : \n if isinstance ( a , ( DogmaticDict , DogmaticList ) ) : \n return True \n elif isinstance ( a , dict ) : \n return any ( is_dogmatic ( v ) for v in a . values ( ) ) \n elif isinstance ( a , ( list , tuple ) ) : \n return any ( is_dogmatic ( v ) for v in a ) \n def test_result_of_conf_dict_is_not_dogmatic ( conf_dict ) : \n cfg = conf_dict ( { '<STR_LIT:e>' : [ <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> ] } ) \n assert not is_dogmatic ( cfg ) \n @ pytest . mark . skipif ( not opt . has_numpy , reason = \"<STR_LIT>\" ) \n def test_conf_scope_handles_numpy_bools ( ) : \n cfg = ConfigDict ( { \n \"<STR_LIT:a>\" : opt . np . bool_ ( <NUM_LIT:1> ) \n } ) \n assert '<STR_LIT:a>' in cfg ( ) \n assert cfg ( ) [ '<STR_LIT:a>' ] \n def test_conf_scope_contains_presets ( ) : \n conf_dict = ConfigDict ( { \n \"<STR_LIT>\" : <NUM_LIT> \n } ) \n cfg = conf_dict ( preset = { '<STR_LIT:a>' : <NUM_LIT> , '<STR_LIT>' : True } ) \n assert set ( cfg . keys ( ) ) == { '<STR_LIT:a>' , '<STR_LIT>' , '<STR_LIT>' } \n assert cfg [ '<STR_LIT:a>' ] == <NUM_LIT> \n assert cfg [ '<STR_LIT>' ] == <NUM_LIT> \n assert cfg [ '<STR_LIT>' ] is True \n def test_conf_scope_does_not_contain_fallback ( ) : \n config_dict = ConfigDict ( { \n \"<STR_LIT>\" : <NUM_LIT> \n } ) \n cfg = config_dict ( fallback = { '<STR_LIT:a>' : <NUM_LIT> , '<STR_LIT:b>' : <NUM_LIT:10> } ) \n assert set ( cfg . keys ( ) ) == { '<STR_LIT>' } \n def test_fixed_subentry_of_preset ( ) : \n config_dict = ConfigDict ( { } ) \n cfg = config_dict ( preset = { '<STR_LIT:d>' : { '<STR_LIT:a>' : <NUM_LIT:1> , '<STR_LIT:b>' : <NUM_LIT:2> } } , fixed = { '<STR_LIT:d>' : { '<STR_LIT:a>' : <NUM_LIT:10> } } ) \n assert set ( cfg . keys ( ) ) == { '<STR_LIT:d>' } \n assert set ( cfg [ '<STR_LIT:d>' ] . keys ( ) ) == { '<STR_LIT:a>' , '<STR_LIT:b>' } \n assert cfg [ '<STR_LIT:d>' ] [ '<STR_LIT:a>' ] == <NUM_LIT:10> \n assert cfg [ '<STR_LIT:d>' ] [ '<STR_LIT:b>' ] == <NUM_LIT:2> \n", "gt": "cfg"}
{"input": "\n class PID ( object ) : \n def __init__ ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n self . kd = <<mask0>:0> \n self . ki = <NUM_LIT:0> \n self . kp = <NUM_LIT:1> \n self . previous_error = <NUM_LIT:0> \n self . integral_error = <NUM_LIT:0> \n def set_k_values ( self , kp , kd , ki ) : \n self . kp = kp \n self . ki = ki \n self . kd = kd \n def clear_error ( self ) : \n self . previous_error = <NUM_LIT:0> \n self . integeral_error = <NUM_LIT:0> \n def pid ( self , target , process_var , timestep ) : \n current_error = ( target - process_var ) \n p_error = self . kp * current_error \n d_error = self . kd * ( current_error - self . previous_error ) / timestep \n self . integral_error = ( \n current_error + self . previous_error ) / <NUM_LIT:2> + self . integral_error \n i_error = self . ki * self . integral_error \n total_error = p_error + d_error + i_error \n self . previous_error = current_error \n return total_error \n", "gt": "NUM_LIT"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import cmd \n import sys \n import os \n import bot . client . ctrl_client as ctrl_client_mod \n import bot . client . sub_client as sub_client_mod \n class CLI ( cmd . Cmd ) : \n \"\"\"<STR_LIT>\"\"\" \n <mask0> = \"<STR_LIT>\" \n def __init__ ( self , ctrl_addr , sub_addr ) : \n \"\"\"<STR_LIT>\"\"\" \n cmd . Cmd . __init__ ( self ) \n try : \n self . ctrl_client = ctrl_client_mod . CtrlClient ( ctrl_addr ) \n except Exception , e : \n print \"<STR_LIT>\" . format ( ctrl_addr , e ) \n sys . exit ( - <NUM_LIT:1> ) \n try : \n self . sub_client = sub_client_mod . SubClient ( sub_addr ) \n except Exception , e : \n print \"<STR_LIT>\" . format ( sub_addr , e ) \n sys . exit ( - <NUM_LIT:1> ) \n def default ( self , raw_args ) : \n \"\"\"<STR_LIT>\"\"\" \n obj_name , _ , rest = raw_args . partition ( \"<STR_LIT:U+0020>\" ) \n if obj_name in self . ctrl_client . objects : \n method_name , _ , params = rest . partition ( \"<STR_LIT:U+0020>\" ) \n if method_name in self . ctrl_client . objects [ obj_name ] : \n try : \n param_dict = { } \n for param in params . split ( ) : \n key , value = param . split ( \"<STR_LIT::>\" ) \n try : \n if \"<STR_LIT:.>\" in value : \n value = float ( value ) \n else : \n value = int ( value ) \n except ValueError : \n if value == \"<STR_LIT:True>\" : \n value = True \n elif value == \"<STR_LIT:False>\" : \n value = False \n elif value . startswith ( \"<STR_LIT:'>\" ) and value . endswith ( \"<STR_LIT:'>\" ) : \n value = value [ <NUM_LIT:1> : - <NUM_LIT:1> ] \n param_dict [ key ] = value \n except IndexError : \n print \"<STR_LIT>\" \n return \n except ValueError : \n print \"<STR_LIT>\" \n return \n result = self . ctrl_client . call ( \n obj_name , method_name , param_dict ) \n print \"<STR_LIT>\" , result \n else : \n print \"<STR_LIT>\" , method_name \n else : \n print \"<STR_LIT>\" , obj_name \n def completenames ( self , text , * ignored ) : \n \"\"\"<STR_LIT>\"\"\" \n cmd_match_names = cmd . Cmd . completenames ( self , text , * ignored ) \n obj_names = self . ctrl_client . objects . keys ( ) \n api_match_names = [ x for x in obj_names if x . startswith ( text ) ] \n return cmd_match_names + api_match_names \n def completedefault ( self , text , line , begidx , endidx ) : \n \"\"\"<STR_LIT>\"\"\" \n obj , _ , rest = line . partition ( \"<STR_LIT:U+0020>\" ) \n if obj in self . ctrl_client . objects : \n method , _ , params = rest . strip ( ) . partition ( \"<STR_LIT:U+0020>\" ) \n if method == text : \n method_names = self . ctrl_client . objects [ obj ] \n match_names = [ x for x in method_names if x . startswith ( text ) ] \n return match_names \n def do_list ( self , raw_args ) : \n \"\"\"<STR_LIT>\"\"\" \n print \n print \"<STR_LIT>\" \n print \n for obj_name , methods in sorted ( self . ctrl_client . objects . items ( ) ) : \n print \"<STR_LIT>\" . format ( obj_name ) \n for method in methods : \n print \"<STR_LIT>\" . format ( method ) \n print \n def help_list ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n print \"<STR_LIT:list>\" \n print \"<STR_LIT>\" \n def do_ping ( self , raw_args ) : \n \"\"\"<STR_LIT>\"\"\" \n reply_time = self . ctrl_client . ping ( ) \n print \"<STR_LIT>\" . format ( reply_time ) \n def help_ping ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n print \"<STR_LIT>\" \n print \"<STR_LIT>\" \n def do_sub_add ( self , raw_args ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n topic = raw_args . split ( ) [ <NUM_LIT:0> ] \n except ( ValueError , IndexError ) : \n print \"<STR_LIT>\" \n return \n self . sub_client . add_topic ( topic ) \n def help_sub_add ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n print \"<STR_LIT>\" \n print \"<STR_LIT>\" \n def do_sub_del ( self , raw_args ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n topic = raw_args . split ( ) [ <NUM_LIT:0> ] \n except ( ValueError , IndexError ) : \n print \"<STR_LIT>\" \n return \n self . sub_client . del_topic ( topic ) \n def help_sub_del ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n print \"<STR_LIT>\" \n print \"<STR_LIT>\" \n def do_sub ( self , raw_args ) : \n \"\"\"<STR_LIT>\"\"\" \n self . sub_client . print_msgs ( ) \n def help_sub ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n print \"<STR_LIT>\" \n print \"<STR_LIT>\" \n def do_stop ( self , raw_args ) : \n \"\"\"<STR_LIT>\"\"\" \n self . ctrl_client . stop_full ( ) \n def help_stop ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n print \"<STR_LIT>\" \n print \"<STR_LIT>\" \n def do_kill ( self , raw_args ) : \n \"\"\"<STR_LIT>\"\"\" \n self . ctrl_client . exit_server ( ) \n def help_kill ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n print \"<STR_LIT>\" \n print \"<STR_LIT>\" \n def do_die ( self , raw_args ) : \n \"\"\"<STR_LIT>\"\"\" \n print \"<STR_LIT>\" \n self . ctrl_client . clean_up ( ) \n self . sub_client . clean_up ( ) \n print \"<STR_LIT>\" \n return True \n def help_die ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n print \"<STR_LIT>\" \n print \"<STR_LIT>\" \n def do_shell ( self , cmd ) : \n \"\"\"<STR_LIT>\"\"\" \n os . system ( cmd ) \n def help_shell ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n print \"<STR_LIT>\" \n print \"<STR_LIT>\" \n def do_EOF ( self , raw_args ) : \n \"\"\"<STR_LIT>\"\"\" \n print \"<STR_LIT>\" \n self . ctrl_client . clean_up ( ) \n self . sub_client . clean_up ( ) \n print \"<STR_LIT>\" \n return True \n def help_EOF ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n print \"<STR_LIT>\" \n print \"<STR_LIT>\" \n def help_help ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n print \"<STR_LIT>\" \n print \"<STR_LIT>\" \n if __name__ == '<STR_LIT:__main__>' : \n if len ( sys . argv ) == <NUM_LIT:1> : \n print \"<STR_LIT>\" \n CLI ( \"<STR_LIT>\" , \"<STR_LIT>\" ) . cmdloop ( ) \n elif len ( sys . argv ) == <NUM_LIT:3> : \n ctrl_addr = sys . argv [ <NUM_LIT:1> ] \n sub_addr = sys . argv [ <NUM_LIT:2> ] \n CLI ( ctrl_addr , sub_addr ) . cmdloop ( ) \n else : \n print \"<STR_LIT>\" \n", "gt": "prompt"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n from random import randint \n from os import path \n import bot . lib . lib as lib \n import bot . hardware . servo as s_mod \n import tests . test_bot as test_bot \n class TestPosition ( test_bot . TestBot ) : \n \"\"\"<STR_LIT>\"\"\" \n def setUp ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n super ( TestPosition , self ) . setUp ( ) \n <mask0> = path . dirname ( path . realpath ( __file__ ) ) + \"<STR_LIT>\" \n self . config = lib . get_config ( config ) \n self . pwm_num = self . config [ '<STR_LIT>' ] \n self . setup_pwm ( self . pwm_num , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n self . servo = s_mod . Servo ( self . pwm_num ) \n def tearDown ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n super ( TestPosition , self ) . tearDown ( ) \n def test_0 ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n self . servo . position = <NUM_LIT:0> \n assert self . servo . position == <NUM_LIT:0> , self . servo . position \n def test_180 ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n self . servo . position = <NUM_LIT> \n assert self . servo . position == <NUM_LIT> , self . servo . position \n def test_middle ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n self . servo . position = <NUM_LIT> \n assert self . servo . position == <NUM_LIT> , self . servo . position \n def test_series ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n for position in range ( <NUM_LIT:0> , <NUM_LIT> , <NUM_LIT> ) : \n self . servo . position = position \n assert self . servo . position == position , self . servo . position \n def test_manually_confirm ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n for i in range ( <NUM_LIT:10> ) : \n test_pos = randint ( <NUM_LIT:0> , <NUM_LIT> ) \n self . servo . position = test_pos \n cur_pwm = self . get_pwm ( self . pwm_num ) \n duty = int ( cur_pwm [ \"<STR_LIT>\" ] ) \n read_pos = int ( round ( ( ( duty - <NUM_LIT> ) / <NUM_LIT> ) * <NUM_LIT> ) ) \n assert read_pos == test_pos , \"<STR_LIT>\" . format ( read_pos , test_pos ) \n def test_over_max ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n self . servo . position = <NUM_LIT> \n assert self . servo . position == <NUM_LIT> , \"<STR_LIT>\" . format ( self . servo . position ) \n def test_under_min ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n self . servo . position = - <NUM_LIT:1> \n assert self . servo . position == <NUM_LIT:0> , \"<STR_LIT>\" . format ( self . servo . position ) \n", "gt": "config"}
{"input": "\n from django . contrib . syndication . views import Feed as SyndicationFeed \n from django . core . urlresolvers import reverse \n from django . conf import settings \n from lifestream . models import Lifestream , Item \n class RecentItemsFeed ( SyndicationFeed ) : \n <mask0> = \"<STR_LIT>\" \n description = \"<STR_LIT>\" \n def link ( self , obj ) : \n return reverse ( '<STR_LIT>' , kwargs = { \n '<STR_LIT>' : obj . slug , \n } ) \n def get_object ( self , bits ) : \n return Lifestream . objects . get ( slug = bits [ <NUM_LIT:0> ] ) \n def items ( self , obj ) : \n return Item . objects . published ( ) . filter ( feed__lifestream = obj ) [ : <NUM_LIT:10> ] \n def item_pubdate ( self , item ) : \n return item . date \n def item_categories ( self , item ) : \n def item_categories ( self , item ) : \n if '<STR_LIT>' in settings . INSTALLED_APPS : \n return [ tag . name for tag in item . tag_set ] \n else : \n return [ ] \n", "gt": "title"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n from functools import update_wrapper \n from google . appengine . api import users \n from werkzeug import redirect \n from werkzeug . exceptions import Forbidden \n from kay . utils import ( \n create_login_url , create_logout_url \n ) \n from kay . utils . decorators import auto_adapt_to_methods \n def login_required ( func ) : \n def inner ( request , * args , ** kwargs ) : \n if request . user . is_anonymous ( ) : \n if request . is_xhr : \n return Forbidden ( ) \n <mask0> : \n return redirect ( create_login_url ( request . url ) ) \n return func ( request , * args , ** kwargs ) \n update_wrapper ( inner , func ) \n return inner \n login_required = auto_adapt_to_methods ( login_required ) \n def admin_required ( func ) : \n def inner ( request , * args , ** kwargs ) : \n if not request . user . is_admin : \n if request . user . is_anonymous ( ) : \n return redirect ( create_login_url ( request . url ) ) \n else : \n raise Forbidden ( \n description = \n '<STR_LIT>' \n '<STR_LIT>' \n '<STR_LIT>' % \n create_logout_url ( request . url ) \n ) \n return func ( request , * args , ** kwargs ) \n update_wrapper ( inner , func ) \n return inner \n admin_required = auto_adapt_to_methods ( admin_required ) \n", "gt": "else"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n <mask0> = - <NUM_LIT> \n INVALID_REQUEST = - <NUM_LIT> \n METHOD_NOT_FOUND = - <NUM_LIT> \n INVALID_PARAMS = - <NUM_LIT> \n INTERNAL_ERROR = - <NUM_LIT> \n errors = { } \n errors [ PARSE_ERROR ] = \"<STR_LIT>\" \n errors [ INVALID_REQUEST ] = \"<STR_LIT>\" \n errors [ METHOD_NOT_FOUND ] = \"<STR_LIT>\" \n errors [ INVALID_PARAMS ] = \"<STR_LIT>\" \n errors [ INTERNAL_ERROR ] = \"<STR_LIT>\" \n try : \n import json \n except ImportError : \n try : \n import django . utils . simplejson as json \n except ImportError : \n import simplejson as json \n import sys \n import logging \n import itertools \n from werkzeug import Request , Response \n from werkzeug import exceptions \n class JsonRpcApplication ( object ) : \n def __init__ ( self , methods = None ) : \n if methods is not None : \n self . methods = methods \n else : \n self . methods = { } \n def add_module ( self , mod , namespace = None ) : \n if namespace is None : \n namespace = mod . __name__ \n for k , v in ( ( k , v ) for k , v in mod . __dict__ . iteritems ( ) \n if not k . startswith ( '<STR_LIT:_>' ) and callable ( v ) ) : \n self . add ( namespace + '<STR_LIT:.>' + k , v ) \n def add ( self , name , func ) : \n self . methods [ name ] = func \n def process ( self , data ) : \n if data . get ( '<STR_LIT>' ) != \"<STR_LIT>\" : \n return { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT:id>' : data . get ( '<STR_LIT:id>' ) , \n '<STR_LIT:error>' : { '<STR_LIT:code>' : INVALID_REQUEST , \n '<STR_LIT:message>' : errors [ INVALID_REQUEST ] } } \n if '<STR_LIT>' not in data : \n return { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT:id>' : data . get ( '<STR_LIT:id>' ) , \n '<STR_LIT:error>' : { '<STR_LIT:code>' : INVALID_REQUEST , \n '<STR_LIT:message>' : errors [ INVALID_REQUEST ] } } \n methodname = data [ '<STR_LIT>' ] \n if not isinstance ( methodname , basestring ) : \n return { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT:id>' : data . get ( '<STR_LIT:id>' ) , \n '<STR_LIT:error>' : { '<STR_LIT:code>' : INVALID_REQUEST , \n '<STR_LIT:message>' : errors [ INVALID_REQUEST ] } } \n if methodname . startswith ( '<STR_LIT:_>' ) : \n return { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT:id>' : data . get ( '<STR_LIT:id>' ) , \n '<STR_LIT:error>' : { '<STR_LIT:code>' : METHOD_NOT_FOUND , \n '<STR_LIT:message>' : errors [ METHOD_NOT_FOUND ] } } \n if methodname not in self . methods : \n return { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT:id>' : data . get ( '<STR_LIT:id>' ) , \n '<STR_LIT:error>' : { '<STR_LIT:code>' : METHOD_NOT_FOUND , \n '<STR_LIT:message>' : errors [ METHOD_NOT_FOUND ] } } \n method = self . methods [ methodname ] \n try : \n params = data . get ( '<STR_LIT>' , [ ] ) \n if isinstance ( params , list ) : \n result = method ( * params ) \n elif isinstance ( params , dict ) : \n result = method ( ** dict ( [ ( str ( k ) , v ) for k , v in params . iteritems ( ) ] ) ) \n else : \n return { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT:id>' : data . get ( '<STR_LIT:id>' ) , \n '<STR_LIT:error>' : { '<STR_LIT:code>' : INVALID_REQUEST , \n '<STR_LIT:message>' : errors [ INVALID_REQUEST ] } } \n resdata = None \n if data . get ( '<STR_LIT:id>' ) : \n resdata = { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT:id>' : data . get ( '<STR_LIT:id>' ) , \n '<STR_LIT:result>' : result , \n } \n return resdata \n except Exception , e : \n return { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT:id>' : data . get ( '<STR_LIT:id>' ) , \n '<STR_LIT:error>' : { '<STR_LIT:code>' : INTERNAL_ERROR , \n '<STR_LIT:message>' : errors [ INTERNAL_ERROR ] , \n '<STR_LIT:data>' : str ( e ) } } \n def __call__ ( self , environ , start_response ) : \n request = Request ( environ ) \n if request . method != \"<STR_LIT:POST>\" : \n raise exceptions . MethodNotAllowed \n if not request . content_type . startswith ( '<STR_LIT:application/json>' ) : \n raise exceptions . BadRequest \n try : \n data = json . loads ( request . data ) \n except ValueError , e : \n resdata = { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT:id>' : None , \n '<STR_LIT:error>' : { '<STR_LIT:code>' : PARSE_ERROR , \n '<STR_LIT:message>' : errors [ PARSE_ERROR ] } } \n else : \n if isinstance ( data , dict ) : \n resdata = self . process ( data ) \n elif isinstance ( data , list ) : \n if len ( [ x for x in data if not isinstance ( x , dict ) ] ) : \n resdata = { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT:id>' : None , \n '<STR_LIT:error>' : { '<STR_LIT:code>' : INVALID_REQUEST , \n '<STR_LIT:message>' : errors [ INVALID_REQUEST ] } } \n else : \n resdata = [ d for d in ( self . process ( d ) for d in data ) \n if d is not None ] \n response = Response ( content_type = \"<STR_LIT:application/json>\" ) \n if resdata : \n response . headers [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n response . headers [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n response . headers [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n response . data = json . dumps ( resdata ) \n return response ( environ , start_response ) \n def getmod ( modname ) : \n try : \n __import__ ( modname ) \n except ImportError , e : \n logging . warn ( \"<STR_LIT>\" % e ) \n return None \n mod = sys . modules [ modname ] \n return mod \n def HTTPExceptionMiddleware ( app ) : \n def wrap ( environ , start_response ) : \n try : \n return app ( environ , start_response ) \n except exceptions . HTTPException , e : \n return e ( environ , start_response ) \n return wrap \n def make_application ( methods ) : \n app = JsonRpcApplication ( ) \n for name , value in methods . iteritems ( ) : \n if \"<STR_LIT::>\" in value : \n modname , funcname = value . split ( \"<STR_LIT::>\" , <NUM_LIT:1> ) \n mod = getmod ( modname ) \n if mod : \n app . add ( name , getattr ( mod , funcname ) ) \n else : \n modname = value \n mod = getmod ( modname ) \n if mod : \n app . add_module ( mod , name ) \n app = HTTPExceptionMiddleware ( app ) \n return app \n", "gt": "PARSE_ERROR"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import re \n from jinja2 . runtime import Undefined \n <mask0> = False \n number_re = re . compile ( r'<STR_LIT>' ) \n regex_type = type ( number_re ) \n try : \n test_callable = callable \n except NameError : \n def test_callable ( x ) : \n return hasattr ( x , '<STR_LIT>' ) \n def test_odd ( value ) : \n \"\"\"<STR_LIT>\"\"\" \n return value % <NUM_LIT:2> == <NUM_LIT:1> \n def test_even ( value ) : \n \"\"\"<STR_LIT>\"\"\" \n return value % <NUM_LIT:2> == <NUM_LIT:0> \n def test_divisibleby ( value , num ) : \n \"\"\"<STR_LIT>\"\"\" \n return value % num == <NUM_LIT:0> \n def test_defined ( value ) : \n \"\"\"<STR_LIT>\"\"\" \n return not isinstance ( value , Undefined ) \n def test_undefined ( value ) : \n \"\"\"<STR_LIT>\"\"\" \n return isinstance ( value , Undefined ) \n def test_none ( value ) : \n \"\"\"<STR_LIT>\"\"\" \n return value is None \n def test_lower ( value ) : \n \"\"\"<STR_LIT>\"\"\" \n return unicode ( value ) . islower ( ) \n def test_upper ( value ) : \n \"\"\"<STR_LIT>\"\"\" \n return unicode ( value ) . isupper ( ) \n def test_string ( value ) : \n \"\"\"<STR_LIT>\"\"\" \n return isinstance ( value , basestring ) \n def test_number ( value ) : \n \"\"\"<STR_LIT>\"\"\" \n return isinstance ( value , ( int , long , float , complex ) ) \n def test_sequence ( value ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n len ( value ) \n value . __getitem__ \n except : \n return False \n return True \n def test_sameas ( value , other ) : \n \"\"\"<STR_LIT>\"\"\" \n return value is other \n def test_iterable ( value ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n iter ( value ) \n except TypeError : \n return False \n return True \n def test_escaped ( value ) : \n \"\"\"<STR_LIT>\"\"\" \n return hasattr ( value , '<STR_LIT>' ) \n TESTS = { \n '<STR_LIT>' : test_odd , \n '<STR_LIT>' : test_even , \n '<STR_LIT>' : test_divisibleby , \n '<STR_LIT>' : test_defined , \n '<STR_LIT>' : test_undefined , \n '<STR_LIT:none>' : test_none , \n '<STR_LIT>' : test_lower , \n '<STR_LIT>' : test_upper , \n '<STR_LIT:string>' : test_string , \n '<STR_LIT>' : test_number , \n '<STR_LIT>' : test_sequence , \n '<STR_LIT>' : test_iterable , \n '<STR_LIT>' : test_callable , \n '<STR_LIT>' : test_sameas , \n '<STR_LIT>' : test_escaped \n } \n", "gt": "__test__"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import re \n import codecs \n import mimetypes \n from werkzeug . _internal import _proxy_repr , _missing , _empty_stream \n <mask0> = re . compile ( r'<STR_LIT>' ) \n def is_immutable ( self ) : \n raise TypeError ( '<STR_LIT>' % self . __class__ . __name__ ) \n def iter_multi_items ( mapping ) : \n \"\"\"<STR_LIT>\"\"\" \n if isinstance ( mapping , MultiDict ) : \n for item in mapping . iteritems ( multi = True ) : \n yield item \n elif isinstance ( mapping , dict ) : \n for key , value in mapping . iteritems ( ) : \n if isinstance ( value , ( tuple , list ) ) : \n for value in value : \n yield key , value \n else : \n yield key , value \n else : \n for item in mapping : \n yield item \n class ImmutableListMixin ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def __reduce_ex__ ( self , protocol ) : \n return type ( self ) , ( list ( self ) , ) \n def __delitem__ ( self , key ) : \n is_immutable ( self ) \n def __delslice__ ( self , i , j ) : \n is_immutable ( self ) \n def __iadd__ ( self , other ) : \n is_immutable ( self ) \n __imul__ = __iadd__ \n def __setitem__ ( self , key , value ) : \n is_immutable ( self ) \n def __setslice__ ( self , i , j , value ) : \n is_immutable ( self ) \n def append ( self , item ) : \n is_immutable ( self ) \n remove = append \n def extend ( self , iterable ) : \n is_immutable ( self ) \n def insert ( self , pos , value ) : \n is_immutable ( self ) \n def pop ( self , index = - <NUM_LIT:1> ) : \n is_immutable ( self ) \n def reverse ( self ) : \n is_immutable ( self ) \n def sort ( self , cmp = None , key = None , reverse = None ) : \n is_immutable ( self ) \n class ImmutableList ( ImmutableListMixin , list ) : \n \"\"\"<STR_LIT>\"\"\" \n __repr__ = _proxy_repr ( list ) \n class ImmutableDictMixin ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def __reduce_ex__ ( self , protocol ) : \n return type ( self ) , ( dict ( self ) , ) \n def setdefault ( self , key , default = None ) : \n is_immutable ( self ) \n def update ( self , * args , ** kwargs ) : \n is_immutable ( self ) \n def pop ( self , key , default = None ) : \n is_immutable ( self ) \n def popitem ( self ) : \n is_immutable ( self ) \n def __setitem__ ( self , key , value ) : \n is_immutable ( self ) \n def __delitem__ ( self , key ) : \n is_immutable ( self ) \n def clear ( self ) : \n is_immutable ( self ) \n class ImmutableMultiDictMixin ( ImmutableDictMixin ) : \n \"\"\"<STR_LIT>\"\"\" \n def __reduce_ex__ ( self , protocol ) : \n return type ( self ) , ( self . items ( multi = True ) , ) \n def add ( self , key , value ) : \n is_immutable ( self ) \n def popitemlist ( self ) : \n is_immutable ( self ) \n def poplist ( self , key ) : \n is_immutable ( self ) \n def setlist ( self , key , new_list ) : \n is_immutable ( self ) \n def setlistdefault ( self , key , default_list = None ) : \n is_immutable ( self ) \n class UpdateDictMixin ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n on_update = None \n def calls_update ( name ) : \n def oncall ( self , * args , ** kw ) : \n rv = getattr ( super ( UpdateDictMixin , self ) , name ) ( * args , ** kw ) \n if self . on_update is not None : \n self . on_update ( self ) \n return rv \n oncall . __name__ = name \n return oncall \n __setitem__ = calls_update ( '<STR_LIT>' ) \n __delitem__ = calls_update ( '<STR_LIT>' ) \n clear = calls_update ( '<STR_LIT>' ) \n pop = calls_update ( '<STR_LIT>' ) \n popitem = calls_update ( '<STR_LIT>' ) \n setdefault = calls_update ( '<STR_LIT>' ) \n update = calls_update ( '<STR_LIT>' ) \n del calls_update \n class TypeConversionDict ( dict ) : \n \"\"\"<STR_LIT>\"\"\" \n def get ( self , key , default = None , type = None ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n rv = self [ key ] \n if type is not None : \n rv = type ( rv ) \n except ( KeyError , ValueError ) : \n rv = default \n return rv \n class ImmutableTypeConversionDict ( ImmutableDictMixin , TypeConversionDict ) : \n \"\"\"<STR_LIT>\"\"\" \n def copy ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return TypeConversionDict ( self ) \n def __copy__ ( self ) : \n return self \n class MultiDict ( TypeConversionDict ) : \n \"\"\"<STR_LIT>\"\"\" \n KeyError = None \n def __init__ ( self , mapping = None ) : \n if isinstance ( mapping , MultiDict ) : \n dict . __init__ ( self , ( ( k , l [ : ] ) for k , l in mapping . iterlists ( ) ) ) \n elif isinstance ( mapping , dict ) : \n tmp = { } \n for key , value in mapping . iteritems ( ) : \n if isinstance ( value , ( tuple , list ) ) : \n value = list ( value ) \n else : \n value = [ value ] \n tmp [ key ] = value \n dict . __init__ ( self , tmp ) \n else : \n tmp = { } \n for key , value in mapping or ( ) : \n tmp . setdefault ( key , [ ] ) . append ( value ) \n dict . __init__ ( self , tmp ) \n def __getstate__ ( self ) : \n return dict ( self . lists ( ) ) \n def __setstate__ ( self , value ) : \n dict . clear ( self ) \n dict . update ( self , value ) \n def __iter__ ( self ) : \n return self . iterkeys ( ) \n def __getitem__ ( self , key ) : \n \"\"\"<STR_LIT>\"\"\" \n if key in self : \n return dict . __getitem__ ( self , key ) [ <NUM_LIT:0> ] \n raise self . KeyError ( key ) \n def __setitem__ ( self , key , value ) : \n \"\"\"<STR_LIT>\"\"\" \n dict . __setitem__ ( self , key , [ value ] ) \n def add ( self , key , value ) : \n \"\"\"<STR_LIT>\"\"\" \n dict . setdefault ( self , key , [ ] ) . append ( value ) \n def getlist ( self , key , type = None ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n rv = dict . __getitem__ ( self , key ) \n except KeyError : \n return [ ] \n if type is None : \n return list ( rv ) \n result = [ ] \n for item in rv : \n try : \n result . append ( type ( item ) ) \n except ValueError : \n pass \n return result \n def setlist ( self , key , new_list ) : \n \"\"\"<STR_LIT>\"\"\" \n dict . __setitem__ ( self , key , list ( new_list ) ) \n def setdefault ( self , key , default = None ) : \n \"\"\"<STR_LIT>\"\"\" \n if key not in self : \n self [ key ] = default \n else : \n default = self [ key ] \n return default \n def setlistdefault ( self , key , default_list = None ) : \n \"\"\"<STR_LIT>\"\"\" \n if key not in self : \n default_list = list ( default_list or ( ) ) \n dict . __setitem__ ( self , key , default_list ) \n else : \n default_list = dict . __getitem__ ( self , key ) \n return default_list \n def items ( self , multi = False ) : \n \"\"\"<STR_LIT>\"\"\" \n return list ( self . iteritems ( multi ) ) \n def lists ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return list ( self . iterlists ( ) ) \n def values ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return [ self [ key ] for key in self . iterkeys ( ) ] \n def listvalues ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return list ( self . iterlistvalues ( ) ) \n def iteritems ( self , multi = False ) : \n \"\"\"<STR_LIT>\"\"\" \n for key , values in dict . iteritems ( self ) : \n if multi : \n for value in values : \n yield key , value \n else : \n yield key , values [ <NUM_LIT:0> ] \n def iterlists ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n for key , values in dict . iteritems ( self ) : \n yield key , list ( values ) \n def itervalues ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n for values in dict . itervalues ( self ) : \n yield values [ <NUM_LIT:0> ] \n def iterlistvalues ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n for values in dict . itervalues ( self ) : \n yield list ( values ) \n def copy ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . __class__ ( self ) \n def to_dict ( self , flat = True ) : \n \"\"\"<STR_LIT>\"\"\" \n if flat : \n return dict ( self . iteritems ( ) ) \n return dict ( self . lists ( ) ) \n def update ( self , other_dict ) : \n \"\"\"<STR_LIT>\"\"\" \n for key , value in iter_multi_items ( other_dict ) : \n MultiDict . add ( self , key , value ) \n def pop ( self , key , default = _missing ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n return dict . pop ( self , key ) [ <NUM_LIT:0> ] \n except KeyError , e : \n if default is not _missing : \n return default \n raise self . KeyError ( str ( e ) ) \n def popitem ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n item = dict . popitem ( self ) \n return ( item [ <NUM_LIT:0> ] , item [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] ) \n except KeyError , e : \n raise self . KeyError ( str ( e ) ) \n def poplist ( self , key ) : \n \"\"\"<STR_LIT>\"\"\" \n return dict . pop ( self , key , [ ] ) \n def popitemlist ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n return dict . popitem ( self ) \n except KeyError , e : \n raise self . KeyError ( str ( e ) ) \n def __repr__ ( self ) : \n return '<STR_LIT>' % ( self . __class__ . __name__ , self . items ( multi = True ) ) \n class _omd_bucket ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n __slots__ = ( '<STR_LIT>' , '<STR_LIT:key>' , '<STR_LIT:value>' , '<STR_LIT>' ) \n def __init__ ( self , omd , key , value ) : \n self . prev = omd . _last_bucket \n self . key = key \n self . value = value \n self . next = None \n if omd . _first_bucket is None : \n omd . _first_bucket = self \n if omd . _last_bucket is not None : \n omd . _last_bucket . next = self \n omd . _last_bucket = self \n def unlink ( self , omd ) : \n if self . prev : \n self . prev . next = self . next \n if self . next : \n self . next . prev = self . prev \n if omd . _first_bucket is self : \n omd . _first_bucket = self . next \n if omd . _last_bucket is self : \n omd . _last_bucket = self . prev \n class OrderedMultiDict ( MultiDict ) : \n \"\"\"<STR_LIT>\"\"\" \n KeyError = None \n def __init__ ( self , mapping = None ) : \n dict . __init__ ( self ) \n self . _first_bucket = self . _last_bucket = None \n if mapping is not None : \n OrderedMultiDict . update ( self , mapping ) \n def __eq__ ( self , other ) : \n if not isinstance ( other , MultiDict ) : \n return NotImplemented \n if isinstance ( other , OrderedMultiDict ) : \n iter1 = self . iteritems ( multi = True ) \n iter2 = other . iteritems ( multi = True ) \n try : \n for k1 , v1 in iter1 : \n k2 , v2 = iter2 . next ( ) \n if k1 != k2 or v1 != v2 : \n return False \n except StopIteration : \n return False \n try : \n iter2 . next ( ) \n except StopIteration : \n return True \n return False \n if len ( self ) != len ( other ) : \n return False \n for key , values in self . iterlists ( ) : \n if other . getlist ( key ) != values : \n return False \n return True \n def __ne__ ( self , other ) : \n return not self . __eq__ ( other ) \n def __reduce_ex__ ( self , protocol ) : \n return type ( self ) , ( self . items ( multi = True ) , ) \n def __getstate__ ( self ) : \n return self . items ( multi = True ) \n def __setstate__ ( self , values ) : \n dict . clear ( self ) \n for key , value in values : \n self . add ( key , value ) \n def __getitem__ ( self , key ) : \n if key in self : \n return dict . __getitem__ ( self , key ) [ <NUM_LIT:0> ] . value \n raise self . KeyError ( key ) \n def __setitem__ ( self , key , value ) : \n self . poplist ( key ) \n self . add ( key , value ) \n def __delitem__ ( self , key ) : \n self . pop ( key ) \n def iterkeys ( self ) : \n return ( key for key , value in self . iteritems ( ) ) \n def itervalues ( self ) : \n return ( value for key , value in self . iteritems ( ) ) \n def iteritems ( self , multi = False ) : \n ptr = self . _first_bucket \n if multi : \n while ptr is not None : \n yield ptr . key , ptr . value \n ptr = ptr . next \n else : \n returned_keys = set ( ) \n while ptr is not None : \n if ptr . key not in returned_keys : \n returned_keys . add ( ptr . key ) \n yield ptr . key , ptr . value \n ptr = ptr . next \n def iterlists ( self ) : \n returned_keys = set ( ) \n ptr = self . _first_bucket \n while ptr is not None : \n if ptr . key not in returned_keys : \n yield ptr . key , self . getlist ( ptr . key ) \n returned_keys . add ( ptr . key ) \n ptr = ptr . next \n def iterlistvalues ( self ) : \n for key , values in self . iterlists ( ) : \n yield values \n def add ( self , key , value ) : \n dict . setdefault ( self , key , [ ] ) . append ( _omd_bucket ( self , key , value ) ) \n def getlist ( self , key , type = None ) : \n try : \n rv = dict . __getitem__ ( self , key ) \n except KeyError : \n return [ ] \n if type is None : \n return [ x . value for x in rv ] \n result = [ ] \n for item in rv : \n try : \n result . append ( type ( item . value ) ) \n except ValueError : \n pass \n return result \n def setlist ( self , key , new_list ) : \n self . poplist ( key ) \n for value in new_list : \n self . add ( key , value ) \n def setlistdefault ( self , key , default_list = None ) : \n raise TypeError ( '<STR_LIT>' \n '<STR_LIT>' ) \n def update ( self , mapping ) : \n for key , value in iter_multi_items ( mapping ) : \n OrderedMultiDict . add ( self , key , value ) \n def poplist ( self , key ) : \n buckets = dict . pop ( self , key , ( ) ) \n for bucket in buckets : \n bucket . unlink ( self ) \n return [ x . value for x in buckets ] \n def pop ( self , key , default = _missing ) : \n try : \n buckets = dict . pop ( self , key ) \n except KeyError , e : \n if default is not _missing : \n return default \n raise self . KeyError ( str ( e ) ) \n for bucket in buckets : \n bucket . unlink ( self ) \n return buckets [ <NUM_LIT:0> ] . value \n def popitem ( self ) : \n try : \n key , buckets = dict . popitem ( self ) \n except KeyError , e : \n raise self . KeyError ( str ( e ) ) \n for bucket in buckets : \n bucket . unlink ( self ) \n return key , buckets [ <NUM_LIT:0> ] . value \n def popitemlist ( self ) : \n try : \n key , buckets = dict . popitem ( self ) \n except KeyError , e : \n raise self . KeyError ( str ( e ) ) \n for bucket in buckets : \n bucket . unlink ( self ) \n return key , [ x . value for x in buckets ] \n def _options_header_vkw ( value , kw ) : \n if not kw : \n return value \n return dump_options_header ( value , dict ( ( k . replace ( '<STR_LIT:_>' , '<STR_LIT:->' ) , v ) \n for k , v in kw . items ( ) ) ) \n class Headers ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n KeyError = None \n def __init__ ( self , defaults = None , _list = None ) : \n if _list is None : \n _list = [ ] \n self . _list = _list \n if defaults is not None : \n if isinstance ( defaults , ( list , Headers ) ) : \n self . _list . extend ( defaults ) \n else : \n self . extend ( defaults ) \n @ classmethod \n def linked ( cls , headerlist ) : \n \"\"\"<STR_LIT>\"\"\" \n return cls ( _list = headerlist ) \n def __getitem__ ( self , key , _index_operation = True ) : \n if _index_operation : \n if isinstance ( key , ( int , long ) ) : \n return self . _list [ key ] \n elif isinstance ( key , slice ) : \n return self . __class__ ( self . _list [ key ] ) \n ikey = key . lower ( ) \n for k , v in self . _list : \n if k . lower ( ) == ikey : \n return v \n raise self . KeyError ( key ) \n def __eq__ ( self , other ) : \n return other . __class__ is self . __class__ and set ( other . _list ) == set ( self . _list ) \n def __ne__ ( self , other ) : \n return not self . __eq__ ( other ) \n def get ( self , key , default = None , type = None ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n rv = self . __getitem__ ( key , _index_operation = False ) \n except KeyError : \n return default \n if type is None : \n return rv \n try : \n return type ( rv ) \n except ValueError : \n return default \n def getlist ( self , key , type = None ) : \n \"\"\"<STR_LIT>\"\"\" \n ikey = key . lower ( ) \n result = [ ] \n for k , v in self : \n if k . lower ( ) == ikey : \n if type is not None : \n try : \n v = type ( v ) \n except ValueError : \n continue \n result . append ( v ) \n return result \n def get_all ( self , name ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . getlist ( name ) \n def iteritems ( self , lower = False ) : \n for key , value in self : \n if lower : \n key = key . lower ( ) \n yield key , value \n def iterkeys ( self , lower = False ) : \n for key , _ in self . iteritems ( lower ) : \n yield key \n def itervalues ( self ) : \n for _ , value in self . iteritems ( ) : \n yield value \n def keys ( self , lower = False ) : \n return list ( self . iterkeys ( lower ) ) \n def values ( self ) : \n return list ( self . itervalues ( ) ) \n def items ( self , lower = False ) : \n return list ( self . iteritems ( lower ) ) \n def extend ( self , iterable ) : \n \"\"\"<STR_LIT>\"\"\" \n if isinstance ( iterable , dict ) : \n for key , value in iterable . iteritems ( ) : \n if isinstance ( value , ( tuple , list ) ) : \n for v in value : \n self . add ( key , v ) \n else : \n self . add ( key , value ) \n else : \n for key , value in iterable : \n self . add ( key , value ) \n def __delitem__ ( self , key , _index_operation = True ) : \n if _index_operation and isinstance ( key , ( int , long , slice ) ) : \n del self . _list [ key ] \n return \n key = key . lower ( ) \n new = [ ] \n for k , v in self . _list : \n if k . lower ( ) != key : \n new . append ( ( k , v ) ) \n self . _list [ : ] = new \n def remove ( self , key ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . __delitem__ ( key , _index_operation = False ) \n def pop ( self , key = None , default = _missing ) : \n \"\"\"<STR_LIT>\"\"\" \n if key is None : \n return self . _list . pop ( ) \n if isinstance ( key , ( int , long ) ) : \n return self . _list . pop ( key ) \n try : \n rv = self [ key ] \n self . remove ( key ) \n except KeyError : \n if default is not _missing : \n return default \n raise \n return rv \n def popitem ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . pop ( ) \n def __contains__ ( self , key ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n self . __getitem__ ( key , _index_operation = False ) \n except KeyError : \n return False \n return True \n has_key = __contains__ \n def __iter__ ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return iter ( self . _list ) \n def __len__ ( self ) : \n return len ( self . _list ) \n def add ( self , _key , _value , ** kw ) : \n \"\"\"<STR_LIT>\"\"\" \n self . _list . append ( ( _key , _options_header_vkw ( _value , kw ) ) ) \n def add_header ( self , _key , _value , ** _kw ) : \n \"\"\"<STR_LIT>\"\"\" \n self . add ( _key , _value , ** _kw ) \n def clear ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n del self . _list [ : ] \n def set ( self , _key , _value , ** kw ) : \n \"\"\"<STR_LIT>\"\"\" \n lc_key = _key . lower ( ) \n _value = _options_header_vkw ( _value , kw ) \n for idx , ( old_key , old_value ) in enumerate ( self . _list ) : \n if old_key . lower ( ) == lc_key : \n self . _list [ idx ] = ( _key , _value ) \n break \n else : \n return self . add ( _key , _value ) \n self . _list [ idx + <NUM_LIT:1> : ] = [ ( k , v ) for k , v in self . _list [ idx + <NUM_LIT:1> : ] \n if k . lower ( ) != lc_key ] \n def setdefault ( self , key , value ) : \n \"\"\"<STR_LIT>\"\"\" \n if key in self : \n return self [ key ] \n self . set ( key , value ) \n return value \n def __setitem__ ( self , key , value ) : \n \"\"\"<STR_LIT>\"\"\" \n if isinstance ( key , ( slice , int , long ) ) : \n self . _list [ key ] = value \n else : \n self . set ( key , value ) \n def to_list ( self , charset = '<STR_LIT:utf-8>' ) : \n \"\"\"<STR_LIT>\"\"\" \n result = [ ] \n for k , v in self : \n if isinstance ( v , unicode ) : \n v = v . encode ( charset ) \n else : \n v = str ( v ) \n result . append ( ( k , v ) ) \n return result \n def copy ( self ) : \n return self . __class__ ( self . _list ) \n def __copy__ ( self ) : \n return self . copy ( ) \n def __str__ ( self , charset = '<STR_LIT:utf-8>' ) : \n \"\"\"<STR_LIT>\"\"\" \n strs = [ ] \n for key , value in self . to_list ( charset ) : \n strs . append ( '<STR_LIT>' % ( key , value ) ) \n strs . append ( '<STR_LIT:\\r\\n>' ) \n return '<STR_LIT:\\r\\n>' . join ( strs ) \n def __repr__ ( self ) : \n return '<STR_LIT>' % ( \n self . __class__ . __name__ , \n list ( self ) \n ) \n class ImmutableHeadersMixin ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def __delitem__ ( self , key ) : \n is_immutable ( self ) \n def __setitem__ ( self , key , value ) : \n is_immutable ( self ) \n set = __setitem__ \n def add ( self , item ) : \n is_immutable ( self ) \n remove = add_header = add \n def extend ( self , iterable ) : \n is_immutable ( self ) \n def insert ( self , pos , value ) : \n is_immutable ( self ) \n def pop ( self , index = - <NUM_LIT:1> ) : \n is_immutable ( self ) \n def popitem ( self ) : \n is_immutable ( self ) \n def setdefault ( self , key , default ) : \n is_immutable ( self ) \n class EnvironHeaders ( ImmutableHeadersMixin , Headers ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , environ ) : \n self . environ = environ \n @ classmethod \n def linked ( cls , environ ) : \n raise TypeError ( '<STR_LIT>' \n '<STR_LIT>' % cls . __name__ ) \n def __eq__ ( self , other ) : \n return self . environ is other . environ \n def __getitem__ ( self , key , _index_operation = False ) : \n key = key . upper ( ) . replace ( '<STR_LIT:->' , '<STR_LIT:_>' ) \n if key in ( '<STR_LIT>' , '<STR_LIT>' ) : \n return self . environ [ key ] \n return self . environ [ '<STR_LIT>' + key ] \n def __len__ ( self ) : \n return len ( list ( iter ( self ) ) ) \n def __iter__ ( self ) : \n for key , value in self . environ . iteritems ( ) : \n if key . startswith ( '<STR_LIT>' ) and key not in ( '<STR_LIT>' , '<STR_LIT>' ) : \n yield key [ <NUM_LIT:5> : ] . replace ( '<STR_LIT:_>' , '<STR_LIT:->' ) . title ( ) , value \n elif key in ( '<STR_LIT>' , '<STR_LIT>' ) : \n yield key . replace ( '<STR_LIT:_>' , '<STR_LIT:->' ) . title ( ) , value \n def copy ( self ) : \n raise TypeError ( '<STR_LIT>' % self . __class__ . __name__ ) \n class CombinedMultiDict ( ImmutableMultiDictMixin , MultiDict ) : \n \"\"\"<STR_LIT>\"\"\" \n def __reduce_ex__ ( self , protocol ) : \n return type ( self ) , ( self . dicts , ) \n def __init__ ( self , dicts = None ) : \n self . dicts = dicts or [ ] \n @ classmethod \n def fromkeys ( cls ) : \n raise TypeError ( '<STR_LIT>' % \n cls . __name__ ) \n def __getitem__ ( self , key ) : \n for d in self . dicts : \n if key in d : \n return d [ key ] \n raise self . KeyError ( key ) \n def get ( self , key , default = None , type = None ) : \n for d in self . dicts : \n if key in d : \n if type is not None : \n try : \n return type ( d [ key ] ) \n except ValueError : \n continue \n return d [ key ] \n return default \n def getlist ( self , key , type = None ) : \n rv = [ ] \n for d in self . dicts : \n rv . extend ( d . getlist ( key , type ) ) \n return rv \n def keys ( self ) : \n rv = set ( ) \n for d in self . dicts : \n rv . update ( d . keys ( ) ) \n return list ( rv ) \n def iteritems ( self , multi = False ) : \n found = set ( ) \n for d in self . dicts : \n for key , value in d . iteritems ( multi ) : \n if multi : \n yield key , value \n elif key not in found : \n found . add ( key ) \n yield key , value \n def itervalues ( self ) : \n for key , value in self . iteritems ( ) : \n yield value \n def values ( self ) : \n return list ( self . itervalues ( ) ) \n def items ( self , multi = False ) : \n return list ( self . iteritems ( multi ) ) \n def iterlists ( self ) : \n rv = { } \n for d in self . dicts : \n for key , values in d . iterlists ( ) : \n rv . setdefault ( key , [ ] ) . extend ( values ) \n return rv . iteritems ( ) \n def lists ( self ) : \n return list ( self . iterlists ( ) ) \n def iterlistvalues ( self ) : \n return ( x [ <NUM_LIT:0> ] for x in self . lists ( ) ) \n def listvalues ( self ) : \n return list ( self . iterlistvalues ( ) ) \n def iterkeys ( self ) : \n return iter ( self . keys ( ) ) \n __iter__ = iterkeys \n def copy ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . __class__ ( self . dicts [ : ] ) \n def to_dict ( self , flat = True ) : \n \"\"\"<STR_LIT>\"\"\" \n rv = { } \n for d in reversed ( self . dicts ) : \n rv . update ( d . to_dict ( flat ) ) \n return rv \n def __len__ ( self ) : \n return len ( self . keys ( ) ) \n def __contains__ ( self , key ) : \n for d in self . dicts : \n if key in d : \n return True \n return False \n has_key = __contains__ \n def __repr__ ( self ) : \n return '<STR_LIT>' % ( self . __class__ . __name__ , self . dicts ) \n class FileMultiDict ( MultiDict ) : \n \"\"\"<STR_LIT>\"\"\" \n def add_file ( self , name , file , filename = None , content_type = None ) : \n \"\"\"<STR_LIT>\"\"\" \n if isinstance ( file , FileStorage ) : \n self [ name ] = file \n return \n if isinstance ( file , basestring ) : \n if filename is None : \n filename = file \n file = open ( file , '<STR_LIT:rb>' ) \n if filename and content_type is None : \n content_type = mimetypes . guess_type ( filename ) [ <NUM_LIT:0> ] or '<STR_LIT>' \n self [ name ] = FileStorage ( file , filename , name , content_type ) \n class ImmutableDict ( ImmutableDictMixin , dict ) : \n \"\"\"<STR_LIT>\"\"\" \n __repr__ = _proxy_repr ( dict ) \n def copy ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return dict ( self ) \n def __copy__ ( self ) : \n return self \n class ImmutableMultiDict ( ImmutableMultiDictMixin , MultiDict ) : \n \"\"\"<STR_LIT>\"\"\" \n def copy ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return MultiDict ( self ) \n def __copy__ ( self ) : \n return self \n class ImmutableOrderedMultiDict ( ImmutableMultiDictMixin , OrderedMultiDict ) : \n \"\"\"<STR_LIT>\"\"\" \n def copy ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return OrderedMultiDict ( self ) \n def __copy__ ( self ) : \n return self \n class Accept ( ImmutableList ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , values = ( ) ) : \n if values is None : \n list . __init__ ( self ) \n self . provided = False \n elif isinstance ( values , Accept ) : \n self . provided = values . provided \n list . __init__ ( self , values ) \n else : \n self . provided = True \n values = [ ( a , b ) for b , a in values ] \n values . sort ( ) \n values . reverse ( ) \n list . __init__ ( self , [ ( a , b ) for b , a in values ] ) \n def _value_matches ( self , value , item ) : \n \"\"\"<STR_LIT>\"\"\" \n return item == '<STR_LIT:*>' or item . lower ( ) == value . lower ( ) \n def __getitem__ ( self , key ) : \n \"\"\"<STR_LIT>\"\"\" \n if isinstance ( key , basestring ) : \n return self . quality ( key ) \n return list . __getitem__ ( self , key ) \n def quality ( self , key ) : \n \"\"\"<STR_LIT>\"\"\" \n for item , quality in self : \n if self . _value_matches ( key , item ) : \n return quality \n return <NUM_LIT:0> \n def __contains__ ( self , value ) : \n for item , quality in self : \n if self . _value_matches ( value , item ) : \n return True \n return False \n def __repr__ ( self ) : \n return '<STR_LIT>' % ( \n self . __class__ . __name__ , \n '<STR_LIT:U+002CU+0020>' . join ( '<STR_LIT>' % ( x , y ) for x , y in self ) \n ) \n def index ( self , key ) : \n \"\"\"<STR_LIT>\"\"\" \n if isinstance ( key , basestring ) : \n for idx , ( item , quality ) in enumerate ( self ) : \n if self . _value_matches ( key , item ) : \n return idx \n raise ValueError ( key ) \n return list . index ( self , key ) \n def find ( self , key ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n return self . index ( key ) \n except ValueError : \n return - <NUM_LIT:1> \n def values ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return list ( self . itervalues ( ) ) \n def itervalues ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n for item in self : \n yield item [ <NUM_LIT:0> ] \n def to_header ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n result = [ ] \n for value , quality in self : \n if quality != <NUM_LIT:1> : \n value = '<STR_LIT>' % ( value , quality ) \n result . append ( value ) \n return '<STR_LIT:U+002C>' . join ( result ) \n def __str__ ( self ) : \n return self . to_header ( ) \n def best_match ( self , matches , default = None ) : \n \"\"\"<STR_LIT>\"\"\" \n best_quality = - <NUM_LIT:1> \n result = default \n for server_item in matches : \n for client_item , quality in self : \n if quality <= best_quality : \n break \n if self . _value_matches ( client_item , server_item ) : \n best_quality = quality \n result = server_item \n return result \n @ property \n def best ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n if self : \n return self [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] \n class MIMEAccept ( Accept ) : \n \"\"\"<STR_LIT>\"\"\" \n def _value_matches ( self , value , item ) : \n def _normalize ( x ) : \n x = x . lower ( ) \n return x == '<STR_LIT:*>' and ( '<STR_LIT:*>' , '<STR_LIT:*>' ) or x . split ( '<STR_LIT:/>' , <NUM_LIT:1> ) \n if '<STR_LIT:/>' not in value : \n raise ValueError ( '<STR_LIT>' % value ) \n value_type , value_subtype = _normalize ( value ) \n if value_type == '<STR_LIT:*>' and value_subtype != '<STR_LIT:*>' : \n raise ValueError ( '<STR_LIT>' % value ) \n if '<STR_LIT:/>' not in item : \n return False \n item_type , item_subtype = _normalize ( item ) \n if item_type == '<STR_LIT:*>' and item_subtype != '<STR_LIT:*>' : \n return False \n return ( \n ( item_type == item_subtype == '<STR_LIT:*>' or \n value_type == value_subtype == '<STR_LIT:*>' ) or \n ( item_type == value_type and ( item_subtype == '<STR_LIT:*>' or \n value_subtype == '<STR_LIT:*>' or \n item_subtype == value_subtype ) ) \n ) \n @ property \n def accept_html ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return ( \n '<STR_LIT>' in self or \n '<STR_LIT>' in self or \n self . accept_xhtml \n ) \n @ property \n def accept_xhtml ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return ( \n '<STR_LIT>' in self or \n '<STR_LIT>' in self \n ) \n class LanguageAccept ( Accept ) : \n \"\"\"<STR_LIT>\"\"\" \n def _value_matches ( self , value , item ) : \n def _normalize ( language ) : \n return _locale_delim_re . split ( language . lower ( ) ) \n return item == '<STR_LIT:*>' or _normalize ( value ) == _normalize ( item ) \n class CharsetAccept ( Accept ) : \n \"\"\"<STR_LIT>\"\"\" \n def _value_matches ( self , value , item ) : \n def _normalize ( name ) : \n try : \n return codecs . lookup ( name ) . name \n except LookupError : \n return name . lower ( ) \n return item == '<STR_LIT:*>' or _normalize ( value ) == _normalize ( item ) \n def cache_property ( key , empty , type ) : \n \"\"\"<STR_LIT>\"\"\" \n return property ( lambda x : x . _get_cache_value ( key , empty , type ) , \n lambda x , v : x . _set_cache_value ( key , v , type ) , \n lambda x : x . _del_cache_value ( key ) , \n '<STR_LIT>' % key ) \n class _CacheControl ( UpdateDictMixin , dict ) : \n \"\"\"<STR_LIT>\"\"\" \n no_cache = cache_property ( '<STR_LIT>' , '<STR_LIT:*>' , None ) \n no_store = cache_property ( '<STR_LIT>' , None , bool ) \n max_age = cache_property ( '<STR_LIT>' , - <NUM_LIT:1> , int ) \n no_transform = cache_property ( '<STR_LIT>' , None , None ) \n def __init__ ( self , values = ( ) , on_update = None ) : \n dict . __init__ ( self , values or ( ) ) \n self . on_update = on_update \n self . provided = values is not None \n def _get_cache_value ( self , key , empty , type ) : \n \"\"\"<STR_LIT>\"\"\" \n if type is bool : \n return key in self \n if key in self : \n value = self [ key ] \n if value is None : \n return empty \n elif type is not None : \n try : \n value = type ( value ) \n except ValueError : \n pass \n return value \n def _set_cache_value ( self , key , value , type ) : \n \"\"\"<STR_LIT>\"\"\" \n if type is bool : \n if value : \n self [ key ] = None \n else : \n self . pop ( key , None ) \n else : \n if value is None : \n self . pop ( key ) \n elif value is True : \n self [ key ] = None \n else : \n self [ key ] = value \n def _del_cache_value ( self , key ) : \n \"\"\"<STR_LIT>\"\"\" \n if key in self : \n del self [ key ] \n def to_header ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return dump_header ( self ) \n def __str__ ( self ) : \n return self . to_header ( ) \n def __repr__ ( self ) : \n return '<STR_LIT>' % ( \n self . __class__ . __name__ , \n self . to_header ( ) \n ) \n class RequestCacheControl ( ImmutableDictMixin , _CacheControl ) : \n \"\"\"<STR_LIT>\"\"\" \n max_stale = cache_property ( '<STR_LIT>' , '<STR_LIT:*>' , int ) \n min_fresh = cache_property ( '<STR_LIT>' , '<STR_LIT:*>' , int ) \n no_transform = cache_property ( '<STR_LIT>' , None , None ) \n only_if_cached = cache_property ( '<STR_LIT>' , None , bool ) \n class ResponseCacheControl ( _CacheControl ) : \n \"\"\"<STR_LIT>\"\"\" \n public = cache_property ( '<STR_LIT>' , None , bool ) \n private = cache_property ( '<STR_LIT>' , '<STR_LIT:*>' , None ) \n must_revalidate = cache_property ( '<STR_LIT>' , None , bool ) \n proxy_revalidate = cache_property ( '<STR_LIT>' , None , bool ) \n s_maxage = cache_property ( '<STR_LIT>' , None , None ) \n _CacheControl . cache_property = staticmethod ( cache_property ) \n class CallbackDict ( UpdateDictMixin , dict ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , initial = None , on_update = None ) : \n dict . __init__ ( self , initial or ( ) ) \n self . on_update = on_update \n def __repr__ ( self ) : \n return '<STR_LIT>' % ( \n self . __class__ . __name__ , \n dict . __repr__ ( self ) \n ) \n class HeaderSet ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , headers = None , on_update = None ) : \n self . _headers = list ( headers or ( ) ) \n self . _set = set ( [ x . lower ( ) for x in self . _headers ] ) \n self . on_update = on_update \n def add ( self , header ) : \n \"\"\"<STR_LIT>\"\"\" \n self . update ( ( header , ) ) \n def remove ( self , header ) : \n \"\"\"<STR_LIT>\"\"\" \n key = header . lower ( ) \n if key not in self . _set : \n raise KeyError ( header ) \n self . _set . remove ( key ) \n for idx , key in enumerate ( self . _headers ) : \n if key . lower ( ) == header : \n del self . _headers [ idx ] \n break \n if self . on_update is not None : \n self . on_update ( self ) \n def update ( self , iterable ) : \n \"\"\"<STR_LIT>\"\"\" \n inserted_any = False \n for header in iterable : \n key = header . lower ( ) \n if key not in self . _set : \n self . _headers . append ( header ) \n self . _set . add ( key ) \n inserted_any = True \n if inserted_any and self . on_update is not None : \n self . on_update ( self ) \n def discard ( self , header ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n return self . remove ( header ) \n except KeyError : \n pass \n def find ( self , header ) : \n \"\"\"<STR_LIT>\"\"\" \n header = header . lower ( ) \n for idx , item in enumerate ( self . _headers ) : \n if item . lower ( ) == header : \n return idx \n return - <NUM_LIT:1> \n def index ( self , header ) : \n \"\"\"<STR_LIT>\"\"\" \n rv = self . find ( header ) \n if rv < <NUM_LIT:0> : \n raise IndexError ( header ) \n return rv \n def clear ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n self . _set . clear ( ) \n del self . _headers [ : ] \n if self . on_update is not None : \n self . on_update ( self ) \n def as_set ( self , preserve_casing = False ) : \n \"\"\"<STR_LIT>\"\"\" \n if preserve_casing : \n return set ( self . _headers ) \n return set ( self . _set ) \n def to_header ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return '<STR_LIT:U+002CU+0020>' . join ( map ( quote_header_value , self . _headers ) ) \n def __getitem__ ( self , idx ) : \n return self . _headers [ idx ] \n def __delitem__ ( self , idx ) : \n rv = self . _headers . pop ( idx ) \n self . _set . remove ( rv . lower ( ) ) \n if self . on_update is not None : \n self . on_update ( self ) \n def __setitem__ ( self , idx , value ) : \n old = self . _headers [ idx ] \n self . _set . remove ( old . lower ( ) ) \n self . _headers [ idx ] = value \n self . _set . add ( value . lower ( ) ) \n if self . on_update is not None : \n self . on_update ( self ) \n def __contains__ ( self , header ) : \n return header . lower ( ) in self . _set \n def __len__ ( self ) : \n return len ( self . _set ) \n def __iter__ ( self ) : \n return iter ( self . _headers ) \n def __nonzero__ ( self ) : \n return bool ( self . _set ) \n def __str__ ( self ) : \n return self . to_header ( ) \n def __repr__ ( self ) : \n return '<STR_LIT>' % ( \n self . __class__ . __name__ , \n self . _headers \n ) \n class ETags ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , strong_etags = None , weak_etags = None , star_tag = False ) : \n self . _strong = frozenset ( not star_tag and strong_etags or ( ) ) \n self . _weak = frozenset ( weak_etags or ( ) ) \n self . star_tag = star_tag \n def as_set ( self , include_weak = False ) : \n \"\"\"<STR_LIT>\"\"\" \n rv = set ( self . _strong ) \n if include_weak : \n rv . update ( self . _weak ) \n return rv \n def is_weak ( self , etag ) : \n \"\"\"<STR_LIT>\"\"\" \n return etag in self . _weak \n def contains_weak ( self , etag ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . is_weak ( etag ) or self . contains ( etag ) \n def contains ( self , etag ) : \n \"\"\"<STR_LIT>\"\"\" \n if self . star_tag : \n return True \n return etag in self . _strong \n def contains_raw ( self , etag ) : \n \"\"\"<STR_LIT>\"\"\" \n etag , weak = unquote_etag ( etag ) \n if weak : \n return self . contains_weak ( etag ) \n return self . contains ( etag ) \n def to_header ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n if self . star_tag : \n return '<STR_LIT:*>' \n return '<STR_LIT:U+002CU+0020>' . join ( \n [ '<STR_LIT>' % x for x in self . _strong ] + \n [ '<STR_LIT>' % x for x in self . _weak ] \n ) \n def __call__ ( self , etag = None , data = None , include_weak = False ) : \n if [ etag , data ] . count ( None ) != <NUM_LIT:1> : \n raise TypeError ( '<STR_LIT>' ) \n if etag is None : \n etag = generate_etag ( data ) \n if include_weak : \n if etag in self . _weak : \n return True \n return etag in self . _strong \n def __nonzero__ ( self ) : \n return bool ( self . star_tag or self . _strong ) \n def __str__ ( self ) : \n return self . to_header ( ) \n def __iter__ ( self ) : \n return iter ( self . _strong ) \n def __contains__ ( self , etag ) : \n return self . contains ( etag ) \n def __repr__ ( self ) : \n return '<STR_LIT>' % ( self . __class__ . __name__ , str ( self ) ) \n class Authorization ( ImmutableDictMixin , dict ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , auth_type , data = None ) : \n dict . __init__ ( self , data or { } ) \n self . type = auth_type \n username = property ( lambda x : x . get ( '<STR_LIT:username>' ) , doc = '''<STR_LIT>''' ) \n password = property ( lambda x : x . get ( '<STR_LIT:password>' ) , doc = '''<STR_LIT>''' ) \n realm = property ( lambda x : x . get ( '<STR_LIT>' ) , doc = '''<STR_LIT>''' ) \n nonce = property ( lambda x : x . get ( '<STR_LIT>' ) , doc = '''<STR_LIT>''' ) \n uri = property ( lambda x : x . get ( '<STR_LIT>' ) , doc = '''<STR_LIT>''' ) \n nc = property ( lambda x : x . get ( '<STR_LIT>' ) , doc = '''<STR_LIT>''' ) \n cnonce = property ( lambda x : x . get ( '<STR_LIT>' ) , doc = '''<STR_LIT>''' ) \n response = property ( lambda x : x . get ( '<STR_LIT>' ) , doc = '''<STR_LIT>''' ) \n opaque = property ( lambda x : x . get ( '<STR_LIT>' ) , doc = '''<STR_LIT>''' ) \n @ property \n def qop ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n def on_update ( header_set ) : \n if not header_set and '<STR_LIT>' in self : \n del self [ '<STR_LIT>' ] \n elif header_set : \n self [ '<STR_LIT>' ] = header_set . to_header ( ) \n return parse_set_header ( self . get ( '<STR_LIT>' ) , on_update ) \n class WWWAuthenticate ( UpdateDictMixin , dict ) : \n \"\"\"<STR_LIT>\"\"\" \n _require_quoting = frozenset ( [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) \n def __init__ ( self , auth_type = None , values = None , on_update = None ) : \n dict . __init__ ( self , values or ( ) ) \n if auth_type : \n self [ '<STR_LIT>' ] = auth_type \n self . on_update = on_update \n def set_basic ( self , realm = '<STR_LIT>' ) : \n \"\"\"<STR_LIT>\"\"\" \n dict . clear ( self ) \n dict . update ( self , { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : realm } ) \n if self . on_update : \n self . on_update ( self ) \n def set_digest ( self , realm , nonce , qop = ( '<STR_LIT>' , ) , opaque = None , \n algorithm = None , stale = False ) : \n \"\"\"<STR_LIT>\"\"\" \n d = { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : realm , \n '<STR_LIT>' : nonce , \n '<STR_LIT>' : dump_header ( qop ) \n } \n if stale : \n d [ '<STR_LIT>' ] = '<STR_LIT>' \n if opaque is not None : \n d [ '<STR_LIT>' ] = opaque \n if algorithm is not None : \n d [ '<STR_LIT>' ] = algorithm \n dict . clear ( self ) \n dict . update ( self , d ) \n if self . on_update : \n self . on_update ( self ) \n def to_header ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n d = dict ( self ) \n auth_type = d . pop ( '<STR_LIT>' , None ) or '<STR_LIT>' \n return '<STR_LIT>' % ( auth_type . title ( ) , '<STR_LIT:U+002CU+0020>' . join ( [ \n '<STR_LIT>' % ( key , quote_header_value ( value , \n allow_token = key not in self . _require_quoting ) ) \n for key , value in d . iteritems ( ) \n ] ) ) \n def __str__ ( self ) : \n return self . to_header ( ) \n def __repr__ ( self ) : \n return '<STR_LIT>' % ( \n self . __class__ . __name__ , \n self . to_header ( ) \n ) \n def auth_property ( name , doc = None ) : \n \"\"\"<STR_LIT>\"\"\" \n def _set_value ( self , value ) : \n if value is None : \n self . pop ( name , None ) \n else : \n self [ name ] = str ( value ) \n return property ( lambda x : x . get ( name ) , _set_value , doc = doc ) \n def _set_property ( name , doc = None ) : \n def fget ( self ) : \n def on_update ( header_set ) : \n if not header_set and name in self : \n del self [ name ] \n elif header_set : \n self [ name ] = header_set . to_header ( ) \n return parse_set_header ( self . get ( name ) , on_update ) \n return property ( fget , doc = doc ) \n type = auth_property ( '<STR_LIT>' , doc = '''<STR_LIT>''' ) \n realm = auth_property ( '<STR_LIT>' , doc = '''<STR_LIT>''' ) \n domain = _set_property ( '<STR_LIT>' , doc = '''<STR_LIT>''' ) \n nonce = auth_property ( '<STR_LIT>' , doc = '''<STR_LIT>''' ) \n opaque = auth_property ( '<STR_LIT>' , doc = '''<STR_LIT>''' ) \n algorithm = auth_property ( '<STR_LIT>' , doc = '''<STR_LIT>''' ) \n qop = _set_property ( '<STR_LIT>' , doc = '''<STR_LIT>''' ) \n def _get_stale ( self ) : \n val = self . get ( '<STR_LIT>' ) \n if val is not None : \n return val . lower ( ) == '<STR_LIT:true>' \n def _set_stale ( self , value ) : \n if value is None : \n self . pop ( '<STR_LIT>' , None ) \n else : \n self [ '<STR_LIT>' ] = value and '<STR_LIT>' or '<STR_LIT>' \n stale = property ( _get_stale , _set_stale , doc = '''<STR_LIT>''' ) \n del _get_stale , _set_stale \n auth_property = staticmethod ( auth_property ) \n del _set_property \n class FileStorage ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , stream = None , filename = None , name = None , \n content_type = '<STR_LIT>' , content_length = - <NUM_LIT:1> , \n headers = None ) : \n self . name = name \n self . stream = stream or _empty_stream \n self . filename = filename or getattr ( stream , '<STR_LIT:name>' , None ) \n self . content_type = content_type \n self . content_length = content_length \n if headers is None : \n headers = Headers ( ) \n self . headers = headers \n def save ( self , dst , buffer_size = <NUM_LIT> ) : \n \"\"\"<STR_LIT>\"\"\" \n from shutil import copyfileobj \n close_dst = False \n if isinstance ( dst , basestring ) : \n dst = file ( dst , '<STR_LIT:wb>' ) \n close_dst = True \n try : \n copyfileobj ( self . stream , dst , buffer_size ) \n finally : \n if close_dst : \n dst . close ( ) \n def close ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n self . stream . close ( ) \n except : \n pass \n def __nonzero__ ( self ) : \n return bool ( self . filename ) \n def __getattr__ ( self , name ) : \n return getattr ( self . stream , name ) \n def __iter__ ( self ) : \n return iter ( self . readline , '<STR_LIT>' ) \n def __repr__ ( self ) : \n return '<STR_LIT>' % ( \n self . __class__ . __name__ , \n self . filename , \n self . content_type \n ) \n from werkzeug . http import dump_options_header , dump_header , generate_etag , quote_header_value , parse_set_header , unquote_etag \n from werkzeug . exceptions import BadRequest \n for _cls in MultiDict , OrderedMultiDict , CombinedMultiDict , Headers , EnvironHeaders : \n _cls . KeyError = BadRequest . wrap ( KeyError , _cls . __name__ + '<STR_LIT>' ) \n del _cls \n", "gt": "_locale_delim_re"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import sys \n import os \n from werkzeug . utils import import_string \n from kay . management . shell import ( \n rshell , shell , clear_datastore , create_user , \n ) \n from kay . management . runserver import runserver_passthru_argv \n from kay . management . startapp import startapp \n from kay . management . startapp import startproject \n from kay . management . appcfg import do_appcfg_passthru_argv \n from kay . management . bulkloader import ( \n do_bulkloader_passthru_argv , dump_all , restore_all , \n ) \n from kay . management . test import do_runtest \n from kay . management . preparse import do_preparse_bundle \n from kay . management . preparse import do_preparse_apps \n from kay . management . extract_messages import do_extract_messages \n from kay . management . add_translations import do_add_translations \n from kay . management . update_translations import do_update_translations \n from kay . management . compile_translations import do_compile_translations \n from kay . management . wxadmin import do_wxadmin \n from kay . management . compile_media import do_compile_media \n from kay . conf import settings \n <mask0> = dump_all \n action_restore_all = restore_all \n action_shell = shell \n action_rshell = rshell \n action_startapp = startapp \n action_startproject = startproject \n action_test = do_runtest \n action_preparse_bundle = do_preparse_bundle \n action_preparse_apps = do_preparse_apps \n action_extract_messages = do_extract_messages \n action_add_translations = do_add_translations \n action_update_translations = do_update_translations \n action_compile_translations = do_compile_translations \n action_appcfg = do_appcfg_passthru_argv \n action_runserver = runserver_passthru_argv \n action_bulkloader = do_bulkloader_passthru_argv \n action_clear_datastore = clear_datastore \n action_create_user = create_user \n action_wxadmin = do_wxadmin \n action_compile_media = do_compile_media \n additional_actions = [ ] \n for app in settings . INSTALLED_APPS : \n try : \n appmod = import_string ( app ) \n if not os . path . exists ( os . path . join ( os . path . dirname ( appmod . __file__ ) , \n '<STR_LIT>' ) ) : \n continue \n management_mod = import_string ( \"<STR_LIT>\" % app ) \n for name , val in vars ( management_mod ) . iteritems ( ) : \n if name . startswith ( \"<STR_LIT>\" ) : \n locals ( ) [ name ] = getattr ( management_mod , name ) \n additional_actions . append ( name ) \n except Exception , e : \n import traceback \n sys . stderr . write ( '<STR_LIT:\\n>' . join ( traceback . format_exception ( * ( sys . exc_info ( ) ) ) ) ) \n pass \n __all__ = [ \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , \n ] + additional_actions \n def print_status ( msg ) : \n print ( msg ) \n sys . stdout . flush ( ) \n", "gt": "action_dump_all"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n from kay . routing import ( \n ViewGroup , Rule \n ) \n <mask0> = [ \n ViewGroup ( \n Rule ( '<STR_LIT>' , endpoint = '<STR_LIT>' , \n view = ( '<STR_LIT>' , ( ) , { } ) ) , \n Rule ( '<STR_LIT>' , endpoint = '<STR_LIT>' , \n view = ( '<STR_LIT>' , ( ) , { } ) ) , \n Rule ( '<STR_LIT>' , endpoint = '<STR_LIT>' , \n view = '<STR_LIT>' ) , \n ) \n ] \n", "gt": "view_groups"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n from google . appengine . ext import db \n from kay . utils . forms import ValidationError \n from kay . utils . forms . modelform import ModelForm \n class MaxLengthValidator ( object ) : \n def __init__ ( self , length ) : \n self . length = length \n def __call__ ( self , val ) : \n if len ( val ) > self . length : \n raise ValidationError ( \"<STR_LIT>\" ) \n return True \n class TestModel ( db . Model ) : \n <mask0> = db . IntegerProperty ( required = True ) \n data_field = db . StringProperty ( required = True , \n validator = MaxLengthValidator ( <NUM_LIT:20> ) ) \n is_active = db . BooleanProperty ( required = True ) \n string_list_field = db . StringListProperty ( required = True ) \n class TestModel2 ( db . Model ) : \n number = db . IntegerProperty ( required = True ) \n data_field = db . StringProperty ( required = True , \n validator = MaxLengthValidator ( <NUM_LIT:20> ) ) \n is_active = db . BooleanProperty ( required = True ) \n string_list_field = db . StringListProperty ( required = True ) \n class TestModelForm ( ModelForm ) : \n csrf_protected = False \n class Meta ( ) : \n model = TestModel \n def __init__ ( self , instance = None , initial = None ) : \n super ( TestModelForm , self ) . __init__ ( instance , initial ) \n self . string_list_field . min_size = <NUM_LIT:1> \n class JsonTestModel ( db . Model ) : \n s = db . StringProperty ( ) \n i = db . IntegerProperty ( ) \n b = db . BooleanProperty ( ) \n l = db . StringListProperty ( ) \n r = db . ReferenceProperty ( ) \n class ModelFormTestModel ( db . Model ) : \n s_name = db . StringProperty ( ) \n zip_code = db . StringProperty ( ) \n addr = db . StringProperty ( ) \n class ModelFormTestForm ( ModelForm ) : \n csrf_protected = False \n class Meta : \n model = ModelFormTestModel \n fields = ( '<STR_LIT>' ) \n class ValidationTestModel ( db . Model ) : \n slist = db . StringListProperty ( ) \n class ValidationTestForm ( ModelForm ) : \n csrf_protected = False \n class Meta : \n model = ValidationTestModel \n def context_validate ( self , data ) : \n raise ValidationError ( \"<STR_LIT>\" ) \n", "gt": "number"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import re \n import sys \n from os import path , listdir , mkdir \n def compile_file ( env , src_path , dst_path , encoding = '<STR_LIT:utf-8>' , base_dir = '<STR_LIT>' ) : \n \"\"\"<STR_LIT>\"\"\" \n <mask0> = file ( src_path , '<STR_LIT:r>' ) \n try : \n source = src_file . read ( ) . decode ( encoding ) \n except Exception , e : \n sys . stderr . write ( \"<STR_LIT>\" \n \"<STR_LIT>\" % src_path ) \n raise \n src_file . close ( ) \n name = src_path . replace ( base_dir , '<STR_LIT>' ) \n raw = env . compile ( source , name = name , filename = name , raw = True ) \n dst_file = open ( dst_path , '<STR_LIT:wb>' ) \n dst_file . write ( raw ) \n dst_file . close ( ) \n def compile_dir ( env , src_path , dst_path , pattern = r'<STR_LIT>' , \n encoding = '<STR_LIT:utf-8>' , base_dir = None , \n negative_pattern = r'<STR_LIT>' ) : \n \"\"\"<STR_LIT>\"\"\" \n if base_dir is None : \n base_dir = src_path \n for filename in listdir ( src_path ) : \n if filename . startswith ( \"<STR_LIT:.>\" ) : \n continue \n src_name = path . join ( src_path , filename ) \n dst_name = path . join ( dst_path , filename ) \n if path . isdir ( src_name ) : \n if not path . isdir ( dst_name ) : \n mkdir ( dst_name ) \n compile_dir ( env , src_name , dst_name , encoding = encoding , \n base_dir = base_dir ) \n elif path . isfile ( src_name ) and re . match ( pattern , filename ) and not re . match ( negative_pattern , filename ) : \n compile_file ( env , src_name , dst_name , encoding = encoding , \n base_dir = base_dir ) \n", "gt": "src_file"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import api \n import random \n import imp \n import shutil \n import os \n from os import path \n from functools import partial \n from bson import json_util \n from api . common import InternalException , SevereInternalException \n <mask0> = api . logger . use ( __name__ ) \n modifiable_problem_fields = [ \"<STR_LIT:description>\" ] \n seed = \"<STR_LIT>\" \n def is_autogen_problem ( pid ) : \n \"\"\"<STR_LIT>\"\"\" \n return api . problem . get_problem ( pid = pid ) . get ( \"<STR_LIT>\" , False ) \n def get_metadata_path ( pid , n ) : \n \"\"\"<STR_LIT>\"\"\" \n return path . join ( get_instance_path ( pid , n = n , public = False ) , \"<STR_LIT>\" ) \n def write_metadata ( pid , n , data ) : \n \"\"\"<STR_LIT>\"\"\" \n metadata_path = get_metadata_path ( pid , n ) \n with open ( metadata_path , \"<STR_LIT:w>\" ) as f : \n f . write ( json_util . dumps ( data ) ) \n @ api . cache . memoize ( timeout = <NUM_LIT> , fast = True ) \n def read_metadata ( pid , n ) : \n \"\"\"<STR_LIT>\"\"\" \n metadata_path = get_metadata_path ( pid , n ) \n with open ( metadata_path , \"<STR_LIT:r>\" ) as f : \n return json_util . loads ( f . read ( ) ) \n def build_problem_instances ( pid , instances ) : \n \"\"\"<STR_LIT>\"\"\" \n problem = api . problem . get_problem ( pid = pid ) \n if not is_autogen_problem ( pid ) : \n raise InternalException ( \"<STR_LIT>\" . format ( problem [ \"<STR_LIT:name>\" ] ) ) \n previous_state = seed_generator ( \"<STR_LIT>\" , pid ) \n instance_path , static_instance_path = get_instance_path ( pid ) , get_static_instance_path ( pid ) \n for autogen_path in [ instance_path , static_instance_path ] : \n log . debug ( \"<STR_LIT>\" , autogen_path ) \n if not path . isdir ( autogen_path ) : \n log . debug ( \"<STR_LIT>\" ) \n os . makedirs ( autogen_path ) \n for n in range ( instances ) : \n log . debug ( \"<STR_LIT>\" , problem [ \"<STR_LIT:name>\" ] , str ( n ) ) \n build = get_generator ( pid ) . generate ( random , pid , api . autogen_tools , n ) \n autogen_instance_path = get_instance_path ( pid , n = n ) \n file_type_paths = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : get_instance_path ( pid , n = n , public = True ) , \n \"<STR_LIT>\" : get_instance_path ( pid , n = n , public = False ) \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : get_static_instance_path ( pid , public = True ) , \n \"<STR_LIT>\" : get_static_instance_path ( pid , public = False ) \n } \n } \n for _ , file_types in file_type_paths . items ( ) : \n for _ , autogen_path in file_types . items ( ) : \n if not path . isdir ( autogen_path ) : \n os . makedirs ( autogen_path ) \n problem_updates = build . get ( \"<STR_LIT>\" , None ) \n if problem_updates is None : \n raise InternalException ( \"<STR_LIT>\" . format ( problem [ \"<STR_LIT>\" ] ) ) \n write_metadata ( pid , n , problem_updates ) \n for file_type , listings in build . items ( ) : \n destination_type = file_type_paths . get ( file_type , None ) \n if destination_type is not None : \n for listing in listings : \n destination = destination_type . get ( listing , None ) \n if destination is not None : \n files = listings [ listing ] \n for f , name in files : \n if path . isfile ( f ) : \n shutil . copyfile ( f , path . join ( destination , name ) ) \n elif path . isdir ( f ) : \n shutil . copytree ( f , autogen_instance_path ) \n api . autogen_tools . clear_build_directories ( ) \n log . debug ( \"<STR_LIT>\" ) \n random . setstate ( previous_state ) \n def get_generator_path ( pid ) : \n \"\"\"<STR_LIT>\"\"\" \n problem = api . problem . get_problem ( pid = pid ) \n if not is_autogen_problem ( pid ) : \n raise InternalException ( \"<STR_LIT>\" ) \n if not problem . get ( \"<STR_LIT>\" , False ) : \n raise InternalException ( \"<STR_LIT>\" . format ( problem [ \"<STR_LIT:name>\" ] ) ) \n return path . join ( api . problem . grader_base_path , problem [ \"<STR_LIT>\" ] ) \n def get_generator ( pid ) : \n \"\"\"<STR_LIT>\"\"\" \n generator_path = get_generator_path ( pid ) \n if not path . isfile ( generator_path ) : \n raise InternalException ( \"<STR_LIT>\" . format ( generator_path ) ) \n return imp . load_source ( generator_path [ : - <NUM_LIT:3> ] , generator_path ) \n def get_seed ( pid , tid ) : \n \"\"\"<STR_LIT>\"\"\" \n return seed + tid + pid \n def seed_generator ( pid , tid ) : \n \"\"\"<STR_LIT>\"\"\" \n previous_state = random . getstate ( ) \n random . seed ( get_seed ( pid , tid ) ) \n return previous_state \n @ api . cache . memoize ( timeout = <NUM_LIT> , fast = True ) \n def get_instance_number ( pid , tid ) : \n \"\"\"<STR_LIT>\"\"\" \n previous_state = seed_generator ( tid , pid ) \n total_instances = get_number_of_instances ( pid ) \n if total_instances == <NUM_LIT:0> : \n raise InternalException ( \"<STR_LIT>\" . format ( pid ) ) \n instance_number = random . randint ( <NUM_LIT:0> , total_instances - <NUM_LIT:1> ) \n random . setstate ( previous_state ) \n return instance_number \n @ api . cache . memoize ( timeout = <NUM_LIT> , fast = True ) \n def get_number_of_instances ( pid ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n return [ dirname . isdigit ( ) for dirname in os . listdir ( get_instance_path ( pid , public = False ) ) ] . count ( True ) \n except FileNotFoundError : \n raise InternalException ( \"<STR_LIT>\" ) \n def get_static_instance_path ( pid , public = True ) : \n \"\"\"<STR_LIT>\"\"\" \n return path . abspath ( path . join ( get_instance_path ( pid , public = public ) , \"<STR_LIT>\" ) ) \n def get_instance_path ( pid , n = \"<STR_LIT>\" , public = True ) : \n \"\"\"<STR_LIT>\"\"\" \n generator_path = get_generator_path ( pid ) \n name = api . problem . get_problem ( pid ) [ \"<STR_LIT:name>\" ] \n instance_path = path . join ( path . dirname ( generator_path ) , \"<STR_LIT>\" , name , str ( n ) ) \n if public : \n instance_path = path . join ( instance_path , \"<STR_LIT>\" ) \n return path . abspath ( instance_path ) \n @ api . cache . memoize ( timeout = <NUM_LIT> , fast = True ) \n def get_problem_instance ( pid , tid ) : \n \"\"\"<STR_LIT>\"\"\" \n problem = api . problem . get_problem ( pid = pid ) \n n = get_instance_number ( pid , tid ) \n metadata = read_metadata ( pid , n ) \n if not set ( metadata ) . issubset ( modifiable_problem_fields ) : \n invalid_keys = set ( metadata ) . difference ( modifiable_problem_fields ) \n raise InternalException ( \"<STR_LIT>\" . format ( pid , invalid_keys ) ) \n problem . update ( metadata ) \n return problem \n def grade_problem_instance ( pid , tid , key ) : \n \"\"\"<STR_LIT>\"\"\" \n if not is_autogen_problem ( pid ) : \n raise InternalException ( \"<STR_LIT>\" . format ( pid ) ) \n problem = api . problem . get_problem ( pid ) \n n = get_instance_number ( pid , tid ) \n grader_problem_instance = GraderProblemInstance ( pid , tid , n ) \n grader = api . problem . get_grader ( pid ) \n try : \n correct , message = grader . grade ( grader_problem_instance , key ) \n except Exception as e : \n raise SevereInternalException ( \"<STR_LIT>\" . format ( pid , str ( e ) ) ) \n return { \n \"<STR_LIT>\" : correct , \n \"<STR_LIT>\" : problem [ \"<STR_LIT>\" ] , \n \"<STR_LIT:message>\" : message \n } \n class GraderProblemInstance ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , pid , tid , n ) : \n self . instance = n \n self . get_instance_path = partial ( get_instance_path , pid , n = n ) \n self . seed_generator = partial ( seed_generator , pid , tid ) \n self . write_metadata = partial ( write_metadata , pid , n ) \n self . read_metadata = partial ( read_metadata , pid ) \n", "gt": "log"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n def generate ( random , pid , tools , n ) : \n \"\"\"<STR_LIT>\"\"\" \n <mask0> = open ( \"<STR_LIT>\" , \"<STR_LIT:w>\" ) \n k = str ( random . randint ( <NUM_LIT:0> , <NUM_LIT:1000> ) ) \n f . write ( k ) \n f . close ( ) \n return { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ] , \n \"<STR_LIT>\" : [ ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ] \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ] , \n \"<STR_LIT>\" : [ ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ] \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT:description>\" : \"<STR_LIT>\" + k + \"<STR_LIT>\" \n } \n } \n", "gt": "f"}
{"input": "\n import IECore \n import GafferUI \n import GafferScene \n import GafferSceneUI \n import os \n <mask0> = script \n scriptWindow = GafferUI . ScriptWindow . acquire ( script ) \n layout = eval ( \"<STR_LIT>\" ) \n scriptWindow . setLayout ( layout ) \n scriptWindow . _Widget__qtWidget . resize ( <NUM_LIT> , <NUM_LIT> ) \n for nodeName in [ '<STR_LIT>' ] : \n script . selection ( ) . add ( script . descendant ( nodeName ) ) \n script . context ( ) [ \"<STR_LIT>\" ] = GafferScene . PathMatcherData ( GafferScene . PathMatcher ( [ '<STR_LIT:/>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) ) \n script . context ( ) [ \"<STR_LIT>\" ] = IECore . StringVectorData ( [ \"<STR_LIT>\" ] ) \n", "gt": "scriptNode"}
{"input": "\n import os \n import glob \n import IECore \n class convertAnimCache ( IECore . Op ) : \n def __init__ ( self ) : \n IECore . Op . __init__ ( self , \"<STR_LIT>\" , IECore . FileSequenceParameter ( \"<STR_LIT:result>\" , \"<STR_LIT>\" ) ) \n self . parameters ( ) . addParameters ( \n [ \n IECore . FileSequenceParameter ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n defaultValue = \"<STR_LIT>\" , \n allowEmptyString = False , \n check = IECore . FileSequenceParameter . CheckType . MustExist , \n extensions = \"<STR_LIT>\" , \n ) , \n IECore . FileSequenceParameter ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n defaultValue = \"<STR_LIT>\" , \n allowEmptyString = False , \n extensions = \"<STR_LIT>\" , \n ) , \n ] , \n ) \n def doOperation ( self , args ) : \n <mask0> = self . parameters ( ) [ \"<STR_LIT>\" ] . getFileSequenceValue ( ) \n dst = self . parameters ( ) [ \"<STR_LIT>\" ] . getFileSequenceValue ( ) \n if isinstance ( dst . frameList , IECore . EmptyFrameList ) : \n dst . frameList = src . frameList \n for ( sf , df ) in zip ( src . fileNames ( ) , dst . fileNames ( ) ) : \n sc = IECore . AttributeCache ( sf , IECore . IndexedIOOpenMode . Read ) \n dc = IECore . AttributeCache ( df , IECore . IndexedIOOpenMode . Write ) \n combinedBound = IECore . Box3f ( ) \n for objectName in sc . objects ( ) : \n p = b = None \n with IECore . IgnoredExceptions ( Exception ) : \n p = sc . read ( objectName , \"<STR_LIT>\" ) \n b = sc . read ( objectName , \"<STR_LIT>\" ) \n if p is not None and b is not None : \n combinedBound . extendBy ( b . value ) \n dc . write ( \"<STR_LIT:->\" + objectName , \"<STR_LIT>\" , p ) \n dc . write ( \"<STR_LIT:->\" + objectName , \"<STR_LIT>\" , b ) \n dc . write ( \"<STR_LIT:->\" , \"<STR_LIT>\" , IECore . Box3fData ( combinedBound ) ) \n return args [ \"<STR_LIT>\" ] . value \n IECore . registerRunTimeTyped ( convertAnimCache ) \n", "gt": "src"}
{"input": "\n import os \n import unittest \n import subprocess32 as subprocess \n import IECore \n import Gaffer \n import GafferTest \n import GafferScene \n import GafferAppleseed \n import GafferAppleseedTest \n class AppleseedRenderTest ( GafferTest . TestCase ) : \n def setUp ( self ) : \n GafferTest . TestCase . setUp ( self ) \n self . __scriptFileName = self . temporaryDirectory ( ) + \"<STR_LIT>\" \n def testExecute ( self ) : \n <mask0> = Gaffer . ScriptNode ( ) \n s [ \"<STR_LIT>\" ] = GafferScene . Plane ( ) \n s [ \"<STR_LIT>\" ] = GafferAppleseed . AppleseedRender ( ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT>\" ] = Gaffer . Expression ( ) \n s [ \"<STR_LIT>\" ] . setExpression ( \"<STR_LIT>\" + self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] . setValue ( self . __scriptFileName ) \n s . save ( ) \n p = subprocess . Popen ( \n \"<STR_LIT>\" + self . __scriptFileName + \"<STR_LIT>\" , \n shell = True , \n stderr = subprocess . PIPE , \n ) \n p . wait ( ) \n self . failIf ( p . returncode ) \n for i in range ( <NUM_LIT:1> , <NUM_LIT:4> ) : \n self . failUnless ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" % i ) ) \n def testWaitForImage ( self ) : \n s = Gaffer . ScriptNode ( ) \n s [ \"<STR_LIT>\" ] = GafferScene . Plane ( ) \n s [ \"<STR_LIT>\" ] = GafferScene . Outputs ( ) \n s [ \"<STR_LIT>\" ] . addOutput ( \n \"<STR_LIT>\" , \n IECore . Display ( \n self . temporaryDirectory ( ) + \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n { } \n ) \n ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT>\" ] = GafferAppleseed . AppleseedRender ( ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] . setValue ( self . __scriptFileName ) \n s . save ( ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . execute ( ) \n self . failUnless ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) ) \n def testExecuteWithStringSubstitutions ( self ) : \n s = Gaffer . ScriptNode ( ) \n s [ \"<STR_LIT>\" ] = GafferScene . Plane ( ) \n s [ \"<STR_LIT>\" ] = GafferAppleseed . AppleseedRender ( ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] . setValue ( self . __scriptFileName ) \n s . save ( ) \n p = subprocess . Popen ( \n \"<STR_LIT>\" + self . __scriptFileName + \"<STR_LIT>\" , \n shell = True , \n stderr = subprocess . PIPE , \n ) \n p . wait ( ) \n self . failIf ( p . returncode ) \n for i in range ( <NUM_LIT:1> , <NUM_LIT:4> ) : \n self . failUnless ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" % i ) ) \n def testImageOutput ( self ) : \n s = Gaffer . ScriptNode ( ) \n s [ \"<STR_LIT>\" ] = GafferScene . Plane ( ) \n s [ \"<STR_LIT>\" ] = GafferScene . Outputs ( ) \n s [ \"<STR_LIT>\" ] . addOutput ( \n \"<STR_LIT>\" , \n IECore . Display ( \n self . temporaryDirectory ( ) + \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n { } \n ) \n ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT>\" ] = GafferAppleseed . AppleseedRender ( ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] . setValue ( self . __scriptFileName ) \n s . save ( ) \n c = Gaffer . Context ( ) \n for i in range ( <NUM_LIT:1> , <NUM_LIT:4> ) : \n c . setFrame ( i ) \n with c : \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . execute ( ) \n for i in range ( <NUM_LIT:1> , <NUM_LIT:4> ) : \n self . failUnless ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" % i ) ) \n def testTypeNamePrefixes ( self ) : \n self . assertTypeNamesArePrefixed ( GafferAppleseed ) \n self . assertTypeNamesArePrefixed ( GafferAppleseedTest ) \n def testDefaultNames ( self ) : \n self . assertDefaultNamesAreCorrect ( GafferAppleseed ) \n self . assertDefaultNamesAreCorrect ( GafferAppleseedTest ) \n def testNodesConstructWithDefaultValues ( self ) : \n self . assertNodesConstructWithDefaultValues ( GafferAppleseed ) \n self . assertNodesConstructWithDefaultValues ( GafferAppleseedTest ) \n def testDirectoryCreation ( self ) : \n s = Gaffer . ScriptNode ( ) \n s [ \"<STR_LIT>\" ] . addMember ( \"<STR_LIT>\" , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] . addMember ( \"<STR_LIT>\" , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] = GafferScene . Plane ( ) \n s [ \"<STR_LIT>\" ] = GafferScene . Outputs ( ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT>\" ] . addOutput ( \n \"<STR_LIT>\" , \n IECore . Display ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n { } \n ) \n ) \n s [ \"<STR_LIT>\" ] = GafferAppleseed . AppleseedRender ( ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT>\" ) \n self . assertFalse ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) ) \n self . assertFalse ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) ) \n self . assertFalse ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) ) \n self . assertFalse ( os . path . exists ( self . __scriptFileName ) ) \n s [ \"<STR_LIT>\" ] . setValue ( self . __scriptFileName ) \n s . save ( ) \n with s . context ( ) : \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . execute ( ) \n self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) ) \n self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) ) \n self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) ) \n self . assertTrue ( os . path . exists ( self . __scriptFileName ) ) \n with s . context ( ) : \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . execute ( ) \n self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) ) \n self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) ) \n self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) ) \n if __name__ == \"<STR_LIT:__main__>\" : \n unittest . main ( ) \n", "gt": "s"}
{"input": "\n import os \n import IECore \n import Gaffer \n import GafferDispatch \n class TextWriter ( GafferDispatch . ExecutableNode ) : \n def __init__ ( self , name = \"<STR_LIT>\" , requiresSequenceExecution = False ) : \n GafferDispatch . ExecutableNode . __init__ ( self , name ) \n self . __requiresSequenceExecution = requiresSequenceExecution \n self . addChild ( Gaffer . StringPlug ( \"<STR_LIT>\" , Gaffer . Plug . Direction . In ) ) \n self . addChild ( Gaffer . StringPlug ( \"<STR_LIT>\" , defaultValue = \"<STR_LIT:w>\" , direction = Gaffer . Plug . Direction . In ) ) \n self . addChild ( Gaffer . StringPlug ( \"<STR_LIT:text>\" , Gaffer . Plug . Direction . In ) ) \n def execute ( self ) : \n <mask0> = Gaffer . Context . current ( ) \n fileName = self [ \"<STR_LIT>\" ] . getValue ( ) \n directory = os . path . dirname ( fileName ) \n if directory : \n try : \n os . makedirs ( directory ) \n except OSError : \n if not os . path . isdir ( directory ) : \n raise \n text = self . __processText ( context ) \n with file ( fileName , self [ \"<STR_LIT>\" ] . getValue ( ) ) as f : \n f . write ( text ) \n def executeSequence ( self , frames ) : \n if not self . __requiresSequenceExecution : \n GafferDispatch . ExecutableNode . executeSequence ( self , frames ) \n return \n context = Gaffer . Context ( Gaffer . Context . current ( ) ) \n fileName = self [ \"<STR_LIT>\" ] . getValue ( ) \n with file ( fileName , self [ \"<STR_LIT>\" ] . getValue ( ) ) as f : \n with context : \n for frame in frames : \n context . setFrame ( frame ) \n text = self . __processText ( context ) \n f . write ( text ) \n def hash ( self , context ) : \n h = GafferDispatch . ExecutableNode . hash ( self , context ) \n h . append ( context . getFrame ( ) ) \n h . append ( context . get ( \"<STR_LIT>\" , IECore . StringVectorData ( ) ) ) \n self [ \"<STR_LIT>\" ] . hash ( h ) \n self [ \"<STR_LIT>\" ] . hash ( h ) \n self [ \"<STR_LIT:text>\" ] . hash ( h ) \n return h \n def requiresSequenceExecution ( self ) : \n return self . __requiresSequenceExecution \n def __processText ( self , context ) : \n text = self [ \"<STR_LIT:text>\" ] . getValue ( ) \n replace = context . get ( \"<STR_LIT>\" , IECore . StringVectorData ( ) ) \n if replace and len ( replace ) == <NUM_LIT:2> : \n text = text . replace ( replace [ <NUM_LIT:0> ] , replace [ <NUM_LIT:1> ] ) \n return text \n IECore . registerRunTimeTyped ( TextWriter , typeName = \"<STR_LIT>\" ) \n", "gt": "context"}
{"input": "\n import os \n import IECore \n import Gaffer \n import GafferImage \n import GafferTest \n import GafferImageTest \n class CopyImageMetadataTest ( GafferImageTest . ImageTestCase ) : \n <mask0> = os . path . expandvars ( \"<STR_LIT>\" ) \n def test ( self ) : \n r = GafferImage . ImageReader ( ) \n r [ \"<STR_LIT>\" ] . setValue ( self . checkerFile ) \n inMetadata = r [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) \n d = GafferImage . DeleteImageMetadata ( ) \n d [ \"<STR_LIT>\" ] . setInput ( r [ \"<STR_LIT>\" ] ) \n d [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT:*>\" ) \n m = GafferImage . CopyImageMetadata ( ) \n m [ \"<STR_LIT>\" ] . setInput ( d [ \"<STR_LIT>\" ] ) \n m [ \"<STR_LIT>\" ] . setInput ( r [ \"<STR_LIT>\" ] ) \n m [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT>\" ) \n metadata = m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) \n self . assertEqual ( m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , IECore . CompoundObject ( ) ) \n self . assertEqual ( m [ \"<STR_LIT>\" ] . image ( ) , d [ \"<STR_LIT>\" ] . image ( ) ) \n m [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT>\" ) \n metadata = m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) \n expected = set ( [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) \n self . assertEqual ( set ( metadata . keys ( ) ) , expected ) \n for key in metadata . keys ( ) : \n self . assertEqual ( metadata [ key ] , inMetadata [ key ] ) \n m [ \"<STR_LIT>\" ] . setValue ( True ) \n metadata = m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) \n expected = set ( [ \"<STR_LIT>\" , \"<STR_LIT>\" ] ) \n self . assertEqual ( set ( metadata . keys ( ) ) , expected ) \n for key in metadata . keys ( ) : \n self . assertEqual ( metadata [ key ] , inMetadata [ key ] ) \n def testOverwrite ( self ) : \n r = GafferImage . ImageReader ( ) \n r [ \"<STR_LIT>\" ] . setValue ( self . checkerFile ) \n inMetadata = r [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) \n a = GafferImage . ImageMetadata ( ) \n a [ \"<STR_LIT>\" ] . addMember ( \"<STR_LIT>\" , IECore . StringData ( \"<STR_LIT>\" ) ) \n m = GafferImage . CopyImageMetadata ( ) \n m [ \"<STR_LIT>\" ] . setInput ( r [ \"<STR_LIT>\" ] ) \n m [ \"<STR_LIT>\" ] . setInput ( a [ \"<STR_LIT>\" ] ) \n m [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT>\" ) \n metadata = m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) \n self . assertEqual ( metadata [ \"<STR_LIT>\" ] , IECore . StringData ( \"<STR_LIT>\" ) ) \n self . assertEqual ( m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , inMetadata ) \n self . assertEqual ( m [ \"<STR_LIT>\" ] . image ( ) , r [ \"<STR_LIT>\" ] . image ( ) ) \n m [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT>\" ) \n metadata = m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) \n self . assertTrue ( \"<STR_LIT>\" in metadata . keys ( ) ) \n self . assertEqual ( metadata [ \"<STR_LIT>\" ] , IECore . StringData ( \"<STR_LIT>\" ) ) \n def testDirtyPropogation ( self ) : \n c = GafferImage . Constant ( ) \n r = GafferImage . ImageReader ( ) \n r [ \"<STR_LIT>\" ] . setValue ( self . checkerFile ) \n inMetadata = r [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) \n m = GafferImage . CopyImageMetadata ( ) \n m [ \"<STR_LIT>\" ] . setInput ( c [ \"<STR_LIT>\" ] ) \n m [ \"<STR_LIT>\" ] . setInput ( r [ \"<STR_LIT>\" ] ) \n cs = GafferTest . CapturingSlot ( m . plugDirtiedSignal ( ) ) \n m [ \"<STR_LIT>\" ] . setInput ( c [ \"<STR_LIT>\" ] ) \n self . assertTrue ( m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] in set ( e [ <NUM_LIT:0> ] for e in cs ) ) \n del cs [ : ] \n m [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT:test>\" ) \n self . assertTrue ( m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] in set ( e [ <NUM_LIT:0> ] for e in cs ) ) \n del cs [ : ] \n m [ \"<STR_LIT>\" ] . setValue ( True ) \n self . assertTrue ( m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] in set ( e [ <NUM_LIT:0> ] for e in cs ) ) \n def testPassThrough ( self ) : \n c = GafferImage . Constant ( ) \n i = GafferImage . ImageReader ( ) \n i [ \"<STR_LIT>\" ] . setValue ( self . checkerFile ) \n m = GafferImage . CopyImageMetadata ( ) \n m [ \"<STR_LIT>\" ] . setInput ( i [ \"<STR_LIT>\" ] ) \n m [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT:*>\" ) \n self . assertEqual ( i [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . hash ( ) , m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . hash ( ) ) \n self . assertEqual ( i [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . hash ( ) , m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . hash ( ) ) \n self . assertEqual ( i [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . hash ( ) , m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . hash ( ) ) \n self . assertEqual ( i [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) ) \n self . assertEqual ( i [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) ) \n self . assertEqual ( i [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) ) \n context = Gaffer . Context ( ) \n context [ \"<STR_LIT>\" ] = IECore . V2i ( <NUM_LIT:0> ) \n with context : \n for c in [ \"<STR_LIT>\" , \"<STR_LIT:B>\" , \"<STR_LIT:A>\" ] : \n context [ \"<STR_LIT>\" ] = c \n self . assertEqual ( i [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . hash ( ) , m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . hash ( ) ) \n self . assertEqual ( i [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , m [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) ) \n if __name__ == \"<STR_LIT:__main__>\" : \n unittest . main ( ) \n", "gt": "checkerFile"}
{"input": "\n import os \n import unittest \n import IECore \n import Gaffer \n import GafferImage \n import GafferImageTest \n class ObjectToImageTest ( GafferImageTest . ImageTestCase ) : \n <mask0> = os . path . expandvars ( \"<STR_LIT>\" ) \n negFileName = os . path . expandvars ( \"<STR_LIT>\" ) \n def test ( self ) : \n i = IECore . Reader . create ( self . fileName ) . read ( ) \n n = GafferImage . ObjectToImage ( ) \n n [ \"<STR_LIT:object>\" ] . setValue ( i ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] . image ( ) , i ) \n def testImageWithANegativeDataWindow ( self ) : \n i = IECore . Reader . create ( self . negFileName ) . read ( ) \n n = GafferImage . ObjectToImage ( ) \n n [ \"<STR_LIT:object>\" ] . setValue ( i ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] . image ( ) , i ) \n def testHashVariesPerTileAndChannel ( self ) : \n n = GafferImage . ObjectToImage ( ) \n n [ \"<STR_LIT:object>\" ] . setValue ( IECore . Reader . create ( self . fileName ) . read ( ) ) \n self . assertNotEqual ( \n n [ \"<STR_LIT>\" ] . channelDataHash ( \"<STR_LIT:R>\" , IECore . V2i ( <NUM_LIT:0> ) ) , \n n [ \"<STR_LIT>\" ] . channelDataHash ( \"<STR_LIT>\" , IECore . V2i ( <NUM_LIT:0> ) ) \n ) \n self . assertNotEqual ( \n n [ \"<STR_LIT>\" ] . channelDataHash ( \"<STR_LIT:R>\" , IECore . V2i ( <NUM_LIT:0> ) ) , \n n [ \"<STR_LIT>\" ] . channelDataHash ( \"<STR_LIT:R>\" , IECore . V2i ( GafferImage . ImagePlug . tileSize ( ) ) ) \n ) \n if __name__ == \"<STR_LIT:__main__>\" : \n unittest . main ( ) \n", "gt": "fileName"}
{"input": "\n import threading \n import IECore \n import Gaffer \n import GafferUI \n import GafferImage \n <mask0> = [ ] \n Gaffer . Metadata . registerNode ( \n GafferImage . Display , \n \"<STR_LIT:description>\" , \n \"\"\"<STR_LIT>\"\"\" , \n plugs = { \n \"<STR_LIT:port>\" : [ \n \"<STR_LIT:description>\" , \n \"\"\"<STR_LIT>\"\"\" , \n ] , \n } \n ) \n __plugsPendingUpdate = [ ] \n __plugsPendingUpdateLock = threading . Lock ( ) \n def __scheduleUpdate ( plug , force = False ) : \n if not force : \n global __plugsPendingUpdate \n global __plugsPendingUpdateLock \n with __plugsPendingUpdateLock : \n for p in __plugsPendingUpdate : \n if plug . isSame ( p ) : \n return \n __plugsPendingUpdate . append ( plug ) \n GafferUI . EventLoop . executeOnUIThread ( lambda : __update ( plug ) ) \n def __update ( plug ) : \n node = plug . node ( ) \n if node : \n updateCountPlug = node [ \"<STR_LIT>\" ] \n updateCountPlug . setValue ( updateCountPlug . getValue ( ) + <NUM_LIT:1> ) \n global __plugsPendingUpdate \n global __plugsPendingUpdateLock \n with __plugsPendingUpdateLock : \n __plugsPendingUpdate = [ p for p in __plugsPendingUpdate if not p . isSame ( plug ) ] \n __displayDataReceivedConnection = GafferImage . Display . dataReceivedSignal ( ) . connect ( __scheduleUpdate ) \n __displayImageReceivedConnection = GafferImage . Display . imageReceivedSignal ( ) . connect ( IECore . curry ( __scheduleUpdate , force = True ) ) \n", "gt": "__all__"}
{"input": "\n import os \n import unittest \n import IECore \n import Gaffer \n import GafferTest \n import GafferScene \n import GafferSceneTest \n import GafferRenderMan \n import GafferRenderManTest \n class RenderManShaderTest ( GafferRenderManTest . RenderManTestCase ) : \n def setUp ( self ) : \n GafferRenderManTest . RenderManTestCase . setUp ( self ) \n GafferRenderMan . RenderManShader . shaderLoader ( ) . clear ( ) \n def test ( self ) : \n <mask0> = GafferRenderMan . RenderManShader ( ) \n n . loadShader ( \"<STR_LIT>\" ) \n self . failUnless ( isinstance ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . FloatPlug ) ) \n self . failUnless ( isinstance ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . FloatPlug ) ) \n self . failUnless ( isinstance ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . FloatPlug ) ) \n self . failUnless ( isinstance ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . FloatPlug ) ) \n self . failUnless ( isinstance ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . Color3fPlug ) ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , <NUM_LIT:0.5> ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , <NUM_LIT:0.5> ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , <NUM_LIT:1> ) \n self . assertAlmostEqual ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , <NUM_LIT:0.1> ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , IECore . Color3f ( <NUM_LIT:1> ) ) \n def testSerialisation ( self ) : \n s = Gaffer . ScriptNode ( ) \n s [ \"<STR_LIT:n>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT:n>\" ] . loadShader ( \"<STR_LIT>\" ) \n ss = s . serialise ( ) \n s = Gaffer . ScriptNode ( ) \n s . execute ( ss ) \n st = s [ \"<STR_LIT:n>\" ] . state ( ) \n self . assertEqual ( len ( st ) , <NUM_LIT:1> ) \n self . assertEqual ( st [ <NUM_LIT:0> ] . type , \"<STR_LIT>\" ) \n self . assertEqual ( st [ <NUM_LIT:0> ] . name , \"<STR_LIT>\" ) \n self . failUnless ( isinstance ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . FloatPlug ) ) \n self . failUnless ( isinstance ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . FloatPlug ) ) \n self . failUnless ( isinstance ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . FloatPlug ) ) \n self . failUnless ( isinstance ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . FloatPlug ) ) \n self . failUnless ( isinstance ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . Color3fPlug ) ) \n self . assertTrue ( \"<STR_LIT>\" not in s [ \"<STR_LIT:n>\" ] ) \n def testShader ( self ) : \n n = GafferRenderMan . RenderManShader ( ) \n n . loadShader ( \"<STR_LIT>\" ) \n s = n . state ( ) \n self . assertEqual ( len ( s ) , <NUM_LIT:1> ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . type , \"<STR_LIT>\" ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . name , \"<STR_LIT>\" ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] , IECore . FloatData ( <NUM_LIT> ) ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] , IECore . FloatData ( <NUM_LIT> ) ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] , IECore . FloatData ( <NUM_LIT:1> ) ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] , IECore . FloatData ( <NUM_LIT> ) ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] , IECore . Color3fData ( IECore . Color3f ( <NUM_LIT:1> ) ) ) \n def testShaderHash ( self ) : \n n = GafferRenderMan . RenderManShader ( ) \n n . loadShader ( \"<STR_LIT>\" ) \n h1 = n . stateHash ( ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( <NUM_LIT> ) \n self . assertNotEqual ( n . stateHash ( ) , h1 ) \n def testCoshaderHash ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n self . assertTrue ( \"<STR_LIT>\" in shaderNode [ \"<STR_LIT>\" ] ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . typeId ( ) , Gaffer . Plug . staticTypeId ( ) ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode = GafferRenderMan . RenderManShader ( ) \n coshaderNode . loadShader ( coshader ) \n shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( coshaderNode [ \"<STR_LIT>\" ] ) \n h1 = shaderNode . stateHash ( ) \n coshaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( <NUM_LIT> ) \n self . assertNotEqual ( shaderNode . stateHash ( ) , h1 ) \n def testParameterOrdering ( self ) : \n n = GafferRenderMan . RenderManShader ( ) \n n . loadShader ( \"<STR_LIT>\" ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . getName ( ) , \"<STR_LIT>\" ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . getName ( ) , \"<STR_LIT>\" ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ <NUM_LIT:2> ] . getName ( ) , \"<STR_LIT>\" ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ <NUM_LIT:3> ] . getName ( ) , \"<STR_LIT>\" ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ <NUM_LIT:4> ] . getName ( ) , \"<STR_LIT>\" ) \n n = GafferRenderMan . RenderManShader ( ) \n n . loadShader ( \"<STR_LIT>\" ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . getName ( ) , \"<STR_LIT>\" ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . getName ( ) , \"<STR_LIT>\" ) \n def testCoshader ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n self . assertTrue ( \"<STR_LIT>\" in shaderNode [ \"<STR_LIT>\" ] ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . typeId ( ) , Gaffer . Plug . staticTypeId ( ) ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode = GafferRenderMan . RenderManShader ( ) \n coshaderNode . loadShader ( coshader ) \n shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( coshaderNode [ \"<STR_LIT>\" ] ) \n s = shaderNode . state ( ) \n self . assertEqual ( len ( s ) , <NUM_LIT:2> ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . name , shader ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] , s [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] ) \n def testInputAcceptance ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode = GafferRenderMan . RenderManShader ( ) \n coshaderNode . loadShader ( coshader ) \n random = Gaffer . Random ( ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderNode [ \"<STR_LIT>\" ] ) ) \n self . assertFalse ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( random [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( random [ \"<STR_LIT>\" ] ) ) \n self . assertFalse ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderNode [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( coshaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( random [ \"<STR_LIT>\" ] ) ) \n self . assertFalse ( coshaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderNode [ \"<STR_LIT>\" ] ) ) \n def testParameterDefaultValue ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . defaultValue ( ) , <NUM_LIT:1> ) \n def testParameterMinMax ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . minValue ( ) , - <NUM_LIT:1> ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . maxValue ( ) , <NUM_LIT:10> ) \n def testReload ( self ) : \n shader1 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader1 ) \n shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( <NUM_LIT:0.1> ) \n shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT:test>\" ) \n shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( IECore . Color3f ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) ) \n self . assertAlmostEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , <NUM_LIT:0.1> ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , \"<STR_LIT:test>\" ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , IECore . Color3f ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) ) \n shader2 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode . loadShader ( shader2 , keepExistingValues = True ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] . keys ( ) , [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) \n self . assertAlmostEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , <NUM_LIT:0.1> ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , \"<STR_LIT:test>\" ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , IECore . Color3f ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) ) \n shaderNode . loadShader ( shader1 , keepExistingValues = True ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] . keys ( ) , [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) \n self . assertAlmostEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , <NUM_LIT:0.1> ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , \"<STR_LIT:test>\" ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , IECore . Color3f ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) ) \n shaderNode . loadShader ( shader1 , keepExistingValues = False ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] . keys ( ) , [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , <NUM_LIT:1> ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , \"<STR_LIT>\" ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , IECore . Color3f ( <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> ) ) \n def testReloadRemovesOldParameters ( self ) : \n shader2 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader2 ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] . keys ( ) , [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) \n shader3 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode . loadShader ( shader3 ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] . keys ( ) , [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) \n def testAutomaticReloadOnScriptLoad ( self ) : \n shader1 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" , shaderName = \"<STR_LIT>\" ) \n s = Gaffer . ScriptNode ( ) \n s [ \"<STR_LIT>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT>\" ] . loadShader ( shader1 ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( <NUM_LIT:0.1> ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT:test>\" ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( IECore . Color3f ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) ) \n ss = s . serialise ( ) \n self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" , shaderName = \"<STR_LIT>\" ) \n GafferRenderMan . RenderManShader . shaderLoader ( ) . clear ( ) \n s = Gaffer . ScriptNode ( ) \n s . execute ( ss ) \n self . assertEqual ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . keys ( ) , [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) \n self . assertAlmostEqual ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , <NUM_LIT:0.1> ) \n self . assertEqual ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , \"<STR_LIT:test>\" ) \n self . assertEqual ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , IECore . Color3f ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) ) \n def testReloadPreservesConnections ( self ) : \n n = GafferRenderMan . RenderManShader ( ) \n n . loadShader ( \"<STR_LIT>\" ) \n random = Gaffer . Random ( ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( random [ \"<STR_LIT>\" ] ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( random [ \"<STR_LIT>\" ] ) \n n . loadShader ( \"<STR_LIT>\" , keepExistingValues = True ) \n self . assertTrue ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getInput ( ) . isSame ( random [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getInput ( ) . isSame ( random [ \"<STR_LIT>\" ] ) ) \n def testReloadPreservesConnectionsWhenMinMaxOrDefaultChanges ( self ) : \n shader1 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" , shaderName = \"<STR_LIT>\" ) \n n = GafferRenderMan . RenderManShader ( ) \n n . loadShader ( shader1 ) \n self . assertFalse ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . hasMinValue ( ) ) \n self . assertFalse ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . hasMaxValue ( ) ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . defaultValue ( ) , \"<STR_LIT>\" ) \n nn = Gaffer . Node ( ) \n nn [ \"<STR_LIT>\" ] = Gaffer . FloatPlug ( direction = Gaffer . Plug . Direction . Out ) \n nn [ \"<STR_LIT>\" ] = Gaffer . StringPlug ( direction = Gaffer . Plug . Direction . Out ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( nn [ \"<STR_LIT>\" ] ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( nn [ \"<STR_LIT>\" ] ) \n shader2 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" , shaderName = \"<STR_LIT>\" ) \n GafferRenderMan . RenderManShader . shaderLoader ( ) . clear ( ) \n n . loadShader ( shader1 , keepExistingValues = True ) \n self . assertTrue ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . hasMinValue ( ) ) \n self . assertTrue ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . hasMaxValue ( ) ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . minValue ( ) , - <NUM_LIT:1> ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . maxValue ( ) , <NUM_LIT:2> ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . defaultValue ( ) , \"<STR_LIT>\" ) \n self . assertTrue ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getInput ( ) . isSame ( nn [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getInput ( ) . isSame ( nn [ \"<STR_LIT>\" ] ) ) \n def testReloadPreservesPartialConnectionsWhenMinMaxOrDefaultChanges ( self ) : \n shader1 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" , shaderName = \"<STR_LIT>\" ) \n n = GafferRenderMan . RenderManShader ( ) \n n . loadShader ( shader1 ) \n nn = Gaffer . Node ( ) \n nn [ \"<STR_LIT>\" ] = Gaffer . FloatPlug ( direction = Gaffer . Plug . Direction . Out ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . setInput ( nn [ \"<STR_LIT>\" ] ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . setInput ( nn [ \"<STR_LIT>\" ] ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:2> ] . setValue ( <NUM_LIT> ) \n shader2 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" , shaderName = \"<STR_LIT>\" ) \n GafferRenderMan . RenderManShader . shaderLoader ( ) . clear ( ) \n n . loadShader ( shader1 , keepExistingValues = True ) \n self . assertTrue ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . getInput ( ) . isSame ( nn [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . getInput ( ) . isSame ( nn [ \"<STR_LIT>\" ] ) ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:2> ] . getValue ( ) , <NUM_LIT> ) \n def testReloadPreservesValuesWhenMinMaxOrDefaultChanges ( self ) : \n shader1 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" , shaderName = \"<STR_LIT>\" ) \n n = GafferRenderMan . RenderManShader ( ) \n n . loadShader ( shader1 ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( <NUM_LIT> ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT>\" ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( IECore . Color3f ( <NUM_LIT:0.1> , <NUM_LIT> , <NUM_LIT:0.5> ) ) \n shader2 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" , shaderName = \"<STR_LIT>\" ) \n GafferRenderMan . RenderManShader . shaderLoader ( ) . clear ( ) \n n . loadShader ( shader1 , keepExistingValues = True ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , <NUM_LIT> ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , \"<STR_LIT>\" ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , IECore . Color3f ( <NUM_LIT:0.1> , <NUM_LIT> , <NUM_LIT:0.5> ) ) \n def testOutputParameters ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n n = GafferRenderMan . RenderManShader ( ) \n n . loadShader ( shader ) \n self . failIf ( \"<STR_LIT>\" in n [ \"<STR_LIT>\" ] . keys ( ) ) \n def testAssignmentDirtyPropagation ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode = GafferRenderMan . RenderManShader ( ) \n coshaderNode . loadShader ( coshader ) \n shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( coshaderNode [ \"<STR_LIT>\" ] ) \n plane = GafferScene . Plane ( ) \n assignment = GafferScene . ShaderAssignment ( ) \n assignment [ \"<STR_LIT>\" ] . setInput ( plane [ \"<STR_LIT>\" ] ) \n assignment [ \"<STR_LIT>\" ] . setInput ( shaderNode [ \"<STR_LIT>\" ] ) \n cs = GafferTest . CapturingSlot ( assignment . plugDirtiedSignal ( ) ) \n coshaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( <NUM_LIT:12> ) \n dirtiedNames = [ x [ <NUM_LIT:0> ] . fullName ( ) for x in cs ] \n self . assertEqual ( len ( dirtiedNames ) , <NUM_LIT:3> ) \n self . assertEqual ( dirtiedNames [ <NUM_LIT:0> ] , \"<STR_LIT>\" ) \n self . assertEqual ( dirtiedNames [ <NUM_LIT:1> ] , \"<STR_LIT>\" ) \n self . assertEqual ( dirtiedNames [ <NUM_LIT:2> ] , \"<STR_LIT>\" ) \n def testArrayParameters ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n n = GafferRenderMan . RenderManShader ( ) \n n . loadShader ( shader ) \n expected = { \n \"<STR_LIT>\" : IECore . FloatVectorData ( [ ] ) , \n \"<STR_LIT>\" : IECore . FloatVectorData ( [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ] ) , \n \"<STR_LIT>\" : IECore . StringVectorData ( [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) , \n \"<STR_LIT>\" : IECore . StringVectorData ( [ \"<STR_LIT:hello>\" , \"<STR_LIT>\" ] ) , \n \"<STR_LIT>\" : IECore . Color3fVectorData ( [ IECore . Color3f ( <NUM_LIT:1> ) , IECore . Color3f ( <NUM_LIT:2> ) ] ) , \n \"<STR_LIT>\" : IECore . Color3fVectorData ( [ IECore . Color3f ( <NUM_LIT:1> ) , IECore . Color3f ( <NUM_LIT:2> ) ] ) , \n \"<STR_LIT>\" : IECore . V3fVectorData ( [ ] , IECore . GeometricData . Interpretation . Vector ) , \n \"<STR_LIT>\" : IECore . V3fVectorData ( [ IECore . V3f ( x ) for x in range ( <NUM_LIT:1> , <NUM_LIT:6> ) ] , IECore . GeometricData . Interpretation . Vector ) , \n \"<STR_LIT>\" : IECore . V3fVectorData ( [ ] , IECore . GeometricData . Interpretation . Point ) , \n \"<STR_LIT>\" : IECore . V3fVectorData ( [ IECore . V3f ( x ) for x in range ( <NUM_LIT:1> , <NUM_LIT:6> ) ] , IECore . GeometricData . Interpretation . Point ) , \n \"<STR_LIT>\" : IECore . V3fVectorData ( [ ] , IECore . GeometricData . Interpretation . Normal ) , \n \"<STR_LIT>\" : IECore . V3fVectorData ( [ IECore . V3f ( x ) for x in range ( <NUM_LIT:1> , <NUM_LIT:6> ) ] , IECore . GeometricData . Interpretation . Normal ) , \n } \n self . assertEqual ( set ( n [ \"<STR_LIT>\" ] . keys ( ) ) , set ( expected . keys ( ) ) ) \n for name , value in expected . items ( ) : \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ name ] . defaultValue ( ) , value ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] [ name ] . getValue ( ) , value ) \n s = n . state ( ) [ <NUM_LIT:0> ] \n for name , value in expected . items ( ) : \n self . assertEqual ( s . parameters [ name ] , value ) \n def testFixedCoshaderArrayParameters ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n n = GafferRenderMan . RenderManShader ( ) \n n . loadShader ( shader ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] . keys ( ) , [ \"<STR_LIT>\" , \"<STR_LIT>\" ] ) \n self . assertTrue ( isinstance ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . ArrayPlug ) ) \n self . assertEqual ( len ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) , <NUM_LIT:4> ) \n self . assertTrue ( isinstance ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . Plug ) ) \n self . assertTrue ( isinstance ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . Plug ) ) \n self . assertTrue ( isinstance ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . Plug ) ) \n self . assertTrue ( isinstance ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . Plug ) ) \n state = n . state ( ) \n self . assertEqual ( state [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] , IECore . StringVectorData ( [ \"<STR_LIT>\" ] * <NUM_LIT:4> ) ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode = GafferRenderMan . RenderManShader ( ) \n coshaderNode . loadShader ( coshader ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( coshaderNode [ \"<STR_LIT>\" ] ) \n state = n . state ( ) \n self . assertEqual ( state [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] , IECore . StringVectorData ( [ state [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] . value , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) ) \n def testCoshaderType ( self ) : \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode = GafferRenderMan . RenderManShader ( ) \n coshaderNode . loadShader ( coshader ) \n self . assertEqual ( coshaderNode . state ( ) [ <NUM_LIT:0> ] . type , \"<STR_LIT>\" ) \n def testCantConnectSurfaceShaderIntoCoshaderInput ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n n1 = GafferRenderMan . RenderManShader ( ) \n n1 . loadShader ( shader ) \n n2 = GafferRenderMan . RenderManShader ( ) \n n2 . loadShader ( \"<STR_LIT>\" ) \n self . assertFalse ( n1 [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( n2 [ \"<STR_LIT>\" ] ) ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n n3 = GafferRenderMan . RenderManShader ( ) \n n3 . loadShader ( coshader ) \n self . assertTrue ( n1 [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( n3 [ \"<STR_LIT>\" ] ) ) \n arrayShader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n n4 = GafferRenderMan . RenderManShader ( ) \n n4 . loadShader ( arrayShader ) \n self . assertFalse ( n4 [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( n2 [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( n4 [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( n3 [ \"<STR_LIT>\" ] ) ) \n def testConnectionsBetweenParameters ( self ) : \n s = GafferRenderMan . RenderManShader ( ) \n s . loadShader ( \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( <NUM_LIT> ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n shader = s . state ( ) [ <NUM_LIT:0> ] \n self . assertEqual ( shader . parameters [ \"<STR_LIT>\" ] . value , <NUM_LIT> ) \n self . assertEqual ( shader . parameters [ \"<STR_LIT>\" ] . value , <NUM_LIT> ) \n def testFixedCoshaderArrayParameterHash ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n n = GafferRenderMan . RenderManShader ( ) \n n . loadShader ( shader ) \n h1 = n . stateHash ( ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode = GafferRenderMan . RenderManShader ( ) \n coshaderNode . loadShader ( coshader ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( coshaderNode [ \"<STR_LIT>\" ] ) \n h2 = n . stateHash ( ) \n self . assertNotEqual ( h2 , h1 ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( coshaderNode [ \"<STR_LIT>\" ] ) \n h3 = n . stateHash ( ) \n self . assertNotEqual ( h3 , h2 ) \n self . assertNotEqual ( h3 , h1 ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( None ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( coshaderNode [ \"<STR_LIT>\" ] ) \n h4 = n . stateHash ( ) \n self . assertNotEqual ( h4 , h3 ) \n self . assertNotEqual ( h4 , h2 ) \n self . assertNotEqual ( h4 , h1 ) \n def testDisabling ( self ) : \n s = GafferRenderMan . RenderManShader ( ) \n s . loadShader ( \"<STR_LIT>\" ) \n stateHash = s . stateHash ( ) \n state = s . state ( ) \n self . assertEqual ( len ( state ) , <NUM_LIT:1> ) \n self . assertEqual ( state [ <NUM_LIT:0> ] . name , \"<STR_LIT>\" ) \n self . assertTrue ( s [ \"<STR_LIT>\" ] . isSame ( s . enabledPlug ( ) ) ) \n s [ \"<STR_LIT>\" ] . setValue ( False ) \n stateHash2 = s . stateHash ( ) \n self . assertNotEqual ( stateHash2 , stateHash ) \n state2 = s . state ( ) \n self . assertEqual ( len ( state2 ) , <NUM_LIT:0> ) \n def testDisablingCoshaders ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode = GafferRenderMan . RenderManShader ( ) \n coshaderNode . loadShader ( coshader ) \n shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( coshaderNode [ \"<STR_LIT>\" ] ) \n s = shaderNode . state ( ) \n self . assertEqual ( len ( s ) , <NUM_LIT:2> ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . name , shader ) \n h = shaderNode . stateHash ( ) \n coshaderNode [ \"<STR_LIT>\" ] . setValue ( False ) \n s2 = shaderNode . state ( ) \n self . assertEqual ( len ( s2 ) , <NUM_LIT:1> ) \n self . assertEqual ( s2 [ <NUM_LIT:0> ] . name , shader ) \n self . assertTrue ( \"<STR_LIT>\" not in s2 [ <NUM_LIT:0> ] . parameters ) \n self . assertNotEqual ( shaderNode . stateHash ( ) , h ) \n def testDisablingCoshaderArrayInputs ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n n = GafferRenderMan . RenderManShader ( ) \n n . loadShader ( shader ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode1 = GafferRenderMan . RenderManShader ( ) \n coshaderNode1 . loadShader ( coshader ) \n coshaderNode2 = GafferRenderMan . RenderManShader ( ) \n coshaderNode2 . loadShader ( coshader ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . setInput ( coshaderNode1 [ \"<STR_LIT>\" ] ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:2> ] . setInput ( coshaderNode2 [ \"<STR_LIT>\" ] ) \n state = n . state ( ) \n h1 = n . stateHash ( ) \n self . assertEqual ( \n state [ <NUM_LIT:2> ] . parameters [ \"<STR_LIT>\" ] , \n IECore . StringVectorData ( [ \n state [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] . value , \n \"<STR_LIT>\" , \n state [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] . value , \n \"<STR_LIT>\" \n ] ) \n ) \n coshaderNode1 [ \"<STR_LIT>\" ] . setValue ( False ) \n state = n . state ( ) \n self . assertEqual ( \n state [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] , \n IECore . StringVectorData ( [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n state [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] . value , \n \"<STR_LIT>\" \n ] ) \n ) \n h2 = n . stateHash ( ) \n self . assertNotEqual ( h2 , h1 ) \n coshaderNode2 [ \"<STR_LIT>\" ] . setValue ( False ) \n state = n . state ( ) \n self . assertEqual ( \n state [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] , \n IECore . StringVectorData ( [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" \n ] ) \n ) \n self . assertNotEqual ( n . stateHash ( ) , h1 ) \n self . assertNotEqual ( n . stateHash ( ) , h2 ) \n def testCorrespondingInput ( self ) : \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode = GafferRenderMan . RenderManShader ( ) \n coshaderNode . loadShader ( coshader ) \n self . assertEqual ( coshaderNode . correspondingInput ( coshaderNode [ \"<STR_LIT>\" ] ) , None ) \n coshader2 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode2 = GafferRenderMan . RenderManShader ( ) \n coshaderNode2 . loadShader ( coshader2 ) \n self . assertTrue ( coshaderNode2 . correspondingInput ( coshaderNode2 [ \"<STR_LIT>\" ] ) . isSame ( coshaderNode2 [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) ) \n def testCoshaderPassThrough ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n passThroughCoshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n passThroughCoshaderNode = GafferRenderMan . RenderManShader ( ) \n passThroughCoshaderNode . loadShader ( passThroughCoshader ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode = GafferRenderMan . RenderManShader ( ) \n coshaderNode . loadShader ( coshader ) \n shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( passThroughCoshaderNode [ \"<STR_LIT>\" ] ) \n passThroughCoshaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( coshaderNode [ \"<STR_LIT>\" ] ) \n h = shaderNode . stateHash ( ) \n s = shaderNode . state ( ) \n self . assertEqual ( len ( s ) , <NUM_LIT:3> ) \n self . assertEqual ( s [ <NUM_LIT:2> ] . parameters [ \"<STR_LIT>\" ] , s [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . name , passThroughCoshader ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] , s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) \n passThroughCoshaderNode [ \"<STR_LIT>\" ] . setValue ( False ) \n s = shaderNode . state ( ) \n self . assertEqual ( len ( s ) , <NUM_LIT:2> ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] , s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) \n def testSplineParameters ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n n = GafferRenderMan . RenderManShader ( ) \n n . loadShader ( shader ) \n self . assertEqual ( n [ \"<STR_LIT>\" ] . keys ( ) , [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) \n self . assertTrue ( isinstance ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . SplineffPlug ) ) \n self . assertTrue ( isinstance ( n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . SplinefColor3fPlug ) ) \n self . assertEqual ( \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . defaultValue ( ) , \n IECore . Splineff ( \n IECore . CubicBasisf . catmullRom ( ) , \n [ \n ( <NUM_LIT:0> , <NUM_LIT:0> ) , \n ( <NUM_LIT:0> , <NUM_LIT:0> ) , \n ( <NUM_LIT:1> , <NUM_LIT:1> ) , \n ( <NUM_LIT:1> , <NUM_LIT:1> ) , \n ] \n ) \n ) \n self . assertEqual ( \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . defaultValue ( ) , \n IECore . SplinefColor3f ( \n IECore . CubicBasisf . catmullRom ( ) , \n [ \n ( <NUM_LIT:0> , IECore . Color3f ( <NUM_LIT:0> ) ) , \n ( <NUM_LIT:0> , IECore . Color3f ( <NUM_LIT:0> ) ) , \n ( <NUM_LIT:1> , IECore . Color3f ( <NUM_LIT:1> ) ) , \n ( <NUM_LIT:1> , IECore . Color3f ( <NUM_LIT:1> ) ) , \n ] \n ) \n ) \n floatValue = IECore . Splineff ( \n IECore . CubicBasisf . catmullRom ( ) , \n [ \n ( <NUM_LIT:0> , <NUM_LIT:0> ) , \n ( <NUM_LIT:0> , <NUM_LIT:0> ) , \n ( <NUM_LIT:1> , <NUM_LIT:2> ) , \n ( <NUM_LIT:1> , <NUM_LIT:2> ) , \n ] \n ) \n colorValue = IECore . SplinefColor3f ( \n IECore . CubicBasisf . catmullRom ( ) , \n [ \n ( <NUM_LIT:0> , IECore . Color3f ( <NUM_LIT:0> ) ) , \n ( <NUM_LIT:0> , IECore . Color3f ( <NUM_LIT:0> ) ) , \n ( <NUM_LIT:1> , IECore . Color3f ( <NUM_LIT> ) ) , \n ( <NUM_LIT:1> , IECore . Color3f ( <NUM_LIT> ) ) , \n ] \n ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( floatValue ) \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( colorValue ) \n s = n . state ( ) [ <NUM_LIT:0> ] \n self . assertEqual ( s . parameters [ \"<STR_LIT>\" ] . value , floatValue ) \n self . assertEqual ( s . parameters [ \"<STR_LIT>\" ] . value , colorValue ) \n def testSplineParameterSerialisationKeepsExistingValues ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n s = Gaffer . ScriptNode ( ) \n s [ \"<STR_LIT:n>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT:n>\" ] . loadShader ( shader ) \n s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( \n IECore . Splineff ( \n IECore . CubicBasisf . catmullRom ( ) , \n [ \n ( <NUM_LIT:0> , <NUM_LIT:0> ) , \n ( <NUM_LIT:0> , <NUM_LIT:0> ) , \n ( <NUM_LIT:1> , <NUM_LIT:2> ) , \n ( <NUM_LIT:1> , <NUM_LIT:2> ) , \n ] \n ) \n ) \n self . assertEqual ( \n s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , \n IECore . Splineff ( \n IECore . CubicBasisf . catmullRom ( ) , \n [ \n ( <NUM_LIT:0> , <NUM_LIT:0> ) , \n ( <NUM_LIT:0> , <NUM_LIT:0> ) , \n ( <NUM_LIT:1> , <NUM_LIT:2> ) , \n ( <NUM_LIT:1> , <NUM_LIT:2> ) , \n ] \n ) , \n ) \n ss = s . serialise ( ) \n s2 = Gaffer . ScriptNode ( ) \n s2 . execute ( ss ) \n self . assertEqual ( \n s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , \n IECore . Splineff ( \n IECore . CubicBasisf . catmullRom ( ) , \n [ \n ( <NUM_LIT:0> , <NUM_LIT:0> ) , \n ( <NUM_LIT:0> , <NUM_LIT:0> ) , \n ( <NUM_LIT:1> , <NUM_LIT:2> ) , \n ( <NUM_LIT:1> , <NUM_LIT:2> ) , \n ] \n ) , \n ) \n def testSplineParameterDefaultValueAnnotation ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n n = GafferRenderMan . RenderManShader ( ) \n n . loadShader ( shader ) \n self . assertEqual ( \n n [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , \n IECore . SplinefColor3f ( \n IECore . CubicBasisf . catmullRom ( ) , \n [ \n ( <NUM_LIT:0> , IECore . Color3f ( <NUM_LIT:1> ) ) , \n ( <NUM_LIT:0> , IECore . Color3f ( <NUM_LIT:1> ) ) , \n ( <NUM_LIT:0.5> , IECore . Color3f ( <NUM_LIT:1> , <NUM_LIT:0.5> , <NUM_LIT> ) ) , \n ( <NUM_LIT:1> , IECore . Color3f ( <NUM_LIT:0> ) ) , \n ( <NUM_LIT:1> , IECore . Color3f ( <NUM_LIT:0> ) ) , \n ] \n ) , \n ) \n def testCoshadersInBox ( self ) : \n s = Gaffer . ScriptNode ( ) \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT>\" ] . loadShader ( shader ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT>\" ] . loadShader ( coshader ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n b = Gaffer . Box . create ( s , Gaffer . StandardSet ( [ s [ \"<STR_LIT>\" ] ] ) ) \n self . assertTrue ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getInput ( ) . parent ( ) . isSame ( b ) ) \n s = s [ \"<STR_LIT>\" ] . state ( ) \n self . assertEqual ( len ( s ) , <NUM_LIT:2> ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] , s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) \n def testShaderInBoxWithExternalCoshader ( self ) : \n s = Gaffer . ScriptNode ( ) \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT>\" ] . loadShader ( shader ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT>\" ] . loadShader ( coshader ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n b = Gaffer . Box . create ( s , Gaffer . StandardSet ( [ s [ \"<STR_LIT>\" ] ] ) ) \n self . assertTrue ( b [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getInput ( ) . parent ( ) . isSame ( b ) ) \n s = b [ \"<STR_LIT>\" ] . state ( ) \n self . assertEqual ( len ( s ) , <NUM_LIT:2> ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] , s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) \n def testNumericTypeAnnotations ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n self . assertTrue ( isinstance ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . FloatPlug ) ) \n self . assertTrue ( isinstance ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . FloatPlug ) ) \n self . assertTrue ( isinstance ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . IntPlug ) ) \n self . assertTrue ( isinstance ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , Gaffer . BoolPlug ) ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . defaultValue ( ) , <NUM_LIT> ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . defaultValue ( ) , <NUM_LIT> ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . defaultValue ( ) , <NUM_LIT:10> ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . defaultValue ( ) , True ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , <NUM_LIT> ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , <NUM_LIT> ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , <NUM_LIT:10> ) \n self . assertEqual ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , True ) \n def testCoshaderTypeAnnotations ( self ) : \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode = GafferRenderMan . RenderManShader ( ) \n coshaderNode . loadShader ( coshader ) \n coshaderType1 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderType1Node = GafferRenderMan . RenderManShader ( ) \n coshaderType1Node . loadShader ( coshaderType1 ) \n coshaderType2 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderType2Node = GafferRenderMan . RenderManShader ( ) \n coshaderType2Node . loadShader ( coshaderType2 ) \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderNode [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderType1Node [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderType2Node [ \"<STR_LIT>\" ] ) ) \n self . assertFalse ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderNode [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderType1Node [ \"<STR_LIT>\" ] ) ) \n self . assertFalse ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderType2Node [ \"<STR_LIT>\" ] ) ) \n self . assertFalse ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderNode [ \"<STR_LIT>\" ] ) ) \n self . assertFalse ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderType1Node [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderType2Node [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderNode [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderType1Node [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderType2Node [ \"<STR_LIT>\" ] ) ) \n self . assertFalse ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderNode [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderType1Node [ \"<STR_LIT>\" ] ) ) \n self . assertFalse ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderType2Node [ \"<STR_LIT>\" ] ) ) \n self . assertFalse ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . acceptsInput ( coshaderNode [ \"<STR_LIT>\" ] ) ) \n self . assertFalse ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . acceptsInput ( coshaderType1Node [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . acceptsInput ( coshaderType2Node [ \"<STR_LIT>\" ] ) ) \n def testMultipleCoshaderTypeAnnotations ( self ) : \n coshaderType1And2 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderType1And2Node = GafferRenderMan . RenderManShader ( ) \n coshaderType1And2Node . loadShader ( coshaderType1And2 ) \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderType1And2Node [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderType1And2Node [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderType1And2Node [ \"<STR_LIT>\" ] ) ) \n self . assertFalse ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( coshaderType1And2Node [ \"<STR_LIT>\" ] ) ) \n def testSplitCoshaderPassThrough ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n S = GafferRenderMan . RenderManShader ( ) \n S . loadShader ( shader ) \n passThroughCoshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n D = GafferRenderMan . RenderManShader ( ) \n D . loadShader ( passThroughCoshader ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n C = GafferRenderMan . RenderManShader ( ) \n C . loadShader ( coshader ) \n S [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . setInput ( C [ \"<STR_LIT>\" ] ) \n S [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . setInput ( D [ \"<STR_LIT>\" ] ) \n D [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( C [ \"<STR_LIT>\" ] ) \n h = S . stateHash ( ) \n s = S . state ( ) \n self . assertEqual ( len ( s ) , <NUM_LIT:3> ) \n self . assertEqual ( s [ <NUM_LIT:2> ] . parameters [ \"<STR_LIT>\" ] , IECore . StringVectorData ( [ s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] . value , s [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] . value , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] , s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . name , passThroughCoshader ) \n D [ \"<STR_LIT>\" ] . setValue ( False ) \n self . assertNotEqual ( S . stateHash ( ) , h ) \n s = S . state ( ) \n self . assertEqual ( len ( s ) , <NUM_LIT:2> ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] , IECore . StringVectorData ( [ s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] . value , s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] . value , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) \n def testSerialDisabledShaders ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n S = GafferRenderMan . RenderManShader ( ) \n S . loadShader ( shader ) \n passThroughCoshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n D1 = GafferRenderMan . RenderManShader ( ) \n D1 . loadShader ( passThroughCoshader ) \n D2 = GafferRenderMan . RenderManShader ( ) \n D2 . loadShader ( passThroughCoshader ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n C = GafferRenderMan . RenderManShader ( ) \n C . loadShader ( coshader ) \n S [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( D2 [ \"<STR_LIT>\" ] ) \n D2 [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( D1 [ \"<STR_LIT>\" ] ) \n D1 [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( C [ \"<STR_LIT>\" ] ) \n h1 = S . stateHash ( ) \n s = S . state ( ) \n self . assertEqual ( len ( s ) , <NUM_LIT:4> ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . name , passThroughCoshader ) \n self . assertEqual ( s [ <NUM_LIT:2> ] . name , passThroughCoshader ) \n self . assertEqual ( s [ <NUM_LIT:3> ] . name , shader ) \n self . assertEqual ( s [ <NUM_LIT:3> ] . parameters [ \"<STR_LIT>\" ] , s [ <NUM_LIT:2> ] . parameters [ \"<STR_LIT>\" ] ) \n self . assertEqual ( s [ <NUM_LIT:2> ] . parameters [ \"<STR_LIT>\" ] , s [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] , s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] ) \n D2 [ \"<STR_LIT>\" ] . setValue ( False ) \n h2 = S . stateHash ( ) \n self . assertNotEqual ( h1 , h2 ) \n s = S . state ( ) \n self . assertEqual ( len ( s ) , <NUM_LIT:3> ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . name , passThroughCoshader ) \n self . assertEqual ( s [ <NUM_LIT:2> ] . name , shader ) \n self . assertEqual ( s [ <NUM_LIT:2> ] . parameters [ \"<STR_LIT>\" ] , s [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] , s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] ) \n D1 [ \"<STR_LIT>\" ] . setValue ( False ) \n h3 = S . stateHash ( ) \n self . assertNotEqual ( h3 , h2 ) \n self . assertNotEqual ( h3 , h1 ) \n s = S . state ( ) \n self . assertEqual ( len ( s ) , <NUM_LIT:2> ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . name , shader ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] , s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] ) \n def testDynamicCoshaderArrayParameters ( self ) : \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode = GafferRenderMan . RenderManShader ( ) \n coshaderNode . loadShader ( coshader ) \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n self . assertEqual ( len ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) , <NUM_LIT:1> ) \n self . assertTrue ( isinstance ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] , Gaffer . Plug ) ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . getInput ( ) is None ) \n shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . setInput ( coshaderNode [ \"<STR_LIT>\" ] ) \n self . assertEqual ( len ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) , <NUM_LIT:2> ) \n self . assertTrue ( isinstance ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] , Gaffer . Plug ) ) \n self . assertTrue ( isinstance ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] , Gaffer . Plug ) ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . getInput ( ) . isSame ( coshaderNode [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . getInput ( ) is None ) \n shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . setInput ( None ) \n self . assertEqual ( len ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) , <NUM_LIT:1> ) \n self . assertTrue ( isinstance ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] , Gaffer . Plug ) ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . getInput ( ) is None ) \n def testSerialiseDynamicCoshaderArrayParameters ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n s = Gaffer . ScriptNode ( ) \n s [ \"<STR_LIT:n>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT:n>\" ] . loadShader ( shader ) \n s [ \"<STR_LIT:c>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT:c>\" ] . loadShader ( coshader ) \n s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . setInput ( s [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . setInput ( s [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:2> ] . setInput ( s [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . setInput ( None ) \n self . assertEqual ( len ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) , <NUM_LIT:4> ) \n s2 = Gaffer . ScriptNode ( ) \n s2 . execute ( s . serialise ( ) ) \n self . assertEqual ( len ( s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) , <NUM_LIT:4> ) \n self . assertTrue ( s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . getInput ( ) . isSame ( s2 [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . getInput ( ) is None ) \n self . assertTrue ( s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:2> ] . getInput ( ) . isSame ( s2 [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:3> ] . getInput ( ) is None ) \n s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:3> ] . setInput ( s2 [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) \n self . assertEqual ( len ( s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) , <NUM_LIT:5> ) \n self . assertTrue ( s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . getInput ( ) . isSame ( s2 [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . getInput ( ) is None ) \n self . assertTrue ( s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:2> ] . getInput ( ) . isSame ( s2 [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:3> ] . getInput ( ) . isSame ( s2 [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:4> ] . getInput ( ) is None ) \n def testConvertFixedCoshaderArrayToDynamic ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderV2 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n s = Gaffer . ScriptNode ( ) \n s [ \"<STR_LIT:n>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT:n>\" ] . loadShader ( shader ) \n s [ \"<STR_LIT:c>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT:c>\" ] . loadShader ( coshader ) \n s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . setInput ( s [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) \n self . assertTrue ( len ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) , <NUM_LIT:4> ) \n s [ \"<STR_LIT:n>\" ] . loadShader ( shaderV2 , keepExistingValues = True ) \n self . assertTrue ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . getInput ( ) . isSame ( s [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . getInput ( ) is None ) \n s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . setInput ( None ) \n self . assertEqual ( len ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) , <NUM_LIT:1> ) \n self . assertTrue ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . getInput ( ) is None ) \n def testConvertFixedCoshaderArrayToDynamicWithFirstPlugUnconnected ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderV2 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n s = Gaffer . ScriptNode ( ) \n s [ \"<STR_LIT:n>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT:n>\" ] . loadShader ( shader ) \n s [ \"<STR_LIT:c>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT:c>\" ] . loadShader ( coshader ) \n s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . setInput ( s [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) \n self . assertTrue ( len ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) , <NUM_LIT:4> ) \n s [ \"<STR_LIT:n>\" ] . loadShader ( shaderV2 , keepExistingValues = True ) \n self . assertTrue ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . getInput ( ) . isSame ( s [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . getInput ( ) is None ) \n s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . setInput ( None ) \n self . assertEqual ( len ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) , <NUM_LIT:1> ) \n self . assertTrue ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . getInput ( ) is None ) \n def testConvertFixedCoshaderArrayToDynamicDuringLoading ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n s = Gaffer . ScriptNode ( ) \n s [ \"<STR_LIT:n>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT:n>\" ] . loadShader ( shader ) \n s [ \"<STR_LIT:c>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT:c>\" ] . loadShader ( coshader ) \n s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . setInput ( s [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) \n self . assertTrue ( len ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) , <NUM_LIT:4> ) \n GafferRenderMan . RenderManShader . shaderLoader ( ) . clear ( ) \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" , shaderName = \"<STR_LIT>\" ) \n s2 = Gaffer . ScriptNode ( ) \n s2 . execute ( s . serialise ( ) ) \n self . assertTrue ( s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . getInput ( ) . isSame ( s2 [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . getInput ( ) is None ) \n s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . setInput ( None ) \n self . assertEqual ( len ( s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) , <NUM_LIT:1> ) \n self . assertTrue ( s2 [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . getInput ( ) is None ) \n def testHashThroughBox ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n b = Gaffer . Box ( ) \n b . addChild ( Gaffer . Plug ( \"<STR_LIT>\" ) ) \n b . addChild ( Gaffer . Plug ( \"<STR_LIT>\" , direction = Gaffer . Plug . Direction . Out ) ) \n intermediateCoshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n intermediateCoshaderNode = GafferRenderMan . RenderManShader ( ) \n intermediateCoshaderNode . loadShader ( intermediateCoshader ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode = GafferRenderMan . RenderManShader ( ) \n coshaderNode . loadShader ( coshader ) \n b [ \"<STR_LIT>\" ] . setInput ( coshaderNode [ \"<STR_LIT>\" ] ) \n intermediateCoshaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( b [ \"<STR_LIT>\" ] ) \n b [ \"<STR_LIT>\" ] . setInput ( intermediateCoshaderNode [ \"<STR_LIT>\" ] ) \n shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( b [ \"<STR_LIT>\" ] ) \n h1 = shaderNode . stateHash ( ) \n coshaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( <NUM_LIT> ) \n self . assertNotEqual ( shaderNode . stateHash ( ) , h1 ) \n def testDanglingBoxConnection ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode1 = GafferRenderMan . RenderManShader ( ) \n shaderNode1 . loadShader ( shader ) \n shaderNode2 = GafferRenderMan . RenderManShader ( ) \n shaderNode2 . loadShader ( shader ) \n b = Gaffer . Box ( ) \n b . addChild ( Gaffer . Plug ( \"<STR_LIT>\" ) ) \n b . addChild ( Gaffer . Plug ( \"<STR_LIT>\" , direction = Gaffer . Plug . Direction . Out ) ) \n b [ \"<STR_LIT>\" ] = shaderNode1 \n shaderNode1 [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( b [ \"<STR_LIT>\" ] ) \n shaderNode2 [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( b [ \"<STR_LIT>\" ] ) \n def testUnconnectedCustomBoxInput ( self ) : \n class CustomBox ( Gaffer . Box ) : \n def __init__ ( self , name = \"<STR_LIT>\" ) : \n Gaffer . Box . __init__ ( self , name ) \n IECore . registerRunTimeTyped ( CustomBox ) \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n b = CustomBox ( ) \n b [ \"<STR_LIT:s>\" ] = GafferRenderMan . RenderManShader ( ) \n b [ \"<STR_LIT:s>\" ] . loadShader ( shader ) \n b [ \"<STR_LIT>\" ] = b [ \"<STR_LIT:s>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . createCounterpart ( \"<STR_LIT>\" , Gaffer . Plug . Direction . In ) \n b [ \"<STR_LIT:s>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( b [ \"<STR_LIT>\" ] ) \n s = b [ \"<STR_LIT:s>\" ] . state ( ) \n self . assertEqual ( len ( s ) , <NUM_LIT:1> ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . name , shader ) \n self . assertTrue ( b [ \"<STR_LIT:s>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getInput ( ) . isSame ( b [ \"<STR_LIT>\" ] ) ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n c = GafferRenderMan . RenderManShader ( ) \n c . loadShader ( coshader ) \n self . assertTrue ( b [ \"<STR_LIT>\" ] . acceptsInput ( c [ \"<STR_LIT>\" ] ) ) \n b [ \"<STR_LIT>\" ] . setInput ( c [ \"<STR_LIT>\" ] ) \n s = b [ \"<STR_LIT:s>\" ] . state ( ) \n self . assertEqual ( len ( s ) , <NUM_LIT:2> ) \n self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] , s [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] ) \n n = Gaffer . Node ( ) \n n [ \"<STR_LIT>\" ] = b [ \"<STR_LIT>\" ] . createCounterpart ( \"<STR_LIT>\" , Gaffer . Plug . Direction . Out ) \n self . assertFalse ( b [ \"<STR_LIT>\" ] . acceptsInput ( n [ \"<STR_LIT>\" ] ) ) \n self . assertRaises ( RuntimeError , b [ \"<STR_LIT>\" ] . setInput , n [ \"<STR_LIT>\" ] ) \n b [ \"<STR_LIT:s>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( None ) \n self . assertTrue ( b [ \"<STR_LIT>\" ] . acceptsInput ( n [ \"<STR_LIT>\" ] ) ) \n b [ \"<STR_LIT>\" ] . setInput ( n [ \"<STR_LIT>\" ] ) \n self . assertTrue ( b [ \"<STR_LIT>\" ] . getInput ( ) . isSame ( n [ \"<STR_LIT>\" ] ) ) \n self . assertFalse ( b [ \"<STR_LIT:s>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( b [ \"<STR_LIT>\" ] ) ) \n self . assertRaises ( RuntimeError , b [ \"<STR_LIT:s>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput , b [ \"<STR_LIT>\" ] ) \n def testCoshaderSwitching ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode0 = GafferRenderMan . RenderManShader ( ) \n coshaderNode0 . loadShader ( coshader ) \n coshaderNode1 = GafferRenderMan . RenderManShader ( ) \n coshaderNode1 . loadShader ( coshader ) \n coshaderNode0 [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( <NUM_LIT:0> ) \n coshaderNode1 [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( <NUM_LIT:1> ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n switch = GafferScene . ShaderSwitch ( ) \n switch [ \"<STR_LIT>\" ] . setInput ( coshaderNode0 [ \"<STR_LIT>\" ] ) \n switch [ \"<STR_LIT>\" ] . setInput ( coshaderNode1 [ \"<STR_LIT>\" ] ) \n shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( switch [ \"<STR_LIT>\" ] ) \n self . assertEqual ( shaderNode . state ( ) [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] . value , <NUM_LIT:0> ) \n switch [ \"<STR_LIT:index>\" ] . setValue ( <NUM_LIT:1> ) \n self . assertEqual ( shaderNode . state ( ) [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] . value , <NUM_LIT:1> ) \n switch [ \"<STR_LIT>\" ] . setValue ( False ) \n self . assertEqual ( shaderNode . state ( ) [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] . value , <NUM_LIT:0> ) \n def testCoshaderTypingPreventsNewInvalidSwitchInputs ( self ) : \n coshaderType1 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderType1Node = GafferRenderMan . RenderManShader ( ) \n coshaderType1Node . loadShader ( coshaderType1 ) \n coshaderType2 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderType2Node = GafferRenderMan . RenderManShader ( ) \n coshaderType2Node . loadShader ( coshaderType2 ) \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n switch = GafferScene . ShaderSwitch ( ) \n switch [ \"<STR_LIT>\" ] . setInput ( coshaderType1Node [ \"<STR_LIT>\" ] ) \n shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( switch [ \"<STR_LIT>\" ] ) \n self . assertFalse ( switch [ \"<STR_LIT>\" ] . acceptsInput ( coshaderType2Node [ \"<STR_LIT>\" ] ) ) \n self . assertTrue ( switch [ \"<STR_LIT>\" ] . acceptsInput ( coshaderType1Node [ \"<STR_LIT>\" ] ) ) \n def testAcceptInputFromEmptySwitch ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n switch = GafferScene . ShaderSwitch ( ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( switch [ \"<STR_LIT>\" ] ) ) \n def testCoshaderSwitchingInBox ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n script = Gaffer . ScriptNode ( ) \n script [ \"<STR_LIT>\" ] = GafferRenderMan . RenderManShader ( ) \n script [ \"<STR_LIT>\" ] . loadShader ( coshader ) \n script [ \"<STR_LIT>\" ] = GafferRenderMan . RenderManShader ( ) \n script [ \"<STR_LIT>\" ] . loadShader ( coshader ) \n script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( <NUM_LIT:0> ) \n script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( <NUM_LIT:1> ) \n script [ \"<STR_LIT>\" ] = GafferRenderMan . RenderManShader ( ) \n script [ \"<STR_LIT>\" ] . loadShader ( shader ) \n script [ \"<STR_LIT>\" ] = GafferScene . ShaderSwitch ( ) \n script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n self . assertEqual ( script [ \"<STR_LIT>\" ] . state ( ) [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] . value , <NUM_LIT:0> ) \n box = Gaffer . Box . create ( script , Gaffer . StandardSet ( script . children ( Gaffer . Node ) ) ) \n self . assertEqual ( box [ \"<STR_LIT>\" ] . state ( ) [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] . value , <NUM_LIT:0> ) \n promotedIndex = box . promotePlug ( box [ \"<STR_LIT>\" ] [ \"<STR_LIT:index>\" ] ) \n self . assertEqual ( box [ \"<STR_LIT>\" ] . state ( ) [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] . value , <NUM_LIT:0> ) \n promotedIndex . setValue ( <NUM_LIT:1> ) \n self . assertEqual ( box [ \"<STR_LIT>\" ] . state ( ) [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] . value , <NUM_LIT:1> ) \n def testRepeatability ( self ) : \n s1 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n s2 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n sn1 = GafferRenderMan . RenderManShader ( ) \n sn2 = GafferRenderMan . RenderManShader ( ) \n sn1 . loadShader ( s1 ) \n sn2 . loadShader ( s2 ) \n sn2 [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( sn1 [ \"<STR_LIT>\" ] ) \n self . assertEqual ( sn2 . stateHash ( ) , sn2 . stateHash ( ) ) \n self . assertEqual ( sn2 . state ( ) , sn2 . state ( ) ) \n def testHandlesAreHumanReadable ( self ) : \n s1 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n s2 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n sn1 = GafferRenderMan . RenderManShader ( \"<STR_LIT>\" ) \n sn2 = GafferRenderMan . RenderManShader ( \"<STR_LIT>\" ) \n sn1 . loadShader ( s1 ) \n sn2 . loadShader ( s2 ) \n sn2 [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( sn1 [ \"<STR_LIT>\" ] ) \n state = sn2 . state ( ) \n self . assertTrue ( \"<STR_LIT>\" in state [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] . value ) \n def testHandlesAreUniqueEvenIfNodeNamesArent ( self ) : \n s1 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n s2 = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n script = Gaffer . ScriptNode ( ) \n script [ \"<STR_LIT>\" ] = GafferRenderMan . RenderManShader ( ) \n script [ \"<STR_LIT>\" ] . loadShader ( s1 ) \n script [ \"<STR_LIT>\" ] = GafferRenderMan . RenderManShader ( ) \n script [ \"<STR_LIT>\" ] . loadShader ( s1 ) \n script [ \"<STR_LIT>\" ] = GafferRenderMan . RenderManShader ( ) \n script [ \"<STR_LIT>\" ] . loadShader ( s2 ) \n script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] . setInput ( script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] . setInput ( script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n box = Gaffer . Box . create ( script , Gaffer . StandardSet ( [ script [ \"<STR_LIT>\" ] ] ) ) \n box [ \"<STR_LIT>\" ] . setName ( \"<STR_LIT>\" ) \n script [ \"<STR_LIT>\" ] . setName ( \"<STR_LIT>\" ) \n state = script [ \"<STR_LIT>\" ] . state ( ) \n self . assertNotEqual ( state [ <NUM_LIT:0> ] . parameters [ \"<STR_LIT>\" ] , state [ <NUM_LIT:1> ] . parameters [ \"<STR_LIT>\" ] ) \n def testShaderTypesInState ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode = GafferRenderMan . RenderManShader ( ) \n coshaderNode . loadShader ( coshader ) \n shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( coshaderNode [ \"<STR_LIT>\" ] ) \n state = shaderNode . state ( ) \n self . assertEqual ( state [ <NUM_LIT:0> ] . type , \"<STR_LIT>\" ) \n self . assertEqual ( state [ <NUM_LIT:1> ] . type , \"<STR_LIT>\" ) \n def testAssignmentAttributeName ( self ) : \n p = GafferScene . Plane ( ) \n s = GafferRenderMan . RenderManShader ( ) \n s . loadShader ( \"<STR_LIT>\" ) \n a = GafferScene . ShaderAssignment ( ) \n a [ \"<STR_LIT>\" ] . setInput ( p [ \"<STR_LIT>\" ] ) \n a [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] ) \n self . assertEqual ( a [ \"<STR_LIT>\" ] . attributes ( \"<STR_LIT>\" ) . keys ( ) , [ \"<STR_LIT>\" ] ) \n def testVolumeShader ( self ) : \n s = GafferRenderMan . RenderManShader ( ) \n s . loadShader ( \"<STR_LIT>\" ) \n self . assertEqual ( s [ \"<STR_LIT:type>\" ] . getValue ( ) , \"<STR_LIT>\" ) \n s [ \"<STR_LIT:type>\" ] . setValue ( \"<STR_LIT>\" ) \n s . loadShader ( \"<STR_LIT>\" , keepExistingValues = True ) \n self . assertEqual ( s [ \"<STR_LIT:type>\" ] . getValue ( ) , \"<STR_LIT>\" ) \n s . loadShader ( \"<STR_LIT>\" , keepExistingValues = False ) \n self . assertEqual ( s [ \"<STR_LIT:type>\" ] . getValue ( ) , \"<STR_LIT>\" ) \n def testInputAcceptanceFromDots ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshaderNode = GafferRenderMan . RenderManShader ( ) \n coshaderNode . loadShader ( coshader ) \n dot = Gaffer . Dot ( ) \n dot . setup ( coshaderNode [ \"<STR_LIT>\" ] ) \n self . assertTrue ( shaderNode [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . acceptsInput ( dot [ \"<STR_LIT>\" ] ) ) \n def testShaderTypeOverride ( self ) : \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n shaderNode = GafferRenderMan . RenderManShader ( ) \n shaderNode . loadShader ( shader ) \n self . assertEqual ( shaderNode [ '<STR_LIT:type>' ] . getValue ( ) , \"<STR_LIT>\" ) \n def testReferencePromotedCoshader ( self ) : \n s = Gaffer . ScriptNode ( ) \n shader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n coshader = self . compileShader ( os . path . dirname ( __file__ ) + \"<STR_LIT>\" ) \n s [ \"<STR_LIT:b>\" ] = Gaffer . Box ( ) \n s [ \"<STR_LIT:b>\" ] [ \"<STR_LIT:s>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT:b>\" ] [ \"<STR_LIT:s>\" ] . loadShader ( shader ) \n p = s [ \"<STR_LIT:b>\" ] . promotePlug ( s [ \"<STR_LIT:b>\" ] [ \"<STR_LIT:s>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n p . setName ( \"<STR_LIT:p>\" ) \n s [ \"<STR_LIT:c>\" ] = GafferRenderMan . RenderManShader ( ) \n s [ \"<STR_LIT:c>\" ] . loadShader ( coshader ) \n self . assertTrue ( s [ \"<STR_LIT:b>\" ] [ \"<STR_LIT:p>\" ] . acceptsInput ( s [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) ) \n s [ \"<STR_LIT:b>\" ] . exportForReference ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n s [ \"<STR_LIT:r>\" ] = Gaffer . Reference ( ) \n s [ \"<STR_LIT:r>\" ] . load ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n self . assertTrue ( s [ \"<STR_LIT:r>\" ] [ \"<STR_LIT:p>\" ] . acceptsInput ( s [ \"<STR_LIT:c>\" ] [ \"<STR_LIT>\" ] ) ) \n def testLoadAndGIL ( self ) : \n script = Gaffer . ScriptNode ( ) \n script [ \"<STR_LIT>\" ] = GafferScene . Plane ( ) \n script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( IECore . V2i ( <NUM_LIT:20> ) ) \n script [ \"<STR_LIT>\" ] = GafferScene . Sphere ( ) \n script [ \"<STR_LIT>\" ] = Gaffer . Expression ( ) \n script [ \"<STR_LIT>\" ] . setExpression ( \"<STR_LIT>\" ) \n script [ \"<STR_LIT>\" ] = GafferScene . Instancer ( ) \n script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT>\" ) \n script [ \"<STR_LIT>\" ] = GafferRenderMan . RenderManShader ( ) \n script [ \"<STR_LIT>\" ] = GafferScene . ShaderAssignment ( ) \n script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n traverseConnection = Gaffer . ScopedConnection ( GafferSceneTest . connectTraverseSceneToPlugDirtiedSignal ( script [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) ) \n script [ \"<STR_LIT>\" ] . loadShader ( \"<STR_LIT>\" ) \n if __name__ == \"<STR_LIT:__main__>\" : \n unittest . main ( ) \n", "gt": "n"}
{"input": "\n import os \n import unittest \n import IECore \n import Gaffer \n import GafferImage \n import GafferScene \n import GafferSceneTest \n @ unittest . skipIf ( \"<STR_LIT>\" in os . environ , \"<STR_LIT>\" ) \n class OpenGLRenderTest ( GafferSceneTest . SceneTestCase ) : \n def test ( self ) : \n self . assertFalse ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) ) \n <mask0> = Gaffer . ScriptNode ( ) \n s [ \"<STR_LIT>\" ] = GafferScene . Plane ( ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( IECore . V3f ( <NUM_LIT:0> , <NUM_LIT:0> , - <NUM_LIT:5> ) ) \n s [ \"<STR_LIT:image>\" ] = GafferImage . ImageReader ( ) \n s [ \"<STR_LIT:image>\" ] [ \"<STR_LIT>\" ] . setValue ( os . path . expandvars ( \"<STR_LIT>\" ) ) \n s [ \"<STR_LIT>\" ] = GafferScene . OpenGLShader ( ) \n s [ \"<STR_LIT>\" ] . loadShader ( \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT:image>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( <NUM_LIT:1> ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue ( IECore . Color4f ( <NUM_LIT:1> ) ) \n s [ \"<STR_LIT>\" ] = GafferScene . ShaderAssignment ( ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT>\" ] = GafferScene . Outputs ( ) \n s [ \"<STR_LIT>\" ] . addOutput ( \n \"<STR_LIT>\" , \n IECore . Display ( \n self . temporaryDirectory ( ) + \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n { } \n ) \n ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT>\" ] = GafferScene . OpenGLRender ( ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT>\" ] . setValue ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n s . save ( ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . execute ( ) \n self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) ) \n i = IECore . EXRImageReader ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) . read ( ) \n e = IECore . ImagePrimitiveEvaluator ( i ) \n r = e . createResult ( ) \n e . pointAtUV ( IECore . V2f ( <NUM_LIT:0.5> ) , r ) \n self . assertAlmostEqual ( r . floatPrimVar ( e . R ( ) ) , <NUM_LIT> , <NUM_LIT:5> ) \n self . assertAlmostEqual ( r . floatPrimVar ( e . G ( ) ) , <NUM_LIT> , <NUM_LIT:5> ) \n self . assertEqual ( r . floatPrimVar ( e . B ( ) ) , <NUM_LIT:0> ) \n def testOutputDirectoryCreation ( self ) : \n s = Gaffer . ScriptNode ( ) \n s [ \"<STR_LIT>\" ] . addMember ( \"<STR_LIT>\" , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n s [ \"<STR_LIT>\" ] = GafferScene . Plane ( ) \n s [ \"<STR_LIT>\" ] = GafferScene . Outputs ( ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT>\" ] . addOutput ( \n \"<STR_LIT>\" , \n IECore . Display ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n { } \n ) \n ) \n s [ \"<STR_LIT>\" ] = GafferScene . OpenGLRender ( ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n self . assertFalse ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) ) \n self . assertFalse ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) ) \n s [ \"<STR_LIT>\" ] . setValue ( \"<STR_LIT>\" ) \n with s . context ( ) : \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . execute ( ) \n self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) ) \n self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) ) \n def testHash ( self ) : \n c = Gaffer . Context ( ) \n c . setFrame ( <NUM_LIT:1> ) \n c2 = Gaffer . Context ( ) \n c2 . setFrame ( <NUM_LIT:2> ) \n s = Gaffer . ScriptNode ( ) \n s [ \"<STR_LIT>\" ] = GafferScene . Plane ( ) \n s [ \"<STR_LIT>\" ] = GafferScene . Outputs ( ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n s [ \"<STR_LIT>\" ] . addOutput ( \"<STR_LIT>\" , IECore . Display ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , { } ) ) \n s [ \"<STR_LIT>\" ] = GafferScene . OpenGLRender ( ) \n self . assertEqual ( s [ \"<STR_LIT>\" ] . hash ( c ) , IECore . MurmurHash ( ) ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n self . assertNotEqual ( s [ \"<STR_LIT>\" ] . hash ( c ) , IECore . MurmurHash ( ) ) \n self . assertNotEqual ( s [ \"<STR_LIT>\" ] . hash ( c ) , s [ \"<STR_LIT>\" ] . hash ( c2 ) ) \n current = s [ \"<STR_LIT>\" ] . hash ( c ) \n c [ \"<STR_LIT>\" ] = self . temporaryDirectory ( ) + \"<STR_LIT>\" \n self . assertNotEqual ( s [ \"<STR_LIT>\" ] . hash ( c ) , current ) \n current = s [ \"<STR_LIT>\" ] . hash ( c ) \n c [ \"<STR_LIT>\" ] = self . temporaryDirectory ( ) + \"<STR_LIT>\" \n self . assertNotEqual ( s [ \"<STR_LIT>\" ] . hash ( c ) , current ) \n current = s [ \"<STR_LIT>\" ] . hash ( c ) \n c [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n self . assertEqual ( s [ \"<STR_LIT>\" ] . hash ( c ) , current ) \n current = s [ \"<STR_LIT>\" ] . hash ( c ) \n s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setInput ( s [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) \n self . assertNotEqual ( s [ \"<STR_LIT>\" ] . hash ( c ) , current ) \n if __name__ == \"<STR_LIT:__main__>\" : \n unittest . main ( ) \n", "gt": "s"}
{"input": "\n import unittest \n import IECore \n import Gaffer \n import GafferTest \n import GafferScene \n import GafferSceneTest \n class SceneTimeWarpTest ( GafferSceneTest . SceneTestCase ) : \n def testConstruct ( self ) : \n <mask0> = Gaffer . ScriptNode ( ) \n s [ \"<STR_LIT:n>\" ] = GafferScene . SceneTimeWarp ( ) \n self . assertEqual ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , <NUM_LIT:1> ) \n self . assertEqual ( s [ \"<STR_LIT:n>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , <NUM_LIT:0> ) \n def testRunTimeTyped ( self ) : \n n = GafferScene . SceneTimeWarp ( ) \n self . failUnless ( n . isInstanceOf ( GafferScene . SceneTimeWarp . staticTypeId ( ) ) ) \n self . failUnless ( n . isInstanceOf ( GafferScene . SceneContextProcessor . staticTypeId ( ) ) ) \n self . failUnless ( n . isInstanceOf ( GafferScene . SceneProcessor . staticTypeId ( ) ) ) \n self . failUnless ( n . isInstanceOf ( GafferScene . SceneNode . staticTypeId ( ) ) ) \n self . failUnless ( n . isInstanceOf ( Gaffer . Node . staticTypeId ( ) ) ) \n baseTypeIds = IECore . RunTimeTyped . baseTypeIds ( n . typeId ( ) ) \n self . failUnless ( GafferScene . SceneContextProcessor . staticTypeId ( ) in baseTypeIds ) \n self . failUnless ( GafferScene . SceneProcessor . staticTypeId ( ) in baseTypeIds ) \n self . failUnless ( GafferScene . SceneNode . staticTypeId ( ) in baseTypeIds ) \n self . failUnless ( Gaffer . Node . staticTypeId ( ) in baseTypeIds ) \n def testAffects ( self ) : \n n = GafferScene . SceneTimeWarp ( ) \n c = GafferTest . CapturingSlot ( n . plugDirtiedSignal ( ) ) \n n [ \"<STR_LIT>\" ] . setValue ( <NUM_LIT:2> ) \n found = False \n for cc in c : \n if cc [ <NUM_LIT:0> ] . isSame ( n [ \"<STR_LIT>\" ] ) : \n found = True \n self . failUnless ( found ) \n del c [ : ] \n n [ \"<STR_LIT>\" ] . setValue ( <NUM_LIT:2> ) \n found = False \n for cc in c : \n if cc [ <NUM_LIT:0> ] . isSame ( n [ \"<STR_LIT>\" ] ) : \n found = True \n self . failUnless ( found ) \n def testNoExtraInputs ( self ) : \n p = GafferScene . Plane ( ) \n n = GafferScene . SceneTimeWarp ( ) \n n [ \"<STR_LIT>\" ] . setInput ( p [ \"<STR_LIT>\" ] ) \n self . assertTrue ( \"<STR_LIT>\" not in n ) \n if __name__ == \"<STR_LIT:__main__>\" : \n unittest . main ( ) \n", "gt": "s"}
{"input": "\n import functools \n import IECore \n import Gaffer \n import GafferUI \n import GafferScene \n import GafferSceneUI \n Gaffer . Metadata . registerNode ( \n GafferSceneUI . SceneView , \n plugs = { \n \"<STR_LIT>\" : [ \n \"<STR_LIT>\" , <NUM_LIT:2> , \n \"<STR_LIT>\" , True , \n \"<STR_LIT>\" , \"<STR_LIT>\" , \n ] , \n \"<STR_LIT>\" : [ \n \"<STR_LIT>\" , \"<STR_LIT>\" , \n \"<STR_LIT>\" , True , \n ] , \n \"<STR_LIT>\" : [ \n \"<STR_LIT>\" , \"<STR_LIT>\" , \n \"<STR_LIT>\" , True , \n \"<STR_LIT>\" , \"<STR_LIT>\" , \n ] , \n \"<STR_LIT>\" : [ \n \"<STR_LIT:description>\" , \n \"\"\"<STR_LIT>\"\"\" , \n ] , \n \"<STR_LIT>\" : [ \n \"<STR_LIT:description>\" , \n \"\"\"<STR_LIT>\"\"\" , \n ] , \n \"<STR_LIT>\" : [ \n \"<STR_LIT>\" , \"<STR_LIT>\" , \n ] , \n \"<STR_LIT>\" : [ \n \"<STR_LIT>\" , \"<STR_LIT>\" , \n ] , \n } \n ) \n class _ShadingModePlugValueWidget ( GafferUI . PlugValueWidget ) : \n def __init__ ( self , plug , parenting = None ) : \n <mask0> = GafferUI . MenuButton ( \n image = \"<STR_LIT>\" , \n menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __menuDefinition ) ) , \n hasFrame = False , \n ) \n GafferUI . PlugValueWidget . __init__ ( self , menuButton , plug , parenting = parenting ) \n def hasLabel ( self ) : \n return True \n def _updateFromPlug ( self ) : \n pass \n def __menuDefinition ( self ) : \n m = IECore . MenuDefinition ( ) \n currentName = self . getPlug ( ) . getValue ( ) \n for name in [ \"<STR_LIT>\" ] + GafferSceneUI . SceneView . registeredShadingModes ( ) : \n m . append ( \n \"<STR_LIT:/>\" + name if name else \"<STR_LIT>\" , \n { \n \"<STR_LIT>\" : name == currentName , \n \"<STR_LIT>\" : functools . partial ( Gaffer . WeakMethod ( self . __setValue ) , name if name != currentName else \"<STR_LIT>\" ) , \n } \n ) \n if not name : \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : True } ) \n return m \n def __setValue ( self , value , * unused ) : \n self . getPlug ( ) . setValue ( value ) \n class _ExpansionPlugValueWidget ( GafferUI . PlugValueWidget ) : \n def __init__ ( self , plug , parenting = None ) : \n menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __menuDefinition ) ) \n menuButton = GafferUI . MenuButton ( menu = menu , image = \"<STR_LIT>\" , hasFrame = False ) \n GafferUI . PlugValueWidget . __init__ ( self , menuButton , plug , parenting = parenting ) \n def hasLabel ( self ) : \n return True \n def _updateFromPlug ( self ) : \n pass \n def __menuDefinition ( self ) : \n expandAll = bool ( self . getPlug ( ) . getValue ( ) ) \n m = IECore . MenuDefinition ( ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : self . getPlug ( ) . node ( ) . expandSelection , \"<STR_LIT>\" : not expandAll , \"<STR_LIT>\" : \"<STR_LIT>\" } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : IECore . curry ( self . getPlug ( ) . node ( ) . expandSelection , depth = <NUM_LIT> ) , \"<STR_LIT>\" : not expandAll , \"<STR_LIT>\" : \"<STR_LIT>\" } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : self . getPlug ( ) . node ( ) . collapseSelection , \"<STR_LIT>\" : not expandAll , \"<STR_LIT>\" : \"<STR_LIT>\" } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : True } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : expandAll , \"<STR_LIT>\" : Gaffer . WeakMethod ( self . __toggleMinimumExpansionDepth ) } ) \n return m \n def __toggleMinimumExpansionDepth ( self , * unused ) : \n self . getPlug ( ) . setValue ( <NUM_LIT:0> if self . getPlug ( ) . getValue ( ) else <NUM_LIT> ) \n class _LookThroughPlugValueWidget ( GafferUI . PlugValueWidget ) : \n def __init__ ( self , plug , parenting = None ) : \n row = GafferUI . ListContainer ( GafferUI . ListContainer . Orientation . Horizontal ) \n GafferUI . PlugValueWidget . __init__ ( self , row , plug , parenting = parenting ) \n with row : \n self . __enabledWidget = GafferUI . BoolPlugValueWidget ( plug [ \"<STR_LIT>\" ] , displayMode = GafferUI . BoolWidget . DisplayMode . Switch ) \n self . __cameraWidget = GafferSceneUI . ScenePathPlugValueWidget ( \n plug [ \"<STR_LIT>\" ] , \n path = GafferScene . ScenePath ( \n plug . node ( ) [ \"<STR_LIT>\" ] , \n plug . node ( ) . getContext ( ) , \n \"<STR_LIT:/>\" , \n filter = GafferScene . ScenePath . createStandardFilter ( [ \"<STR_LIT>\" ] , \"<STR_LIT>\" ) \n ) , \n ) \n self . __cameraWidget . pathWidget ( ) . setFixedCharacterWidth ( <NUM_LIT> ) \n if hasattr ( self . __cameraWidget . pathWidget ( ) . _qtWidget ( ) , \"<STR_LIT>\" ) : \n self . __cameraWidget . pathWidget ( ) . _qtWidget ( ) . setPlaceholderText ( \"<STR_LIT>\" ) \n self . _updateFromPlug ( ) \n def _updateFromPlug ( self ) : \n with self . getContext ( ) : \n self . __cameraWidget . setEnabled ( self . getPlug ( ) [ \"<STR_LIT>\" ] . getValue ( ) ) \n class _GridPlugValueWidget ( GafferUI . PlugValueWidget ) : \n def __init__ ( self , plug , parenting = None ) : \n menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __menuDefinition ) ) \n menuButton = GafferUI . MenuButton ( menu = menu , image = \"<STR_LIT>\" , hasFrame = False ) \n GafferUI . PlugValueWidget . __init__ ( self , menuButton , plug , parenting = parenting ) \n def hasLabel ( self ) : \n return True \n def _updateFromPlug ( self ) : \n pass \n def __menuDefinition ( self ) : \n m = IECore . MenuDefinition ( ) \n m . append ( \n \"<STR_LIT>\" , \n { \n \"<STR_LIT>\" : self . getPlug ( ) [ \"<STR_LIT>\" ] . getValue ( ) , \n \"<STR_LIT>\" : self . getPlug ( ) [ \"<STR_LIT>\" ] . setValue , \n } \n ) \n m . append ( \n \"<STR_LIT>\" , \n { \n \"<STR_LIT>\" : self . getPlug ( ) . node ( ) [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . getValue ( ) , \n \"<STR_LIT>\" : self . getPlug ( ) . node ( ) [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . setValue , \n } \n ) \n return m \n", "gt": "menuButton"}
{"input": "\n import IECore \n import Gaffer \n class AddNode ( Gaffer . ComputeNode ) : \n def __init__ ( self , name = \"<STR_LIT>\" ) : \n Gaffer . ComputeNode . __init__ ( self , name ) \n <mask0> = Gaffer . IntPlug ( \"<STR_LIT>\" , Gaffer . Plug . Direction . In ) \n p2 = Gaffer . IntPlug ( \"<STR_LIT>\" , Gaffer . Plug . Direction . In ) \n self . addChild ( Gaffer . BoolPlug ( \"<STR_LIT>\" , defaultValue = True ) ) \n self . addChild ( p1 ) \n self . addChild ( p2 ) \n p3 = Gaffer . IntPlug ( \"<STR_LIT>\" , Gaffer . Plug . Direction . Out ) \n self . addChild ( p3 ) \n self . numHashCalls = <NUM_LIT:0> \n self . numComputeCalls = <NUM_LIT:0> \n def enabledPlug ( self ) : \n return self [ \"<STR_LIT>\" ] \n def correspondingInput ( self , output ) : \n if output . isSame ( self [ \"<STR_LIT>\" ] ) : \n return self [ \"<STR_LIT>\" ] \n return Gaffer . ComputeNode . correspondingInput ( self , output ) \n def affects ( self , input ) : \n outputs = Gaffer . ComputeNode . affects ( self , input ) \n if input . getName ( ) in ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) : \n outputs . append ( self . getChild ( \"<STR_LIT>\" ) ) \n return outputs \n def hash ( self , output , context , h ) : \n assert ( output . isSame ( self . getChild ( \"<STR_LIT>\" ) ) or plug . getFlags ( ) & plug . Flags . Dynamic ) \n self . getChild ( \"<STR_LIT>\" ) . hash ( h ) \n self . getChild ( \"<STR_LIT>\" ) . hash ( h ) \n self . getChild ( \"<STR_LIT>\" ) . hash ( h ) \n self . numHashCalls += <NUM_LIT:1> \n def compute ( self , plug , context ) : \n assert ( plug . isSame ( self . getChild ( \"<STR_LIT>\" ) ) or plug . getFlags ( ) & plug . Flags . Dynamic ) \n assert ( isinstance ( context , Gaffer . Context ) ) \n assert ( plug . settable ( ) ) \n assert ( not self [ \"<STR_LIT>\" ] . settable ( ) ) \n assert ( not self [ \"<STR_LIT>\" ] . settable ( ) ) \n if self [ \"<STR_LIT>\" ] . getValue ( ) : \n plug . setValue ( self . getChild ( \"<STR_LIT>\" ) . getValue ( ) + self . getChild ( \"<STR_LIT>\" ) . getValue ( ) ) \n else : \n plug . setValue ( self . getChild ( \"<STR_LIT>\" ) . getValue ( ) ) \n self . numComputeCalls += <NUM_LIT:1> \n IECore . registerRunTimeTyped ( AddNode , typeName = \"<STR_LIT>\" ) \n", "gt": "p1"}
{"input": "\n from __future__ import with_statement \n import unittest \n import time \n import datetime \n import pwd \n import grp \n import os \n import IECore \n import Gaffer \n import GafferTest \n class FileSystemPathTest ( GafferTest . TestCase ) : \n def test ( self ) : \n <mask0> = Gaffer . FileSystemPath ( __file__ ) \n self . assert_ ( p . isValid ( ) ) \n self . assert_ ( p . isLeaf ( ) ) \n while len ( p ) : \n del p [ - <NUM_LIT:1> ] \n self . assert_ ( p . isValid ( ) ) \n self . assert_ ( not p . isLeaf ( ) ) \n def testIsLeaf ( self ) : \n path = Gaffer . FileSystemPath ( \"<STR_LIT>\" ) \n self . assert_ ( not path . isLeaf ( ) ) \n def testConstructWithFilter ( self ) : \n p = Gaffer . FileSystemPath ( __file__ ) \n self . failUnless ( p . getFilter ( ) is None ) \n f = Gaffer . FileNamePathFilter ( [ \"<STR_LIT>\" ] ) \n p = Gaffer . FileSystemPath ( __file__ , filter = f ) \n self . failUnless ( p . getFilter ( ) . isSame ( f ) ) \n def testBrokenSymbolicLinks ( self ) : \n os . symlink ( self . temporaryDirectory ( ) + \"<STR_LIT>\" , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n d = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) ) \n c = d . children ( ) \n self . assertEqual ( len ( c ) , <NUM_LIT:1> ) \n l = c [ <NUM_LIT:0> ] \n self . assertEqual ( str ( l ) , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n self . assertEqual ( l . isValid ( ) , True ) \n info = l . info ( ) \n self . failUnless ( info is not None ) \n def testSymLinkInfo ( self ) : \n with open ( self . temporaryDirectory ( ) + \"<STR_LIT>\" , \"<STR_LIT:w>\" ) as f : \n f . write ( \"<STR_LIT>\" ) \n os . symlink ( self . temporaryDirectory ( ) + \"<STR_LIT>\" , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n a = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n l = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n aInfo = a . info ( ) \n self . assertEqual ( aInfo [ \"<STR_LIT>\" ] , l . info ( ) [ \"<STR_LIT>\" ] ) \n os . remove ( str ( a ) ) \n self . assertNotEqual ( aInfo [ \"<STR_LIT>\" ] , l . info ( ) [ \"<STR_LIT>\" ] ) \n def testCopy ( self ) : \n p = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) ) \n p2 = p . copy ( ) \n self . assertEqual ( p , p2 ) \n self . assertEqual ( str ( p ) , str ( p2 ) ) \n def testEmptyPath ( self ) : \n p = Gaffer . FileSystemPath ( ) \n self . assertEqual ( str ( p ) , \"<STR_LIT>\" ) \n self . assertTrue ( p . isEmpty ( ) ) \n self . assertFalse ( p . isValid ( ) ) \n def testRelativePath ( self ) : \n os . chdir ( self . temporaryDirectory ( ) ) \n with open ( self . temporaryDirectory ( ) + \"<STR_LIT>\" , \"<STR_LIT:w>\" ) as f : \n f . write ( \"<STR_LIT>\" ) \n p = Gaffer . FileSystemPath ( \"<STR_LIT:a>\" ) \n self . assertEqual ( str ( p ) , \"<STR_LIT:a>\" ) \n self . assertFalse ( p . isEmpty ( ) ) \n self . assertTrue ( p . isValid ( ) ) \n p2 = Gaffer . FileSystemPath ( \"<STR_LIT>\" ) \n self . assertEqual ( str ( p2 ) , \"<STR_LIT>\" ) \n self . assertFalse ( p2 . isEmpty ( ) ) \n self . assertFalse ( p2 . isValid ( ) ) \n def testRelativePathChildren ( self ) : \n os . chdir ( self . temporaryDirectory ( ) ) \n os . mkdir ( \"<STR_LIT>\" ) \n with open ( self . temporaryDirectory ( ) + \"<STR_LIT>\" , \"<STR_LIT:w>\" ) as f : \n f . write ( \"<STR_LIT>\" ) \n p = Gaffer . FileSystemPath ( \"<STR_LIT>\" ) \n c = p . children ( ) \n self . assertEqual ( len ( c ) , <NUM_LIT:1> ) \n self . assertEqual ( str ( c [ <NUM_LIT:0> ] ) , \"<STR_LIT>\" ) \n self . assertTrue ( c [ <NUM_LIT:0> ] . isValid ( ) ) \n def testChildrenOfFile ( self ) : \n p = Gaffer . FileSystemPath ( __file__ ) \n self . assertEqual ( p . children ( ) , [ ] ) \n def testModificationTimes ( self ) : \n p = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) ) \n p . append ( \"<STR_LIT:t>\" ) \n with open ( str ( p ) , \"<STR_LIT:w>\" ) as f : \n f . write ( \"<STR_LIT>\" ) \n mt = p . property ( \"<STR_LIT>\" ) \n self . assertTrue ( isinstance ( mt , datetime . datetime ) ) \n self . assertLess ( ( datetime . datetime . utcnow ( ) - mt ) . total_seconds ( ) , <NUM_LIT:2> ) \n time . sleep ( <NUM_LIT:1> ) \n with open ( str ( p ) , \"<STR_LIT:w>\" ) as f : \n f . write ( \"<STR_LIT>\" ) \n mt = p . property ( \"<STR_LIT>\" ) \n self . assertTrue ( isinstance ( mt , datetime . datetime ) ) \n self . assertLess ( ( datetime . datetime . utcnow ( ) - mt ) . total_seconds ( ) , <NUM_LIT:2> ) \n def testOwner ( self ) : \n p = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) ) \n p . append ( \"<STR_LIT:t>\" ) \n with open ( str ( p ) , \"<STR_LIT:w>\" ) as f : \n f . write ( \"<STR_LIT>\" ) \n o = p . property ( \"<STR_LIT>\" ) \n self . assertTrue ( isinstance ( o , str ) ) \n self . assertEqual ( o , pwd . getpwuid ( os . stat ( str ( p ) ) . st_uid ) . pw_name ) \n def testGroup ( self ) : \n p = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) ) \n p . append ( \"<STR_LIT:t>\" ) \n with open ( str ( p ) , \"<STR_LIT:w>\" ) as f : \n f . write ( \"<STR_LIT>\" ) \n g = p . property ( \"<STR_LIT>\" ) \n self . assertTrue ( isinstance ( g , str ) ) \n self . assertEqual ( g , grp . getgrgid ( os . stat ( str ( p ) ) . st_gid ) . gr_name ) \n def testPropertyNames ( self ) : \n p = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) ) \n a = p . propertyNames ( ) \n self . assertTrue ( isinstance ( a , list ) ) \n self . assertTrue ( \"<STR_LIT>\" in a ) \n self . assertTrue ( \"<STR_LIT>\" in a ) \n self . assertTrue ( \"<STR_LIT>\" in a ) \n self . assertTrue ( \"<STR_LIT>\" in a ) \n self . assertTrue ( \"<STR_LIT>\" not in a ) \n p = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) , includeSequences = True ) \n self . assertTrue ( \"<STR_LIT>\" in p . propertyNames ( ) ) \n def testSequences ( self ) : \n os . mkdir ( self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n for n in [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] : \n with open ( self . temporaryDirectory ( ) + \"<STR_LIT:/>\" + n , \"<STR_LIT:w>\" ) as f : \n f . write ( \"<STR_LIT>\" ) \n p = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) , includeSequences = True ) \n self . assertTrue ( p . getIncludeSequences ( ) ) \n c = p . children ( ) \n self . assertEqual ( len ( c ) , <NUM_LIT:8> ) \n s = sorted ( c , key = str ) \n self . assertEqual ( str ( s [ <NUM_LIT:0> ] ) , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n self . assertEqual ( str ( s [ <NUM_LIT:1> ] ) , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n self . assertEqual ( str ( s [ <NUM_LIT:2> ] ) , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n self . assertEqual ( str ( s [ <NUM_LIT:3> ] ) , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n self . assertEqual ( str ( s [ <NUM_LIT:4> ] ) , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n self . assertEqual ( str ( s [ <NUM_LIT:5> ] ) , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n self . assertEqual ( str ( s [ <NUM_LIT:6> ] ) , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n self . assertEqual ( str ( s [ <NUM_LIT:7> ] ) , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n for x in s : \n self . assertTrue ( x . isValid ( ) ) \n if not os . path . isdir ( str ( x ) ) : \n self . assertTrue ( x . isLeaf ( ) ) \n self . assertEqual ( x . property ( \"<STR_LIT>\" ) , pwd . getpwuid ( os . stat ( str ( p ) ) . st_uid ) . pw_name ) \n self . assertEqual ( x . property ( \"<STR_LIT>\" ) , grp . getgrgid ( os . stat ( str ( p ) ) . st_gid ) . gr_name ) \n self . assertLess ( ( datetime . datetime . utcnow ( ) - x . property ( \"<STR_LIT>\" ) ) . total_seconds ( ) , <NUM_LIT:2> ) \n if \"<STR_LIT>\" not in str ( x ) : \n self . assertFalse ( x . isFileSequence ( ) ) \n self . assertEqual ( x . fileSequence ( ) , None ) \n self . assertEqual ( x . property ( \"<STR_LIT>\" ) , \"<STR_LIT>\" ) \n if os . path . isdir ( str ( x ) ) : \n self . assertEqual ( x . property ( \"<STR_LIT>\" ) , <NUM_LIT:0> ) \n else : \n self . assertEqual ( x . property ( \"<STR_LIT>\" ) , <NUM_LIT:4> ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . property ( \"<STR_LIT>\" ) , \"<STR_LIT>\" ) \n self . assertTrue ( s [ <NUM_LIT:0> ] . isFileSequence ( ) ) \n self . assertTrue ( isinstance ( s [ <NUM_LIT:0> ] . fileSequence ( ) , IECore . FileSequence ) ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . fileSequence ( ) , IECore . FileSequence ( str ( s [ <NUM_LIT:0> ] ) , IECore . frameListFromList ( [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:4> ] ) ) ) \n self . assertEqual ( s [ <NUM_LIT:0> ] . property ( \"<STR_LIT>\" ) , <NUM_LIT:4> * <NUM_LIT:3> ) \n self . assertEqual ( s [ <NUM_LIT:4> ] . property ( \"<STR_LIT>\" ) , \"<STR_LIT:3>\" ) \n self . assertTrue ( s [ <NUM_LIT:4> ] . isFileSequence ( ) ) \n self . assertTrue ( isinstance ( s [ <NUM_LIT:4> ] . fileSequence ( ) , IECore . FileSequence ) ) \n self . assertEqual ( s [ <NUM_LIT:4> ] . fileSequence ( ) , IECore . FileSequence ( str ( s [ <NUM_LIT:4> ] ) , IECore . frameListFromList ( [ <NUM_LIT:3> ] ) ) ) \n self . assertEqual ( s [ <NUM_LIT:4> ] . property ( \"<STR_LIT>\" ) , <NUM_LIT:4> ) \n p2 = p . copy ( ) \n self . assertTrue ( p2 . getIncludeSequences ( ) ) \n self . assertEqual ( len ( p2 . children ( ) ) , <NUM_LIT:8> ) \n p = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) , includeSequences = False ) \n self . assertFalse ( p . getIncludeSequences ( ) ) \n c = p . children ( ) \n self . assertEqual ( len ( c ) , <NUM_LIT:6> ) \n s = sorted ( c , key = str ) \n self . assertEqual ( str ( s [ <NUM_LIT:0> ] ) , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n self . assertEqual ( str ( s [ <NUM_LIT:1> ] ) , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n self . assertEqual ( str ( s [ <NUM_LIT:2> ] ) , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n self . assertEqual ( str ( s [ <NUM_LIT:3> ] ) , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n self . assertEqual ( str ( s [ <NUM_LIT:4> ] ) , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n self . assertEqual ( str ( s [ <NUM_LIT:5> ] ) , self . temporaryDirectory ( ) + \"<STR_LIT>\" ) \n p . setIncludeSequences ( True ) \n self . assertTrue ( p . getIncludeSequences ( ) ) \n c = p . children ( ) \n self . assertEqual ( len ( c ) , <NUM_LIT:8> ) \n def setUp ( self ) : \n GafferTest . TestCase . setUp ( self ) \n self . __originalCWD = os . getcwd ( ) \n def tearDown ( self ) : \n GafferTest . TestCase . tearDown ( self ) \n os . chdir ( self . __originalCWD ) \n if __name__ == \"<STR_LIT:__main__>\" : \n unittest . main ( ) \n", "gt": "p"}
{"input": "\n import unittest \n import IECore \n import Gaffer \n import GafferTest \n class SequencePathTest ( GafferTest . TestCase ) : \n def __dictPath ( self ) : \n <mask0> = { } \n dict [ \"<STR_LIT>\" ] = { } \n for f in IECore . FileSequence ( \"<STR_LIT>\" ) . fileNames ( ) : \n dict [ \"<STR_LIT>\" ] [ f ] = <NUM_LIT:1> \n for f in IECore . FileSequence ( \"<STR_LIT>\" ) . fileNames ( ) : \n dict [ \"<STR_LIT>\" ] [ f ] = <NUM_LIT:1> \n return Gaffer . DictPath ( dict , \"<STR_LIT:/>\" ) \n def test ( self ) : \n path = Gaffer . SequencePath ( self . __dictPath ( ) ) \n self . failUnless ( path . isValid ( ) ) \n self . failUnless ( not path . isLeaf ( ) ) \n path . append ( \"<STR_LIT>\" ) \n self . failUnless ( path . isValid ( ) ) \n self . failUnless ( not path . isLeaf ( ) ) \n path [ <NUM_LIT:0> ] = \"<STR_LIT>\" \n self . failIf ( path . isValid ( ) ) \n self . failIf ( path . isLeaf ( ) ) \n path [ : ] = [ \"<STR_LIT>\" ] \n children = path . children ( ) \n for child in children : \n self . failUnless ( isinstance ( child , Gaffer . SequencePath ) ) \n self . assertEqual ( len ( children ) , <NUM_LIT:2> ) \n childrenStrings = [ str ( c ) for c in children ] \n self . failUnless ( \"<STR_LIT>\" in childrenStrings ) \n self . failUnless ( \"<STR_LIT>\" in childrenStrings ) \n def testNonLeafChildren ( self ) : \n path = Gaffer . SequencePath ( self . __dictPath ( ) ) \n children = path . children ( ) \n for child in children : \n self . failUnless ( isinstance ( child , Gaffer . SequencePath ) ) \n self . assertEqual ( len ( children ) , <NUM_LIT:1> ) \n self . assertEqual ( str ( children [ <NUM_LIT:0> ] ) , \"<STR_LIT>\" ) \n def testCopy ( self ) : \n path = Gaffer . SequencePath ( self . __dictPath ( ) ) \n path . append ( \"<STR_LIT>\" ) \n path2 = path . copy ( ) \n self . failUnless ( isinstance ( path2 , Gaffer . SequencePath ) ) \n self . assertEqual ( path [ : ] , path2 [ : ] ) \n self . failUnless ( path . getFilter ( ) is path2 . getFilter ( ) ) \n c = [ str ( p ) for p in path . children ( ) ] \n c2 = [ str ( p ) for p in path2 . children ( ) ] \n self . assertEqual ( c , c2 ) \n def testInfo ( self ) : \n dictPath = self . __dictPath ( ) \n path = Gaffer . SequencePath ( dictPath ) \n self . assertEqual ( dictPath . info ( ) , path . info ( ) ) \n def testInfoOfInvalidPath ( self ) : \n fp = Gaffer . FileSystemPath ( \"<STR_LIT>\" ) \n self . assertEqual ( fp . isValid ( ) , False ) \n self . assertEqual ( fp . info ( ) , None ) \n sp = Gaffer . SequencePath ( fp ) \n self . assertEqual ( sp . isValid ( ) , False ) \n self . assertEqual ( sp . info ( ) , None ) \n def testFilter ( self ) : \n dictPath = self . __dictPath ( ) \n path = Gaffer . SequencePath ( dictPath ) \n def testIsEmpty ( self ) : \n dictPath = self . __dictPath ( ) \n path = Gaffer . SequencePath ( dictPath ) \n path . setFromString ( \"<STR_LIT>\" ) \n self . assertTrue ( path . isEmpty ( ) ) \n path2 = path . copy ( ) \n self . assertTrue ( path2 . isEmpty ( ) ) \n def testProperties ( self ) : \n dictPath = self . __dictPath ( ) \n path = Gaffer . SequencePath ( dictPath ) \n self . assertEqual ( dictPath . propertyNames ( ) , path . propertyNames ( ) ) \n self . assertEqual ( dictPath . property ( \"<STR_LIT>\" ) , path . property ( \"<STR_LIT>\" ) ) \n if __name__ == \"<STR_LIT:__main__>\" : \n unittest . main ( ) \n", "gt": "dict"}
{"input": "\n from __future__ import with_statement \n import IECore \n import Gaffer \n import GafferUI \n class CompoundDataPlugValueWidget ( GafferUI . PlugValueWidget ) : \n def __init__ ( self , plug , parenting = None ) : \n self . __column = GafferUI . ListContainer ( spacing = <NUM_LIT:6> ) \n GafferUI . PlugValueWidget . __init__ ( self , self . __column , plug , parenting = parenting ) \n with self . __column : \n self . __layout = GafferUI . PlugLayout ( plug ) \n with GafferUI . ListContainer ( GafferUI . ListContainer . Orientation . Horizontal ) as self . __editRow : \n GafferUI . Spacer ( IECore . V2i ( GafferUI . PlugWidget . labelWidth ( ) , <NUM_LIT:1> ) ) \n GafferUI . MenuButton ( \n image = \"<STR_LIT>\" , \n hasFrame = False , \n menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __addMenuDefinition ) ) \n ) \n GafferUI . Spacer ( IECore . V2i ( <NUM_LIT:1> ) , IECore . V2i ( <NUM_LIT> , <NUM_LIT:1> ) , parenting = { \"<STR_LIT>\" : True } ) \n self . _updateFromPlug ( ) \n def hasLabel ( self ) : \n return True \n def setPlug ( self , plug ) : \n GafferUI . PlugValueWidget . setPlug ( self , plug ) \n self . __layout = GafferUI . PlugLayout ( plug ) \n self . __column [ <NUM_LIT:0> ] = self . __layout \n def setReadOnly ( self , readOnly ) : \n if readOnly == self . getReadOnly ( ) : \n return \n GafferUI . PlugValueWidget . setReadOnly ( self , readOnly ) \n self . __layout . setReadOnly ( readOnly ) \n def childPlugValueWidget ( self , childPlug , lazy = True ) : \n return self . __layout . plugValueWidget ( childPlug , lazy ) \n def _updateFromPlug ( self ) : \n <mask0> = True \n if self . getPlug ( ) is not None : \n editable = Gaffer . Metadata . plugValue ( self . getPlug ( ) , \"<STR_LIT>\" ) \n editable = editable if editable is not None else True \n self . __editRow . setVisible ( editable ) \n def __addMenuDefinition ( self ) : \n result = IECore . MenuDefinition ( ) \n result . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , \"<STR_LIT>\" , IECore . BoolData ( False ) ) } ) \n result . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , \"<STR_LIT>\" , IECore . FloatData ( <NUM_LIT:0> ) ) } ) \n result . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , \"<STR_LIT>\" , IECore . IntData ( <NUM_LIT:0> ) ) } ) \n result . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : True } ) \n result . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , \"<STR_LIT>\" , IECore . StringData ( \"<STR_LIT>\" ) ) } ) \n result . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : True } ) \n result . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , \"<STR_LIT>\" , IECore . V2iData ( IECore . V2i ( <NUM_LIT:0> ) ) ) } ) \n result . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , \"<STR_LIT>\" , IECore . V3iData ( IECore . V3i ( <NUM_LIT:0> ) ) ) } ) \n result . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , \"<STR_LIT>\" , IECore . V2fData ( IECore . V2f ( <NUM_LIT:0> ) ) ) } ) \n result . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , \"<STR_LIT>\" , IECore . V3fData ( IECore . V3f ( <NUM_LIT:0> ) ) ) } ) \n result . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : True } ) \n result . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , \"<STR_LIT>\" , IECore . Color3fData ( IECore . Color3f ( <NUM_LIT:0> ) ) ) } ) \n result . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , \"<STR_LIT>\" , IECore . Color4fData ( IECore . Color4f ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1> ) ) ) } ) \n return result \n def __addItem ( self , name , value ) : \n with Gaffer . UndoContext ( self . getPlug ( ) . ancestor ( Gaffer . ScriptNode . staticTypeId ( ) ) ) : \n self . getPlug ( ) . addOptionalMember ( name , value , enabled = True ) \n class _MemberPlugValueWidget ( GafferUI . PlugValueWidget ) : \n def __init__ ( self , childPlug ) : \n self . __row = GafferUI . ListContainer ( GafferUI . ListContainer . Orientation . Horizontal , spacing = <NUM_LIT:4> ) \n GafferUI . PlugValueWidget . __init__ ( self , self . __row , childPlug ) \n if not childPlug . getFlags ( Gaffer . Plug . Flags . Dynamic ) : \n nameWidget = GafferUI . LabelPlugValueWidget ( \n childPlug , \n horizontalAlignment = GafferUI . Label . HorizontalAlignment . Right , \n verticalAlignment = GafferUI . Label . VerticalAlignment . Center , \n ) \n nameWidget . label ( ) . _qtWidget ( ) . setFixedWidth ( GafferUI . PlugWidget . labelWidth ( ) ) \n nameWidget . label ( ) . _qtWidget ( ) . setFixedHeight ( <NUM_LIT:20> ) \n else : \n nameWidget = GafferUI . StringPlugValueWidget ( childPlug [ \"<STR_LIT:name>\" ] ) \n nameWidget . textWidget ( ) . _qtWidget ( ) . setFixedWidth ( GafferUI . PlugWidget . labelWidth ( ) ) \n self . __row . append ( nameWidget , \n verticalAlignment = GafferUI . Label . VerticalAlignment . Top \n ) \n if \"<STR_LIT>\" in childPlug : \n self . __row . append ( \n GafferUI . BoolPlugValueWidget ( \n childPlug [ \"<STR_LIT>\" ] , \n displayMode = GafferUI . BoolWidget . DisplayMode . Switch \n ) , \n verticalAlignment = GafferUI . Label . VerticalAlignment . Top , \n ) \n self . __row . append ( GafferUI . PlugValueWidget . create ( childPlug [ \"<STR_LIT:value>\" ] ) , expand = True ) \n self . _updateFromPlug ( ) \n def setPlug ( self , plug ) : \n GafferUI . PlugValueWidget . setPlug ( self , plug ) \n if isinstance ( self . __row [ <NUM_LIT:0> ] , GafferUI . LabelPlugValueWidget ) : \n self . __row [ <NUM_LIT:0> ] . setPlug ( plug ) \n else : \n self . __row [ <NUM_LIT:0> ] . setPlug ( plug [ \"<STR_LIT:name>\" ] ) \n if \"<STR_LIT>\" in plug : \n self . __row [ <NUM_LIT:1> ] . setPlug ( plug [ \"<STR_LIT>\" ] ) \n self . __row [ - <NUM_LIT:1> ] . setPlug ( plug [ \"<STR_LIT:value>\" ] ) \n def hasLabel ( self ) : \n return True \n def childPlugValueWidget ( self , childPlug , lazy = True ) : \n for w in self . __row : \n if w . getPlug ( ) . isSame ( childPlug ) : \n return w \n return None \n def setReadOnly ( self , readOnly ) : \n if readOnly == self . getReadOnly ( ) : \n return \n GafferUI . PlugValueWidget . setReadOnly ( self , readOnly ) \n for w in self . __row : \n w . setReadOnly ( readOnly ) \n def _updateFromPlug ( self ) : \n if \"<STR_LIT>\" in self . getPlug ( ) : \n with self . getContext ( ) : \n enabled = self . getPlug ( ) [ \"<STR_LIT>\" ] . getValue ( ) \n if isinstance ( self . __row [ <NUM_LIT:0> ] , GafferUI . StringPlugValueWidget ) : \n self . __row [ <NUM_LIT:0> ] . setEnabled ( enabled ) \n self . __row [ - <NUM_LIT:1> ] . setEnabled ( enabled ) \n GafferUI . PlugValueWidget . registerType ( Gaffer . CompoundDataPlug , CompoundDataPlugValueWidget ) \n GafferUI . PlugValueWidget . registerType ( Gaffer . CompoundDataPlug . MemberPlug , _MemberPlugValueWidget ) \n def __deletePlug ( plug ) : \n with Gaffer . UndoContext ( plug . ancestor ( Gaffer . ScriptNode ) ) : \n plug . parent ( ) . removeChild ( plug ) \n def __plugPopupMenu ( menuDefinition , plugValueWidget ) : \n plug = plugValueWidget . getPlug ( ) \n memberPlug = plug if isinstance ( plug , Gaffer . CompoundDataPlug . MemberPlug ) else None \n memberPlug = memberPlug if memberPlug is not None else plug . ancestor ( Gaffer . CompoundDataPlug . MemberPlug ) \n if memberPlug is None : \n return \n if not memberPlug . getFlags ( Gaffer . Plug . Flags . Dynamic ) : \n return \n menuDefinition . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : True } ) \n menuDefinition . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : IECore . curry ( __deletePlug , memberPlug ) , \"<STR_LIT>\" : not plugValueWidget . getReadOnly ( ) } ) \n __plugPopupMenuConnection = GafferUI . PlugValueWidget . popupMenuSignal ( ) . connect ( __plugPopupMenu ) \n", "gt": "editable"}
{"input": "\n import Gaffer \n import GafferUI \n class FileSystemPathPlugValueWidget ( GafferUI . PathPlugValueWidget ) : \n def __init__ ( self , plug , path = None , parenting = None ) : \n GafferUI . PathPlugValueWidget . __init__ ( \n self , \n plug , \n path , \n parenting = parenting \n ) \n self . _updateFromPlug ( ) \n self . __plugMetadataChangedConnection = Gaffer . Metadata . plugValueChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __plugMetadataChanged ) ) \n def getToolTip ( self ) : \n <mask0> = GafferUI . PathPlugValueWidget . getToolTip ( self ) \n extensions = self . __extensions ( ) \n if extensions : \n result += \"<STR_LIT>\" + \"<STR_LIT:U+002CU+0020>\" . join ( extensions ) \n return result \n def _pathChooserDialogue ( self ) : \n dialogue = GafferUI . PathPlugValueWidget . _pathChooserDialogue ( self ) \n if Gaffer . Metadata . plugValue ( self . getPlug ( ) , \"<STR_LIT>\" ) : \n columns = dialogue . pathChooserWidget ( ) . pathListingWidget ( ) . getColumns ( ) \n columns . append ( GafferUI . PathListingWidget . StandardColumn ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) \n dialogue . pathChooserWidget ( ) . pathListingWidget ( ) . setColumns ( columns ) \n return dialogue \n def _updateFromPlug ( self ) : \n GafferUI . PathPlugValueWidget . _updateFromPlug ( self ) \n includeSequences = Gaffer . Metadata . plugValue ( self . getPlug ( ) , \"<STR_LIT>\" ) or False \n self . path ( ) . setFilter ( \n Gaffer . FileSystemPath . createStandardFilter ( \n self . __extensions ( ) , \n Gaffer . Metadata . plugValue ( self . getPlug ( ) , \"<STR_LIT>\" ) or \"<STR_LIT>\" , \n includeSequenceFilter = includeSequences , \n ) \n ) \n self . path ( ) . setIncludeSequences ( includeSequences ) \n def _setPlugFromPath ( self , path ) : \n if Gaffer . Metadata . plugValue ( self . getPlug ( ) , \"<STR_LIT>\" ) : \n sequence = path . fileSequence ( ) \n if sequence : \n self . getPlug ( ) . setValue ( str ( sequence ) ) \n return \n GafferUI . PathPlugValueWidget . _setPlugFromPath ( self , path ) \n def __plugMetadataChanged ( self , nodeTypeId , plugPath , key , plug ) : \n if self . getPlug ( ) is None : \n return \n if plug is not None and not plug . isSame ( self . getPlug ( ) ) : \n return \n if not self . getPlug ( ) . node ( ) . isInstanceOf ( nodeTypeId ) : \n return \n if key . startswith ( \"<STR_LIT>\" ) : \n self . _updateFromPlug ( ) \n def __extensions ( self ) : \n if self . getPlug ( ) is None : \n return [ ] \n extensions = Gaffer . Metadata . plugValue ( self . getPlug ( ) , \"<STR_LIT>\" ) or [ ] \n if isinstance ( extensions , str ) : \n extensions = extensions . split ( ) \n else : \n extensions = list ( extensions ) \n return extensions \n", "gt": "result"}
{"input": "\n import IECore \n import Gaffer \n import GafferUI \n class NameLabel ( GafferUI . Label ) : \n def __init__ ( self , graphComponent , horizontalAlignment = GafferUI . Label . HorizontalAlignment . Left , verticalAlignment = GafferUI . Label . VerticalAlignment . Center , numComponents = <NUM_LIT:1> , formatter = None , parenting = None ) : \n GafferUI . Label . __init__ ( self , \"<STR_LIT>\" , horizontalAlignment , verticalAlignment , parenting = parenting ) \n self . __formatter = formatter if formatter is not None else self . defaultFormatter \n self . __numComponents = numComponents \n self . __connections = [ ] \n self . __graphComponent = False \n self . setGraphComponent ( graphComponent ) \n self . __buttonPressConnection = self . buttonPressSignal ( ) . connect ( Gaffer . WeakMethod ( self . __buttonPress ) ) \n self . __dragBeginConnection = self . dragBeginSignal ( ) . connect ( Gaffer . WeakMethod ( self . __dragBegin ) ) \n self . __dragEndConnection = self . dragEndSignal ( ) . connect ( Gaffer . WeakMethod ( self . __dragEnd ) ) \n def setText ( self , text ) : \n GafferUI . Label . setText ( self , text ) \n self . __connections = [ ] \n def setGraphComponent ( self , graphComponent ) : \n if graphComponent is not None and self . __graphComponent is not False : \n if graphComponent . isSame ( self . __graphComponent ) : \n return \n elif self . __graphComponent is None : \n return \n self . __graphComponent = graphComponent \n self . __setupConnections ( ) \n self . __setText ( ) \n def getGraphComponent ( self ) : \n return self . __graphComponent \n def setNumComponents ( self , numComponents ) : \n assert ( numComponents > <NUM_LIT:0> ) \n if numComponents == self . __numComponents : \n return \n self . __numComponents = numComponents \n self . __setupConnections ( ) \n self . __setText ( ) \n def getNumComponents ( self ) : \n return self . __numComponents \n def setFormatter ( self , formatter ) : \n self . __formatter = formatter \n self . __setText ( ) \n def getFormatter ( self ) : \n return self . __formatter \n @ staticmethod \n def defaultFormatter ( graphComponents ) : \n return \"<STR_LIT:.>\" . join ( IECore . CamelCase . toSpaced ( g . getName ( ) ) for g in graphComponents ) \n def __setupConnections ( self , reuseUntil = None ) : \n if self . __graphComponent is None : \n self . __connections = [ ] \n return \n <mask0> = [ ] \n n = <NUM_LIT:0> \n g = self . __graphComponent \n reuse = reuseUntil is not None \n while g is not None and n < self . __numComponents : \n if reuse : \n updatedConnections . extend ( self . __connections [ n * <NUM_LIT:2> : n * <NUM_LIT:2> + <NUM_LIT:2> ] ) \n else : \n updatedConnections . append ( g . nameChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __setText ) ) ) \n if n < self . __numComponents - <NUM_LIT:1> : \n updatedConnections . append ( g . parentChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __parentChanged ) ) ) \n if g . isSame ( reuseUntil ) : \n reuse = False \n g = g . parent ( ) \n n += <NUM_LIT:1> \n self . __connections = updatedConnections \n def __parentChanged ( self , child , oldParent ) : \n self . __setText ( ) \n self . __setupConnections ( reuseUntil = child ) \n def __setText ( self , * unwantedArgs ) : \n graphComponents = [ ] \n n = <NUM_LIT:0> \n g = self . __graphComponent \n while g is not None and n < self . __numComponents : \n graphComponents . append ( g ) \n g = g . parent ( ) \n n += <NUM_LIT:1> \n graphComponents . reverse ( ) \n GafferUI . Label . setText ( self , self . __formatter ( graphComponents ) ) \n def __buttonPress ( self , widget , event ) : \n return self . getGraphComponent ( ) is not None and event . buttons & ( event . Buttons . Left | event . Buttons . Middle ) \n def __dragBegin ( self , widget , event ) : \n if event . buttons & ( event . Buttons . Left | event . Buttons . Middle ) : \n GafferUI . Pointer . setCurrent ( \"<STR_LIT>\" ) \n return self . getGraphComponent ( ) \n return None \n def __dragEnd ( self , widget , event ) : \n GafferUI . Pointer . setCurrent ( None ) \n", "gt": "updatedConnections"}
{"input": "\n import functools \n import IECore \n import Gaffer \n import GafferUI \n class PresetsPlugValueWidget ( GafferUI . PlugValueWidget ) : \n def __init__ ( self , plug , parenting = None ) : \n self . __menuButton = GafferUI . MenuButton ( \"<STR_LIT>\" , menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __menuDefinition ) ) ) \n GafferUI . PlugValueWidget . __init__ ( self , self . __menuButton , plug , parenting = parenting ) \n self . __plugMetadataChangedConnection = Gaffer . Metadata . plugValueChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __plugMetadataChanged ) ) \n self . _addPopupMenu ( self . __menuButton ) \n self . _updateFromPlug ( ) \n def _updateFromPlug ( self ) : \n self . __menuButton . setEnabled ( self . _editable ( ) ) \n <mask0> = \"<STR_LIT>\" \n if self . getPlug ( ) is not None : \n with self . getContext ( ) : \n text = Gaffer . NodeAlgo . currentPreset ( self . getPlug ( ) ) or \"<STR_LIT>\" \n self . __menuButton . setText ( text ) \n def __menuDefinition ( self ) : \n result = IECore . MenuDefinition ( ) \n if self . getPlug ( ) is None : \n return result \n currentPreset = Gaffer . NodeAlgo . currentPreset ( self . getPlug ( ) ) \n for n in Gaffer . NodeAlgo . presets ( self . getPlug ( ) ) : \n result . append ( \n \"<STR_LIT:/>\" + n , \n { \n \"<STR_LIT>\" : functools . partial ( Gaffer . WeakMethod ( self . __applyPreset ) , preset = n ) , \n \"<STR_LIT>\" : n == currentPreset , \n } \n ) \n return result \n def __applyPreset ( self , unused , preset ) : \n with Gaffer . UndoContext ( self . getPlug ( ) . ancestor ( Gaffer . ScriptNode ) ) : \n Gaffer . NodeAlgo . applyPreset ( self . getPlug ( ) , preset ) \n def __plugMetadataChanged ( self , nodeTypeId , plugPath , key , plug ) : \n if self . getPlug ( ) is None : \n return \n if plug is not None and not plug . isSame ( self . getPlug ( ) ) : \n return \n if not self . getPlug ( ) . node ( ) . isInstanceOf ( nodeTypeId ) : \n return \n if key . startswith ( \"<STR_LIT>\" ) : \n self . _updateFromPlug ( ) \n", "gt": "text"}
{"input": "\n import weakref \n import functools \n import types \n import re \n import collections \n import IECore \n import Gaffer \n import GafferUI \n class UIEditor ( GafferUI . NodeSetEditor ) : \n def __init__ ( self , scriptNode , parenting = None ) : \n self . __frame = GafferUI . Frame ( borderWidth = <NUM_LIT:4> , borderStyle = GafferUI . Frame . BorderStyle . None ) \n GafferUI . NodeSetEditor . __init__ ( self , self . __frame , scriptNode , parenting = parenting ) \n self . __nodeMetadataWidgets = [ ] \n self . __plugMetadataWidgets = [ ] \n with self . __frame : \n self . __tabbedContainer = GafferUI . TabbedContainer ( ) \n with self . __tabbedContainer : \n with GafferUI . ListContainer ( spacing = <NUM_LIT:4> , borderWidth = <NUM_LIT:8> , parenting = { \"<STR_LIT:label>\" : \"<STR_LIT>\" } ) as self . __nodeTab : \n with _Row ( ) : \n _Label ( \"<STR_LIT:Name>\" ) \n self . __nodeNameWidget = GafferUI . NameWidget ( None ) \n with _Row ( ) : \n _Label ( \"<STR_LIT>\" , parenting = { \"<STR_LIT>\" : GafferUI . ListContainer . VerticalAlignment . Top } ) \n self . __nodeMetadataWidgets . append ( \n _MultiLineStringMetadataWidget ( key = \"<STR_LIT:description>\" ) \n ) \n with _Row ( ) : \n _Label ( \"<STR_LIT>\" ) \n self . __nodeMetadataWidgets . append ( \n _ColorSwatchMetadataWidget ( key = \"<STR_LIT>\" ) \n ) \n with GafferUI . SplitContainer ( orientation = GafferUI . SplitContainer . Orientation . Horizontal , borderWidth = <NUM_LIT:8> , parenting = { \"<STR_LIT:label>\" : \"<STR_LIT>\" } ) as self . __plugTab : \n self . __plugListing = _PlugListing ( ) \n self . __plugListingSelectionChangedConnection = self . __plugListing . selectionChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __plugListingSelectionChanged ) ) \n with GafferUI . TabbedContainer ( ) as self . __plugAndSectionEditorsContainer : \n self . __plugEditor = _PlugEditor ( ) \n self . __sectionEditor = _SectionEditor ( ) \n self . __sectionEditorNameChangedConnection = self . __sectionEditor . nameChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __sectionEditorNameChanged ) ) \n self . __plugAndSectionEditorsContainer . setTabsVisible ( False ) \n self . __plugTab . setSizes ( [ <NUM_LIT> , <NUM_LIT> ] ) \n self . __node = None \n self . __selectedPlug = None \n self . __updateFromSetInternal ( lazy = False ) \n def setSelection ( self , selection ) : \n self . __plugListing . setSelection ( selection ) \n def getSelection ( self ) : \n return self . __plugListing . getSelection ( ) \n def nodeEditor ( self ) : \n return self . __nodeTab \n def plugEditor ( self ) : \n return self . __plugTab \n @ classmethod \n def appendNodeContextMenuDefinitions ( cls , nodeGraph , node , menuDefinition ) : \n menuDefinition . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : True } ) \n menuDefinition . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : functools . partial ( cls . __setColor , node = node ) } ) \n @ classmethod \n def appendNodeEditorToolMenuDefinitions ( cls , nodeEditor , node , menuDefinition ) : \n menuDefinition . append ( \n \"<STR_LIT>\" , \n { \n \"<STR_LIT>\" : functools . partial ( GafferUI . UIEditor . acquire , node ) , \n \"<STR_LIT>\" : isinstance ( node , Gaffer . Box ) or nodeEditor . nodeUI ( ) . plugValueWidget ( node [ \"<STR_LIT:user>\" ] ) is not None \n } \n ) \n def _updateFromSet ( self ) : \n GafferUI . NodeSetEditor . _updateFromSet ( self ) \n self . __updateFromSetInternal ( ) \n def __updateFromSetInternal ( self , lazy = True ) : \n <mask0> = self . _lastAddedNode ( ) \n if lazy and node == self . __node : \n return \n self . __node = node \n self . __nodeNameWidget . setGraphComponent ( self . __node ) \n self . __nodeTab . setEnabled ( self . __node is not None ) \n if self . __node is None : \n self . __plugListing . setPlugParent ( None ) \n self . __sectionEditor . setPlugParent ( None ) \n else : \n plugParent = self . __node [ \"<STR_LIT:user>\" ] \n if isinstance ( self . __node , Gaffer . Box ) : \n plugParent = self . __node \n self . __plugListing . setPlugParent ( plugParent ) \n self . __sectionEditor . setPlugParent ( plugParent ) \n for widget in self . __nodeMetadataWidgets : \n widget . setTarget ( self . __node ) \n self . setSelection ( None ) \n def __plugListingSelectionChanged ( self , listing ) : \n selection = listing . getSelection ( ) \n if selection is None or isinstance ( selection , Gaffer . Plug ) : \n self . __plugEditor . setPlug ( selection ) \n self . __plugAndSectionEditorsContainer . setCurrent ( self . __plugEditor ) \n elif isinstance ( selection , basestring ) : \n self . __plugEditor . setPlug ( None ) \n self . __sectionEditor . setSection ( selection ) \n self . __plugAndSectionEditorsContainer . setCurrent ( self . __sectionEditor ) \n def __sectionEditorNameChanged ( self , sectionEditor , oldName , newName ) : \n self . __plugListing . setSelection ( newName ) \n def __repr__ ( self ) : \n return \"<STR_LIT>\" \n @ classmethod \n def __setColor ( cls , menu , node ) : \n color = Gaffer . Metadata . nodeValue ( node , \"<STR_LIT>\" ) or IECore . Color3f ( <NUM_LIT:1> ) \n dialogue = GafferUI . ColorChooserDialogue ( color = color , useDisplayTransform = False ) \n color = dialogue . waitForColor ( parentWindow = menu . ancestor ( GafferUI . Window ) ) \n if color is not None : \n with Gaffer . UndoContext ( node . ancestor ( Gaffer . ScriptNode ) ) : \n Gaffer . Metadata . registerNodeValue ( node , \"<STR_LIT>\" , color ) \n GafferUI . EditorWidget . registerType ( \"<STR_LIT>\" , UIEditor ) \n def __editPlugUI ( node , plug ) : \n editor = GafferUI . UIEditor . acquire ( node ) \n editor . setSelection ( plug ) \n editor . plugEditor ( ) . reveal ( ) \n def __plugPopupMenu ( menuDefinition , plugValueWidget ) : \n plug = plugValueWidget . getPlug ( ) \n node = plug . node ( ) \n if node is None : \n return \n if isinstance ( node , Gaffer . Box ) : \n if not plug . parent ( ) . isSame ( node ) : \n return \n else : \n if not plug . parent ( ) . isSame ( node [ \"<STR_LIT:user>\" ] ) : \n return \n menuDefinition . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : True } ) \n menuDefinition . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : IECore . curry ( __editPlugUI , node , plug ) , \"<STR_LIT>\" : not plugValueWidget . getReadOnly ( ) } ) \n __plugPopupMenuConnection = GafferUI . PlugValueWidget . popupMenuSignal ( ) . connect ( __plugPopupMenu ) \n class _Label ( GafferUI . Label ) : \n def __init__ ( self , * args , ** kw ) : \n GafferUI . Label . __init__ ( \n self , \n horizontalAlignment = GafferUI . Label . HorizontalAlignment . Right , \n * args , ** kw \n ) \n self . _qtWidget ( ) . setFixedWidth ( <NUM_LIT> ) \n class _Row ( GafferUI . ListContainer ) : \n def __init__ ( self , * args , ** kw ) : \n GafferUI . ListContainer . __init__ ( self , GafferUI . ListContainer . Orientation . Horizontal , spacing = <NUM_LIT:4> , * args , ** kw ) \n class _MetadataWidget ( GafferUI . Widget ) : \n def __init__ ( self , topLevelWidget , key , target = None , parenting = None ) : \n GafferUI . Widget . __init__ ( self , topLevelWidget , parenting = parenting ) \n self . __key = key \n self . __target = None \n self . setTarget ( target ) \n def setTarget ( self , target ) : \n assert ( isinstance ( target , ( Gaffer . Node , Gaffer . Plug , type ( None ) ) ) ) \n self . __target = target \n self . setEnabled ( self . __target is not None ) \n if isinstance ( self . __target , Gaffer . Node ) : \n self . __metadataChangedConnection = Gaffer . Metadata . nodeValueChangedSignal ( ) . connect ( \n Gaffer . WeakMethod ( self . __nodeMetadataChanged ) \n ) \n elif isinstance ( self . __target , Gaffer . Plug ) : \n self . __metadataChangedConnection = Gaffer . Metadata . plugValueChangedSignal ( ) . connect ( \n Gaffer . WeakMethod ( self . __plugMetadataChanged ) \n ) \n else : \n self . __metadataChangedConnection = None \n self . __update ( ) \n def getTarget ( self ) : \n return self . __target \n def setKey ( self , key ) : \n if key == self . __key : \n return \n self . __key = key \n self . __update ( ) \n def getKey ( self , key ) : \n return self . __key \n def _updateFromValue ( self , value ) : \n raise NotImplementedError \n def _updateFromWidget ( self , value ) : \n if self . __target is None : \n return \n with Gaffer . UndoContext ( self . __target . ancestor ( Gaffer . ScriptNode ) ) : \n _registerMetadata ( self . __target , self . __key , value ) \n def _deregisterValue ( self ) : \n if self . __target is None : \n return \n with Gaffer . UndoContext ( self . __target . ancestor ( Gaffer . ScriptNode ) ) : \n _deregisterMetadata ( self . __target , self . __key ) \n def __update ( self ) : \n if isinstance ( self . __target , Gaffer . Node ) : \n self . _updateFromValue ( Gaffer . Metadata . nodeValue ( self . __target , self . __key ) ) \n elif isinstance ( self . __target , Gaffer . Plug ) : \n self . _updateFromValue ( Gaffer . Metadata . plugValue ( self . __target , self . __key ) ) \n else : \n self . _updateFromValue ( None ) \n def __nodeMetadataChanged ( self , nodeTypeId , key , node ) : \n if self . __key != key : \n return \n if node is not None and not node . isSame ( self . __target ) : \n return \n if not self . __target . isInstanceOf ( nodeTypeId ) : \n return \n self . __update ( ) \n def __plugMetadataChanged ( self , nodeTypeId , plugPath , key , plug ) : \n if self . __key != key : \n return \n if plug is not None and not plug . isSame ( self . __target ) : \n return \n if not self . __target . node ( ) . isInstanceOf ( nodeTypeId ) : \n return \n if not Gaffer . match ( self . __target . relativeName ( self . __target . node ( ) ) , plugPath ) : \n return \n self . __update ( ) \n class _BoolMetadataWidget ( _MetadataWidget ) : \n def __init__ ( self , key , target = None , parenting = None ) : \n self . __boolWidget = GafferUI . BoolWidget ( ) \n _MetadataWidget . __init__ ( self , self . __boolWidget , key , target , parenting = parenting ) \n self . __stateChangedConnection = self . __boolWidget . stateChangedSignal ( ) . connect ( \n Gaffer . WeakMethod ( self . __stateChanged ) \n ) \n def _updateFromValue ( self , value ) : \n self . __boolWidget . setState ( value if value is not None else False ) \n def __stateChanged ( self , * unused ) : \n self . _updateFromWidget ( self . __boolWidget . getState ( ) ) \n class _StringMetadataWidget ( _MetadataWidget ) : \n def __init__ ( self , key , target = None , acceptEmptyString = True , parenting = None ) : \n self . __textWidget = GafferUI . TextWidget ( ) \n _MetadataWidget . __init__ ( self , self . __textWidget , key , target , parenting = None ) \n self . __acceptEmptyString = acceptEmptyString \n self . __editingFinishedConnection = self . __textWidget . editingFinishedSignal ( ) . connect ( \n Gaffer . WeakMethod ( self . __editingFinished ) \n ) \n def textWidget ( self ) : \n return self . __textWidget \n def _updateFromValue ( self , value ) : \n self . __textWidget . setText ( value if value is not None else \"<STR_LIT>\" ) \n def __editingFinished ( self , * unused ) : \n text = self . __textWidget . getText ( ) \n if text or self . __acceptEmptyString : \n self . _updateFromWidget ( text ) \n else : \n self . _deregisterValue ( ) \n class _MultiLineStringMetadataWidget ( _MetadataWidget ) : \n def __init__ ( self , key , target = None , parenting = None ) : \n self . __textWidget = GafferUI . MultiLineTextWidget ( ) \n _MetadataWidget . __init__ ( self , self . __textWidget , key , target , parenting = None ) \n self . __editingFinishedConnection = self . __textWidget . editingFinishedSignal ( ) . connect ( \n Gaffer . WeakMethod ( self . __editingFinished ) \n ) \n def textWidget ( self ) : \n return self . __textWidget \n def _updateFromValue ( self , value ) : \n self . __textWidget . setText ( value if value is not None else \"<STR_LIT>\" ) \n def __editingFinished ( self , * unused ) : \n self . _updateFromWidget ( self . __textWidget . getText ( ) ) \n class _ColorSwatchMetadataWidget ( _MetadataWidget ) : \n def __init__ ( self , key , target = None , parenting = None ) : \n self . __swatch = GafferUI . ColorSwatch ( useDisplayTransform = False ) \n _MetadataWidget . __init__ ( self , self . __swatch , key , target , parenting = parenting ) \n self . __swatch . _qtWidget ( ) . setFixedHeight ( <NUM_LIT> ) \n self . __swatch . _qtWidget ( ) . setMaximumWidth ( <NUM_LIT> ) \n self . __value = None \n self . __buttonReleaseConnection = self . __swatch . buttonReleaseSignal ( ) . connect ( Gaffer . WeakMethod ( self . __buttonRelease ) ) \n def _updateFromValue ( self , value ) : \n if value is not None : \n self . __swatch . setColor ( value ) \n else : \n self . __swatch . setColor ( IECore . Color4f ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> ) ) \n self . __value = value \n def __buttonRelease ( self , swatch , event ) : \n if event . button != event . Buttons . Left : \n return False \n color = self . __value if self . __value is not None else IECore . Color3f ( <NUM_LIT:1> ) \n dialogue = GafferUI . ColorChooserDialogue ( color = color , useDisplayTransform = False ) \n color = dialogue . waitForColor ( parentWindow = self . ancestor ( GafferUI . Window ) ) \n if color is not None : \n self . _updateFromWidget ( color ) \n class _MenuMetadataWidget ( _MetadataWidget ) : \n def __init__ ( self , key , labelsAndValues , target = None , parenting = None ) : \n self . __menuButton = GafferUI . MenuButton ( \n menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __menuDefinition ) ) \n ) \n self . __labelsAndValues = labelsAndValues \n self . __currentValue = None \n _MetadataWidget . __init__ ( self , self . __menuButton , key , target , parenting = parenting ) \n def _updateFromValue ( self , value ) : \n self . __currentValue = value \n buttonText = str ( value ) \n for label , value in self . __labelsAndValues : \n if value == self . __currentValue : \n buttonText = label \n break \n self . __menuButton . setText ( buttonText ) \n def __menuDefinition ( self ) : \n result = IECore . MenuDefinition ( ) \n for label , value in self . __labelsAndValues : \n result . append ( \n \"<STR_LIT:/>\" + label , \n { \n \"<STR_LIT>\" : functools . partial ( Gaffer . WeakMethod ( self . __setValue ) , value = value ) , \n \"<STR_LIT>\" : value == self . __currentValue \n } \n ) \n return result \n def __setValue ( self , unused , value ) : \n self . _updateFromWidget ( value ) \n class _LayoutItem ( object ) : \n def __init__ ( self ) : \n self . __parent = None \n self . __children = [ ] \n def parent ( self ) : \n if self . __parent is None : \n return None \n else : \n return self . __parent ( ) \n def child ( self , name ) : \n for c in self . __children : \n if c . name ( ) == name : \n return c \n return None \n def isAncestorOf ( self , item ) : \n while item is not None : \n parent = item . parent ( ) \n if parent is self : \n return True \n item = parent \n return False \n def append ( self , child ) : \n self . insert ( len ( self ) , child ) \n def insert ( self , index , child ) : \n assert ( child . parent ( ) is None ) \n self . __children . insert ( index , child ) \n child . __parent = weakref . ref ( self ) \n def remove ( self , child ) : \n assert ( child . parent ( ) is self ) \n self . __children . remove ( child ) \n child . __parent = None \n def index ( self , child ) : \n return self . __children . index ( child ) \n def name ( self ) : \n raise NotImplementedError \n def fullName ( self ) : \n result = \"<STR_LIT>\" \n item = self \n while item . parent ( ) is not None : \n if result : \n result = item . name ( ) + \"<STR_LIT:.>\" + result \n else : \n result = item . name ( ) \n item = item . parent ( ) \n return result \n def __len__ ( self ) : \n return len ( self . __children ) \n def __getitem__ ( self , index ) : \n return self . __children [ index ] \n class _SectionLayoutItem ( _LayoutItem ) : \n def __init__ ( self , sectionName ) : \n _LayoutItem . __init__ ( self ) \n self . __sectionName = sectionName \n def name ( self ) : \n return self . __sectionName \n class _PlugLayoutItem ( _LayoutItem ) : \n def __init__ ( self , plug ) : \n _LayoutItem . __init__ ( self ) \n self . plug = plug \n self . __name = plug . getName ( ) \n def name ( self ) : \n return self . __name \n class _PlugListing ( GafferUI . Widget ) : \n class __LayoutPath ( Gaffer . Path ) : \n def __init__ ( self , rootItem , path , root = \"<STR_LIT:/>\" , filter = None ) : \n Gaffer . Path . __init__ ( self , path , root , filter ) \n self . __rootItem = rootItem \n def rootItem ( self ) : \n return self . __rootItem \n def item ( self ) : \n result = self . __rootItem \n for name in self : \n result = result . child ( name ) \n if result is None : \n return None \n return result \n def copy ( self ) : \n return self . __class__ ( self . __rootItem , self [ : ] , self . root ( ) , self . getFilter ( ) ) \n def isLeaf ( self ) : \n return not isinstance ( self . item ( ) , _SectionLayoutItem ) \n def isValid ( self ) : \n return self . item ( ) is not None \n def _children ( self ) : \n item = self . item ( ) \n if item is None : \n return [ ] \n result = [ \n self . __class__ ( self . __rootItem , self [ : ] + [ c . name ( ) ] , self . root ( ) , self . getFilter ( ) ) \n for c in item \n ] \n if len ( result ) == <NUM_LIT:0> and isinstance ( item , _SectionLayoutItem ) : \n result . append ( self . __class__ ( self . __rootItem , self [ : ] + [ \"<STR_LIT:U+0020>\" ] , self . root ( ) , self . getFilter ( ) ) ) \n return result \n def __init__ ( self , parenting = None ) : \n column = GafferUI . ListContainer ( spacing = <NUM_LIT:4> ) \n GafferUI . Widget . __init__ ( self , column , parenting = parenting ) \n with column : \n self . __pathListing = GafferUI . PathListingWidget ( \n self . __LayoutPath ( _SectionLayoutItem ( \"<STR_LIT>\" ) , \"<STR_LIT:/>\" ) , \n columns = ( GafferUI . PathListingWidget . defaultNameColumn , ) , \n displayMode = GafferUI . PathListingWidget . DisplayMode . Tree , \n ) \n self . __pathListing . setDragPointer ( \"<STR_LIT>\" ) \n self . __pathListing . setSortable ( False ) \n self . __pathListing . setHeaderVisible ( False ) \n with GafferUI . ListContainer ( GafferUI . ListContainer . Orientation . Horizontal , spacing = <NUM_LIT:4> ) : \n GafferUI . MenuButton ( \n image = \"<STR_LIT>\" , \n hasFrame = False , \n menu = GafferUI . Menu ( \n definition = Gaffer . WeakMethod ( self . __addMenuDefinition ) \n ) \n ) \n self . __deleteButton = GafferUI . Button ( image = \"<STR_LIT>\" , hasFrame = False ) \n self . __deleteButtonClickedConnection = self . __deleteButton . clickedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __deleteButtonClicked ) ) \n self . __parent = None \n self . __dragItem = None \n self . __selectionChangedSignal = Gaffer . Signal1 ( ) \n self . __dragEnterConnection = self . __pathListing . dragEnterSignal ( ) . connect ( Gaffer . WeakMethod ( self . __dragEnter ) ) \n self . __dragMoveConnection = self . __pathListing . dragMoveSignal ( ) . connect ( Gaffer . WeakMethod ( self . __dragMove ) ) \n self . __dragEndConnection = self . __pathListing . dragEndSignal ( ) . connect ( Gaffer . WeakMethod ( self . __dragEnd ) ) \n self . __selectionChangedConnection = self . __pathListing . selectionChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __selectionChanged ) ) \n self . __keyPressConnection = self . keyPressSignal ( ) . connect ( Gaffer . WeakMethod ( self . __keyPress ) ) \n self . __nodeMetadataChangedConnection = Gaffer . Metadata . nodeValueChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __nodeMetadataChanged ) ) \n self . __plugMetadataChangedConnection = Gaffer . Metadata . plugValueChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __plugMetadataChanged ) ) \n def setPlugParent ( self , parent ) : \n assert ( isinstance ( parent , ( Gaffer . Plug , Gaffer . Node , types . NoneType ) ) ) \n self . __parent = parent \n self . __childAddedConnection = None \n self . __childRemovedConnection = None \n self . __childNameChangedConnections = { } \n if self . __parent is not None : \n self . __childAddedConnection = self . __parent . childAddedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __childAddedOrRemoved ) ) \n self . __childRemovedConnection = self . __parent . childRemovedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __childAddedOrRemoved ) ) \n for child in self . __parent . children ( ) : \n self . __updateChildNameChangedConnection ( child ) \n self . __updatePath ( ) \n def getPlugParent ( self ) : \n return self . __parent \n def setSelection ( self , selection ) : \n self . __updatePathLazily . flush ( self ) \n def findPlugPath ( path , plug ) : \n item = path . item ( ) \n if isinstance ( item , _PlugLayoutItem ) and item . plug . isSame ( plug ) : \n return path \n else : \n for child in path . children ( ) : \n r = findPlugPath ( child , plug ) \n if r is not None : \n return r \n return None \n if isinstance ( selection , Gaffer . Plug ) : \n path = findPlugPath ( self . __pathListing . getPath ( ) , selection ) \n if path is None : \n self . __pathListing . setSelectedPaths ( [ ] ) \n else : \n self . __pathListing . setSelectedPaths ( [ path ] ) \n elif isinstance ( selection , basestring ) : \n path = self . __pathListing . getPath ( ) . copy ( ) \n path [ : ] = selection . split ( \"<STR_LIT:.>\" ) \n self . __pathListing . setSelectedPaths ( [ path ] ) \n else : \n assert ( selection is None ) \n self . __pathListing . setSelectedPaths ( [ ] ) \n def getSelection ( self ) : \n item = self . __selectedItem ( ) \n if item is None : \n return None \n elif isinstance ( item , _PlugLayoutItem ) : \n return item . plug \n elif isinstance ( item , _SectionLayoutItem ) : \n return item . fullName ( ) \n else : \n return None \n def selectionChangedSignal ( self ) : \n return self . __selectionChangedSignal \n def __updatePath ( self ) : \n if self . __parent is None : \n self . __pathListing . setPath ( self . __LayoutPath ( _SectionLayoutItem ( \"<STR_LIT>\" ) , \"<STR_LIT:/>\" ) ) \n return \n def section ( rootLayoutItem , sectionPath ) : \n sectionItem = rootLayoutItem \n if sectionPath != \"<STR_LIT>\" : \n for sectionName in sectionPath . split ( \"<STR_LIT:.>\" ) : \n childSectionItem = sectionItem . child ( sectionName ) \n if childSectionItem is None : \n childSectionItem = _SectionLayoutItem ( sectionName ) \n sectionItem . append ( childSectionItem ) \n sectionItem = childSectionItem \n return sectionItem \n layout = _SectionLayoutItem ( \"<STR_LIT>\" ) \n for sectionPath in GafferUI . PlugLayout . layoutSections ( self . __parent ) : \n if sectionPath == \"<STR_LIT>\" and isinstance ( self . __parent , Gaffer . Node ) : \n continue \n sectionItem = section ( layout , sectionPath ) \n for plug in GafferUI . PlugLayout . layoutOrder ( self . __parent , section = sectionPath ) : \n sectionItem . append ( _PlugLayoutItem ( plug ) ) \n emptySections = _metadata ( self . getPlugParent ( ) , \"<STR_LIT>\" ) \n emptySectionIndices = _metadata ( self . getPlugParent ( ) , \"<STR_LIT>\" ) \n if emptySections and emptySectionIndices : \n for sectionPath , sectionIndex in zip ( emptySections , emptySectionIndices ) : \n parentPath , unused , sectionName = sectionPath . rpartition ( \"<STR_LIT:.>\" ) \n parentSection = section ( layout , parentPath ) \n if parentSection . child ( sectionName ) is None : \n parentSection . insert ( sectionIndex , _SectionLayoutItem ( sectionName ) ) \n if len ( layout ) == <NUM_LIT:0> and isinstance ( self . __parent , Gaffer . Node ) : \n layout . append ( _SectionLayoutItem ( \"<STR_LIT>\" ) ) \n expandedPaths = self . __pathListing . getExpandedPaths ( ) \n self . __pathListing . setPath ( self . __LayoutPath ( layout , \"<STR_LIT:/>\" ) ) \n self . __pathListing . setExpandedPaths ( expandedPaths ) \n @ GafferUI . LazyMethod ( ) \n def __updatePathLazily ( self ) : \n self . __updatePath ( ) \n def __updateMetadata ( self ) : \n emptySections = IECore . StringVectorData ( ) \n emptySectionIndices = IECore . IntVectorData ( ) \n def walk ( layoutItem , path = \"<STR_LIT>\" , index = <NUM_LIT:0> ) : \n for childItem in layoutItem : \n if isinstance ( childItem , _PlugLayoutItem ) : \n Gaffer . Metadata . registerPlugValue ( childItem . plug , \"<STR_LIT>\" , path ) \n Gaffer . Metadata . registerPlugValue ( childItem . plug , \"<STR_LIT>\" , index ) \n index += <NUM_LIT:1> \n elif isinstance ( childItem , _SectionLayoutItem ) : \n childPath = path + \"<STR_LIT:.>\" + childItem . name ( ) if path else childItem . name ( ) \n if len ( childItem ) : \n index = walk ( childItem , childPath , index ) \n else : \n emptySections . append ( childPath ) \n emptySectionIndices . append ( layoutItem . index ( childItem ) ) \n return index \n with Gaffer . BlockedConnection ( self . __plugMetadataChangedConnection ) : \n walk ( self . __pathListing . getPath ( ) . copy ( ) . setFromString ( \"<STR_LIT:/>\" ) . item ( ) ) \n _registerMetadata ( self . getPlugParent ( ) , \"<STR_LIT>\" , emptySections ) \n _registerMetadata ( self . getPlugParent ( ) , \"<STR_LIT>\" , emptySectionIndices ) \n def __childAddedOrRemoved ( self , parent , child ) : \n assert ( parent . isSame ( self . __parent ) ) \n self . __updateChildNameChangedConnection ( child ) \n self . __updatePathLazily ( ) \n def __childNameChanged ( self , child ) : \n selection = self . getSelection ( ) \n self . __updatePath ( ) \n if isinstance ( selection , Gaffer . Plug ) and child . isSame ( selection ) : \n self . setSelection ( selection ) \n def __updateChildNameChangedConnection ( self , child ) : \n if self . __parent . isSame ( child . parent ( ) ) : \n if child not in self . __childNameChangedConnections : \n self . __childNameChangedConnections [ child ] = child . nameChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __childNameChanged ) ) \n else : \n if child in self . __childNameChangedConnections : \n del self . __childNameChangedConnections [ child ] \n def __dragEnter ( self , listing , event ) : \n if event . sourceWidget is not self . __pathListing : \n return False \n if not isinstance ( event . data , IECore . StringVectorData ) : \n return False \n dragPath = self . __pathListing . getPath ( ) . copy ( ) . setFromString ( event . data [ <NUM_LIT:0> ] ) \n self . __dragItem = dragPath . item ( ) \n self . __pathListing . setPathExpanded ( dragPath , False ) \n return True \n def __dragMove ( self , listing , event ) : \n if self . __dragItem is None : \n return False \n targetPath = self . __pathListing . pathAt ( event . line . p0 ) \n if targetPath is not None : \n targetItem = targetPath . item ( ) \n if targetItem is not None : \n if isinstance ( targetItem , _SectionLayoutItem ) and self . __pathListing . getPathExpanded ( targetPath ) and targetItem . parent ( ) is self . __dragItem . parent ( ) : \n newParent = targetItem \n newIndex = <NUM_LIT:0> \n else : \n newParent = targetItem . parent ( ) \n newIndex = newParent . index ( targetItem ) \n else : \n newParent = targetPath . copy ( ) . truncateUntilValid ( ) . item ( ) \n newIndex = <NUM_LIT:0> \n else : \n newParent = self . __pathListing . getPath ( ) . rootItem ( ) \n newIndex = <NUM_LIT:0> if event . line . p0 . y < <NUM_LIT:1> else len ( newParent ) \n if newParent is self . __dragItem or self . __dragItem . isAncestorOf ( newParent ) : \n return True \n firstNonPlugIndex = next ( \n ( x [ <NUM_LIT:0> ] for x in enumerate ( newParent ) if not isinstance ( x [ <NUM_LIT:1> ] , _PlugLayoutItem ) ) , \n len ( newParent ) \n ) \n if self . __dragItem . parent ( ) is newParent and newParent . index ( self . __dragItem ) < firstNonPlugIndex : \n firstNonPlugIndex -= <NUM_LIT:1> \n if isinstance ( self . __dragItem , _PlugLayoutItem ) : \n if newIndex > firstNonPlugIndex : \n return True \n else : \n if newIndex < firstNonPlugIndex : \n newIndex = max ( newIndex , firstNonPlugIndex ) \n self . __dragItem . parent ( ) . remove ( self . __dragItem ) \n newParent . insert ( newIndex , self . __dragItem ) \n self . __pathListing . getPath ( ) . pathChangedSignal ( ) ( self . __pathListing . getPath ( ) ) \n selection = self . __pathListing . getPath ( ) . copy ( ) \n selection [ : ] = self . __dragItem . fullName ( ) . split ( \"<STR_LIT:.>\" ) \n self . __pathListing . setSelectedPaths ( [ selection ] , scrollToFirst = False , expandNonLeaf = False ) \n return True \n def __dragEnd ( self , listing , event ) : \n if self . __dragItem is None : \n return False \n with Gaffer . UndoContext ( self . __parent . ancestor ( Gaffer . ScriptNode ) ) : \n self . __updateMetadata ( ) \n self . __dragItem = None \n return True \n def __selectionChanged ( self , pathListing ) : \n self . __deleteButton . setEnabled ( bool ( pathListing . getSelectedPaths ( ) ) ) \n self . __selectionChangedSignal ( self ) \n def __deleteButtonClicked ( self , button ) : \n self . __deleteSelected ( ) \n def __nodeMetadataChanged ( self , nodeTypeId , key , node ) : \n if self . __parent is None : \n return \n if node is not None and not self . __parent . isSame ( node ) : \n return \n if not self . __parent . isInstanceOf ( nodeTypeId ) : \n return \n if key in ( \"<STR_LIT>\" , \"<STR_LIT>\" ) : \n self . __updatePathLazily ( ) \n def __plugMetadataChanged ( self , nodeTypeId , plugPath , key , plug ) : \n if self . __parent is None : \n return \n if plug is not None and not self . __parent . isSame ( plug ) and not self . __parent . isSame ( plug . parent ( ) ) : \n return \n node = self . __parent . node ( ) if isinstance ( self . __parent , Gaffer . Plug ) else self . __parent \n if not node . isInstanceOf ( nodeTypeId ) : \n return \n if key in ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) : \n self . __updatePathLazily ( ) \n def __keyPress ( self , widget , event ) : \n assert ( widget is self ) \n if event . key == \"<STR_LIT>\" or event . key == \"<STR_LIT>\" : \n self . __deleteSelected ( ) \n return True \n return False \n def __addMenuDefinition ( self ) : \n m = IECore . MenuDefinition ( ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . BoolPlug ) } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . FloatPlug ) } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . IntPlug ) } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : True } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . StringPlug ) } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : True } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . V2iPlug ) } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . V3iPlug ) } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . V2fPlug ) } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . V3fPlug ) } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : True } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . Color3fPlug ) } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . Color4fPlug ) } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : True } ) \n m . append ( \"<STR_LIT>\" , { \"<STR_LIT>\" : Gaffer . WeakMethod ( self . __addSection ) } ) \n return m \n def __addPlug ( self , plugType ) : \n plug = plugType ( flags = Gaffer . Plug . Flags . Default | Gaffer . Plug . Flags . Dynamic ) \n _registerMetadata ( plug , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n parentItem = self . __selectedItem ( ) \n if parentItem is not None : \n while not isinstance ( parentItem , _SectionLayoutItem ) : \n parentItem = parentItem . parent ( ) \n else : \n parentItem = self . __pathListing . getPath ( ) . rootItem ( ) \n parentItem = next ( \n ( c for c in parentItem if isinstance ( c , _SectionLayoutItem ) ) , \n parentItem \n ) \n _registerMetadata ( plug , \"<STR_LIT>\" , parentItem . fullName ( ) ) \n with Gaffer . UndoContext ( self . __parent . ancestor ( Gaffer . ScriptNode ) ) : \n self . getPlugParent ( ) . addChild ( plug ) \n self . __updatePathLazily . flush ( self ) \n self . setSelection ( plug ) \n def __addSection ( self ) : \n rootItem = self . __pathListing . getPath ( ) . rootItem ( ) \n existingSectionNames = set ( c . name ( ) for c in rootItem if isinstance ( c , _SectionLayoutItem ) ) \n name = \"<STR_LIT>\" \n index = <NUM_LIT:1> \n while name in existingSectionNames : \n name = \"<STR_LIT>\" % index \n index += <NUM_LIT:1> \n rootItem . append ( _SectionLayoutItem ( name ) ) \n self . __pathListing . getPath ( ) . pathChangedSignal ( ) ( self . __pathListing . getPath ( ) ) \n with Gaffer . UndoContext ( self . __parent . ancestor ( Gaffer . ScriptNode ) ) : \n self . __updateMetadata ( ) \n self . __pathListing . setSelectedPaths ( \n self . __pathListing . getPath ( ) . copy ( ) . setFromString ( \"<STR_LIT:/>\" + name ) \n ) \n def __selectedItem ( self ) : \n selectedPaths = self . __pathListing . getSelectedPaths ( ) \n if not len ( selectedPaths ) : \n return None \n assert ( len ( selectedPaths ) == <NUM_LIT:1> ) \n return selectedPaths [ <NUM_LIT:0> ] . item ( ) \n def __deleteSelected ( self ) : \n selectedItem = self . __selectedItem ( ) \n if selectedItem is None : \n return \n selectedItem . parent ( ) . remove ( selectedItem ) \n def deletePlugsWalk ( item ) : \n if isinstance ( item , _PlugLayoutItem ) : \n item . plug . parent ( ) . removeChild ( item . plug ) \n else : \n for childItem in item : \n deletePlugsWalk ( childItem ) \n with Gaffer . UndoContext ( self . __parent . ancestor ( Gaffer . ScriptNode ) ) : \n deletePlugsWalk ( selectedItem ) \n self . __updateMetadata ( ) \n class _PresetsEditor ( GafferUI . Widget ) : \n def __init__ ( self , parenting = None ) : \n row = GafferUI . ListContainer ( GafferUI . ListContainer . Orientation . Horizontal , spacing = <NUM_LIT:8> ) \n GafferUI . Widget . __init__ ( self , row , parenting = parenting ) \n with row : \n with GafferUI . ListContainer ( spacing = <NUM_LIT:4> ) : \n self . __pathListing = GafferUI . PathListingWidget ( \n Gaffer . DictPath ( collections . OrderedDict ( ) , \"<STR_LIT:/>\" ) , \n columns = ( GafferUI . PathListingWidget . defaultNameColumn , ) , \n ) \n self . __pathListing . setDragPointer ( \"<STR_LIT>\" ) \n self . __pathListing . setSortable ( False ) \n self . __pathListing . setHeaderVisible ( False ) \n self . __pathListing . _qtWidget ( ) . setFixedWidth ( <NUM_LIT:200> ) \n self . __pathListing . _qtWidget ( ) . setFixedHeight ( <NUM_LIT:200> ) \n self . __pathListingSelectionChangedConnection = self . __pathListing . selectionChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __selectionChanged ) ) \n self . __dragEnterConnection = self . __pathListing . dragEnterSignal ( ) . connect ( Gaffer . WeakMethod ( self . __dragEnter ) ) \n self . __dragMoveConnection = self . __pathListing . dragMoveSignal ( ) . connect ( Gaffer . WeakMethod ( self . __dragMove ) ) \n self . __dragEndConnection = self . __pathListing . dragEndSignal ( ) . connect ( Gaffer . WeakMethod ( self . __dragEnd ) ) \n with GafferUI . ListContainer ( GafferUI . ListContainer . Orientation . Horizontal , spacing = <NUM_LIT:4> ) : \n self . __addButton = GafferUI . Button ( image = \"<STR_LIT>\" , hasFrame = False ) \n self . __addButtonClickedConnection = self . __addButton . clickedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __addButtonClicked ) ) \n self . __deleteButton = GafferUI . Button ( image = \"<STR_LIT>\" , hasFrame = False ) \n self . __deleteButtonClickedConnection = self . __deleteButton . clickedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __deleteButtonClicked ) ) \n with GafferUI . ListContainer ( spacing = <NUM_LIT:4> ) as self . __editingColumn : \n GafferUI . Label ( \"<STR_LIT:Name>\" ) \n self . __nameWidget = GafferUI . TextWidget ( ) \n self . __nameEditingFinishedConnection = self . __nameWidget . editingFinishedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __nameEditingFinished ) ) \n GafferUI . Spacer ( IECore . V2i ( <NUM_LIT:4> ) , maximumSize = IECore . V2i ( <NUM_LIT:4> ) ) \n GafferUI . Label ( \"<STR_LIT>\" ) \n self . __valueNode = Gaffer . Node ( \"<STR_LIT>\" ) \n self . __valuePlugSetConnection = self . __valueNode . plugSetSignal ( ) . connect ( Gaffer . WeakMethod ( self . __valuePlugSet ) ) \n def setPlug ( self , plug ) : \n self . __plug = plug \n self . __plugMetadataChangedConnection = None \n del self . __editingColumn [ <NUM_LIT:4> : ] \n plugValueWidget = None \n if self . __plug is not None : \n self . __plugMetadataChangedConnection = Gaffer . Metadata . plugValueChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __plugMetadataChanged ) ) \n self . __valueNode [ \"<STR_LIT>\" ] = plug . createCounterpart ( \"<STR_LIT>\" , plug . Direction . In ) \n if hasattr ( self . __plug , \"<STR_LIT>\" ) : \n plugValueWidget = GafferUI . PlugValueWidget . create ( self . __valueNode [ \"<STR_LIT>\" ] , useTypeOnly = True ) \n self . __editingColumn . append ( plugValueWidget if plugValueWidget is not None else GafferUI . TextWidget ( ) ) \n self . __editingColumn . append ( GafferUI . Spacer ( IECore . V2i ( <NUM_LIT:0> ) , parenting = { \"<STR_LIT>\" : True } ) ) \n self . __updatePath ( ) \n self . __addButton . setEnabled ( hasattr ( self . __plug , \"<STR_LIT>\" ) ) \n def getPlug ( self ) : \n return self . __plug \n def __updatePath ( self ) : \n d = self . __pathListing . getPath ( ) . dict ( ) \n d . clear ( ) \n if self . __plug is not None : \n for name in _registeredMetadata ( self . __plug , instanceOnly = True , persistentOnly = True ) : \n if name . startswith ( \"<STR_LIT>\" ) : \n d [ name [ <NUM_LIT:7> : ] ] = _metadata ( self . __plug , name ) \n self . __pathListing . getPath ( ) . pathChangedSignal ( ) ( self . __pathListing . getPath ( ) ) \n def __plugMetadataChanged ( self , nodeTypeId , plugPath , key , plug ) : \n if plug is None or not plug . isSame ( self . __plug ) : \n return \n if key . startswith ( \"<STR_LIT>\" ) : \n self . __updatePath ( ) \n def __selectionChanged ( self , listing ) : \n selectedPaths = listing . getSelectedPaths ( ) \n self . __nameWidget . setText ( selectedPaths [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] if selectedPaths else \"<STR_LIT>\" ) \n if selectedPaths : \n with Gaffer . BlockedConnection ( self . __valuePlugSetConnection ) : \n self . __valueNode [ \"<STR_LIT>\" ] . setValue ( \n Gaffer . Metadata . plugValue ( self . getPlug ( ) , \"<STR_LIT>\" + selectedPaths [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] ) \n ) \n self . __editingColumn . setEnabled ( bool ( selectedPaths ) ) \n self . __deleteButton . setEnabled ( bool ( selectedPaths ) ) \n def __dragEnter ( self , listing , event ) : \n if event . sourceWidget is not self . __pathListing : \n return False \n if not isinstance ( event . data , IECore . StringVectorData ) : \n return False \n return True \n def __dragMove ( self , listing , event ) : \n d = self . __pathListing . getPath ( ) . dict ( ) \n srcPath = self . __pathListing . getPath ( ) . copy ( ) . setFromString ( event . data [ <NUM_LIT:0> ] ) \n srcIndex = d . keys ( ) . index ( srcPath [ <NUM_LIT:0> ] ) \n targetPath = self . __pathListing . pathAt ( event . line . p0 ) \n if targetPath is not None : \n targetIndex = d . keys ( ) . index ( targetPath [ <NUM_LIT:0> ] ) \n else : \n targetIndex = <NUM_LIT:0> if event . line . p0 . y < <NUM_LIT:1> else len ( d ) \n if srcIndex == targetIndex : \n return True \n items = d . items ( ) \n item = items [ srcIndex ] \n del items [ srcIndex ] \n items . insert ( targetIndex , item ) \n d . clear ( ) \n d . update ( items ) \n self . __pathListing . getPath ( ) . pathChangedSignal ( ) ( self . __pathListing . getPath ( ) ) \n return True \n def __dragEnd ( self , listing , event ) : \n d = self . __pathListing . getPath ( ) . dict ( ) \n with Gaffer . BlockedConnection ( self . __plugMetadataChangedConnection ) : \n with Gaffer . UndoContext ( self . getPlug ( ) . ancestor ( Gaffer . ScriptNode ) ) : \n for item in d . items ( ) : \n Gaffer . Metadata . deregisterPlugValue ( self . getPlug ( ) , \"<STR_LIT>\" + item [ <NUM_LIT:0> ] ) \n for item in d . items ( ) : \n Gaffer . Metadata . registerPlugValue ( self . getPlug ( ) , \"<STR_LIT>\" + item [ <NUM_LIT:0> ] , item [ <NUM_LIT:1> ] ) \n self . __updatePath ( ) \n return True \n def __addButtonClicked ( self , button ) : \n existingNames = [ p [ <NUM_LIT:0> ] for p in self . __pathListing . getPath ( ) . children ( ) ] \n name = \"<STR_LIT>\" \n index = <NUM_LIT:1> \n while name in existingNames : \n name = \"<STR_LIT>\" % index \n index += <NUM_LIT:1> \n with Gaffer . UndoContext ( self . __plug . ancestor ( Gaffer . ScriptNode ) ) : \n Gaffer . Metadata . registerPlugValue ( self . __plug , \"<STR_LIT>\" + name , self . __plug . getValue ( ) ) \n self . __pathListing . setSelectedPaths ( \n self . __pathListing . getPath ( ) . copy ( ) . setFromString ( \"<STR_LIT:/>\" + name ) \n ) \n self . __nameWidget . grabFocus ( ) \n self . __nameWidget . setSelection ( <NUM_LIT:0> , len ( name ) ) \n return True \n def __deleteButtonClicked ( self , button ) : \n paths = self . __pathListing . getPath ( ) . children ( ) \n selectedPreset = self . __pathListing . getSelectedPaths ( ) [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] \n selectedIndex = [ p [ <NUM_LIT:0> ] for p in paths ] . index ( selectedPreset ) \n with Gaffer . UndoContext ( self . __plug . ancestor ( Gaffer . ScriptNode ) ) : \n Gaffer . Metadata . deregisterPlugValue ( self . __plug , \"<STR_LIT>\" + selectedPreset ) \n del paths [ selectedIndex ] \n if len ( paths ) : \n self . __pathListing . setSelectedPaths ( [ paths [ min ( selectedIndex , len ( paths ) - <NUM_LIT:1> ) ] ] ) \n return True \n def __nameEditingFinished ( self , nameWidget ) : \n selectedPaths = self . __pathListing . getSelectedPaths ( ) \n if not len ( selectedPaths ) : \n return True \n oldName = selectedPaths [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] \n newName = nameWidget . getText ( ) \n items = self . __pathListing . getPath ( ) . dict ( ) . items ( ) \n with Gaffer . BlockedConnection ( self . __plugMetadataChangedConnection ) : \n with Gaffer . UndoContext ( self . getPlug ( ) . ancestor ( Gaffer . ScriptNode ) ) : \n for item in items : \n Gaffer . Metadata . deregisterPlugValue ( self . getPlug ( ) , \"<STR_LIT>\" + item [ <NUM_LIT:0> ] ) \n for item in items : \n Gaffer . Metadata . registerPlugValue ( self . getPlug ( ) , \"<STR_LIT>\" + ( item [ <NUM_LIT:0> ] if item [ <NUM_LIT:0> ] != oldName else newName ) , item [ <NUM_LIT:1> ] ) \n self . __updatePath ( ) \n self . __pathListing . setSelectedPaths ( [ self . __pathListing . getPath ( ) . copy ( ) . setFromString ( \"<STR_LIT:/>\" + newName ) ] ) \n return True \n def __valuePlugSet ( self , plug ) : \n if not plug . isSame ( self . __valueNode [ \"<STR_LIT>\" ] ) : \n return \n selectedPaths = self . __pathListing . getSelectedPaths ( ) \n preset = selectedPaths [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] \n with Gaffer . UndoContext ( self . getPlug ( ) . ancestor ( Gaffer . ScriptNode ) ) : \n Gaffer . Metadata . registerPlugValue ( self . getPlug ( ) , \"<STR_LIT>\" + preset , plug . getValue ( ) ) \n class _PlugEditor ( GafferUI . Widget ) : \n def __init__ ( self , parenting = None ) : \n scrolledContainer = GafferUI . ScrolledContainer ( horizontalMode = GafferUI . ScrolledContainer . ScrollMode . Never , borderWidth = <NUM_LIT:8> ) \n GafferUI . Widget . __init__ ( self , scrolledContainer , parenting = parenting ) \n self . __metadataWidgets = { } \n scrolledContainer . setChild ( GafferUI . ListContainer ( spacing = <NUM_LIT:4> ) ) \n with scrolledContainer . getChild ( ) : \n with _Row ( ) : \n _Label ( \"<STR_LIT:Name>\" ) \n self . __nameWidget = GafferUI . NameWidget ( None ) \n with _Row ( ) : \n _Label ( \"<STR_LIT>\" ) \n self . __metadataWidgets [ \"<STR_LIT:label>\" ] = _StringMetadataWidget ( key = \"<STR_LIT:label>\" , acceptEmptyString = False ) \n with _Row ( ) : \n _Label ( \"<STR_LIT>\" , parenting = { \"<STR_LIT>\" : GafferUI . ListContainer . VerticalAlignment . Top } ) \n self . __metadataWidgets [ \"<STR_LIT:description>\" ] = _MultiLineStringMetadataWidget ( key = \"<STR_LIT:description>\" ) \n self . __metadataWidgets [ \"<STR_LIT:description>\" ] . textWidget ( ) . setFixedLineHeight ( <NUM_LIT:10> ) \n with _Row ( ) : \n _Label ( \"<STR_LIT>\" ) \n self . __widgetMenu = GafferUI . MenuButton ( \n menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __widgetMenuDefinition ) ) \n ) \n with GafferUI . Collapsible ( \"<STR_LIT>\" , collapsed = True ) : \n with _Row ( ) : \n _Label ( \"<STR_LIT>\" ) \n self . __presetsEditor = _PresetsEditor ( ) \n with GafferUI . Collapsible ( \"<STR_LIT>\" , collapsed = True ) : \n with GafferUI . ListContainer ( spacing = <NUM_LIT:4> ) : \n with _Row ( ) : \n _Label ( \"<STR_LIT>\" ) \n self . __metadataWidgets [ \"<STR_LIT>\" ] = _BoolMetadataWidget ( key = \"<STR_LIT>\" ) \n for m in self . __metadataDefinitions : \n with _Row ( ) : \n _Label ( m . label ) \n self . __metadataWidgets [ m . key ] = m . metadataWidgetType ( key = m . key ) \n with GafferUI . Collapsible ( \"<STR_LIT>\" , collapsed = True ) : \n with GafferUI . ListContainer ( spacing = <NUM_LIT:4> ) as self . __nodeGraphSection : \n with _Row ( ) : \n _Label ( \"<STR_LIT>\" ) \n self . __gadgetMenu = GafferUI . MenuButton ( \n menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __gadgetMenuDefinition ) ) \n ) \n with _Row ( ) : \n _Label ( \"<STR_LIT>\" ) \n self . __metadataWidgets [ \"<STR_LIT>\" ] = _MenuMetadataWidget ( \n key = \"<STR_LIT>\" , \n labelsAndValues = [ \n ( \"<STR_LIT>\" , None ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT:left>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT:right>\" ) , \n ] \n ) \n with _Row ( ) : \n _Label ( \"<STR_LIT>\" ) \n self . __metadataWidgets [ \"<STR_LIT>\" ] = _ColorSwatchMetadataWidget ( key = \"<STR_LIT>\" ) \n with _Row ( ) : \n _Label ( \"<STR_LIT>\" ) \n self . __metadataWidgets [ \"<STR_LIT>\" ] = _ColorSwatchMetadataWidget ( key = \"<STR_LIT>\" ) \n GafferUI . Spacer ( IECore . V2i ( <NUM_LIT:0> ) , parenting = { \"<STR_LIT>\" : True } ) \n self . __plugMetadataChangedConnection = Gaffer . Metadata . plugValueChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __plugMetadataChanged ) ) \n self . __plug = None \n def setPlug ( self , plug ) : \n self . __plug = plug \n self . __nameWidget . setGraphComponent ( self . __plug ) \n for widget in self . __metadataWidgets . values ( ) : \n widget . setTarget ( self . __plug ) \n self . __updateWidgetMenuText ( ) \n self . __updateWidgetSettings ( ) \n self . __updateGadgetMenuText ( ) \n self . __presetsEditor . setPlug ( plug ) \n self . __nodeGraphSection . setEnabled ( self . __plug is not None and self . __plug . parent ( ) . isSame ( self . __plug . node ( ) ) ) \n self . setEnabled ( self . __plug is not None ) \n def getPlug ( self ) : \n return self . __plug \n def __plugMetadataChanged ( self , nodeTypeId , plugPath , key , plug ) : \n if self . getPlug ( ) is None : \n return \n if plug is not None and not plug . isSame ( self . getPlug ( ) ) : \n return \n if not self . getPlug ( ) . node ( ) . isInstanceOf ( nodeTypeId ) : \n return \n if key == \"<STR_LIT>\" : \n self . __updateWidgetMenuText ( ) \n self . __updateWidgetSettings ( ) \n elif key == \"<STR_LIT>\" : \n self . __updateGadgetMenuText ( ) \n def __updateWidgetMenuText ( self ) : \n if self . getPlug ( ) is None : \n self . __widgetMenu . setText ( \"<STR_LIT>\" ) \n return \n metadata = Gaffer . Metadata . plugValue ( self . getPlug ( ) , \"<STR_LIT>\" ) \n for w in self . __widgetDefinitions : \n if w . metadata == metadata : \n self . __widgetMenu . setText ( w . label ) \n return \n self . __widgetMenu . setText ( metadata ) \n def __updateWidgetSettings ( self ) : \n widgetType = None \n if self . getPlug ( ) is not None : \n widgetType = Gaffer . Metadata . plugValue ( self . getPlug ( ) , \"<STR_LIT>\" ) \n for m in self . __metadataDefinitions : \n widget = self . __metadataWidgets [ m . key ] \n widget . parent ( ) . setEnabled ( m . plugValueWidgetType == widgetType ) \n self . __metadataWidgets [ \"<STR_LIT>\" ] . parent ( ) . setEnabled ( \n self . getPlug ( ) is not None and self . getPlug ( ) . direction ( ) == Gaffer . Plug . Direction . In \n ) \n def __widgetMenuDefinition ( self ) : \n result = IECore . MenuDefinition ( ) \n if self . getPlug ( ) is None : \n return result \n metadata = Gaffer . Metadata . plugValue ( self . getPlug ( ) , \"<STR_LIT>\" ) \n for w in self . __widgetDefinitions : \n if not isinstance ( self . getPlug ( ) , w . plugType ) : \n continue \n result . append ( \n \"<STR_LIT:/>\" + w . label , \n { \n \"<STR_LIT>\" : functools . partial ( Gaffer . WeakMethod ( self . __registerOrDeregisterMetadata ) , key = \"<STR_LIT>\" , value = w . metadata ) , \n \"<STR_LIT>\" : metadata == w . metadata , \n } \n ) \n return result \n def __updateGadgetMenuText ( self ) : \n if self . getPlug ( ) is None : \n self . __gadgetMenu . setText ( \"<STR_LIT>\" ) \n return \n metadata = Gaffer . Metadata . plugValue ( self . getPlug ( ) , \"<STR_LIT>\" ) \n metadata = None if metadata == \"<STR_LIT>\" else metadata \n for g in self . __gadgetDefinitions : \n if g . metadata == metadata : \n self . __gadgetMenu . setText ( g . label ) \n return \n self . __gadgetMenu . setText ( metadata ) \n def __gadgetMenuDefinition ( self ) : \n result = IECore . MenuDefinition ( ) \n if self . getPlug ( ) is None : \n return result \n metadata = Gaffer . Metadata . plugValue ( self . getPlug ( ) , \"<STR_LIT>\" ) \n for g in self . __gadgetDefinitions : \n if not isinstance ( self . getPlug ( ) , g . plugType ) : \n continue \n result . append ( \n \"<STR_LIT:/>\" + g . label , \n { \n \"<STR_LIT>\" : functools . partial ( Gaffer . WeakMethod ( self . __registerOrDeregisterMetadata ) , key = \"<STR_LIT>\" , value = g . metadata ) , \n \"<STR_LIT>\" : metadata == g . metadata , \n } \n ) \n return result \n def __registerOrDeregisterMetadata ( self , unused , key , value ) : \n with Gaffer . UndoContext ( self . getPlug ( ) . ancestor ( Gaffer . ScriptNode ) ) : \n if value is not None : \n Gaffer . Metadata . registerPlugValue ( self . getPlug ( ) , key , value ) \n else : \n Gaffer . Metadata . deregisterPlugValue ( self . getPlug ( ) , key ) \n __WidgetDefinition = collections . namedtuple ( \"<STR_LIT>\" , ( \"<STR_LIT:label>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) ) \n __widgetDefinitions = ( \n __WidgetDefinition ( \"<STR_LIT>\" , Gaffer . Plug , None ) , \n __WidgetDefinition ( \"<STR_LIT>\" , Gaffer . IntPlug , \"<STR_LIT>\" ) , \n __WidgetDefinition ( \"<STR_LIT>\" , Gaffer . StringPlug , \"<STR_LIT>\" ) , \n __WidgetDefinition ( \"<STR_LIT>\" , Gaffer . StringPlug , \"<STR_LIT>\" ) , \n __WidgetDefinition ( \"<STR_LIT>\" , Gaffer . ValuePlug , \"<STR_LIT>\" ) , \n __WidgetDefinition ( \"<STR_LIT>\" , Gaffer . Plug , \"<STR_LIT>\" ) , \n __WidgetDefinition ( \"<STR_LIT:None>\" , Gaffer . Plug , \"<STR_LIT>\" ) , \n ) \n __MetadataDefinition = collections . namedtuple ( \"<STR_LIT>\" , ( \"<STR_LIT:key>\" , \"<STR_LIT:label>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) ) \n __metadataDefinitions = ( \n __MetadataDefinition ( \"<STR_LIT>\" , \"<STR_LIT>\" , _StringMetadataWidget , \"<STR_LIT>\" ) , \n __MetadataDefinition ( \"<STR_LIT>\" , \"<STR_LIT>\" , _StringMetadataWidget , \"<STR_LIT>\" ) , \n __MetadataDefinition ( \"<STR_LIT>\" , \"<STR_LIT>\" , _BoolMetadataWidget , \"<STR_LIT>\" ) , \n __MetadataDefinition ( \"<STR_LIT>\" , \"<STR_LIT>\" , _BoolMetadataWidget , \"<STR_LIT>\" ) , \n __MetadataDefinition ( \"<STR_LIT>\" , \"<STR_LIT>\" , _BoolMetadataWidget , \"<STR_LIT>\" ) , \n __MetadataDefinition ( \"<STR_LIT>\" , \"<STR_LIT>\" , _BoolMetadataWidget , \"<STR_LIT>\" ) , \n ) \n __GadgetDefinition = collections . namedtuple ( \"<STR_LIT>\" , ( \"<STR_LIT:label>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) ) \n __gadgetDefinitions = ( \n __GadgetDefinition ( \"<STR_LIT>\" , Gaffer . Plug , None ) , \n __GadgetDefinition ( \"<STR_LIT>\" , Gaffer . ArrayPlug , \"<STR_LIT>\" ) , \n __GadgetDefinition ( \"<STR_LIT:None>\" , Gaffer . Plug , \"<STR_LIT>\" ) , \n ) \n class _SectionEditor ( GafferUI . Widget ) : \n def __init__ ( self , parenting = None ) : \n column = GafferUI . ListContainer ( spacing = <NUM_LIT:4> , borderWidth = <NUM_LIT:8> ) \n GafferUI . Widget . __init__ ( self , column , parenting = parenting ) \n with column : \n with _Row ( ) : \n _Label ( \"<STR_LIT:Name>\" ) \n self . __nameWidget = GafferUI . TextWidget ( ) \n self . __nameWidgetEditingFinishedConnection = self . __nameWidget . editingFinishedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __nameWidgetEditingFinished ) ) \n with _Row ( ) : \n _Label ( \"<STR_LIT>\" , parenting = { \"<STR_LIT>\" : GafferUI . ListContainer . VerticalAlignment . Top } ) \n self . __summaryMetadataWidget = _MultiLineStringMetadataWidget ( key = \"<STR_LIT>\" ) \n self . __section = \"<STR_LIT>\" \n self . __plugParent = None \n self . __nameChangedSignal = Gaffer . Signal3 ( ) \n def setPlugParent ( self , plugParent ) : \n self . __plugParent = plugParent \n self . __summaryMetadataWidget . setTarget ( self . __plugParent ) \n def getPlugParent ( self ) : \n return self . __plugParent \n def setSection ( self , section ) : \n assert ( isinstance ( section , basestring ) ) \n self . __section = section \n self . __nameWidget . setText ( section . rpartition ( \"<STR_LIT:.>\" ) [ - <NUM_LIT:1> ] ) \n self . __summaryMetadataWidget . setKey ( \"<STR_LIT>\" + self . __section + \"<STR_LIT>\" ) \n def getSection ( self ) : \n return self . __section \n def nameChangedSignal ( self ) : \n return self . __nameChangedSignal \n def __nameWidgetEditingFinished ( self , nameWidget ) : \n if nameWidget . getText ( ) == \"<STR_LIT>\" : \n self . setSection ( self . __section ) \n return \n oldSectionPath = self . __section . split ( \"<STR_LIT:.>\" ) \n newSectionPath = oldSectionPath [ : ] \n newSectionPath [ - <NUM_LIT:1> ] = nameWidget . getText ( ) . replace ( \"<STR_LIT:.>\" , \"<STR_LIT>\" ) \n if oldSectionPath == newSectionPath : \n return \n def newSection ( oldSection ) : \n s = oldSection . split ( \"<STR_LIT:.>\" ) \n if s [ : len ( oldSectionPath ) ] == oldSectionPath : \n s [ : len ( oldSectionPath ) ] = newSectionPath \n return \"<STR_LIT:.>\" . join ( s ) \n else : \n return oldSection \n with Gaffer . UndoContext ( self . __plugParent . ancestor ( Gaffer . ScriptNode ) ) : \n for plug in self . __plugParent . children ( Gaffer . Plug ) : \n s = _metadata ( plug , \"<STR_LIT>\" ) \n if s is not None : \n _registerMetadata ( plug , \"<STR_LIT>\" , newSection ( s ) ) \n emptySections = _metadata ( self . getPlugParent ( ) , \"<STR_LIT>\" ) \n if emptySections : \n for i in range ( <NUM_LIT:0> , len ( emptySections ) ) : \n emptySections [ i ] = newSection ( emptySections [ i ] ) \n _registerMetadata ( self . getPlugParent ( ) , \"<STR_LIT>\" , emptySections ) \n for name in _registeredMetadata ( self . getPlugParent ( ) , instanceOnly = True , persistentOnly = True ) : \n m = re . match ( \"<STR_LIT>\" , name ) \n if m : \n if newSection ( m . group ( <NUM_LIT:2> ) ) != m . group ( <NUM_LIT:2> ) : \n _registerMetadata ( \n self . getPlugParent ( ) , \n m . group ( <NUM_LIT:1> ) + newSection ( m . group ( <NUM_LIT:2> ) ) + m . group ( <NUM_LIT:3> ) , \n _metadata ( self . getPlugParent ( ) , name ) \n ) \n _deregisterMetadata ( self . getPlugParent ( ) , name ) \n self . setSection ( \"<STR_LIT:.>\" . join ( newSectionPath ) ) \n self . nameChangedSignal ( ) ( self , \"<STR_LIT:.>\" . join ( oldSectionPath ) , \"<STR_LIT:.>\" . join ( newSectionPath ) ) \n def _registerMetadata ( target , name , value ) : \n if isinstance ( target , Gaffer . Node ) : \n Gaffer . Metadata . registerNodeValue ( target , name , value ) \n else : \n Gaffer . Metadata . registerPlugValue ( target , name , value ) \n def _registeredMetadata ( target , inherit = True , instanceOnly = False , persistentOnly = False ) : \n if isinstance ( target , Gaffer . Node ) : \n return Gaffer . Metadata . registeredNodeValues ( target , inherit , instanceOnly , persistentOnly ) \n else : \n return Gaffer . Metadata . registeredPlugValues ( target , inherit , instanceOnly , persistentOnly ) \n def _metadata ( target , name ) : \n if isinstance ( target , Gaffer . Node ) : \n return Gaffer . Metadata . nodeValue ( target , name ) \n else : \n return Gaffer . Metadata . plugValue ( target , name ) \n def _deregisterMetadata ( target , name ) : \n if isinstance ( target , Gaffer . Node ) : \n return Gaffer . Metadata . deregisterNodeValue ( target , name ) \n else : \n return Gaffer . Metadata . deregisterPlugValue ( target , name ) \n", "gt": "node"}
{"input": "\n import unittest \n import GafferTest \n import GafferUI \n class NumericSliderTest ( unittest . TestCase ) : \n def testConstruction ( self ) : \n <mask0> = GafferUI . NumericSlider ( value = <NUM_LIT:0> , min = <NUM_LIT:0> , max = <NUM_LIT:1> ) \n self . assertEqual ( s . getPosition ( ) , <NUM_LIT:0> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:0> ) \n self . assertEqual ( s . getRange ( ) , ( <NUM_LIT:0> , <NUM_LIT:1> , <NUM_LIT:0> , <NUM_LIT:1> ) ) \n def testSetValue ( self ) : \n s = GafferUI . NumericSlider ( value = <NUM_LIT:0> , min = <NUM_LIT:0> , max = <NUM_LIT:2> ) \n self . assertEqual ( s . getPosition ( ) , <NUM_LIT:0> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:0> ) \n s . setValue ( <NUM_LIT:0.5> ) \n self . assertEqual ( s . getPosition ( ) , <NUM_LIT> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:0.5> ) \n def testSetRange ( self ) : \n s = GafferUI . NumericSlider ( value = <NUM_LIT:1> , min = <NUM_LIT:0> , max = <NUM_LIT:2> ) \n self . assertEqual ( s . getPosition ( ) , <NUM_LIT:0.5> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:1> ) \n s . setRange ( <NUM_LIT:0> , <NUM_LIT:1> ) \n self . assertEqual ( s . getPosition ( ) , <NUM_LIT:1> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:1> ) \n def testSetZeroRange ( self ) : \n s = GafferUI . NumericSlider ( value = <NUM_LIT:1> , min = <NUM_LIT:1> , max = <NUM_LIT:2> ) \n self . assertEqual ( s . getPosition ( ) , <NUM_LIT:0> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:1> ) \n s . setRange ( <NUM_LIT:1> , <NUM_LIT:1> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:1> ) \n def testSetPosition ( self ) : \n s = GafferUI . NumericSlider ( value = <NUM_LIT:0> , min = <NUM_LIT:0> , max = <NUM_LIT:2> ) \n self . assertEqual ( s . getPosition ( ) , <NUM_LIT:0> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:0> ) \n s . setPosition ( <NUM_LIT:0.5> ) \n self . assertEqual ( s . getPosition ( ) , <NUM_LIT:0.5> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:1> ) \n def testValuesOutsideRangeAreClamped ( self ) : \n s = GafferUI . NumericSlider ( value = <NUM_LIT:0.1> , min = <NUM_LIT:0> , max = <NUM_LIT:2> ) \n cs = GafferTest . CapturingSlot ( s . valueChangedSignal ( ) , s . positionChangedSignal ( ) ) \n s . setValue ( <NUM_LIT:3> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:2> ) \n self . assertEqual ( s . getPosition ( ) , <NUM_LIT:1> ) \n self . assertEqual ( len ( cs ) , <NUM_LIT:2> ) \n s . setValue ( <NUM_LIT:3> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:2> ) \n self . assertEqual ( s . getPosition ( ) , <NUM_LIT:1> ) \n self . assertEqual ( len ( cs ) , <NUM_LIT:2> ) \n def testPositionsOutsideRangeAreClamped ( self ) : \n s = GafferUI . NumericSlider ( value = <NUM_LIT:0.1> , min = <NUM_LIT:0> , max = <NUM_LIT:2> ) \n cs = GafferTest . CapturingSlot ( s . valueChangedSignal ( ) , s . positionChangedSignal ( ) ) \n s . setPosition ( <NUM_LIT:2> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:2> ) \n self . assertEqual ( s . getPosition ( ) , <NUM_LIT:1> ) \n self . assertEqual ( len ( cs ) , <NUM_LIT:2> ) \n s . setPosition ( <NUM_LIT:2> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:2> ) \n self . assertEqual ( s . getPosition ( ) , <NUM_LIT:1> ) \n self . assertEqual ( len ( cs ) , <NUM_LIT:2> ) \n def testHardRange ( self ) : \n s = GafferUI . NumericSlider ( value = <NUM_LIT:0.1> , min = <NUM_LIT:0> , max = <NUM_LIT:2> , hardMin = - <NUM_LIT:1> , hardMax = <NUM_LIT:3> ) \n self . assertEqual ( s . getRange ( ) , ( <NUM_LIT:0> , <NUM_LIT:2> , - <NUM_LIT:1> , <NUM_LIT:3> ) ) \n cs = GafferTest . CapturingSlot ( s . valueChangedSignal ( ) , s . positionChangedSignal ( ) ) \n s . setValue ( <NUM_LIT:3> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:3> ) \n self . assertEqual ( s . getPosition ( ) , <NUM_LIT> ) \n self . assertEqual ( len ( cs ) , <NUM_LIT:2> ) \n s . setValue ( <NUM_LIT> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:3> ) \n self . assertEqual ( s . getPosition ( ) , <NUM_LIT> ) \n self . assertEqual ( len ( cs ) , <NUM_LIT:2> ) \n s . setValue ( - <NUM_LIT:1> ) \n self . assertEqual ( s . getValue ( ) , - <NUM_LIT:1> ) \n self . assertEqual ( s . getPosition ( ) , - <NUM_LIT:0.5> ) \n self . assertEqual ( len ( cs ) , <NUM_LIT:4> ) \n s . setValue ( - <NUM_LIT:2> ) \n self . assertEqual ( s . getValue ( ) , - <NUM_LIT:1> ) \n self . assertEqual ( s . getPosition ( ) , - <NUM_LIT:0.5> ) \n self . assertEqual ( len ( cs ) , <NUM_LIT:4> ) \n def testSetRangeClampsValue ( self ) : \n s = GafferUI . NumericSlider ( value = <NUM_LIT:0.5> , min = <NUM_LIT:0> , max = <NUM_LIT:2> ) \n self . assertEqual ( s . getPosition ( ) , <NUM_LIT> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:0.5> ) \n s . setRange ( <NUM_LIT:1> , <NUM_LIT:2> ) \n self . assertEqual ( s . getPosition ( ) , <NUM_LIT:0> ) \n self . assertEqual ( s . getValue ( ) , <NUM_LIT:1> ) \n def testMultipleValues ( self ) : \n self . assertRaises ( Exception , GafferUI . NumericSlider , value = <NUM_LIT:0> , values = [ <NUM_LIT:1> , <NUM_LIT:2> ] ) \n s = GafferUI . NumericSlider ( values = [ <NUM_LIT:1> , <NUM_LIT> ] , min = <NUM_LIT:0> , max = <NUM_LIT:2> ) \n self . assertEqual ( s . getValues ( ) , [ <NUM_LIT:1> , <NUM_LIT> ] ) \n self . assertEqual ( s . getPositions ( ) , [ <NUM_LIT:0.5> , <NUM_LIT> ] ) \n self . assertRaises ( ValueError , s . getValue ) \n if __name__ == \"<STR_LIT:__main__>\" : \n unittest . main ( ) \n", "gt": "s"}
{"input": "\n import unittest \n import weakref \n import sys \n import IECore \n import Gaffer \n import GafferTest \n import GafferUI \n import GafferUITest \n <mask0> = GafferUI . _qtImport ( \"<STR_LIT>\" ) \n QtGui = GafferUI . _qtImport ( \"<STR_LIT>\" ) \n class TestWidget ( GafferUI . Widget ) : \n def __init__ ( self , ** kw ) : \n GafferUI . Widget . __init__ ( self , QtGui . QLabel ( \"<STR_LIT:hello>\" ) , ** kw ) \n class TestWidget2 ( GafferUI . Widget ) : \n def __init__ ( self ) : \n self . topLevelGafferWidget = TestWidget ( ) \n GafferUI . Widget . __init__ ( self , self . topLevelGafferWidget ) \n class WidgetTest ( GafferUITest . TestCase ) : \n def testOwner ( self ) : \n w = TestWidget ( ) \n self . assert_ ( GafferUI . Widget . _owner ( w . _qtWidget ( ) ) is w ) \n def testParent ( self ) : \n w = TestWidget ( ) \n self . assert_ ( w . parent ( ) is None ) \n def testCanDie ( self ) : \n w = TestWidget ( ) \n wr1 = weakref . ref ( w ) \n wr2 = weakref . ref ( w . _qtWidget ( ) ) \n del w \n self . assert_ ( wr1 ( ) is None ) \n self . assert_ ( wr2 ( ) is None ) \n def testAncestor ( self ) : \n w = GafferUI . Window ( \"<STR_LIT:test>\" ) \n l = GafferUI . ListContainer ( GafferUI . ListContainer . Orientation . Vertical ) \n p = GafferUI . SplitContainer ( ) \n l . append ( p ) \n w . setChild ( l ) \n self . assert_ ( p . ancestor ( GafferUI . ListContainer ) is l ) \n self . assert_ ( p . ancestor ( GafferUI . Window ) is w ) \n self . assert_ ( p . ancestor ( GafferUI . Menu ) is None ) \n def testIsAncestorOf ( self ) : \n with GafferUI . Window ( \"<STR_LIT:test>\" ) as w : \n with GafferUI . SplitContainer ( ) as p : \n with GafferUI . ListContainer ( ) as l1 : \n b1 = GafferUI . Button ( ) \n with GafferUI . ListContainer ( ) as l2 : \n b2 = GafferUI . Button ( ) \n self . assertTrue ( l2 . isAncestorOf ( b2 ) ) \n self . assertFalse ( l1 . isAncestorOf ( b2 ) ) \n self . assertTrue ( p . isAncestorOf ( b2 ) ) \n self . assertTrue ( w . isAncestorOf ( b2 ) ) \n self . assertFalse ( b2 . isAncestorOf ( b1 ) ) \n self . assertFalse ( b2 . isAncestorOf ( l1 ) ) \n self . assertFalse ( b2 . isAncestorOf ( l2 ) ) \n self . assertFalse ( b2 . isAncestorOf ( p ) ) \n self . assertFalse ( b2 . isAncestorOf ( w ) ) \n self . assertTrue ( l1 . isAncestorOf ( b1 ) ) \n self . assertFalse ( l2 . isAncestorOf ( b1 ) ) \n self . assertTrue ( p . isAncestorOf ( b1 ) ) \n self . assertTrue ( w . isAncestorOf ( b1 ) ) \n def testGafferWidgetAsTopLevel ( self ) : \n w = TestWidget2 ( ) \n self . assert_ ( GafferUI . Widget . _owner ( w . _qtWidget ( ) ) is w ) \n self . assert_ ( w . topLevelGafferWidget . parent ( ) is w ) \n self . assert_ ( GafferUI . Widget . _owner ( w . topLevelGafferWidget . _qtWidget ( ) ) is not w ) \n def testToolTip ( self ) : \n w = TestWidget ( ) \n self . assertEqual ( w . getToolTip ( ) , \"<STR_LIT>\" ) \n w = TestWidget ( toolTip = \"<STR_LIT>\" ) \n self . assertEqual ( w . getToolTip ( ) , \"<STR_LIT>\" ) \n w . setToolTip ( \"<STR_LIT:a>\" ) \n self . assertEqual ( w . getToolTip ( ) , \"<STR_LIT:a>\" ) \n def testEnabledState ( self ) : \n w = TestWidget ( ) \n self . assertEqual ( w . getEnabled ( ) , True ) \n self . assertEqual ( w . enabled ( ) , True ) \n w . setEnabled ( False ) \n self . assertEqual ( w . getEnabled ( ) , False ) \n self . assertEqual ( w . enabled ( ) , False ) \n w . setEnabled ( True ) \n self . assertEqual ( w . getEnabled ( ) , True ) \n self . assertEqual ( w . enabled ( ) , True ) \n def testDisabledWidgetsDontGetSignals ( self ) : \n w = TestWidget ( ) \n def f ( w , event ) : \n WidgetTest . signalsEmitted += <NUM_LIT:1> \n c = w . buttonPressSignal ( ) . connect ( f ) \n WidgetTest . signalsEmitted = <NUM_LIT:0> \n event = QtGui . QMouseEvent ( QtCore . QEvent . MouseButtonPress , QtCore . QPoint ( <NUM_LIT:0> , <NUM_LIT:0> ) , QtCore . Qt . LeftButton , QtCore . Qt . LeftButton , QtCore . Qt . NoModifier ) \n QtGui . QApplication . instance ( ) . sendEvent ( w . _qtWidget ( ) , event ) \n self . assertEqual ( WidgetTest . signalsEmitted , <NUM_LIT:1> ) \n w . setEnabled ( False ) \n QtGui . QApplication . instance ( ) . sendEvent ( w . _qtWidget ( ) , event ) \n self . assertEqual ( WidgetTest . signalsEmitted , <NUM_LIT:1> ) \n w . setEnabled ( True ) \n QtGui . QApplication . instance ( ) . sendEvent ( w . _qtWidget ( ) , event ) \n self . assertEqual ( WidgetTest . signalsEmitted , <NUM_LIT:2> ) \n def testCanDieAfterUsingSignals ( self ) : \n w = TestWidget ( ) \n wr1 = weakref . ref ( w ) \n wr2 = weakref . ref ( w . _qtWidget ( ) ) \n w . buttonPressSignal ( ) \n w . buttonReleaseSignal ( ) \n w . mouseMoveSignal ( ) \n w . wheelSignal ( ) \n del w \n self . assert_ ( wr1 ( ) is None ) \n self . assert_ ( wr2 ( ) is None ) \n def testVisibility ( self ) : \n with GafferUI . Window ( ) as w : \n with GafferUI . ListContainer ( ) as l : \n t = TestWidget ( ) \n self . assertEqual ( w . getVisible ( ) , False ) \n self . assertEqual ( l . getVisible ( ) , True ) \n self . assertEqual ( t . getVisible ( ) , True ) \n self . assertEqual ( w . visible ( ) , False ) \n self . assertEqual ( l . visible ( ) , False ) \n self . assertEqual ( t . visible ( ) , False ) \n w . setVisible ( True ) \n self . assertEqual ( w . getVisible ( ) , True ) \n self . assertEqual ( l . getVisible ( ) , True ) \n self . assertEqual ( t . getVisible ( ) , True ) \n self . assertEqual ( w . visible ( ) , True ) \n self . assertEqual ( l . visible ( ) , True ) \n self . assertEqual ( t . visible ( ) , True ) \n w . setVisible ( False ) \n self . assertEqual ( w . getVisible ( ) , False ) \n self . assertEqual ( l . getVisible ( ) , True ) \n self . assertEqual ( t . getVisible ( ) , True ) \n self . assertEqual ( w . visible ( ) , False ) \n self . assertEqual ( l . visible ( ) , False ) \n self . assertEqual ( t . visible ( ) , False ) \n self . assertEqual ( t . visible ( relativeTo = l ) , True ) \n self . assertEqual ( t . visible ( relativeTo = w ) , True ) \n w . setVisible ( True ) \n t . setVisible ( False ) \n self . assertEqual ( t . getVisible ( ) , False ) \n self . assertEqual ( t . visible ( ) , False ) \n self . assertEqual ( t . visible ( relativeTo = l ) , False ) \n def testGetVisibleForNewWidgets ( self ) : \n w = TestWidget ( ) \n self . assertEqual ( w . getVisible ( ) , True ) \n def testVisibilityOfParentlessWidgets ( self ) : \n w = GafferUI . Window ( ) \n t = TestWidget ( ) \n self . assertEqual ( w . getVisible ( ) , False ) \n self . assertEqual ( w . visible ( ) , False ) \n self . assertEqual ( t . getVisible ( ) , True ) \n self . assertEqual ( t . visible ( ) , False ) \n w . setVisible ( True ) \n self . assertEqual ( w . getVisible ( ) , True ) \n self . assertEqual ( w . visible ( ) , True ) \n w . setChild ( t ) \n self . assertEqual ( t . getVisible ( ) , True ) \n self . assertEqual ( t . visible ( ) , True ) \n w . removeChild ( t ) \n self . assertEqual ( t . parent ( ) , None ) \n self . assertEqual ( t . getVisible ( ) , True ) \n self . assertEqual ( t . visible ( ) , False ) \n def testVisibilityWhenTransferringWidgets ( self ) : \n w1 = GafferUI . Window ( ) \n w1 . setVisible ( True ) \n w2 = GafferUI . Window ( ) \n w2 . setVisible ( True ) \n v = TestWidget ( ) \n self . assertEqual ( v . getVisible ( ) , True ) \n self . assertEqual ( v . visible ( ) , False ) \n h = TestWidget ( ) \n self . assertEqual ( h . getVisible ( ) , True ) \n h . setVisible ( False ) \n self . assertEqual ( h . getVisible ( ) , False ) \n self . assertEqual ( h . visible ( ) , False ) \n w1 . setChild ( v ) \n self . assertEqual ( v . getVisible ( ) , True ) \n self . assertEqual ( v . visible ( ) , True ) \n self . assertEqual ( h . getVisible ( ) , False ) \n self . assertEqual ( h . visible ( ) , False ) \n w2 . setChild ( v ) \n self . assertEqual ( v . getVisible ( ) , True ) \n self . assertEqual ( v . visible ( ) , True ) \n self . assertEqual ( h . getVisible ( ) , False ) \n self . assertEqual ( h . visible ( ) , False ) \n w1 . setChild ( h ) \n self . assertEqual ( v . getVisible ( ) , True ) \n self . assertEqual ( v . visible ( ) , True ) \n self . assertEqual ( h . getVisible ( ) , False ) \n self . assertEqual ( h . visible ( ) , False ) \n w2 . setChild ( h ) \n self . assertEqual ( v . getVisible ( ) , True ) \n self . assertEqual ( v . visible ( ) , False ) \n self . assertEqual ( h . getVisible ( ) , False ) \n self . assertEqual ( h . visible ( ) , False ) \n def testSignals ( self ) : \n w = TestWidget ( ) \n for s in [ \n ( \"<STR_LIT>\" , GafferUI . WidgetEventSignal ) , \n ( \"<STR_LIT>\" , GafferUI . WidgetEventSignal ) , \n ( \"<STR_LIT>\" , GafferUI . WidgetEventSignal ) , \n ( \"<STR_LIT>\" , GafferUI . WidgetEventSignal ) , \n ( \"<STR_LIT>\" , GafferUI . WidgetEventSignal ) , \n ( \"<STR_LIT>\" , GafferUI . WidgetEventSignal ) , \n ( \"<STR_LIT>\" , GafferUI . WidgetSignal ) , \n ( \"<STR_LIT>\" , GafferUI . WidgetSignal ) , \n ( \"<STR_LIT>\" , GafferUI . WidgetEventSignal ) , \n ( \"<STR_LIT>\" , GafferUI . WidgetSignal ) , \n ( \"<STR_LIT>\" , GafferUI . WidgetSignal ) , \n ( \"<STR_LIT>\" , GafferUI . WidgetSignal ) , \n ] : \n self . failUnless ( isinstance ( getattr ( w , s [ <NUM_LIT:0> ] ) ( ) , s [ <NUM_LIT:1> ] ) ) \n self . failUnless ( getattr ( w , s [ <NUM_LIT:0> ] ) ( ) is getattr ( w , s [ <NUM_LIT:0> ] ) ( ) ) \n def testBound ( self ) : \n w = GafferUI . Window ( borderWidth = <NUM_LIT:8> ) \n b = GafferUI . Button ( ) \n w . setChild ( b ) \n w . setVisible ( True ) \n w . setPosition ( IECore . V2i ( <NUM_LIT:100> ) ) \n self . waitForIdle ( <NUM_LIT:1000> ) \n wb = w . bound ( ) \n bb = b . bound ( ) \n bbw = b . bound ( relativeTo = w ) \n self . failUnless ( isinstance ( wb , IECore . Box2i ) ) \n self . failUnless ( isinstance ( bb , IECore . Box2i ) ) \n self . failUnless ( isinstance ( bbw , IECore . Box2i ) ) \n self . assertEqual ( bb . size ( ) , bbw . size ( ) ) \n self . assertEqual ( bbw . min , bb . min - wb . min ) \n self . assertEqual ( b . size ( ) , bb . size ( ) ) \n def testParentChangedSignal ( self ) : \n w = TestWidget ( ) \n window = GafferUI . Window ( ) \n cs = GafferTest . CapturingSlot ( w . parentChangedSignal ( ) ) \n self . assertEqual ( len ( cs ) , <NUM_LIT:0> ) \n window . setChild ( w ) \n self . assertEqual ( len ( cs ) , <NUM_LIT:1> ) \n self . assertEqual ( cs [ <NUM_LIT:0> ] , ( w , ) ) \n window . setChild ( None ) \n self . assertEqual ( len ( cs ) , <NUM_LIT:2> ) \n self . assertEqual ( cs [ <NUM_LIT:1> ] , ( w , ) ) \n def testHighlighting ( self ) : \n w = TestWidget ( ) \n self . assertEqual ( w . getHighlighted ( ) , False ) \n w . setHighlighted ( True ) \n self . assertEqual ( w . getHighlighted ( ) , True ) \n w . setHighlighted ( False ) \n self . assertEqual ( w . getHighlighted ( ) , False ) \n def testWidgetAt ( self ) : \n with GafferUI . Window ( ) as w1 : \n t1 = GafferUI . TextWidget ( \"<STR_LIT:hello>\" ) \n with GafferUI . Window ( ) as w2 : \n t2 = GafferUI . TextWidget ( \"<STR_LIT:hello>\" ) \n w1 . setVisible ( True ) \n w2 . setVisible ( True ) \n w1 . setPosition ( IECore . V2i ( <NUM_LIT:100> ) ) \n w2 . setPosition ( IECore . V2i ( <NUM_LIT> ) ) \n self . waitForIdle ( <NUM_LIT:1000> ) \n self . assertTrue ( GafferUI . Widget . widgetAt ( w1 . bound ( ) . center ( ) ) is t1 ) \n self . assertTrue ( GafferUI . Widget . widgetAt ( w2 . bound ( ) . center ( ) ) is t2 ) \n self . assertTrue ( GafferUI . Widget . widgetAt ( w1 . bound ( ) . center ( ) , widgetType = GafferUI . Window ) is w1 ) \n self . assertTrue ( GafferUI . Widget . widgetAt ( w2 . bound ( ) . center ( ) , widgetType = GafferUI . Window ) is w2 ) \n def testMousePosition ( self ) : \n w = GafferUI . Window ( borderWidth = <NUM_LIT:8> ) \n b = GafferUI . Button ( ) \n w . setChild ( b ) \n w . setVisible ( True ) \n w . setPosition ( IECore . V2i ( <NUM_LIT:100> ) ) \n self . waitForIdle ( <NUM_LIT:1000> ) \n mouseGlobal = GafferUI . Widget . mousePosition ( ) \n mouseLocal = GafferUI . Widget . mousePosition ( relativeTo = b ) \n self . assertEqual ( mouseGlobal , mouseLocal + b . bound ( ) . min ) \n def testAddressAndObject ( self ) : \n button = GafferUI . Button ( ) \n address = GafferUI . _qtAddress ( button . _qtWidget ( ) ) \n self . assertTrue ( isinstance ( address , int ) ) \n widget = GafferUI . _qtObject ( address , QtGui . QPushButton ) \n self . assertTrue ( isinstance ( widget , QtGui . QPushButton ) ) \n def testSetVisibleWithNonBool ( self ) : \n w = TestWidget ( ) \n self . assertTrue ( w . getVisible ( ) is True ) \n w . setVisible ( <NUM_LIT:0> ) \n self . assertTrue ( w . getVisible ( ) is False ) \n w . setVisible ( <NUM_LIT:1> ) \n self . assertTrue ( w . getVisible ( ) is True ) \n if __name__ == \"<STR_LIT:__main__>\" : \n unittest . main ( ) \n", "gt": "QtCore"}
{"input": "\n import GafferUI \n import GafferSceneUI \n def __toolMenu ( nodeEditor , node , menuDefinition ) : \n GafferUI . UIEditor . appendNodeEditorToolMenuDefinitions ( nodeEditor , node , menuDefinition ) \n GafferUI . BoxUI . appendNodeEditorToolMenuDefinitions ( nodeEditor , node , menuDefinition ) \n GafferSceneUI . FilteredSceneProcessorUI . appendNodeEditorToolMenuDefinitions ( nodeEditor , node , menuDefinition ) \n <mask0> = GafferUI . NodeEditor . toolMenuSignal ( ) . connect ( __toolMenu ) \n", "gt": "__nodeEditorToolMenuConnection"}
{"input": "\n <mask0> = ( <NUM_LIT:0> , <NUM_LIT:1> , <NUM_LIT:0> , '<STR_LIT>' , <NUM_LIT:1> ) \n __version__ = '<STR_LIT:.>' . join ( map ( str , VERSION ) ) \n def get_version ( ) : \n version = '<STR_LIT>' % ( VERSION [ <NUM_LIT:0> ] , VERSION [ <NUM_LIT:1> ] ) \n if VERSION [ <NUM_LIT:2> ] : \n version = '<STR_LIT>' % ( version , VERSION [ <NUM_LIT:2> ] ) \n if VERSION [ <NUM_LIT:3> : ] == ( '<STR_LIT>' , <NUM_LIT:0> ) : \n version = '<STR_LIT>' % version \n else : \n if VERSION [ <NUM_LIT:3> ] != '<STR_LIT>' : \n version = '<STR_LIT>' % ( version , VERSION [ <NUM_LIT:3> ] , VERSION [ <NUM_LIT:4> ] ) \n return version \n", "gt": "VERSION"}
{"input": "\n import yappi \n import os \n from totalimpact import backend \n <mask0> = \"<STR_LIT:.>\" \n logfile = '<STR_LIT>' \n yappi . clear_stats ( ) \n yappi . start ( ) \n backend . main ( logfile ) \n yappi . stop ( ) \n yappi . print_stats ( sort_type = yappi . SORTTYPE_TTOT , limit = <NUM_LIT:30> , thread_stats_on = False ) \n", "gt": "rootdir"}
{"input": "\n import os , collections , simplejson \n from totalimpact import db , app \n from totalimpact . providers import pmc \n from test . unit_tests . providers import common \n from test . unit_tests . providers . common import ProviderTestCase \n from totalimpact . providers . provider import Provider , ProviderContentMalformedError , ProviderFactory \n from totalimpact import provider_batch_data \n from test . utils import http \n from test . utils import setup_postgres_for_unittests , teardown_postgres_for_unittests \n from nose . tools import assert_equals , raises , nottest , assert_items_equal \n <mask0> = os . path . join ( os . path . split ( __file__ ) [ <NUM_LIT:0> ] , \"<STR_LIT>\" ) \n SAMPLE_EXTRACT_METRICS_PAGE = os . path . join ( datadir , \"<STR_LIT>\" ) \n SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH = os . path . join ( datadir , \"<STR_LIT>\" ) \n TEST_PMID = \"<STR_LIT>\" \n class TestPmc ( ProviderTestCase ) : \n provider_name = \"<STR_LIT>\" \n testitem_aliases = ( \"<STR_LIT>\" , TEST_PMID ) \n testitem_metrics = ( \"<STR_LIT>\" , TEST_PMID ) \n def setUp ( self ) : \n ProviderTestCase . setUp ( self ) \n self . db = setup_postgres_for_unittests ( db , app ) \n sample_data_dump = open ( SAMPLE_EXTRACT_METRICS_PAGE , \"<STR_LIT:r>\" ) . read ( ) \n sample_data_dump_different_month = open ( SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH , \"<STR_LIT:r>\" ) . read ( ) \n test_monthly_data = [ \n { \"<STR_LIT>\" : \"<STR_LIT:abc>\" , \n \"<STR_LIT:type>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : sample_data_dump , \n \"<STR_LIT>\" : <NUM_LIT:1.0> , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \"<STR_LIT>\" : [ \"<STR_LIT>\" , \"<STR_LIT>\" ] } , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } , \n { \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT:type>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : sample_data_dump_different_month , \n \"<STR_LIT>\" : <NUM_LIT:1.0> , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \"<STR_LIT>\" : [ \"<STR_LIT>\" ] } , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } , \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" \n ] \n } , \n \"<STR_LIT>\" : <NUM_LIT:1> , \n \"<STR_LIT:type>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } \n ] \n for doc in test_monthly_data : \n new_object = provider_batch_data . create_objects_from_doc ( doc ) \n print new_object \n self . provider = pmc . Pmc ( ) \n print \"<STR_LIT>\" \n def tearDown ( self ) : \n teardown_postgres_for_unittests ( self . db ) \n def test_has_applicable_batch_data_true ( self ) : \n response = self . provider . has_applicable_batch_data ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert_equals ( response , True ) \n def test_has_applicable_batch_data_false ( self ) : \n response = self . provider . has_applicable_batch_data ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert_equals ( response , False ) \n def test_build_batch_data_dict ( self ) : \n response = self . provider . build_batch_data_dict ( ) \n print response . keys ( ) \n expected = [ ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) ] \n assert_items_equal ( response . keys ( ) , expected ) \n def test_is_relevant_alias ( self ) : \n assert_equals ( self . provider . is_relevant_alias ( self . testitem_aliases ) , True ) \n def test_extract_metrics_success ( self ) : \n f = open ( SAMPLE_EXTRACT_METRICS_PAGE , \"<STR_LIT:r>\" ) \n good_page = f . read ( ) \n metrics_dict = self . provider . _extract_metrics ( good_page , id = \"<STR_LIT>\" ) \n print metrics_dict \n expected = { '<STR_LIT>' : <NUM_LIT> , '<STR_LIT>' : <NUM_LIT> , '<STR_LIT>' : <NUM_LIT> , '<STR_LIT>' : <NUM_LIT:9> } \n assert_equals ( metrics_dict , expected ) \n def test_provider_metrics_500 ( self ) : \n pass \n def test_provider_metrics_400 ( self ) : \n pass \n def test_provider_metrics_nonsense_xml ( self ) : \n pass \n def test_provider_metrics_nonsense_txt ( self ) : \n pass \n def test_provider_metrics_empty ( self ) : \n pass \n @ http \n def test_metrics ( self ) : \n metrics_dict = self . provider . metrics ( [ ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ] ) \n expected = { '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT:9> , '<STR_LIT>' ) } \n print metrics_dict \n for key in expected : \n assert metrics_dict [ key ] [ <NUM_LIT:0> ] >= expected [ key ] [ <NUM_LIT:0> ] , [ key , metrics_dict [ key ] , expected [ key ] ] \n assert metrics_dict [ key ] [ <NUM_LIT:1> ] == expected [ key ] [ <NUM_LIT:1> ] , [ key , metrics_dict [ key ] , expected [ key ] ] \n @ http \n def test_metrics_multiple_months ( self ) : \n metrics_dict = self . provider . metrics ( [ ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ] ) \n expected = { '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) } \n print metrics_dict \n for key in expected : \n assert metrics_dict [ key ] [ <NUM_LIT:0> ] >= expected [ key ] [ <NUM_LIT:0> ] , [ key , metrics_dict [ key ] , expected [ key ] ] \n assert metrics_dict [ key ] [ <NUM_LIT:1> ] == expected [ key ] [ <NUM_LIT:1> ] , [ key , metrics_dict [ key ] , expected [ key ] ] \n @ http \n def test_metrics_real ( self ) : \n metrics_dict = self . provider . metrics ( [ ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ] ) \n expected = { '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) } \n print metrics_dict \n for key in expected : \n assert metrics_dict [ key ] [ <NUM_LIT:0> ] >= expected [ key ] [ <NUM_LIT:0> ] , [ key , metrics_dict [ key ] , expected [ key ] ] \n assert metrics_dict [ key ] [ <NUM_LIT:1> ] == expected [ key ] [ <NUM_LIT:1> ] , [ key , metrics_dict [ key ] , expected [ key ] ] \n", "gt": "datadir"}
{"input": "\n import os \n import sys \n import hashlib \n import logging \n import json \n from cPickle import PicklingError \n import redis \n from totalimpact import REDIS_CACHE_DATABASE_NUMBER \n <mask0> = logging . getLogger ( \"<STR_LIT>\" ) \n cache_client = redis . from_url ( os . getenv ( \"<STR_LIT>\" ) , REDIS_CACHE_DATABASE_NUMBER ) \n MAX_PAYLOAD_SIZE_BYTES = <NUM_LIT:1000> * <NUM_LIT:1000> \n MAX_CACHE_SIZE_BYTES = <NUM_LIT:100> * <NUM_LIT:1000> * <NUM_LIT:1000> \n class CacheException ( Exception ) : \n pass \n class Cache ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def _build_hash_key ( self , key ) : \n json_key = json . dumps ( key ) \n hash_key = hashlib . md5 ( json_key . encode ( \"<STR_LIT:utf-8>\" ) ) . hexdigest ( ) \n return hash_key \n def _get_client ( self ) : \n return cache_client \n def __init__ ( self , max_cache_age = <NUM_LIT> * <NUM_LIT> ) : \n self . max_cache_age = max_cache_age \n self . flush_cache ( ) \n def flush_cache ( self ) : \n mc = self . _get_client ( ) \n def get_cache_entry ( self , key ) : \n \"\"\"<STR_LIT>\"\"\" \n mc = self . _get_client ( ) \n hash_key = self . _build_hash_key ( key ) \n response = mc . get ( hash_key ) \n if response : \n response = json . loads ( response ) \n return response \n def set_cache_entry ( self , key , data ) : \n \"\"\"<STR_LIT>\"\"\" \n if sys . getsizeof ( data [ \"<STR_LIT:text>\" ] ) > MAX_PAYLOAD_SIZE_BYTES : \n logger . debug ( u\"<STR_LIT>\" ) \n return None \n mc = self . _get_client ( ) \n if mc . info ( ) [ \"<STR_LIT>\" ] >= MAX_CACHE_SIZE_BYTES : \n logger . debug ( u\"<STR_LIT>\" ) \n return None \n hash_key = self . _build_hash_key ( key ) \n set_response = mc . set ( hash_key , json . dumps ( data ) ) \n mc . expire ( hash_key , self . max_cache_age ) \n if not set_response : \n logger . warning ( \"<STR_LIT>\" ) \n raise CacheException ( \"<STR_LIT>\" ) \n return set_response \n", "gt": "logger"}
{"input": "\n from totalimpact . providers import provider \n from totalimpact . providers . provider import Provider , ProviderContentMalformedError \n import simplejson , os , re , urllib \n import logging \n <mask0> = logging . getLogger ( '<STR_LIT>' ) \n class Plosalm ( Provider ) : \n example_id = ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n url = \"<STR_LIT>\" \n descr = \"<STR_LIT>\" \n metrics_url_template = \"<STR_LIT>\" + os . environ [ \"<STR_LIT>\" ] \n provenance_url_template = \"<STR_LIT>\" \n PLOS_ICON = \"<STR_LIT>\" \n static_meta_dict = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT:description>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : PLOS_ICON , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT:description>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : PLOS_ICON , \n } \n } \n def __init__ ( self ) : \n super ( Plosalm , self ) . __init__ ( ) \n def is_relevant_alias ( self , alias ) : \n ( namespace , nid ) = alias \n relevant = ( ( \"<STR_LIT>\" == namespace ) and ( \"<STR_LIT>\" in nid ) ) \n return ( relevant ) \n def _extract_metrics ( self , page , status_code = <NUM_LIT:200> , id = None ) : \n if status_code != <NUM_LIT:200> : \n if status_code == <NUM_LIT> : \n return { } \n else : \n raise ( self . _get_error ( status_code ) ) \n if not \"<STR_LIT>\" in page : \n raise ProviderContentMalformedError \n json_response = provider . _load_json ( page ) \n this_article = json_response [ <NUM_LIT:0> ] [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] [ \"<STR_LIT>\" ] \n dict_of_keylists = { \n '<STR_LIT>' : [ '<STR_LIT:html>' ] , \n '<STR_LIT>' : [ '<STR_LIT>' ] \n } \n metrics_dict = provider . _extract_from_data_dict ( this_article , dict_of_keylists ) \n return metrics_dict \n", "gt": "logger"}
{"input": "\n import os \n import sys \n import urlparse \n from kombu import Exchange , Queue \n sys . path . append ( '<STR_LIT:.>' ) \n <mask0> = os . environ . get ( '<STR_LIT>' , \"<STR_LIT>\" ) \n if not redis_url . endswith ( \"<STR_LIT:/>\" ) : \n redis_url += \"<STR_LIT:/>\" \n BROKER_URL = redis_url + \"<STR_LIT:1>\" \n CELERY_RESULT_BACKEND = redis_url + \"<STR_LIT:2>\" \n REDIS_CONNECT_RETRY = True \n BROKER_TRANSPORT_OPTIONS = { '<STR_LIT>' : True , \n '<STR_LIT>' : True , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT:100> \n } \n CELERY_DEFAULT_QUEUE = '<STR_LIT>' \n CELERY_QUEUES = [ \n Queue ( '<STR_LIT>' , routing_key = '<STR_LIT>' ) , \n Queue ( '<STR_LIT>' , routing_key = '<STR_LIT>' ) \n ] \n BROKER_POOL_LIMIT = None \n CELERY_CREATE_MISSING_QUEUES = True \n CELERY_ACCEPT_CONTENT = [ '<STR_LIT>' , '<STR_LIT>' ] \n CELERY_ENABLE_UTC = True \n CELERY_TASK_RESULT_EXPIRES = <NUM_LIT> * <NUM_LIT> * <NUM_LIT:1> \n CELERY_ACKS_LATE = True \n CELERYD_FORCE_EXECV = True \n CELERY_TRACK_STARTED = True \n CELERYD_PREFETCH_MULTIPLIER = <NUM_LIT:1> \n CELERY_IMPORTS = ( \"<STR_LIT>\" , ) \n CELERY_ANNOTATIONS = { \n '<STR_LIT>' : { '<STR_LIT>' : <NUM_LIT> * <NUM_LIT:2> } \n } \n", "gt": "redis_url"}
{"input": "\n from totalimpact . providers import provider \n from totalimpact . providers . provider import Provider , ProviderFactory \n from totalimpactwebapp import app , db \n from nose . tools import assert_equals , nottest \n from xml . dom import minidom \n from test . utils import setup_postgres_for_unittests , teardown_postgres_for_unittests \n import simplejson , BeautifulSoup \n import os \n from sqlalchemy . sql import text \n <mask0> = os . path . join ( os . path . split ( __file__ ) [ <NUM_LIT:0> ] , \"<STR_LIT>\" ) \n class Test_Provider ( ) : \n TEST_PROVIDER_CONFIG = [ \n ( \"<STR_LIT>\" , { \"<STR_LIT>\" : <NUM_LIT:1> } ) , \n ( \"<STR_LIT>\" , { \"<STR_LIT>\" : <NUM_LIT:3> } ) , \n ( \"<STR_LIT>\" , { \"<STR_LIT>\" : <NUM_LIT:3> } ) , \n ] \n TEST_JSON = \"\"\"<STR_LIT>\"\"\" \n TEST_XML = open ( os . path . join ( sampledir , \"<STR_LIT>\" , \"<STR_LIT>\" ) ) . read ( ) \n def setUp ( self ) : \n self . db = setup_postgres_for_unittests ( db , app ) \n def tearDown ( self ) : \n teardown_postgres_for_unittests ( self . db ) \n def test_get_provider ( self ) : \n provider = ProviderFactory . get_provider ( \"<STR_LIT>\" ) \n assert_equals ( provider . __class__ . __name__ , \"<STR_LIT>\" ) \n def test_get_providers ( self ) : \n providers = ProviderFactory . get_providers ( self . TEST_PROVIDER_CONFIG ) \n provider_names = [ provider . __class__ . __name__ for provider in providers ] \n assert_equals ( set ( provider_names ) , set ( [ '<STR_LIT>' , '<STR_LIT>' , \"<STR_LIT>\" ] ) ) \n def test_get_providers_filters_by_metrics ( self ) : \n providers = ProviderFactory . get_providers ( self . TEST_PROVIDER_CONFIG , \"<STR_LIT>\" ) \n provider_names = [ provider . __class__ . __name__ for provider in providers ] \n assert_equals ( set ( provider_names ) , set ( [ '<STR_LIT>' , '<STR_LIT>' , \"<STR_LIT>\" ] ) ) \n def test_get_providers_filters_by_biblio ( self ) : \n providers = ProviderFactory . get_providers ( self . TEST_PROVIDER_CONFIG , \"<STR_LIT>\" ) \n provider_names = [ provider . __class__ . __name__ for provider in providers ] \n assert_equals ( set ( provider_names ) , set ( [ '<STR_LIT>' , '<STR_LIT>' ] ) ) \n def test_get_providers_filters_by_aliases ( self ) : \n providers = ProviderFactory . get_providers ( self . TEST_PROVIDER_CONFIG , \"<STR_LIT>\" ) \n provider_names = [ provider . __class__ . __name__ for provider in providers ] \n assert_equals ( set ( provider_names ) , set ( [ '<STR_LIT>' , '<STR_LIT>' ] ) ) \n def test_lookup_json ( self ) : \n page = self . TEST_JSON \n data = simplejson . loads ( page ) \n response = provider . _lookup_json ( data , [ '<STR_LIT>' , '<STR_LIT:name>' ] ) \n assert_equals ( response , u'<STR_LIT>' ) \n def test_extract_json ( self ) : \n page = self . TEST_JSON \n dict_of_keylists = { \n '<STR_LIT:title>' : [ '<STR_LIT>' , '<STR_LIT:name>' ] , \n '<STR_LIT:description>' : [ '<STR_LIT>' , '<STR_LIT:description>' ] } \n response = provider . _extract_from_json ( page , dict_of_keylists ) \n assert_equals ( response , { '<STR_LIT:description>' : u'<STR_LIT>' , '<STR_LIT:title>' : u'<STR_LIT>' } ) \n def test_lookup_xml_from_dom ( self ) : \n page = self . TEST_XML \n doc = minidom . parseString ( page . strip ( ) ) \n response = provider . _lookup_xml_from_dom ( doc , [ '<STR_LIT>' ] ) \n assert_equals ( response , <NUM_LIT> ) \n def test_lookup_xml_from_soup ( self ) : \n page = self . TEST_XML \n doc = BeautifulSoup . BeautifulStoneSoup ( page ) \n response = provider . _lookup_xml_from_soup ( doc , [ '<STR_LIT>' ] ) \n assert_equals ( response , <NUM_LIT> ) \n def test_extract_xml ( self ) : \n page = self . TEST_XML \n dict_of_keylists = { \n '<STR_LIT:count>' : [ '<STR_LIT>' ] } \n response = provider . _extract_from_xml ( page , dict_of_keylists ) \n assert_equals ( response , { '<STR_LIT:count>' : <NUM_LIT> } ) \n def test_doi_from_url_string ( self ) : \n test_url = \"<STR_LIT>\" \n expected = \"<STR_LIT>\" \n response = provider . doi_from_url_string ( test_url ) \n assert_equals ( response , expected ) \n def test_is_issn_in_doaj_false ( self ) : \n response = provider . is_issn_in_doaj ( \"<STR_LIT>\" ) \n assert_equals ( response , False ) \n def test_is_issn_in_doaj_true ( self ) : \n zookeys_issn = \"<STR_LIT>\" \n response = provider . is_issn_in_doaj ( zookeys_issn ) \n assert_equals ( response , True ) \n def test_import_products ( self ) : \n response = provider . import_products ( \"<STR_LIT>\" , \n { \"<STR_LIT>\" : [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] } ) \n expected = [ ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT:url>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) ] \n assert_equals ( response , expected ) \n def test_import_products_bad_providername ( self ) : \n response = provider . import_products ( \"<STR_LIT>\" , { } ) \n expected = [ ] \n assert_equals ( response , expected ) \n class TestProviderFactory ( ) : \n TEST_PROVIDER_CONFIG = [ \n ( \"<STR_LIT>\" , { \"<STR_LIT>\" : <NUM_LIT:1> } ) , \n ( \"<STR_LIT>\" , { \"<STR_LIT>\" : <NUM_LIT:3> } ) , \n ( \"<STR_LIT>\" , { \"<STR_LIT>\" : <NUM_LIT:3> } ) , \n ] \n def test_get_all_static_meta ( self ) : \n sm = ProviderFactory . get_all_static_meta ( self . TEST_PROVIDER_CONFIG ) \n expected = '<STR_LIT>' \n assert_equals ( sm [ \"<STR_LIT>\" ] [ \"<STR_LIT:description>\" ] , expected ) \n def test_get_all_metric_names ( self ) : \n response = ProviderFactory . get_all_metric_names ( self . TEST_PROVIDER_CONFIG ) \n expected = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n assert_equals ( response , expected ) \n def test_get_all_metadata ( self ) : \n md = ProviderFactory . get_all_metadata ( self . TEST_PROVIDER_CONFIG ) \n print md [ \"<STR_LIT>\" ] \n assert_equals ( md [ \"<STR_LIT>\" ] [ '<STR_LIT:url>' ] , '<STR_LIT>' ) \n", "gt": "sampledir"}
{"input": "\n import datetime \n import copy \n import unicode_helpers \n import json \n import logging \n from util import cached_property \n from util import dict_from_dir \n from totalimpactwebapp import db \n <mask0> = logging . getLogger ( \"<STR_LIT>\" ) \n def clean_id ( nid ) : \n try : \n nid = nid . strip ( '<STR_LIT>' ) . strip ( ) \n nid = unicode_helpers . remove_nonprinting_characters ( nid ) \n except ( TypeError , AttributeError ) : \n pass \n return ( nid ) \n def normalize_alias_tuple ( ns , nid ) : \n ns = clean_id ( ns ) \n ns = ns . lower ( ) \n if ns == \"<STR_LIT>\" : \n return ( ns , nid ) \n nid = clean_id ( nid ) \n from totalimpact . providers import crossref \n from totalimpact . providers import pubmed \n from totalimpact . providers import arxiv \n from totalimpact . providers import webpage \n from totalimpact import importer \n clean_nid = None \n if ns == \"<STR_LIT>\" or importer . is_doi ( nid ) : \n ns = \"<STR_LIT>\" \n clean_nid = crossref . clean_doi ( nid ) \n elif ns == \"<STR_LIT>\" or importer . is_pmid ( nid ) : \n ns = \"<STR_LIT>\" \n clean_nid = pubmed . clean_pmid ( nid ) \n elif ns == \"<STR_LIT>\" or importer . is_arxiv ( nid ) : \n ns = \"<STR_LIT>\" \n clean_nid = arxiv . clean_arxiv_id ( nid ) \n elif ns == \"<STR_LIT:url>\" or importer . is_url ( nid ) : \n ns = \"<STR_LIT:url>\" \n clean_nid = webpage . clean_url ( nid ) \n elif ns not in [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT:url>\" ] : \n clean_nid = nid \n if not clean_nid : \n return None \n return ( ns , clean_nid ) \n def clean_alias_tuple_for_comparing ( ns , nid ) : \n alias_tuple = normalize_alias_tuple ( ns , nid ) \n if not alias_tuple : \n return None \n try : \n ( ns , nid ) = alias_tuple \n cleaned_alias = ( ns . lower ( ) , nid . lower ( ) ) \n except AttributeError : \n logger . debug ( u\"<STR_LIT>\" . format ( \n ns = ns , nid = nid ) ) \n cleaned_alias = ( ns , nid ) \n return cleaned_alias \n def alias_tuples_from_dict ( aliases_dict ) : \n \"\"\"<STR_LIT>\"\"\" \n alias_tuples = [ ] \n for ns , ids in aliases_dict . iteritems ( ) : \n if isinstance ( ids , basestring ) : \n alias_tuples . append ( ( ns , ids ) ) \n else : \n for id in ids : \n alias_tuples . append ( ( ns , id ) ) \n return alias_tuples \n def alias_dict_from_tuples ( aliases_tuples ) : \n alias_dict = { } \n for ( ns , ids ) in aliases_tuples : \n if ns in alias_dict : \n alias_dict [ ns ] += [ ids ] \n else : \n alias_dict [ ns ] = [ ids ] \n return alias_dict \n def canonical_aliases ( orig_aliases_dict ) : \n lowercase_aliases_dict = { } \n for orig_namespace in orig_aliases_dict : \n lowercase_namespace = clean_id ( orig_namespace . lower ( ) ) \n if lowercase_namespace == \"<STR_LIT>\" : \n lowercase_aliases_dict [ lowercase_namespace ] = [ clean_id ( doi . lower ( ) ) for doi in orig_aliases_dict [ orig_namespace ] ] \n else : \n lowercase_aliases_dict [ lowercase_namespace ] = [ clean_id ( nid ) for nid in orig_aliases_dict [ orig_namespace ] ] \n return lowercase_aliases_dict \n def merge_alias_dicts ( aliases1 , aliases2 ) : \n merged_aliases = copy . deepcopy ( aliases1 ) \n for ns , nid_list in aliases2 . iteritems ( ) : \n for nid in nid_list : \n try : \n if not nid in merged_aliases [ ns ] : \n merged_aliases [ ns ] . append ( nid ) \n except KeyError : \n merged_aliases [ ns ] = [ nid ] \n return merged_aliases \n def matches_alias ( product1 , product2 , exclude = [ ] ) : \n alias_tuple_list1 = [ alias_row . my_alias_tuple_for_comparing for alias_row in product1 . alias_rows ] \n alias_tuple_list2 = [ alias_row . my_alias_tuple_for_comparing for alias_row in product2 . alias_rows ] \n has_matches = False \n for alias_tuple1 in alias_tuple_list1 : \n if alias_tuple1 : \n ( ns , nid ) = alias_tuple1 \n if alias_tuple1 in alias_tuple_list2 and ns not in exclude : \n has_matches = True \n return has_matches \n class AliasRow ( db . Model ) : \n __tablename__ = '<STR_LIT>' \n tiid = db . Column ( db . Text , db . ForeignKey ( '<STR_LIT>' ) , primary_key = True ) \n namespace = db . Column ( db . Text , primary_key = True ) \n nid = db . Column ( db . Text , primary_key = True ) \n collected_date = db . Column ( db . DateTime ( ) ) \n def __init__ ( self , ** kwargs ) : \n if \"<STR_LIT>\" not in kwargs : \n self . collected_date = datetime . datetime . utcnow ( ) \n super ( AliasRow , self ) . __init__ ( ** kwargs ) \n @ cached_property \n def alias_tuple ( self ) : \n return ( self . namespace , self . nid ) \n @ cached_property \n def my_alias_tuple_for_comparing ( self ) : \n return clean_alias_tuple_for_comparing ( self . namespace , self . nid ) \n def is_equivalent_alias ( self , given_namespace , given_nid ) : \n if not given_nid : \n return False \n given_clean_alias = clean_alias_tuple_for_comparing ( given_namespace , given_nid ) \n if not given_clean_alias : \n return False \n return given_clean_alias == self . my_alias_tuple_for_comparing \n class Aliases ( object ) : \n def __init__ ( self , alias_rows ) : \n ignore_namepaces = [ \"<STR_LIT>\" ] \n self . tiid = None \n for alias_row in alias_rows : \n if alias_row . namespace not in ignore_namepaces : \n self . tiid = alias_row . tiid \n try : \n getattr ( self , alias_row . namespace ) . append ( alias_row . nid ) \n except AttributeError : \n setattr ( self , alias_row . namespace , [ alias_row . nid ] ) \n @ cached_property \n def best_url ( self ) : \n if self . display_doi : \n return u\"<STR_LIT>\" + self . display_doi \n if self . display_pmid : \n return u\"<STR_LIT>\" + self . display_pmid \n if self . display_pmc : \n return u\"<STR_LIT>\" + self . display_pmc \n if self . resolved_url : \n return self . resolved_url \n try : \n return self . url [ <NUM_LIT:0> ] \n except AttributeError : \n return None \n @ cached_property \n def display_best_url ( self ) : \n return self . best_url \n @ cached_property \n def display_pmid ( self ) : \n try : \n return self . pmid [ <NUM_LIT:0> ] \n except AttributeError : \n return None \n @ cached_property \n def display_pmc ( self ) : \n try : \n return self . pmc [ <NUM_LIT:0> ] \n except AttributeError : \n return None \n @ cached_property \n def display_doi ( self ) : \n try : \n return self . doi [ <NUM_LIT:0> ] \n except AttributeError : \n return None \n @ cached_property \n def display_arxiv ( self ) : \n try : \n return self . arxiv [ <NUM_LIT:0> ] \n except AttributeError : \n return None \n @ cached_property \n def has_formal_alias ( self ) : \n if self . display_arxiv or self . display_doi or self . display_pmid or self . display_pmc : \n return True \n else : \n return False \n @ cached_property \n def resolved_url ( self ) : \n try : \n for url in self . url : \n if \"<STR_LIT>\" in url : \n continue \n elif \"<STR_LIT>\" in url : \n continue \n elif \"<STR_LIT>\" in url : \n continue \n elif \"<STR_LIT>\" in url : \n continue \n elif \"<STR_LIT>\" in url : \n continue \n else : \n return url \n return self . url [ <NUM_LIT:0> ] \n except AttributeError : \n return None \n def get_genre ( self ) : \n return self . _guess_genre_and_host_from_aliases ( ) [ <NUM_LIT:0> ] \n def get_host ( self ) : \n return self . _guess_genre_and_host_from_aliases ( ) [ <NUM_LIT:1> ] \n def _guess_genre_and_host_from_aliases ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n genre = \"<STR_LIT>\" \n host = \"<STR_LIT>\" \n if hasattr ( self , \"<STR_LIT>\" ) : \n joined_doi_string = \"<STR_LIT>\" . join ( self . doi ) . lower ( ) \n if \"<STR_LIT>\" in joined_doi_string : \n genre = \"<STR_LIT>\" \n host = \"<STR_LIT>\" \n elif \"<STR_LIT>\" in joined_doi_string : \n host = \"<STR_LIT>\" \n genre = \"<STR_LIT>\" \n else : \n genre = \"<STR_LIT>\" \n elif hasattr ( self , \"<STR_LIT>\" ) : \n genre = \"<STR_LIT>\" \n elif hasattr ( self , \"<STR_LIT>\" ) : \n genre = \"<STR_LIT>\" \n host = \"<STR_LIT>\" \n elif hasattr ( self , \"<STR_LIT>\" ) : \n genre = \"<STR_LIT>\" \n host = \"<STR_LIT>\" \n elif hasattr ( self , \"<STR_LIT>\" ) : \n genre = \"<STR_LIT>\" \n host = \"<STR_LIT>\" \n elif hasattr ( self , \"<STR_LIT:url>\" ) : \n joined_url_string = \"<STR_LIT>\" . join ( self . url ) . lower ( ) \n if \"<STR_LIT>\" in joined_url_string : \n genre = \"<STR_LIT>\" \n host = \"<STR_LIT>\" \n elif \"<STR_LIT>\" in joined_url_string : \n genre = \"<STR_LIT>\" \n host = \"<STR_LIT>\" \n elif ( \"<STR_LIT>\" in joined_url_string ) or ( \"<STR_LIT>\" in joined_url_string ) : \n genre = \"<STR_LIT>\" \n host = \"<STR_LIT>\" \n elif \"<STR_LIT>\" in joined_url_string : \n genre = \"<STR_LIT>\" \n host = \"<STR_LIT>\" \n else : \n genre = \"<STR_LIT>\" \n return genre , host \n def to_dict ( self ) : \n ret = dict_from_dir ( self ) \n return ret \n", "gt": "logger"}
{"input": "\n from totalimpactwebapp import json_sqlalchemy \n from util import commit \n from util import cached_property \n from util import dict_from_dir \n from util import as_int_or_float_if_possible \n from totalimpactwebapp import db \n from totalimpactwebapp . tweeter import Tweeter \n from birdy . twitter import AppClient , TwitterApiError , TwitterRateLimitError , TwitterClientError \n from collections import defaultdict \n from sqlalchemy import case \n import os \n import re \n import datetime \n import logging \n <mask0> = logging . getLogger ( '<STR_LIT>' ) \n def tweets_from_tiids ( tiids ) : \n if not tiids : \n return [ ] \n tweets = db . session . query ( Tweet ) . filter ( Tweet . tiid . in_ ( tiids ) ) . all ( ) \n return tweets \n def get_product_tweets_for_profile ( profile_id ) : \n tweets = db . session . query ( Tweet ) . filter ( Tweet . profile_id == profile_id ) . all ( ) \n response = defaultdict ( list ) \n for tweet in tweets : \n if tweet . tiid and tweet . tweet_text : \n response [ tweet . tiid ] . append ( tweet ) \n return response \n def store_tweet_payload_and_tweeter_from_twitter ( payload_dicts_from_twitter , tweets ) : \n tweets_by_tweet_id = defaultdict ( list ) \n for tweet in tweets : \n tweets_by_tweet_id [ tweet . tweet_id ] . append ( tweet ) \n for payload_dict in payload_dicts_from_twitter : \n tweet_id = payload_dict [ \"<STR_LIT>\" ] \n logger . debug ( \"<STR_LIT>\" . format ( \n tweet_id = tweet_id ) ) \n for tweet in tweets_by_tweet_id [ tweet_id ] : \n if not tweet . payload : \n tweet . payload = payload_dict \n logger . info ( u\"<STR_LIT>\" . format ( \n tweet_id = tweet_id , tiid = tweet . tiid ) ) \n if \"<STR_LIT:user>\" in payload_dict : \n try : \n tweet . tweeter . set_attributes_from_twitter_data ( payload_dict [ \"<STR_LIT:user>\" ] ) \n except AttributeError : \n tweeter = Tweeter . query . get ( tweet . screen_name ) \n if not tweeter : \n tweeter = Tweeter ( screen_name = tweet . screen_name ) \n db . session . add ( tweeter ) \n tweeter . set_attributes_from_twitter_data ( payload_dict [ \"<STR_LIT:user>\" ] ) \n tweet . tweeter = tweeter \n commit ( db ) \n if tweet . tweeter : \n logger . info ( u\"<STR_LIT>\" . format ( \n screen_name = tweet . tweeter . screen_name ) ) \n def flag_deleted_tweets ( tweet_ids ) : \n if not tweet_ids : \n return None \n for tweet in Tweet . query . filter ( Tweet . tweet_id . in_ ( tweet_ids ) ) . all ( ) : \n tweet . is_deleted = True \n db . session . merge ( tweet ) \n def handle_all_tweets ( data , tweets ) : \n store_tweet_payload_and_tweeter_from_twitter ( data , tweets ) \n tweet_ids = [ tweet . tweet_id for tweet in tweets ] \n tweet_ids_with_response = [ tweet [ \"<STR_LIT>\" ] for tweet in data ] \n tweet_ids_without_response = [ tweet for tweet in tweet_ids if tweet not in tweet_ids_with_response ] \n flag_deleted_tweets ( tweet_ids_without_response ) \n return True \n class AppDictClient ( AppClient ) : \n @ staticmethod \n def get_json_object_hook ( data ) : \n return data \n def get_and_save_tweet_text_and_tweeter_followers ( tweets ) : \n client = AppDictClient ( \n os . getenv ( \"<STR_LIT>\" ) , \n os . getenv ( \"<STR_LIT>\" ) , \n access_token = os . getenv ( \"<STR_LIT>\" ) \n ) \n logger . info ( u\"<STR_LIT>\" . format ( \n num = len ( tweets ) ) ) \n group_size = <NUM_LIT:100> \n list_of_groups = [ tweets [ i : i + group_size ] for i in range ( <NUM_LIT:0> , len ( tweets ) , group_size ) ] \n for tweet_subset in list_of_groups : \n tweet_id_string = \"<STR_LIT:U+002C>\" . join ( [ tweet . tweet_id for tweet in tweet_subset ] ) \n try : \n response = client . api . statuses . lookup . post ( id = tweet_id_string , trim_user = False ) \n handle_all_tweets ( response . data , tweet_subset ) \n except TwitterApiError , e : \n logger . exception ( \"<STR_LIT>\" ) \n except TwitterClientError , e : \n logger . exception ( \"<STR_LIT>\" ) \n except TwitterRateLimitError , e : \n logger . exception ( \"<STR_LIT>\" ) \n return \n def hydrate_twitter_text_and_followers ( profile_id , altmetric_twitter_posts ) : \n logger . info ( u\"<STR_LIT>\" . format ( \n profile_id = profile_id ) ) \n tweets_to_hydrate_from_twitter = [ ] \n tweets = Tweet . query . filter ( Tweet . profile_id == profile_id ) \n tweet_dict = dict ( [ ( ( tweet . tweet_id , tweet . tiid ) , tweet ) for tweet in tweets ] ) \n for tiid , post_list in altmetric_twitter_posts . iteritems ( ) : \n for post in post_list : \n tweet_id = post [ \"<STR_LIT>\" ] \n screen_name = post [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n if ( tweet_id , tiid ) in tweet_dict . keys ( ) : \n tweet = tweet_dict [ ( tweet_id , tiid ) ] \n if not tweet . tweet_text and not tweet . is_deleted : \n tweets_to_hydrate_from_twitter . append ( tweet ) \n else : \n if not Tweet . query . get ( ( tweet_id , tiid ) ) : \n tweet = Tweet ( tweet_id = tweet_id , tiid = tiid ) \n tweet . set_attributes_from_altmetric_post ( post ) \n tweet . profile_id = profile_id \n tweets_to_hydrate_from_twitter . append ( tweet ) \n db . session . add ( tweet ) \n if not tweet . tweeter : \n tweeter = Tweeter . query . get ( screen_name ) \n if not tweeter : \n tweeter = Tweeter ( screen_name = screen_name ) \n db . session . add ( tweeter ) \n tweeter . set_attributes_from_altmetric_post ( post ) \n commit ( db ) \n logger . info ( u\"<STR_LIT>\" . format ( \n profile_id = profile_id ) ) \n if tweets_to_hydrate_from_twitter : \n commit ( db ) \n tweet_ids = [ tweet . tweet_id for tweet in tweets_to_hydrate_from_twitter ] \n logger . info ( u\"<STR_LIT>\" . format ( \n profile_id = profile_id ) ) \n get_and_save_tweet_text_and_tweeter_followers ( tweets_to_hydrate_from_twitter ) \n commit ( db ) \n else : \n logger . info ( u\"<STR_LIT>\" . format ( \n profile_id = profile_id ) ) \n return \n handle_workaround_join_string = \"<STR_LIT>\" \n class Tweet ( db . Model ) : \n tweet_id = db . Column ( db . Text , primary_key = True ) \n tiid = db . Column ( db . Text , primary_key = True ) \n profile_id = db . Column ( db . Integer , db . ForeignKey ( '<STR_LIT>' ) ) \n screen_name = db . Column ( db . Text , db . ForeignKey ( '<STR_LIT>' ) ) \n tweet_timestamp = db . Column ( db . DateTime ( ) ) \n payload = db . Column ( json_sqlalchemy . JSONAlchemy ( db . Text ) ) \n is_deleted = db . Column ( db . Boolean ) \n tweet_url = db . Column ( db . Text ) \n country = db . Column ( db . Text ) \n followers_at_time_of_tweet = db . Column ( db . Integer ) \n tweeter = db . relationship ( \n '<STR_LIT>' , \n lazy = '<STR_LIT>' , \n cascade = '<STR_LIT:all>' , \n backref = db . backref ( \"<STR_LIT>\" ) , \n uselist = False , \n primaryjoin = handle_workaround_join_string \n ) \n def __init__ ( self , ** kwargs ) : \n if \"<STR_LIT>\" in kwargs : \n payload_dict = kwargs [ \"<STR_LIT>\" ] \n kwargs [ \"<STR_LIT>\" ] = payload_dict [ \"<STR_LIT>\" ] \n kwargs [ \"<STR_LIT>\" ] = payload_dict [ \"<STR_LIT:user>\" ] [ \"<STR_LIT>\" ] \n kwargs [ \"<STR_LIT>\" ] = payload_dict \n kwargs [ \"<STR_LIT>\" ] = datetime . datetime . strptime ( payload_dict [ \"<STR_LIT>\" ] , r\"<STR_LIT>\" ) \n if not \"<STR_LIT>\" in kwargs : \n try : \n kwargs [ \"<STR_LIT>\" ] = payload_dict [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n except ( AttributeError , TypeError ) : \n pass \n super ( Tweet , self ) . __init__ ( ** kwargs ) \n @ classmethod \n def most_recent_tweet_id ( cls , screen_name ) : \n screen_name = screen_name . replace ( \"<STR_LIT:@>\" , \"<STR_LIT>\" ) \n q = db . session . query ( Tweet ) . filter ( Tweet . screen_name == screen_name ) . order_by ( Tweet . tweet_timestamp . desc ( ) ) \n tweet = q . first ( ) \n try : \n tweet_id = tweet . tweet_id \n except AttributeError : \n tweet_id = None \n return tweet_id \n @ cached_property \n def tweet_text ( self ) : \n try : \n return self . payload [ \"<STR_LIT:text>\" ] \n except TypeError : \n return None \n @ cached_property \n def tweet_text_with_links ( self ) : \n if self . tweet_text is None : \n return None \n ret = self . tweet_text \n ret = re . sub ( r\"<STR_LIT>\" , r\"<STR_LIT>\" , ret ) \n for url_info in self . urls : \n my_link = u\"<STR_LIT>\" . format ( \n url = url_info [ \"<STR_LIT>\" ] , \n display_url = url_info [ \"<STR_LIT>\" ] \n ) \n ret = re . sub ( r\"<STR_LIT>\" , my_link , ret , <NUM_LIT:1> ) \n ret = re . sub ( r\"<STR_LIT>\" , r\"<STR_LIT>\" , ret ) \n ret = re . sub ( r\"<STR_LIT>\" , r\"<STR_LIT>\" , ret ) \n return ret \n @ cached_property \n def urls ( self ) : \n try : \n return self . payload [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n except TypeError : \n return None \n except KeyError : \n return [ ] \n @ cached_property \n def has_country ( self ) : \n return self . country != None \n def set_attributes_from_altmetric_post ( self , post ) : \n self . tweet_id = post [ \"<STR_LIT>\" ] \n self . screen_name = post [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n self . tweet_timestamp = post [ \"<STR_LIT>\" ] \n if \"<STR_LIT>\" in post [ \"<STR_LIT>\" ] : \n self . country = post [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . get ( \"<STR_LIT>\" , None ) \n return self \n def __repr__ ( self ) : \n return u'<STR_LIT>' . format ( \n tweet_id = self . tweet_id , \n profile_id = self . profile_id , \n screen_name = self . screen_name , \n timestamp = self . tweet_timestamp ) \n def to_dict ( self ) : \n attributes_to_ignore = [ \n \"<STR_LIT>\" \n ] \n ret = dict_from_dir ( self , attributes_to_ignore ) \n return ret \n twitter_example_contents = \"\"\"<STR_LIT>\"\"\" \n", "gt": "logger"}
{"input": "\n import os \n import numpy as np \n def load_gender_data ( ntrain = <NUM_LIT> , ntest = <NUM_LIT> ) : \n import pandas as pd \n <mask0> = os . path . dirname ( os . path . realpath ( __file__ ) ) \n relative_path = \"<STR_LIT>\" \n fullpath = os . path . join ( file_loc , relative_path ) \n data = pd . read_csv ( fullpath , nrows = ntrain + ntest ) \n X = data [ '<STR_LIT:text>' ] . values \n X = [ str ( x ) for x in X ] \n Y = data [ '<STR_LIT>' ] . values \n trX = X [ : - ntest ] \n teX = X [ - ntest : ] \n trY = Y [ : - ntest ] \n teY = Y [ - ntest : ] \n return trX , teX , trY , teY \n def load_mnist ( data_dir = None ) : \n if data_dir is None : \n import urllib \n import gzip \n url = '<STR_LIT>' \n fnames = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' \n ] \n for fname in fnames : \n if not os . path . isfile ( fname ) : \n print '<STR_LIT>' , fname \n urllib . urlretrieve ( url + fname , fname ) \n data_dir = '<STR_LIT>' \n fd = gzip . open ( os . path . join ( data_dir , '<STR_LIT>' ) ) \n loaded = np . fromstring ( fd . read ( ) , dtype = np . uint8 ) \n trX = loaded [ <NUM_LIT:16> : ] . reshape ( ( <NUM_LIT> , - <NUM_LIT:1> ) ) \n fd = gzip . open ( os . path . join ( data_dir , '<STR_LIT>' ) ) \n loaded = np . fromstring ( fd . read ( ) , dtype = np . uint8 ) \n trY = loaded [ <NUM_LIT:8> : ] . reshape ( ( <NUM_LIT> ) ) \n fd = gzip . open ( os . path . join ( data_dir , '<STR_LIT>' ) ) \n loaded = np . fromstring ( fd . read ( ) , dtype = np . uint8 ) \n teX = loaded [ <NUM_LIT:16> : ] . reshape ( ( <NUM_LIT> , - <NUM_LIT:1> ) ) \n fd = gzip . open ( os . path . join ( data_dir , '<STR_LIT>' ) ) \n loaded = np . fromstring ( fd . read ( ) , dtype = np . uint8 ) \n teY = loaded [ <NUM_LIT:8> : ] . reshape ( ( <NUM_LIT> ) ) \n trX = trX / <NUM_LIT> \n teX = teX / <NUM_LIT> \n trX = trX . reshape ( - <NUM_LIT:1> , <NUM_LIT> , <NUM_LIT> ) \n teX = teX . reshape ( - <NUM_LIT:1> , <NUM_LIT> , <NUM_LIT> ) \n return trX , teX , trY , teY \n", "gt": "file_loc"}
{"input": "\n import unittest \n import os \n import commands \n from utils import get_temporary_location \n from utils import delete_repository \n from gitpy import LocalRepository \n from gitpy import find_repository \n from gitpy . exceptions import GitException \n class EmptyRepositoryTest ( unittest . TestCase ) : \n def setUp ( self ) : \n self . dirname = get_temporary_location ( ) \n self . repo = LocalRepository ( self . dirname ) \n self . assertFalse ( os . path . exists ( self . dirname ) ) \n self . assertFalse ( self . repo . isValid ( ) ) \n def tearDown ( self ) : \n if os . path . exists ( self . dirname ) : \n delete_repository ( self . repo ) \n class BasicRepositories ( EmptyRepositoryTest ) : \n def testRepositoryInit ( self ) : \n self . repo . init ( ) \n self . assertTrue ( self . repo . isValid ( ) ) \n self . failUnless ( os . path . isdir ( self . dirname ) ) \n self . failUnless ( os . path . isdir ( os . path . join ( self . dirname , \"<STR_LIT>\" ) ) ) \n def testConfiguration ( self ) : \n self . repo . init ( ) \n self . repo . config . setParameter ( '<STR_LIT>' , <NUM_LIT:2> ) \n self . assertEquals ( self . repo . config . getParameter ( '<STR_LIT>' ) , '<STR_LIT:2>' ) \n def testRepositoryInitWhenExists ( self ) : \n os . mkdir ( self . dirname ) \n self . repo . init ( ) \n self . failUnless ( os . path . isdir ( self . dirname ) ) \n self . failUnless ( os . path . isdir ( os . path . join ( self . dirname , \"<STR_LIT>\" ) ) ) \n class ModifiedRepositoryTest ( EmptyRepositoryTest ) : \n <mask0> = \"<STR_LIT>\" \n def setUp ( self ) : \n super ( ModifiedRepositoryTest , self ) . setUp ( ) \n self . repo . init ( ) \n with open ( os . path . join ( self . repo . path , self . FILENAME ) , \"<STR_LIT:wb>\" ) as f : \n print >> f , \"<STR_LIT>\" \n self . assertFalse ( self . repo . isWorkingDirectoryClean ( ) ) \n class ModifiedRepositories ( ModifiedRepositoryTest ) : \n def testStatus ( self ) : \n untracked = self . repo . getUntrackedFiles ( ) \n self . assertEquals ( untracked , [ self . FILENAME ] ) \n def testAdding ( self ) : \n untracked_files = self . repo . getUntrackedFiles ( ) \n for u in untracked_files : \n self . repo . add ( u ) \n self . assertEquals ( self . repo . getStagedFiles ( ) , untracked_files ) \n self . assertFalse ( self . repo . isWorkingDirectoryClean ( ) ) \n def testCommitting ( self ) : \n self . repo . addAll ( ) \n self . assertNotEquals ( self . repo . getStagedFiles ( ) , [ ] ) \n c = self . repo . commit ( message = \"<STR_LIT>\" ) \n self . assertTrue ( self . repo . isWorkingDirectoryClean ( ) ) \n self . assertEquals ( self . repo . getStagedFiles ( ) , [ ] ) \n class CleaningUntrackedFiles ( ModifiedRepositoryTest ) : \n def _clean ( self ) : \n self . repo . cleanUntrackedFiles ( ) \n self . failIf ( self . repo . getUntrackedFiles ( ) ) \n def testCleaningUpUntrackedFiles ( self ) : \n with open ( os . path . join ( self . repo . path , \"<STR_LIT>\" ) , \"<STR_LIT:wb>\" ) as f : \n print >> f , \"<STR_LIT:data>\" \n self . failUnless ( self . repo . getUntrackedFiles ( ) ) \n self . _clean ( ) \n dirpath = os . path . join ( self . repo . path , \"<STR_LIT>\" ) \n os . mkdir ( dirpath ) \n self . _clean ( ) \n self . failIf ( os . path . exists ( dirpath ) ) \n class TestAPI ( ModifiedRepositoryTest ) : \n def test_find_repository ( self ) : \n prev_path = os . path . realpath ( \"<STR_LIT:.>\" ) \n subpath = os . path . join ( self . repo . path , \"<STR_LIT:a>\" , \"<STR_LIT:b>\" , \"<STR_LIT:c>\" ) \n os . makedirs ( subpath ) \n os . chdir ( subpath ) \n try : \n repo = find_repository ( ) \n finally : \n os . chdir ( prev_path ) \n self . failUnless ( repo . path == self . repo . path ) \n if __name__ == '<STR_LIT:__main__>' : \n unittest . main ( ) \n", "gt": "FILENAME"}
{"input": "\n import logging \n from okcupyd . db import model , txn , with_txn \n <mask0> = logging . getLogger ( __name__ ) \n class UserAdapter ( object ) : \n def __init__ ( self , profile ) : \n self . profile = profile \n def build ( self , session ) : \n found = model . User . query_no_txn ( session , model . User . handle == \n self . profile . username ) \n if found : \n return found [ <NUM_LIT:0> ] \n else : \n return model . User ( okc_id = self . profile . id , \n handle = self . profile . username , \n age = self . profile . age , \n location = self . profile . location ) \n def get_no_txn ( self , session ) : \n return model . User . upsert_one_no_txn ( session , self . build ( session ) , \n id_key = '<STR_LIT>' ) \n get = with_txn ( get_no_txn ) \n class ThreadAdapter ( object ) : \n def __init__ ( self , thread ) : \n self . thread = thread \n def _get_thread ( self , session ) : \n initiator = UserAdapter ( self . thread . initiator ) . get_no_txn ( session ) \n respondent = UserAdapter ( self . thread . respondent ) . get_no_txn ( session ) \n message_thread = model . MessageThread ( okc_id = self . thread . id , \n initiator = initiator , \n respondent = respondent ) \n return model . MessageThread . upsert_one_no_txn ( session , message_thread , \n id_key = '<STR_LIT>' ) \n def _add_messages ( self , thread_model ) : \n existing_message_ids = set ( [ m . okc_id for m in thread_model . messages ] ) \n new_messages = [ message for message in self . thread . messages \n if message . id not in existing_message_ids ] \n new_message_models = [ ] \n for new_message in new_messages : \n from_initiator = thread_model . initiator . handle . lower ( ) == new_message . sender . username . lower ( ) \n sender , recipient = ( thread_model . initiator , \n thread_model . respondent ) if from_initiator else ( thread_model . respondent , \n thread_model . initiator ) \n new_message_model = model . Message ( okc_id = new_message . id , \n text = new_message . content , \n sender = sender , \n recipient = recipient , \n time_sent = new_message . time_sent ) \n new_message_models . append ( new_message_model ) \n thread_model . messages . append ( new_message_model ) \n return new_message_models \n def add_messages ( self ) : \n with txn ( ) as session : \n thread_model = model . MessageThread . find_no_txn ( session , \n self . thread . id , \n id_key = '<STR_LIT>' ) \n return self . _add_messages ( thread_model ) \n def get_thread ( self ) : \n with txn ( ) as session : \n thread_model = self . _get_thread ( session ) \n return thread_model , self . _add_messages ( thread_model ) \n", "gt": "log"}
{"input": "\n import logging \n from invoke import task \n import IPython \n from okcupyd import db \n from okcupyd import util \n from okcupyd . db import mailbox , model \n from okcupyd . user import User \n <mask0> = logging . getLogger ( __name__ ) \n @ task ( default = True ) \n def session ( ) : \n with db . txn ( ) as session : \n IPython . embed ( ) \n @ task \n def reset ( ) : \n util . enable_logger ( __name__ ) \n log . info ( db . Base . metadata . bind ) \n db . Base . metadata . drop_all ( ) \n db . Base . metadata . create_all ( ) \n @ task \n def sync ( ) : \n user = User ( ) \n mailbox . Sync ( user ) . all ( ) \n log . info ( model . Message . query ( model . User . okc_id == user . profile . id ) ) \n @ task \n def make ( ) : \n user = User ( ) \n user_model = model . User . from_profile ( user . profile ) \n user_model . upsert_model ( id_key = '<STR_LIT>' ) \n okcupyd_user = model . OKCupydUser ( user_id = user_model . id ) \n okcupyd_user . upsert_model ( id_key = '<STR_LIT>' ) \n return okcupyd_user \n", "gt": "log"}
{"input": "\n from . import util \n from okcupyd import User , photo \n @ util . use_cassette ( path = '<STR_LIT>' , \n match_on = util . match_on_no_body ) \n def test_photo_upload ( ) : \n <mask0> = photo . PhotoUploader ( ) \n upload_response_dict = uploader . upload_and_confirm ( '<STR_LIT>' ) \n assert int ( upload_response_dict [ '<STR_LIT:id>' ] ) > <NUM_LIT:0> \n @ util . use_cassette ( path = '<STR_LIT>' , match_on = util . match_on_no_body ) \n def test_photo_delete ( ) : \n user = User ( ) \n response_dict = user . photo . upload_and_confirm ( user . quickmatch ( ) . photo_infos [ <NUM_LIT:0> ] ) \n before_delete_photos = user . profile . photo_infos \n user . photo . delete ( response_dict [ '<STR_LIT:id>' ] ) \n user . profile . refresh ( ) \n assert len ( before_delete_photos ) - <NUM_LIT:1> == len ( user . profile . photo_infos ) \n def test_make_photo_uri_from_https_link ( ) : \n photo_info = photo . Info . from_cdn_uri ( \n '<STR_LIT>' \n '<STR_LIT>' \n '<STR_LIT>' \n ) \n assert photo_info . id == <NUM_LIT> \n assert photo_info . thumb_nail_top == <NUM_LIT> \n @ util . use_cassette \n def test_photo_info_upload ( vcr_live_sleep ) : \n user = User ( ) \n response = user . photo . upload_and_confirm ( user . quickmatch ( ) . photo_infos [ <NUM_LIT:0> ] ) \n vcr_live_sleep ( <NUM_LIT:2> ) \n assert int ( response [ '<STR_LIT:id>' ] ) in [ pi . id for pi in user . profile . photo_infos ] \n", "gt": "uploader"}
{"input": "\n import theano \n import theano . tensor as T \n from theano . sandbox . rng_mrg import MRG_RandomStreams \n from theano . tensor . nnet . conv import conv2d \n from theano . tensor . signal . downsample import max_pool_2d \n from theano . tensor . shared_randomstreams import RandomStreams \n import numpy as np \n from toolbox import * \n from modelbase import * \n class LM_gru ( ModelLMBase ) : \n def __init__ ( self , data , hp ) : \n super ( LM_gru , self ) . __init__ ( self . __class__ . __name__ , data , hp ) \n self . n_h = <NUM_LIT> \n self . dropout = <<mask0>:0.5> \n self . params = Parameters ( ) \n self . hiddenstates = Parameters ( ) \n n_tokens = self . data [ '<STR_LIT>' ] \n n_h = self . n_h \n scale = hp . init_scale \n gates = <NUM_LIT:3> \n with self . hiddenstates : \n b1_h = shared_zeros ( ( self . hp . batch_size , n_h ) ) \n b2_h = shared_zeros ( ( self . hp . batch_size , n_h ) ) \n if hp . load_model and os . path . isfile ( self . filename ) : \n self . params . load ( self . filename ) \n else : \n with self . params : \n W_emb = shared_normal ( ( n_tokens , n_h ) , scale = scale ) \n W1 = shared_normal ( ( n_h , n_h * gates ) , scale = scale * <NUM_LIT> ) \n V1 = shared_normal ( ( n_h , n_h * gates ) , scale = scale * <NUM_LIT> ) \n b1 = shared_zeros ( ( n_h * gates ) ) \n W2 = shared_normal ( ( n_h , n_h * gates ) , scale = scale * <NUM_LIT> ) \n V2 = shared_normal ( ( n_h , n_h * gates ) , scale = scale * <NUM_LIT> ) \n b2 = shared_zeros ( ( n_h * gates , ) ) \n def lstm ( X , h , c , W , U , b ) : \n g_on = T . dot ( X , W ) + T . dot ( h , U ) + b \n i_on = T . nnet . sigmoid ( g_on [ : , : n_h ] ) \n f_on = T . nnet . sigmoid ( g_on [ : , n_h : <NUM_LIT:2> * n_h ] ) \n o_on = T . nnet . sigmoid ( g_on [ : , <NUM_LIT:2> * n_h : <NUM_LIT:3> * n_h ] ) \n c = f_on * c + i_on * T . tanh ( g_on [ : , <NUM_LIT:3> * n_h : ] ) \n h = o_on * T . tanh ( c ) \n return h , c \n def gru ( X , h , W , U , b ) : \n z_t = T . nnet . sigmoid ( T . dot ( X , W [ : , : n_h ] ) + T . dot ( h , U [ : , : n_h ] ) + b [ : n_h ] ) \n r_t = T . nnet . sigmoid ( T . dot ( X , W [ : , n_h : <NUM_LIT:2> * n_h ] ) + T . dot ( h , U [ : , n_h : <NUM_LIT:2> * n_h ] ) + b [ n_h : <NUM_LIT:2> * n_h ] ) \n h_t = T . tanh ( T . dot ( X , W [ : , <NUM_LIT:2> * n_h : <NUM_LIT:3> * n_h ] ) + r_t * T . dot ( h , U [ : , <NUM_LIT:2> * n_h : <NUM_LIT:3> * n_h ] ) + b [ <NUM_LIT:2> * n_h : <NUM_LIT:3> * n_h ] ) \n return ( <NUM_LIT:1> - z_t ) * h + z_t * h_t \n def sgru ( X , h , W , U , b ) : \n z_t = T . tanh ( T . dot ( X , W [ : , : n_h ] ) + T . dot ( h , U [ : , : n_h ] ) + b [ : n_h ] ) \n h_t = T . tanh ( T . dot ( X , W [ : , <NUM_LIT:1> * n_h : <NUM_LIT:2> * n_h ] ) + T . dot ( h , U [ : , <NUM_LIT:1> * n_h : <NUM_LIT:2> * n_h ] ) + b [ <NUM_LIT:1> * n_h : <NUM_LIT:2> * n_h ] ) \n return z_t * h_t \n def model ( x , p , p_dropout ) : \n input_size = x . shape [ <NUM_LIT:1> ] \n h0 = p . W_emb [ x ] \n h0 = dropout ( h0 , p_dropout ) \n cost , h1 , h2 = [ <NUM_LIT:0.> , b1_h , b2_h ] \n for t in xrange ( <NUM_LIT:0> , self . hp . seq_size ) : \n if t >= self . hp . warmup_size : \n pyx = softmax ( T . dot ( dropout ( h2 , p_dropout ) , T . transpose ( p . W_emb ) ) ) \n cost += T . sum ( T . nnet . categorical_crossentropy ( pyx , theano_one_hot ( x [ t ] , n_tokens ) ) ) \n h1 = gru ( h0 [ t ] , h1 , p . W1 , p . V1 , p . b1 ) \n h2 = gru ( dropout ( h1 , p_dropout ) , h2 , p . W2 , p . V2 , p . b2 ) \n h_updates = [ ( b1_h , h1 ) , ( b2_h , h2 ) ] \n return cost , h_updates \n cost , h_updates = model ( self . X , self . params , self . dropout ) \n te_cost , te_h_updates = model ( self . X , self . params , <NUM_LIT:0.> ) \n self . compile ( cost , te_cost , h_updates , te_h_updates ) \n", "gt": "NUM_LIT"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import csv \n import sys \n def csvOutput ( queryResult , separator = '<STR_LIT:U+002C>' , quote = '<STR_LIT:\">' ) : \n \"\"\"<STR_LIT>\"\"\" \n <mask0> = csv . writer ( sys . stdout , delimiter = separator , quotechar = quote , \n quoting = csv . QUOTE_MINIMAL ) \n for line in queryResult : \n csvWriter . writerow ( line ) \n", "gt": "csvWriter"}
{"input": "\n import sys , os , stat \n import pythoncom \n from win32com . shell import shell , shellcon \n import commctrl \n import winerror \n from win32com . server . util import wrap \n from pywintypes import IID \n <mask0> = [ \"<STR_LIT>\" ] \n IColumnProvider_Methods = IPersist_Methods + [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n class ColumnProvider : \n _reg_progid_ = \"<STR_LIT>\" \n _reg_desc_ = \"<STR_LIT>\" \n _reg_clsid_ = IID ( \"<STR_LIT>\" ) \n _com_interfaces_ = [ pythoncom . IID_IPersist , \n shell . IID_IColumnProvider , \n ] \n _public_methods_ = IColumnProvider_Methods \n def GetClassID ( self ) : \n return self . _reg_clsid_ \n def Initialize ( self , colInit ) : \n flags , reserved , name = colInit \n print \"<STR_LIT>\" , name \n def GetColumnInfo ( self , index ) : \n if index in [ <NUM_LIT:0> , <NUM_LIT:1> ] : \n if index == <NUM_LIT:0> : \n ext = \"<STR_LIT>\" \n else : \n ext = \"<STR_LIT>\" \n title = ext + \"<STR_LIT>\" \n description = \"<STR_LIT>\" % ext \n col_id = ( self . _reg_clsid_ , \n index ) \n col_info = ( \n col_id , \n pythoncom . VT_I4 , \n commctrl . LVCFMT_RIGHT , \n <NUM_LIT:20> , \n shellcon . SHCOLSTATE_TYPE_INT | shellcon . SHCOLSTATE_SECONDARYUI , \n title , \n description ) \n return col_info \n return None \n def GetItemData ( self , colid , colData ) : \n fmt_id , pid = colid \n fmt_id == self . _reg_clsid_ \n flags , attr , reserved , ext , name = colData \n if ext . lower ( ) not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : \n return None \n if pid == <NUM_LIT:0> : \n ext = \"<STR_LIT>\" \n else : \n ext = \"<STR_LIT>\" \n check_file = os . path . splitext ( name ) [ <NUM_LIT:0> ] + ext \n try : \n st = os . stat ( check_file ) \n return st [ stat . ST_SIZE ] \n except OSError : \n return None \n def DllRegisterServer ( ) : \n import _winreg \n key = _winreg . CreateKey ( _winreg . HKEY_CLASSES_ROOT , \n \"<STR_LIT>\" + str ( ColumnProvider . _reg_clsid_ ) ) \n _winreg . SetValueEx ( key , None , <NUM_LIT:0> , _winreg . REG_SZ , ColumnProvider . _reg_desc_ ) \n print ColumnProvider . _reg_desc_ , \"<STR_LIT>\" \n def DllUnregisterServer ( ) : \n import _winreg \n try : \n key = _winreg . DeleteKey ( _winreg . HKEY_CLASSES_ROOT , \n \"<STR_LIT>\" + str ( ColumnProvider . _reg_clsid_ ) ) \n except WindowsError , details : \n import errno \n if details . errno != errno . ENOENT : \n raise \n print ColumnProvider . _reg_desc_ , \"<STR_LIT>\" \n if __name__ == '<STR_LIT:__main__>' : \n from win32com . server import register \n register . UseCommandLine ( ColumnProvider , \n finalize_register = DllRegisterServer , \n finalize_unregister = DllUnregisterServer ) \n", "gt": "IPersist_Methods"}
{"input": "\n def __load ( ) : \n import imp , os , sys \n try : \n <mask0> = os . path . dirname ( __loader__ . archive ) \n except NameError : \n dirname = sys . prefix \n path = os . path . join ( dirname , '<STR_LIT>' ) \n mod = imp . load_dynamic ( __name__ , path ) \n __load ( ) \n del __load \n", "gt": "dirname"}
{"input": "\n import logging \n class LoggerFactory ( object ) : \n <mask0> = False \n def __init__ ( self , level = logging . DEBUG ) : \n if LoggerFactory . _isSetup is False : \n logger = logging . getLogger ( \"<STR_LIT>\" ) \n logger . setLevel ( level ) \n formatter = logging . Formatter ( '<STR_LIT>' ) \n ch = logging . StreamHandler ( ) \n ch . setLevel ( level ) \n ch . setFormatter ( formatter ) \n logger . addHandler ( ch ) \n LoggerFactory . _isSetup = True \n def getLogger ( self , name , level = logging . DEBUG ) : \n logger = logging . getLogger ( \"<STR_LIT>\" % name ) \n logger . setLevel ( level ) \n return logger \n", "gt": "_isSetup"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n <mask0> = [ \n '<STR_LIT>' \n ] \n __version__ = '<STR_LIT>' \n", "gt": "__all__"}
{"input": "\n from myapp import utils \n <mask0> = utils . getFinalName ( __name__ ) \n module = utils . getModule ( __name__ , subdomain = module_name ) \n import views \n import views . morepages \n", "gt": "module_name"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import sys \n import os \n import subprocess \n def perform_testing ( config ) : \n <mask0> = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } \n print \"<STR_LIT>\" \n print canwrite ( config [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) , \"<STR_LIT>\" \n print \"<STR_LIT>\" \n print \"<STR_LIT>\" \n for req in requirements : \n print checkcommand ( requirements [ req ] ) , req \n sys . exit ( <NUM_LIT:0> ) \n def canwrite ( path ) : \n try : \n ret = booltostatus ( os . access ( path , os . W_OK | os . X_OK ) ) \n except : \n ret = False \n finally : \n return ret \n def booltostatus ( inbool ) : \n if inbool : \n return \"<STR_LIT>\" \n else : \n return \"<STR_LIT>\" \n def checkcommand ( com ) : \n proc = subprocess . Popen ( \n [ \n '<STR_LIT>' , \n str ( com ) \n ] , \n stderr = subprocess . PIPE , \n stdout = subprocess . PIPE \n ) \n return booltostatus ( len ( proc . stdout . read ( ) ) > <NUM_LIT:0> ) \n", "gt": "requirements"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n from collections import namedtuple \n from uuid import uuid4 \n from django . http import HttpResponse \n from django . contrib . gis . db . models . query import GeoQuerySet \n from django . contrib . gis . db . models import GeometryField \n from django import forms as f \n import json \n from django . shortcuts import render_to_response \n from ga_ows . views import common \n from ga_ows . utils import MultipleValueField , BBoxField , CaseInsensitiveDict \n from lxml import etree \n from ga_ows . views . common import RequestForm , CommonParameters , GetCapabilitiesMixin \n from osgeo import ogr \n from django . conf import settings \n from tempfile import gettempdir \n from django . db import connections \n import re \n from lxml import etree \n import os \n class InputParameters ( RequestForm ) : \n \"\"\"<STR_LIT:U+0020>\"\"\" \n <mask0> = f . CharField ( ) \n input_format = f . CharField ( ) \n srs_format = f . CharField ( required = False ) \n @ classmethod \n def from_request ( cls , request ) : \n request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' , '<STR_LIT>' ) \n request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' , \"<STR_LIT>\" ) \n class PresentationParameters ( RequestForm ) : \n count = f . IntegerField ( ) \n start_index = f . IntegerField ( ) \n max_features = f . IntegerField ( ) \n output_format = f . CharField ( ) \n @ classmethod \n def from_request ( cls , request ) : \n request [ '<STR_LIT:count>' ] = int ( request . get ( '<STR_LIT:count>' , '<STR_LIT:1>' ) ) \n request [ '<STR_LIT>' ] = int ( request . get ( '<STR_LIT>' , '<STR_LIT:1>' ) ) \n request [ '<STR_LIT>' ] = int ( request . get ( '<STR_LIT>' , '<STR_LIT:1>' ) ) \n request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' , \"<STR_LIT>\" ) \n class AdHocQueryParameters ( RequestForm ) : \n type_names = MultipleValueField ( ) \n aliases = MultipleValueField ( required = False ) \n filter = f . CharField ( required = False ) \n filter_language = f . CharField ( required = False ) \n resource_id = f . CharField ( required = False ) \n bbox = BBoxField ( ) \n sort_by = f . CharField ( required = False ) \n @ classmethod \n def from_request ( cls , request ) : \n request [ '<STR_LIT>' ] = request . getlist ( '<STR_LIT>' ) \n request [ '<STR_LIT>' ] = request . getlist ( '<STR_LIT>' ) \n request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' ) \n request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' ) \n request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' ) \n request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' ) \n request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' ) \n class StoredQueryParameters ( RequestForm ) : \n stored_query_id = f . CharField ( required = False ) \n @ classmethod \n def from_request ( cls , request ) : \n request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' ) \n class GetFeatureByIdParameters ( RequestForm ) : \n feature_id = f . CharField ( ) \n @ classmethod \n def from_request ( cls , request ) : \n request [ '<STR_LIT>' ] = request . get ( '<STR_LIT:id>' ) \n class ResolveParameters ( RequestForm ) : \n resolve = f . CharField ( required = False ) \n resolve_depth = f . IntegerField ( ) \n resolve_timeout = f . FloatField ( ) \n @ classmethod \n def from_request ( cls , request ) : \n request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' ) \n request [ '<STR_LIT>' ] = int ( request . get ( '<STR_LIT>' , '<STR_LIT:0>' ) ) \n request [ '<STR_LIT>' ] = float ( request . get ( '<STR_LIT>' , '<STR_LIT:0>' ) ) \n class CannotLockAllFeatures ( common . OWSException ) : \n \"\"\"<STR_LIT>\"\"\" \n class DuplicateStoredQueryIdValue ( common . OWSException ) : \n \"\"\"<STR_LIT>\"\"\" \n class DuplicateStoredQueryParameterName ( common . OWSException ) : \n \"\"\"<STR_LIT>\"\"\" \n class FeaturesNotLocked ( common . OWSException ) : \n \"\"\"<STR_LIT>\"\"\" \n class InvalidLockId ( common . OWSException ) : \n \"\"\"<STR_LIT>\"\"\" \n class InvalidValue ( common . OWSException ) : \n \"\"\"<STR_LIT>\"\"\" \n class LockHasExpired ( common . OWSException ) : \n \"\"\"<STR_LIT>\"\"\" \n class OperationParsingFailed ( common . OWSException ) : \n \"\"\"<STR_LIT>\"\"\" \n class OperationProcessingFailed ( common . OWSException ) : \n \"\"\"<STR_LIT>\"\"\" \n class ResponseCacheExpired ( common . OWSException ) : \n \"\"\"<STR_LIT>\"\"\" \n class OperationNotSupported ( common . OWSException ) : \n \"\"\"<STR_LIT>\"\"\" \n FeatureDescription = namedtuple ( '<STR_LIT>' , ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT:name>' , '<STR_LIT:title>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) ) \n StoredQueryParameter = namedtuple ( \"<STR_LIT>\" , ( '<STR_LIT:type>' , '<STR_LIT:name>' , '<STR_LIT:title>' , '<STR_LIT>' , '<STR_LIT>' ) ) \n StoredQueryExpression = namedtuple ( \"<STR_LIT>\" , ( '<STR_LIT:text>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) ) \n StoredQueryDescription = namedtuple ( \"<STR_LIT>\" , ( '<STR_LIT:name>' , '<STR_LIT>' , '<STR_LIT:title>' , '<STR_LIT>' ) ) \n class WFSAdapter ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def get_feature_descriptions ( self , request , * types ) : \n raise OperationNotSupported . at ( '<STR_LIT>' , '<STR_LIT>' ) \n def list_stored_queries ( self , request ) : \n \"\"\"<STR_LIT>\"\"\" \n queries = dict ( [ ( q [ <NUM_LIT:3> : ] , [ ] ) for q in filter ( lambda x : x . startswith ( \"<STR_LIT>\" ) , \n reduce ( \n list . __add__ , \n [ c . __dict__ . keys ( ) for c in self . __class__ . mro ( ) ] \n ) \n ) ] ) \n return queries \n def get_features ( self , request , parms ) : \n raise OperationNotSupported . at ( '<STR_LIT>' , \"<STR_LIT>\" ) \n def supports_feature_versioning ( self ) : \n return False \n class GeoDjangoWFSAdapter ( WFSAdapter ) : \n def __init__ ( self , models ) : \n self . models = { } \n self . srids = { } \n self . geometries = { } \n for model in models : \n self . models [ model . _meta . app_label + \"<STR_LIT::>\" + model . _meta . object_name ] = model \n for field in model . _meta . fields : \n if isinstance ( field , GeometryField ) : \n self . geometries [ model . _meta . app_label + \"<STR_LIT::>\" + model . _meta . object_name ] = field \n self . srids [ model . _meta . app_label + \"<STR_LIT::>\" + model . _meta . object_name ] = field . srid \n def list_stored_queries ( self , request ) : \n sq = super ( GeoDjangoWFSAdapter , self ) . list_stored_queries ( request ) \n fts = list ( self . models . keys ( ) ) \n for k in sq . keys ( ) : \n sq [ k ] = StoredQueryDescription ( name = k , feature_types = fts , title = k , parameters = [ ] ) \n return sq \n def get_feature_descriptions ( self , request , * types ) : \n namespace = request . build_absolute_uri ( ) . split ( '<STR_LIT:?>' ) [ <NUM_LIT:0> ] + \"<STR_LIT>\" \n for model in self . models . values ( ) : \n if model . objects . count ( ) > <NUM_LIT:0> : \n extent = model . objects . extent ( ) \n else : \n extent = ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> ) \n yield FeatureDescription ( \n ns = namespace , \n ns_name = model . _meta . app_label , \n name = model . _meta . object_name , \n abstract = model . __doc__ , \n title = model . _meta . verbose_name , \n keywords = [ ] , \n srs = self . srids [ model . _meta . app_label + \"<STR_LIT::>\" + model . _meta . object_name ] , \n bbox = extent , \n schema = namespace \n ) \n def get_features ( self , request , parms ) : \n if parms . cleaned_data [ '<STR_LIT>' ] : \n squid = \"<STR_LIT>\" + parms . cleaned_data [ '<STR_LIT>' ] \n try : \n return self . __getattribute__ ( squid ) ( request , parms ) \n except AttributeError : \n raise OperationNotSupported . at ( '<STR_LIT>' , '<STR_LIT>' . format ( squid = squid ) ) \n else : \n return self . AdHocQuery ( request , parms ) \n def AdHocQuery ( self , request , parms ) : \n type_names = parms . cleaned_data [ '<STR_LIT>' ] \n flt = parms . cleaned_data [ '<STR_LIT>' ] \n flt_lang = parms . cleaned_data [ '<STR_LIT>' ] \n bbox = parms . cleaned_data [ '<STR_LIT>' ] \n sort_by = parms . cleaned_data [ '<STR_LIT>' ] \n count = parms . cleaned_data [ '<STR_LIT:count>' ] \n if not count : \n count = parms . cleaned_data [ '<STR_LIT>' ] \n start_index = parms . cleaned_data [ '<STR_LIT>' ] \n srs_name = parms . cleaned_data [ '<STR_LIT>' ] \n srs_format = parms . cleaned_data [ '<STR_LIT>' ] \n model = self . models [ type_names [ <NUM_LIT:0> ] ] \n geometry_field = self . geometries [ type_names [ <NUM_LIT:0> ] ] \n query_set = model . objects . all ( ) \n if bbox : \n mnx , mny , mxx , mxy = bbox \n query_set . filter ( ** { geometry_field . name + \"<STR_LIT>\" : \n \"<STR_LIT>\" . format ( \n mnx = mnx , \n mny = mny , \n mxx = mxx , \n mxy = mxy ) \n } ) \n if flt : \n flt = json . loads ( flt ) \n query_set = query_set . filter ( ** flt ) \n if sort_by and '<STR_LIT:U+002C>' in sort_by : \n sort_by = sort_by . split ( '<STR_LIT:U+002C>' ) \n query_set = query_set . order_by ( * sort_by ) \n elif sort_by : \n query_set = query_set . order_by ( sort_by ) \n if start_index and count : \n query_set = query_set [ start_index : start_index + count ] \n elif start_index : \n query_set = query_set [ start_index : ] \n elif count : \n query_set = query_set [ : count ] \n if srs_name : \n if ( not srs_format or srs_format == '<STR_LIT>' ) and srs_name != geometry_field . srid : \n if srs_name . lower ( ) . startswith ( '<STR_LIT>' ) : \n srs_name = srs_name [ <NUM_LIT:5> : ] \n query_set . transform ( int ( srs_name ) ) \n return query_set \n def SQ_GetFeatureById ( self , request , parms ) : \n my_parms = GetFeatureByIdParameters . create ( request . REQUEST ) \n typename , pk = my_parms . cleaned_data [ '<STR_LIT>' ] . split ( '<STR_LIT:.>' ) \n return self . models [ typename ] . objects . filter ( pk = int ( pk ) ) \n class WFSBase ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n adapter = None \n class DescribeFeatureTypeMixin ( WFSBase ) : \n \"\"\"<STR_LIT>\"\"\" \n class Parameters ( \n CommonParameters \n ) : \n type_names = MultipleValueField ( ) \n output_format = f . CharField ( ) \n @ classmethod \n def from_request ( cls , request ) : \n request [ '<STR_LIT>' ] = request . getlist ( '<STR_LIT>' ) + request . getlist ( '<STR_LIT>' ) \n request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' , \"<STR_LIT>\" ) \n def _parse_xml_DescribeFeatureType ( self , request ) : \n \"\"\"<STR_LIT>\"\"\" \n def add_ns ( it , ns ) : \n x = it . split ( '<STR_LIT::>' ) \n if len ( x ) > <NUM_LIT:1> : \n return ns [ x [ <NUM_LIT:0> ] ] , x [ <NUM_LIT:1> ] \n else : \n return '<STR_LIT>' , x \n root = etree . fromstring ( request ) \n xmlns = root . get ( '<STR_LIT>' ) \n output_format = root . get ( '<STR_LIT>' , '<STR_LIT>' ) \n if xmlns is not None : \n xmlns = \"<STR_LIT:{>\" + xmlns + \"<STR_LIT:}>\" \n else : \n xmlns = \"<STR_LIT>\" \n namespaces = { } \n for name , value in root . attrib . items ( ) : \n if name . startswith ( xmlns ) : \n namespaces [ value ] = name [ len ( xmlns ) : ] \n type_names = root . get ( '<STR_LIT>' ) \n if type_names is not None : \n type_names = [ add_ns ( n , namespaces ) for n in type_names . split ( '<STR_LIT:U+002C>' ) ] \n else : \n type_names = [ ] \n for elt in root : \n if elt . tag . endswith ( \"<STR_LIT>\" ) : \n namespace , name = elt . text . split ( \"<STR_LIT::>\" ) \n namespace = namespaces [ namespace ] \n type_names . append ( ( namespace , name ) ) \n if not len ( type_names ) : \n type_names = '<STR_LIT:all>' \n return DescribeFeatureTypeMixin . Parameters . create ( CaseInsensitiveDict ( { \"<STR_LIT>\" : type_names , \"<STR_LIT>\" : output_format } ) ) \n def _response_xml_DescribeFeatureType ( self , response ) : \n return render_to_response ( \"<STR_LIT>\" , { \"<STR_LIT>\" : list ( response ) } ) \n def _response_json_DescribeFeatureType ( self , response , callback = None ) : \n rsp = [ ] \n for feature_type in response : \n rsp . append ( { \n \"<STR_LIT>\" : feature_type . schema , \n \"<STR_LIT:name>\" : feature_type . name , \n \"<STR_LIT>\" : feature_type . abstract , \n \"<STR_LIT:title>\" : feature_type . title , \n \"<STR_LIT>\" : feature_type . ns_name \n } ) \n if callback is not None : \n return HttpResponse ( callback + \"<STR_LIT:(>\" + json . dumps ( rsp ) + \"<STR_LIT:)>\" , mimetype = '<STR_LIT>' ) \n else : \n return HttpResponse ( json . dumps ( rsp ) , mimetype = '<STR_LIT:application/json>' ) \n def DescribeFeatureType ( self , request , kwargs ) : \n \"\"\"<STR_LIT>\"\"\" \n if '<STR_LIT>' in kwargs : \n parms = self . _parse_xml_DescribeFeatureType ( kwargs [ '<STR_LIT>' ] ) \n else : \n parms = DescribeFeatureTypeMixin . Parameters . create ( kwargs ) \n response = self . adapter . get_feature_descriptions ( request , * parms . cleaned_data [ '<STR_LIT>' ] ) \n if parms . cleaned_data [ '<STR_LIT>' ] . endswith ( '<STR_LIT>' ) : \n if '<STR_LIT>' in kwargs : \n return self . _response_json_DescribeFeatureType ( response , callback = kwargs [ '<STR_LIT>' ] ) \n elif '<STR_LIT>' in kwargs : \n return self . _response_json_DescribeFeatureType ( response , callback = kwargs [ '<STR_LIT>' ] ) \n else : \n return self . _response_json_DescribeFeatureType ( response ) \n else : \n return self . _response_xml_DescribeFeatureType ( response ) \n class GetFeatureMixin ( WFSBase ) : \n \"\"\"<STR_LIT>\"\"\" \n class Parameters ( \n CommonParameters , \n InputParameters , \n PresentationParameters , \n AdHocQueryParameters , \n StoredQueryParameters \n ) : \n pass \n def _parse_xml_GetFeature ( self , request ) : \n \"\"\"<STR_LIT:U+0020>\"\"\" \n raise OperationNotSupported . at ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n def GetFeature ( self , request , kwargs ) : \n \"\"\"<STR_LIT:U+0020>\"\"\" \n mimetypes = { \n '<STR_LIT>' : '<STR_LIT:application/json>' \n } \n if '<STR_LIT>' in kwargs : \n parms = self . _parse_xml_GetFeature ( kwargs [ '<STR_LIT>' ] ) \n else : \n parms = GetFeatureMixin . Parameters . create ( kwargs ) \n response = self . adapter . get_features ( request , parms ) \n if isinstance ( response , GeoQuerySet ) : \n layer = None \n db_params = settings . DATABASES [ response . db ] \n if db_params [ '<STR_LIT>' ] . endswith ( '<STR_LIT>' ) : \n from psycopg2 . extensions import adapt \n query , parameters = response . query . get_compiler ( response . db ) . as_sql ( ) \n parameters = tuple ( [ adapt ( p ) for p in parameters ] ) \n query = query % parameters \n drv = ogr . GetDriverByName ( \"<STR_LIT>\" ) \n connection_string = \"<STR_LIT>\" . format ( db = db_params [ '<STR_LIT>' ] ) \n if '<STR_LIT>' in db_params and db_params [ '<STR_LIT>' ] : \n connection_string += \"<STR_LIT>\" . format ( host = db_params [ '<STR_LIT>' ] ) \n if '<STR_LIT>' in db_params and db_params [ '<STR_LIT>' ] : \n connection_string += \"<STR_LIT>\" . format ( port = db_params [ '<STR_LIT>' ] ) \n if '<STR_LIT>' in db_params and db_params [ '<STR_LIT>' ] : \n connection_string += \"<STR_LIT>\" . format ( user = db_params [ '<STR_LIT>' ] ) \n if '<STR_LIT>' in db_params and db_params [ '<STR_LIT>' ] : \n connection_string += \"<STR_LIT>\" . format ( password = db_params [ '<STR_LIT>' ] ) \n conn = drv . Open ( connection_string ) \n layer = conn . ExecuteSQL ( query . encode ( '<STR_LIT:ascii>' ) ) \n elif db_params [ '<STR_LIT>' ] . endswith ( '<STR_LIT>' ) : \n from psycopg2 . extensions import adapt \n query , parameters = response . query . get_compiler ( response . db ) . as_sql ( ) \n parameters = tuple ( [ adapt ( p ) for p in parameters ] ) \n query = query % parameters \n drv = ogr . GetDriverByName ( \"<STR_LIT>\" ) \n conn = drv . Open ( db_params [ '<STR_LIT>' ] ) \n layer = conn . ExecuteSQL ( query ) \n else : \n layer = response . GetLayerByIndex ( <NUM_LIT:0> ) \n drivers = dict ( [ ( ogr . GetDriver ( drv ) . GetName ( ) , ogr . GetDriver ( drv ) ) for drv in range ( ogr . GetDriverCount ( ) ) if ogr . GetDriver ( drv ) . TestCapability ( ogr . ODrCCreateDataSource ) ] ) \n output_format = parms . cleaned_data [ '<STR_LIT>' ] . decode ( '<STR_LIT:ascii>' ) \n if '<STR_LIT>' in output_format or '<STR_LIT>' in output_format : \n tmpname = \"<STR_LIT>\" . format ( tmpdir = gettempdir ( ) , uuid = uuid4 ( ) , output_format = '<STR_LIT>' , sep = os . path . sep ) \n drv = ogr . GetDriverByName ( \"<STR_LIT>\" ) \n ds = drv . CreateDataSource ( tmpname ) \n l2 = ds . CopyLayer ( layer , '<STR_LIT>' ) \n l2 . SyncToDisk ( ) \n del ds \n responsef = open ( tmpname ) \n rdata = responsef . read ( ) \n responsef . close ( ) \n os . unlink ( tmpname ) \n return HttpResponse ( rdata , mimetype = output_format ) \n elif output_format in drivers : \n tmpname = \"<STR_LIT>\" . format ( tmpdir = gettempdir ( ) , uuid = uuid4 ( ) , output_format = output_format , sep = os . path . sep ) \n drv = drivers [ output_format ] \n ds = drv . CreateDataSource ( tmpname ) \n l2 = ds . CopyLayer ( layer , '<STR_LIT>' ) \n l2 . SyncToDisk ( ) \n del ds \n responsef = open ( tmpname ) \n rdata = responsef . read ( ) \n responsef . close ( ) \n os . unlink ( tmpname ) \n return HttpResponse ( rdata , mimetype = mimetypes . get ( output_format , '<STR_LIT>' ) ) \n else : \n raise OperationProcessingFailed . at ( '<STR_LIT>' , '<STR_LIT>' . format ( of = output_format , formats = drivers . keys ( ) ) ) \n class ListStoredQueriesMixin ( WFSBase ) : \n \"\"\"<STR_LIT>\"\"\" \n def ListStoredQueries ( self , request , kwargs ) : \n \"\"\"<STR_LIT:U+0020>\"\"\" \n queries = self . adapter . list_stored_queries ( request ) \n response = etree . Element ( \"<STR_LIT>\" ) \n for query , description in queries . items ( ) : \n sub = etree . SubElement ( response , \"<STR_LIT>\" ) \n etree . SubElement ( sub , \"<STR_LIT>\" ) . text = query \n for feature_type in description . feature_types : \n etree . SubElement ( sub , '<STR_LIT>' ) . text = feature_type \n return HttpResponse ( etree . tostring ( response , pretty_print = True ) , mimetype = '<STR_LIT>' ) \n class DescribeStoredQueriesMixin ( WFSBase ) : \n class Parameters ( CommonParameters ) : \n stored_query_id = MultipleValueField ( ) \n @ classmethod \n def from_request ( cls , request ) : \n request [ '<STR_LIT>' ] = request . getlist ( '<STR_LIT>' ) \n def DescribeStoredQueries ( self , request , kwargs ) : \n parms = DescribeStoredQueriesMixin . Parameters . create ( kwargs ) \n inspected_queries = parms . cleaned_data [ '<STR_LIT>' ] \n response = etree . Element ( '<STR_LIT>' ) \n for query , description in filter ( lambda ( x , y ) : x in inspected_queries , self . adapter . list_stored_queries ( request ) . items ( ) ) : \n desc = etree . SubElement ( response , \"<STR_LIT>\" ) \n etree . SubElement ( desc , '<STR_LIT>' ) . text = query \n for parameter in description . parameters : \n p = etree . SubElement ( desc , \"<STR_LIT>\" , attrib = { \"<STR_LIT:name>\" : parameter . name , \"<STR_LIT:type>\" : parameter . type } ) \n etree . SubElement ( p , '<STR_LIT>' ) . text = parameter . title \n etree . SubElement ( p , '<STR_LIT>' ) . text = parameter . abstractS \n if parameter . query_expression : \n etree . SubElement ( p , \"<STR_LIT>\" , attrib = { \n \"<STR_LIT>\" : parameter . query_expression . private == True , \n \"<STR_LIT>\" : parameter . query_expression . language , \n \"<STR_LIT>\" : '<STR_LIT:U+0020>' . join ( parameter . query_expression . return_feature_types ) \n } ) . text = parameter . query_expression . text \n return HttpResponse ( etree . tostring ( response , pretty_print = True ) , mimetype = '<STR_LIT>' ) \n class CreateStoredQuery ( WFSBase ) : \n def CreateStoredQuery ( self , request , kwargs ) : \n raise OperationNotSupported . at ( \"<STR_LIT>\" ) \n class DropStoredQuery ( WFSBase ) : \n def DropStoredQuery ( self , request , kwargs ) : \n raise OperationNotSupported . at ( \"<STR_LIT>\" ) \n class TransactionMixin ( WFSBase ) : \n def Transaction ( self , request , kwargs ) : \n \"\"\"<STR_LIT:U+0020>\"\"\" \n raise OperationNotSupported . at ( '<STR_LIT>' ) \n class GetFeatureWithLockMixin ( WFSBase ) : \n def GetFeatureWithLock ( self , request , kwargs ) : \n raise OperationNotSupported . at ( \"<STR_LIT>\" ) \n class LockFeatureMixin ( WFSBase ) : \n def LockFeature ( self , request , kwargs ) : \n raise OperationNotSupported . at ( '<STR_LIT>' ) \n class GetPropertyValueMixin ( WFSBase ) : \n class Parameters ( StoredQueryParameters , AdHocQueryParameters ) : \n value_reference = f . CharField ( ) \n resolve_path = f . CharField ( required = False ) \n def from_request ( cls , request ) : \n request [ '<STR_LIT>' ] = request [ '<STR_LIT>' ] \n request [ '<STR_LIT>' ] = request [ '<STR_LIT>' ] \n def GetPropertyValue ( self , request , kwargs ) : \n raise OperationNotSupported . at ( '<STR_LIT>' ) \n class WFS ( \n common . OWSView , \n GetCapabilitiesMixin , \n DescribeFeatureTypeMixin , \n DescribeStoredQueriesMixin , \n GetFeatureMixin , \n ListStoredQueriesMixin , \n GetPropertyValueMixin \n ) : \n \"\"\"<STR_LIT>\"\"\" \n adapter = None \n models = None \n title = None \n keywords = [ ] \n fees = None \n access_constraints = None \n provider_name = None \n addr_street = None \n addr_city = None \n addr_admin_area = None \n addr_postcode = None \n addr_country = None \n addr_email = None \n def __init__ ( self , ** kwargs ) : \n common . OWSView . __init__ ( self , ** kwargs ) \n if self . models : \n self . adapter = GeoDjangoWFSAdapter ( self . models ) \n def get_capabilities_response ( self , request , params ) : \n return render_to_response ( '<STR_LIT>' , { \n \"<STR_LIT:title>\" : self . title , \n \"<STR_LIT>\" : self . keywords , \n \"<STR_LIT>\" : self . fees , \n \"<STR_LIT>\" : self . access_constraints , \n \"<STR_LIT>\" : request . build_absolute_uri ( ) . split ( '<STR_LIT:?>' ) [ <NUM_LIT:0> ] , \n \"<STR_LIT>\" : [ ogr . GetDriver ( drv ) . GetName ( ) for drv in range ( ogr . GetDriverCount ( ) ) if ogr . GetDriver ( drv ) . TestCapability ( ogr . ODrCCreateDataSource ) ] , \n \"<STR_LIT>\" : self . addr_street , \n \"<STR_LIT>\" : self . addr_city , \n \"<STR_LIT>\" : self . addr_admin_area , \n \"<STR_LIT>\" : self . addr_postcode , \n \"<STR_LIT>\" : self . addr_country , \n \"<STR_LIT>\" : False , \n \"<STR_LIT>\" : False , \n '<STR_LIT>' : self . adapter . get_feature_descriptions ( request ) \n } ) \n class WFST ( WFS , TransactionMixin , GetFeatureWithLockMixin , LockFeatureMixin ) : \n \"\"\"<STR_LIT>\"\"\" \n def get_capabilities_response ( self , request , params ) : \n return render_to_response ( '<STR_LIT>' , { \n \"<STR_LIT:title>\" : self . title , \n \"<STR_LIT>\" : self . keywords , \n \"<STR_LIT>\" : self . fees , \n \"<STR_LIT>\" : self . access_constraints , \n \"<STR_LIT>\" : request . build_absolute_uri ( ) . split ( '<STR_LIT:?>' ) [ <NUM_LIT:0> ] , \n \"<STR_LIT>\" : [ ogr . GetDriver ( drv ) . GetName ( ) for drv in range ( ogr . GetDriverCount ( ) ) if ogr . GetDriver ( drv ) . TestCapability ( ogr . ODrCCreateDataSource ) ] , \n \"<STR_LIT>\" : self . addr_street , \n \"<STR_LIT>\" : self . addr_city , \n \"<STR_LIT>\" : self . addr_admin_area , \n \"<STR_LIT>\" : self . addr_postcode , \n \"<STR_LIT>\" : self . addr_country , \n \"<STR_LIT>\" : self . adapter . supports_feature_versioning ( ) , \n \"<STR_LIT>\" : True , \n '<STR_LIT>' : self . adapter . get_feature_descriptions ( request ) \n } ) \n", "gt": "srs_name"}
{"input": "\n from sondra . document . valuehandlers import DateTime , Geometry , Now \n from shapely . geometry import Point \n from datetime import datetime \n import rethinkdb as r \n import pytest \n from sondra . tests . api import * \n from sondra . auth import Auth \n <mask0> = ConcreteSuite ( ) \n api = SimpleApp ( s ) \n auth = Auth ( s ) \n AuthenticatedApp ( s ) \n AuthorizedApp ( s ) \n s . ensure_database_objects ( ) \n @ pytest . fixture ( scope = '<STR_LIT>' ) \n def simple_doc ( request ) : \n simple_doc = s [ '<STR_LIT>' ] [ '<STR_LIT>' ] . create ( { \n '<STR_LIT:name>' : \"<STR_LIT>\" , \n \"<STR_LIT:date>\" : datetime . now ( ) , \n \"<STR_LIT:value>\" : <NUM_LIT:0> \n } ) \n def teardown ( ) : \n simple_doc . delete ( ) \n request . addfinalizer ( teardown ) \n return simple_doc \n @ pytest . fixture ( scope = '<STR_LIT>' ) \n def fk_doc ( request , simple_doc ) : \n fk_doc = s [ '<STR_LIT>' ] [ '<STR_LIT>' ] . create ( { \n '<STR_LIT:name>' : \"<STR_LIT>\" , \n '<STR_LIT>' : simple_doc , \n '<STR_LIT>' : [ simple_doc ] \n } ) \n def teardown ( ) : \n fk_doc . delete ( ) \n request . addfinalizer ( teardown ) \n return fk_doc \n def test_foreignkey ( fk_doc , simple_doc ) : \n retr_doc = s [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n assert isinstance ( fk_doc . obj [ '<STR_LIT>' ] , str ) \n assert fk_doc . obj [ '<STR_LIT>' ] == simple_doc . url \n assert isinstance ( retr_doc . obj [ '<STR_LIT>' ] , str ) \n assert retr_doc . obj [ '<STR_LIT>' ] == simple_doc . url \n storage_repr = fk_doc . rql_repr ( ) \n assert storage_repr [ '<STR_LIT>' ] == simple_doc . id \n assert isinstance ( fk_doc [ '<STR_LIT>' ] , SimpleDocument ) \n", "gt": "s"}
{"input": "\n import os \n from PySide . QtGui import * \n from PySide . QtCore import * \n from ui_Event import Ui_Event \n '''<STR_LIT>''' \n class EventWindow ( QDialog , Ui_Event ) : \n def __init__ ( self , parent , eventId ) : \n super ( EventWindow , self ) . __init__ ( parent ) \n self . rent = parent \n self . data = parent . eventData [ eventId ] \n self . deckAssignment = [ ] \n self . setupUi ( self ) \n self . assignWidgets ( ) \n self . setWindowTitle ( unicode ( \"<STR_LIT>\" % eventId ) ) \n def savePressed ( self ) : \n self . data [ \"<STR_LIT>\" ] = self . notesText . toPlainText ( ) \n self . data [ \"<STR_LIT>\" ] = self . deckText . text ( ) \n self . data [ \"<STR_LIT>\" ] = self . placeText . text ( ) \n self . data [ \"<STR_LIT>\" ] = self . eventTypeText . text ( ) \n self . data [ \"<STR_LIT>\" ] = self . playersText . text ( ) \n self . data [ \"<STR_LIT>\" ] = self . formatText . text ( ) \n self . data [ \"<STR_LIT>\" ] = self . locationText . text ( ) \n self . data [ \"<STR_LIT>\" ] = self . dateText . text ( ) \n <mask0> = <NUM_LIT:0> \n for ourRound in self . deckAssignment : \n self . data [ \"<STR_LIT>\" ] [ self . deckAssignment [ ourCounter ] [ <NUM_LIT:0> ] ] [ <NUM_LIT:2> ] = self . deckAssignment [ ourCounter ] [ <NUM_LIT:1> ] \n ourCounter += <NUM_LIT:1> \n self . rent . updateGUI ( ) \n self . rent . messageBox ( \"<STR_LIT>\" ) \n def closePressed ( self ) : \n self . hide ( ) \n def roundSelected ( self , ourRound , ourColumn ) : \n ourIndex = int ( ourRound . text ( <NUM_LIT:0> ) ) - <NUM_LIT:1> \n deckName , ok = QInputDialog . getText ( self , \"<STR_LIT>\" , \n \"<STR_LIT>\" ) \n if ok and deckName : \n self . data [ \"<STR_LIT>\" ] [ ourIndex ] [ <NUM_LIT:3> ] . setData ( <NUM_LIT:3> , <NUM_LIT:0> , deckName ) \n self . deckAssignment . append ( [ ourIndex , deckName ] ) \n def assignWidgets ( self ) : \n self . saveChangesButton . clicked . connect ( self . savePressed ) \n self . closeButton . clicked . connect ( self . closePressed ) \n self . roundTree . itemDoubleClicked . connect ( self . roundSelected ) \n self . notesText . setPlainText ( self . data [ \"<STR_LIT>\" ] ) \n self . deckText . setText ( self . data [ \"<STR_LIT>\" ] ) \n self . placeText . setText ( self . data [ \"<STR_LIT>\" ] ) \n self . eventTypeText . setText ( self . data [ \"<STR_LIT>\" ] ) \n self . playersText . setText ( self . data [ \"<STR_LIT>\" ] ) \n self . formatText . setText ( self . data [ \"<STR_LIT>\" ] ) \n self . locationText . setText ( self . data [ \"<STR_LIT>\" ] ) \n self . dateText . setText ( self . data [ \"<STR_LIT>\" ] ) \n matchItem = TreeWidgetItem ( self . resultsTree ) \n matchItem . setText ( <NUM_LIT:0> , unicode ( self . data [ \"<STR_LIT>\" ] ) ) \n matchItem . setText ( <NUM_LIT:1> , unicode ( self . data [ \"<STR_LIT>\" ] ) ) \n matchItem . setText ( <NUM_LIT:2> , unicode ( self . data [ \"<STR_LIT>\" ] ) ) \n matchItem . setText ( <NUM_LIT:3> , unicode ( self . data [ \"<STR_LIT>\" ] ) ) \n self . resultsTree . addTopLevelItem ( matchItem ) \n for i in range ( <NUM_LIT:4> ) : \n self . resultsTree . resizeColumnToContents ( i ) \n roundCounter = <NUM_LIT:1> \n for opponent in self . data [ \"<STR_LIT>\" ] : \n roundItem = TreeWidgetItem ( self . roundTree ) \n roundItem . setText ( <NUM_LIT:0> , unicode ( roundCounter ) ) \n roundItem . setText ( <NUM_LIT:1> , unicode ( opponent [ <NUM_LIT:0> ] ) ) \n roundItem . setText ( <NUM_LIT:2> , unicode ( opponent [ <NUM_LIT:1> ] ) ) \n roundItem . setText ( <NUM_LIT:3> , unicode ( opponent [ <NUM_LIT:2> ] ) ) \n opponent [ <NUM_LIT:3> ] = roundItem \n self . roundTree . addTopLevelItem ( roundItem ) \n roundCounter += <NUM_LIT:1> \n for i in range ( <NUM_LIT:4> ) : \n self . roundTree . resizeColumnToContents ( i ) \n class TreeWidgetItem ( QTreeWidgetItem ) : \n def __init__ ( self , parent = None ) : \n QTreeWidgetItem . __init__ ( self , parent ) \n def __lt__ ( self , otherItem ) : \n column = self . treeWidget ( ) . sortColumn ( ) \n try : \n return float ( self . text ( column ) ) > float ( otherItem . text ( column ) ) \n except ValueError : \n return self . text ( column ) > otherItem . text ( column ) \n", "gt": "ourCounter"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import numpy as np \n from pylatex import Document , Section , Subsection , Math , Matrix , VectorName \n if __name__ == '<STR_LIT:__main__>' : \n <mask0> = np . array ( [ [ <NUM_LIT:100> , <NUM_LIT:10> , <NUM_LIT:20> ] ] ) . T \n doc = Document ( ) \n section = Section ( '<STR_LIT>' ) \n subsection = Subsection ( '<STR_LIT>' ) \n vec = Matrix ( a ) \n vec_name = VectorName ( '<STR_LIT:a>' ) \n math = Math ( data = [ vec_name , '<STR_LIT:=>' , vec ] ) \n subsection . append ( math ) \n section . append ( subsection ) \n subsection = Subsection ( '<STR_LIT>' ) \n M = np . matrix ( [ [ <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ] , \n [ <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1> ] , \n [ <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:2> ] ] ) \n matrix = Matrix ( M , mtype = '<STR_LIT:b>' ) \n math = Math ( data = [ '<STR_LIT>' , matrix ] ) \n subsection . append ( math ) \n section . append ( subsection ) \n subsection = Subsection ( '<STR_LIT>' ) \n math = Math ( data = [ '<STR_LIT:M>' , vec_name , '<STR_LIT:=>' , Matrix ( M * a ) ] ) \n subsection . append ( math ) \n section . append ( subsection ) \n doc . append ( section ) \n doc . generate_pdf ( '<STR_LIT>' ) \n", "gt": "a"}
{"input": "\n import quantities as pq \n from pylatex . quantities import _dimensionality_to_siunitx , Quantity \n def test_quantity ( ) : \n <mask0> = <NUM_LIT:1> * pq . m / pq . s \n q1 = Quantity ( v ) \n assert q1 . dumps ( ) == r'<STR_LIT>' \n q2 = Quantity ( v , format_cb = lambda x : str ( int ( x ) ) ) \n assert q2 . dumps ( ) == r'<STR_LIT>' \n q3 = Quantity ( v , options = { '<STR_LIT>' : '<STR_LIT:true>' } ) \n ref = r'<STR_LIT>' \n assert q3 . dumps ( ) == ref \n def test_quantity_float ( ) : \n q1 = Quantity ( <NUM_LIT> ) \n assert q1 . dumps ( ) == r'<STR_LIT>' \n def test_quantity_uncertain ( ) : \n t = pq . UncertainQuantity ( <NUM_LIT> , pq . second , <NUM_LIT:1.> ) \n q1 = Quantity ( t ) \n assert q1 . dumps ( ) == r'<STR_LIT>' \n def test_dimensionality_to_siunitx ( ) : \n assert _dimensionality_to_siunitx ( ( pq . volt / pq . kelvin ) . dimensionality ) == r'<STR_LIT>' \n if __name__ == '<STR_LIT:__main__>' : \n test_quantity ( ) \n test_dimensionality_to_siunitx ( ) \n", "gt": "v"}
{"input": "\n from supervisor . medusa import asyncore_25 as asyncore \n from supervisor . medusa import default_handler \n from supervisor . medusa import http_server \n from supervisor . medusa import put_handler \n from supervisor . medusa import auth_handler \n from supervisor . medusa import filesys \n <mask0> = { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } \n fs = filesys . os_filesystem ( '<STR_LIT>' ) \n dh = default_handler . default_handler ( fs ) \n ph = put_handler . put_handler ( fs , '<STR_LIT>' ) \n ah = auth_handler . auth_handler ( users , ph ) \n hs = http_server . http_server ( ip = '<STR_LIT>' , port = <NUM_LIT> ) \n hs . install_handler ( dh ) \n hs . install_handler ( ah ) \n asyncore . loop ( ) \n", "gt": "users"}
{"input": "\n import socket \n import string \n from supervisor . medusa import asyncore_25 as asyncore \n from supervisor . medusa import asynchat_25 as asynchat \n class test_client ( asynchat . async_chat ) : \n <mask0> = <NUM_LIT> \n ac_out_buffer_size = <NUM_LIT> \n total_in = <NUM_LIT:0> \n concurrent = <NUM_LIT:0> \n max_concurrent = <NUM_LIT:0> \n def __init__ ( self , addr , chain ) : \n asynchat . async_chat . __init__ ( self ) \n self . create_socket ( socket . AF_INET , socket . SOCK_STREAM ) \n self . set_terminator ( '<STR_LIT>' ) \n self . connect ( addr ) \n self . push ( chain ) \n def handle_connect ( self ) : \n test_client . concurrent = test_client . concurrent + <NUM_LIT:1> \n if ( test_client . concurrent > test_client . max_concurrent ) : \n test_client . max_concurrent = test_client . concurrent \n def handle_expt ( self ) : \n print '<STR_LIT>' \n self . close ( ) \n def close ( self ) : \n test_client . concurrent = test_client . concurrent - <NUM_LIT:1> \n asynchat . async_chat . close ( self ) \n def collect_incoming_data ( self , data ) : \n test_client . total_in = test_client . total_in + len ( data ) \n def found_terminator ( self ) : \n pass \n def log ( self , * args ) : \n pass \n import time \n class timer : \n def __init__ ( self ) : \n self . start = time . time ( ) \n def end ( self ) : \n return time . time ( ) - self . start \n def build_request_chain ( num , host , request_size ) : \n s = '<STR_LIT>' % ( request_size , host ) \n sl = [ s ] * ( num - <NUM_LIT:1> ) \n sl . append ( \n '<STR_LIT>' % ( \n request_size , host \n ) \n ) \n return string . join ( sl , '<STR_LIT>' ) \n if __name__ == '<STR_LIT:__main__>' : \n import string \n import sys \n if len ( sys . argv ) != <NUM_LIT:6> : \n print '<STR_LIT>' % sys . argv [ <NUM_LIT:0> ] \n else : \n host = sys . argv [ <NUM_LIT:1> ] \n ip = socket . gethostbyname ( host ) \n [ port , request_size , num_requests , num_conns ] = map ( \n string . atoi , sys . argv [ <NUM_LIT:2> : ] \n ) \n chain = build_request_chain ( num_requests , host , request_size ) \n t = timer ( ) \n for i in range ( num_conns ) : \n test_client ( ( host , port ) , chain ) \n asyncore . loop ( ) \n total_time = t . end ( ) \n total_bytes = test_client . total_in \n num_trans = num_requests * num_conns \n throughput = float ( total_bytes ) / total_time \n trans_per_sec = num_trans / total_time \n sys . stderr . write ( '<STR_LIT>' % total_time ) \n sys . stderr . write ( '<STR_LIT>' % num_trans ) \n sys . stderr . write ( '<STR_LIT>' % total_bytes ) \n sys . stderr . write ( '<STR_LIT>' % throughput ) \n sys . stderr . write ( '<STR_LIT>' % trans_per_sec ) \n sys . stderr . write ( '<STR_LIT>' % test_client . max_concurrent ) \n sys . stdout . write ( \n string . join ( \n map ( str , ( num_conns , num_requests , request_size , throughput , trans_per_sec ) ) , \n '<STR_LIT:U+002C>' \n ) + '<STR_LIT:\\n>' \n ) \n", "gt": "ac_in_buffer_size"}
{"input": "\n from os import * \n from os import _exit \n import os \n class FakeOS : \n def __init__ ( self ) : \n self . orig_uid = os . getuid ( ) \n self . orig_gid = os . getgid ( ) \n def setgroups ( * args ) : \n return \n def getuid ( ) : \n return <NUM_LIT:0> \n def setuid ( arg ) : \n self . uid = arg \n self . setuid_called = <<mask0>:1> \n def setgid ( arg ) : \n self . gid = arg \n self . setgid_called = <NUM_LIT:1> \n def clear ( ) : \n self . uid = orig_uid \n self . gid = orig_gid \n self . setuid_called = <NUM_LIT:0> \n self . setgid_called = <NUM_LIT:0> \n fake = FakeOS ( ) \n setgroups = fake . setgroups \n getuid = fake . getuid \n setuid = fake . setuid \n setgid = fake . setgid \n clear = fake . clear \n", "gt": "NUM_LIT"}
{"input": "\n import unittest \n from uuid import uuid4 \n from time import time , sleep \n from toto . tasks import TaskQueue , AwaitableInstance , InstancePool \n from tornado . ioloop import IOLoop \n from tornado . gen import coroutine \n class _Instance ( object ) : \n def __init__ ( self ) : \n self . counter = <<mask0>:0> \n def increment ( self ) : \n self . counter += <NUM_LIT:1> \n return self . counter \n def value ( self ) : \n return self . counter \n class TestTasks ( unittest . TestCase ) : \n def test_add_task ( self ) : \n queue = TaskQueue ( ) \n self . assertEquals ( len ( queue ) , <NUM_LIT:0> ) \n task_results = [ ] \n task = lambda x : task_results . append ( x ) \n queue . add_task ( task , <NUM_LIT:1> ) \n queue . add_task ( task , <NUM_LIT:2> ) \n queue . add_task ( task , <NUM_LIT:3> ) \n start = time ( ) \n while <NUM_LIT:1> : \n if len ( task_results ) == <NUM_LIT:3> : \n break \n if time ( ) - start > <NUM_LIT:5> : \n break \n sleep ( <NUM_LIT> ) \n self . assertEquals ( len ( task_results ) , <NUM_LIT:3> ) \n self . assertEquals ( task_results , [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ) \n def test_yield_task ( self ) : \n queue = TaskQueue ( ) \n task_results = [ ] \n @ coroutine \n def yield_tasks ( ) : \n task = lambda x : x \n futures = [ ] \n futures . append ( queue . yield_task ( task , <NUM_LIT:1> ) ) \n futures . append ( queue . yield_task ( task , <NUM_LIT:2> ) ) \n futures . append ( queue . yield_task ( task , <NUM_LIT:3> ) ) \n res = yield futures \n task_results [ : ] = res \n loop = IOLoop ( ) \n loop . make_current ( ) \n loop . run_sync ( yield_tasks ) \n self . assertEquals ( len ( task_results ) , <NUM_LIT:3> ) \n self . assertEquals ( task_results , [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ) \n def test_add_task_exception ( self ) : \n queue = TaskQueue ( ) \n self . assertEquals ( len ( queue ) , <NUM_LIT:0> ) \n task_results = [ ] \n def task ( x ) : \n task_results . append ( x ) \n raise Exception ( '<STR_LIT>' ) \n queue . add_task ( task , <NUM_LIT:1> ) \n queue . add_task ( task , <NUM_LIT:2> ) \n queue . add_task ( task , <NUM_LIT:3> ) \n start = time ( ) \n while <NUM_LIT:1> : \n if len ( task_results ) == <NUM_LIT:3> : \n break \n if time ( ) - start > <NUM_LIT:5> : \n break \n sleep ( <NUM_LIT> ) \n self . assertEquals ( len ( task_results ) , <NUM_LIT:3> ) \n self . assertEquals ( task_results , [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ) \n def test_yield_task_exception ( self ) : \n queue = TaskQueue ( ) \n task_results = [ ] \n @ coroutine \n def yield_tasks ( ) : \n def task ( x ) : \n raise Exception ( '<STR_LIT>' ) \n futures = [ ] \n futures . append ( queue . yield_task ( task , <NUM_LIT:1> ) ) \n futures . append ( queue . yield_task ( task , <NUM_LIT:2> ) ) \n futures . append ( queue . yield_task ( task , <NUM_LIT:3> ) ) \n for f in futures : \n try : \n yield f \n except Exception as e : \n task_results . append ( e ) \n loop = IOLoop ( ) \n loop . make_current ( ) \n loop . run_sync ( yield_tasks ) \n self . assertEquals ( len ( task_results ) , <NUM_LIT:3> ) \n for e in task_results : \n self . assertEquals ( e . message , '<STR_LIT>' ) \n def test_awaitable ( self ) : \n instance = _Instance ( ) \n instance . increment ( ) \n self . assertEquals ( instance . value ( ) , <NUM_LIT:1> ) \n awaitable = AwaitableInstance ( instance ) \n @ coroutine \n def yield_tasks ( ) : \n self . assertEquals ( ( yield awaitable . increment ( ) ) , <NUM_LIT:2> ) \n self . assertEquals ( ( yield awaitable . increment ( ) ) , <NUM_LIT:3> ) \n self . assertEquals ( ( yield awaitable . increment ( ) ) , <NUM_LIT:4> ) \n self . assertEquals ( ( yield awaitable . value ( ) ) , <NUM_LIT:4> ) \n loop = IOLoop ( ) \n loop . make_current ( ) \n loop . run_sync ( yield_tasks ) \n self . assertEquals ( instance . value ( ) , <NUM_LIT:4> ) \n def test_instance_pool ( self ) : \n instance1 = _Instance ( ) \n instance2 = _Instance ( ) \n pool = InstancePool ( [ instance1 , instance2 ] ) \n pool . increment ( ) \n pool . increment ( ) \n self . assertEquals ( instance1 . value ( ) , <NUM_LIT:1> ) \n self . assertEquals ( instance2 . value ( ) , <NUM_LIT:1> ) \n pool . transaction ( lambda i : i . increment ( ) ) \n pool . transaction ( lambda i : i . increment ( ) ) \n self . assertEquals ( instance1 . value ( ) , <NUM_LIT:2> ) \n self . assertEquals ( instance2 . value ( ) , <NUM_LIT:2> ) \n @ coroutine \n def yield_tasks ( ) : \n self . assertEquals ( ( yield pool . await ( ) . increment ( ) ) , <NUM_LIT:3> ) \n self . assertEquals ( ( yield pool . await ( ) . increment ( ) ) , <NUM_LIT:3> ) \n self . assertEquals ( instance1 . value ( ) , <NUM_LIT:3> ) \n self . assertEquals ( instance2 . value ( ) , <NUM_LIT:3> ) \n self . assertEquals ( ( yield pool . await_transaction ( lambda i : i . increment ( ) ) ) , <NUM_LIT:4> ) \n self . assertEquals ( ( yield pool . await_transaction ( lambda i : i . increment ( ) ) ) , <NUM_LIT:4> ) \n loop = IOLoop ( ) \n loop . make_current ( ) \n loop . run_sync ( yield_tasks ) \n self . assertEquals ( instance1 . value ( ) , <NUM_LIT:4> ) \n self . assertEquals ( instance2 . value ( ) , <NUM_LIT:4> ) \n", "gt": "NUM_LIT"}
{"input": "\n '''<STR_LIT>''' \n import cPickle as pickle \n from threading import Thread \n from collections import deque \n from tornado . web import * \n from tornado . ioloop import IOLoop \n from traceback import format_exc \n from tornado . options import options \n import zmq \n import logging \n import zlib \n from random import choice , shuffle \n class EventManager ( ) : \n '''<STR_LIT>''' \n def __init__ ( self , address = None ) : \n self . __handlers = { } \n self . address = address \n self . __zmq_context = zmq . Context ( ) \n self . __remote_servers = { } \n self . __thread = None \n self . __queued_servers = deque ( ) \n def register_server ( self , address ) : \n '''<STR_LIT>''' \n if address in self . __remote_servers : \n raise Exception ( '<STR_LIT>' , address ) \n <mask0> = self . __zmq_context . socket ( zmq . PUSH ) \n socket . connect ( address ) \n self . __remote_servers [ address ] = socket \n self . refresh_server_queue ( ) \n def remove_server ( self , address ) : \n '''<STR_LIT>''' \n del self . __remote_servers [ address ] \n self . refresh_server_queue ( ) \n def remove_all_servers ( self ) : \n '''<STR_LIT>''' \n self . __remote_servers . clear ( ) \n self . refresh_server_queue ( ) \n def refresh_server_queue ( self ) : \n '''<STR_LIT>''' \n self . __queued_servers . clear ( ) \n self . __queued_servers . extend ( self . __remote_servers . itervalues ( ) ) \n shuffle ( self . __queued_servers ) \n def register_handler ( self , event_name , event_handler , run_on_main_loop = False , request_handler = None , persist = False ) : \n '''<STR_LIT>''' \n if not event_name in self . __handlers : \n self . __handlers [ event_name ] = set ( ) \n handler_tuple = ( event_handler , run_on_main_loop , request_handler , persist ) \n self . __handlers [ event_name ] . add ( handler_tuple ) \n return ( event_name , handler_tuple ) \n def remove_handler ( self , handler_sig ) : \n '''<STR_LIT>''' \n self . __handlers [ handler_sig [ <NUM_LIT:0> ] ] . discard ( handler_sig [ <NUM_LIT:1> ] ) \n def start_listening ( self ) : \n '''<STR_LIT>''' \n if self . __thread : \n return \n def receive ( ) : \n context = zmq . Context ( ) \n socket = context . socket ( zmq . PULL ) \n socket . bind ( self . address ) \n while True : \n event = pickle . loads ( zlib . decompress ( socket . recv ( ) ) ) \n event_name = event [ '<STR_LIT:name>' ] \n event_args = event [ '<STR_LIT:args>' ] \n if event_name in self . __handlers : \n handlers = self . __handlers [ event_name ] \n for handler in list ( handlers ) : \n if not handler [ <NUM_LIT:3> ] : \n handlers . remove ( handler ) \n try : \n if handler [ <NUM_LIT:2> ] and handler [ <NUM_LIT:2> ] . _finished : \n continue \n if handler [ <NUM_LIT:1> ] : \n ( lambda h : IOLoop . instance ( ) . add_callback ( lambda : h [ <NUM_LIT:0> ] ( event_args ) ) ) ( handler ) \n else : \n handler [ <NUM_LIT:0> ] ( event_args ) \n except Exception as e : \n logging . error ( format_exc ( ) ) \n self . __thread = Thread ( target = receive ) \n self . __thread . daemon = True \n self . __thread . start ( ) \n def send_to_server ( self , address , event_name , event_args ) : \n '''<STR_LIT>''' \n event = { '<STR_LIT:name>' : event_name , '<STR_LIT:args>' : event_args } \n event_data = zlib . compress ( pickle . dumps ( event ) ) \n self . __remote_servers [ address ] . send ( event_data ) \n def send ( self , event_name , event_args , broadcast = True ) : \n '''<STR_LIT>''' \n if not self . __remote_servers : \n return \n event = { '<STR_LIT:name>' : event_name , '<STR_LIT:args>' : event_args } \n event_data = zlib . compress ( pickle . dumps ( event ) ) \n if not broadcast : \n self . __queued_servers [ <NUM_LIT:0> ] . send ( event_data ) \n self . __queued_servers . rotate ( - <NUM_LIT:1> ) \n return \n for socket in self . __queued_servers : \n socket . send ( event_data ) \n @ classmethod \n def instance ( cls ) : \n '''<STR_LIT>''' \n if not hasattr ( cls , '<STR_LIT>' ) : \n cls . _instance = cls ( ) \n return cls . _instance \n", "gt": "socket"}
{"input": "\n import toto \n import cPickle as pickle \n import zlib \n import logging \n from threading import Thread \n from tornado . options import options \n from tornado . gen import Task \n from collections import deque \n from time import time \n from uuid import uuid4 \n from traceback import format_exc \n from toto . options import safe_define \n safe_define ( \"<STR_LIT>\" , type = str , help = \"<STR_LIT>\" ) \n safe_define ( \"<STR_LIT>\" , type = str , help = \"<STR_LIT>\" ) \n safe_define ( \"<STR_LIT>\" , type = str , default = '<STR_LIT>' , help = \"<STR_LIT>\" ) \n safe_define ( \"<STR_LIT>\" , default = <NUM_LIT> , help = \"<STR_LIT>\" ) \n safe_define ( \"<STR_LIT>\" , default = False , help = \"<STR_LIT>\" ) \n safe_define ( \"<STR_LIT>\" , default = <NUM_LIT:0> , help = \"<STR_LIT>\" ) \n safe_define ( \"<STR_LIT>\" , default = '<STR_LIT>' , help = \"<STR_LIT>\" ) \n safe_define ( \"<STR_LIT>\" , default = '<STR_LIT>' , help = \"<STR_LIT>\" ) \n <mask0> = '<STR_LIT>' \n WORKER_SOCKET_DISCONNECT = '<STR_LIT>' \n class WorkerConnection ( object ) : \n '''<STR_LIT>''' \n def __getattr__ ( self , path ) : \n return WorkerInvocation ( path , self ) \n def log_error ( self , error ) : \n logging . error ( repr ( error ) ) \n def enable_traceback_logging ( self ) : \n from new import instancemethod \n from traceback import format_exc \n def log_error ( self , e ) : \n logging . error ( format_exc ( ) ) \n self . log_error = instancemethod ( log_error , self ) \n @ classmethod \n def instance ( cls ) : \n '''<STR_LIT>''' \n if not hasattr ( cls , '<STR_LIT>' ) : \n if options . worker_transport == '<STR_LIT:http>' : \n from toto . httpworkerconnection import HTTPWorkerConnection \n cls . _instance = HTTPWorkerConnection . instance ( ) \n else : \n from toto . zmqworkerconnection import ZMQWorkerConnection \n cls . _instance = ZMQWorkerConnection . instance ( ) \n return cls . _instance \n class WorkerInvocation ( object ) : \n def __init__ ( self , path , connection ) : \n self . _path = path \n self . _connection = connection \n def __call__ ( self , * args , ** kwargs ) : \n return self . _connection . invoke ( self . _path , * args , ** kwargs ) \n def __getattr__ ( self , path ) : \n return getattr ( self . _connection , self . _path + '<STR_LIT:.>' + path ) \n", "gt": "WORKER_SOCKET_CONNECT"}
{"input": "\n from . import multiarray \n <mask0> = [ ] \n", "gt": "__all__"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n <mask0> = '<STR_LIT>' \n import urllib \n from pyactiveresource import connection \n from pyactiveresource import formats \n class Error ( Exception ) : \n \"\"\"<STR_LIT>\"\"\" \n class FakeConnection ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , format = formats . XMLFormat ) : \n \"\"\"<STR_LIT>\"\"\" \n self . format = format \n self . _request_map = { } \n self . _debug_only = False \n def _split_path ( self , path ) : \n \"\"\"<STR_LIT>\"\"\" \n path_only , query_string = urllib . splitquery ( path ) \n if query_string : \n query_dict = dict ( [ i . split ( '<STR_LIT:=>' ) for i in query_string . split ( '<STR_LIT:&>' ) ] ) \n else : \n query_dict = { } \n return path_only , query_dict \n def debug_only ( self , debug = True ) : \n self . _debug_only = debug \n def respond_to ( self , method , path , headers , data , body , \n response_headers = None ) : \n \"\"\"<STR_LIT>\"\"\" \n path_only , query = self . _split_path ( path ) \n if response_headers is None : \n response_headers = { } \n self . _request_map . setdefault ( method , [ ] ) . append ( \n ( ( path_only , query , headers , data ) , ( body , response_headers ) ) ) \n def _lookup_response ( self , method , path , headers , data ) : \n path_only , query = self . _split_path ( path ) \n for key , value in self . _request_map . get ( method , { } ) : \n if key == ( path_only , query , headers , data ) : \n response_body , response_headers = value \n return connection . Response ( <NUM_LIT:200> , response_body , response_headers ) \n raise Error ( '<STR_LIT>' % \n ( path , headers , data ) ) \n def get ( self , path , headers = None ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . format . decode ( \n self . _lookup_response ( '<STR_LIT>' , path , headers , None ) . body ) \n def post ( self , path , headers = None , data = None ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . _lookup_response ( '<STR_LIT>' , path , headers , data ) \n def put ( self , path , headers = None , data = None ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . _lookup_response ( '<STR_LIT>' , path , headers , data ) \n def delete ( self , path , headers = None ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . _lookup_response ( '<STR_LIT>' , path , headers , None ) \n", "gt": "__author__"}
{"input": "\n from trac . env import Environment \n from trac . attachment import Attachment \n from tracLib import * \n from ConfigParser import ConfigParser \n import tracLib \n import tracLib . timetracking \n class Client ( object ) : \n def __init__ ( self , env_path ) : \n self . env_path = env_path \n self . env = Environment ( env_path ) \n self . db_cnx = self . env . get_db_cnx ( ) \n self . _registered_users_logins = [ ] \n self . _timetracking_plugins = self . _get_timetracking_plugins ( ) \n def _get_timetracking_plugins ( self ) : \n <mask0> = { } \n if tracLib . SUPPORT_TIME_TRACKING == '<STR_LIT>' : \n for plugin in tracLib . timetracking . plugins : \n plugin_name = plugin . get_name ( ) \n for com_name , com_enabled in self . env . _component_rules . items ( ) : \n if com_name . startswith ( plugin_name ) and com_enabled and plugin_name not in plugins : \n plugins [ plugin_name ] = plugin ( self . env ) \n else : \n for plugin in tracLib . timetracking . plugins : \n plugin_name = plugin . get_name ( ) \n if plugin_name == tracLib . SUPPORT_TIME_TRACKING : \n plugins [ plugin_name ] = plugin ( self . env ) \n break ; \n for plugin_name in plugins . keys ( ) : \n print \"<STR_LIT>\" % plugin_name \n return plugins . values ( ) \n def get_project_description ( self ) : \n return self . env . project_description \n def get_users ( self ) : \n result = self . env . get_known_users ( ) \n trac_users = list ( [ ] ) \n for user in result : \n user_login = user [ <NUM_LIT:0> ] . lower ( ) \n if user_login in self . _registered_users_logins : \n continue \n u = TracUser ( user_login ) \n u . email = user [ <NUM_LIT:2> ] \n trac_users . append ( u ) \n self . _registered_users_logins . append ( user_login ) \n if not tracLib . ACCEPT_NON_AUTHORISED_USERS : \n return trac_users \n user_fields = [ ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ] \n first = True \n request = \"<STR_LIT>\" \n for column_name , table_name in user_fields : \n if first : \n first = False \n else : \n request += \"<STR_LIT>\" \n request += \"<STR_LIT>\" % ( column_name , table_name ) \n cursor = self . db_cnx . cursor ( ) \n cursor . execute ( request ) \n for row in cursor : \n if row [ <NUM_LIT:0> ] not in self . _registered_users_logins : \n trac_user = self . _get_non_authorised_user ( row [ <NUM_LIT:0> ] ) \n if trac_user is not None : \n trac_users . append ( trac_user ) \n self . _registered_users_logins . append ( trac_user . name ) \n return trac_users \n def _get_non_authorised_user ( self , user_name ) : \n if user_name is None : \n return None \n start = user_name . find ( \"<STR_LIT:<>\" ) \n end = user_name . rfind ( \"<STR_LIT:>>\" ) \n if ( start > - <NUM_LIT:1> ) and ( end > start + <NUM_LIT:1> ) : \n if user_name . find ( \"<STR_LIT:@>\" , start , end ) > <NUM_LIT:0> : \n user = TracUser ( user_name [ start + <NUM_LIT:1> : end ] . replace ( \"<STR_LIT:U+0020>\" , \"<STR_LIT:_>\" ) ) \n user . email = user_name [ start + <NUM_LIT:1> : end ] . replace ( \"<STR_LIT:U+0020>\" , \"<STR_LIT:_>\" ) \n return user \n return None \n def _get_user_login ( self , user_name ) : \n if user_name is None : \n return None \n if user_name in self . _registered_users_logins : \n return user_name \n if not tracLib . ACCEPT_NON_AUTHORISED_USERS : \n return None \n user = self . _get_non_authorised_user ( user_name ) \n if ( user is None ) or ( user . name not in self . _registered_users_logins ) : \n return None \n return user . name \n def get_severities ( self ) : \n return self . _get_data_from_enum ( \"<STR_LIT>\" ) \n def get_issue_types ( self ) : \n return self . _get_data_from_enum ( \"<STR_LIT>\" ) \n def get_issue_priorities ( self ) : \n return self . _get_data_from_enum ( \"<STR_LIT>\" ) \n def get_issue_resolutions ( self ) : \n return [ TracResolution ( name ) for name in self . _get_data_from_enum ( \"<STR_LIT>\" ) ] \n def get_components ( self ) : \n cursor = self . db_cnx . cursor ( ) \n cursor . execute ( \"<STR_LIT>\" ) \n trac_components = list ( [ ] ) \n for row in cursor : \n component = TracComponent ( row [ <NUM_LIT:0> ] ) \n component . owner = self . _get_user_login ( component . owner ) \n if row [ <NUM_LIT:2> ] is not None : \n component . description = row [ <NUM_LIT:2> ] \n trac_components . append ( component ) \n return trac_components \n def get_versions ( self ) : \n cursor = self . db_cnx . cursor ( ) \n cursor . execute ( \"<STR_LIT>\" ) \n trac_versions = list ( [ ] ) \n for row in cursor : \n version = TracVersion ( row [ <NUM_LIT:0> ] ) \n if row [ <NUM_LIT:1> ] : \n version . time = to_unix_time ( row [ <NUM_LIT:1> ] ) \n if row [ <NUM_LIT:2> ] is not None : \n version . description = row [ <NUM_LIT:2> ] \n trac_versions . append ( version ) \n return trac_versions \n def get_issues ( self ) : \n cursor = self . db_cnx . cursor ( ) \n cursor . execute ( \"<STR_LIT>\" \n \"<STR_LIT>\" ) \n trac_issues = list ( [ ] ) \n for row in cursor : \n issue = TracIssue ( row [ <NUM_LIT:0> ] ) \n issue . time = to_unix_time ( row [ <NUM_LIT:2> ] ) \n issue . changetime = to_unix_time ( row [ <NUM_LIT:3> ] ) \n issue . reporter = self . _get_user_login ( row [ <NUM_LIT:8> ] ) \n if row [ <NUM_LIT:9> ] is not None : \n cc = row [ <NUM_LIT:9> ] . split ( \"<STR_LIT:U+002C>\" ) \n for c in cc : \n if len ( c ) > <NUM_LIT:0> : \n cc_name = self . _get_user_login ( c . strip ( ) ) \n if cc_name is not None : \n issue . cc . add ( cc_name ) \n issue . summary = row [ <NUM_LIT> ] \n issue . description = row [ <NUM_LIT> ] \n issue . custom_fields [ \"<STR_LIT>\" ] = row [ <NUM_LIT:1> ] \n issue . custom_fields [ \"<STR_LIT>\" ] = row [ <NUM_LIT:4> ] \n issue . custom_fields [ \"<STR_LIT>\" ] = row [ <NUM_LIT:5> ] \n issue . custom_fields [ \"<STR_LIT>\" ] = row [ <NUM_LIT:6> ] \n issue . custom_fields [ \"<STR_LIT>\" ] = self . _get_user_login ( row [ <NUM_LIT:7> ] ) \n issue . custom_fields [ \"<STR_LIT>\" ] = row [ <NUM_LIT:10> ] \n issue . custom_fields [ \"<STR_LIT>\" ] = row [ <NUM_LIT:11> ] \n issue . custom_fields [ \"<STR_LIT>\" ] = row [ <NUM_LIT:12> ] \n if row [ <NUM_LIT:15> ] is not None : \n keywords = row [ <NUM_LIT:15> ] . rsplit ( \"<STR_LIT:U+002C>\" ) \n for kw in keywords : \n if len ( kw ) > <NUM_LIT:0> : \n issue . keywords . add ( kw . strip ( ) ) \n custom_field_cursor = self . db_cnx . cursor ( ) \n custom_field_cursor . execute ( \"<STR_LIT>\" , ( str ( row [ <NUM_LIT:0> ] ) , ) ) \n for cf in custom_field_cursor : \n issue . custom_fields [ cf [ <NUM_LIT:0> ] . capitalize ( ) ] = cf [ <NUM_LIT:1> ] \n attachment_cursor = self . db_cnx . cursor ( ) \n attachment_cursor . execute ( \"<STR_LIT>\" \n \"<STR_LIT>\" , ( \"<STR_LIT>\" , str ( issue . id ) ) ) \n for elem in attachment_cursor : \n at = TracAttachment ( Attachment . _get_path ( self . env . path , '<STR_LIT>' , str ( issue . id ) , elem [ <NUM_LIT:0> ] ) ) \n at . name = elem [ <NUM_LIT:0> ] \n at . size = elem [ <NUM_LIT:1> ] \n at . time = to_unix_time ( elem [ <NUM_LIT:2> ] ) \n at . description = elem [ <NUM_LIT:3> ] \n at . author_name = elem [ <NUM_LIT:4> ] \n issue . attachment . add ( at ) \n trac_issues . append ( issue ) \n change_cursor = self . db_cnx . cursor ( ) \n change_cursor . execute ( \"<STR_LIT>\" , ( str ( row [ <NUM_LIT:0> ] ) , \"<STR_LIT>\" , ) ) \n for elem in change_cursor : \n if ( elem [ <NUM_LIT:2> ] is None ) or ( not len ( elem [ <NUM_LIT:2> ] . lstrip ( ) ) ) : \n continue \n comment = TracComment ( to_unix_time ( elem [ <NUM_LIT:0> ] ) ) \n comment . author = str ( elem [ <NUM_LIT:1> ] ) \n comment . content = unicode ( elem [ <NUM_LIT:2> ] ) \n comment . id = elem [ <NUM_LIT:3> ] \n issue . comments . add ( comment ) \n for ttp in self . _timetracking_plugins : \n issue . workitems . update ( set ( ttp [ row [ <NUM_LIT:0> ] ] ) ) \n return trac_issues \n def get_custom_fields_declared ( self ) : \n ini_file_path = self . env_path + \"<STR_LIT>\" \n parser = ConfigParser ( ) \n parser . read ( ini_file_path ) \n if not ( \"<STR_LIT>\" in parser . sections ( ) ) : \n return set ( [ ] ) \n result = parser . items ( \"<STR_LIT>\" ) \n items = dict ( [ ] ) \n for elem in result : \n items [ elem [ <NUM_LIT:0> ] ] = elem [ <NUM_LIT:1> ] \n keys = items . keys ( ) \n custom_fields = list ( [ ] ) \n for k in keys : \n if not ( \"<STR_LIT:.>\" in k ) : \n field = TracCustomFieldDeclaration ( k . capitalize ( ) ) \n field . type = items [ k ] \n options_key = k + \"<STR_LIT>\" \n if options_key in items : \n opts_str = items [ options_key ] \n opts = opts_str . rsplit ( \"<STR_LIT:|>\" ) \n for o in opts : \n field . options . append ( o ) \n value_key = k + \"<STR_LIT>\" \n if value_key in items : \n field . value = items [ value_key ] \n label_key = k + \"<STR_LIT>\" \n if label_key in items : \n field . label = items [ label_key ] \n custom_fields . append ( field ) \n return custom_fields \n def _get_data_from_enum ( self , type_name ) : \n cursor = self . db_cnx . cursor ( ) \n cursor . execute ( \"<STR_LIT>\" , ( type_name , ) ) \n return [ row [ <NUM_LIT:0> ] for row in cursor ] \n", "gt": "plugins"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import sys \n from collections import defaultdict \n from bacpypes . debugging import Logging , function_debugging , ModuleLogger \n from bacpypes . consolelogging import ConsoleLogHandler \n from bacpypes . pdu import Address \n from bacpypes . analysis import trace , strftimestamp , Tracer \n from bacpypes . npdu import WhoIsRouterToNetwork \n <mask0> = <NUM_LIT:0> \n _log = ModuleLogger ( globals ( ) ) \n filterSource = None \n filterDestination = None \n filterHost = None \n requests = defaultdict ( int ) \n networks = defaultdict ( list ) \n @ function_debugging \n def Match ( addr1 , addr2 ) : \n \"\"\"<STR_LIT>\"\"\" \n if _debug : Match . _debug ( \"<STR_LIT>\" , addr1 , addr2 ) \n if ( addr2 . addrType == Address . localBroadcastAddr ) : \n return ( addr1 . addrType == Address . localStationAddr ) or ( addr1 . addrType == Address . localBroadcastAddr ) \n elif ( addr2 . addrType == Address . localStationAddr ) : \n return ( addr1 . addrType == Address . localStationAddr ) and ( addr1 . addrAddr == addr2 . addrAddr ) \n elif ( addr2 . addrType == Address . remoteBroadcastAddr ) : \n return ( ( addr1 . addrType == Address . remoteStationAddr ) or ( addr1 . addrType == Address . remoteBroadcastAddr ) ) and ( addr1 . addrNet == addr2 . addrNet ) \n elif ( addr2 . addrType == Address . remoteStationAddr ) : \n return ( addr1 . addrType == Address . remoteStationAddr ) and ( addr1 . addrNet == addr2 . addrNet ) and ( addr1 . addrAddr == addr2 . addrAddr ) \n elif ( addr2 . addrType == Address . globalBroadcastAddr ) : \n return ( addr1 . addrType == Address . globalBroadcastAddr ) \n else : \n raise RuntimeError , \"<STR_LIT>\" \n class WhoIsRouterToNetworkSummary ( Tracer , Logging ) : \n def __init__ ( self ) : \n if _debug : IAmRouterToNetworkSummary . _debug ( \"<STR_LIT>\" ) \n Tracer . __init__ ( self , self . Filter ) \n def Filter ( self , pkt ) : \n if _debug : WhoIsRouterToNetworkSummary . _debug ( \"<STR_LIT>\" , pkt ) \n global requests , networks \n if not isinstance ( pkt , WhoIsRouterToNetwork ) : \n return \n if filterSource : \n if not Match ( pkt . pduSource , filterSource ) : \n if _debug : WhoIsRouterToNetworkSummary . _debug ( \"<STR_LIT>\" ) \n return \n if filterDestination : \n if not Match ( pkt . pduDestination , filterDestination ) : \n if _debug : WhoIsRouterToNetworkSummary . _debug ( \"<STR_LIT>\" ) \n return \n if filterHost : \n if ( not Match ( pkt . pduSource , filterHost ) ) and ( not Match ( pkt . pduDestination , filterHost ) ) : \n if _debug : WhoIsRouterToNetworkSummary . _debug ( \"<STR_LIT>\" ) \n return \n requests [ pkt . pduSource ] += <NUM_LIT:1> \n networks [ pkt . pduSource ] . append ( pkt . wirtnNetwork ) \n try : \n if ( '<STR_LIT>' in sys . argv ) : \n indx = sys . argv . index ( '<STR_LIT>' ) \n for i in range ( indx + <NUM_LIT:1> , len ( sys . argv ) ) : \n ConsoleLogHandler ( sys . argv [ i ] ) \n del sys . argv [ indx : ] \n if _debug : _log . debug ( \"<STR_LIT>\" ) \n if ( '<STR_LIT>' in sys . argv ) : \n i = sys . argv . index ( '<STR_LIT>' ) \n filterSource = Address ( sys . argv [ i + <NUM_LIT:1> ] ) \n if _debug : _log . debug ( \"<STR_LIT>\" , filterSource ) \n del sys . argv [ i : i + <NUM_LIT:2> ] \n if ( '<STR_LIT>' in sys . argv ) : \n i = sys . argv . index ( '<STR_LIT>' ) \n filterDestination = Address ( sys . argv [ i + <NUM_LIT:1> ] ) \n if _debug : _log . debug ( \"<STR_LIT>\" , filterDestination ) \n del sys . argv [ i : i + <NUM_LIT:2> ] \n if ( '<STR_LIT>' in sys . argv ) : \n i = sys . argv . index ( '<STR_LIT>' ) \n filterHost = Address ( sys . argv [ i + <NUM_LIT:1> ] ) \n if _debug : _log . debug ( \"<STR_LIT>\" , filterHost ) \n del sys . argv [ i : i + <NUM_LIT:2> ] \n for fname in sys . argv [ <NUM_LIT:1> : ] : \n trace ( fname , [ WhoIsRouterToNetworkSummary ] ) \n items = requests . items ( ) \n items . sort ( lambda x , y : cmp ( y [ <NUM_LIT:1> ] , x [ <NUM_LIT:1> ] ) ) \n print \"<STR_LIT>\" % ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n for key , count in items : \n print \"<STR_LIT>\" % ( key , count ) \n net_count = defaultdict ( int ) \n for net in networks [ key ] : \n net_count [ net ] += <NUM_LIT:1> \n net_count = net_count . items ( ) \n net_count . sort ( lambda x , y : cmp ( y [ <NUM_LIT:1> ] , x [ <NUM_LIT:1> ] ) ) \n for net , count in net_count : \n print \"<STR_LIT>\" % ( net , count ) \n except KeyboardInterrupt : \n pass \n except Exception , e : \n _log . exception ( \"<STR_LIT>\" , e ) \n finally : \n if _debug : _log . debug ( \"<STR_LIT>\" ) \n", "gt": "_debug"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import asyncore \n import socket \n import cPickle as pickle \n from time import time as _time , sleep as _sleep \n from StringIO import StringIO \n from . debugging import ModuleLogger , DebugContents , bacpypes_debugging \n from . core import deferred \n from . task import FunctionTask , OneShotFunction \n from . comm import PDU , Client , Server \n from . comm import ServiceAccessPoint , ApplicationServiceElement \n <mask0> = <NUM_LIT:0> \n _log = ModuleLogger ( globals ( ) ) \n REBIND_SLEEP_INTERVAL = <NUM_LIT> \n class PickleActorMixIn : \n def __init__ ( self , * args ) : \n if _debug : PickleActorMixIn . _debug ( \"<STR_LIT>\" , args ) \n super ( PickleActorMixIn , self ) . __init__ ( * args ) \n self . pickleBuffer = '<STR_LIT>' \n def indication ( self , pdu ) : \n if _debug : PickleActorMixIn . _debug ( \"<STR_LIT>\" , pdu ) \n pdu . pduData = pickle . dumps ( pdu . pduData ) \n super ( PickleActorMixIn , self ) . indication ( pdu ) \n def response ( self , pdu ) : \n if _debug : PickleActorMixIn . _debug ( \"<STR_LIT>\" , pdu ) \n self . pickleBuffer += pdu . pduData \n strm = StringIO ( self . pickleBuffer ) \n pos = <NUM_LIT:0> \n while ( pos < strm . len ) : \n try : \n msg = pickle . load ( strm ) \n except : \n break \n rpdu = PDU ( msg ) \n rpdu . update ( pdu ) \n super ( PickleActorMixIn , self ) . response ( rpdu ) \n pos = strm . tell ( ) \n if ( pos < strm . len ) : \n self . pickleBuffer = self . pickleBuffer [ pos : ] \n else : \n self . pickleBuffer = '<STR_LIT>' \n bacpypes_debugging ( PickleActorMixIn ) \n class TCPClient ( asyncore . dispatcher ) : \n def __init__ ( self , peer ) : \n if _debug : TCPClient . _debug ( \"<STR_LIT>\" , peer ) \n asyncore . dispatcher . __init__ ( self ) \n self . create_socket ( socket . AF_INET , socket . SOCK_STREAM ) \n self . peer = peer \n self . request = '<STR_LIT>' \n self . socketError = None \n if _debug : TCPClient . _debug ( \"<STR_LIT>\" ) \n self . connect ( peer ) \n if _debug : TCPClient . _debug ( \"<STR_LIT>\" ) \n def handle_connect ( self ) : \n if _debug : deferred ( TCPClient . _debug , \"<STR_LIT>\" ) \n def handle_expt ( self ) : \n pass \n def readable ( self ) : \n return <NUM_LIT:1> \n def handle_read ( self ) : \n if _debug : deferred ( TCPClient . _debug , \"<STR_LIT>\" ) \n try : \n msg = self . recv ( <NUM_LIT> ) \n if _debug : deferred ( TCPClient . _debug , \"<STR_LIT>\" , len ( msg ) ) \n self . socketError = None \n if not self . socket : \n if _debug : deferred ( TCPClient . _debug , \"<STR_LIT>\" ) \n else : \n deferred ( self . response , PDU ( msg ) ) \n except socket . error , err : \n if ( err . args [ <NUM_LIT:0> ] == <NUM_LIT> ) : \n deferred ( TCPClient . _error , \"<STR_LIT>\" , self . peer ) \n else : \n deferred ( TCPClient . _error , \"<STR_LIT>\" , err ) \n self . socketError = err \n def writable ( self ) : \n return ( len ( self . request ) != <NUM_LIT:0> ) \n def handle_write ( self ) : \n if _debug : deferred ( TCPClient . _debug , \"<STR_LIT>\" ) \n try : \n sent = self . send ( self . request ) \n if _debug : deferred ( TCPClient . _debug , \"<STR_LIT>\" , sent , len ( self . request ) - sent ) \n self . socketError = None \n self . request = self . request [ sent : ] \n except socket . error , err : \n if ( err . args [ <NUM_LIT:0> ] == <NUM_LIT> ) : \n deferred ( TCPClient . _error , \"<STR_LIT>\" , self . peer ) \n else : \n deferred ( TCPClient . _error , \"<STR_LIT>\" , err ) \n self . socketError = err \n def handle_close ( self ) : \n if _debug : deferred ( TCPClient . _debug , \"<STR_LIT>\" ) \n self . close ( ) \n self . socket = None \n def indication ( self , pdu ) : \n \"\"\"<STR_LIT>\"\"\" \n if _debug : TCPClient . _debug ( \"<STR_LIT>\" , pdu ) \n self . request += pdu . pduData \n bacpypes_debugging ( TCPClient ) \n class TCPClientActor ( TCPClient ) : \n def __init__ ( self , director , peer ) : \n if _debug : TCPClientActor . _debug ( \"<STR_LIT>\" , director , peer ) \n TCPClient . __init__ ( self , peer ) \n self . director = director \n self . timeout = director . timeout \n if self . timeout > <NUM_LIT:0> : \n self . timer = FunctionTask ( self . idle_timeout ) \n self . timer . install_task ( _time ( ) + self . timeout ) \n else : \n self . timer = None \n self . flushTask = None \n self . director . add_actor ( self ) \n def handle_close ( self ) : \n if _debug : TCPClientActor . _debug ( \"<STR_LIT>\" ) \n if self . flushTask : \n self . flushTask . suspend_task ( ) \n if self . timer : \n self . timer . suspend_task ( ) \n self . director . remove_actor ( self ) \n TCPClient . handle_close ( self ) \n def idle_timeout ( self ) : \n if _debug : TCPClientActor . _debug ( \"<STR_LIT>\" ) \n self . handle_close ( ) \n def indication ( self , pdu ) : \n if _debug : TCPClientActor . _debug ( \"<STR_LIT>\" , pdu ) \n if self . flushTask : \n if _debug : TCPServerActor . _debug ( \"<STR_LIT>\" ) \n return \n if self . timer : \n self . timer . install_task ( _time ( ) + self . timeout ) \n TCPClient . indication ( self , pdu ) \n def response ( self , pdu ) : \n if _debug : TCPClientActor . _debug ( \"<STR_LIT>\" , pdu ) \n pdu . pduSource = self . peer \n if self . timer : \n self . timer . install_task ( _time ( ) + self . timeout ) \n self . director . response ( pdu ) \n def flush ( self ) : \n if _debug : TCPClientActor . _debug ( \"<STR_LIT>\" ) \n self . flushTask = None \n if self . request : \n self . flushTask = OneShotFunction ( self . flush ) \n return \n self . handle_close ( ) \n bacpypes_debugging ( TCPClientActor ) \n class TCPPickleClientActor ( PickleActorMixIn , TCPClientActor ) : \n pass \n class TCPClientDirector ( Server , ServiceAccessPoint , DebugContents ) : \n _debug_contents = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n def __init__ ( self , timeout = <NUM_LIT:0> , actorClass = TCPClientActor , sid = None , sapID = None ) : \n if _debug : TCPClientDirector . _debug ( \"<STR_LIT>\" , timeout , actorClass , sid , sapID ) \n Server . __init__ ( self , sid ) \n ServiceAccessPoint . __init__ ( self , sapID ) \n if not issubclass ( actorClass , TCPClientActor ) : \n raise TypeError ( \"<STR_LIT>\" ) \n self . actorClass = actorClass \n self . timeout = timeout \n self . clients = { } \n self . reconnect = { } \n def add_actor ( self , actor ) : \n \"\"\"<STR_LIT>\"\"\" \n if _debug : TCPClientDirector . _debug ( \"<STR_LIT>\" , actor ) \n self . clients [ actor . peer ] = actor \n if self . serviceElement : \n self . sap_request ( addPeer = actor . peer ) \n def remove_actor ( self , actor ) : \n \"\"\"<STR_LIT>\"\"\" \n if _debug : TCPClientDirector . _debug ( \"<STR_LIT>\" , actor ) \n del self . clients [ actor . peer ] \n if self . serviceElement : \n self . sap_request ( delPeer = actor . peer ) \n if actor . peer in self . reconnect : \n connect_task = FunctionTask ( self . connect , actor . peer ) \n connect_task . install_task ( _time ( ) + self . reconnect [ actor . peer ] ) \n def get_actor ( self , address ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . clients . get ( address , None ) \n def connect ( self , address , reconnect = <NUM_LIT:0> ) : \n if _debug : TCPClientDirector . _debug ( \"<STR_LIT>\" , address , reconnect ) \n if address in self . clients : \n return \n client = self . actorClass ( self , address ) \n if _debug : TCPClientDirector . _debug ( \"<STR_LIT>\" , client ) \n if reconnect : \n self . reconnect [ address ] = reconnect \n def disconnect ( self , address ) : \n if _debug : TCPClientDirector . _debug ( \"<STR_LIT>\" , address ) \n if address not in self . clients : \n return \n if address in self . reconnect : \n del self . reconnect [ address ] \n self . clients [ address ] . handle_close ( ) \n def indication ( self , pdu ) : \n \"\"\"<STR_LIT>\"\"\" \n if _debug : TCPClientDirector . _debug ( \"<STR_LIT>\" , pdu ) \n addr = pdu . pduDestination \n client = self . clients . get ( addr , None ) \n if not client : \n client = self . actorClass ( self , addr ) \n client . indication ( pdu ) \n bacpypes_debugging ( TCPClientDirector ) \n class TCPServer ( asyncore . dispatcher ) : \n def __init__ ( self , sock , peer ) : \n if _debug : TCPServer . _debug ( \"<STR_LIT>\" , sock , peer ) \n asyncore . dispatcher . __init__ ( self , sock ) \n self . peer = peer \n self . request = '<STR_LIT>' \n self . socketError = None \n def handle_connect ( self ) : \n if _debug : deferred ( TCPServer . _debug , \"<STR_LIT>\" ) \n def readable ( self ) : \n return <NUM_LIT:1> \n def handle_read ( self ) : \n if _debug : deferred ( TCPServer . _debug , \"<STR_LIT>\" ) \n try : \n msg = self . recv ( <NUM_LIT> ) \n if _debug : deferred ( TCPServer . _debug , \"<STR_LIT>\" , len ( msg ) ) \n self . socketError = None \n if not self . socket : \n if _debug : deferred ( TCPServer . _debug , \"<STR_LIT>\" ) \n else : \n deferred ( self . response , PDU ( msg ) ) \n except socket . error , err : \n if ( err . args [ <NUM_LIT:0> ] == <NUM_LIT> ) : \n deferred ( TCPServer . _error , \"<STR_LIT>\" , self . peer ) \n else : \n deferred ( TCPServer . _error , \"<STR_LIT>\" , err ) \n self . socketError = err \n def writable ( self ) : \n return ( len ( self . request ) != <NUM_LIT:0> ) \n def handle_write ( self ) : \n if _debug : deferred ( TCPServer . _debug , \"<STR_LIT>\" ) \n try : \n sent = self . send ( self . request ) \n if _debug : deferred ( TCPServer . _debug , \"<STR_LIT>\" , sent , len ( self . request ) - sent ) \n self . socketError = None \n self . request = self . request [ sent : ] \n except socket . error , why : \n if ( why . args [ <NUM_LIT:0> ] == <NUM_LIT> ) : \n deferred ( TCPServer . _error , \"<STR_LIT>\" , self . peer ) \n else : \n deferred ( TCPServer . _error , \"<STR_LIT>\" , why ) \n self . socketError = why \n def handle_close ( self ) : \n if _debug : deferred ( TCPServer . _debug , \"<STR_LIT>\" ) \n if not self : \n deferred ( TCPServer . _warning , \"<STR_LIT>\" ) \n return \n if not self . socket : \n deferred ( TCPServer . _warning , \"<STR_LIT>\" ) \n return \n self . close ( ) \n self . socket = None \n def indication ( self , pdu ) : \n \"\"\"<STR_LIT>\"\"\" \n if _debug : TCPServer . _debug ( \"<STR_LIT>\" , pdu ) \n self . request += pdu . pduData \n bacpypes_debugging ( TCPServer ) \n class TCPServerActor ( TCPServer ) : \n def __init__ ( self , director , sock , peer ) : \n if _debug : TCPServerActor . _debug ( \"<STR_LIT>\" , director , sock , peer ) \n TCPServer . __init__ ( self , sock , peer ) \n self . director = director \n self . timeout = director . timeout \n if self . timeout > <NUM_LIT:0> : \n self . timer = FunctionTask ( self . idle_timeout ) \n self . timer . install_task ( _time ( ) + self . timeout ) \n else : \n self . timer = None \n self . flushTask = None \n self . director . add_actor ( self ) \n def handle_close ( self ) : \n if _debug : TCPServerActor . _debug ( \"<STR_LIT>\" ) \n if self . flushTask : \n self . flushTask . suspend_task ( ) \n self . director . remove_actor ( self ) \n TCPServer . handle_close ( self ) \n def idle_timeout ( self ) : \n if _debug : TCPServerActor . _debug ( \"<STR_LIT>\" ) \n self . handle_close ( ) \n def indication ( self , pdu ) : \n if _debug : TCPServerActor . _debug ( \"<STR_LIT>\" , pdu ) \n if self . flushTask : \n if _debug : TCPServerActor . _debug ( \"<STR_LIT>\" ) \n return \n if self . timer : \n self . timer . install_task ( _time ( ) + self . timeout ) \n TCPServer . indication ( self , pdu ) \n def response ( self , pdu ) : \n if _debug : TCPServerActor . _debug ( \"<STR_LIT>\" , pdu ) \n if self . flushTask : \n if _debug : TCPServerActor . _debug ( \"<STR_LIT>\" ) \n return \n pdu . pduSource = self . peer \n if self . timer : \n self . timer . install_task ( _time ( ) + self . timeout ) \n self . director . response ( pdu ) \n def flush ( self ) : \n if _debug : TCPServerActor . _debug ( \"<STR_LIT>\" ) \n self . flushTask = None \n if self . request : \n self . flushTask = OneShotFunction ( self . flush ) \n return \n self . handle_close ( ) \n bacpypes_debugging ( TCPServerActor ) \n class TCPPickleServerActor ( PickleActorMixIn , TCPServerActor ) : \n pass \n class TCPServerDirector ( asyncore . dispatcher , Server , ServiceAccessPoint , DebugContents ) : \n _debug_contents = ( '<STR_LIT:port>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n def __init__ ( self , address , listeners = <NUM_LIT:5> , timeout = <NUM_LIT:0> , reuse = False , actorClass = TCPServerActor , cid = None , sapID = None ) : \n if _debug : \n TCPServerDirector . _debug ( \"<STR_LIT>\" \n , address , listeners , timeout , reuse , actorClass , cid , sapID \n ) \n Server . __init__ ( self , cid ) \n ServiceAccessPoint . __init__ ( self , sapID ) \n self . port = address \n self . timeout = timeout \n if not issubclass ( actorClass , TCPServerActor ) : \n raise TypeError ( \"<STR_LIT>\" ) \n self . actorClass = actorClass \n self . servers = { } \n asyncore . dispatcher . __init__ ( self ) \n self . create_socket ( socket . AF_INET , socket . SOCK_STREAM ) \n if reuse : \n self . set_reuse_addr ( ) \n hadBindErrors = False \n for i in range ( <NUM_LIT:30> ) : \n try : \n self . bind ( address ) \n break \n except socket . error , err : \n hadBindErrors = True \n TCPServerDirector . _warning ( '<STR_LIT>' , err ) \n _sleep ( REBIND_SLEEP_INTERVAL ) \n else : \n TCPServerDirector . _error ( '<STR_LIT>' ) \n raise RuntimeError ( \"<STR_LIT>\" ) \n if hadBindErrors : \n TCPServerDirector . _info ( '<STR_LIT>' ) \n self . listen ( listeners ) \n def handle_accept ( self ) : \n if _debug : TCPServerDirector . _debug ( \"<STR_LIT>\" ) \n try : \n client , addr = self . accept ( ) \n except socket . error : \n TCPServerDirector . _warning ( '<STR_LIT>' ) \n return \n except TypeError : \n TCPServerDirector . _warning ( '<STR_LIT>' ) \n return \n if _debug : TCPServerDirector . _debug ( \"<STR_LIT>\" , client , addr ) \n server = self . actorClass ( self , client , addr ) \n self . servers [ addr ] = server \n return server \n def handle_close ( self ) : \n if _debug : TCPServerDirector . _debug ( \"<STR_LIT>\" ) \n self . close ( ) \n def add_actor ( self , actor ) : \n if _debug : TCPServerDirector . _debug ( \"<STR_LIT>\" , actor ) \n self . servers [ actor . peer ] = actor \n if self . serviceElement : \n self . sap_request ( addPeer = actor . peer ) \n def remove_actor ( self , actor ) : \n if _debug : TCPServerDirector . _debug ( \"<STR_LIT>\" , actor ) \n try : \n del self . servers [ actor . peer ] \n except KeyError : \n TCPServerDirector . _warning ( \"<STR_LIT>\" , actor ) \n if self . serviceElement : \n self . sap_request ( delPeer = actor . peer ) \n def get_actor ( self , address ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . servers . get ( address , None ) \n def indication ( self , pdu ) : \n \"\"\"<STR_LIT>\"\"\" \n if _debug : TCPServerDirector . _debug ( \"<STR_LIT>\" , pdu ) \n addr = pdu . pduDestination \n server = self . servers . get ( addr , None ) \n if not server : \n raise RuntimeError ( \"<STR_LIT>\" ) \n server . indication ( pdu ) \n bacpypes_debugging ( TCPServerDirector ) \n class StreamToPacket ( Client , Server ) : \n def __init__ ( self , fn , cid = None , sid = None ) : \n if _debug : StreamToPacket . _debug ( \"<STR_LIT>\" , fn , cid , sid ) \n Client . __init__ ( self , cid ) \n Server . __init__ ( self , sid ) \n self . packetFn = fn \n self . upstreamBuffer = { } \n self . downstreamBuffer = { } \n def packetize ( self , pdu , streamBuffer ) : \n if _debug : StreamToPacket . _debug ( \"<STR_LIT>\" , pdu ) \n def chop ( addr ) : \n if _debug : StreamToPacket . _debug ( \"<STR_LIT>\" , addr ) \n buff = streamBuffer . get ( addr , '<STR_LIT>' ) + pdu . pduData \n if _debug : StreamToPacket . _debug ( \"<STR_LIT>\" , buff ) \n while <NUM_LIT:1> : \n packet = self . packetFn ( buff ) \n if packet is None : \n break \n yield PDU ( packet [ <NUM_LIT:0> ] , \n source = pdu . pduSource , \n destination = pdu . pduDestination , \n user_data = pdu . pduUserData , \n ) \n buff = packet [ <NUM_LIT:1> ] \n streamBuffer [ addr ] = buff \n if pdu . pduSource : \n for pdu in chop ( pdu . pduSource ) : \n yield pdu \n if pdu . pduDestination : \n for pdu in chop ( pdu . pduDestination ) : \n yield pdu \n def indication ( self , pdu ) : \n \"\"\"<STR_LIT>\"\"\" \n if _debug : StreamToPacket . _debug ( \"<STR_LIT>\" , pdu ) \n for packet in self . packetize ( pdu , self . downstreamBuffer ) : \n self . request ( packet ) \n def confirmation ( self , pdu ) : \n \"\"\"<STR_LIT>\"\"\" \n if _debug : StreamToPacket . _debug ( \"<STR_LIT>\" , pdu ) \n for packet in self . packetize ( pdu , self . upstreamBuffer ) : \n self . response ( packet ) \n bacpypes_debugging ( StreamToPacket ) \n class StreamToPacketSAP ( ApplicationServiceElement , ServiceAccessPoint ) : \n def __init__ ( self , stp , aseID = None , sapID = None ) : \n if _debug : StreamToPacketSAP . _debug ( \"<STR_LIT>\" , stp , aseID , sapID ) \n ApplicationServiceElement . __init__ ( self , aseID ) \n ServiceAccessPoint . __init__ ( self , sapID ) \n self . stp = stp \n def indication ( self , addPeer = None , delPeer = None ) : \n if _debug : StreamToPacketSAP . _debug ( \"<STR_LIT>\" , addPeer , delPeer ) \n if addPeer : \n self . stp . upstreamBuffer [ addPeer ] = '<STR_LIT>' \n self . stp . downstreamBuffer [ addPeer ] = '<STR_LIT>' \n if delPeer : \n del self . stp . upstreamBuffer [ delPeer ] \n del self . stp . downstreamBuffer [ delPeer ] \n if self . serviceElement : \n self . sap_request ( addPeer = addPeer , delPeer = delPeer ) \n bacpypes_debugging ( StreamToPacketSAP ) \n", "gt": "_debug"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import random \n from copy import deepcopy \n from . errors import ConfigurationError \n from . debugging import ModuleLogger , bacpypes_debugging \n from . core import deferred \n from . pdu import Address \n from . comm import Server \n <mask0> = <NUM_LIT:0> \n _log = ModuleLogger ( globals ( ) ) \n @ bacpypes_debugging \n class Network : \n def __init__ ( self , dropPercent = <NUM_LIT:0.0> ) : \n if _debug : Network . _debug ( \"<STR_LIT>\" , dropPercent ) \n self . nodes = [ ] \n self . dropPercent = dropPercent \n def add_node ( self , node ) : \n \"\"\"<STR_LIT>\"\"\" \n if _debug : Network . _debug ( \"<STR_LIT>\" , node ) \n self . nodes . append ( node ) \n node . lan = self \n def remove_node ( self , node ) : \n \"\"\"<STR_LIT>\"\"\" \n if _debug : Network . _debug ( \"<STR_LIT>\" , node ) \n self . nodes . remove ( node ) \n node . lan = None \n def process_pdu ( self , pdu ) : \n \"\"\"<STR_LIT>\"\"\" \n if _debug : Network . _debug ( \"<STR_LIT>\" , pdu ) \n if self . dropPercent != <NUM_LIT:0.0> : \n if ( random . random ( ) * <NUM_LIT> ) < self . dropPercent : \n if _debug : Network . _debug ( \"<STR_LIT>\" ) \n return \n if not pdu . pduDestination or not isinstance ( pdu . pduDestination , Address ) : \n raise RuntimeError ( \"<STR_LIT>\" ) \n elif pdu . pduDestination . addrType == Address . localBroadcastAddr : \n for n in self . nodes : \n if ( pdu . pduSource != n . address ) : \n n . response ( deepcopy ( pdu ) ) \n elif pdu . pduDestination . addrType == Address . localStationAddr : \n for n in self . nodes : \n if n . promiscuous or ( pdu . pduDestination == n . address ) : \n n . response ( deepcopy ( pdu ) ) \n else : \n raise RuntimeError ( \"<STR_LIT>\" ) \n def __len__ ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n if _debug : Network . _debug ( \"<STR_LIT>\" ) \n return len ( self . nodes ) \n @ bacpypes_debugging \n class Node ( Server ) : \n def __init__ ( self , addr , lan = None , promiscuous = False , spoofing = False , sid = None ) : \n if _debug : \n Node . _debug ( \"<STR_LIT>\" , \n addr , lan , promiscuous , spoofing , sid \n ) \n Server . __init__ ( self , sid ) \n if not isinstance ( addr , Address ) : \n raise TypeError ( \"<STR_LIT>\" ) \n self . lan = None \n self . address = addr \n if lan : \n self . bind ( lan ) \n self . promiscuous = promiscuous \n self . spoofing = spoofing \n def bind ( self , lan ) : \n \"\"\"<STR_LIT>\"\"\" \n if _debug : Node . _debug ( \"<STR_LIT>\" , lan ) \n lan . add_node ( self ) \n def indication ( self , pdu ) : \n \"\"\"<STR_LIT>\"\"\" \n if _debug : Node . _debug ( \"<STR_LIT>\" , pdu ) \n if not self . lan : \n raise ConfigurationError ( \"<STR_LIT>\" ) \n if pdu . pduSource is None : \n pdu . pduSource = self . address \n elif ( not self . spoofing ) and ( pdu . pduSource != self . address ) : \n raise RuntimeError ( \"<STR_LIT>\" ) \n deferred ( self . lan . process_pdu , pdu ) \n", "gt": "_debug"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import sys \n from bacpypes . debugging import bacpypes_debugging , ModuleLogger \n from bacpypes . consolelogging import ConfigArgumentParser \n from bacpypes . consolecmd import ConsoleCmd \n from bacpypes . core import run \n from bacpypes . pdu import Address \n from bacpypes . app import LocalDeviceObject , BIPSimpleApplication \n from bacpypes . apdu import Error , AbortPDU , AtomicReadFileRequest , AtomicReadFileRequestAccessMethodChoice , AtomicReadFileRequestAccessMethodChoiceRecordAccess , AtomicReadFileRequestAccessMethodChoiceStreamAccess , AtomicReadFileACK , AtomicWriteFileRequest , AtomicWriteFileRequestAccessMethodChoice , AtomicWriteFileRequestAccessMethodChoiceRecordAccess , AtomicWriteFileRequestAccessMethodChoiceStreamAccess , AtomicWriteFileACK \n from bacpypes . basetypes import ServicesSupported \n <mask0> = <NUM_LIT:0> \n _log = ModuleLogger ( globals ( ) ) \n this_application = None \n @ bacpypes_debugging \n class TestApplication ( BIPSimpleApplication ) : \n def request ( self , apdu ) : \n if _debug : TestApplication . _debug ( \"<STR_LIT>\" , apdu ) \n self . _request = apdu \n BIPSimpleApplication . request ( self , apdu ) \n def confirmation ( self , apdu ) : \n if _debug : TestApplication . _debug ( \"<STR_LIT>\" , apdu ) \n if isinstance ( apdu , Error ) : \n sys . stdout . write ( \"<STR_LIT>\" % ( apdu . errorCode , ) ) \n sys . stdout . flush ( ) \n elif isinstance ( apdu , AbortPDU ) : \n apdu . debug_contents ( ) \n elif ( isinstance ( self . _request , AtomicReadFileRequest ) ) and ( isinstance ( apdu , AtomicReadFileACK ) ) : \n if apdu . accessMethod . recordAccess : \n value = apdu . accessMethod . recordAccess . fileRecordData \n elif apdu . accessMethod . streamAccess : \n value = apdu . accessMethod . streamAccess . fileData \n TestApplication . _debug ( \"<STR_LIT>\" , value ) \n sys . stdout . write ( repr ( value ) + '<STR_LIT:\\n>' ) \n sys . stdout . flush ( ) \n elif ( isinstance ( self . _request , AtomicWriteFileRequest ) ) and ( isinstance ( apdu , AtomicWriteFileACK ) ) : \n if apdu . fileStartPosition is not None : \n value = apdu . fileStartPosition \n elif apdu . fileStartRecord is not None : \n value = apdu . fileStartRecord \n TestApplication . _debug ( \"<STR_LIT>\" , value ) \n sys . stdout . write ( repr ( value ) + '<STR_LIT:\\n>' ) \n sys . stdout . flush ( ) \n @ bacpypes_debugging \n class TestConsoleCmd ( ConsoleCmd ) : \n def do_readrecord ( self , args ) : \n \"\"\"<STR_LIT>\"\"\" \n args = args . split ( ) \n if _debug : TestConsoleCmd . _debug ( \"<STR_LIT>\" , args ) \n try : \n addr , obj_inst , start_record , record_count = args \n obj_type = '<STR_LIT:file>' \n obj_inst = int ( obj_inst ) \n start_record = int ( start_record ) \n record_count = int ( record_count ) \n request = AtomicReadFileRequest ( \n fileIdentifier = ( obj_type , obj_inst ) , \n accessMethod = AtomicReadFileRequestAccessMethodChoice ( \n recordAccess = AtomicReadFileRequestAccessMethodChoiceRecordAccess ( \n fileStartRecord = start_record , \n requestedRecordCount = record_count , \n ) , \n ) , \n ) \n request . pduDestination = Address ( addr ) \n if _debug : TestConsoleCmd . _debug ( \"<STR_LIT>\" , request ) \n this_application . request ( request ) \n except Exception , e : \n TestConsoleCmd . _exception ( \"<STR_LIT>\" , e ) \n def do_readstream ( self , args ) : \n \"\"\"<STR_LIT>\"\"\" \n args = args . split ( ) \n if _debug : TestConsoleCmd . _debug ( \"<STR_LIT>\" , args ) \n try : \n addr , obj_inst , start_position , octet_count = args \n obj_type = '<STR_LIT:file>' \n obj_inst = int ( obj_inst ) \n start_position = int ( start_position ) \n octet_count = int ( octet_count ) \n request = AtomicReadFileRequest ( \n fileIdentifier = ( obj_type , obj_inst ) , \n accessMethod = AtomicReadFileRequestAccessMethodChoice ( \n streamAccess = AtomicReadFileRequestAccessMethodChoiceStreamAccess ( \n fileStartPosition = start_position , \n requestedOctetCount = octet_count , \n ) , \n ) , \n ) \n request . pduDestination = Address ( addr ) \n if _debug : TestConsoleCmd . _debug ( \"<STR_LIT>\" , request ) \n this_application . request ( request ) \n except Exception , e : \n TestConsoleCmd . _exception ( \"<STR_LIT>\" , e ) \n def do_writerecord ( self , args ) : \n \"\"\"<STR_LIT>\"\"\" \n args = args . split ( ) \n if _debug : TestConsoleCmd . _debug ( \"<STR_LIT>\" , args ) \n try : \n addr , obj_inst , start_record , record_count = args [ <NUM_LIT:0> : <NUM_LIT:4> ] \n obj_type = '<STR_LIT:file>' \n obj_inst = int ( obj_inst ) \n start_record = int ( start_record ) \n record_count = int ( record_count ) \n record_data = list ( args [ <NUM_LIT:4> : ] ) \n request = AtomicWriteFileRequest ( \n fileIdentifier = ( obj_type , obj_inst ) , \n accessMethod = AtomicWriteFileRequestAccessMethodChoice ( \n recordAccess = AtomicWriteFileRequestAccessMethodChoiceRecordAccess ( \n fileStartRecord = start_record , \n recordCount = record_count , \n fileRecordData = record_data , \n ) , \n ) , \n ) \n request . pduDestination = Address ( addr ) \n if _debug : TestConsoleCmd . _debug ( \"<STR_LIT>\" , request ) \n this_application . request ( request ) \n except Exception , e : \n TestConsoleCmd . _exception ( \"<STR_LIT>\" , e ) \n def do_writestream ( self , args ) : \n \"\"\"<STR_LIT>\"\"\" \n args = args . split ( ) \n if _debug : TestConsoleCmd . _debug ( \"<STR_LIT>\" , args ) \n try : \n addr , obj_inst , start_position , data = args \n obj_type = '<STR_LIT:file>' \n obj_inst = int ( obj_inst ) \n start_position = int ( start_position ) \n request = AtomicWriteFileRequest ( \n fileIdentifier = ( obj_type , obj_inst ) , \n accessMethod = AtomicWriteFileRequestAccessMethodChoice ( \n streamAccess = AtomicWriteFileRequestAccessMethodChoiceStreamAccess ( \n fileStartPosition = start_position , \n fileData = data , \n ) , \n ) , \n ) \n request . pduDestination = Address ( addr ) \n if _debug : TestConsoleCmd . _debug ( \"<STR_LIT>\" , request ) \n this_application . request ( request ) \n except Exception , e : \n TestConsoleCmd . _exception ( \"<STR_LIT>\" , e ) \n try : \n args = ConfigArgumentParser ( description = __doc__ ) . parse_args ( ) \n if _debug : _log . debug ( \"<STR_LIT>\" ) \n if _debug : _log . debug ( \"<STR_LIT>\" , args ) \n this_device = LocalDeviceObject ( \n objectName = args . ini . objectname , \n objectIdentifier = int ( args . ini . objectidentifier ) , \n maxApduLengthAccepted = int ( args . ini . maxapdulengthaccepted ) , \n segmentationSupported = args . ini . segmentationsupported , \n vendorIdentifier = int ( args . ini . vendoridentifier ) , \n ) \n this_application = TestApplication ( this_device , args . ini . address ) \n services_supported = this_application . get_services_supported ( ) \n if _debug : _log . debug ( \"<STR_LIT>\" , services_supported ) \n this_device . protocolServicesSupported = services_supported . value \n this_console = TestConsoleCmd ( ) \n _log . debug ( \"<STR_LIT>\" ) \n run ( ) \n except Exception , e : \n _log . exception ( \"<STR_LIT>\" , e ) \n finally : \n _log . debug ( \"<STR_LIT>\" ) \n", "gt": "_debug"}
{"input": "\n from __future__ import division , unicode_literals \n import os \n import hashlib \n import logging \n from collections import defaultdict \n from . bencode import bencode , bdecode \n from . humanize import humanize_bytes \n from . utils import is_unsplitable , get_root_of_unsplitable , Pieces \n <mask0> = logging . getLogger ( '<STR_LIT>' ) \n class Color : \n BLACK = '<STR_LIT>' \n RED = '<STR_LIT>' \n GREEN = '<STR_LIT>' \n YELLOW = '<STR_LIT>' \n BLUE = '<STR_LIT>' \n PINK = '<STR_LIT>' \n CYAN = '<STR_LIT>' \n WHITE = '<STR_LIT>' \n ENDC = '<STR_LIT>' \n COLOR_OK = Color . GREEN \n COLOR_MISSING_FILES = Color . RED \n COLOR_ALREADY_SEEDING = Color . BLUE \n COLOR_FOLDER_EXIST_NOT_SEEDING = Color . YELLOW \n COLOR_FAILED_TO_ADD_TO_CLIENT = Color . PINK \n class Status : \n OK = <NUM_LIT:0> \n MISSING_FILES = <NUM_LIT:1> \n ALREADY_SEEDING = <NUM_LIT:2> \n FOLDER_EXIST_NOT_SEEDING = <NUM_LIT:3> \n FAILED_TO_ADD_TO_CLIENT = <NUM_LIT:4> \n status_messages = { \n Status . OK : '<STR_LIT>' % ( COLOR_OK , Color . ENDC ) , \n Status . MISSING_FILES : '<STR_LIT>' % ( COLOR_MISSING_FILES , Color . ENDC ) , \n Status . ALREADY_SEEDING : '<STR_LIT>' % ( COLOR_ALREADY_SEEDING , Color . ENDC ) , \n Status . FOLDER_EXIST_NOT_SEEDING : '<STR_LIT>' % ( COLOR_FOLDER_EXIST_NOT_SEEDING , Color . ENDC ) , \n Status . FAILED_TO_ADD_TO_CLIENT : '<STR_LIT>' % ( COLOR_FAILED_TO_ADD_TO_CLIENT , Color . ENDC ) , \n } \n CHUNK_SIZE = <NUM_LIT> \n class UnknownLinkTypeException ( Exception ) : \n pass \n class IllegalPathException ( Exception ) : \n pass \n class AutoTorrent ( object ) : \n def __init__ ( self , db , client , store_path , add_limit_size , add_limit_percent , delete_torrents , link_type = '<STR_LIT>' ) : \n self . db = db \n self . client = client \n self . store_path = store_path \n self . add_limit_size = add_limit_size \n self . add_limit_percent = add_limit_percent \n self . delete_torrents = delete_torrents \n self . link_type = link_type \n self . torrents_seeded = set ( ) \n def try_decode ( self , value ) : \n try : \n return value . decode ( '<STR_LIT:utf-8>' ) \n except UnicodeDecodeError : \n logger . debug ( '<STR_LIT>' % value ) \n return value . decode ( '<STR_LIT>' ) \n def is_legal_path ( self , path ) : \n for p in path : \n if p in [ '<STR_LIT:.>' , '<STR_LIT:..>' ] or '<STR_LIT:/>' in p : \n return False \n return True \n def populate_torrents_seeded ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n self . torrents_seeded = set ( x . lower ( ) for x in self . client . get_torrents ( ) ) \n def get_info_hash ( self , torrent ) : \n \"\"\"<STR_LIT>\"\"\" \n return hashlib . sha1 ( bencode ( torrent [ b'<STR_LIT:info>' ] ) ) . hexdigest ( ) \n def find_hash_checks ( self , torrent , result ) : \n \"\"\"<STR_LIT>\"\"\" \n modified_result = False \n pieces = Pieces ( torrent ) \n if self . db . hash_slow_mode : \n logger . info ( '<STR_LIT>' ) \n self . db . build_hash_size_table ( ) \n start_size = <NUM_LIT:0> \n end_size = <NUM_LIT:0> \n logger . info ( '<STR_LIT>' ) \n for f in result : \n start_size = end_size \n end_size += f [ '<STR_LIT>' ] \n if f [ '<STR_LIT>' ] : \n continue \n files_to_check = [ ] \n logger . debug ( '<STR_LIT>' ) \n if self . db . hash_size_mode : \n logger . debug ( '<STR_LIT>' ) \n files_to_check += self . db . find_hash_size ( f [ '<STR_LIT>' ] ) \n if self . db . hash_name_mode : \n logger . debug ( '<STR_LIT>' ) \n name = f [ '<STR_LIT:path>' ] [ - <NUM_LIT:1> ] \n files_to_check += self . db . find_hash_name ( name ) \n if self . db . hash_slow_mode : \n logger . debug ( '<STR_LIT>' ) \n files_to_check += self . db . find_hash_varying_size ( f [ '<STR_LIT>' ] ) \n logger . debug ( '<STR_LIT>' % len ( files_to_check ) ) \n checked_files = set ( ) \n for db_file in files_to_check : \n if db_file in checked_files : \n logger . debug ( '<STR_LIT>' % db_file ) \n checked_files . add ( db_file ) \n logger . info ( '<STR_LIT>' % db_file ) \n match_start , match_end = pieces . match_file ( db_file , start_size , end_size ) \n logger . info ( '<STR_LIT>' % ( db_file , match_start , match_end ) ) \n if match_start or match_end : \n size = os . path . getsize ( db_file ) \n if size != f [ '<STR_LIT>' ] : \n logger . debug ( '<STR_LIT>' ) \n if match_start and match_end : \n logger . debug ( '<STR_LIT>' ) \n modification_point = pieces . find_piece_breakpoint ( db_file , start_size , end_size ) \n elif match_start : \n logger . debug ( '<STR_LIT>' ) \n modification_point = min ( f [ '<STR_LIT>' ] , size ) \n elif match_end : \n logger . debug ( '<STR_LIT>' ) \n modification_point = <NUM_LIT:0> \n if size > f [ '<STR_LIT>' ] : \n modification_action = '<STR_LIT>' \n else : \n modification_action = '<STR_LIT>' \n f [ '<STR_LIT>' ] = False \n f [ '<STR_LIT>' ] = ( '<STR_LIT>' , modification_action , modification_point ) \n modified_result = True \n else : \n logger . debug ( '<STR_LIT>' ) \n f [ '<STR_LIT>' ] = True \n f [ '<STR_LIT>' ] = db_file \n break \n return modified_result , result \n def index_torrent ( self , torrent ) : \n \"\"\"<STR_LIT>\"\"\" \n torrent_name = torrent [ b'<STR_LIT:info>' ] [ b'<STR_LIT:name>' ] \n logger . debug ( '<STR_LIT>' % ( torrent_name , ) ) \n torrent_name = self . try_decode ( torrent_name ) \n if not self . is_legal_path ( [ torrent_name ] ) : \n raise IllegalPathException ( '<STR_LIT>' % torrent_name ) \n logger . info ( '<STR_LIT>' % torrent_name ) \n if self . db . exact_mode : \n prefix = '<STR_LIT:d>' if b'<STR_LIT>' in torrent [ b'<STR_LIT:info>' ] else '<STR_LIT:f>' \n paths = self . db . find_exact_file_path ( prefix , torrent_name ) \n if paths : \n for path in paths : \n logger . debug ( '<STR_LIT>' % path ) \n if prefix == '<STR_LIT:f>' : \n logger . info ( '<STR_LIT>' ) \n size = os . path . getsize ( path ) \n if torrent [ b'<STR_LIT:info>' ] [ b'<STR_LIT>' ] != size : \n continue \n return { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : os . path . dirname ( path ) , \n '<STR_LIT>' : [ { \n '<STR_LIT>' : path , \n '<STR_LIT>' : size , \n '<STR_LIT:path>' : [ torrent_name ] , \n '<STR_LIT>' : True , \n } ] } \n else : \n result = [ ] \n for f in torrent [ b'<STR_LIT:info>' ] [ b'<STR_LIT>' ] : \n orig_path = [ self . try_decode ( x ) for x in f [ b'<STR_LIT:path>' ] ] \n p = os . path . join ( path , * orig_path ) \n if not os . path . isfile ( p ) : \n logger . debug ( '<STR_LIT>' % p ) \n break \n size = os . path . getsize ( p ) \n if size != f [ b'<STR_LIT>' ] : \n logger . debug ( '<STR_LIT>' % ( p , size , f [ b'<STR_LIT>' ] ) ) \n break \n result . append ( { \n '<STR_LIT>' : p , \n '<STR_LIT>' : f [ b'<STR_LIT>' ] , \n '<STR_LIT:path>' : orig_path , \n '<STR_LIT>' : True , \n } ) \n else : \n logger . info ( '<STR_LIT>' ) \n return { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : path , \n '<STR_LIT>' : result } \n result = [ ] \n if b'<STR_LIT>' in torrent [ b'<STR_LIT:info>' ] : \n files_sorted = { } \n files = { } \n if b'<STR_LIT>' in torrent [ b'<STR_LIT:info>' ] : \n i = <NUM_LIT:0> \n path_files = defaultdict ( list ) \n for f in torrent [ b'<STR_LIT:info>' ] [ b'<STR_LIT>' ] : \n logger . debug ( '<STR_LIT>' % ( f , ) ) \n orig_path = [ self . try_decode ( x ) for x in f [ b'<STR_LIT:path>' ] if x ] \n if not self . is_legal_path ( orig_path ) : \n raise IllegalPathException ( '<STR_LIT>' % orig_path ) \n path = [ torrent_name ] + orig_path \n name = path . pop ( ) \n path_files [ os . path . join ( * path ) ] . append ( { \n '<STR_LIT:path>' : orig_path , \n '<STR_LIT>' : f [ b'<STR_LIT>' ] , \n } ) \n files_sorted [ '<STR_LIT:/>' . join ( orig_path ) ] = i \n i += <NUM_LIT:1> \n if self . db . unsplitable_mode : \n unsplitable_paths = set ( ) \n for path , files in path_files . items ( ) : \n if is_unsplitable ( f [ '<STR_LIT:path>' ] [ - <NUM_LIT:1> ] for f in files ) : \n path = path . split ( os . sep ) \n name = get_root_of_unsplitable ( path ) \n if not name : \n continue \n while path [ - <NUM_LIT:1> ] != name : \n path . pop ( ) \n unsplitable_paths . add ( os . path . join ( * path ) ) \n for path , files in path_files . items ( ) : \n if self . db . unsplitable_mode : \n path = path . split ( os . sep ) \n while path and os . path . join ( * path ) not in unsplitable_paths : \n path . pop ( ) \n else : \n path = None \n if path : \n name = path [ - <NUM_LIT:1> ] \n for f in files : \n actual_path = self . db . find_unsplitable_file_path ( name , f [ '<STR_LIT:path>' ] , f [ '<STR_LIT>' ] ) \n f [ '<STR_LIT>' ] = actual_path \n f [ '<STR_LIT>' ] = actual_path is not None \n result += files \n else : \n for f in files : \n actual_path = self . db . find_file_path ( f [ '<STR_LIT:path>' ] [ - <NUM_LIT:1> ] , f [ '<STR_LIT>' ] ) \n f [ '<STR_LIT>' ] = actual_path \n f [ '<STR_LIT>' ] = actual_path is not None \n result += files \n result = sorted ( result , key = lambda x : files_sorted [ '<STR_LIT:/>' . join ( x [ '<STR_LIT:path>' ] ) ] ) \n else : \n length = torrent [ b'<STR_LIT:info>' ] [ b'<STR_LIT>' ] \n actual_path = self . db . find_file_path ( torrent_name , length ) \n result . append ( { \n '<STR_LIT>' : actual_path , \n '<STR_LIT>' : length , \n '<STR_LIT:path>' : [ torrent_name ] , \n '<STR_LIT>' : actual_path is not None , \n } ) \n mode = '<STR_LIT>' \n if self . db . hash_mode : \n modified_result , result = self . find_hash_checks ( torrent , result ) \n if modified_result : \n mode = '<STR_LIT>' \n return { '<STR_LIT>' : mode , '<STR_LIT>' : result } \n def parse_torrent ( self , torrent ) : \n \"\"\"<STR_LIT>\"\"\" \n files = self . index_torrent ( torrent ) \n found_size , missing_size = <NUM_LIT:0> , <NUM_LIT:0> \n for f in files [ '<STR_LIT>' ] : \n if f [ '<STR_LIT>' ] or f . get ( '<STR_LIT>' ) : \n found_size += f [ '<STR_LIT>' ] \n else : \n missing_size += f [ '<STR_LIT>' ] \n return found_size , missing_size , files \n def link_files ( self , destination_path , files ) : \n \"\"\"<STR_LIT>\"\"\" \n if not os . path . isdir ( destination_path ) : \n os . makedirs ( destination_path ) \n for f in files : \n if f [ '<STR_LIT>' ] : \n destination = os . path . join ( destination_path , * f [ '<STR_LIT:path>' ] ) \n file_path = os . path . dirname ( destination ) \n if not os . path . isdir ( file_path ) : \n logger . debug ( '<STR_LIT>' % file_path ) \n os . makedirs ( file_path ) \n logger . debug ( '<STR_LIT>' % ( self . link_type , f [ '<STR_LIT>' ] , destination ) ) \n if self . link_type == '<STR_LIT>' : \n os . symlink ( f [ '<STR_LIT>' ] , destination ) \n elif self . link_type == '<STR_LIT>' : \n os . link ( f [ '<STR_LIT>' ] , destination ) \n else : \n raise UnknownLinkTypeException ( '<STR_LIT>' % self . link_type ) \n def rewrite_hashed_files ( self , destination_path , files ) : \n \"\"\"<STR_LIT>\"\"\" \n if not os . path . isdir ( destination_path ) : \n os . makedirs ( destination_path ) \n for f in files : \n if not f [ '<STR_LIT>' ] and '<STR_LIT>' in f : \n destination = os . path . join ( destination_path , * f [ '<STR_LIT:path>' ] ) \n file_path = os . path . dirname ( destination ) \n if not os . path . isdir ( file_path ) : \n logger . debug ( '<STR_LIT>' % file_path ) \n os . makedirs ( file_path ) \n logger . debug ( '<STR_LIT>' % ( f [ '<STR_LIT>' ] , destination ) ) \n _ , modification_action , modification_point = f [ '<STR_LIT>' ] \n current_size = os . path . getsize ( f [ '<STR_LIT>' ] ) \n expected_size = f [ '<STR_LIT>' ] \n diff = abs ( current_size - expected_size ) \n modified = False \n bytes_written = <NUM_LIT:0> \n with open ( destination , '<STR_LIT:wb>' ) as output_fp : \n with open ( f [ '<STR_LIT>' ] , '<STR_LIT:rb>' ) as input_fp : \n logger . debug ( '<STR_LIT>' % ( f [ '<STR_LIT>' ] , destination , modification_point ) ) \n while True : \n if not modified and bytes_written == modification_point : \n logger . debug ( '<STR_LIT>' % ( modification_action , diff ) ) \n modified = True \n if modification_action == '<STR_LIT>' : \n seek_point = bytes_written + diff \n logger . debug ( '<STR_LIT>' % ( seek_point , ) ) \n input_fp . seek ( seek_point ) \n elif modification_action == '<STR_LIT>' : \n logger . debug ( '<STR_LIT>' % diff ) \n while diff > <NUM_LIT:0> : \n write_bytes = min ( CHUNK_SIZE , diff ) \n output_fp . write ( b'<STR_LIT:\\x00>' * write_bytes ) \n diff -= write_bytes \n read_bytes = CHUNK_SIZE \n if not modified : \n read_bytes = min ( read_bytes , modification_point - bytes_written ) \n logger . debug ( '<STR_LIT>' % ( read_bytes , ) ) \n data = input_fp . read ( read_bytes ) \n if not data : \n break \n output_fp . write ( data ) \n bytes_written += read_bytes \n logger . debug ( '<STR_LIT>' ) \n def handle_torrentfile ( self , path , dry_run = False ) : \n \"\"\"<STR_LIT>\"\"\" \n logger . info ( '<STR_LIT>' % path ) \n torrent = self . open_torrentfile ( path ) \n if self . check_torrent_in_client ( torrent ) : \n self . print_status ( Status . ALREADY_SEEDING , path , '<STR_LIT>' ) \n if self . delete_torrents : \n logger . info ( '<STR_LIT>' % path ) \n os . remove ( path ) \n return Status . ALREADY_SEEDING \n found_size , missing_size , files = self . parse_torrent ( torrent ) \n missing_percent = ( missing_size / ( found_size + missing_size ) ) * <NUM_LIT:100> \n found_percent = <NUM_LIT:100> - missing_percent \n would_not_add = missing_size and missing_percent > self . add_limit_percent or missing_size > self . add_limit_size \n if dry_run : \n return found_size , missing_size , would_not_add , [ f [ '<STR_LIT>' ] for f in files [ '<STR_LIT>' ] if f . get ( '<STR_LIT>' ) ] \n if would_not_add : \n logger . info ( '<STR_LIT>' % ( path , found_percent , humanize_bytes ( missing_size ) ) ) \n self . print_status ( Status . MISSING_FILES , path , '<STR_LIT>' % ( found_percent , humanize_bytes ( missing_size ) ) ) \n return Status . MISSING_FILES \n if files [ '<STR_LIT>' ] == '<STR_LIT>' or files [ '<STR_LIT>' ] == '<STR_LIT>' : \n logger . info ( '<STR_LIT>' ) \n destination_path = os . path . join ( self . store_path , os . path . splitext ( os . path . basename ( path ) ) [ <NUM_LIT:0> ] ) \n if os . path . isdir ( destination_path ) : \n logger . info ( '<STR_LIT>' % destination_path ) \n self . print_status ( Status . FOLDER_EXIST_NOT_SEEDING , path , '<STR_LIT>' ) \n return Status . FOLDER_EXIST_NOT_SEEDING \n self . link_files ( destination_path , files [ '<STR_LIT>' ] ) \n elif files [ '<STR_LIT>' ] == '<STR_LIT>' : \n logger . info ( '<STR_LIT>' ) \n destination_path = files [ '<STR_LIT>' ] \n fast_resume = True \n if files [ '<STR_LIT>' ] == '<STR_LIT>' : \n fast_resume = False \n logger . info ( '<STR_LIT>' ) \n self . rewrite_hashed_files ( destination_path , files [ '<STR_LIT>' ] ) \n if self . delete_torrents : \n logger . info ( '<STR_LIT>' % path ) \n os . remove ( path ) \n if self . client . add_torrent ( torrent , destination_path , files [ '<STR_LIT>' ] , fast_resume ) : \n self . print_status ( Status . OK , path , '<STR_LIT>' ) \n return Status . OK \n else : \n self . print_status ( Status . FAILED_TO_ADD_TO_CLIENT , path , '<STR_LIT>' ) \n return Status . FAILED_TO_ADD_TO_CLIENT \n def check_torrent_in_client ( self , torrent ) : \n \"\"\"<STR_LIT>\"\"\" \n info_hash = self . get_info_hash ( torrent ) \n return info_hash in self . torrents_seeded \n def open_torrentfile ( self , path ) : \n \"\"\"<STR_LIT>\"\"\" \n with open ( path , '<STR_LIT:rb>' ) as f : \n return bdecode ( f . read ( ) ) \n def print_status ( self , status , torrentfile , message ) : \n print ( '<STR_LIT>' % ( '<STR_LIT>' % status_messages [ status ] , os . path . splitext ( os . path . basename ( torrentfile ) ) [ <NUM_LIT:0> ] , message ) ) \n", "gt": "logger"}
{"input": "\n import os \n import legofy \n import tkinter as tk \n import tkinter . ttk as ttk \n from tkinter import filedialog \n import tkinter . messagebox as tkmsg \n <mask0> = ( '<STR_LIT:none>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT:all>' , ) \n class LegofyGui ( tk . Tk ) : \n def __init__ ( self , * args , ** kwargs ) : \n super ( ) . __init__ ( * args , ** kwargs ) \n self . wm_title ( \"<STR_LIT>\" ) \n self . iconbitmap ( os . path . dirname ( os . path . realpath ( __file__ ) ) + '<STR_LIT>' ) \n self . resizable ( False , False ) \n self . body = LegofyGuiMainFrame ( self ) \n self . body . grid ( row = <NUM_LIT:0> , column = <NUM_LIT:0> , padx = <NUM_LIT:10> , pady = <NUM_LIT:10> ) \n class LegofyGuiMainFrame ( tk . Frame ) : \n def __init__ ( self , * args , ** kwargs ) : \n super ( ) . __init__ ( * args , ** kwargs ) \n self . chosenFile = None \n self . chosenFilePath = tk . StringVar ( ) \n self . pathField = tk . Entry ( self , width = <NUM_LIT> , textvariable = self . chosenFilePath , state = tk . DISABLED ) \n self . pathField . grid ( row = <NUM_LIT:0> , column = <NUM_LIT:0> , padx = <NUM_LIT:10> ) \n self . selectFile = tk . Button ( self , text = \"<STR_LIT>\" , command = self . choose_a_file ) \n self . selectFile . grid ( row = <NUM_LIT:0> , column = <NUM_LIT:1> ) \n self . groupFrame = tk . LabelFrame ( self , text = \"<STR_LIT>\" , padx = <NUM_LIT:5> , pady = <NUM_LIT:5> ) \n self . groupFrame . grid ( row = <NUM_LIT:1> , column = <NUM_LIT:0> , columnspan = <NUM_LIT:2> , ) \n self . colorPaletteLabel = tk . Label ( self . groupFrame , text = '<STR_LIT>' ) \n self . colorPaletteLabel . grid ( row = <NUM_LIT:0> , column = <NUM_LIT:0> ) \n self . colorPalette = ttk . Combobox ( self . groupFrame ) \n self . colorPalette [ '<STR_LIT>' ] = LEGO_PALETTE \n self . colorPalette . current ( <NUM_LIT:0> ) \n self . colorPalette . grid ( row = <NUM_LIT:0> , column = <NUM_LIT:1> ) \n self . brickNumberScale = tk . Scale ( self . groupFrame , from_ = <NUM_LIT:1> , to = <NUM_LIT:200> , orient = tk . HORIZONTAL , label = \"<STR_LIT>\" , length = <NUM_LIT> ) \n self . brickNumberScale . set ( <NUM_LIT:30> ) \n self . brickNumberScale . grid ( row = <NUM_LIT:1> , column = <NUM_LIT:0> , columnspan = <NUM_LIT:2> , ) \n self . convertFile = tk . Button ( text = \"<STR_LIT>\" , command = self . convert_file ) \n self . convertFile . grid ( row = <NUM_LIT:2> , column = <NUM_LIT:0> , columnspan = <NUM_LIT:2> ) \n def choose_a_file ( self ) : \n options = { } \n options [ '<STR_LIT>' ] = '<STR_LIT>' \n options [ '<STR_LIT>' ] = [ ( '<STR_LIT>' , '<STR_LIT>' ) , \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ( '<STR_LIT>' , '<STR_LIT>' ) , ] \n options [ '<STR_LIT>' ] = os . path . realpath ( \"<STR_LIT:\\\\>\" ) \n options [ '<STR_LIT>' ] = '<STR_LIT>' \n options [ '<STR_LIT>' ] = self \n options [ '<STR_LIT:title>' ] = '<STR_LIT>' \n self . chosenFile = filedialog . askopenfile ( mode = '<STR_LIT:r>' , ** options ) \n if self . chosenFile : \n self . chosenFilePath . set ( self . chosenFile . name ) \n def convert_file ( self ) : \n try : \n if self . chosenFile is not None : \n palette = self . colorPalette . get ( ) \n if palette in LEGO_PALETTE and palette != '<STR_LIT:none>' : \n legofy . main ( self . chosenFile . name , size = self . brickNumberScale . get ( ) , palette_mode = palette ) \n else : \n legofy . main ( self . chosenFile . name , size = self . brickNumberScale . get ( ) ) \n tkmsg . showinfo ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n else : \n tkmsg . showerror ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n except Exception as e : \n tkmsg . showerror ( \"<STR_LIT>\" , str ( e ) ) \n if __name__ == '<STR_LIT:__main__>' : \n app = LegofyGui ( ) \n app . mainloop ( ) \n", "gt": "LEGO_PALETTE"}
{"input": "\n from distutils . core import setup \n from condent import __version__ \n with open ( \"<STR_LIT>\" ) as readme : \n <mask0> = readme . read ( ) \n classifiers = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n setup ( \n name = \"<STR_LIT>\" , \n version = __version__ , \n py_modules = [ \"<STR_LIT>\" ] , \n scripts = [ \"<STR_LIT>\" ] , \n author = \"<STR_LIT>\" , \n author_email = \"<STR_LIT>\" , \n classifiers = classifiers , \n description = \"<STR_LIT>\" , \n license = \"<STR_LIT>\" , \n long_description = long_description , \n url = \"<STR_LIT>\" , \n ) \n", "gt": "long_description"}
{"input": "\n from pyvi import window \n from pyvi . modes import normal \n class Editor ( object ) : \n <mask0> = None \n active_tab = None \n def __init__ ( self , tabs = None , config = None , normal = normal ) : \n self . config = config \n self . mode = self . normal = normal \n self . count = None \n if tabs is None : \n tabs = self . tabs = [ window . Tab ( self ) ] \n else : \n tabs = self . tabs = list ( tabs ) \n if tabs : \n self . active_tab = tabs [ <NUM_LIT:0> ] \n @ property \n def active_window ( self ) : \n return self . active_tab . active_window \n def keypress ( self , keys ) : \n return self . mode . keypress ( self , keys ) \n", "gt": "_command"}
{"input": "\n from collections import deque \n from contextlib import contextmanager \n import json \n from jsonschema import FormatChecker , ValidationError \n from jsonschema . tests . compat import mock , unittest \n from jsonschema . validators import ( \n RefResolutionError , UnknownType , Draft3Validator , \n Draft4Validator , RefResolver , create , extend , validator_for , validate , \n ) \n class TestCreateAndExtend ( unittest . TestCase ) : \n def setUp ( self ) : \n self . meta_schema = { u\"<STR_LIT>\" : { u\"<STR_LIT>\" : { } } } \n self . smelly = mock . MagicMock ( ) \n self . validators = { u\"<STR_LIT>\" : self . smelly } \n self . types = { u\"<STR_LIT>\" : dict } \n self . Validator = create ( \n meta_schema = self . meta_schema , \n validators = self . validators , \n default_types = self . types , \n ) \n self . validator_value = <<mask0>:12> \n self . schema = { u\"<STR_LIT>\" : self . validator_value } \n self . validator = self . Validator ( self . schema ) \n def test_attrs ( self ) : \n self . assertEqual ( self . Validator . VALIDATORS , self . validators ) \n self . assertEqual ( self . Validator . META_SCHEMA , self . meta_schema ) \n self . assertEqual ( self . Validator . DEFAULT_TYPES , self . types ) \n def test_init ( self ) : \n self . assertEqual ( self . validator . schema , self . schema ) \n def test_iter_errors ( self ) : \n instance = \"<STR_LIT:hello>\" \n self . smelly . return_value = [ ] \n self . assertEqual ( list ( self . validator . iter_errors ( instance ) ) , [ ] ) \n error = mock . Mock ( ) \n self . smelly . return_value = [ error ] \n self . assertEqual ( list ( self . validator . iter_errors ( instance ) ) , [ error ] ) \n self . smelly . assert_called_with ( \n self . validator , self . validator_value , instance , self . schema , \n ) \n def test_if_a_version_is_provided_it_is_registered ( self ) : \n with mock . patch ( \"<STR_LIT>\" ) as validates : \n validates . side_effect = lambda version : lambda cls : cls \n Validator = create ( meta_schema = { u\"<STR_LIT:id>\" : \"<STR_LIT>\" } , version = \"<STR_LIT>\" ) \n validates . assert_called_once_with ( \"<STR_LIT>\" ) \n self . assertEqual ( Validator . __name__ , \"<STR_LIT>\" ) \n def test_if_a_version_is_not_provided_it_is_not_registered ( self ) : \n with mock . patch ( \"<STR_LIT>\" ) as validates : \n create ( meta_schema = { u\"<STR_LIT:id>\" : \"<STR_LIT:id>\" } ) \n self . assertFalse ( validates . called ) \n def test_extend ( self ) : \n validators = dict ( self . Validator . VALIDATORS ) \n new = mock . Mock ( ) \n Extended = extend ( self . Validator , validators = { u\"<STR_LIT>\" : new } ) \n validators . update ( [ ( u\"<STR_LIT>\" , new ) ] ) \n self . assertEqual ( Extended . VALIDATORS , validators ) \n self . assertNotIn ( u\"<STR_LIT>\" , self . Validator . VALIDATORS ) \n self . assertEqual ( Extended . META_SCHEMA , self . Validator . META_SCHEMA ) \n self . assertEqual ( Extended . DEFAULT_TYPES , self . Validator . DEFAULT_TYPES ) \n class TestIterErrors ( unittest . TestCase ) : \n def setUp ( self ) : \n self . validator = Draft3Validator ( { } ) \n def test_iter_errors ( self ) : \n instance = [ <NUM_LIT:1> , <NUM_LIT:2> ] \n schema = { \n u\"<STR_LIT>\" : u\"<STR_LIT>\" , \n u\"<STR_LIT>\" : [ [ \"<STR_LIT:a>\" , \"<STR_LIT:b>\" , \"<STR_LIT:c>\" ] , [ \"<STR_LIT:d>\" , \"<STR_LIT:e>\" , \"<STR_LIT:f>\" ] ] , \n u\"<STR_LIT>\" : <NUM_LIT:3> \n } \n got = ( e . message for e in self . validator . iter_errors ( instance , schema ) ) \n expected = [ \n \"<STR_LIT>\" % ( schema [ \"<STR_LIT>\" ] , ) , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" % ( schema [ \"<STR_LIT>\" ] , ) , \n ] \n self . assertEqual ( sorted ( got ) , sorted ( expected ) ) \n def test_iter_errors_multiple_failures_one_validator ( self ) : \n instance = { \"<STR_LIT:foo>\" : <NUM_LIT:2> , \"<STR_LIT:bar>\" : [ <NUM_LIT:1> ] , \"<STR_LIT>\" : <NUM_LIT:15> , \"<STR_LIT>\" : \"<STR_LIT>\" } \n schema = { \n u\"<STR_LIT>\" : { \n \"<STR_LIT:foo>\" : { u\"<STR_LIT:type>\" : \"<STR_LIT:string>\" } , \n \"<STR_LIT:bar>\" : { u\"<STR_LIT>\" : <NUM_LIT:2> } , \n \"<STR_LIT>\" : { u\"<STR_LIT>\" : <NUM_LIT:10> , u\"<STR_LIT>\" : [ <NUM_LIT:2> , <NUM_LIT:4> , <NUM_LIT:6> , <NUM_LIT:8> ] } , \n } \n } \n errors = list ( self . validator . iter_errors ( instance , schema ) ) \n self . assertEqual ( len ( errors ) , <NUM_LIT:4> ) \n class TestValidationErrorMessages ( unittest . TestCase ) : \n def message_for ( self , instance , schema , * args , ** kwargs ) : \n kwargs . setdefault ( \"<STR_LIT>\" , Draft3Validator ) \n with self . assertRaises ( ValidationError ) as e : \n validate ( instance , schema , * args , ** kwargs ) \n return e . exception . message \n def test_single_type_failure ( self ) : \n message = self . message_for ( instance = <NUM_LIT:1> , schema = { u\"<STR_LIT:type>\" : u\"<STR_LIT:string>\" } ) \n self . assertEqual ( message , \"<STR_LIT>\" % u\"<STR_LIT:string>\" ) \n def test_single_type_list_failure ( self ) : \n message = self . message_for ( instance = <NUM_LIT:1> , schema = { u\"<STR_LIT:type>\" : [ u\"<STR_LIT:string>\" ] } ) \n self . assertEqual ( message , \"<STR_LIT>\" % u\"<STR_LIT:string>\" ) \n def test_multiple_type_failure ( self ) : \n types = u\"<STR_LIT:string>\" , u\"<STR_LIT:object>\" \n message = self . message_for ( instance = <NUM_LIT:1> , schema = { u\"<STR_LIT:type>\" : list ( types ) } ) \n self . assertEqual ( message , \"<STR_LIT>\" % types ) \n def test_object_without_title_type_failure ( self ) : \n type = { u\"<STR_LIT:type>\" : [ { u\"<STR_LIT>\" : <NUM_LIT:3> } ] } \n message = self . message_for ( instance = <NUM_LIT:1> , schema = { u\"<STR_LIT:type>\" : [ type ] } ) \n self . assertEqual ( message , \"<STR_LIT>\" % ( type , ) ) \n def test_object_with_name_type_failure ( self ) : \n name = \"<STR_LIT>\" \n schema = { u\"<STR_LIT:type>\" : [ { u\"<STR_LIT:name>\" : name , u\"<STR_LIT>\" : <NUM_LIT:3> } ] } \n message = self . message_for ( instance = <NUM_LIT:1> , schema = schema ) \n self . assertEqual ( message , \"<STR_LIT>\" % ( name , ) ) \n def test_minimum ( self ) : \n message = self . message_for ( instance = <NUM_LIT:1> , schema = { \"<STR_LIT>\" : <NUM_LIT:2> } ) \n self . assertEqual ( message , \"<STR_LIT>\" ) \n def test_maximum ( self ) : \n message = self . message_for ( instance = <NUM_LIT:1> , schema = { \"<STR_LIT>\" : <NUM_LIT:0> } ) \n self . assertEqual ( message , \"<STR_LIT>\" ) \n def test_dependencies_failure_has_single_element_not_list ( self ) : \n depend , on = \"<STR_LIT:bar>\" , \"<STR_LIT:foo>\" \n schema = { u\"<STR_LIT>\" : { depend : on } } \n message = self . message_for ( { \"<STR_LIT:bar>\" : <NUM_LIT:2> } , schema ) \n self . assertEqual ( message , \"<STR_LIT>\" % ( on , depend ) ) \n def test_additionalItems_single_failure ( self ) : \n message = self . message_for ( \n [ <NUM_LIT:2> ] , { u\"<STR_LIT>\" : [ ] , u\"<STR_LIT>\" : False } , \n ) \n self . assertIn ( \"<STR_LIT>\" , message ) \n def test_additionalItems_multiple_failures ( self ) : \n message = self . message_for ( \n [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] , { u\"<STR_LIT>\" : [ ] , u\"<STR_LIT>\" : False } \n ) \n self . assertIn ( \"<STR_LIT>\" , message ) \n def test_additionalProperties_single_failure ( self ) : \n additional = \"<STR_LIT:foo>\" \n schema = { u\"<STR_LIT>\" : False } \n message = self . message_for ( { additional : <NUM_LIT:2> } , schema ) \n self . assertIn ( \"<STR_LIT>\" % ( additional , ) , message ) \n def test_additionalProperties_multiple_failures ( self ) : \n schema = { u\"<STR_LIT>\" : False } \n message = self . message_for ( dict . fromkeys ( [ \"<STR_LIT:foo>\" , \"<STR_LIT:bar>\" ] ) , schema ) \n self . assertIn ( repr ( \"<STR_LIT:foo>\" ) , message ) \n self . assertIn ( repr ( \"<STR_LIT:bar>\" ) , message ) \n self . assertIn ( \"<STR_LIT>\" , message ) \n def test_invalid_format_default_message ( self ) : \n checker = FormatChecker ( formats = ( ) ) \n check_fn = mock . Mock ( return_value = False ) \n checker . checks ( u\"<STR_LIT>\" ) ( check_fn ) \n schema = { u\"<STR_LIT>\" : u\"<STR_LIT>\" } \n message = self . message_for ( \"<STR_LIT>\" , schema , format_checker = checker ) \n self . assertIn ( repr ( \"<STR_LIT>\" ) , message ) \n self . assertIn ( repr ( \"<STR_LIT>\" ) , message ) \n self . assertIn ( \"<STR_LIT>\" , message ) \n class TestValidationErrorDetails ( unittest . TestCase ) : \n def test_anyOf ( self ) : \n instance = <NUM_LIT:5> \n schema = { \n \"<STR_LIT>\" : [ \n { \"<STR_LIT>\" : <NUM_LIT:20> } , \n { \"<STR_LIT:type>\" : \"<STR_LIT:string>\" } \n ] \n } \n validator = Draft4Validator ( schema ) \n errors = list ( validator . iter_errors ( instance ) ) \n self . assertEqual ( len ( errors ) , <NUM_LIT:1> ) \n e = errors [ <NUM_LIT:0> ] \n self . assertEqual ( e . validator , \"<STR_LIT>\" ) \n self . assertEqual ( e . validator_value , schema [ \"<STR_LIT>\" ] ) \n self . assertEqual ( e . instance , instance ) \n self . assertEqual ( e . schema , schema ) \n self . assertIsNone ( e . parent ) \n self . assertEqual ( e . path , deque ( [ ] ) ) \n self . assertEqual ( e . relative_path , deque ( [ ] ) ) \n self . assertEqual ( e . absolute_path , deque ( [ ] ) ) \n self . assertEqual ( e . schema_path , deque ( [ \"<STR_LIT>\" ] ) ) \n self . assertEqual ( e . relative_schema_path , deque ( [ \"<STR_LIT>\" ] ) ) \n self . assertEqual ( e . absolute_schema_path , deque ( [ \"<STR_LIT>\" ] ) ) \n self . assertEqual ( len ( e . context ) , <NUM_LIT:2> ) \n e1 , e2 = sorted_errors ( e . context ) \n self . assertEqual ( e1 . validator , \"<STR_LIT>\" ) \n self . assertEqual ( e1 . validator_value , schema [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] [ \"<STR_LIT>\" ] ) \n self . assertEqual ( e1 . instance , instance ) \n self . assertEqual ( e1 . schema , schema [ \"<STR_LIT>\" ] [ <NUM_LIT:0> ] ) \n self . assertIs ( e1 . parent , e ) \n self . assertEqual ( e1 . path , deque ( [ ] ) ) \n self . assertEqual ( e1 . absolute_path , deque ( [ ] ) ) \n self . assertEqual ( e1 . relative_path , deque ( [ ] ) ) \n self . assertEqual ( e1 . schema_path , deque ( [ <NUM_LIT:0> , \"<STR_LIT>\" ] ) ) \n self . assertEqual ( e1 . relative_schema_path , deque ( [ <NUM_LIT:0> , \"<STR_LIT>\" ] ) ) \n self . assertEqual ( \n e1 . absolute_schema_path , deque ( [ \"<STR_LIT>\" , <NUM_LIT:0> , \"<STR_LIT>\" ] ) , \n ) \n self . assertFalse ( e1 . context ) \n self . assertEqual ( e2 . validator , \"<STR_LIT:type>\" ) \n self . assertEqual ( e2 . validator_value , schema [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] [ \"<STR_LIT:type>\" ] ) \n self . assertEqual ( e2 . instance , instance ) \n self . assertEqual ( e2 . schema , schema [ \"<STR_LIT>\" ] [ <NUM_LIT:1> ] ) \n self . assertIs ( e2 . parent , e ) \n self . assertEqual ( e2 . path , deque ( [ ] ) ) \n self . assertEqual ( e2 . relative_path , deque ( [ ] ) ) \n self . assertEqual ( e2 . absolute_path , deque ( [ ] ) ) \n self . assertEqual ( e2 . schema_path , deque ( [ <NUM_LIT:1> , \"<STR_LIT:type>\" ] ) ) \n self . assertEqual ( e2 . relative_schema_path , deque ( [ <NUM_LIT:1> , \"<STR_LIT:type>\" ] ) ) \n self . assertEqual ( e2 . absolute_schema_path , deque ( [ \"<STR_LIT>\" , <NUM_LIT:1> , \"<STR_LIT:type>\" ] ) ) \n self . assertEqual ( len ( e2 . context ) , <NUM_LIT:0> ) \n def test_type ( self ) : \n instance = { \"<STR_LIT:foo>\" : <NUM_LIT:1> } \n schema = { \n \"<STR_LIT:type>\" : [ \n { \"<STR_LIT:type>\" : \"<STR_LIT>\" } , \n { \n \"<STR_LIT:type>\" : \"<STR_LIT:object>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT:foo>\" : { \"<STR_LIT>\" : [ <NUM_LIT:2> ] } \n } \n } \n ] \n } \n validator = Draft3Validator ( schema ) \n errors = list ( validator . iter_errors ( instance ) ) \n self . assertEqual ( len ( errors ) , <NUM_LIT:1> ) \n e = errors [ <NUM_LIT:0> ] \n self . assertEqual ( e . validator , \"<STR_LIT:type>\" ) \n self . assertEqual ( e . validator_value , schema [ \"<STR_LIT:type>\" ] ) \n self . assertEqual ( e . instance , instance ) \n self . assertEqual ( e . schema , schema ) \n self . assertIsNone ( e . parent ) \n self . assertEqual ( e . path , deque ( [ ] ) ) \n self . assertEqual ( e . relative_path , deque ( [ ] ) ) \n self . assertEqual ( e . absolute_path , deque ( [ ] ) ) \n self . assertEqual ( e . schema_path , deque ( [ \"<STR_LIT:type>\" ] ) ) \n self . assertEqual ( e . relative_schema_path , deque ( [ \"<STR_LIT:type>\" ] ) ) \n self . assertEqual ( e . absolute_schema_path , deque ( [ \"<STR_LIT:type>\" ] ) ) \n self . assertEqual ( len ( e . context ) , <NUM_LIT:2> ) \n e1 , e2 = sorted_errors ( e . context ) \n self . assertEqual ( e1 . validator , \"<STR_LIT:type>\" ) \n self . assertEqual ( e1 . validator_value , schema [ \"<STR_LIT:type>\" ] [ <NUM_LIT:0> ] [ \"<STR_LIT:type>\" ] ) \n self . assertEqual ( e1 . instance , instance ) \n self . assertEqual ( e1 . schema , schema [ \"<STR_LIT:type>\" ] [ <NUM_LIT:0> ] ) \n self . assertIs ( e1 . parent , e ) \n self . assertEqual ( e1 . path , deque ( [ ] ) ) \n self . assertEqual ( e1 . relative_path , deque ( [ ] ) ) \n self . assertEqual ( e1 . absolute_path , deque ( [ ] ) ) \n self . assertEqual ( e1 . schema_path , deque ( [ <NUM_LIT:0> , \"<STR_LIT:type>\" ] ) ) \n self . assertEqual ( e1 . relative_schema_path , deque ( [ <NUM_LIT:0> , \"<STR_LIT:type>\" ] ) ) \n self . assertEqual ( e1 . absolute_schema_path , deque ( [ \"<STR_LIT:type>\" , <NUM_LIT:0> , \"<STR_LIT:type>\" ] ) ) \n self . assertFalse ( e1 . context ) \n self . assertEqual ( e2 . validator , \"<STR_LIT>\" ) \n self . assertEqual ( e2 . validator_value , [ <NUM_LIT:2> ] ) \n self . assertEqual ( e2 . instance , <NUM_LIT:1> ) \n self . assertEqual ( e2 . schema , { u\"<STR_LIT>\" : [ <NUM_LIT:2> ] } ) \n self . assertIs ( e2 . parent , e ) \n self . assertEqual ( e2 . path , deque ( [ \"<STR_LIT:foo>\" ] ) ) \n self . assertEqual ( e2 . relative_path , deque ( [ \"<STR_LIT:foo>\" ] ) ) \n self . assertEqual ( e2 . absolute_path , deque ( [ \"<STR_LIT:foo>\" ] ) ) \n self . assertEqual ( \n e2 . schema_path , deque ( [ <NUM_LIT:1> , \"<STR_LIT>\" , \"<STR_LIT:foo>\" , \"<STR_LIT>\" ] ) , \n ) \n self . assertEqual ( \n e2 . relative_schema_path , deque ( [ <NUM_LIT:1> , \"<STR_LIT>\" , \"<STR_LIT:foo>\" , \"<STR_LIT>\" ] ) , \n ) \n self . assertEqual ( \n e2 . absolute_schema_path , \n deque ( [ \"<STR_LIT:type>\" , <NUM_LIT:1> , \"<STR_LIT>\" , \"<STR_LIT:foo>\" , \"<STR_LIT>\" ] ) , \n ) \n self . assertFalse ( e2 . context ) \n def test_single_nesting ( self ) : \n instance = { \"<STR_LIT:foo>\" : <NUM_LIT:2> , \"<STR_LIT:bar>\" : [ <NUM_LIT:1> ] , \"<STR_LIT>\" : <NUM_LIT:15> , \"<STR_LIT>\" : \"<STR_LIT>\" } \n schema = { \n \"<STR_LIT>\" : { \n \"<STR_LIT:foo>\" : { \"<STR_LIT:type>\" : \"<STR_LIT:string>\" } , \n \"<STR_LIT:bar>\" : { \"<STR_LIT>\" : <NUM_LIT:2> } , \n \"<STR_LIT>\" : { \"<STR_LIT>\" : <NUM_LIT:10> , \"<STR_LIT>\" : [ <NUM_LIT:2> , <NUM_LIT:4> , <NUM_LIT:6> , <NUM_LIT:8> ] } , \n } \n } \n validator = Draft3Validator ( schema ) \n errors = validator . iter_errors ( instance ) \n e1 , e2 , e3 , e4 = sorted_errors ( errors ) \n self . assertEqual ( e1 . path , deque ( [ \"<STR_LIT:bar>\" ] ) ) \n self . assertEqual ( e2 . path , deque ( [ \"<STR_LIT>\" ] ) ) \n self . assertEqual ( e3 . path , deque ( [ \"<STR_LIT>\" ] ) ) \n self . assertEqual ( e4 . path , deque ( [ \"<STR_LIT:foo>\" ] ) ) \n self . assertEqual ( e1 . relative_path , deque ( [ \"<STR_LIT:bar>\" ] ) ) \n self . assertEqual ( e2 . relative_path , deque ( [ \"<STR_LIT>\" ] ) ) \n self . assertEqual ( e3 . relative_path , deque ( [ \"<STR_LIT>\" ] ) ) \n self . assertEqual ( e4 . relative_path , deque ( [ \"<STR_LIT:foo>\" ] ) ) \n self . assertEqual ( e1 . absolute_path , deque ( [ \"<STR_LIT:bar>\" ] ) ) \n self . assertEqual ( e2 . absolute_path , deque ( [ \"<STR_LIT>\" ] ) ) \n self . assertEqual ( e3 . absolute_path , deque ( [ \"<STR_LIT>\" ] ) ) \n self . assertEqual ( e4 . absolute_path , deque ( [ \"<STR_LIT:foo>\" ] ) ) \n self . assertEqual ( e1 . validator , \"<STR_LIT>\" ) \n self . assertEqual ( e2 . validator , \"<STR_LIT>\" ) \n self . assertEqual ( e3 . validator , \"<STR_LIT>\" ) \n self . assertEqual ( e4 . validator , \"<STR_LIT:type>\" ) \n def test_multiple_nesting ( self ) : \n instance = [ <NUM_LIT:1> , { \"<STR_LIT:foo>\" : <NUM_LIT:2> , \"<STR_LIT:bar>\" : { \"<STR_LIT>\" : [ <NUM_LIT:1> ] } } , \"<STR_LIT>\" ] \n schema = { \n \"<STR_LIT:type>\" : \"<STR_LIT:string>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT:type>\" : [ \"<STR_LIT:string>\" , \"<STR_LIT:object>\" ] , \n \"<STR_LIT>\" : { \n \"<STR_LIT:foo>\" : { \"<STR_LIT>\" : [ <NUM_LIT:1> , <NUM_LIT:3> ] } , \n \"<STR_LIT:bar>\" : { \n \"<STR_LIT:type>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT:bar>\" : { \"<STR_LIT>\" : True } , \n \"<STR_LIT>\" : { \"<STR_LIT>\" : <NUM_LIT:2> } , \n } \n } \n } \n } \n } \n validator = Draft3Validator ( schema ) \n errors = validator . iter_errors ( instance ) \n e1 , e2 , e3 , e4 , e5 , e6 = sorted_errors ( errors ) \n self . assertEqual ( e1 . path , deque ( [ ] ) ) \n self . assertEqual ( e2 . path , deque ( [ <NUM_LIT:0> ] ) ) \n self . assertEqual ( e3 . path , deque ( [ <NUM_LIT:1> , \"<STR_LIT:bar>\" ] ) ) \n self . assertEqual ( e4 . path , deque ( [ <NUM_LIT:1> , \"<STR_LIT:bar>\" , \"<STR_LIT:bar>\" ] ) ) \n self . assertEqual ( e5 . path , deque ( [ <NUM_LIT:1> , \"<STR_LIT:bar>\" , \"<STR_LIT>\" ] ) ) \n self . assertEqual ( e6 . path , deque ( [ <NUM_LIT:1> , \"<STR_LIT:foo>\" ] ) ) \n self . assertEqual ( e1 . schema_path , deque ( [ \"<STR_LIT:type>\" ] ) ) \n self . assertEqual ( e2 . schema_path , deque ( [ \"<STR_LIT>\" , \"<STR_LIT:type>\" ] ) ) \n self . assertEqual ( \n list ( e3 . schema_path ) , [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT:bar>\" , \"<STR_LIT:type>\" ] , \n ) \n self . assertEqual ( \n list ( e4 . schema_path ) , \n [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT:bar>\" , \"<STR_LIT>\" , \"<STR_LIT:bar>\" , \"<STR_LIT>\" ] , \n ) \n self . assertEqual ( \n list ( e5 . schema_path ) , \n [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT:bar>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n ) \n self . assertEqual ( \n list ( e6 . schema_path ) , [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT:foo>\" , \"<STR_LIT>\" ] , \n ) \n self . assertEqual ( e1 . validator , \"<STR_LIT:type>\" ) \n self . assertEqual ( e2 . validator , \"<STR_LIT:type>\" ) \n self . assertEqual ( e3 . validator , \"<STR_LIT:type>\" ) \n self . assertEqual ( e4 . validator , \"<STR_LIT>\" ) \n self . assertEqual ( e5 . validator , \"<STR_LIT>\" ) \n self . assertEqual ( e6 . validator , \"<STR_LIT>\" ) \n def test_recursive ( self ) : \n schema = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ { \n \"<STR_LIT:type>\" : \"<STR_LIT:object>\" , \n \"<STR_LIT>\" : [ \"<STR_LIT:name>\" , \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : { \n \"<STR_LIT:name>\" : { \n \"<STR_LIT:type>\" : \"<STR_LIT:string>\" , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT:type>\" : \"<STR_LIT:object>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n } , \n } , \n } , \n } ] , \n } , \n } , \n \"<STR_LIT:type>\" : \"<STR_LIT:object>\" , \n \"<STR_LIT>\" : [ \"<STR_LIT:root>\" ] , \n \"<STR_LIT>\" : { \n \"<STR_LIT:root>\" : { \"<STR_LIT>\" : \"<STR_LIT>\" } , \n } \n } \n instance = { \n \"<STR_LIT:root>\" : { \n \"<STR_LIT:name>\" : \"<STR_LIT:root>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT:a>\" : { \n \"<STR_LIT:name>\" : \"<STR_LIT:a>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT:name>\" : \"<STR_LIT>\" , \n } \n } \n } , \n } , \n } , \n } \n validator = Draft4Validator ( schema ) \n e , = validator . iter_errors ( instance ) \n self . assertEqual ( e . absolute_path , deque ( [ \"<STR_LIT:root>\" ] ) ) \n self . assertEqual ( \n e . absolute_schema_path , deque ( [ \"<STR_LIT>\" , \"<STR_LIT:root>\" , \"<STR_LIT>\" ] ) , \n ) \n e1 , = e . context \n self . assertEqual ( e1 . absolute_path , deque ( [ \"<STR_LIT:root>\" , \"<STR_LIT>\" , \"<STR_LIT:a>\" ] ) ) \n self . assertEqual ( \n e1 . absolute_schema_path , deque ( \n [ \n \"<STR_LIT>\" , \n \"<STR_LIT:root>\" , \n \"<STR_LIT>\" , \n <NUM_LIT:0> , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] , \n ) , \n ) \n e2 , = e1 . context \n self . assertEqual ( \n e2 . absolute_path , deque ( \n [ \"<STR_LIT:root>\" , \"<STR_LIT>\" , \"<STR_LIT:a>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n ) , \n ) \n self . assertEqual ( \n e2 . absolute_schema_path , deque ( \n [ \n \"<STR_LIT>\" , \n \"<STR_LIT:root>\" , \n \"<STR_LIT>\" , \n <NUM_LIT:0> , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n <NUM_LIT:0> , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" \n ] , \n ) , \n ) \n def test_additionalProperties ( self ) : \n instance = { \"<STR_LIT:bar>\" : \"<STR_LIT:bar>\" , \"<STR_LIT:foo>\" : <NUM_LIT:2> } \n schema = { \n \"<STR_LIT>\" : { \"<STR_LIT:type>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : <NUM_LIT:5> } \n } \n validator = Draft3Validator ( schema ) \n errors = validator . iter_errors ( instance ) \n e1 , e2 = sorted_errors ( errors ) \n self . assertEqual ( e1 . path , deque ( [ \"<STR_LIT:bar>\" ] ) ) \n self . assertEqual ( e2 . path , deque ( [ \"<STR_LIT:foo>\" ] ) ) \n self . assertEqual ( e1 . validator , \"<STR_LIT:type>\" ) \n self . assertEqual ( e2 . validator , \"<STR_LIT>\" ) \n def test_patternProperties ( self ) : \n instance = { \"<STR_LIT:bar>\" : <NUM_LIT:1> , \"<STR_LIT:foo>\" : <NUM_LIT:2> } \n schema = { \n \"<STR_LIT>\" : { \n \"<STR_LIT:bar>\" : { \"<STR_LIT:type>\" : \"<STR_LIT:string>\" } , \n \"<STR_LIT:foo>\" : { \"<STR_LIT>\" : <NUM_LIT:5> } \n } \n } \n validator = Draft3Validator ( schema ) \n errors = validator . iter_errors ( instance ) \n e1 , e2 = sorted_errors ( errors ) \n self . assertEqual ( e1 . path , deque ( [ \"<STR_LIT:bar>\" ] ) ) \n self . assertEqual ( e2 . path , deque ( [ \"<STR_LIT:foo>\" ] ) ) \n self . assertEqual ( e1 . validator , \"<STR_LIT:type>\" ) \n self . assertEqual ( e2 . validator , \"<STR_LIT>\" ) \n def test_additionalItems ( self ) : \n instance = [ \"<STR_LIT:foo>\" , <NUM_LIT:1> ] \n schema = { \n \"<STR_LIT>\" : [ ] , \n \"<STR_LIT>\" : { \"<STR_LIT:type>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : <NUM_LIT:5> } \n } \n validator = Draft3Validator ( schema ) \n errors = validator . iter_errors ( instance ) \n e1 , e2 = sorted_errors ( errors ) \n self . assertEqual ( e1 . path , deque ( [ <NUM_LIT:0> ] ) ) \n self . assertEqual ( e2 . path , deque ( [ <NUM_LIT:1> ] ) ) \n self . assertEqual ( e1 . validator , \"<STR_LIT:type>\" ) \n self . assertEqual ( e2 . validator , \"<STR_LIT>\" ) \n def test_additionalItems_with_items ( self ) : \n instance = [ \"<STR_LIT:foo>\" , \"<STR_LIT:bar>\" , <NUM_LIT:1> ] \n schema = { \n \"<STR_LIT>\" : [ { } ] , \n \"<STR_LIT>\" : { \"<STR_LIT:type>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : <NUM_LIT:5> } \n } \n validator = Draft3Validator ( schema ) \n errors = validator . iter_errors ( instance ) \n e1 , e2 = sorted_errors ( errors ) \n self . assertEqual ( e1 . path , deque ( [ <NUM_LIT:1> ] ) ) \n self . assertEqual ( e2 . path , deque ( [ <NUM_LIT:2> ] ) ) \n self . assertEqual ( e1 . validator , \"<STR_LIT:type>\" ) \n self . assertEqual ( e2 . validator , \"<STR_LIT>\" ) \n class ValidatorTestMixin ( object ) : \n def setUp ( self ) : \n self . instance = mock . Mock ( ) \n self . schema = { } \n self . resolver = mock . Mock ( ) \n self . validator = self . validator_class ( self . schema ) \n def test_valid_instances_are_valid ( self ) : \n errors = iter ( [ ] ) \n with mock . patch . object ( \n self . validator , \"<STR_LIT>\" , return_value = errors , \n ) : \n self . assertTrue ( \n self . validator . is_valid ( self . instance , self . schema ) \n ) \n def test_invalid_instances_are_not_valid ( self ) : \n errors = iter ( [ mock . Mock ( ) ] ) \n with mock . patch . object ( \n self . validator , \"<STR_LIT>\" , return_value = errors , \n ) : \n self . assertFalse ( \n self . validator . is_valid ( self . instance , self . schema ) \n ) \n def test_non_existent_properties_are_ignored ( self ) : \n instance , my_property , my_value = mock . Mock ( ) , mock . Mock ( ) , mock . Mock ( ) \n validate ( instance = instance , schema = { my_property : my_value } ) \n def test_it_creates_a_ref_resolver_if_not_provided ( self ) : \n self . assertIsInstance ( self . validator . resolver , RefResolver ) \n def test_it_delegates_to_a_ref_resolver ( self ) : \n resolver = RefResolver ( \"<STR_LIT>\" , { } ) \n schema = { \"<STR_LIT>\" : mock . Mock ( ) } \n with mock . patch . object ( resolver , \"<STR_LIT>\" ) as resolve : \n resolve . return_value = \"<STR_LIT:url>\" , { \"<STR_LIT:type>\" : \"<STR_LIT>\" } \n with self . assertRaises ( ValidationError ) : \n self . validator_class ( schema , resolver = resolver ) . validate ( None ) \n resolve . assert_called_once_with ( schema [ \"<STR_LIT>\" ] ) \n def test_it_delegates_to_a_legacy_ref_resolver ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n class LegacyRefResolver ( object ) : \n @ contextmanager \n def resolving ( this , ref ) : \n self . assertEqual ( ref , \"<STR_LIT>\" ) \n yield { \"<STR_LIT:type>\" : \"<STR_LIT>\" } \n resolver = LegacyRefResolver ( ) \n schema = { \"<STR_LIT>\" : \"<STR_LIT>\" } \n with self . assertRaises ( ValidationError ) : \n self . validator_class ( schema , resolver = resolver ) . validate ( None ) \n def test_is_type_is_true_for_valid_type ( self ) : \n self . assertTrue ( self . validator . is_type ( \"<STR_LIT:foo>\" , \"<STR_LIT:string>\" ) ) \n def test_is_type_is_false_for_invalid_type ( self ) : \n self . assertFalse ( self . validator . is_type ( \"<STR_LIT:foo>\" , \"<STR_LIT>\" ) ) \n def test_is_type_evades_bool_inheriting_from_int ( self ) : \n self . assertFalse ( self . validator . is_type ( True , \"<STR_LIT>\" ) ) \n self . assertFalse ( self . validator . is_type ( True , \"<STR_LIT>\" ) ) \n def test_is_type_raises_exception_for_unknown_type ( self ) : \n with self . assertRaises ( UnknownType ) : \n self . validator . is_type ( \"<STR_LIT:foo>\" , object ( ) ) \n class TestDraft3Validator ( ValidatorTestMixin , unittest . TestCase ) : \n validator_class = Draft3Validator \n def test_is_type_is_true_for_any_type ( self ) : \n self . assertTrue ( self . validator . is_valid ( mock . Mock ( ) , { \"<STR_LIT:type>\" : \"<STR_LIT>\" } ) ) \n def test_is_type_does_not_evade_bool_if_it_is_being_tested ( self ) : \n self . assertTrue ( self . validator . is_type ( True , \"<STR_LIT>\" ) ) \n self . assertTrue ( self . validator . is_valid ( True , { \"<STR_LIT:type>\" : \"<STR_LIT>\" } ) ) \n def test_non_string_custom_types ( self ) : \n schema = { '<STR_LIT:type>' : [ None ] } \n cls = self . validator_class ( schema , types = { None : type ( None ) } ) \n cls . validate ( None , schema ) \n class TestDraft4Validator ( ValidatorTestMixin , unittest . TestCase ) : \n validator_class = Draft4Validator \n class TestBuiltinFormats ( unittest . TestCase ) : \n \"\"\"<STR_LIT>\"\"\" \n for format in FormatChecker . checkers : \n def test ( self , format = format ) : \n v = Draft4Validator ( { \"<STR_LIT>\" : format } , format_checker = FormatChecker ( ) ) \n v . validate ( <NUM_LIT> ) \n name = \"<STR_LIT>\" . format ( format ) \n test . __name__ = name \n setattr ( TestBuiltinFormats , name , test ) \n del test \n class TestValidatorFor ( unittest . TestCase ) : \n def test_draft_3 ( self ) : \n schema = { \"<STR_LIT>\" : \"<STR_LIT>\" } \n self . assertIs ( validator_for ( schema ) , Draft3Validator ) \n schema = { \"<STR_LIT>\" : \"<STR_LIT>\" } \n self . assertIs ( validator_for ( schema ) , Draft3Validator ) \n def test_draft_4 ( self ) : \n schema = { \"<STR_LIT>\" : \"<STR_LIT>\" } \n self . assertIs ( validator_for ( schema ) , Draft4Validator ) \n schema = { \"<STR_LIT>\" : \"<STR_LIT>\" } \n self . assertIs ( validator_for ( schema ) , Draft4Validator ) \n def test_custom_validator ( self ) : \n Validator = create ( meta_schema = { \"<STR_LIT:id>\" : \"<STR_LIT>\" } , version = \"<STR_LIT>\" ) \n schema = { \"<STR_LIT>\" : \"<STR_LIT>\" } \n self . assertIs ( validator_for ( schema ) , Validator ) \n def test_validator_for_jsonschema_default ( self ) : \n self . assertIs ( validator_for ( { } ) , Draft4Validator ) \n def test_validator_for_custom_default ( self ) : \n self . assertIs ( validator_for ( { } , default = None ) , None ) \n class TestValidate ( unittest . TestCase ) : \n def test_draft3_validator_is_chosen ( self ) : \n schema = { \"<STR_LIT>\" : \"<STR_LIT>\" } \n with mock . patch . object ( Draft3Validator , \"<STR_LIT>\" ) as chk_schema : \n validate ( { } , schema ) \n chk_schema . assert_called_once_with ( schema ) \n schema = { \"<STR_LIT>\" : \"<STR_LIT>\" } \n with mock . patch . object ( Draft3Validator , \"<STR_LIT>\" ) as chk_schema : \n validate ( { } , schema ) \n chk_schema . assert_called_once_with ( schema ) \n def test_draft4_validator_is_chosen ( self ) : \n schema = { \"<STR_LIT>\" : \"<STR_LIT>\" } \n with mock . patch . object ( Draft4Validator , \"<STR_LIT>\" ) as chk_schema : \n validate ( { } , schema ) \n chk_schema . assert_called_once_with ( schema ) \n def test_draft4_validator_is_the_default ( self ) : \n with mock . patch . object ( Draft4Validator , \"<STR_LIT>\" ) as chk_schema : \n validate ( { } , { } ) \n chk_schema . assert_called_once_with ( { } ) \n class TestRefResolver ( unittest . TestCase ) : \n base_uri = \"<STR_LIT>\" \n stored_uri = \"<STR_LIT>\" \n stored_schema = { \"<STR_LIT>\" : \"<STR_LIT>\" } \n def setUp ( self ) : \n self . referrer = { } \n self . store = { self . stored_uri : self . stored_schema } \n self . resolver = RefResolver ( self . base_uri , self . referrer , self . store ) \n def test_it_does_not_retrieve_schema_urls_from_the_network ( self ) : \n ref = Draft3Validator . META_SCHEMA [ \"<STR_LIT:id>\" ] \n with mock . patch . object ( self . resolver , \"<STR_LIT>\" ) as remote : \n with self . resolver . resolving ( ref ) as resolved : \n self . assertEqual ( resolved , Draft3Validator . META_SCHEMA ) \n self . assertFalse ( remote . called ) \n def test_it_resolves_local_refs ( self ) : \n ref = \"<STR_LIT>\" \n self . referrer [ \"<STR_LIT>\" ] = { \"<STR_LIT:foo>\" : object ( ) } \n with self . resolver . resolving ( ref ) as resolved : \n self . assertEqual ( resolved , self . referrer [ \"<STR_LIT>\" ] [ \"<STR_LIT:foo>\" ] ) \n def test_it_resolves_local_refs_with_id ( self ) : \n schema = { \"<STR_LIT:id>\" : \"<STR_LIT>\" , \"<STR_LIT:a>\" : { \"<STR_LIT:foo>\" : \"<STR_LIT:bar>\" } } \n resolver = RefResolver . from_schema ( schema ) \n with resolver . resolving ( \"<STR_LIT>\" ) as resolved : \n self . assertEqual ( resolved , schema [ \"<STR_LIT:a>\" ] ) \n with resolver . resolving ( \"<STR_LIT>\" ) as resolved : \n self . assertEqual ( resolved , schema [ \"<STR_LIT:a>\" ] ) \n def test_it_retrieves_stored_refs ( self ) : \n with self . resolver . resolving ( self . stored_uri ) as resolved : \n self . assertIs ( resolved , self . stored_schema ) \n self . resolver . store [ \"<STR_LIT>\" ] = { \"<STR_LIT:foo>\" : <NUM_LIT:12> } \n with self . resolver . resolving ( \"<STR_LIT>\" ) as resolved : \n self . assertEqual ( resolved , <NUM_LIT:12> ) \n def test_it_retrieves_unstored_refs_via_requests ( self ) : \n ref = \"<STR_LIT>\" \n schema = { \"<STR_LIT>\" : <NUM_LIT:12> } \n with mock . patch ( \"<STR_LIT>\" ) as requests : \n requests . get . return_value . json . return_value = schema \n with self . resolver . resolving ( ref ) as resolved : \n self . assertEqual ( resolved , <NUM_LIT:12> ) \n requests . get . assert_called_once_with ( \"<STR_LIT>\" ) \n def test_it_retrieves_unstored_refs_via_urlopen ( self ) : \n ref = \"<STR_LIT>\" \n schema = { \"<STR_LIT>\" : <NUM_LIT:12> } \n with mock . patch ( \"<STR_LIT>\" , None ) : \n with mock . patch ( \"<STR_LIT>\" ) as urlopen : \n urlopen . return_value . read . return_value = ( \n json . dumps ( schema ) . encode ( \"<STR_LIT:utf8>\" ) ) \n with self . resolver . resolving ( ref ) as resolved : \n self . assertEqual ( resolved , <NUM_LIT:12> ) \n urlopen . assert_called_once_with ( \"<STR_LIT>\" ) \n def test_it_can_construct_a_base_uri_from_a_schema ( self ) : \n schema = { \"<STR_LIT:id>\" : \"<STR_LIT:foo>\" } \n resolver = RefResolver . from_schema ( schema ) \n self . assertEqual ( resolver . base_uri , \"<STR_LIT:foo>\" ) \n self . assertEqual ( resolver . resolution_scope , \"<STR_LIT:foo>\" ) \n with resolver . resolving ( \"<STR_LIT>\" ) as resolved : \n self . assertEqual ( resolved , schema ) \n with resolver . resolving ( \"<STR_LIT:#>\" ) as resolved : \n self . assertEqual ( resolved , schema ) \n with resolver . resolving ( \"<STR_LIT:foo>\" ) as resolved : \n self . assertEqual ( resolved , schema ) \n with resolver . resolving ( \"<STR_LIT>\" ) as resolved : \n self . assertEqual ( resolved , schema ) \n def test_it_can_construct_a_base_uri_from_a_schema_without_id ( self ) : \n schema = { } \n resolver = RefResolver . from_schema ( schema ) \n self . assertEqual ( resolver . base_uri , \"<STR_LIT>\" ) \n self . assertEqual ( resolver . resolution_scope , \"<STR_LIT>\" ) \n with resolver . resolving ( \"<STR_LIT>\" ) as resolved : \n self . assertEqual ( resolved , schema ) \n with resolver . resolving ( \"<STR_LIT:#>\" ) as resolved : \n self . assertEqual ( resolved , schema ) \n def test_custom_uri_scheme_handlers ( self ) : \n schema = { \"<STR_LIT:foo>\" : \"<STR_LIT:bar>\" } \n ref = \"<STR_LIT>\" \n foo_handler = mock . Mock ( return_value = schema ) \n resolver = RefResolver ( \"<STR_LIT>\" , { } , handlers = { \"<STR_LIT:foo>\" : foo_handler } ) \n with resolver . resolving ( ref ) as resolved : \n self . assertEqual ( resolved , schema ) \n foo_handler . assert_called_once_with ( ref ) \n def test_cache_remote_on ( self ) : \n ref = \"<STR_LIT>\" \n foo_handler = mock . Mock ( ) \n resolver = RefResolver ( \n \"<STR_LIT>\" , { } , cache_remote = True , handlers = { \"<STR_LIT:foo>\" : foo_handler } , \n ) \n with resolver . resolving ( ref ) : \n pass \n with resolver . resolving ( ref ) : \n pass \n foo_handler . assert_called_once_with ( ref ) \n def test_cache_remote_off ( self ) : \n ref = \"<STR_LIT>\" \n foo_handler = mock . Mock ( ) \n resolver = RefResolver ( \n \"<STR_LIT>\" , { } , cache_remote = False , handlers = { \"<STR_LIT:foo>\" : foo_handler } , \n ) \n with resolver . resolving ( ref ) : \n pass \n self . assertEqual ( foo_handler . call_count , <NUM_LIT:1> ) \n def test_if_you_give_it_junk_you_get_a_resolution_error ( self ) : \n ref = \"<STR_LIT>\" \n foo_handler = mock . Mock ( side_effect = ValueError ( \"<STR_LIT>\" ) ) \n resolver = RefResolver ( \"<STR_LIT>\" , { } , handlers = { \"<STR_LIT:foo>\" : foo_handler } ) \n with self . assertRaises ( RefResolutionError ) as err : \n with resolver . resolving ( ref ) : \n pass \n self . assertEqual ( str ( err . exception ) , \"<STR_LIT>\" ) \n def test_helpful_error_message_on_failed_pop_scope ( self ) : \n resolver = RefResolver ( \"<STR_LIT>\" , { } ) \n resolver . pop_scope ( ) \n with self . assertRaises ( RefResolutionError ) as exc : \n resolver . pop_scope ( ) \n self . assertIn ( \"<STR_LIT>\" , str ( exc . exception ) ) \n class UniqueTupleItemsMixin ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def test_it_properly_formats_an_error_message ( self ) : \n validator = self . validator_class ( \n schema = { \"<STR_LIT>\" : True } , \n types = { \"<STR_LIT>\" : ( tuple , ) } , \n ) \n with self . assertRaises ( ValidationError ) as e : \n validator . validate ( ( <NUM_LIT:1> , <NUM_LIT:1> ) ) \n self . assertIn ( \"<STR_LIT>\" , str ( e . exception ) ) \n class TestDraft4UniqueTupleItems ( UniqueTupleItemsMixin , unittest . TestCase ) : \n validator_class = Draft4Validator \n class TestDraft3UniqueTupleItems ( UniqueTupleItemsMixin , unittest . TestCase ) : \n validator_class = Draft3Validator \n def sorted_errors ( errors ) : \n def key ( error ) : \n return ( \n [ str ( e ) for e in error . path ] , \n [ str ( e ) for e in error . schema_path ] \n ) \n return sorted ( errors , key = key ) \n", "gt": "NUM_LIT"}
{"input": "\n '''<STR_LIT>''' \n import unittest \n import os \n from jnpr . openclos . report import ResourceAllocationReport , L2Report , L3Report \n from test_dao import InMemoryDao \n class Test ( unittest . TestCase ) : \n def setUp ( self ) : \n '''<STR_LIT>''' \n self . __conf = { } \n self . __conf [ '<STR_LIT>' ] = os . path . join ( os . path . dirname ( os . path . abspath ( __file__ ) ) , '<STR_LIT>' ) \n self . __conf [ '<STR_LIT>' ] = '<STR_LIT>' \n self . __conf [ '<STR_LIT>' ] = '<STR_LIT:false>' \n self . __conf [ '<STR_LIT>' ] = { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' \n } \n self . __conf [ '<STR_LIT>' ] = { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] } \n self . __conf [ '<STR_LIT>' ] = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : '<STR_LIT>' \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : '<STR_LIT>' , \n \"<STR_LIT>\" : '<STR_LIT>' \n } \n } \n self . _dao = InMemoryDao . getInstance ( ) \n def tearDown ( self ) : \n self . _dao = None \n InMemoryDao . _destroy ( ) \n '''<STR_LIT>''' \n def testGenerateL2Report ( self ) : \n <mask0> = L2Report ( self . __conf , self . _dao ) \n from test_model import createPod \n with self . _dao . getReadSession ( ) as session : \n pod = createPod ( \"<STR_LIT:test>\" , session ) \n l2Report . generateReport ( pod . id , True , False ) \n def testGenerateL3Report ( self ) : \n l3Report = L3Report ( self . __conf , self . _dao ) \n from test_model import createPod \n with self . _dao . getReadSession ( ) as session : \n pod = createPod ( \"<STR_LIT:test>\" , session ) \n l3Report . generateReport ( pod . id , True , False ) \n if __name__ == \"<STR_LIT:__main__>\" : \n unittest . main ( ) \n", "gt": "l2Report"}
{"input": "\n import yaml \n import os . path \n from jnpr . junos . factory . factory_loader import FactoryLoader \n <mask0> = [ '<STR_LIT>' , '<STR_LIT>' ] \n def loadyaml ( path ) : \n \"\"\"<STR_LIT>\"\"\" \n if os . path . splitext ( path ) [ <NUM_LIT:1> ] == '<STR_LIT>' : \n path += '<STR_LIT>' \n return FactoryLoader ( ) . load ( yaml . load ( open ( path , '<STR_LIT:r>' ) ) ) \n", "gt": "__all__"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n from jnpr . junos . factory import loadyaml \n from os . path import splitext \n <mask0> = splitext ( __file__ ) [ <NUM_LIT:0> ] + '<STR_LIT>' \n globals ( ) . update ( loadyaml ( _YAML_ ) ) \n", "gt": "_YAML_"}
{"input": "\n <mask0> = \"<STR_LIT>\" \n __credits__ = \"<STR_LIT>\" \n import unittest \n from nose . plugins . attrib import attr \n from jnpr . junos import Device \n from jnpr . junos . utils . util import Util \n from mock import patch \n @ attr ( '<STR_LIT>' ) \n class TestUtil ( unittest . TestCase ) : \n @ patch ( '<STR_LIT>' ) \n def setUp ( self , mock_connect ) : \n self . dev = Device ( host = '<STR_LIT>' , user = '<STR_LIT>' , password = '<STR_LIT>' , \n gather_facts = False ) \n self . dev . open ( ) \n self . util = Util ( self . dev ) \n def test_repr ( self ) : \n self . assertEqual ( repr ( self . util ) , '<STR_LIT>' ) \n def test_dev_setter_exception ( self ) : \n def mod_dev ( ) : \n self . util . dev = '<STR_LIT:abc>' \n self . assertRaises ( RuntimeError , mod_dev ) \n def test_rpc_setter_exception ( self ) : \n def mod_rpc ( ) : \n self . util . rpc = '<STR_LIT:abc>' \n self . assertRaises ( RuntimeError , mod_rpc ) \n", "gt": "__author__"}
{"input": "\n import unittest \n from openmdao . main . api import set_as_top , Assembly \n from openmdao . util . testutil import assert_rel_error \n from openmdao . lib . drivers . api import BroydenSolver \n from hyperloop . tube_wall_temp import TubeWallTemp \n class TubeHeatBalance ( Assembly ) : \n def configure ( self ) : \n <mask0> = self . add ( '<STR_LIT>' , TubeWallTemp ( ) ) \n driver = self . add ( '<STR_LIT>' , BroydenSolver ( ) ) \n driver . add_parameter ( '<STR_LIT>' , low = <NUM_LIT:0.> , high = <NUM_LIT> ) \n driver . add_constraint ( '<STR_LIT>' ) \n driver . workflow . add ( [ '<STR_LIT>' ] ) \n class TubeWallTestCase ( unittest . TestCase ) : \n def test_tube_temp ( self ) : \n test = set_as_top ( TubeHeatBalance ( ) ) \n test . tm . nozzle_air . setTotalTP ( <NUM_LIT> , <NUM_LIT> ) \n test . tm . nozzle_air . W = <NUM_LIT> \n test . tm . bearing_air . W = <NUM_LIT:0.> \n test . tm . diameter_outer_tube = <NUM_LIT> \n test . tm . length_tube = <NUM_LIT> \n test . tm . num_pods = <NUM_LIT> \n test . tm . temp_boundary = <NUM_LIT> \n test . tm . temp_outside_ambient = <NUM_LIT> \n test . run ( ) \n assert_rel_error ( self , test . tm . heat_rate_pod , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . total_heat_rate_pods , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . GrDelTL3 , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . Pr , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . Gr , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . Ra , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . Nu , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . k , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . h , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . area_convection , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . q_per_area_nat_conv , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . total_q_nat_conv , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . area_viewing , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . q_per_area_solar , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . q_total_solar , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . area_rad , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . q_rad_per_area , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . q_rad_tot , <NUM_LIT> , <NUM_LIT> ) \n assert_rel_error ( self , test . tm . q_total_out , <NUM_LIT> , <NUM_LIT> ) \n if __name__ == \"<STR_LIT:__main__>\" : \n unittest . main ( ) \n", "gt": "tm"}
{"input": "\n import os \n from setuptools import setup , find_packages \n with open ( os . path . join ( os . path . dirname ( __file__ ) , '<STR_LIT>' ) ) as f : \n <mask0> = f . read ( ) . splitlines ( ) \n setup ( \n name = '<STR_LIT>' , \n version = '<STR_LIT>' , \n description = '<STR_LIT>' , \n author = '<STR_LIT>' , \n author_email = '<STR_LIT>' , \n packages = find_packages ( exclude = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) , \n include_package_data = True , \n setup_requires = [ \n '<STR_LIT>' , \n ] , \n install_requires = required , \n entry_points = { \n '<STR_LIT>' : [ \n '<STR_LIT>' , \n ] , \n } , \n ) \n del required \n", "gt": "required"}
{"input": "\n import re \n import os \n import sys \n import time \n import hmac \n import base64 \n import hashlib \n import threading \n import logging \n import requests \n from yubico_client . otp import OTP \n from yubico_client . yubico_exceptions import ( StatusCodeError , \n InvalidClientIdError , \n InvalidValidationResponse , \n SignatureVerificationError ) \n from yubico_client . py3 import b \n from yubico_client . py3 import urlencode \n from yubico_client . py3 import unquote \n <mask0> = logging . getLogger ( '<STR_LIT>' ) \n COMMON_CA_LOCATIONS = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' \n ] \n DEFAULT_API_URLS = ( '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' ) \n DEFAULT_TIMEOUT = <NUM_LIT:10> \n DEFAULT_MAX_TIME_WINDOW = <NUM_LIT:5> \n BAD_STATUS_CODES = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' ] \n class Yubico ( object ) : \n def __init__ ( self , client_id , key = None , verify_cert = True , \n translate_otp = True , api_urls = DEFAULT_API_URLS , \n ca_certs_bundle_path = None ) : \n if ca_certs_bundle_path and not self . _is_valid_ca_bundle_file ( ca_certs_bundle_path ) : \n raise ValueError ( ( '<STR_LIT>' \n '<STR_LIT>' ) ) \n self . client_id = client_id \n if key is not None : \n key = base64 . b64decode ( key . encode ( '<STR_LIT:ascii>' ) ) \n self . key = key \n self . verify_cert = verify_cert \n self . translate_otp = translate_otp \n self . api_urls = self . _init_request_urls ( api_urls = api_urls ) \n self . ca_certs_bundle_path = ca_certs_bundle_path \n def verify ( self , otp , timestamp = False , sl = None , timeout = None , \n return_response = False ) : \n \"\"\"<STR_LIT>\"\"\" \n ca_bundle_path = self . _get_ca_bundle_path ( ) \n otp = OTP ( otp , self . translate_otp ) \n rand_str = b ( os . urandom ( <NUM_LIT:30> ) ) \n nonce = base64 . b64encode ( rand_str , b ( '<STR_LIT>' ) ) [ : <NUM_LIT> ] . decode ( '<STR_LIT:utf-8>' ) \n query_string = self . generate_query_string ( otp . otp , nonce , timestamp , \n sl , timeout ) \n threads = [ ] \n timeout = timeout or DEFAULT_TIMEOUT \n for url in self . api_urls : \n thread = URLThread ( '<STR_LIT>' % ( url , query_string ) , timeout , \n self . verify_cert , ca_bundle_path ) \n thread . start ( ) \n threads . append ( thread ) \n start_time = time . time ( ) \n while threads and ( start_time + timeout ) > time . time ( ) : \n for thread in threads : \n if not thread . is_alive ( ) : \n if thread . exception : \n raise thread . exception \n elif thread . response : \n status = self . verify_response ( thread . response , \n otp . otp , nonce , \n return_response ) \n if status : \n if return_response : \n return status \n else : \n return True \n threads . remove ( thread ) \n time . sleep ( <NUM_LIT:0.1> ) \n raise Exception ( '<STR_LIT>' ) \n def verify_multi ( self , otp_list , max_time_window = DEFAULT_MAX_TIME_WINDOW , \n sl = None , timeout = None ) : \n \"\"\"<STR_LIT>\"\"\" \n otps = [ ] \n for otp in otp_list : \n otps . append ( OTP ( otp , self . translate_otp ) ) \n if len ( otp_list ) < <NUM_LIT:2> : \n raise ValueError ( '<STR_LIT>' ) \n device_ids = set ( ) \n for otp in otps : \n device_ids . add ( otp . device_id ) \n if len ( device_ids ) != <NUM_LIT:1> : \n raise Exception ( '<STR_LIT>' ) \n for otp in otps : \n response = self . verify ( otp . otp , True , sl , timeout , \n return_response = True ) \n if not response : \n return False \n otp . timestamp = int ( response [ '<STR_LIT>' ] ) \n count = len ( otps ) \n delta = otps [ count - <NUM_LIT:1> ] . timestamp - otps [ <NUM_LIT:0> ] . timestamp \n delta = delta / <NUM_LIT:8> \n if delta < <NUM_LIT:0> : \n raise Exception ( '<STR_LIT>' \n '<STR_LIT>' ) \n if delta > max_time_window : \n raise Exception ( ( '<STR_LIT>' \n '<STR_LIT>' ) % \n ( max_time_window ) ) \n return True \n def verify_response ( self , response , otp , nonce , return_response = False ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n status = re . search ( r'<STR_LIT>' , response ) . groups ( ) \n if len ( status ) > <NUM_LIT:1> : \n message = '<STR_LIT>' \n raise InvalidValidationResponse ( message , response ) \n status = status [ <NUM_LIT:0> ] \n except ( AttributeError , IndexError ) : \n return False \n signature , parameters = self . parse_parameters_from_response ( response ) \n if self . key : \n generated_signature = self . generate_message_signature ( parameters ) \n if signature != generated_signature : \n logger . warn ( \"<STR_LIT>\" , parameters ) \n raise SignatureVerificationError ( generated_signature , \n signature ) \n param_dict = self . get_parameters_as_dictionary ( parameters ) \n if '<STR_LIT>' in param_dict and param_dict [ '<STR_LIT>' ] != otp : \n message = '<STR_LIT>' \n raise InvalidValidationResponse ( message , response , param_dict ) \n if '<STR_LIT>' in param_dict and param_dict [ '<STR_LIT>' ] != nonce : \n message = '<STR_LIT>' \n raise InvalidValidationResponse ( message , response , param_dict ) \n if status == '<STR_LIT:OK>' : \n if return_response : \n return param_dict \n else : \n return True \n elif status == '<STR_LIT>' : \n raise InvalidClientIdError ( self . client_id ) \n elif status == '<STR_LIT>' : \n raise StatusCodeError ( status ) \n return False \n def generate_query_string ( self , otp , nonce , timestamp = False , sl = None , \n timeout = None ) : \n \"\"\"<STR_LIT>\"\"\" \n data = [ ( '<STR_LIT:id>' , self . client_id ) , \n ( '<STR_LIT>' , otp ) , \n ( '<STR_LIT>' , nonce ) ] \n if timestamp : \n data . append ( ( '<STR_LIT>' , '<STR_LIT:1>' ) ) \n if sl is not None : \n if sl not in range ( <NUM_LIT:0> , <NUM_LIT> ) and sl not in [ '<STR_LIT>' , '<STR_LIT>' ] : \n raise Exception ( '<STR_LIT>' \n '<STR_LIT>' ) \n data . append ( ( '<STR_LIT>' , sl ) ) \n if timeout : \n data . append ( ( '<STR_LIT>' , timeout ) ) \n query_string = urlencode ( data ) \n if self . key : \n hmac_signature = self . generate_message_signature ( query_string ) \n hmac_signature = hmac_signature \n query_string += '<STR_LIT>' % ( hmac_signature . replace ( '<STR_LIT:+>' , '<STR_LIT>' ) ) \n return query_string \n def generate_message_signature ( self , query_string ) : \n \"\"\"<STR_LIT>\"\"\" \n pairs = query_string . split ( '<STR_LIT:&>' ) \n pairs = [ pair . split ( '<STR_LIT:=>' , <NUM_LIT:1> ) for pair in pairs ] \n pairs_sorted = sorted ( pairs ) \n pairs_string = '<STR_LIT:&>' . join ( [ '<STR_LIT:=>' . join ( pair ) for pair in pairs_sorted ] ) \n digest = hmac . new ( self . key , b ( pairs_string ) , hashlib . sha1 ) . digest ( ) \n signature = base64 . b64encode ( digest ) . decode ( '<STR_LIT:utf-8>' ) \n return signature \n def parse_parameters_from_response ( self , response ) : \n \"\"\"<STR_LIT>\"\"\" \n lines = response . splitlines ( ) \n pairs = [ line . strip ( ) . split ( '<STR_LIT:=>' , <NUM_LIT:1> ) for line in lines if '<STR_LIT:=>' in line ] \n pairs = sorted ( pairs ) \n signature = ( [ unquote ( v ) for k , v in pairs if k == '<STR_LIT:h>' ] or [ None ] ) [ <NUM_LIT:0> ] \n query_string = '<STR_LIT:&>' . join ( [ k + '<STR_LIT:=>' + v for k , v in pairs if k != '<STR_LIT:h>' ] ) \n return ( signature , query_string ) \n def get_parameters_as_dictionary ( self , query_string ) : \n \"\"\"<STR_LIT>\"\"\" \n pairs = ( x . split ( '<STR_LIT:=>' , <NUM_LIT:1> ) for x in query_string . split ( '<STR_LIT:&>' ) ) \n return dict ( ( k , unquote ( v ) ) for k , v in pairs ) \n def _init_request_urls ( self , api_urls ) : \n \"\"\"<STR_LIT>\"\"\" \n if not isinstance ( api_urls , ( str , list , tuple ) ) : \n raise TypeError ( '<STR_LIT>' ) \n if isinstance ( api_urls , str ) : \n api_urls = ( api_urls , ) \n api_urls = list ( api_urls ) \n for url in api_urls : \n if not url . startswith ( '<STR_LIT>' ) and not url . startswith ( '<STR_LIT>' ) : \n raise ValueError ( ( '<STR_LIT>' \n '<STR_LIT>' % ( url ) ) ) \n return list ( api_urls ) \n def _get_ca_bundle_path ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n if self . ca_certs_bundle_path : \n return self . ca_certs_bundle_path \n for file_path in COMMON_CA_LOCATIONS : \n if self . _is_valid_ca_bundle_file ( file_path = file_path ) : \n return file_path \n return None \n def _is_valid_ca_bundle_file ( self , file_path ) : \n return os . path . exists ( file_path ) and os . path . isfile ( file_path ) \n class URLThread ( threading . Thread ) : \n def __init__ ( self , url , timeout , verify_cert , ca_bundle_path = None ) : \n super ( URLThread , self ) . __init__ ( ) \n self . url = url \n self . timeout = timeout \n self . verify_cert = verify_cert \n self . ca_bundle_path = ca_bundle_path \n self . exception = None \n self . request = None \n self . response = None \n def run ( self ) : \n logger . debug ( '<STR_LIT>' % ( self . url , \n self . name ) ) \n verify = self . verify_cert \n if self . ca_bundle_path is not None : \n verify = self . ca_bundle_path \n logger . debug ( '<STR_LIT>' % ( self . ca_bundle_path ) ) \n try : \n self . request = requests . get ( url = self . url , timeout = self . timeout , \n verify = verify ) \n self . response = self . request . content . decode ( '<STR_LIT:utf-8>' ) \n except requests . exceptions . SSLError : \n e = sys . exc_info ( ) [ <NUM_LIT:1> ] \n self . exception = e \n self . response = None \n except Exception : \n e = sys . exc_info ( ) [ <NUM_LIT:1> ] \n logger . error ( '<STR_LIT>' + str ( e ) ) \n self . response = None \n args = ( self . url , self . name , self . response ) \n logger . debug ( '<STR_LIT>' % args ) \n", "gt": "logger"}
{"input": "\n import logging \n from app import app , logger \n <mask0> = logging . getLogger ( ) \n root . setLevel ( logging . DEBUG ) \n logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . INFO ) \n if __name__ == '<STR_LIT:__main__>' : \n logger . warn ( \"<STR_LIT>\" ) \n app . run ( host = '<STR_LIT>' , debug = True ) \n", "gt": "root"}
{"input": "\n from nose . tools import ok_ , raises \n from linot import config \n from linot . interfaces . line_interface import LineClientP , LineInterface \n class TestLineClientP : \n def setUp ( self ) : \n self . line_cfg = config [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . lineclient = LineClientP ( self . line_cfg [ '<STR_LIT>' ] , \n self . line_cfg [ '<STR_LIT:password>' ] ) \n def test_find_contact_by_id ( self ) : \n <mask0> = self . lineclient . find_contact_by_id ( self . line_cfg [ '<STR_LIT>' ] ) \n ok_ ( contact . id == self . line_cfg [ '<STR_LIT>' ] ) \n @ raises ( ValueError ) \n def test_find_contact_by_id_exception ( self ) : \n self . lineclient . find_contact_by_id ( self . line_cfg [ '<STR_LIT>' ] [ : - <NUM_LIT:2> ] ) \n class TestLineInterface : \n def setUp ( self ) : \n self . line_interface = LineInterface ( ) \n def test_polling_command ( self ) : \n test_str = '<STR_LIT>' \n me = self . line_interface . _client . getProfile ( ) \n me . sendMessage ( test_str ) \n result = self . line_interface . polling_command ( ) \n ok_ ( len ( result ) == <NUM_LIT:1> , result ) \n submitter , msg = result [ <NUM_LIT:0> ] \n ok_ ( submitter . code == me . id , submitter ) \n ok_ ( msg == test_str , \n '<STR_LIT>' . format ( msg , test_str ) ) \n def test_get_contact_by_id ( self ) : \n me = self . line_interface . _client . getProfile ( ) \n contact = self . line_interface . _get_contact_by_id ( me . id ) \n ok_ ( me . id == contact . id , '<STR_LIT>' . format ( me . id , contact . id ) ) \n def test_send_message ( self ) : \n test_str = '<STR_LIT>' \n me = self . line_interface . _client . getProfile ( ) \n me . sendMessage ( test_str ) \n result = self . line_interface . polling_command ( ) \n me , msg = result [ <NUM_LIT:0> ] \n self . line_interface . send_message ( me , test_str ) \n result = self . line_interface . polling_command ( ) \n me , msg = result [ <NUM_LIT:0> ] \n ok_ ( msg == test_str , '<STR_LIT>' . format ( msg , test_str ) ) \n def test_send_message_to_id ( self ) : \n test_str = '<STR_LIT>' \n me = self . line_interface . _client . getProfile ( ) \n me . sendMessage ( test_str ) \n result = self . line_interface . polling_command ( ) \n me , msg = result [ <NUM_LIT:0> ] \n self . line_interface . _send_message_to_id ( me . code , test_str ) \n result = self . line_interface . polling_command ( ) \n me , msg = result [ <NUM_LIT:0> ] \n ok_ ( msg == test_str , '<STR_LIT>' . format ( msg , test_str ) ) \n def test_get_display_name ( self ) : \n test_str = '<STR_LIT>' \n me = self . line_interface . _client . getProfile ( ) \n me . sendMessage ( test_str ) \n result = self . line_interface . polling_command ( ) \n me_submitter , msg = result [ <NUM_LIT:0> ] \n me_display_name = self . line_interface . get_display_name ( me_submitter ) \n ok_ ( me_display_name == me . name ) \n", "gt": "contact"}
{"input": "\n import pytest \n import socket \n from aiohttp . parsers import StreamWriter , CORK \n from unittest import mock \n def test_nodelay_default ( loop ) : \n <mask0> = mock . Mock ( ) \n s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) \n transport . get_extra_info . return_value = s \n proto = mock . Mock ( ) \n reader = mock . Mock ( ) \n writer = StreamWriter ( transport , proto , reader , loop ) \n assert not writer . tcp_nodelay \n assert not s . getsockopt ( socket . IPPROTO_TCP , socket . TCP_NODELAY ) \n def test_set_nodelay_no_change ( loop ) : \n transport = mock . Mock ( ) \n s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) \n transport . get_extra_info . return_value = s \n proto = mock . Mock ( ) \n reader = mock . Mock ( ) \n writer = StreamWriter ( transport , proto , reader , loop ) \n writer . set_tcp_nodelay ( False ) \n assert not writer . tcp_nodelay \n assert not s . getsockopt ( socket . IPPROTO_TCP , socket . TCP_NODELAY ) \n def test_set_nodelay_enable ( loop ) : \n transport = mock . Mock ( ) \n s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) \n transport . get_extra_info . return_value = s \n proto = mock . Mock ( ) \n reader = mock . Mock ( ) \n writer = StreamWriter ( transport , proto , reader , loop ) \n writer . set_tcp_nodelay ( True ) \n assert writer . tcp_nodelay \n assert s . getsockopt ( socket . IPPROTO_TCP , socket . TCP_NODELAY ) \n def test_set_nodelay_enable_and_disable ( loop ) : \n transport = mock . Mock ( ) \n s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) \n transport . get_extra_info . return_value = s \n proto = mock . Mock ( ) \n reader = mock . Mock ( ) \n writer = StreamWriter ( transport , proto , reader , loop ) \n writer . set_tcp_nodelay ( True ) \n writer . set_tcp_nodelay ( False ) \n assert not writer . tcp_nodelay \n assert not s . getsockopt ( socket . IPPROTO_TCP , socket . TCP_NODELAY ) \n def test_set_nodelay_enable_ipv6 ( loop ) : \n transport = mock . Mock ( ) \n s = socket . socket ( socket . AF_INET6 , socket . SOCK_STREAM ) \n transport . get_extra_info . return_value = s \n proto = mock . Mock ( ) \n reader = mock . Mock ( ) \n writer = StreamWriter ( transport , proto , reader , loop ) \n writer . set_tcp_nodelay ( True ) \n assert writer . tcp_nodelay \n assert s . getsockopt ( socket . IPPROTO_TCP , socket . TCP_NODELAY ) \n @ pytest . mark . skipif ( not hasattr ( socket , '<STR_LIT>' ) , \n reason = \"<STR_LIT>\" ) \n def test_set_nodelay_enable_unix ( loop ) : \n transport = mock . Mock ( ) \n s = socket . socket ( socket . AF_UNIX , socket . SOCK_STREAM ) \n transport . get_extra_info . return_value = s \n proto = mock . Mock ( ) \n reader = mock . Mock ( ) \n writer = StreamWriter ( transport , proto , reader , loop ) \n writer . set_tcp_nodelay ( True ) \n assert writer . tcp_nodelay \n def test_set_nodelay_enable_no_socket ( loop ) : \n transport = mock . Mock ( ) \n transport . get_extra_info . return_value = None \n proto = mock . Mock ( ) \n reader = mock . Mock ( ) \n writer = StreamWriter ( transport , proto , reader , loop ) \n writer . set_tcp_nodelay ( True ) \n assert writer . tcp_nodelay \n assert writer . _socket is None \n @ pytest . mark . skipif ( CORK is None , reason = \"<STR_LIT>\" ) \n def test_cork_default ( loop ) : \n transport = mock . Mock ( ) \n s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) \n transport . get_extra_info . return_value = s \n proto = mock . Mock ( ) \n reader = mock . Mock ( ) \n writer = StreamWriter ( transport , proto , reader , loop ) \n assert not writer . tcp_cork \n assert not s . getsockopt ( socket . IPPROTO_TCP , CORK ) \n @ pytest . mark . skipif ( CORK is None , reason = \"<STR_LIT>\" ) \n def test_set_cork_no_change ( loop ) : \n transport = mock . Mock ( ) \n s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) \n transport . get_extra_info . return_value = s \n proto = mock . Mock ( ) \n reader = mock . Mock ( ) \n writer = StreamWriter ( transport , proto , reader , loop ) \n writer . set_tcp_cork ( False ) \n assert not writer . tcp_cork \n assert not s . getsockopt ( socket . IPPROTO_TCP , CORK ) \n @ pytest . mark . skipif ( CORK is None , reason = \"<STR_LIT>\" ) \n def test_set_cork_enable ( loop ) : \n transport = mock . Mock ( ) \n s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) \n transport . get_extra_info . return_value = s \n proto = mock . Mock ( ) \n reader = mock . Mock ( ) \n writer = StreamWriter ( transport , proto , reader , loop ) \n writer . set_tcp_cork ( True ) \n assert writer . tcp_cork \n assert s . getsockopt ( socket . IPPROTO_TCP , CORK ) \n @ pytest . mark . skipif ( CORK is None , reason = \"<STR_LIT>\" ) \n def test_set_cork_enable_and_disable ( loop ) : \n transport = mock . Mock ( ) \n s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) \n transport . get_extra_info . return_value = s \n proto = mock . Mock ( ) \n reader = mock . Mock ( ) \n writer = StreamWriter ( transport , proto , reader , loop ) \n writer . set_tcp_cork ( True ) \n writer . set_tcp_cork ( False ) \n assert not writer . tcp_cork \n assert not s . getsockopt ( socket . IPPROTO_TCP , CORK ) \n @ pytest . mark . skipif ( CORK is None , reason = \"<STR_LIT>\" ) \n def test_set_cork_enable_ipv6 ( loop ) : \n transport = mock . Mock ( ) \n s = socket . socket ( socket . AF_INET6 , socket . SOCK_STREAM ) \n transport . get_extra_info . return_value = s \n proto = mock . Mock ( ) \n reader = mock . Mock ( ) \n writer = StreamWriter ( transport , proto , reader , loop ) \n writer . set_tcp_cork ( True ) \n assert writer . tcp_cork \n assert s . getsockopt ( socket . IPPROTO_TCP , CORK ) \n @ pytest . mark . skipif ( not hasattr ( socket , '<STR_LIT>' ) , \n reason = \"<STR_LIT>\" ) \n @ pytest . mark . skipif ( CORK is None , reason = \"<STR_LIT>\" ) \n def test_set_cork_enable_unix ( loop ) : \n transport = mock . Mock ( ) \n s = socket . socket ( socket . AF_UNIX , socket . SOCK_STREAM ) \n transport . get_extra_info . return_value = s \n proto = mock . Mock ( ) \n reader = mock . Mock ( ) \n writer = StreamWriter ( transport , proto , reader , loop ) \n writer . set_tcp_cork ( True ) \n assert writer . tcp_cork \n @ pytest . mark . skipif ( CORK is None , reason = \"<STR_LIT>\" ) \n def test_set_cork_enable_no_socket ( loop ) : \n transport = mock . Mock ( ) \n transport . get_extra_info . return_value = None \n proto = mock . Mock ( ) \n reader = mock . Mock ( ) \n writer = StreamWriter ( transport , proto , reader , loop ) \n writer . set_tcp_cork ( True ) \n assert writer . tcp_cork \n assert writer . _socket is None \n @ pytest . mark . skipif ( CORK is None , reason = \"<STR_LIT>\" ) \n def test_set_enabling_cork_disables_nodelay ( loop ) : \n transport = mock . Mock ( ) \n s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) \n transport . get_extra_info . return_value = s \n proto = mock . Mock ( ) \n reader = mock . Mock ( ) \n writer = StreamWriter ( transport , proto , reader , loop ) \n writer . set_tcp_nodelay ( True ) \n writer . set_tcp_cork ( True ) \n assert not writer . tcp_nodelay \n assert not s . getsockopt ( socket . IPPROTO_TCP , socket . TCP_NODELAY ) \n assert writer . tcp_cork \n assert s . getsockopt ( socket . IPPROTO_TCP , CORK ) \n @ pytest . mark . skipif ( CORK is None , reason = \"<STR_LIT>\" ) \n def test_set_enabling_nodelay_disables_cork ( loop ) : \n transport = mock . Mock ( ) \n s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) \n transport . get_extra_info . return_value = s \n proto = mock . Mock ( ) \n reader = mock . Mock ( ) \n writer = StreamWriter ( transport , proto , reader , loop ) \n writer . set_tcp_cork ( True ) \n writer . set_tcp_nodelay ( True ) \n assert writer . tcp_nodelay \n assert s . getsockopt ( socket . IPPROTO_TCP , socket . TCP_NODELAY ) \n assert not writer . tcp_cork \n assert not s . getsockopt ( socket . IPPROTO_TCP , CORK ) \n", "gt": "transport"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import argparse \n import logging \n from collections import namedtuple \n from . import placeholder \n <mask0> = logging . getLogger ( ) \n ShortenerSettings = namedtuple ( '<STR_LIT>' , [ \n '<STR_LIT:name>' , \n '<STR_LIT>' \n ] ) \n Settings = namedtuple ( '<STR_LIT>' , [ \n '<STR_LIT:source>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT:strict>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' \n ] ) \n def default_settings ( ) : \n return Settings ( \n verbose = False , \n strict = True , \n force = False , \n source = '<STR_LIT:src>' , \n destination = '<STR_LIT:target>' , \n templates = '<STR_LIT>' , \n images = '<STR_LIT>' , \n right_to_left = [ '<STR_LIT>' , '<STR_LIT>' ] , \n pattern = '<STR_LIT>' , \n shortener = { } , \n exclusive = None , \n default_locale = '<STR_LIT>' , \n workers_pool = <NUM_LIT:10> , \n local_images = '<STR_LIT>' , \n save = None , \n cms_service_host = \"<STR_LIT>\" \n ) \n def read_args ( argsargs = argparse . ArgumentParser ) : \n settings = default_settings ( ) \n logger . debug ( '<STR_LIT>' ) \n args = argsargs ( epilog = '<STR_LIT>' ) \n args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = '<STR_LIT>' % settings . source ) \n args . add_argument ( \n '<STR_LIT>' , '<STR_LIT>' , help = '<STR_LIT>' % settings . exclusive ) \n args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , \n help = '<STR_LIT>' % settings . destination ) \n args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = '<STR_LIT>' % settings . templates ) \n args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , \n help = '<STR_LIT>' % settings . right_to_left ) \n args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = '<STR_LIT>' % settings . images ) \n args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = '<STR_LIT>' % settings . pattern ) \n args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , \n help = '<STR_LIT>' , \n action = '<STR_LIT>' ) \n args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = '<STR_LIT>' , action = '<STR_LIT:store_true>' ) \n args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , \n help = '<STR_LIT>' % settings . workers_pool , type = int ) \n args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = '<STR_LIT>' , action = '<STR_LIT:store_true>' ) \n args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = '<STR_LIT>' , action = '<STR_LIT:store_true>' ) \n subparsers = args . add_subparsers ( help = '<STR_LIT>' , dest = '<STR_LIT>' ) \n template_parser = subparsers . add_parser ( '<STR_LIT>' ) \n template_parser . add_argument ( '<STR_LIT>' , help = '<STR_LIT>' ) \n template_parser . add_argument ( '<STR_LIT>' , \n help = '<STR_LIT>' ) \n config_parser = subparsers . add_parser ( '<STR_LIT>' ) \n config_parser . add_argument ( '<STR_LIT>' , help = '<STR_LIT>' ) \n gui_parser = subparsers . add_parser ( '<STR_LIT>' ) \n gui_parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , type = int , help = '<STR_LIT>' , default = <NUM_LIT> ) \n gui_parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , type = str , help = '<STR_LIT>' , \n default = '<STR_LIT>' ) \n gui_parser . add_argument ( '<STR_LIT>' , type = str , help = '<STR_LIT>' ) \n gui_parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , type = str , help = '<STR_LIT>' ) \n return args . parse_args ( ) \n def read_settings ( args ) : \n args = vars ( args ) \n settings = default_settings ( ) . _asdict ( ) \n for k in settings : \n if k in args and args [ k ] is not None : \n settings [ k ] = args [ k ] \n return Settings ( ** settings ) \n def print_version ( ) : \n import pkg_resources \n version = pkg_resources . require ( '<STR_LIT>' ) [ <NUM_LIT:0> ] . version \n print ( version ) \n return True \n def generate_config ( args ) : \n if args . config_name == '<STR_LIT>' : \n logger . info ( '<STR_LIT>' ) \n settings = read_settings ( args ) \n placeholder . generate_config ( settings ) \n return True \n return False \n def execute_command ( args ) : \n if args . command == '<STR_LIT>' : \n return generate_config ( args ) \n elif args . command == '<STR_LIT>' : \n from . gui . gui import serve \n serve ( args ) \n return True \n return False \n", "gt": "logger"}
{"input": "\n from ldap3 import Server , Connection , ALL \n \"\"\"<STR_LIT>\"\"\" \n def rotate ( record , newpassword ) : \n <mask0> = False \n host = record . get ( '<STR_LIT>' ) \n user_dn = record . get ( '<STR_LIT>' ) \n try : \n server = Server ( \n host = host , \n use_ssl = True , \n get_info = ALL ) \n conn = Connection ( \n server = server , \n user = user_dn , \n password = record . password , \n auto_bind = True ) \n changePwdResult = conn . extend . microsoft . modify_password ( user_dn , newpassword ) \n if ( changePwdResult == True ) : \n print ( '<STR_LIT>' ) \n record . password = newpassword \n result = True \n else : \n print ( \"<STR_LIT>\" % ( changePwdResult ) ) \n conn . unbind ( ) \n except : \n print ( \"<STR_LIT>\" ) \n return result \n", "gt": "result"}
{"input": "\n from keepercommander . record import Record \n def sample_record ( ) : \n <mask0> = Record ( ) \n record . folder = '<STR_LIT>' \n record . title = '<STR_LIT:title>' \n record . login = '<STR_LIT>' \n record . password = '<STR_LIT:password>' \n record . login_url = '<STR_LIT>' \n record . notes = '<STR_LIT>' \n record . custom_fields = [ \n { '<STR_LIT:name>' : '<STR_LIT>' , '<STR_LIT:value>' : '<STR_LIT>' , '<STR_LIT:type>' : '<STR_LIT:text>' } , \n { '<STR_LIT:name>' : '<STR_LIT>' , '<STR_LIT:value>' : '<STR_LIT>' , '<STR_LIT:type>' : '<STR_LIT:text>' } ] \n return record \n class TestRecord : \n def test_to_tab_delimited ( self ) : \n assert sample_record ( ) . to_tab_delimited ( ) == '<STR_LIT>' \n def test_to_tab_dictionary ( self ) : \n assert sample_record ( ) . to_dictionary ( ) == { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT:title>' : '<STR_LIT:title>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT:password>' : '<STR_LIT:password>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : [ \n { '<STR_LIT:name>' : '<STR_LIT>' , '<STR_LIT:value>' : '<STR_LIT>' , '<STR_LIT:type>' : '<STR_LIT:text>' } , \n { '<STR_LIT:name>' : '<STR_LIT>' , '<STR_LIT:value>' : '<STR_LIT>' , '<STR_LIT:type>' : '<STR_LIT:text>' } ] , \n } \n", "gt": "record"}
{"input": "\n import os \n import logbook \n import pytest \n import pyshark \n @ pytest . fixture \n def caps_directory ( ) : \n return os . path . join ( os . path . dirname ( __file__ ) , '<STR_LIT>' ) \n @ pytest . fixture \n def lazy_simple_capture ( request , caps_directory ) : \n \"\"\"<STR_LIT>\"\"\" \n <mask0> = os . path . join ( caps_directory , '<STR_LIT>' ) \n cap = pyshark . FileCapture ( cap_path ) \n cap . log . level = logbook . DEBUG \n def finalizer ( ) : \n cap . close ( ) \n cap . eventloop . stop ( ) \n request . addfinalizer ( finalizer ) \n return cap \n @ pytest . fixture \n def simple_capture ( lazy_simple_capture ) : \n \"\"\"<STR_LIT>\"\"\" \n lazy_simple_capture . load_packets ( ) \n return lazy_simple_capture \n", "gt": "cap_path"}
{"input": "\n from cornice import Service \n from pyramid import httpexceptions \n from pyramid . security import NO_PERMISSION_REQUIRED \n from kinto . events import ServerFlushed \n <mask0> = Service ( name = '<STR_LIT>' , \n description = '<STR_LIT>' , \n path = '<STR_LIT>' ) \n @ flush . post ( permission = NO_PERMISSION_REQUIRED ) \n def flush_post ( request ) : \n request . registry . storage . flush ( ) \n request . registry . permission . flush ( ) \n request . registry . cache . flush ( ) \n event = ServerFlushed ( request ) \n request . registry . notify ( event ) \n return httpexceptions . HTTPAccepted ( ) \n", "gt": "flush"}
{"input": "\n import os \n os . environ [ '<STR_LIT>' ] = os . environ . get ( '<STR_LIT>' , '<STR_LIT>' ) \n from tests import base \n def setUpModule ( ) : \n \"\"\"<STR_LIT>\"\"\" \n base . enabledPlugins . append ( '<STR_LIT>' ) \n base . enabledPlugins . append ( '<STR_LIT>' ) \n base . enabledPlugins . append ( '<STR_LIT>' ) \n base . enabledPlugins . append ( '<STR_LIT>' ) \n base . startServer ( False ) \n def tearDownModule ( ) : \n \"\"\"<STR_LIT>\"\"\" \n base . stopServer ( ) \n class SourceTestCase ( base . TestCase ) : \n \"\"\"<STR_LIT>\"\"\" \n def setUp ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n super ( SourceTestCase , self ) . setUp ( ) \n self . _user = self . model ( '<STR_LIT:user>' ) . createUser ( \n '<STR_LIT>' , '<STR_LIT:password>' , '<STR_LIT>' , '<STR_LIT:user>' , \n '<STR_LIT>' ) \n def testSource ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n <mask0> = '<STR_LIT>' \n params = { \n '<STR_LIT>' : self . _user [ '<STR_LIT>' ] , \n } \n response = self . request ( path = path , method = '<STR_LIT:GET>' , params = params ) \n self . assertStatusOk ( response ) \n folder = response . json [ '<STR_LIT>' ] \n self . assertEquals ( folder , None ) \n response = self . request ( path = path , method = '<STR_LIT:POST>' , params = params ) \n self . assertStatus ( response , <NUM_LIT> ) \n response = self . request ( path = path , method = '<STR_LIT:POST>' , params = params , user = self . _user ) \n self . assertStatusOk ( response ) \n folder = response . json [ '<STR_LIT>' ] \n self . assertNotEquals ( folder , None ) \n self . assertEquals ( folder [ '<STR_LIT>' ] , '<STR_LIT:user>' ) \n self . assertEquals ( folder [ '<STR_LIT>' ] , str ( self . _user [ '<STR_LIT>' ] ) ) \n response = self . request ( path = path , method = '<STR_LIT:GET>' , params = params ) \n self . assertStatusOk ( response ) \n folder = response . json [ '<STR_LIT>' ] \n self . assertEquals ( folder , None ) \n response = self . request ( path = path , method = '<STR_LIT:GET>' , params = params , user = self . _user ) \n self . assertStatusOk ( response ) \n folder = response . json [ '<STR_LIT>' ] \n self . assertNotEquals ( folder , None ) \n self . assertEquals ( folder [ '<STR_LIT>' ] , '<STR_LIT:user>' ) \n self . assertEquals ( folder [ '<STR_LIT>' ] , str ( self . _user [ '<STR_LIT>' ] ) ) \n params = { \n '<STR_LIT:name>' : '<STR_LIT>' , \n '<STR_LIT>' : folder [ '<STR_LIT>' ] \n } \n response = self . request ( path = '<STR_LIT>' , method = '<STR_LIT:POST>' , params = params , \n user = self . _user ) \n item1Id = response . json [ '<STR_LIT>' ] \n params = { \n '<STR_LIT:name>' : '<STR_LIT>' , \n '<STR_LIT>' : folder [ '<STR_LIT>' ] \n } \n response = self . request ( path = '<STR_LIT>' , method = '<STR_LIT:POST>' , params = params , \n user = self . _user ) \n item2Id = response . json [ '<STR_LIT>' ] \n path = '<STR_LIT>' \n params = { \n '<STR_LIT>' : self . _user [ '<STR_LIT>' ] , \n } \n response = self . request ( path = path , method = '<STR_LIT:GET>' , params = params ) \n self . assertStatusOk ( response ) \n self . assertEquals ( len ( response . json ) , <NUM_LIT:0> ) \n response = self . request ( path = path , method = '<STR_LIT:GET>' , params = params , user = self . _user ) \n self . assertStatusOk ( response ) \n self . assertEquals ( len ( response . json ) , <NUM_LIT:2> ) \n sourceIds = [ d [ '<STR_LIT>' ] for d in response . json ] \n self . assertTrue ( item1Id in sourceIds , \"<STR_LIT>\" ) \n self . assertTrue ( item2Id in sourceIds , \"<STR_LIT>\" ) \n", "gt": "path"}
{"input": "\n from girder . api import access \n from girder . api . describe import Description \n from girder . api . rest import loadmodel , RestException \n from girder . constants import AccessType \n from girder . plugins . minerva . rest . dataset import Dataset \n from girder . plugins . minerva . utility . minerva_utility import findDatasetFolder , updateMinervaMetadata \n class GeojsonDataset ( Dataset ) : \n def __init__ ( self ) : \n self . resourceName = '<STR_LIT>' \n self . route ( '<STR_LIT:POST>' , ( ) , self . createGeojsonDataset ) \n @ access . user \n @ loadmodel ( map = { '<STR_LIT>' : '<STR_LIT>' } , model = '<STR_LIT>' , \n level = AccessType . WRITE ) \n def createGeojsonDataset ( self , item , params ) : \n <mask0> = self . getCurrentUser ( ) \n folder = findDatasetFolder ( user , user , create = True ) \n if folder is None : \n raise RestException ( '<STR_LIT>' ) \n if folder [ '<STR_LIT>' ] != item [ '<STR_LIT>' ] : \n raise RestException ( \"<STR_LIT>\" + \n \"<STR_LIT>\" ) \n minerva_metadata = { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n } \n for file in self . model ( '<STR_LIT>' ) . childFiles ( item = item , limit = <NUM_LIT:0> ) : \n if '<STR_LIT>' in file [ '<STR_LIT>' ] or '<STR_LIT>' in file [ '<STR_LIT>' ] : \n minerva_metadata [ '<STR_LIT>' ] = [ { \n '<STR_LIT:name>' : file [ '<STR_LIT:name>' ] , '<STR_LIT>' : file [ '<STR_LIT>' ] } ] \n minerva_metadata [ '<STR_LIT>' ] = { \n '<STR_LIT:name>' : file [ '<STR_LIT:name>' ] , '<STR_LIT>' : file [ '<STR_LIT>' ] } \n break \n if '<STR_LIT>' not in minerva_metadata : \n raise RestException ( '<STR_LIT>' ) \n updateMinervaMetadata ( item , minerva_metadata ) \n return item \n createGeojsonDataset . description = ( \n Description ( '<STR_LIT>' ) \n . responseClass ( '<STR_LIT>' ) \n . param ( '<STR_LIT>' , '<STR_LIT>' , required = True ) \n . errorResponse ( '<STR_LIT>' ) \n . errorResponse ( '<STR_LIT>' , <NUM_LIT> ) ) \n", "gt": "user"}
{"input": "\n from setuptools import setup , find_packages \n import re \n import os \n from os . path import join as opj \n <mask0> = os . path . dirname ( os . path . realpath ( __file__ ) ) \n def read ( fname ) : \n contents = '<STR_LIT>' \n with open ( fname ) as f : \n contents = f . read ( ) \n return contents \n package_name = '<STR_LIT>' \n def version ( ) : \n text = read ( opj ( curdir , package_name , '<STR_LIT>' ) ) \n matches = re . findall ( \"<STR_LIT>\" , text ) \n return matches [ <NUM_LIT:0> ] [ <NUM_LIT:1> ] \n install_requires = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] \n test_requires = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] \n if __name__ == '<STR_LIT:__main__>' : \n setup ( \n name = package_name , \n packages = [ package_name ] , \n include_package_data = True , \n author = '<STR_LIT>' , \n author_email = '<STR_LIT>' , \n version = version ( ) , \n description = \"<STR_LIT>\" , \n long_description = read ( opj ( curdir , '<STR_LIT>' ) ) , \n url = '<STR_LIT>' , \n install_requires = install_requires , \n license = '<STR_LIT>' , \n classifiers = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] , \n package_data = { '<STR_LIT>' : [ '<STR_LIT>' ] } , \n zip_safe = False , \n tests_require = test_requires , \n ) \n", "gt": "curdir"}
{"input": "\n import unittest \n import utils \n import sdk \n <mask0> = [ '<STR_LIT>' ] \n change_folder_permissions = [ '<STR_LIT>' , '<STR_LIT>' ] \n list_permissions = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n readonly_permissions = [ '<STR_LIT>' , '<STR_LIT>' ] \n class Permissions ( unittest . TestCase ) : \n new_roles = { } \n @ utils . allow ( services = list_permissions ) \n def setUp ( self ) : \n acc = self . account \n if acc . service in list_permissions : \n self . test_folder = utils . create_or_get_test_folder ( acc ) \n self . test_file = utils . create_test_file ( acc ) \n new_roles = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } \n if acc . service in change_folder_permissions : \n self . new_roles = new_roles \n self . test_folder . permissions . create ( data = self . new_roles ) \n if acc . service in change_file_permissions : \n self . new_roles = new_roles \n self . test_file . permissions . create ( data = self . new_roles ) \n def list_helper ( self , data ) : \n result = data . permissions . all ( ) \n self . assertIsInstance ( result , sdk . resources . AnnotatedList ) \n owner_exists = False \n for perm in result : \n self . assertIsInstance ( perm , sdk . resources . Permission ) \n if self . account . service not in readonly_permissions : \n if perm . role == \"<STR_LIT>\" : \n owner_exists = True \n else : \n self . assertIn ( perm . email , self . new_roles ) \n self . assertEqual ( perm . role , self . new_roles . get ( perm . email ) ) \n self . assertTrue ( owner_exists ) \n def test_folder_permissions_list ( self ) : \n if self . account . service in list_permissions : \n self . list_helper ( self . test_folder ) \n def test_folder_permissions_set ( self ) : \n if self . account . service in change_folder_permissions : \n self . new_roles = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } \n result = self . test_folder . permissions . create ( data = self . new_roles ) \n self . assertIsInstance ( result . permissions , list ) \n self . list_helper ( self . test_folder ) \n def test_folder_permissions_update ( self ) : \n if self . account . service in change_folder_permissions : \n self . new_roles . update ( { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } ) \n result = self . test_folder . permissions . update ( data = self . new_roles ) \n self . assertIsInstance ( result . permissions , list ) \n self . list_helper ( self . test_folder ) \n def test_file_permissions_list ( self ) : \n if self . account . service in list_permissions : \n self . list_helper ( self . test_file ) \n def test_file_permissions_set ( self ) : \n if self . account . service in change_file_permissions : \n self . new_roles = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } \n result = self . test_file . permissions . create ( data = self . new_roles ) \n self . assertIsInstance ( result . permissions , list ) \n self . list_helper ( self . test_file ) \n def test_file_permissions_update ( self ) : \n if self . account . service in change_file_permissions : \n self . new_roles . update ( { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } ) \n result = self . test_file . permissions . update ( data = self . new_roles ) \n self . assertIsInstance ( result . permissions , list ) \n self . list_helper ( self . test_file ) \n def test_cases ( ) : \n return [ utils . create_test_case ( acc , Permissions ) for acc in utils . accounts ] \n if __name__ == '<STR_LIT:__main__>' : \n suite = utils . create_suite ( test_cases ( ) ) \n unittest . TextTestRunner ( verbosity = <NUM_LIT:2> ) . run ( suite ) \n", "gt": "change_file_permissions"}
{"input": "\n try : \n <mask0> = basestring \n except NameError : \n basestring = str \n from . nmea import NMEASentence \n class NMEAFile ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , f , * args , ** kwargs ) : \n super ( NMEAFile , self ) . __init__ ( ) \n if isinstance ( f , basestring ) or args or kwargs : \n self . _file = self . open ( f , * args , ** kwargs ) \n else : \n self . _file = f \n self . _context = None \n def open ( self , fp , mode = '<STR_LIT:r>' ) : \n \"\"\"<STR_LIT>\"\"\" \n self . _file = open ( fp , mode = mode ) \n return self . _file \n def close ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n self . _file . close ( ) \n def __iter__ ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n for line in self . _file : \n yield self . parse ( line ) \n def __enter__ ( self ) : \n if hasattr ( self . _file , '<STR_LIT>' ) : \n self . _context = self . _file . __enter__ ( ) \n return self \n def __exit__ ( self , exc_type , exc_val , exc_tb ) : \n if self . _context : \n ctx = self . _context \n self . _context = None \n ctx . __exit__ ( exc_type , exc_val , exc_tb ) \n def next ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n data = self . _file . readline ( ) \n return self . parse ( data ) \n def parse ( self , s ) : \n return NMEASentence . parse ( s ) \n def readline ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n data = self . _file . readline ( ) \n s = self . parse ( data ) \n return s \n def read ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return [ s for s in self ] \n", "gt": "basestring"}
{"input": "\n from optparse import make_option \n from django . core . management . base import BaseCommand \n from django . utils . translation import ugettext as _ \n from django_q . cluster import Cluster \n class Command ( BaseCommand ) : \n <mask0> = _ ( \"<STR_LIT>\" ) \n option_list = BaseCommand . option_list + ( \n make_option ( '<STR_LIT>' , \n action = '<STR_LIT:store_true>' , \n dest = '<STR_LIT>' , \n default = False , \n help = '<STR_LIT>' ) , \n ) \n def handle ( self , * args , ** options ) : \n q = Cluster ( ) \n q . start ( ) \n if options . get ( '<STR_LIT>' , False ) : \n q . stop ( ) \n", "gt": "help"}
{"input": "\n <mask0> = \"\"\"<STR_LIT>\"\"\" \n import sys \n import base64 \n import zlib \n class DictImporter ( object ) : \n def __init__ ( self , sources ) : \n self . sources = sources \n def find_module ( self , fullname , path = None ) : \n if fullname == \"<STR_LIT>\" and sys . version_info >= ( <NUM_LIT:2> , <NUM_LIT:7> ) : \n return None \n if fullname in self . sources : \n return self \n if fullname + '<STR_LIT>' in self . sources : \n return self \n return None \n def load_module ( self , fullname ) : \n from types import ModuleType \n try : \n s = self . sources [ fullname ] \n is_pkg = False \n except KeyError : \n s = self . sources [ fullname + '<STR_LIT>' ] \n is_pkg = True \n co = compile ( s , fullname , '<STR_LIT>' ) \n module = sys . modules . setdefault ( fullname , ModuleType ( fullname ) ) \n module . __file__ = \"<STR_LIT>\" % ( __file__ , fullname ) \n module . __loader__ = self \n if is_pkg : \n module . __path__ = [ fullname ] \n do_exec ( co , module . __dict__ ) \n return sys . modules [ fullname ] \n def get_source ( self , name ) : \n res = self . sources . get ( name ) \n if res is None : \n res = self . sources . get ( name + '<STR_LIT>' ) \n return res \n if __name__ == \"<STR_LIT:__main__>\" : \n try : \n import pkg_resources \n except ImportError : \n sys . stderr . write ( \"<STR_LIT>\" ) \n sys . exit ( <NUM_LIT:2> ) \n if sys . version_info >= ( <NUM_LIT:3> , <NUM_LIT:0> ) : \n exec ( \"<STR_LIT>\" ) \n import pickle \n sources = sources . encode ( \"<STR_LIT:ascii>\" ) \n sources = pickle . loads ( zlib . decompress ( base64 . decodebytes ( sources ) ) ) \n else : \n import cPickle as pickle \n exec ( \"<STR_LIT>\" ) \n sources = pickle . loads ( zlib . decompress ( base64 . decodestring ( sources ) ) ) \n importer = DictImporter ( sources ) \n sys . meta_path . insert ( <NUM_LIT:0> , importer ) \n entry = \"<STR_LIT>\" \n do_exec ( entry , locals ( ) ) \n", "gt": "sources"}
{"input": "\n from __future__ import with_statement \n from contextlib import contextmanager \n from datetime import datetime \n from UserDict import DictMixin \n import bcrypt \n from pyramid . location import lineage \n from pyramid . security import view_execution_permitted \n from six import string_types \n from sqlalchemy import Boolean , bindparam \n from sqlalchemy import Column \n from sqlalchemy import DateTime \n from sqlalchemy import func \n from sqlalchemy import Integer \n from sqlalchemy import Unicode \n from sqlalchemy . orm . exc import NoResultFound \n from sqlalchemy . sql . expression import and_ \n from sqlalchemy . sql . expression import or_ \n from zope . deprecation . deprecation import deprecated \n from kotti import Base \n from kotti import DBSession \n from kotti import get_settings \n from kotti . sqla import bakery \n from kotti . sqla import JsonType \n from kotti . sqla import MutationList \n from kotti . util import _ \n from kotti . util import request_cache \n from kotti . util import DontCache \n def get_principals ( ) : \n return get_settings ( ) [ '<STR_LIT>' ] [ <NUM_LIT:0> ] ( ) \n @ request_cache ( lambda request : None ) \n def get_user ( request ) : \n <mask0> = request . unauthenticated_userid \n return get_principals ( ) . get ( userid ) \n def has_permission ( permission , context , request ) : \n \"\"\"<STR_LIT>\"\"\" \n return request . has_permission ( permission , context ) \n deprecated ( u'<STR_LIT>' , \n u\"<STR_LIT>\" \n u\"<STR_LIT>\" \n u\"<STR_LIT>\" ) \n class Principal ( Base ) : \n \"\"\"<STR_LIT>\"\"\" \n id = Column ( Integer , primary_key = True ) \n name = Column ( Unicode ( <NUM_LIT:100> ) , unique = True ) \n password = Column ( Unicode ( <NUM_LIT:100> ) ) \n active = Column ( Boolean ) \n confirm_token = Column ( Unicode ( <NUM_LIT:100> ) ) \n title = Column ( Unicode ( <NUM_LIT:100> ) , nullable = False ) \n email = Column ( Unicode ( <NUM_LIT:100> ) , unique = True ) \n groups = Column ( MutationList . as_mutable ( JsonType ) , nullable = False ) \n creation_date = Column ( DateTime ( ) , nullable = False ) \n last_login_date = Column ( DateTime ( ) ) \n __tablename__ = '<STR_LIT>' \n __mapper_args__ = dict ( \n order_by = name , \n ) \n def __init__ ( self , name , password = None , active = True , confirm_token = None , \n title = u\"<STR_LIT>\" , email = None , groups = None ) : \n self . name = name \n if password is not None : \n password = get_principals ( ) . hash_password ( password ) \n self . password = password \n self . active = active \n self . confirm_token = confirm_token \n self . title = title \n self . email = email \n if groups is None : \n groups = [ ] \n self . groups = groups \n self . creation_date = datetime . now ( ) \n self . last_login_date = None \n def __repr__ ( self ) : \n return u'<STR_LIT>' . format ( self . name ) \n class AbstractPrincipals ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def __getitem__ ( self , name ) : \n \"\"\"<STR_LIT>\"\"\" \n def __setitem__ ( self , name , principal ) : \n \"\"\"<STR_LIT>\"\"\" \n def __delitem__ ( self , name ) : \n \"\"\"<STR_LIT>\"\"\" \n def keys ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n def search ( self , ** kwargs ) : \n \"\"\"<STR_LIT>\"\"\" \n def hash_password ( self , password ) : \n \"\"\"<STR_LIT>\"\"\" \n def validate_password ( self , clear , hashed ) : \n \"\"\"<STR_LIT>\"\"\" \n ROLES = { \n u'<STR_LIT>' : Principal ( u'<STR_LIT>' , title = _ ( u'<STR_LIT>' ) ) , \n u'<STR_LIT>' : Principal ( u'<STR_LIT>' , title = _ ( u'<STR_LIT>' ) ) , \n u'<STR_LIT>' : Principal ( u'<STR_LIT>' , title = _ ( u'<STR_LIT>' ) ) , \n u'<STR_LIT>' : Principal ( u'<STR_LIT>' , title = _ ( u'<STR_LIT>' ) ) , \n } \n _DEFAULT_ROLES = ROLES . copy ( ) \n SHARING_ROLES = [ u'<STR_LIT>' , u'<STR_LIT>' , u'<STR_LIT>' ] \n USER_MANAGEMENT_ROLES = SHARING_ROLES + [ '<STR_LIT>' ] \n _DEFAULT_SHARING_ROLES = SHARING_ROLES [ : ] \n _DEFAULT_USER_MANAGEMENT_ROLES = USER_MANAGEMENT_ROLES [ : ] \n SITE_ACL = [ \n [ '<STR_LIT>' , '<STR_LIT>' , [ '<STR_LIT>' ] ] , \n [ '<STR_LIT>' , '<STR_LIT>' , [ '<STR_LIT>' ] ] , \n [ '<STR_LIT>' , '<STR_LIT>' , [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ] , \n [ '<STR_LIT>' , '<STR_LIT>' , [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ] , \n ] \n def set_roles ( roles_dict ) : \n ROLES . clear ( ) \n ROLES . update ( roles_dict ) \n def set_sharing_roles ( role_names ) : \n SHARING_ROLES [ : ] = role_names \n def set_user_management_roles ( role_names ) : \n USER_MANAGEMENT_ROLES [ : ] = role_names \n def reset_roles ( ) : \n ROLES . clear ( ) \n ROLES . update ( _DEFAULT_ROLES ) \n def reset_sharing_roles ( ) : \n SHARING_ROLES [ : ] = _DEFAULT_SHARING_ROLES \n def reset_user_management_roles ( ) : \n USER_MANAGEMENT_ROLES [ : ] = _DEFAULT_USER_MANAGEMENT_ROLES \n def reset ( ) : \n reset_roles ( ) \n reset_sharing_roles ( ) \n reset_user_management_roles ( ) \n class PersistentACLMixin ( object ) : \n def _get_acl ( self ) : \n if self . _acl is None : \n raise AttributeError ( '<STR_LIT>' ) \n return self . _acl \n def _set_acl ( self , value ) : \n self . _acl = value \n def _del_acl ( self ) : \n self . _acl = None \n __acl__ = property ( _get_acl , _set_acl , _del_acl ) \n def _cachekey_list_groups_raw ( name , context ) : \n context_id = context is not None and getattr ( context , '<STR_LIT:id>' , id ( context ) ) \n return name , context_id \n @ request_cache ( _cachekey_list_groups_raw ) \n def list_groups_raw ( name , context ) : \n \"\"\"<STR_LIT>\"\"\" \n from kotti . resources import Node \n if isinstance ( context , Node ) : \n return set ( \n r . group_name for r in context . local_groups \n if r . principal_name == name \n ) \n return set ( ) \n def list_groups ( name , context = None ) : \n \"\"\"<STR_LIT>\"\"\" \n return list_groups_ext ( name , context ) [ <NUM_LIT:0> ] \n def _cachekey_list_groups_ext ( name , context = None , _seen = None , _inherited = None ) : \n if _seen is not None or _inherited is not None : \n raise DontCache \n else : \n context_id = getattr ( context , '<STR_LIT:id>' , id ( context ) ) \n return unicode ( name ) , context_id \n @ request_cache ( _cachekey_list_groups_ext ) \n def list_groups_ext ( name , context = None , _seen = None , _inherited = None ) : \n name = unicode ( name ) \n groups = set ( ) \n recursing = _inherited is not None \n _inherited = _inherited or set ( ) \n principal = get_principals ( ) . get ( name ) \n if principal is not None : \n groups . update ( principal . groups ) \n if context is not None or ( context is None and _seen is not None ) : \n _inherited . update ( principal . groups ) \n if _seen is None : \n _seen = { name } \n if context is not None : \n items = lineage ( context ) \n for idx , item in enumerate ( items ) : \n group_names = [ i for i in list_groups_raw ( name , item ) \n if i not in _seen ] \n groups . update ( group_names ) \n if recursing or idx != <NUM_LIT:0> : \n _inherited . update ( group_names ) \n new_groups = groups - _seen \n _seen . update ( new_groups ) \n for group_name in new_groups : \n g , i = list_groups_ext ( \n group_name , context , _seen = _seen , _inherited = _inherited ) \n groups . update ( g ) \n _inherited . update ( i ) \n return list ( groups ) , list ( _inherited ) \n def set_groups ( name , context , groups_to_set = ( ) ) : \n \"\"\"<STR_LIT>\"\"\" \n from kotti . resources import LocalGroup \n name = unicode ( name ) \n context . local_groups = [ \n lg for lg in context . local_groups \n if lg . principal_name != name \n ] + [ \n LocalGroup ( context , name , unicode ( group_name ) ) \n for group_name in groups_to_set \n ] \n def list_groups_callback ( name , request ) : \n \"\"\"<STR_LIT>\"\"\" \n if not is_user ( name ) : \n return None \n if name in get_principals ( ) : \n context = request . environ . get ( \n '<STR_LIT>' , getattr ( request , '<STR_LIT>' , None ) ) \n if context is None : \n from kotti . resources import get_root \n context = get_root ( request ) \n return list_groups ( name , context ) \n @ contextmanager \n def authz_context ( context , request ) : \n before = request . environ . pop ( '<STR_LIT>' , None ) \n request . environ [ '<STR_LIT>' ] = context \n try : \n yield \n finally : \n del request . environ [ '<STR_LIT>' ] \n if before is not None : \n request . environ [ '<STR_LIT>' ] = before \n @ contextmanager \n def request_method ( request , method ) : \n before = request . method \n request . method = method \n try : \n yield \n finally : \n request . method = before \n def view_permitted ( context , request , name = '<STR_LIT>' , method = '<STR_LIT:GET>' ) : \n with authz_context ( context , request ) : \n with request_method ( request , method ) : \n return view_execution_permitted ( context , request , name ) \n def principals_with_local_roles ( context , inherit = True ) : \n \"\"\"<STR_LIT>\"\"\" \n principals = set ( ) \n items = [ context ] \n if inherit : \n items = lineage ( context ) \n for item in items : \n principals . update ( \n r . principal_name for r in item . local_groups \n if not r . principal_name . startswith ( '<STR_LIT>' ) \n ) \n return list ( principals ) \n def map_principals_with_local_roles ( context ) : \n principals = get_principals ( ) \n value = [ ] \n for principal_name in principals_with_local_roles ( context ) : \n try : \n principal = principals [ principal_name ] \n except KeyError : \n continue \n else : \n all , inherited = list_groups_ext ( principal_name , context ) \n value . append ( ( principal , ( all , inherited ) ) ) \n return sorted ( value , key = lambda t : t [ <NUM_LIT:0> ] . name ) \n def is_user ( principal ) : \n if not isinstance ( principal , string_types ) : \n principal = principal . name \n return '<STR_LIT::>' not in principal \n class Principals ( DictMixin ) : \n \"\"\"<STR_LIT>\"\"\" \n factory = Principal \n @ classmethod \n def _principal_by_name ( cls , name ) : \n query = bakery ( lambda session : session . query ( cls . factory ) . filter ( \n cls . factory . name == bindparam ( '<STR_LIT:name>' ) ) ) \n return query ( DBSession ( ) ) . params ( name = name ) . one ( ) \n @ request_cache ( lambda self , name : unicode ( name ) ) \n def __getitem__ ( self , name ) : \n name = unicode ( name ) \n if name . startswith ( '<STR_LIT>' ) : \n raise KeyError ( name ) \n try : \n return self . _principal_by_name ( name ) \n except NoResultFound : \n raise KeyError ( name ) \n def __setitem__ ( self , name , principal ) : \n name = unicode ( name ) \n if isinstance ( principal , dict ) : \n principal = self . factory ( ** principal ) \n DBSession . add ( principal ) \n def __delitem__ ( self , name ) : \n name = unicode ( name ) \n try : \n principal = self . _principal_by_name ( name ) \n DBSession . delete ( principal ) \n except NoResultFound : \n raise KeyError ( name ) \n def iterkeys ( self ) : \n for ( principal_name , ) in DBSession . query ( self . factory . name ) : \n yield principal_name \n def keys ( self ) : \n return list ( self . iterkeys ( ) ) \n def search ( self , match = '<STR_LIT>' , ** kwargs ) : \n \"\"\"<STR_LIT>\"\"\" \n if not kwargs : \n return [ ] \n filters = [ ] \n for key , value in kwargs . items ( ) : \n col = getattr ( self . factory , key ) \n if isinstance ( value , string_types ) and '<STR_LIT:*>' in value : \n value = value . replace ( '<STR_LIT:*>' , '<STR_LIT:%>' ) . lower ( ) \n filters . append ( func . lower ( col ) . like ( value ) ) \n else : \n filters . append ( col == value ) \n query = DBSession . query ( self . factory ) \n if match == '<STR_LIT>' : \n query = query . filter ( or_ ( * filters ) ) \n elif match == '<STR_LIT:all>' : \n query = query . filter ( and_ ( * filters ) ) \n else : \n raise ValueError ( '<STR_LIT>' ) \n return query \n log_rounds = <NUM_LIT:10> \n def hash_password ( self , password , hashed = None ) : \n if hashed is None : \n hashed = bcrypt . gensalt ( self . log_rounds ) \n return unicode ( \n bcrypt . hashpw ( password . encode ( '<STR_LIT:utf-8>' ) , hashed . encode ( '<STR_LIT:utf-8>' ) ) ) \n def validate_password ( self , clear , hashed ) : \n try : \n return self . hash_password ( clear , hashed ) == hashed \n except ValueError : \n return False \n def principals_factory ( ) : \n return Principals ( ) \n", "gt": "userid"}
{"input": "\n import json \n from mechanize . _mechanize import LinkNotFoundError \n from pytest import raises \n from kotti . testing import BASE_URL \n from kotti . testing import user \n from kotti . views . edit . upload import UploadView \n def test_upload_anonymous ( root , dummy_request , browser ) : \n <mask0> = UploadView ( root , dummy_request ) \n assert view . factories == [ ] \n link = browser . getLink \n browser . open ( u'<STR_LIT>' . format ( BASE_URL ) ) \n with raises ( LinkNotFoundError ) : \n link ( '<STR_LIT>' ) . click ( ) \n browser . open ( u'<STR_LIT>' . format ( BASE_URL ) ) \n assert browser . url . startswith ( u'<STR_LIT>' . format ( BASE_URL ) ) \n browser . open ( u'<STR_LIT>' . format ( BASE_URL ) ) \n assert browser . url . startswith ( u'<STR_LIT>' . format ( BASE_URL ) ) \n @ user ( '<STR_LIT>' ) \n def test_upload_authenticated_wo_mimetype ( root , dummy_request , browser ) : \n with raises ( KeyError ) : \n browser . open ( u'<STR_LIT>' . format ( BASE_URL ) ) \n @ user ( '<STR_LIT>' ) \n def test_upload_authenticated_text ( root , dummy_request , browser ) : \n browser . open ( u'<STR_LIT>' . format ( BASE_URL ) ) \n j = json . loads ( browser . contents ) \n assert '<STR_LIT>' in j \n types = j [ '<STR_LIT>' ] \n assert len ( types ) == <NUM_LIT:1> \n assert types [ <NUM_LIT:0> ] [ '<STR_LIT:name>' ] == u'<STR_LIT>' \n", "gt": "view"}
{"input": "\n import os \n import sys \n from setuptools import setup \n from setuptools import find_packages \n <mask0> = os . path . abspath ( os . path . dirname ( __file__ ) ) \n try : \n README = open ( os . path . join ( here , '<STR_LIT>' ) ) . read ( ) \n AUTHORS = open ( os . path . join ( here , '<STR_LIT>' ) ) . read ( ) \n CHANGES = open ( os . path . join ( here , '<STR_LIT>' ) ) . read ( ) \n except IOError : \n README = AUTHORS = CHANGES = '<STR_LIT>' \n install_requires = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] \n tests_require = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] \n development_requires = [ ] \n docs_require = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] \n if sys . version_info [ : <NUM_LIT:3> ] < ( <NUM_LIT:2> , <NUM_LIT:7> , <NUM_LIT:0> ) : \n install_requires . append ( '<STR_LIT>' ) \n setup ( name = '<STR_LIT>' , \n version = '<STR_LIT>' , \n description = \"<STR_LIT>\" , \n long_description = '<STR_LIT>' . join ( [ README , AUTHORS , CHANGES ] ) , \n classifiers = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] , \n author = '<STR_LIT>' , \n author_email = '<STR_LIT>' , \n url = '<STR_LIT>' , \n keywords = '<STR_LIT>' , \n license = \"<STR_LIT>\" , \n packages = find_packages ( ) , \n include_package_data = True , \n zip_safe = False , \n install_requires = install_requires , \n tests_require = tests_require , \n dependency_links = [ ] , \n entry_points = \"\"\"<STR_LIT>\"\"\" , \n extras_require = { \n '<STR_LIT>' : tests_require , \n '<STR_LIT>' : development_requires , \n '<STR_LIT>' : docs_require , \n } , \n ) \n", "gt": "here"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n from __future__ import division , unicode_literals \n from . markers import list_marker_layout \n from . min_max import handle_min_max_width \n from . percentages import resolve_percentages , resolve_position_percentages \n from . preferred import shrink_to_fit \n from . tables import table_wrapper_width \n from . . formatting_structure import boxes \n @ handle_min_max_width \n def float_width ( box , context , containing_block ) : \n if box . width == '<STR_LIT>' : \n box . width = shrink_to_fit ( context , box , containing_block . width ) \n def float_layout ( context , box , containing_block , device_size , absolute_boxes , \n fixed_boxes ) : \n \"\"\"<STR_LIT>\"\"\" \n from . blocks import block_container_layout \n from . inlines import inline_replaced_box_width_height \n resolve_percentages ( box , ( containing_block . width , containing_block . height ) ) \n resolve_position_percentages ( \n box , ( containing_block . width , containing_block . height ) ) \n if box . margin_left == '<STR_LIT>' : \n box . margin_left = <<mask0>:0> \n if box . margin_right == '<STR_LIT>' : \n box . margin_right = <NUM_LIT:0> \n if box . margin_top == '<STR_LIT>' : \n box . margin_top = <NUM_LIT:0> \n if box . margin_bottom == '<STR_LIT>' : \n box . margin_bottom = <NUM_LIT:0> \n clearance = get_clearance ( context , box ) \n if clearance is not None : \n box . position_y += clearance \n if isinstance ( box , boxes . BlockReplacedBox ) : \n inline_replaced_box_width_height ( box , device_size = None ) \n elif box . width == '<STR_LIT>' : \n float_width ( box , context , containing_block ) \n if box . is_table_wrapper : \n table_wrapper_width ( \n context , box , ( containing_block . width , containing_block . height ) ) \n if isinstance ( box , boxes . BlockBox ) : \n context . create_block_formatting_context ( ) \n box , _ , _ , _ , _ = block_container_layout ( \n context , box , max_position_y = float ( '<STR_LIT>' ) , \n skip_stack = None , device_size = device_size , page_is_empty = False , \n absolute_boxes = absolute_boxes , fixed_boxes = fixed_boxes , \n adjoining_margins = None ) \n list_marker_layout ( context , box ) \n context . finish_block_formatting_context ( box ) \n else : \n assert isinstance ( box , boxes . BlockReplacedBox ) \n box = find_float_position ( context , box , containing_block ) \n context . excluded_shapes . append ( box ) \n return box \n def find_float_position ( context , box , containing_block ) : \n \"\"\"<STR_LIT>\"\"\" \n if context . excluded_shapes : \n highest_y = context . excluded_shapes [ - <NUM_LIT:1> ] . position_y \n if box . position_y < highest_y : \n box . translate ( <NUM_LIT:0> , highest_y - box . position_y ) \n position_x , position_y , available_width = avoid_collisions ( \n context , box , containing_block ) \n if box . style . float == '<STR_LIT:right>' : \n position_x += available_width - box . margin_width ( ) \n box . translate ( position_x - box . position_x , position_y - box . position_y ) \n return box \n def get_clearance ( context , box , collapsed_margin = <NUM_LIT:0> ) : \n \"\"\"<STR_LIT>\"\"\" \n clearance = None \n hypothetical_position = box . position_y + collapsed_margin \n for excluded_shape in context . excluded_shapes : \n if box . style . clear in ( excluded_shape . style . float , '<STR_LIT>' ) : \n y , h = excluded_shape . position_y , excluded_shape . margin_height ( ) \n if hypothetical_position < y + h : \n clearance = max ( \n ( clearance or <NUM_LIT:0> ) , y + h - hypothetical_position ) \n return clearance \n def avoid_collisions ( context , box , containing_block , outer = True ) : \n excluded_shapes = context . excluded_shapes \n position_y = box . position_y if outer else box . border_box_y ( ) \n box_width = box . margin_width ( ) if outer else box . border_width ( ) \n box_height = box . margin_height ( ) if outer else box . border_height ( ) \n if box . border_height ( ) == <NUM_LIT:0> and box . is_floated ( ) : \n return <NUM_LIT:0> , <NUM_LIT:0> , containing_block . width \n while True : \n colliding_shapes = [ \n shape for shape in excluded_shapes \n if ( shape . position_y < position_y < \n shape . position_y + shape . margin_height ( ) ) or \n ( shape . position_y < position_y + box_height < \n shape . position_y + shape . margin_height ( ) ) or \n ( shape . position_y >= position_y and \n shape . position_y + shape . margin_height ( ) <= \n position_y + box_height ) \n ] \n left_bounds = [ \n shape . position_x + shape . margin_width ( ) \n for shape in colliding_shapes \n if shape . style . float == '<STR_LIT:left>' ] \n right_bounds = [ \n shape . position_x \n for shape in colliding_shapes \n if shape . style . float == '<STR_LIT:right>' ] \n max_left_bound = containing_block . content_box_x ( ) \n max_right_bound = containing_block . content_box_x ( ) + containing_block . width \n if not outer : \n max_left_bound += box . margin_left \n max_right_bound -= box . margin_right \n if left_bounds or right_bounds : \n if left_bounds : \n max_left_bound = max ( max ( left_bounds ) , max_left_bound ) \n if right_bounds : \n max_right_bound = min ( min ( right_bounds ) , max_right_bound ) \n if box_width > max_right_bound - max_left_bound : \n new_positon_y = min ( \n shape . position_y + shape . margin_height ( ) \n for shape in colliding_shapes ) \n if new_positon_y > position_y : \n position_y = new_positon_y \n continue \n break \n position_x = max_left_bound \n available_width = max_right_bound - max_left_bound \n if not outer : \n position_x -= box . margin_left \n position_y -= box . margin_top \n return position_x , position_y , available_width \n", "gt": "NUM_LIT"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n from setuptools import setup , find_packages \n <mask0> = '<STR_LIT>' \n options = dict ( \n name = \"<STR_LIT>\" , \n version = VERSION , \n description = \"<STR_LIT>\" , \n long_description = __doc__ , \n author = \"<STR_LIT>\" , \n author_email = \"<STR_LIT>\" , \n license = \"<STR_LIT>\" , \n platforms = \"<STR_LIT>\" , \n install_requires = [ '<STR_LIT>' ] , \n provides = [ '<STR_LIT>' ] , \n packages = find_packages ( ) , \n use_2to3 = True , \n classifiers = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" ] ) \n setup ( ** options ) \n", "gt": "VERSION"}
{"input": "\n from django . conf . urls import patterns , include , url \n import health_check \n health_check . autodiscover ( ) \n <mask0> = patterns ( '<STR_LIT>' , \n url ( r'<STR_LIT>' , '<STR_LIT>' , name = '<STR_LIT>' ) , \n ) \n", "gt": "urlpatterns"}
{"input": "\n import django \n from django . db import connection \n from django . db . models import Count \n from django . db . models . query_utils import Q \n from django . utils import translation \n from hvad . test_utils . data import NORMAL , STANDARD \n from hvad . test_utils . testcase import HvadTestCase , minimumDjangoVersion \n from hvad . test_utils . project . app . models import Normal , AggregateModel , Standard , SimpleRelated \n from hvad . test_utils . fixtures import NormalFixture , StandardFixture \n class FilterTests ( HvadTestCase , NormalFixture ) : \n <mask0> = <NUM_LIT:2> \n def test_simple_filter ( self ) : \n qs = Normal . objects . language ( '<STR_LIT>' ) . filter ( shared_field__contains = '<STR_LIT:2>' ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) \n obj = qs [ <NUM_LIT:0> ] \n self . assertEqual ( obj . shared_field , NORMAL [ <NUM_LIT:2> ] . shared_field ) \n self . assertEqual ( obj . translated_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) \n qs = Normal . objects . language ( '<STR_LIT>' ) . filter ( shared_field__contains = '<STR_LIT:1>' ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) \n obj = qs [ <NUM_LIT:0> ] \n self . assertEqual ( obj . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) \n self . assertEqual ( obj . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n def test_translated_filter ( self ) : \n qs = Normal . objects . language ( '<STR_LIT>' ) . filter ( translated_field__contains = '<STR_LIT>' ) \n self . assertEqual ( qs . count ( ) , self . normal_count ) \n obj1 , obj2 = qs \n self . assertEqual ( obj1 . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) \n self . assertEqual ( obj1 . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n self . assertEqual ( obj2 . shared_field , NORMAL [ <NUM_LIT:2> ] . shared_field ) \n self . assertEqual ( obj2 . translated_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) \n def test_fallbacks_filter ( self ) : \n ( Normal . objects . language ( '<STR_LIT>' ) \n . filter ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) \n . delete_translations ( ) ) \n with translation . override ( '<STR_LIT>' ) : \n qs = Normal . objects . language ( ) . fallbacks ( ) \n with self . assertNumQueries ( <NUM_LIT:2> ) : \n self . assertEqual ( qs . count ( ) , self . normal_count ) \n self . assertEqual ( len ( qs ) , self . normal_count ) \n with self . assertNumQueries ( <NUM_LIT:0> ) : \n self . assertCountEqual ( ( obj . pk for obj in qs ) , tuple ( self . normal_id . values ( ) ) ) \n self . assertCountEqual ( ( obj . language_code for obj in qs ) , self . translations ) \n def test_all_languages_filter ( self ) : \n with self . assertNumQueries ( <NUM_LIT:2> ) : \n qs = Normal . objects . language ( '<STR_LIT:all>' ) . filter ( shared_field__contains = '<STR_LIT>' ) \n self . assertEqual ( qs . count ( ) , self . normal_count * len ( self . translations ) ) \n self . assertCountEqual ( ( obj . shared_field for obj in qs ) , \n ( NORMAL [ <NUM_LIT:1> ] . shared_field , \n NORMAL [ <NUM_LIT:2> ] . shared_field ) * <NUM_LIT:2> ) \n self . assertCountEqual ( ( obj . translated_field for obj in qs ) , \n ( NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] , \n NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] , \n NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] , \n NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) ) \n with self . assertNumQueries ( <NUM_LIT:2> ) : \n qs = Normal . objects . language ( '<STR_LIT:all>' ) . filter ( translated_field__contains = '<STR_LIT>' ) \n self . assertEqual ( qs . count ( ) , self . normal_count ) \n self . assertCountEqual ( ( obj . shared_field for obj in qs ) , \n ( NORMAL [ <NUM_LIT:1> ] . shared_field , \n NORMAL [ <NUM_LIT:2> ] . shared_field ) ) \n self . assertCountEqual ( ( obj . translated_field for obj in qs ) , \n ( NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] , \n NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) ) \n with self . assertNumQueries ( <NUM_LIT:2> ) : \n qs = Normal . objects . language ( '<STR_LIT:all>' ) . filter ( translated_field__contains = '<STR_LIT:1>' ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) \n obj = qs [ <NUM_LIT:0> ] \n self . assertEqual ( obj . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) \n self . assertEqual ( obj . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n def test_deferred_language_filter ( self ) : \n with translation . override ( '<STR_LIT>' ) : \n qs = Normal . objects . language ( ) . filter ( translated_field__contains = '<STR_LIT>' ) \n with translation . override ( '<STR_LIT>' ) : \n self . assertEqual ( qs . count ( ) , self . normal_count ) \n obj1 , obj2 = qs \n self . assertEqual ( obj1 . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) \n self . assertEqual ( obj1 . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n self . assertEqual ( obj2 . shared_field , NORMAL [ <NUM_LIT:2> ] . shared_field ) \n self . assertEqual ( obj2 . translated_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) \n class ExtraTests ( HvadTestCase , NormalFixture ) : \n normal_count = <NUM_LIT:2> \n def test_simple_extra ( self ) : \n qs = Normal . objects . language ( '<STR_LIT>' ) . extra ( select = { '<STR_LIT>' : '<STR_LIT>' } ) \n self . assertEqual ( qs . count ( ) , self . normal_count ) \n self . assertEqual ( int ( qs [ <NUM_LIT:0> ] . test_extra ) , <NUM_LIT:4> ) \n class QueryCachingTests ( HvadTestCase , NormalFixture ) : \n normal_count = <NUM_LIT:2> \n def _try_all_cache_using_methods ( self , qs , length ) : \n with self . assertNumQueries ( <NUM_LIT:0> ) : \n x = <NUM_LIT:0> \n for obj in qs : x += <NUM_LIT:1> \n self . assertEqual ( x , length ) \n with self . assertNumQueries ( <NUM_LIT:0> ) : \n qs [ <NUM_LIT:0> ] \n with self . assertNumQueries ( <NUM_LIT:0> ) : \n self . assertEqual ( qs . exists ( ) , length != <NUM_LIT:0> ) \n with self . assertNumQueries ( <NUM_LIT:0> ) : \n self . assertEqual ( qs . count ( ) , length ) \n with self . assertNumQueries ( <NUM_LIT:0> ) : \n self . assertEqual ( len ( qs ) , length ) \n with self . assertNumQueries ( <NUM_LIT:0> ) : \n self . assertEqual ( bool ( qs ) , length != <NUM_LIT:0> ) \n def test_iter_caches ( self ) : \n with translation . override ( '<STR_LIT>' ) : \n index = <NUM_LIT:0> \n qs = Normal . objects . language ( ) . filter ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n for obj in qs : \n index += <NUM_LIT:1> \n self . assertEqual ( index , <NUM_LIT:1> ) \n self . _try_all_cache_using_methods ( qs , <NUM_LIT:1> ) \n def test_pickling_caches ( self ) : \n import pickle \n with translation . override ( '<STR_LIT>' ) : \n qs = Normal . objects . language ( ) . filter ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n pickle . dumps ( qs ) \n self . _try_all_cache_using_methods ( qs , <NUM_LIT:1> ) \n def test_len_caches ( self ) : \n with translation . override ( '<STR_LIT>' ) : \n qs = Normal . objects . language ( ) . filter ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n self . assertEqual ( len ( qs ) , <NUM_LIT:1> ) \n self . _try_all_cache_using_methods ( qs , <NUM_LIT:1> ) \n def test_bool_caches ( self ) : \n with translation . override ( '<STR_LIT>' ) : \n qs = Normal . objects . language ( ) . filter ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n self . assertTrue ( qs ) \n self . _try_all_cache_using_methods ( qs , <NUM_LIT:1> ) \n class IterTests ( HvadTestCase , NormalFixture ) : \n normal_count = <NUM_LIT:2> \n def test_simple_iter ( self ) : \n with translation . override ( '<STR_LIT>' ) : \n with self . assertNumQueries ( <NUM_LIT:1> ) : \n for index , obj in enumerate ( Normal . objects . language ( ) , <NUM_LIT:1> ) : \n self . assertEqual ( obj . shared_field , NORMAL [ index ] . shared_field ) \n self . assertEqual ( obj . translated_field , NORMAL [ index ] . translated_field [ '<STR_LIT>' ] ) \n with translation . override ( '<STR_LIT>' ) : \n with self . assertNumQueries ( <NUM_LIT:1> ) : \n for index , obj in enumerate ( Normal . objects . language ( ) , <NUM_LIT:1> ) : \n self . assertEqual ( obj . shared_field , NORMAL [ index ] . shared_field ) \n self . assertEqual ( obj . translated_field , NORMAL [ index ] . translated_field [ '<STR_LIT>' ] ) \n def test_iter_unique_reply ( self ) : \n with translation . override ( '<STR_LIT>' ) : \n self . assertEqual ( len ( Normal . objects . all ( ) ) , len ( Normal . objects . untranslated ( ) ) ) \n def test_iter_deferred_language ( self ) : \n with translation . override ( '<STR_LIT>' ) : \n qs = Normal . objects . language ( ) \n with translation . override ( '<STR_LIT>' ) : \n for index , obj in enumerate ( qs , <NUM_LIT:1> ) : \n self . assertEqual ( obj . shared_field , NORMAL [ index ] . shared_field ) \n self . assertEqual ( obj . translated_field , NORMAL [ index ] . translated_field [ '<STR_LIT>' ] ) \n class UpdateTests ( HvadTestCase , NormalFixture ) : \n normal_count = <NUM_LIT:2> \n def test_update_shared ( self ) : \n NEW_SHARED = '<STR_LIT>' \n n1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n n2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) \n ja1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n ja2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) \n with self . assertNumQueries ( <NUM_LIT:1> if connection . features . update_can_self_select else <NUM_LIT:2> ) : \n Normal . objects . language ( '<STR_LIT>' ) . update ( shared_field = NEW_SHARED ) \n new1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n new2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) \n self . assertEqual ( new1 . shared_field , NEW_SHARED ) \n self . assertEqual ( new1 . translated_field , n1 . translated_field ) \n self . assertEqual ( new2 . shared_field , NEW_SHARED ) \n self . assertEqual ( new2 . translated_field , n2 . translated_field ) \n newja1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n newja2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) \n self . assertEqual ( newja1 . shared_field , NEW_SHARED ) \n self . assertEqual ( newja2 . shared_field , NEW_SHARED ) \n self . assertEqual ( newja1 . translated_field , ja1 . translated_field ) \n self . assertEqual ( newja2 . translated_field , ja2 . translated_field ) \n def test_update_translated ( self ) : \n NEW_TRANSLATED = '<STR_LIT>' \n n1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n n2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) \n ja1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n ja2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) \n with self . assertNumQueries ( <NUM_LIT:1> ) : \n Normal . objects . language ( '<STR_LIT>' ) . update ( translated_field = NEW_TRANSLATED ) \n new1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n new2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) \n self . assertEqual ( new1 . shared_field , n1 . shared_field ) \n self . assertEqual ( new2 . shared_field , n2 . shared_field ) \n self . assertEqual ( new1 . translated_field , NEW_TRANSLATED ) \n self . assertEqual ( new2 . translated_field , NEW_TRANSLATED ) \n newja1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n newja2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) \n self . assertEqual ( newja1 . shared_field , ja1 . shared_field ) \n self . assertEqual ( newja2 . shared_field , ja2 . shared_field ) \n self . assertEqual ( newja1 . translated_field , ja1 . translated_field ) \n self . assertEqual ( newja2 . translated_field , ja2 . translated_field ) \n def test_update_mixed ( self ) : \n NEW_SHARED = '<STR_LIT>' \n NEW_TRANSLATED = '<STR_LIT>' \n ja1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n ja2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) \n with self . assertNumQueries ( <NUM_LIT:2> if connection . features . update_can_self_select else <NUM_LIT:3> ) : \n Normal . objects . language ( '<STR_LIT>' ) . update ( \n shared_field = NEW_SHARED , translated_field = NEW_TRANSLATED \n ) \n new1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n new2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) \n self . assertEqual ( new1 . shared_field , NEW_SHARED ) \n self . assertEqual ( new1 . translated_field , NEW_TRANSLATED ) \n self . assertEqual ( new2 . shared_field , NEW_SHARED ) \n self . assertEqual ( new2 . translated_field , NEW_TRANSLATED ) \n newja1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n newja2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) \n self . assertEqual ( newja1 . shared_field , NEW_SHARED ) \n self . assertEqual ( newja2 . shared_field , NEW_SHARED ) \n self . assertEqual ( newja1 . translated_field , ja1 . translated_field ) \n self . assertEqual ( newja2 . translated_field , ja2 . translated_field ) \n def test_update_deferred_language ( self ) : \n NEW_TRANSLATED = '<STR_LIT>' \n n1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n n2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) \n ja1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n ja2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) \n with translation . override ( '<STR_LIT>' ) : \n qs = Normal . objects . language ( ) \n with translation . override ( '<STR_LIT>' ) : \n with self . assertNumQueries ( <NUM_LIT:1> ) : \n qs . update ( translated_field = NEW_TRANSLATED ) \n new1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n new2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) \n self . assertEqual ( new1 . shared_field , n1 . shared_field ) \n self . assertEqual ( new2 . shared_field , n2 . shared_field ) \n self . assertEqual ( new1 . translated_field , NEW_TRANSLATED ) \n self . assertEqual ( new2 . translated_field , NEW_TRANSLATED ) \n newja1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) \n newja2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) \n self . assertEqual ( newja1 . shared_field , ja1 . shared_field ) \n self . assertEqual ( newja2 . shared_field , ja2 . shared_field ) \n self . assertEqual ( newja1 . translated_field , ja1 . translated_field ) \n self . assertEqual ( newja2 . translated_field , ja2 . translated_field ) \n def test_update_fallbacks ( self ) : \n qs = Normal . objects . language ( ) . fallbacks ( ) \n with self . assertNumQueries ( <NUM_LIT:1> if connection . features . update_can_self_select else <NUM_LIT:2> ) : \n qs . filter ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) . update ( shared_field = '<STR_LIT>' ) \n self . assertEqual ( Normal . objects . language ( '<STR_LIT>' ) . get ( shared_field = '<STR_LIT>' ) . pk , self . normal_id [ <NUM_LIT:1> ] ) \n self . assertEqual ( Normal . objects . language ( '<STR_LIT>' ) . get ( shared_field = '<STR_LIT>' ) . pk , self . normal_id [ <NUM_LIT:1> ] ) \n class ValuesListTests ( HvadTestCase , NormalFixture ) : \n normal_count = <NUM_LIT:2> \n def test_values_list_translated ( self ) : \n values = Normal . objects . language ( '<STR_LIT>' ) . values_list ( '<STR_LIT>' , flat = True ) \n values_list = list ( values ) \n self . assertCountEqual ( values_list , [ NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] , \n NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ] ) \n def test_values_list_shared ( self ) : \n values = Normal . objects . language ( '<STR_LIT>' ) . values_list ( '<STR_LIT>' , flat = True ) \n values_list = list ( values ) \n self . assertCountEqual ( values_list , [ NORMAL [ <NUM_LIT:1> ] . shared_field , \n NORMAL [ <NUM_LIT:2> ] . shared_field ] ) \n def test_values_list_mixed ( self ) : \n values = Normal . objects . language ( '<STR_LIT>' ) . values_list ( '<STR_LIT>' , '<STR_LIT>' ) \n values_list = list ( values ) \n check = [ \n ( NORMAL [ <NUM_LIT:1> ] . shared_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) , \n ( NORMAL [ <NUM_LIT:2> ] . shared_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) , \n ] \n self . assertCountEqual ( values_list , check ) \n def test_values_list_deferred_language ( self ) : \n with translation . override ( '<STR_LIT>' ) : \n qs = Normal . objects . language ( ) \n with translation . override ( '<STR_LIT>' ) : \n values = qs . values_list ( '<STR_LIT>' , '<STR_LIT>' ) \n values_list = list ( values ) \n check = [ \n ( NORMAL [ <NUM_LIT:1> ] . shared_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) , \n ( NORMAL [ <NUM_LIT:2> ] . shared_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) , \n ] \n self . assertCountEqual ( values_list , check ) \n def test_values_list_language_all ( self ) : \n values = ( Normal . objects . language ( '<STR_LIT:all>' ) . filter ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) \n . values_list ( '<STR_LIT>' , '<STR_LIT>' ) ) \n values_list = list ( values ) \n check = [ \n ( NORMAL [ <NUM_LIT:1> ] . shared_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) , \n ( NORMAL [ <NUM_LIT:1> ] . shared_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) , \n ] \n self . assertCountEqual ( values_list , check ) \n class ValuesTests ( HvadTestCase , NormalFixture ) : \n normal_count = <NUM_LIT:2> \n def test_values_shared ( self ) : \n values = Normal . objects . language ( '<STR_LIT>' ) . values ( '<STR_LIT>' ) \n values_list = list ( values ) \n check = [ \n { '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . shared_field } , \n { '<STR_LIT>' : NORMAL [ <NUM_LIT:2> ] . shared_field } , \n ] \n self . assertCountEqual ( values_list , check ) \n def test_values_translated ( self ) : \n values = Normal . objects . language ( '<STR_LIT>' ) . values ( '<STR_LIT>' ) \n values_list = list ( values ) \n check = [ \n { '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] } , \n { '<STR_LIT>' : NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] } , \n ] \n self . assertCountEqual ( values_list , check ) \n def test_values_mixed ( self ) : \n values = Normal . objects . language ( '<STR_LIT>' ) . values ( '<STR_LIT>' , '<STR_LIT>' ) \n values_list = list ( values ) \n check = [ \n { '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] , \n '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . shared_field } , \n { '<STR_LIT>' : NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] , \n '<STR_LIT>' : NORMAL [ <NUM_LIT:2> ] . shared_field } , \n ] \n self . assertCountEqual ( values_list , check ) \n def test_values_post_language ( self ) : \n values = Normal . objects . language ( ) . values ( '<STR_LIT>' ) . language ( '<STR_LIT>' ) \n values_list = list ( values ) \n check = [ \n { '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . shared_field } , \n { '<STR_LIT>' : NORMAL [ <NUM_LIT:2> ] . shared_field } , \n ] \n self . assertCountEqual ( values_list , check ) \n def test_values_post_filter ( self ) : \n qs = Normal . objects . language ( '<STR_LIT>' ) . values ( '<STR_LIT>' ) \n values = qs . filter ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) \n values_list = list ( values ) \n check = [ \n { '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . shared_field } , \n ] \n self . assertCountEqual ( values_list , check ) \n def test_values_deferred_language ( self ) : \n with translation . override ( '<STR_LIT>' ) : \n qs = Normal . objects . language ( ) \n with translation . override ( '<STR_LIT>' ) : \n values = qs . values ( '<STR_LIT>' ) \n values_list = list ( values ) \n check = [ \n { '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] } , \n { '<STR_LIT>' : NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] } , \n ] \n self . assertCountEqual ( values_list , check ) \n def test_values_language_all ( self ) : \n values = ( Normal . objects . language ( '<STR_LIT:all>' ) . filter ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) \n . values ( '<STR_LIT>' , '<STR_LIT>' ) ) \n values_list = list ( values ) \n check = [ \n { '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . shared_field , \n '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] } , \n { '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . shared_field , \n '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] } , \n ] \n self . assertCountEqual ( values_list , check ) \n class InBulkTests ( HvadTestCase , NormalFixture ) : \n normal_count = <NUM_LIT:2> \n def test_empty_in_bulk ( self ) : \n with self . assertNumQueries ( <NUM_LIT:0> ) : \n result = Normal . objects . language ( '<STR_LIT>' ) . in_bulk ( [ ] ) \n self . assertEqual ( len ( result ) , <NUM_LIT:0> ) \n def test_in_bulk ( self ) : \n pk1 , pk2 = self . normal_id [ <NUM_LIT:1> ] , self . normal_id [ <NUM_LIT:2> ] \n with self . assertNumQueries ( <NUM_LIT:1> ) : \n result = Normal . objects . language ( '<STR_LIT>' ) . in_bulk ( [ pk1 , pk2 ] ) \n self . assertCountEqual ( ( pk1 , pk2 ) , result ) \n self . assertEqual ( result [ pk1 ] . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) \n self . assertEqual ( result [ pk1 ] . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n self . assertEqual ( result [ pk1 ] . language_code , '<STR_LIT>' ) \n self . assertEqual ( result [ pk2 ] . shared_field , NORMAL [ <NUM_LIT:2> ] . shared_field ) \n self . assertEqual ( result [ pk2 ] . translated_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) \n self . assertEqual ( result [ pk2 ] . language_code , '<STR_LIT>' ) \n def test_untranslated_in_bulk ( self ) : \n pk1 = self . normal_id [ <NUM_LIT:1> ] \n with translation . override ( '<STR_LIT>' ) : \n with self . assertNumQueries ( <NUM_LIT:2> ) : \n result = Normal . objects . untranslated ( ) . in_bulk ( [ pk1 ] ) \n self . assertCountEqual ( ( pk1 , ) , result ) \n self . assertEqual ( result [ pk1 ] . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) \n self . assertEqual ( result [ pk1 ] . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n self . assertEqual ( result [ pk1 ] . language_code , '<STR_LIT>' ) \n def test_fallbacks_in_bulk ( self ) : \n ( Normal . objects . language ( '<STR_LIT>' ) \n . filter ( shared_field = NORMAL [ <NUM_LIT:2> ] . shared_field ) \n . delete_translations ( ) ) \n with self . assertNumQueries ( <NUM_LIT:1> ) : \n pk1 , pk2 = self . normal_id [ <NUM_LIT:1> ] , self . normal_id [ <NUM_LIT:2> ] \n result = Normal . objects . language ( '<STR_LIT>' ) . fallbacks ( '<STR_LIT>' , '<STR_LIT>' ) . in_bulk ( [ pk1 , pk2 ] ) \n self . assertCountEqual ( ( pk1 , pk2 ) , result ) \n self . assertEqual ( result [ pk1 ] . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) \n self . assertEqual ( result [ pk1 ] . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n self . assertEqual ( result [ pk1 ] . language_code , '<STR_LIT>' ) \n self . assertEqual ( result [ pk2 ] . shared_field , NORMAL [ <NUM_LIT:2> ] . shared_field ) \n self . assertEqual ( result [ pk2 ] . translated_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) \n self . assertEqual ( result [ pk2 ] . language_code , '<STR_LIT>' ) \n def test_all_languages_in_bulk ( self ) : \n with self . assertRaises ( ValueError ) : \n Normal . objects . language ( '<STR_LIT:all>' ) . in_bulk ( [ self . normal_id [ <NUM_LIT:1> ] ] ) \n def test_in_bulk_deferred_language ( self ) : \n pk1 = self . normal_id [ <NUM_LIT:1> ] \n with translation . override ( '<STR_LIT>' ) : \n qs = Normal . objects . language ( ) \n with translation . override ( '<STR_LIT>' ) : \n result = qs . in_bulk ( [ pk1 ] ) \n self . assertCountEqual ( ( pk1 , ) , result ) \n self . assertEqual ( result [ pk1 ] . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) \n self . assertEqual ( result [ pk1 ] . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n self . assertEqual ( result [ pk1 ] . language_code , '<STR_LIT>' ) \n class DeleteTests ( HvadTestCase , NormalFixture ) : \n normal_count = <NUM_LIT:2> \n def test_delete_all ( self ) : \n Normal . objects . all ( ) . delete ( ) \n self . assertEqual ( Normal . objects . count ( ) , <NUM_LIT:0> ) \n self . assertEqual ( Normal . _meta . translations_model . objects . count ( ) , <NUM_LIT:0> ) \n def test_delete_translation ( self ) : \n self . assertEqual ( Normal . _meta . translations_model . objects . count ( ) , <NUM_LIT:4> ) \n Normal . objects . language ( '<STR_LIT>' ) . delete_translations ( ) \n self . assertEqual ( Normal . objects . untranslated ( ) . count ( ) , <NUM_LIT:2> ) \n self . assertEqual ( Normal . _meta . translations_model . objects . count ( ) , <NUM_LIT:2> ) \n Normal . objects . language ( '<STR_LIT>' ) . delete_translations ( ) \n self . assertEqual ( Normal . objects . untranslated ( ) . count ( ) , <NUM_LIT:2> ) \n self . assertEqual ( Normal . _meta . translations_model . objects . count ( ) , <NUM_LIT:0> ) \n def test_filtered_delete_translation ( self ) : \n self . assertEqual ( Normal . _meta . translations_model . objects . count ( ) , <NUM_LIT:4> ) \n ( Normal . objects . language ( '<STR_LIT>' ) \n . filter ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) \n . delete_translations ( ) ) \n self . assertEqual ( Normal . objects . untranslated ( ) . count ( ) , <NUM_LIT:2> ) \n self . assertEqual ( Normal . _meta . translations_model . objects . count ( ) , <NUM_LIT:3> ) \n ( Normal . objects . language ( '<STR_LIT>' ) \n . filter ( translated_field = NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) \n . delete_translations ( ) ) \n self . assertEqual ( Normal . objects . untranslated ( ) . count ( ) , <NUM_LIT:2> ) \n self . assertEqual ( Normal . _meta . translations_model . objects . count ( ) , <NUM_LIT:2> ) \n def test_delete_translation_deferred_language ( self ) : \n self . assertEqual ( Normal . _meta . translations_model . objects . count ( ) , <NUM_LIT:4> ) \n with translation . override ( '<STR_LIT>' ) : \n qs = Normal . objects . language ( ) \n with translation . override ( '<STR_LIT>' ) : \n qs . delete_translations ( ) \n self . assertEqual ( Normal . objects . language ( '<STR_LIT>' ) . count ( ) , <NUM_LIT:2> ) \n self . assertEqual ( Normal . objects . language ( '<STR_LIT>' ) . count ( ) , <NUM_LIT:0> ) \n def test_delete_fallbacks ( self ) : \n qs = Normal . objects . language ( ) . fallbacks ( ) \n qs . filter ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) . delete ( ) \n self . assertEqual ( Normal . objects . language ( '<STR_LIT>' ) . count ( ) , self . normal_count - <NUM_LIT:1> ) \n self . assertEqual ( Normal . objects . language ( '<STR_LIT>' ) . count ( ) , self . normal_count - <NUM_LIT:1> ) \n class GetTranslationFromInstanceTests ( HvadTestCase , NormalFixture ) : \n normal_count = <NUM_LIT:1> \n def test_simple ( self ) : \n en = Normal . objects . language ( '<STR_LIT>' ) . get ( ) \n ja_trans = en . translations . get_language ( '<STR_LIT>' ) \n ja = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = en . pk ) \n self . assertEqual ( en . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) \n self . assertEqual ( en . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n self . assertRaises ( AttributeError , getattr , ja_trans , '<STR_LIT>' ) \n self . assertEqual ( ja_trans . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n self . assertEqual ( ja . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) \n self . assertEqual ( ja . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n def test_cached ( self ) : \n en = Normal . objects . untranslated ( ) . prefetch_related ( '<STR_LIT>' ) . get ( ) \n with self . assertNumQueries ( <NUM_LIT:0> ) : \n ja_trans = en . translations . get_language ( '<STR_LIT>' ) \n ja = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = en . pk ) \n self . assertEqual ( en . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) \n self . assertEqual ( en . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n self . assertRaises ( AttributeError , getattr , ja_trans , '<STR_LIT>' ) \n self . assertEqual ( ja_trans . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n self . assertEqual ( ja . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) \n self . assertEqual ( ja . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n def test_not_exist ( self ) : \n en = Normal . objects . untranslated ( ) . get ( ) \n with self . assertRaises ( Normal . DoesNotExist ) : \n en . translations . get_language ( '<STR_LIT>' ) \n en = Normal . objects . untranslated ( ) . prefetch_related ( '<STR_LIT>' ) . get ( ) \n with self . assertRaises ( Normal . DoesNotExist ) : \n en . translations . get_language ( '<STR_LIT>' ) \n class AggregateTests ( HvadTestCase ) : \n def test_aggregate ( self ) : \n from django . db . models import Avg \n AggregateModel . objects . language ( \"<STR_LIT>\" ) . create ( number = <NUM_LIT:10> , translated_number = <NUM_LIT:20> ) \n AggregateModel . objects . language ( \"<STR_LIT>\" ) . create ( number = <NUM_LIT:0> , translated_number = <NUM_LIT:0> ) \n self . assertEqual ( AggregateModel . objects . language ( \"<STR_LIT>\" ) . aggregate ( Avg ( \"<STR_LIT>\" ) ) , { '<STR_LIT>' : <NUM_LIT:5> } ) \n self . assertEqual ( AggregateModel . objects . language ( \"<STR_LIT>\" ) . aggregate ( Avg ( \"<STR_LIT>\" ) ) , { '<STR_LIT>' : <NUM_LIT:10> } ) \n self . assertEqual ( AggregateModel . objects . language ( \"<STR_LIT>\" ) . aggregate ( num = Avg ( \"<STR_LIT>\" ) ) , { '<STR_LIT>' : <NUM_LIT:5> } ) \n self . assertEqual ( AggregateModel . objects . language ( \"<STR_LIT>\" ) . aggregate ( tnum = Avg ( \"<STR_LIT>\" ) ) , { '<STR_LIT>' : <NUM_LIT:10> } ) \n class AnnotateTests ( HvadTestCase , StandardFixture , NormalFixture ) : \n normal_count = <NUM_LIT:2> \n standard_count = <NUM_LIT:4> \n def test_annotate ( self ) : \n qs = Normal . objects . language ( '<STR_LIT>' ) . annotate ( Count ( '<STR_LIT>' ) ) \n self . assertEqual ( len ( qs ) , self . normal_count ) \n self . assertEqual ( qs [ <NUM_LIT:0> ] . standards__count , <NUM_LIT:2> ) \n self . assertEqual ( qs [ <NUM_LIT:1> ] . standards__count , <NUM_LIT:2> ) \n qs = Normal . objects . language ( '<STR_LIT>' ) . annotate ( foo = Count ( '<STR_LIT>' ) ) \n self . assertEqual ( len ( qs ) , self . normal_count ) \n self . assertEqual ( qs [ <NUM_LIT:0> ] . foo , <NUM_LIT:2> ) \n self . assertEqual ( qs [ <NUM_LIT:1> ] . foo , <NUM_LIT:2> ) \n with self . assertRaises ( ValueError ) : \n qs = Normal . objects . language ( '<STR_LIT>' ) . annotate ( Count ( '<STR_LIT>' ) , standards__count = Count ( '<STR_LIT>' ) ) \n class NotImplementedTests ( HvadTestCase ) : \n def test_notimplemented ( self ) : \n baseqs = SimpleRelated . objects . language ( '<STR_LIT>' ) \n self . assertRaises ( NotImplementedError , baseqs . defer , '<STR_LIT>' ) \n self . assertRaises ( NotImplementedError , baseqs . only ) \n self . assertRaises ( NotImplementedError , baseqs . bulk_create , [ ] ) \n self . assertRaises ( NotImplementedError , baseqs . select_related ) \n if django . VERSION >= ( <NUM_LIT:1> , <NUM_LIT:7> ) : \n self . assertRaises ( NotImplementedError , baseqs . update_or_create ) \n class MinimumVersionTests ( HvadTestCase ) : \n def test_versions ( self ) : \n qs = SimpleRelated . objects . language ( '<STR_LIT>' ) \n if django . VERSION < ( <NUM_LIT:1> , <NUM_LIT:7> ) : \n self . assertRaises ( AttributeError , getattr , qs , '<STR_LIT>' ) \n class ExcludeTests ( HvadTestCase , NormalFixture ) : \n normal_count = <NUM_LIT:1> \n def test_defer ( self ) : \n qs = Normal . objects . language ( '<STR_LIT>' ) . exclude ( translated_field = NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:0> ) \n def test_fallbacks_exclude ( self ) : \n ( Normal . objects . language ( '<STR_LIT>' ) \n . filter ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) \n . delete_translations ( ) ) \n qs = ( Normal . objects . language ( '<STR_LIT>' ) \n . fallbacks ( '<STR_LIT>' , '<STR_LIT>' ) \n . exclude ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:0> ) \n def test_all_languages_exclude ( self ) : \n qs = Normal . objects . language ( '<STR_LIT:all>' ) . exclude ( translated_field = NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) \n self . assertEqual ( qs [ <NUM_LIT:0> ] . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n def test_invalid_all_languages_exclude ( self ) : \n with self . assertRaises ( ValueError ) : \n Normal . objects . language ( ) . exclude ( language_code = '<STR_LIT:all>' ) \n class ComplexFilterTests ( HvadTestCase , StandardFixture , NormalFixture ) : \n normal_count = <NUM_LIT:2> \n standard_count = <NUM_LIT:2> \n def test_qobject_filter ( self ) : \n shared_contains_one = Q ( shared_field__contains = '<STR_LIT:1>' ) \n shared_contains_two = Q ( shared_field__contains = '<STR_LIT:2>' ) \n qs = Normal . objects . language ( '<STR_LIT>' ) . filter ( shared_contains_two ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) \n obj = qs [ <NUM_LIT:0> ] \n self . assertEqual ( obj . shared_field , NORMAL [ <NUM_LIT:2> ] . shared_field ) \n self . assertEqual ( obj . translated_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) \n qs = ( Normal . objects . language ( '<STR_LIT>' ) . filter ( Q ( shared_contains_one | shared_contains_two ) ) \n . order_by ( '<STR_LIT>' ) ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:2> ) \n obj = qs [ <NUM_LIT:0> ] \n self . assertEqual ( obj . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) \n self . assertEqual ( obj . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) \n obj = qs [ <NUM_LIT:1> ] \n self . assertEqual ( obj . shared_field , NORMAL [ <NUM_LIT:2> ] . shared_field ) \n self . assertEqual ( obj . translated_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) \n def test_aware_qobject_filter ( self ) : \n from hvad . utils import get_translation_aware_manager \n manager = get_translation_aware_manager ( Standard ) \n normal_one = Q ( normal_field = STANDARD [ <NUM_LIT:1> ] . normal_field ) \n normal_two = Q ( normal_field = STANDARD [ <NUM_LIT:2> ] . normal_field ) \n shared_one = Q ( normal__shared_field = NORMAL [ STANDARD [ <NUM_LIT:1> ] . normal ] . shared_field ) \n translated_one_en = Q ( normal__translated_field = NORMAL [ STANDARD [ <NUM_LIT:1> ] . normal ] . translated_field [ '<STR_LIT>' ] ) \n translated_two_en = Q ( normal__translated_field = NORMAL [ STANDARD [ <NUM_LIT:2> ] . normal ] . translated_field [ '<STR_LIT>' ] ) \n with translation . override ( '<STR_LIT>' ) : \n qs = manager . filter ( shared_one ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) \n obj = qs [ <NUM_LIT:0> ] \n self . assertEqual ( obj . normal_field , STANDARD [ <NUM_LIT:1> ] . normal_field ) \n qs = manager . filter ( translated_one_en ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) \n obj = qs [ <NUM_LIT:0> ] \n self . assertEqual ( obj . normal_field , STANDARD [ <NUM_LIT:1> ] . normal_field ) \n qs = manager . filter ( Q ( normal_one & shared_one & translated_one_en ) ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) \n obj = qs [ <NUM_LIT:0> ] \n self . assertEqual ( obj . normal_field , STANDARD [ <NUM_LIT:1> ] . normal_field ) \n qs = manager . filter ( Q ( normal_one & translated_two_en ) ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:0> ) \n qs = manager . filter ( Q ( shared_one & translated_two_en ) ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:0> ) \n qs = manager . filter ( Q ( translated_one_en & translated_two_en ) ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:0> ) \n qs = manager . filter ( Q ( normal_one | translated_one_en ) ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) \n qs = manager . filter ( Q ( shared_one | translated_one_en ) ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) \n qs = manager . filter ( Q ( normal_one | translated_two_en ) ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:2> ) \n qs = manager . filter ( Q ( shared_one | translated_two_en ) ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:2> ) \n qs = manager . filter ( Q ( translated_one_en | translated_two_en ) ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:2> ) \n qs = manager . filter ( Q ( normal_one & ( translated_one_en | translated_two_en ) ) ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) \n qs = manager . filter ( Q ( normal_two & ( translated_one_en | translated_two_en ) ) ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) \n qs = manager . filter ( shared_one & ~ translated_one_en ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:0> ) \n qs = manager . filter ( shared_one & ~ translated_two_en ) \n self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) \n def test_defer ( self ) : \n qs = Normal . objects . language ( '<STR_LIT>' ) . complex_filter ( { } ) \n self . assertEqual ( qs . count ( ) , self . normal_count ) \n self . assertRaises ( NotImplementedError , \n Normal . objects . language ( '<STR_LIT>' ) . complex_filter , \n Q ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) ) \n", "gt": "normal_count"}
{"input": "\n import json \n import threading \n import sublime \n import sublime_plugin \n import analytics \n import uuid \n from elasticsearch import Elasticsearch \n from elasticsearch_connections import CustomHeadersConnection \n from abc import ABCMeta , abstractmethod \n from . . panel import IndexListPanel \n from . . panel import DocTypeListPanel \n from . . panel import SwitchServerListPanel \n from . . panel import AnalyzerListPanel \n from . . panel import ScriptListPanel \n from . . panel import SearchTemplateListPanel \n from . . panel import AliasListPanel \n from . . panel import IndexTemplateListPanel \n from . . panel import WarmerListPanel \n from . . panel import FieldListPanel \n from . . panel import RepositoryListPanel \n from . . panel import SnapshotListPanel \n <mask0> = \"<STR_LIT>\" \n def track_command ( user_id , command_name ) : \n analytics . write_key = ANALYTICS_WRITE_KEY \n analytics . identify ( user_id ) \n analytics . track ( user_id , \"<STR_LIT>\" , { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT:label>\" : command_name , \n } ) \n def track_activate ( user_id ) : \n analytics . write_key = ANALYTICS_WRITE_KEY \n analytics . identify ( user_id ) \n analytics . track ( user_id , \"<STR_LIT>\" , { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT:label>\" : sublime . platform ( ) , \n } ) \n class Settings ( object ) : \n SETTINGS_FILE = '<STR_LIT>' \n def __init__ ( self ) : \n self . settings = sublime . load_settings ( self . SETTINGS_FILE ) \n @ property \n def base_url ( self ) : \n base_url = self . settings . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n if base_url . endswith ( \"<STR_LIT:/>\" ) : \n return base_url [ : - <NUM_LIT:1> ] \n return base_url \n @ property \n def index ( self ) : \n return self . settings . get ( \"<STR_LIT:index>\" , \"<STR_LIT>\" ) \n @ property \n def doc_type ( self ) : \n return self . settings . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n @ property \n def scroll_size ( self ) : \n return self . settings . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n @ property \n def headers ( self ) : \n return self . settings . get ( \"<STR_LIT>\" , { } ) \n @ property \n def servers ( self ) : \n def _normalize_servers ( servers ) : \n items = [ ] \n for name , server in servers . items ( ) : \n server [ \"<STR_LIT:name>\" ] = name \n items . append ( server ) \n servers = sorted ( items , key = lambda k : k [ \"<STR_LIT:name>\" ] ) \n return servers \n servers = self . settings . get ( \"<STR_LIT>\" , [ ] ) \n if isinstance ( servers , dict ) : \n servers = _normalize_servers ( servers ) \n return servers \n @ property \n def active_server ( self ) : \n return dict ( \n base_url = self . base_url , \n index = self . index , \n doc_type = self . doc_type , \n scroll_size = self . scroll_size , \n ) \n @ property \n def ab_command ( self ) : \n return self . settings . get ( \"<STR_LIT>\" ) \n @ property \n def ab_requests ( self ) : \n return str ( self . settings . get ( \"<STR_LIT>\" ) ) \n @ property \n def ab_concurrency ( self ) : \n return str ( self . settings . get ( \"<STR_LIT>\" ) ) \n @ property \n def analytics ( self ) : \n return self . settings . get ( \"<STR_LIT>\" , True ) \n @ property \n def user_id ( self ) : \n return self . settings . get ( \"<STR_LIT>\" , None ) \n @ property \n def dump_file ( self ) : \n return self . settings . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n @ property \n def chunk_size ( self ) : \n return self . settings . get ( \"<STR_LIT>\" , <NUM_LIT> ) \n def set ( self , key , value ) : \n self . settings . set ( key , value ) \n def save ( self ) : \n sublime . save_settings ( self . SETTINGS_FILE ) \n class BaseCommand ( sublime_plugin . WindowCommand ) : \n __metaclass__ = ABCMeta \n command_name = None \n def __init__ ( self , * args , ** kwargs ) : \n self . settings = Settings ( ) \n sublime_plugin . WindowCommand . __init__ ( self , * args , ** kwargs ) \n @ property \n def view ( self ) : \n return self . window . active_view ( ) \n def is_valid_json ( self ) : \n try : \n json . loads ( self . get_text ( ) ) \n except ValueError : \n return False \n return True \n def is_enabled ( self ) : \n return self . is_valid_json ( ) \n def get_text ( self ) : \n return self . view . substr ( sublime . Region ( <NUM_LIT:0> , self . view . size ( ) ) ) \n def init_client ( self ) : \n self . _client = Elasticsearch ( \n self . settings . base_url , \n send_get_body_as = '<STR_LIT:POST>' , \n connection_class = CustomHeadersConnection , \n headers = self . settings . headers \n ) \n return self . _client \n def save_settings ( self ) : \n self . settings . save ( ) \n self . init_client ( ) \n @ property \n def client ( self ) : \n return self . init_client ( ) \n def track_command ( self ) : \n if self . settings . analytics : \n user_id = self . settings . user_id \n if not user_id : \n user_id = str ( uuid . uuid4 ( ) ) \n self . settings . set ( \"<STR_LIT>\" , user_id ) \n self . settings . save ( ) \n track_activate ( user_id ) \n track_command ( user_id , self . command_name ) \n def show_input_panel ( self , label , default , callback ) : \n self . window . show_input_panel ( label , default , callback , None , None ) \n def show_response ( self , response , title = \"<STR_LIT>\" ) : \n title = title or self . command_name \n text = json . dumps ( response , indent = <NUM_LIT:2> , ensure_ascii = False ) \n self . window . run_command ( \n \"<STR_LIT>\" , { \"<STR_LIT:title>\" : title , \"<STR_LIT:text>\" : text } ) \n def show_index_list_panel ( self , callback ) : \n list_panel = IndexListPanel ( \n self . window , self . client , self . settings . index ) \n list_panel . show ( callback ) \n def show_doc_type_list_panel ( self , callback ) : \n list_panel = DocTypeListPanel ( \n self . window , self . client , self . settings . index ) \n list_panel . show ( callback ) \n def show_analyzer_list_panel ( self , callback ) : \n list_panel = AnalyzerListPanel ( \n self . window , self . client , self . settings . index ) \n list_panel . show ( callback ) \n def show_switch_server_list_panel ( self , callback ) : \n list_panel = SwitchServerListPanel ( self . window , self . settings . servers ) \n list_panel . show ( callback ) \n def show_script_list_panel ( self , callback ) : \n list_panel = ScriptListPanel ( self . window , self . client ) \n list_panel . show ( callback ) \n def show_search_template_list_panel ( self , callback ) : \n list_panel = SearchTemplateListPanel ( self . window , self . client ) \n list_panel . show ( callback ) \n def show_alias_list_panel ( self , callback ) : \n list_panel = AliasListPanel ( \n self . window , self . client , self . settings . index ) \n list_panel . show ( callback ) \n def show_index_template_list_panel ( self , callback ) : \n list_panel = IndexTemplateListPanel ( self . window , self . client ) \n list_panel . show ( callback ) \n def show_warmer_list_panel ( self , callback ) : \n list_panel = WarmerListPanel ( \n self . window , self . client , self . settings . index ) \n list_panel . show ( callback ) \n def show_field_list_panel ( self , callback ) : \n list_panel = FieldListPanel ( \n self . window , self . client , \n self . settings . index , self . settings . doc_type ) \n list_panel . show ( callback ) \n def show_repository_list_panel ( self , callback ) : \n list_panel = RepositoryListPanel ( self . window , self . client ) \n list_panel . show ( callback ) \n def show_snapshot_list_panel ( self , repository , callback ) : \n list_panel = SnapshotListPanel ( self . window , self . client , repository ) \n list_panel . show ( callback ) \n def show_output_panel ( self , text , syntax = None ) : \n self . window . run_command ( \n \"<STR_LIT>\" , { \"<STR_LIT:text>\" : text , \"<STR_LIT>\" : syntax } ) \n def show_object_output_panel ( self , obj ) : \n options = dict ( \n indent = <NUM_LIT:4> , \n ensure_ascii = False \n ) \n self . show_output_panel ( \n json . dumps ( obj , ** options ) , \n syntax = \"<STR_LIT>\" ) \n def show_active_server ( self ) : \n self . window . run_command ( \"<STR_LIT>\" ) \n @ abstractmethod \n def run_request ( self , * args , ** kwargs ) : \n raise NotImplementedError ( ) \n def run_request_wrapper ( self , * args , ** kwargs ) : \n try : \n response = self . run_request ( * args , ** kwargs ) \n except Exception as e : \n sublime . error_message ( \"<STR_LIT>\" . format ( e ) ) \n return \n if response is not None : \n self . show_response ( response ) \n self . track_command ( ) \n def request_thread ( self , * args , ** kwargs ) : \n thread = threading . Thread ( \n target = self . run_request_wrapper , args = args , kwargs = kwargs ) \n thread . start ( ) \n def run ( self , * args , ** kwargs ) : \n self . request_thread ( * args , ** kwargs ) \n class CreateBaseCommand ( BaseCommand ) : \n def run_request_wrapper ( self , * args , ** kwargs ) : \n try : \n response = self . run_request ( * args , ** kwargs ) \n except Exception as e : \n sublime . error_message ( \"<STR_LIT>\" . format ( e ) ) \n return \n if response is not None : \n self . show_object_output_panel ( response ) \n self . track_command ( ) \n class DeleteBaseCommand ( CreateBaseCommand ) : \n pass \n class CatBaseCommand ( CreateBaseCommand ) : \n def is_enabled ( self ) : \n return True \n def run_request_wrapper ( self , * args , ** kwargs ) : \n try : \n response = self . run_request ( * args , ** kwargs ) \n except Exception as e : \n sublime . error_message ( \"<STR_LIT>\" . format ( e ) ) \n return \n if response is not None : \n self . show_output_panel ( response ) \n self . track_command ( ) \n class SearchBaseCommand ( BaseCommand ) : \n def extend_options ( self , options , search_type = None ) : \n if search_type : \n self . command_name = \"<STR_LIT>\" . format ( \n base = self . command_name , \n search_type = search_type . lower ( ) \n ) \n if search_type == \"<STR_LIT>\" : \n options [ \"<STR_LIT>\" ] = dict ( \n search_type = search_type , \n scroll = self . settings . scroll_size \n ) \n elif search_type is not None : \n options [ \"<STR_LIT>\" ] = dict ( \n search_type = search_type \n ) \n return options \n class SettingsBaseCommand ( BaseCommand ) : \n def is_enabled ( self ) : \n return True \n", "gt": "ANALYTICS_WRITE_KEY"}
{"input": "\n import sublime \n from . base import DeleteBaseCommand \n class DeleteDocumentCommand ( DeleteBaseCommand ) : \n <mask0> = \"<STR_LIT>\" \n def is_enabled ( self ) : \n return True \n def run_request ( self , id = None ) : \n if not id : \n self . show_input_panel ( '<STR_LIT>' , '<STR_LIT>' , self . run ) \n return \n options = dict ( \n index = self . settings . index , \n doc_type = self . settings . doc_type , \n id = id \n ) \n if sublime . ok_cancel_dialog ( \"<STR_LIT>\" , ok_title = '<STR_LIT>' ) : \n return self . client . delete ( ** options ) \n", "gt": "command_name"}
{"input": "\n import sublime \n from . base import DeleteBaseCommand \n class IndicesDeleteAliasCommand ( DeleteBaseCommand ) : \n <mask0> = \"<STR_LIT>\" \n def is_enabled ( self ) : \n return True \n def run_request ( self , index = None , name = None ) : \n if not index or not name : \n self . show_alias_list_panel ( self . run ) \n return \n options = dict ( \n index = index , \n name = name \n ) \n if sublime . ok_cancel_dialog ( \"<STR_LIT>\" , ok_title = '<STR_LIT>' ) : \n return self . client . indices . delete_alias ( ** options ) \n", "gt": "command_name"}
{"input": "\n from . base import BaseCommand \n class IndicesStatsCommand ( BaseCommand ) : \n <mask0> = \"<STR_LIT>\" \n def is_enabled ( self ) : \n return True \n def run_request ( self , index = None ) : \n if index is None : \n self . show_index_list_panel ( self . run ) \n return \n options = dict ( \n index = index , \n params = dict ( human = True ) \n ) \n return self . client . indices . stats ( ** options ) \n", "gt": "command_name"}
{"input": "\n import sublime_plugin \n class ShowOutputPanelCommand ( sublime_plugin . WindowCommand ) : \n <mask0> = \"<STR_LIT>\" \n def run ( self , text , syntax = None ) : \n if syntax is None : \n syntax = self . default_syntax \n panel = self . window . create_output_panel ( \"<STR_LIT>\" ) \n self . window . run_command ( \n \"<STR_LIT>\" , { \"<STR_LIT>\" : \"<STR_LIT>\" } ) \n panel . set_syntax_file ( syntax ) \n panel . settings ( ) . set ( '<STR_LIT>' , True ) \n panel . settings ( ) . set ( '<STR_LIT>' , False ) \n panel . set_read_only ( False ) \n panel . run_command ( '<STR_LIT>' , { '<STR_LIT>' : text } ) \n panel . set_read_only ( True ) \n", "gt": "default_syntax"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import datetime \n <mask0> = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n EASTER_JULIAN = <NUM_LIT:1> \n EASTER_ORTHODOX = <NUM_LIT:2> \n EASTER_WESTERN = <NUM_LIT:3> \n def easter ( year , method = EASTER_WESTERN ) : \n \"\"\"<STR_LIT>\"\"\" \n if not ( <NUM_LIT:1> <= method <= <NUM_LIT:3> ) : \n raise ValueError ( \"<STR_LIT>\" ) \n y = year \n g = y % <NUM_LIT> \n e = <NUM_LIT:0> \n if method < <NUM_LIT:3> : \n i = ( <NUM_LIT> * g + <NUM_LIT:15> ) % <NUM_LIT:30> \n j = ( y + y // <NUM_LIT:4> + i ) % <NUM_LIT:7> \n if method == <NUM_LIT:2> : \n e = <NUM_LIT:10> \n if y > <NUM_LIT> : \n e = e + y // <NUM_LIT:100> - <NUM_LIT:16> - ( y // <NUM_LIT:100> - <NUM_LIT:16> ) // <NUM_LIT:4> \n else : \n c = y // <NUM_LIT:100> \n h = ( c - c // <NUM_LIT:4> - ( <NUM_LIT:8> * c + <NUM_LIT> ) // <NUM_LIT> + <NUM_LIT> * g + <NUM_LIT:15> ) % <NUM_LIT:30> \n i = h - ( h // <NUM_LIT> ) * ( <NUM_LIT:1> - ( h // <NUM_LIT> ) * ( <NUM_LIT> // ( h + <NUM_LIT:1> ) ) * ( ( <NUM_LIT> - g ) // <NUM_LIT:11> ) ) \n j = ( y + y // <NUM_LIT:4> + i + <NUM_LIT:2> - c + c // <NUM_LIT:4> ) % <NUM_LIT:7> \n p = i - j + e \n d = <NUM_LIT:1> + ( p + <NUM_LIT> + ( p + <NUM_LIT:6> ) // <NUM_LIT> ) % <NUM_LIT> \n m = <NUM_LIT:3> + ( p + <NUM_LIT> ) // <NUM_LIT:30> \n return datetime . date ( int ( y ) , int ( m ) , int ( d ) ) \n", "gt": "__all__"}
{"input": "\n <mask0> = [ \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' \n ] \n class ImproperlyConfigured ( Exception ) : \n \"\"\"<STR_LIT>\"\"\" \n class ElasticsearchException ( Exception ) : \n \"\"\"<STR_LIT>\"\"\" \n class SerializationError ( ElasticsearchException ) : \n \"\"\"<STR_LIT>\"\"\" \n class TransportError ( ElasticsearchException ) : \n \"\"\"<STR_LIT>\"\"\" \n @ property \n def status_code ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . args [ <NUM_LIT:0> ] \n @ property \n def error ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . args [ <NUM_LIT:1> ] \n @ property \n def info ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . args [ <NUM_LIT:2> ] \n def __str__ ( self ) : \n return '<STR_LIT>' % ( self . status_code , self . error ) \n class ConnectionError ( TransportError ) : \n \"\"\"<STR_LIT>\"\"\" \n def __str__ ( self ) : \n return '<STR_LIT>' % ( \n self . error , self . info . __class__ . __name__ , self . info ) \n class SSLError ( ConnectionError ) : \n \"\"\"<STR_LIT>\"\"\" \n class ConnectionTimeout ( ConnectionError ) : \n \"\"\"<STR_LIT>\"\"\" \n def __str__ ( self ) : \n return '<STR_LIT>' % ( \n self . info . __class__ . __name__ , self . info ) \n class NotFoundError ( TransportError ) : \n \"\"\"<STR_LIT>\"\"\" \n class ConflictError ( TransportError ) : \n \"\"\"<STR_LIT>\"\"\" \n class RequestError ( TransportError ) : \n \"\"\"<STR_LIT>\"\"\" \n class AuthenticationException ( TransportError ) : \n \"\"\"<STR_LIT>\"\"\" \n class AuthorizationException ( TransportError ) : \n \"\"\"<STR_LIT>\"\"\" \n HTTP_EXCEPTIONS = { \n <NUM_LIT> : RequestError , \n <NUM_LIT> : AuthenticationException , \n <NUM_LIT> : AuthorizationException , \n <NUM_LIT> : NotFoundError , \n <NUM_LIT> : ConflictError , \n } \n", "gt": "__all__"}
{"input": "\n from . alias_list_panel import AliasListPanel \n from . analyzer_list_panel import AnalyzerListPanel \n from . doc_type_list_panel import DocTypeListPanel \n from . field_list_panel import FieldListPanel \n from . index_list_panel import IndexListPanel \n from . index_template_list_panel import IndexTemplateListPanel \n from . repository_list_panel import RepositoryListPanel \n from . script_list_panel import ScriptListPanel \n from . search_template_list_panel import SearchTemplateListPanel \n from . snapshot_list_panel import SnapshotListPanel \n from . switch_server_list_panel import SwitchServerListPanel \n from . warmer_list_panel import WarmerListPanel \n <mask0> = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n", "gt": "__all__"}
{"input": "\n import unittest \n from test . asserting . policy import PolicyAssertion , get_fixture_path \n from vint . linting . level import Level \n from vint . linting . policy . prohibit_command_with_unintended_side_effect import ProhibitCommandWithUnintendedSideEffect \n <mask0> = get_fixture_path ( '<STR_LIT>' ) \n PATH_INVALID_VIM_SCRIPT = get_fixture_path ( '<STR_LIT>' ) \n class TestProhibitCommandWithUnintendedSideEffect ( PolicyAssertion , unittest . TestCase ) : \n def _create_violation_by_line_number ( self , line_number ) : \n return { \n '<STR_LIT:name>' : '<STR_LIT>' , \n '<STR_LIT>' : Level . WARNING , \n '<STR_LIT>' : { \n '<STR_LIT>' : line_number , \n '<STR_LIT>' : <NUM_LIT:1> , \n '<STR_LIT:path>' : PATH_INVALID_VIM_SCRIPT \n } \n } \n def test_get_violation_if_found_with_valid_file ( self ) : \n self . assertFoundNoViolations ( PATH_VALID_VIM_SCRIPT , \n ProhibitCommandWithUnintendedSideEffect ) \n def test_get_violation_if_found_with_invalid_file ( self ) : \n expected_violations = [ self . _create_violation_by_line_number ( line_number ) \n for line_number in range ( <NUM_LIT:1> , <NUM_LIT> ) ] \n expected_violations [ <NUM_LIT:3> ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] = <NUM_LIT:2> \n expected_violations [ <NUM_LIT:4> ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] = <NUM_LIT:6> \n self . assertFoundViolationsEqual ( PATH_INVALID_VIM_SCRIPT , \n ProhibitCommandWithUnintendedSideEffect , \n expected_violations ) \n if __name__ == '<STR_LIT:__main__>' : \n unittest . main ( ) \n", "gt": "PATH_VALID_VIM_SCRIPT"}
{"input": "\n import unittest \n from test . asserting . config_source import ConfigSourceAssertion \n from test . asserting . config_source import get_fixture_path \n from vint . linting . config . config_file_source import ConfigFileSource \n from vint . linting . level import Level \n <mask0> = get_fixture_path ( '<STR_LIT>' ) \n class TestConfigFileSource ( ConfigSourceAssertion , unittest . TestCase ) : \n class ConcreteConfigFileSource ( ConfigFileSource ) : \n def get_file_path ( self , env ) : \n return FIXTURE_CONFIG_FILE \n def test_get_config_dict ( self ) : \n expected_config_dict = { \n '<STR_LIT>' : { \n '<STR_LIT>' : True , \n '<STR_LIT>' : Level . WARNING , \n '<STR_LIT>' : <NUM_LIT:10> , \n } , \n '<STR_LIT>' : { \n '<STR_LIT>' : { \n '<STR_LIT>' : False , \n } , \n '<STR_LIT>' : { \n '<STR_LIT>' : True , \n } , \n } \n } \n config_source = self . initialize_config_source_with_env ( \n TestConfigFileSource . ConcreteConfigFileSource ) \n self . assertConfigDict ( config_source , expected_config_dict ) \n if __name__ == '<STR_LIT:__main__>' : \n unittest . main ( ) \n", "gt": "FIXTURE_CONFIG_FILE"}
{"input": "\n from vint . ast . plugin . scope_plugin . scope_detector import ( \n detect_scope_visibility , \n normalize_variable_name , \n is_builtin_variable , \n ) \n from vint . ast . plugin . scope_plugin . scope_linker import ScopeLinker \n from vint . ast . plugin . scope_plugin . identifier_classifier import ( \n IdentifierClassifier , \n is_function_identifier , \n ) \n <mask0> = '<STR_LIT>' \n REFERECED_FLAG = '<STR_LIT>' \n class ReferenceReachabilityTester ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n class TwoWayScopeReferenceAttacher ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n @ classmethod \n def attach ( cls , root_scope_tree ) : \n root_scope_tree [ '<STR_LIT>' ] = None \n return cls . _attach_recursively ( root_scope_tree ) \n @ classmethod \n def _attach_recursively ( cls , scope_tree ) : \n for child_scope in scope_tree [ '<STR_LIT>' ] : \n child_scope [ '<STR_LIT>' ] = scope_tree \n cls . _attach_recursively ( child_scope ) \n return scope_tree \n def process ( self , ast ) : \n scope_linker = ScopeLinker ( ) \n scope_linker . process ( ast ) \n id_collector = IdentifierClassifier . IdentifierCollector ( ) \n classified_id_group = id_collector . collect_identifiers ( ast ) \n dec_id_nodes = classified_id_group [ '<STR_LIT>' ] \n ref_id_nodes = classified_id_group [ '<STR_LIT>' ] \n self . _scope_tree = scope_linker . scope_tree \n self . _link_registry = scope_linker . link_registry \n ReferenceReachabilityTester . TwoWayScopeReferenceAttacher . attach ( self . _scope_tree ) \n for dec_id_node in dec_id_nodes : \n dec_id_node [ REFERECED_FLAG ] = False \n for ref_id_node in ref_id_nodes : \n is_reachable = self . check_reachability ( ref_id_node ) \n ref_id_node [ REACHABILITY_FLAG ] = is_reachable \n def get_objective_scope_visibility ( self , node ) : \n \"\"\"<STR_LIT>\"\"\" \n context_scope = self . _link_registry . get_scope_by_referencing_identifier ( node ) \n return detect_scope_visibility ( node , context_scope ) [ '<STR_LIT>' ] \n def _reset_referenced_flag ( self , scope_tree ) : \n for child_scope in scope_tree [ '<STR_LIT>' ] : \n for functions in child_scope [ '<STR_LIT>' ] . values ( ) : \n for function in functions : \n function [ REFERECED_FLAG ] = False \n for variables in child_scope [ '<STR_LIT>' ] . values ( ) : \n for variable in variables : \n variable [ REFERECED_FLAG ] = False \n self . _reset_referenced_flag ( child_scope ) \n def check_reachability ( self , ref_id_node ) : \n scope = self . _link_registry . get_context_scope_by_identifier ( ref_id_node ) \n var_name = normalize_variable_name ( ref_id_node , scope ) \n is_func_id = is_function_identifier ( ref_id_node ) \n while scope is not None : \n if is_func_id : \n functions_list = scope [ '<STR_LIT>' ] \n if var_name in functions_list : \n for variable in functions_list [ var_name ] : \n declaring_id_node = self . _link_registry . get_declarative_identifier_by_variable ( variable ) \n declaring_id_node [ REFERECED_FLAG ] = True \n return True \n else : \n pass \n variables_list = scope [ '<STR_LIT>' ] \n if var_name in variables_list : \n for variable in variables_list [ var_name ] : \n declaring_id_node = self . _link_registry . get_declarative_identifier_by_variable ( variable ) \n declaring_id_node [ REFERECED_FLAG ] = True \n return True \n scope = scope [ '<STR_LIT>' ] \n return is_builtin_variable ( ref_id_node ) \n def is_reference_identifier ( node ) : \n return REACHABILITY_FLAG in node \n def is_reachable_reference_identifier ( node ) : \n return node . get ( REACHABILITY_FLAG , False ) \n def is_declarative_identifier ( node ) : \n return REFERECED_FLAG in node \n def is_referenced_declarative_identifier ( node ) : \n return node . get ( REFERECED_FLAG , False ) \n", "gt": "REACHABILITY_FLAG"}
{"input": "\n import re \n from vint . ast . node_type import NodeType \n from vint . linting . level import Level \n from vint . linting . policy . abstract_policy import AbstractPolicy \n from vint . linting . policy_registry import register_policy \n from vint . ast . dictionary . abbreviations import ( \n Abbreviations , \n AbbreviationsIncludingInvertPrefix , \n ) \n <mask0> = { \n '<STR_LIT>' : True , \n '<STR_LIT>' : True , \n '<STR_LIT>' : True , \n } \n @ register_policy \n class ProhibitAbbreviationOption ( AbstractPolicy ) : \n def __init__ ( self ) : \n super ( ProhibitAbbreviationOption , self ) . __init__ ( ) \n self . description = '<STR_LIT>' \n self . reference = '<STR_LIT>' \n self . level = Level . STYLE_PROBLEM \n self . was_scriptencoding_found = False \n self . has_encoding_opt_after_scriptencoding = False \n def listen_node_types ( self ) : \n return [ NodeType . EXCMD , NodeType . OPTION ] \n def is_valid ( self , node , lint_context ) : \n \"\"\"<STR_LIT>\"\"\" \n node_type = NodeType ( node [ '<STR_LIT:type>' ] ) \n if node_type is NodeType . OPTION : \n option_name = node [ '<STR_LIT:value>' ] [ <NUM_LIT:1> : ] \n is_valid = option_name not in Abbreviations \n if not is_valid : \n self . _make_description_by_option_name ( option_name ) \n return is_valid \n excmd_node = node \n is_set_cmd = excmd_node [ '<STR_LIT>' ] [ '<STR_LIT>' ] . get ( '<STR_LIT:name>' ) in SetCommandFamily \n if not is_set_cmd : \n return True \n option_expr = excmd_node [ '<STR_LIT:str>' ] . split ( ) [ <NUM_LIT:1> ] \n option_name = re . match ( r'<STR_LIT>' , option_expr ) . group ( <NUM_LIT:0> ) \n is_valid = option_name not in AbbreviationsIncludingInvertPrefix \n if not is_valid : \n self . _make_description_by_option_name ( option_name ) \n return is_valid \n def _make_description_by_option_name ( self , option_name ) : \n param = { \n '<STR_LIT>' : AbbreviationsIncludingInvertPrefix [ option_name ] , \n '<STR_LIT>' : option_name , \n } \n self . description = ( '<STR_LIT>' \n '<STR_LIT>' . format ( ** param ) ) \n", "gt": "SetCommandFamily"}
{"input": "\n from serfclient import result \n class TestSerfResult ( object ) : \n def test_initialises_to_none ( self ) : \n <mask0> = result . SerfResult ( ) \n assert r . head is None \n assert r . body is None \n def test_provides_a_pretty_printed_form_for_repl_use ( self ) : \n r = result . SerfResult ( head = { \"<STR_LIT:a>\" : <NUM_LIT:1> } , body = ( '<STR_LIT:foo>' , '<STR_LIT:bar>' ) ) \n assert str ( r ) == \"<STR_LIT>\" \n def test_can_convert_to_list ( self ) : \n r = result . SerfResult ( head = <NUM_LIT:1> , body = <NUM_LIT:2> ) \n assert sorted ( list ( r ) ) == [ <NUM_LIT:1> , <NUM_LIT:2> ] \n def test_can_convert_to_tuple ( self ) : \n r = result . SerfResult ( head = <NUM_LIT:1> , body = <NUM_LIT:2> ) \n assert sorted ( tuple ( r ) ) == [ <NUM_LIT:1> , <NUM_LIT:2> ] \n", "gt": "r"}
{"input": "\n import os \n import logging \n class AttrDict ( dict ) : \n \"\"\"<STR_LIT>\"\"\" \n def __getattr__ ( self , name ) : \n if name in self : \n return self [ name ] \n raise AttributeError ( '<STR_LIT>' % name ) \n def __setattr__ ( self , name , val ) : \n self [ name ] = val \n def get_logger ( name , level = None ) : \n \"\"\"<STR_LIT>\"\"\" \n <mask0> = logging . getLogger ( name ) \n if not logger . handlers : \n stderr = logging . StreamHandler ( ) \n stderr . setFormatter ( logging . Formatter ( \n '<STR_LIT>' ) ) \n logger . addHandler ( stderr ) \n level = level if level else os . environ . get ( '<STR_LIT>' , '<STR_LIT>' ) \n logger . setLevel ( getattr ( logging , level ) ) \n return logger \n", "gt": "logger"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n from math import * \n def AirDensity ( RH , Tc , P = <NUM_LIT> ) : \n <mask0> = <NUM_LIT> \n q = <NUM_LIT> * ( RH * SatVapor ( Tc ) ) / P \n Tv = ( Tc + <NUM_LIT> ) * ( <NUM_LIT:1.0> + <NUM_LIT> * q ) \n P *= <NUM_LIT> \n rho_a = P / ( Rd * Tv ) \n return rho_a \n def PsychConst ( P , cP = <NUM_LIT> , lambda_v = <NUM_LIT> ) : \n gamma = ( cP * P / ( <NUM_LIT> * lambda_v ) ) \n return gamma \n def SatVaporPress ( Tc ) : \n eSat = <NUM_LIT> * exp ( <NUM_LIT> * Tc / ( <NUM_LIT> + Tc ) ) \n return eSat \n def SlopeSatVaporPress ( Tc ) : \n delta = <NUM_LIT> * SatVaporPress ( Tc ) / ( <NUM_LIT> + Tc ) ** <NUM_LIT:2> \n return delta \n def AeroReist ( um , zm , z0 , d , zmp = zm ) : \n k = <NUM_LIT> \n r_a = <NUM_LIT:1.0> / ( k ** <NUM_LIT:2> * um ) * log ( ( zm - d ) / z0 ) * log ( ( zmp - d ) / ( z0 / <NUM_LIT> ) ) \n return r_a \n def SurfResist ( g0 , S , D , Tc , SM , SM0 ) : \n g_c = Gee_C ( ) \n g_R = Gee_R ( S ) \n g_D = Gee_D ( D ) \n g_T = Gee_T ( Tc + <NUM_LIT> ) \n g_M = Gee_M ( SM , SM0 ) \n g_s = g0 * g_c * g_R * g_D * g_T * g_M \n r_s = <NUM_LIT:1.0> / g_s \n return r_s \n def Gee_c ( ) : \n g_c = <NUM_LIT:1.0> \n return g_c \n def Gee_R ( S , K_R = <NUM_LIT> ) : \n g_R = ( S * ( <NUM_LIT> + K_R ) ) / ( <NUM_LIT> * ( S + K_R ) ) \n return g_R \n def Gee_D ( D , K_D1 = - <NUM_LIT> , K_D2 = <NUM_LIT> ) : \n g_D = <NUM_LIT:1.0> + K_D1 * D + K_D2 * D ** <NUM_LIT:2> \n return g_D \n def Gee_T ( TK , TL = <NUM_LIT> , TH = <NUM_LIT> , T0 = <NUM_LIT> ) : \n alpha_T = ( TH - T0 ) / ( T0 - TL ) \n g_T = ( ( TK - TL ) * ( TH - TK ) ** alpha_T ) / ( ( T0 - TL ) * ( TH - T0 ) ** alpha_T ) \n return g_T \n def Gee_M ( SM , SM0 , K_M1 , K_M2 ) : \n g_SM = <NUM_LIT:1.0> - K_M1 * exp ( K_M2 * ( SM - SM0 ) ) \n return g_SM \n def PenmanMonteithPET ( Tc , RH , Rn , S , SM , um , z0 , d , g0 , SM0 , P = <NUM_LIT> , zm = <NUM_LIT> ) : \n cP = <NUM_LIT> \n rho_a = AirDensity ( RH , Tc , P ) \n D = ( <NUM_LIT:1.0> - RH ) * SatVaporPress ( Tc ) \n delta = SlopeSatVaporPress ( Tc ) \n gamma = PsychConst ( P ) \n r_a = AeroReist ( um , zm , z0 , d ) \n r_s = SurfResist ( g0 , S , D , Tc , SM , SM0 ) \n LE = ( delta * Rn + ( rho_a * cP * D ) / r_a ) / ( delta + gamma * ( <NUM_LIT:1.0> + r_s / r_a ) ) \n return LE \n", "gt": "Rd"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n from contextlib import contextmanager \n from OpenGL . GL import * \n @ contextmanager \n def glSection ( type ) : \n glBegin ( type ) \n yield \n glEnd ( ) \n @ contextmanager \n def glMatrix ( ) : \n glPushMatrix ( ) \n yield \n glPopMatrix ( ) \n @ contextmanager \n def glModeMatrix ( type ) : \n glMatrixMode ( type ) \n glPushMatrix ( ) \n yield \n glMatrixMode ( type ) \n glPopMatrix ( ) \n @ contextmanager \n def attributes ( * glBits ) : \n for bit in glBits : \n glPushAttrib ( bit ) \n yield \n for bit in glBits : \n glPopAttrib ( ) \n @ contextmanager \n def enabled ( * glBits ) : \n for bit in glBits : \n glEnable ( bit ) \n yield \n for bit in glBits : \n glDisable ( bit ) \n @ contextmanager \n def disabled ( * glBits ) : \n for bit in glBits : \n glDisable ( bit ) \n yield \n for bit in glBits : \n glEnable ( bit ) \n @ contextmanager \n def overlays2D ( width , height , background_color ) : \n \"\"\"<STR_LIT>\"\"\" \n glDisable ( GL_LIGHTING ) \n glDisable ( GL_LIGHT0 ) \n glDisable ( GL_BLEND ) \n glEnable ( GL_SCISSOR_TEST ) \n with glModeMatrix ( GL_PROJECTION ) : \n yield \n glViewport ( <NUM_LIT:0> , <NUM_LIT:0> , width , height ) \n glDisable ( GL_SCISSOR_TEST ) \n glMatrixMode ( GL_MODELVIEW ) \n glLoadIdentity ( ) \n glEnable ( GL_LIGHTING ) \n glEnable ( GL_LIGHT0 ) \n glEnable ( GL_BLEND ) \n glClearColor ( * background_color ) \n def setup_overlay2D ( x , y , width , height ) : \n \"\"\"<STR_LIT>\"\"\" \n glMatrixMode ( GL_PROJECTION ) \n glLoadIdentity ( ) \n glScissor ( x , y , width , height ) \n glViewport ( x , y , width , height ) \n glOrtho ( x , x + width , y , y + height , - <NUM_LIT:1> , <NUM_LIT:1> ) \n glMatrixMode ( GL_MODELVIEW ) \n <mask0> = [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] ; \n def notGlePolyCylinder ( points , color , radius ) : \n trigs = [ radius * x for x in cyltrigs ] ; \n if abs ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] - points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] ) > <NUM_LIT> : \n with glSection ( GL_QUAD_STRIP ) : \n glNormal3f ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1.> ) \n glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , <NUM_LIT:0> , radius ) \n glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , <NUM_LIT:0> , radius ) \n glNormal3f ( <NUM_LIT:0> , cyltrigs [ <NUM_LIT:0> ] , cyltrigs [ <NUM_LIT:1> ] ) \n glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:1> ] ) \n glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:1> ] ) \n glNormal3f ( <NUM_LIT:0> , cyltrigs [ <NUM_LIT:2> ] , cyltrigs [ <NUM_LIT:3> ] ) \n glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:2> ] , trigs [ <NUM_LIT:3> ] ) \n glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:2> ] , trigs [ <NUM_LIT:3> ] ) \n glNormal3f ( <NUM_LIT:0> , cyltrigs [ <NUM_LIT:2> ] , - cyltrigs [ <NUM_LIT:3> ] ) \n glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:2> ] , - trigs [ <NUM_LIT:3> ] ) \n glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:2> ] , - trigs [ <NUM_LIT:3> ] ) \n glNormal3f ( <NUM_LIT:0> , cyltrigs [ <NUM_LIT:0> ] , - cyltrigs [ <NUM_LIT:1> ] ) \n glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:1> ] ) \n glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:1> ] ) \n glNormal3f ( <NUM_LIT:0> , <NUM_LIT:0> , - <NUM_LIT:1.> ) \n glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , <NUM_LIT:0> , - radius ) \n glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , <NUM_LIT:0> , - radius ) \n glNormal3f ( <NUM_LIT:0> , - cyltrigs [ <NUM_LIT:0> ] , - cyltrigs [ <NUM_LIT:1> ] ) \n glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:1> ] ) \n glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:1> ] ) \n glNormal3f ( <NUM_LIT:0> , - cyltrigs [ <NUM_LIT:2> ] , - cyltrigs [ <NUM_LIT:3> ] ) \n glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:2> ] , - trigs [ <NUM_LIT:3> ] ) \n glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:2> ] , - trigs [ <NUM_LIT:3> ] ) \n glNormal3f ( <NUM_LIT:0> , - cyltrigs [ <NUM_LIT:2> ] , cyltrigs [ <NUM_LIT:3> ] ) \n glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:2> ] , trigs [ <NUM_LIT:3> ] ) \n glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:2> ] , trigs [ <NUM_LIT:3> ] ) \n glNormal3f ( <NUM_LIT:0> , - cyltrigs [ <NUM_LIT:0> ] , cyltrigs [ <NUM_LIT:1> ] ) \n glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:1> ] ) \n glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:1> ] ) \n glNormal3f ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1.> ) \n glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , <NUM_LIT:0> , radius ) \n glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , <NUM_LIT:0> , radius ) \n elif abs ( points [ <NUM_LIT:1> ] [ <NUM_LIT:1> ] - points [ <NUM_LIT:2> ] [ <NUM_LIT:1> ] ) > <NUM_LIT> : \n p1 = points [ <NUM_LIT:1> ] [ <NUM_LIT:1> ] \n p2 = points [ <NUM_LIT:2> ] [ <NUM_LIT:1> ] \n with glSection ( GL_QUAD_STRIP ) : \n glNormal3f ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1.> ) \n glVertex ( <NUM_LIT:0> , p1 , radius ) \n glVertex ( <NUM_LIT:0> , p2 , radius ) \n glNormal3f ( cyltrigs [ <NUM_LIT:0> ] , <NUM_LIT:0> , cyltrigs [ <NUM_LIT:1> ] ) \n glVertex ( trigs [ <NUM_LIT:0> ] , p1 , trigs [ <NUM_LIT:1> ] ) \n glVertex ( trigs [ <NUM_LIT:0> ] , p2 , trigs [ <NUM_LIT:1> ] ) \n glNormal3f ( cyltrigs [ <NUM_LIT:2> ] , <NUM_LIT:0> , cyltrigs [ <NUM_LIT:3> ] ) \n glVertex ( trigs [ <NUM_LIT:2> ] , p1 , trigs [ <NUM_LIT:3> ] ) \n glVertex ( trigs [ <NUM_LIT:2> ] , p2 , trigs [ <NUM_LIT:3> ] ) \n glNormal3f ( cyltrigs [ <NUM_LIT:2> ] , <NUM_LIT:0> , - cyltrigs [ <NUM_LIT:3> ] ) \n glVertex ( trigs [ <NUM_LIT:2> ] , p1 , - trigs [ <NUM_LIT:3> ] ) \n glVertex ( trigs [ <NUM_LIT:2> ] , p2 , - trigs [ <NUM_LIT:3> ] ) \n glNormal3f ( cyltrigs [ <NUM_LIT:0> ] , <NUM_LIT:0> , - cyltrigs [ <NUM_LIT:1> ] ) \n glVertex ( trigs [ <NUM_LIT:0> ] , p1 , - trigs [ <NUM_LIT:1> ] ) \n glVertex ( trigs [ <NUM_LIT:0> ] , p2 , - trigs [ <NUM_LIT:1> ] ) \n glNormal3f ( <NUM_LIT:0> , <NUM_LIT:0> , - <NUM_LIT:1.> ) \n glVertex ( <NUM_LIT:0> , p1 , - radius ) \n glVertex ( <NUM_LIT:0> , p2 , - radius ) \n glNormal3f ( - cyltrigs [ <NUM_LIT:0> ] , <NUM_LIT:0> , - cyltrigs [ <NUM_LIT:1> ] ) \n glVertex ( - trigs [ <NUM_LIT:0> ] , p1 , - trigs [ <NUM_LIT:1> ] ) \n glVertex ( - trigs [ <NUM_LIT:0> ] , p2 , - trigs [ <NUM_LIT:1> ] ) \n glNormal3f ( - cyltrigs [ <NUM_LIT:2> ] , <NUM_LIT:0> , - cyltrigs [ <NUM_LIT:3> ] ) \n glVertex ( - trigs [ <NUM_LIT:2> ] , p1 , - trigs [ <NUM_LIT:3> ] ) \n glVertex ( - trigs [ <NUM_LIT:2> ] , p2 , - trigs [ <NUM_LIT:3> ] ) \n glNormal3f ( - cyltrigs [ <NUM_LIT:2> ] , <NUM_LIT:0> , cyltrigs [ <NUM_LIT:3> ] ) \n glVertex ( - trigs [ <NUM_LIT:2> ] , p1 , trigs [ <NUM_LIT:3> ] ) \n glVertex ( - trigs [ <NUM_LIT:2> ] , p2 , trigs [ <NUM_LIT:3> ] ) \n glNormal3f ( - cyltrigs [ <NUM_LIT:0> ] , <NUM_LIT:0> , cyltrigs [ <NUM_LIT:1> ] ) \n glVertex ( - trigs [ <NUM_LIT:0> ] , p1 , trigs [ <NUM_LIT:1> ] ) \n glVertex ( - trigs [ <NUM_LIT:0> ] , p2 , trigs [ <NUM_LIT:1> ] ) \n glNormal3f ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1.> ) \n glVertex ( <NUM_LIT:0> , p1 , radius ) \n glVertex ( <NUM_LIT:0> , p2 , radius ) \n else : \n p1 = points [ <NUM_LIT:1> ] [ <NUM_LIT:2> ] \n p2 = points [ <NUM_LIT:2> ] [ <NUM_LIT:2> ] \n with glSection ( GL_QUAD_STRIP ) : \n glNormal3f ( <NUM_LIT:0> , <NUM_LIT:1.> , <NUM_LIT:0> ) \n glVertex ( <NUM_LIT:0> , radius , p1 ) \n glVertex ( <NUM_LIT:0> , radius , p2 ) \n glNormal3f ( cyltrigs [ <NUM_LIT:0> ] , cyltrigs [ <NUM_LIT:1> ] , <NUM_LIT:0> ) \n glVertex ( trigs [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:1> ] , p1 ) \n glVertex ( trigs [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:1> ] , p2 ) \n glNormal3f ( cyltrigs [ <NUM_LIT:2> ] , cyltrigs [ <NUM_LIT:3> ] , <NUM_LIT:0> ) \n glVertex ( trigs [ <NUM_LIT:2> ] , trigs [ <NUM_LIT:3> ] , p1 ) \n glVertex ( trigs [ <NUM_LIT:2> ] , trigs [ <NUM_LIT:3> ] , p2 ) \n glNormal3f ( cyltrigs [ <NUM_LIT:2> ] , - cyltrigs [ <NUM_LIT:3> ] , <NUM_LIT:0> ) \n glVertex ( trigs [ <NUM_LIT:2> ] , - trigs [ <NUM_LIT:3> ] , p1 ) \n glVertex ( trigs [ <NUM_LIT:2> ] , - trigs [ <NUM_LIT:3> ] , p2 ) \n glNormal3f ( cyltrigs [ <NUM_LIT:0> ] , - cyltrigs [ <NUM_LIT:1> ] , <NUM_LIT:0> ) \n glVertex ( trigs [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:1> ] , p1 ) \n glVertex ( trigs [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:1> ] , p2 ) \n glNormal3f ( <NUM_LIT:0> , - <NUM_LIT:1.> , <NUM_LIT:0> ) \n glVertex ( <NUM_LIT:0> , - radius , p1 ) \n glVertex ( <NUM_LIT:0> , - radius , p2 ) \n glNormal3f ( - cyltrigs [ <NUM_LIT:0> ] , - cyltrigs [ <NUM_LIT:1> ] , <NUM_LIT:0> ) \n glVertex ( - trigs [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:1> ] , p1 ) \n glVertex ( - trigs [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:1> ] , p2 ) \n glNormal3f ( - cyltrigs [ <NUM_LIT:2> ] , - cyltrigs [ <NUM_LIT:3> ] , <NUM_LIT:0> ) \n glVertex ( - trigs [ <NUM_LIT:2> ] , - trigs [ <NUM_LIT:3> ] , p1 ) \n glVertex ( - trigs [ <NUM_LIT:2> ] , - trigs [ <NUM_LIT:3> ] , p2 ) \n glNormal3f ( - cyltrigs [ <NUM_LIT:2> ] , cyltrigs [ <NUM_LIT:3> ] , <NUM_LIT:0> ) \n glVertex ( - trigs [ <NUM_LIT:2> ] , trigs [ <NUM_LIT:3> ] , p1 ) \n glVertex ( - trigs [ <NUM_LIT:2> ] , trigs [ <NUM_LIT:3> ] , p2 ) \n glNormal3f ( - cyltrigs [ <NUM_LIT:0> ] , cyltrigs [ <NUM_LIT:1> ] , <NUM_LIT:0> ) \n glVertex ( - trigs [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:1> ] , p1 ) \n glVertex ( - trigs [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:1> ] , p2 ) \n glNormal3f ( <NUM_LIT:0> , <NUM_LIT:1.> , <NUM_LIT:0> ) \n glVertex ( <NUM_LIT:0> , radius , p1 ) \n glVertex ( <NUM_LIT:0> , radius , p2 ) \n def notGlutSolidCube ( size ) : \n p = size / <NUM_LIT:2> \n n = - <NUM_LIT:1> * p \n with glSection ( GL_QUADS ) : \n glNormal3f ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1.> ) \n glVertex ( n , p , n ) \n glVertex ( n , n , n ) \n glVertex ( p , n , n ) \n glVertex ( p , p , n ) \n with glSection ( GL_QUADS ) : \n glNormal3f ( <NUM_LIT:0> , <NUM_LIT:1.> , <NUM_LIT:0> ) \n glVertex ( n , p , p ) \n glVertex ( n , p , n ) \n glVertex ( p , p , n ) \n glVertex ( p , p , p ) \n with glSection ( GL_QUADS ) : \n glNormal3f ( <NUM_LIT:1.> , <NUM_LIT:0> , <NUM_LIT:0> ) \n glVertex ( p , p , n ) \n glVertex ( p , n , n ) \n glVertex ( p , n , p ) \n glVertex ( p , p , p ) \n with glSection ( GL_QUADS ) : \n glNormal3f ( <NUM_LIT:0> , <NUM_LIT:0> , - <NUM_LIT:1.> ) \n glVertex ( p , p , p ) \n glVertex ( p , n , p ) \n glVertex ( n , n , p ) \n glVertex ( n , p , p ) \n with glSection ( GL_QUADS ) : \n glNormal3f ( <NUM_LIT:0> , - <NUM_LIT:1.> , <NUM_LIT:0> ) \n glVertex ( p , n , p ) \n glVertex ( p , n , n ) \n glVertex ( n , n , n ) \n glVertex ( n , n , p ) \n with glSection ( GL_QUADS ) : \n glNormal3f ( - <NUM_LIT:1.> , <NUM_LIT:0> , <NUM_LIT:0> ) \n glVertex ( n , p , p ) \n glVertex ( n , n , p ) \n glVertex ( n , n , n ) \n glVertex ( n , p , n ) \n class DisplayList ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , renderFunction ) : \n self . renderFunction = renderFunction \n self . needsUpdate = True \n self . listId = None \n def update ( self ) : \n self . needsUpdate = True \n def __call__ ( self , * args ) : \n if self . needsUpdate : \n if self . listId : \n glDeleteLists ( self . listId , <NUM_LIT:1> ) \n self . listId = glGenLists ( <NUM_LIT:1> ) \n glNewList ( self . listId , GL_COMPILE_AND_EXECUTE ) \n self . renderFunction ( * args ) \n glEndList ( ) \n self . needsUpdate = False \n else : \n glCallList ( self . listId ) \n", "gt": "cyltrigs"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n from lantz import Q_ \n from lantz . drivers . examples . dummydrivers import DummyOsci , DummyFunGen , DummyShutter \n from myapps import AmplitudeScannerShutter \n <mask0> = DummyFunGen ( '<STR_LIT>' ) \n osci = DummyOsci ( '<STR_LIT>' ) \n shutter = DummyShutter ( '<STR_LIT>' ) \n with AmplitudeScannerShutter ( fungen = fungen , osci = osci , shutter = shutter ) as app : \n print ( '<STR_LIT>' ) \n data = list ( app . scan_amplitude ( Q_ ( range ( <NUM_LIT:1> , <NUM_LIT:10> ) , '<STR_LIT>' ) ) ) \n print ( data ) \n", "gt": "fungen"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n from . cobolt0601 import Cobolt0601 \n <mask0> = [ '<STR_LIT>' ] \n", "gt": "__all__"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import warnings \n from . import Q_ \n from . log import LOGGER as _LOG \n from stringparser import Parser \n class DimensionalityWarning ( Warning ) : \n pass \n def _do_nothing ( value ) : \n return value \n def _getitem ( a , b ) : \n \"\"\"<STR_LIT>\"\"\" \n try : \n return a [ b ] \n except KeyError : \n return a [ type ( b ) ] \n <mask0> = _getitem \n def convert_to ( units , on_dimensionless = '<STR_LIT>' , on_incompatible = '<STR_LIT>' , \n return_float = False ) : \n \"\"\"<STR_LIT>\"\"\" \n if on_dimensionless not in ( '<STR_LIT:ignore>' , '<STR_LIT>' , '<STR_LIT>' ) : \n raise ValueError ( \"<STR_LIT>\" \n \"<STR_LIT>\" . format ( on_dimensionless ) ) \n if on_incompatible not in ( '<STR_LIT:ignore>' , '<STR_LIT>' , '<STR_LIT>' ) : \n raise ValueError ( \"<STR_LIT>\" \n \"<STR_LIT>\" . format ( on_dimensionless ) ) \n if isinstance ( units , str ) : \n units = Q_ ( <NUM_LIT:1> , units ) \n elif not isinstance ( units , Q_ ) : \n raise ValueError ( \"<STR_LIT>\" \n \"<STR_LIT>\" ) \n if return_float : \n def _inner ( value ) : \n if isinstance ( value , Q_ ) : \n try : \n return value . to ( units ) . magnitude \n except ValueError as e : \n if on_incompatible == '<STR_LIT>' : \n raise ValueError ( e ) \n elif on_incompatible == '<STR_LIT>' : \n msg = '<STR_LIT>' . format ( value , units ) \n warnings . warn ( msg , DimensionalityWarning ) \n _LOG . warn ( msg ) \n return value . magnitude \n else : \n if not units . dimensionless : \n if on_dimensionless == '<STR_LIT>' : \n raise ValueError ( '<STR_LIT>' . format ( value , units ) ) \n elif on_dimensionless == '<STR_LIT>' : \n msg = '<STR_LIT>' . format ( value , units ) \n warnings . warn ( msg , DimensionalityWarning ) \n _LOG . warn ( msg ) \n return float ( value ) \n return _inner \n else : \n def _inner ( value ) : \n if isinstance ( value , Q_ ) : \n try : \n return value . to ( units ) \n except ValueError as e : \n if on_incompatible == '<STR_LIT>' : \n raise ValueError ( e ) \n elif on_incompatible == '<STR_LIT>' : \n msg = '<STR_LIT>' . format ( value , units ) \n warnings . warn ( msg , DimensionalityWarning ) \n _LOG . warn ( msg ) \n return float ( value . magnitude ) * units \n else : \n if not units . dimensionless : \n if on_dimensionless == '<STR_LIT>' : \n raise ValueError ( '<STR_LIT>' . format ( value , units ) ) \n elif on_dimensionless == '<STR_LIT>' : \n msg = '<STR_LIT>' . format ( value , units ) \n warnings . warn ( msg , DimensionalityWarning ) \n _LOG . warn ( msg ) \n return float ( value ) * units \n return _inner \n class Processor ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def __new__ ( cls , processors ) : \n if isinstance ( processors , ( tuple , list ) ) : \n if len ( processors ) > <NUM_LIT:1> : \n inst = super ( ) . __new__ ( cls ) \n inst . processors = tuple ( cls . _to_callable ( processor ) \n for processor in processors ) \n return inst \n else : \n return cls . _to_callable ( processors [ <NUM_LIT:0> ] ) \n else : \n return cls . _to_callable ( processors ) \n def __call__ ( self , values ) : \n return tuple ( processor ( value ) \n for processor , value in zip ( self . processors , values ) ) \n @ classmethod \n def _to_callable ( cls , obj ) : \n if callable ( obj ) : \n return obj \n if obj is None : \n return _do_nothing \n return cls . to_callable ( obj ) \n @ classmethod \n def to_callable ( cls , obj ) : \n raise TypeError ( '<STR_LIT>' . format ( obj ) ) \n def __len__ ( self ) : \n if isinstance ( self . processors , tuple ) : \n return len ( self . processors ) \n return <NUM_LIT:1> \n class FromQuantityProcessor ( Processor ) : \n \"\"\"<STR_LIT>\"\"\" \n @ classmethod \n def to_callable ( cls , obj ) : \n if isinstance ( obj , ( str , Q_ ) ) : \n return convert_to ( obj , return_float = True ) \n raise TypeError ( '<STR_LIT>' \n '<STR_LIT>' . format ( obj ) ) \n class ToQuantityProcessor ( Processor ) : \n \"\"\"<STR_LIT>\"\"\" \n @ classmethod \n def to_callable ( cls , obj ) : \n if isinstance ( obj , ( str , Q_ ) ) : \n return convert_to ( obj , on_dimensionless = '<STR_LIT:ignore>' ) \n raise TypeError ( '<STR_LIT>' \n '<STR_LIT>' . format ( obj ) ) \n class ParseProcessor ( Processor ) : \n \"\"\"<STR_LIT>\"\"\" \n @ classmethod \n def to_callable ( cls , obj ) : \n if isinstance ( obj , str ) : \n return Parser ( obj ) \n raise TypeError ( '<STR_LIT>' \n '<STR_LIT>' . format ( obj ) ) \n class MapProcessor ( Processor ) : \n \"\"\"<STR_LIT>\"\"\" \n @ classmethod \n def to_callable ( cls , obj ) : \n if isinstance ( obj , dict ) : \n return get_mapping ( obj ) \n if isinstance ( obj , set ) : \n return check_membership ( obj ) \n raise TypeError ( '<STR_LIT>' \n '<STR_LIT>' . format ( obj ) ) \n class ReverseMapProcessor ( Processor ) : \n \"\"\"<STR_LIT>\"\"\" \n __reversed_cache = { } \n @ classmethod \n def to_callable ( cls , obj ) : \n if isinstance ( obj , dict ) : \n obj = cls . __reversed_cache . setdefault ( id ( obj ) , \n { value : key for key , value \n in obj . items ( ) } ) \n return get_mapping ( obj ) \n if isinstance ( obj , set ) : \n return check_membership ( obj ) \n raise TypeError ( '<STR_LIT>' \n '<STR_LIT>' . format ( obj ) ) \n class RangeProcessor ( Processor ) : \n \"\"\"<STR_LIT>\"\"\" \n @ classmethod \n def to_callable ( cls , obj ) : \n if not isinstance ( obj , ( list , tuple ) ) : \n raise TypeError ( '<STR_LIT>' \n '<STR_LIT>' . format ( obj ) ) \n if not len ( obj ) in ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) : \n raise TypeError ( '<STR_LIT>' \n '<STR_LIT>' \n '<STR_LIT>' . format ( len ( obj ) ) ) \n if len ( obj ) == <NUM_LIT:1> : \n return check_range_and_coerce_step ( <NUM_LIT:0> , * obj ) \n return check_range_and_coerce_step ( * obj ) \n def check_range_and_coerce_step ( low , high , step = None ) : \n \"\"\"<STR_LIT>\"\"\" \n def _inner ( value ) : \n if not ( low <= value <= high ) : \n raise ValueError ( '<STR_LIT>' . format ( value , low , high ) ) \n if step : \n value = round ( ( value - low ) / step ) * step + low \n return value \n return _inner \n def check_membership ( container ) : \n \"\"\"<STR_LIT>\"\"\" \n def _inner ( value ) : \n if value not in container : \n raise ValueError ( '<STR_LIT>' . format ( value , container ) ) \n return value \n return _inner \n def get_mapping ( container ) : \n \"\"\"<STR_LIT>\"\"\" \n def _inner ( key ) : \n if key not in container : \n raise ValueError ( \"<STR_LIT>\" . format ( key , tuple ( container . keys ( ) ) ) ) \n return container [ key ] \n return _inner \n", "gt": "getitem"}
{"input": "\n try : \n from setuptools import setup \n except <mask0> : \n print ( '<STR_LIT>' ) \n sys . exit ( <NUM_LIT:1> ) \n import os \n import sys \n import codecs \n def read ( filename ) : \n return codecs . open ( filename , encoding = '<STR_LIT:utf-8>' ) . read ( ) \n long_description = '<STR_LIT>' . join ( [ read ( '<STR_LIT>' ) , \n read ( '<STR_LIT>' ) , \n read ( '<STR_LIT>' ) ] ) \n __doc__ = long_description \n requirements = [ ] \n if sys . version_info < ( <NUM_LIT:3> , <NUM_LIT:4> ) : \n requirements . append ( '<STR_LIT>' ) \n root_folder = os . path . dirname ( os . path . abspath ( __file__ ) ) \n folder = os . path . join ( root_folder , '<STR_LIT>' , '<STR_LIT>' ) \n paths = os . listdir ( folder ) \n companies = [ path for path in paths \n if os . path . isdir ( os . path . join ( folder , path ) ) \n and os . path . exists ( os . path . join ( folder , path , '<STR_LIT>' ) ) ] \n folder = os . path . join ( root_folder , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n paths = os . listdir ( folder ) \n legacy_companies = [ path for path in paths \n if os . path . isdir ( os . path . join ( folder , path ) ) \n and os . path . exists ( os . path . join ( folder , path , '<STR_LIT>' ) ) ] \n setup ( name = '<STR_LIT>' , \n version = '<STR_LIT>' , \n license = '<STR_LIT>' , \n description = '<STR_LIT>' , \n long_description = long_description , \n keywords = '<STR_LIT>' , \n author = '<STR_LIT>' , \n author_email = '<STR_LIT>' , \n url = '<STR_LIT>' , \n packages = [ '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' ] + \n [ '<STR_LIT>' + company for company in companies ] + \n [ '<STR_LIT>' + company for company in legacy_companies ] , \n test_suite = '<STR_LIT>' , \n install_requires = [ '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] + requirements , \n zip_safe = False , \n platforms = '<STR_LIT>' , \n entry_points = { \n '<STR_LIT>' : [ \n '<STR_LIT>' , \n ] , \n '<STR_LIT>' : [ \n '<STR_LIT>' , \n ] \n } , \n classifiers = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' \n ] , \n scripts = [ '<STR_LIT>' , \n ] , \n ) \n", "gt": "ImportError"}
{"input": "\n <mask0> = '<STR_LIT>' \n from learnpy . Problem import Problem \n pro = Problem ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n pro . set_label ( '<STR_LIT:Name>' ) \n pro . set_model ( \"<STR_LIT>\" ) \n pro . model . fit ( None ) \n pro . set_testing ( \"<STR_LIT>\" ) \n pro . predict ( ) \n pro2 = Problem ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n pro2 . set_label ( '<STR_LIT:Name>' ) \n pro2 . set_model ( \"<STR_LIT>\" ) \n pro2 . model . fit ( None ) \n pro2 . set_testing ( \"<STR_LIT>\" ) \n pro2 . predict ( ) \n", "gt": "__author__"}
{"input": "\n from collections import OrderedDict \n import theano . tensor as T \n from . . import utils \n <mask0> = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n class Layer ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , incoming , name = None ) : \n if isinstance ( incoming , tuple ) : \n self . input_shape = incoming \n self . input_layer = None \n else : \n self . input_shape = incoming . output_shape \n self . input_layer = incoming \n self . name = name \n self . params = OrderedDict ( ) \n self . get_output_kwargs = [ ] \n if any ( d is not None and d <= <NUM_LIT:0> for d in self . input_shape ) : \n raise ValueError ( ( \n \"<STR_LIT>\" \n \"<STR_LIT>\" ) % ( \n self . input_shape , self . name ) ) \n @ property \n def output_shape ( self ) : \n shape = self . get_output_shape_for ( self . input_shape ) \n if any ( isinstance ( s , T . Variable ) for s in shape ) : \n raise ValueError ( \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" % ( self . __class__ . __name__ , shape ) ) \n return shape \n def get_params ( self , ** tags ) : \n \"\"\"<STR_LIT>\"\"\" \n result = list ( self . params . keys ( ) ) \n only = set ( tag for tag , value in tags . items ( ) if value ) \n if only : \n result = [ param for param in result \n if not ( only - self . params [ param ] ) ] \n exclude = set ( tag for tag , value in tags . items ( ) if not value ) \n if exclude : \n result = [ param for param in result \n if not ( self . params [ param ] & exclude ) ] \n return utils . collect_shared_vars ( result ) \n def get_output_shape_for ( self , input_shape ) : \n \"\"\"<STR_LIT>\"\"\" \n return input_shape \n def get_output_for ( self , input , ** kwargs ) : \n \"\"\"<STR_LIT>\"\"\" \n raise NotImplementedError \n def add_param ( self , spec , shape , name = None , ** tags ) : \n \"\"\"<STR_LIT>\"\"\" \n if name is not None : \n if self . name is not None : \n name = \"<STR_LIT>\" % ( self . name , name ) \n param = utils . create_param ( spec , shape , name ) \n tags [ '<STR_LIT>' ] = tags . get ( '<STR_LIT>' , True ) \n tags [ '<STR_LIT>' ] = tags . get ( '<STR_LIT>' , True ) \n self . params [ param ] = set ( tag for tag , value in tags . items ( ) if value ) \n return param \n class MergeLayer ( Layer ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , incomings , name = None ) : \n self . input_shapes = [ incoming if isinstance ( incoming , tuple ) \n else incoming . output_shape \n for incoming in incomings ] \n self . input_layers = [ None if isinstance ( incoming , tuple ) \n else incoming \n for incoming in incomings ] \n self . name = name \n self . params = OrderedDict ( ) \n self . get_output_kwargs = [ ] \n @ Layer . output_shape . getter \n def output_shape ( self ) : \n shape = self . get_output_shape_for ( self . input_shapes ) \n if any ( isinstance ( s , T . Variable ) for s in shape ) : \n raise ValueError ( \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" % ( self . __class__ . __name__ , shape ) ) \n return shape \n def get_output_shape_for ( self , input_shapes ) : \n \"\"\"<STR_LIT>\"\"\" \n raise NotImplementedError \n def get_output_for ( self , inputs , ** kwargs ) : \n \"\"\"<STR_LIT>\"\"\" \n raise NotImplementedError \n", "gt": "__all__"}
{"input": "\n from mock import Mock \n import numpy \n import pytest \n import theano \n class TestAutocrop : \n def test_autocrop_array_shapes ( self ) : \n from lasagne . layers . merge import autocrop_array_shapes \n <mask0> = None \n crop1 = [ None , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n crop2 = [ '<STR_LIT>' , '<STR_LIT>' ] \n crop_bad = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n assert autocrop_array_shapes ( \n [ ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ) , ( <NUM_LIT:5> , <NUM_LIT:6> , <NUM_LIT:7> , <NUM_LIT:8> ) , ( <NUM_LIT:5> , <NUM_LIT:4> , <NUM_LIT:3> , <NUM_LIT:2> ) ] , crop0 ) == [ ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ) , ( <NUM_LIT:5> , <NUM_LIT:6> , <NUM_LIT:7> , <NUM_LIT:8> ) , ( <NUM_LIT:5> , <NUM_LIT:4> , <NUM_LIT:3> , <NUM_LIT:2> ) ] \n assert autocrop_array_shapes ( \n [ ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ) , ( <NUM_LIT:5> , <NUM_LIT:6> , <NUM_LIT:7> , <NUM_LIT:8> ) , ( <NUM_LIT:5> , <NUM_LIT:4> , <NUM_LIT:3> , <NUM_LIT:2> ) ] , crop1 ) == [ ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:5> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:5> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:2> ) ] \n assert autocrop_array_shapes ( \n [ ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ) , ( <NUM_LIT:5> , <NUM_LIT:6> , <NUM_LIT:7> , <NUM_LIT:8> ) , ( <NUM_LIT:5> , <NUM_LIT:4> , <NUM_LIT:3> , <NUM_LIT:2> ) ] , crop2 ) == [ ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ) , ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:7> , <NUM_LIT:8> ) , ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:2> ) ] \n with pytest . raises ( ValueError ) : \n autocrop_array_shapes ( \n [ ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ) , ( <NUM_LIT:5> , <NUM_LIT:6> , <NUM_LIT:7> , <NUM_LIT:8> ) , ( <NUM_LIT:5> , <NUM_LIT:4> , <NUM_LIT:3> , <NUM_LIT:2> ) ] , crop_bad ) \n with pytest . raises ( ValueError ) : \n autocrop_array_shapes ( \n [ ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ) , ( <NUM_LIT:5> , <NUM_LIT:6> , <NUM_LIT:7> ) , ( <NUM_LIT:5> , <NUM_LIT:4> , <NUM_LIT:3> , <NUM_LIT:2> , <NUM_LIT:10> ) ] , crop1 ) \n def test_crop_inputs ( self ) : \n from lasagne . layers . merge import autocrop \n from numpy . testing import assert_array_equal \n crop_0 = None \n crop_1 = [ None , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n crop_l = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n crop_c = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n crop_u = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n crop_x = [ '<STR_LIT>' , '<STR_LIT>' ] \n crop_bad = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n x0 = numpy . random . random ( ( <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:5> , <NUM_LIT:7> ) ) \n x1 = numpy . random . random ( ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ) ) \n x2 = numpy . random . random ( ( <NUM_LIT:6> , <NUM_LIT:3> , <NUM_LIT:4> , <NUM_LIT:2> ) ) \n def crop_test ( cropping , inputs , expected ) : \n inputs = [ theano . shared ( x ) for x in inputs ] \n outs = autocrop ( inputs , cropping ) \n outs = [ o . eval ( ) for o in outs ] \n assert len ( outs ) == len ( expected ) \n for o , e in zip ( outs , expected ) : \n assert_array_equal ( o , e ) \n crop_test ( crop_0 , [ x0 , x1 ] , \n [ x0 , x1 ] ) \n crop_test ( crop_1 , [ x0 , x1 ] , \n [ x0 [ : , : <NUM_LIT:2> , <NUM_LIT:1> : <NUM_LIT:4> , <NUM_LIT:3> : ] , x1 [ : , : , : , : ] ] ) \n crop_test ( crop_l , [ x0 , x1 ] , \n [ x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : <NUM_LIT:3> , : <NUM_LIT:4> ] , x1 [ : , : , : , : ] ] ) \n crop_test ( crop_c , [ x0 , x1 ] , \n [ x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , <NUM_LIT:1> : <NUM_LIT:4> , <NUM_LIT:1> : <NUM_LIT:5> ] , x1 [ : , : , : , : ] ] ) \n crop_test ( crop_u , [ x0 , x1 ] , \n [ x0 [ <NUM_LIT:1> : , <NUM_LIT:1> : , <NUM_LIT:2> : , <NUM_LIT:3> : ] , x1 [ : , : , : , : ] ] ) \n crop_test ( crop_0 , [ x0 , x2 ] , \n [ x0 , x2 ] ) \n crop_test ( crop_1 , [ x0 , x2 ] , \n [ x0 [ : , : , : <NUM_LIT:4> , <NUM_LIT:5> : ] , x2 [ : , : , : , : ] ] ) \n crop_test ( crop_l , [ x0 , x2 ] , \n [ x0 [ : , : , : <NUM_LIT:4> , : <NUM_LIT:2> ] , x2 [ : <NUM_LIT:2> , : , : , : ] ] ) \n crop_test ( crop_c , [ x0 , x2 ] , \n [ x0 [ : , : , : <NUM_LIT:4> , <NUM_LIT:2> : <NUM_LIT:4> ] , x2 [ <NUM_LIT:2> : <NUM_LIT:4> , : , : , : ] ] ) \n crop_test ( crop_u , [ x0 , x2 ] , \n [ x0 [ : , : , <NUM_LIT:1> : , <NUM_LIT:5> : ] , x2 [ <NUM_LIT:4> : , : , : , : ] ] ) \n crop_test ( crop_0 , [ x0 , x1 , x2 ] , \n [ x0 , x1 , x2 ] ) \n crop_test ( crop_1 , [ x0 , x1 , x2 ] , \n [ x0 [ : , : <NUM_LIT:2> , <NUM_LIT:1> : <NUM_LIT:4> , <NUM_LIT:5> : ] , x1 [ : , : , : , <NUM_LIT:2> : ] , x2 [ : , : <NUM_LIT:2> , : <NUM_LIT:3> , : ] ] ) \n crop_test ( crop_l , [ x0 , x1 , x2 ] , \n [ x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : <NUM_LIT:3> , : <NUM_LIT:2> ] , x1 [ : , : , : , : <NUM_LIT:2> ] , x2 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : <NUM_LIT:3> , : ] ] ) \n crop_test ( crop_c , [ x0 , x1 , x2 ] , \n [ x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , <NUM_LIT:1> : <NUM_LIT:4> , <NUM_LIT:2> : <NUM_LIT:4> ] , x1 [ : , : , : , <NUM_LIT:1> : <NUM_LIT:3> ] , x2 [ <NUM_LIT:2> : <NUM_LIT:3> , : <NUM_LIT:2> , : <NUM_LIT:3> , : ] ] ) \n crop_test ( crop_u , [ x0 , x1 , x2 ] , \n [ x0 [ <NUM_LIT:1> : , <NUM_LIT:1> : , <NUM_LIT:2> : , <NUM_LIT:5> : ] , x1 [ : , : , : , <NUM_LIT:2> : ] , x2 [ <NUM_LIT:5> : , <NUM_LIT:1> : , <NUM_LIT:1> : , : ] ] ) \n crop_test ( crop_x , [ x0 , x1 , x2 ] , \n [ x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x1 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x2 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] ] ) \n crop_test ( crop_x , [ x0 , x1 , x2 , x0 , x1 , x2 ] , \n [ x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x1 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x2 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , \n x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x1 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x2 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] ] ) \n with pytest . raises ( ValueError ) : \n crop_test ( crop_bad , [ x0 , x1 , x2 ] , \n [ x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x1 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x2 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] ] ) \n with pytest . raises ( ValueError ) : \n crop_test ( crop_bad , [ x0 [ : , : , : , <NUM_LIT:0> ] , x1 , x2 [ : , : , : , : , None ] ] , \n [ x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x1 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x2 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] ] ) \n class TestConcatLayer : \n @ pytest . fixture \n def layer ( self ) : \n from lasagne . layers . merge import ConcatLayer \n return ConcatLayer ( [ Mock ( ) , Mock ( ) ] , axis = <NUM_LIT:1> ) \n @ pytest . fixture \n def crop_layer_0 ( self ) : \n from lasagne . layers . merge import ConcatLayer \n return ConcatLayer ( [ Mock ( ) , Mock ( ) ] , axis = <NUM_LIT:0> , \n cropping = [ '<STR_LIT>' ] * <NUM_LIT:2> ) \n @ pytest . fixture \n def crop_layer_1 ( self ) : \n from lasagne . layers . merge import ConcatLayer \n return ConcatLayer ( [ Mock ( ) , Mock ( ) ] , axis = <NUM_LIT:1> , \n cropping = [ '<STR_LIT>' ] * <NUM_LIT:2> ) \n def test_get_output_shape_for ( self , layer ) : \n assert layer . get_output_shape_for ( [ ( <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:3> , <NUM_LIT:5> ) ] ) == ( <NUM_LIT:3> , <NUM_LIT:7> ) \n assert layer . get_output_shape_for ( [ ( <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:3> , None ) ] ) == ( <NUM_LIT:3> , None ) \n assert layer . get_output_shape_for ( [ ( None , <NUM_LIT:2> ) , ( <NUM_LIT:3> , <NUM_LIT:5> ) ] ) == ( <NUM_LIT:3> , <NUM_LIT:7> ) \n assert layer . get_output_shape_for ( [ ( None , <NUM_LIT:2> ) , ( None , <NUM_LIT:5> ) ] ) == ( None , <NUM_LIT:7> ) \n with pytest . raises ( ValueError ) : \n layer . get_output_shape_for ( [ ( <NUM_LIT:4> , None ) , ( <NUM_LIT:3> , <NUM_LIT:5> ) ] ) \n with pytest . raises ( ValueError ) : \n layer . get_output_shape_for ( [ ( <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:4> , None ) ] ) \n with pytest . raises ( ValueError ) : \n layer . get_output_shape_for ( [ ( None , <NUM_LIT:2> ) , ( <NUM_LIT:3> , <NUM_LIT:5> ) , ( <NUM_LIT:4> , <NUM_LIT:5> ) ] ) \n def test_get_output_shape_for_cropped ( self , crop_layer_0 , crop_layer_1 ) : \n input_shapes = [ ( <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:4> , <NUM_LIT:5> ) ] \n result_0 = crop_layer_0 . get_output_shape_for ( input_shapes ) \n result_1 = crop_layer_1 . get_output_shape_for ( input_shapes ) \n assert result_0 == ( <NUM_LIT:7> , <NUM_LIT:2> ) \n assert result_1 == ( <NUM_LIT:3> , <NUM_LIT:7> ) \n def test_get_output_for ( self , layer ) : \n inputs = [ theano . shared ( numpy . ones ( ( <NUM_LIT:3> , <NUM_LIT:3> ) ) ) , \n theano . shared ( numpy . ones ( ( <NUM_LIT:3> , <NUM_LIT:2> ) ) ) ] \n result = layer . get_output_for ( inputs ) \n result_eval = result . eval ( ) \n desired_result = numpy . hstack ( [ input . get_value ( ) for input in inputs ] ) \n assert ( result_eval == desired_result ) . all ( ) \n def test_get_output_for_cropped ( self , crop_layer_0 , crop_layer_1 ) : \n x0 = numpy . random . random ( ( <NUM_LIT:5> , <NUM_LIT:3> ) ) \n x1 = numpy . random . random ( ( <NUM_LIT:4> , <NUM_LIT:2> ) ) \n inputs = [ theano . shared ( x0 ) , \n theano . shared ( x1 ) ] \n result_0 = crop_layer_0 . get_output_for ( inputs ) . eval ( ) \n result_1 = crop_layer_1 . get_output_for ( inputs ) . eval ( ) \n desired_result_0 = numpy . concatenate ( [ x0 [ : , : <NUM_LIT:2> ] , x1 [ : , : <NUM_LIT:2> ] ] , axis = <NUM_LIT:0> ) \n desired_result_1 = numpy . concatenate ( [ x0 [ : <NUM_LIT:4> , : ] , x1 [ : <NUM_LIT:4> , : ] ] , axis = <NUM_LIT:1> ) \n assert ( result_0 == desired_result_0 ) . all ( ) \n assert ( result_1 == desired_result_1 ) . all ( ) \n class TestElemwiseSumLayer : \n @ pytest . fixture \n def layer ( self ) : \n from lasagne . layers . merge import ElemwiseSumLayer \n return ElemwiseSumLayer ( [ Mock ( ) , Mock ( ) ] , coeffs = [ <NUM_LIT:2> , - <NUM_LIT:1> ] ) \n @ pytest . fixture \n def crop_layer ( self ) : \n from lasagne . layers . merge import ElemwiseSumLayer \n return ElemwiseSumLayer ( [ Mock ( ) , Mock ( ) ] , coeffs = [ <NUM_LIT:2> , - <NUM_LIT:1> ] , \n cropping = [ '<STR_LIT>' ] * <NUM_LIT:2> ) \n def test_get_output_shape_for ( self , layer ) : \n assert layer . get_output_shape_for ( [ ( <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:3> , <NUM_LIT:2> ) ] ) == ( <NUM_LIT:3> , <NUM_LIT:2> ) \n assert layer . get_output_shape_for ( [ ( <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:3> , None ) ] ) == ( <NUM_LIT:3> , <NUM_LIT:2> ) \n assert layer . get_output_shape_for ( [ ( None , <NUM_LIT:2> ) , ( <NUM_LIT:3> , <NUM_LIT:2> ) ] ) == ( <NUM_LIT:3> , <NUM_LIT:2> ) \n assert layer . get_output_shape_for ( [ ( None , <NUM_LIT:2> ) , ( None , <NUM_LIT:2> ) ] ) == ( None , <NUM_LIT:2> ) \n with pytest . raises ( ValueError ) : \n layer . get_output_shape_for ( [ ( <NUM_LIT:3> , None ) , ( <NUM_LIT:4> , <NUM_LIT:2> ) ] ) \n with pytest . raises ( ValueError ) : \n layer . get_output_shape_for ( [ ( <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:4> , None ) ] ) \n with pytest . raises ( ValueError ) : \n layer . get_output_shape_for ( [ ( None , <NUM_LIT:2> ) , ( <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:4> , <NUM_LIT:2> ) ] ) \n def test_get_output_for ( self , layer ) : \n a = numpy . array ( [ [ <NUM_LIT:0> , <NUM_LIT:1> ] , [ <NUM_LIT:2> , <NUM_LIT:3> ] ] ) \n b = numpy . array ( [ [ <NUM_LIT:1> , <NUM_LIT:2> ] , [ <NUM_LIT:4> , <NUM_LIT:5> ] ] ) \n inputs = [ theano . shared ( a ) , \n theano . shared ( b ) ] \n result = layer . get_output_for ( inputs ) \n result_eval = result . eval ( ) \n desired_result = <NUM_LIT:2> * a - b \n assert ( result_eval == desired_result ) . all ( ) \n def test_get_output_for_cropped ( self , crop_layer ) : \n from numpy . testing import assert_array_almost_equal as aeq \n x0 = numpy . random . random ( ( <NUM_LIT:5> , <NUM_LIT:3> ) ) \n x1 = numpy . random . random ( ( <NUM_LIT:4> , <NUM_LIT:2> ) ) \n inputs = [ theano . shared ( x0 ) , \n theano . shared ( x1 ) ] \n result = crop_layer . get_output_for ( inputs ) . eval ( ) \n desired_result = <NUM_LIT:2> * x0 [ : <NUM_LIT:4> , : <NUM_LIT:2> ] - x1 [ : <NUM_LIT:4> , : <NUM_LIT:2> ] \n aeq ( result , desired_result ) \n def test_bad_coeffs_fails ( self , layer ) : \n from lasagne . layers . merge import ElemwiseSumLayer \n with pytest . raises ( ValueError ) : \n ElemwiseSumLayer ( [ Mock ( ) , Mock ( ) ] , coeffs = [ <NUM_LIT:2> , <NUM_LIT:3> , - <NUM_LIT:1> ] ) \n class TestElemwiseMergeLayerMul : \n @ pytest . fixture \n def layer ( self ) : \n import theano . tensor as T \n from lasagne . layers . merge import ElemwiseMergeLayer \n return ElemwiseMergeLayer ( [ Mock ( ) , Mock ( ) ] , merge_function = T . mul ) \n def test_get_output_for ( self , layer ) : \n a = numpy . array ( [ [ <NUM_LIT:0> , <NUM_LIT:1> ] , [ <NUM_LIT:2> , <NUM_LIT:3> ] ] ) \n b = numpy . array ( [ [ <NUM_LIT:1> , <NUM_LIT:2> ] , [ <NUM_LIT:4> , <NUM_LIT:5> ] ] ) \n inputs = [ theano . shared ( a ) , \n theano . shared ( b ) ] \n result = layer . get_output_for ( inputs ) \n result_eval = result . eval ( ) \n desired_result = a * b \n assert ( result_eval == desired_result ) . all ( ) \n class TestElemwiseMergeLayerMaximum : \n @ pytest . fixture \n def layer ( self ) : \n import theano . tensor as T \n from lasagne . layers . merge import ElemwiseMergeLayer \n return ElemwiseMergeLayer ( [ Mock ( ) , Mock ( ) ] , merge_function = T . maximum ) \n def test_get_output_for ( self , layer ) : \n a = numpy . array ( [ [ <NUM_LIT:0> , <NUM_LIT:1> ] , [ <NUM_LIT:2> , <NUM_LIT:3> ] ] ) \n b = numpy . array ( [ [ <NUM_LIT:1> , <NUM_LIT:2> ] , [ <NUM_LIT:4> , <NUM_LIT:5> ] ] ) \n inputs = [ theano . shared ( a ) , \n theano . shared ( b ) ] \n result = layer . get_output_for ( inputs ) \n result_eval = result . eval ( ) \n desired_result = numpy . maximum ( a , b ) \n assert ( result_eval == desired_result ) . all ( ) \n", "gt": "crop0"}
{"input": "\n from gevent import monkey ; monkey . patch_all ( ) \n import gevent \n from ws4py . client . geventclient import WebSocketClient \n if __name__ == '<STR_LIT:__main__>' : \n <mask0> = WebSocketClient ( '<STR_LIT>' , protocols = [ '<STR_LIT>' , '<STR_LIT>' ] ) \n ws . connect ( ) \n ws . send ( \"<STR_LIT>\" ) \n print ( ( ws . receive ( ) , ) ) \n ws . send ( \"<STR_LIT>\" ) \n print ( ( ws . receive ( ) , ) ) \n def incoming ( ) : \n while True : \n m = ws . receive ( ) \n if m is not None : \n m = str ( m ) \n print ( ( m , len ( m ) ) ) \n if len ( m ) == <NUM_LIT> : \n ws . close ( ) \n break \n else : \n break \n print ( ( \"<STR_LIT>\" , ) ) \n def outgoing ( ) : \n for i in range ( <NUM_LIT:0> , <NUM_LIT> , <NUM_LIT:5> ) : \n ws . send ( \"<STR_LIT:*>\" * i ) \n ws . send ( \"<STR_LIT>\" ) \n greenlets = [ \n gevent . spawn ( incoming ) , \n gevent . spawn ( outgoing ) , \n ] \n gevent . joinall ( greenlets ) \n", "gt": "ws"}
{"input": "\n import os \n import struct \n from ws4py . framing import Frame , OPCODE_CONTINUATION , OPCODE_TEXT , OPCODE_BINARY , OPCODE_CLOSE , OPCODE_PING , OPCODE_PONG \n from ws4py . compat import unicode , py3k \n <mask0> = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' ] \n class Message ( object ) : \n def __init__ ( self , opcode , data = b'<STR_LIT>' , encoding = '<STR_LIT:utf-8>' ) : \n \"\"\"<STR_LIT>\"\"\" \n self . opcode = opcode \n self . _completed = False \n self . encoding = encoding \n if isinstance ( data , unicode ) : \n if not encoding : \n raise TypeError ( \"<STR_LIT>\" ) \n data = data . encode ( encoding ) \n elif isinstance ( data , bytearray ) : \n data = bytes ( data ) \n elif not isinstance ( data , bytes ) : \n raise TypeError ( \"<STR_LIT>\" % type ( data ) ) \n self . data = data \n def single ( self , mask = False ) : \n \"\"\"<STR_LIT>\"\"\" \n mask = os . urandom ( <NUM_LIT:4> ) if mask else None \n return Frame ( body = self . data , opcode = self . opcode , \n masking_key = mask , fin = <NUM_LIT:1> ) . build ( ) \n def fragment ( self , first = False , last = False , mask = False ) : \n \"\"\"<STR_LIT>\"\"\" \n fin = <NUM_LIT:1> if last is True else <NUM_LIT:0> \n opcode = self . opcode if first is True else OPCODE_CONTINUATION \n mask = os . urandom ( <NUM_LIT:4> ) if mask else None \n return Frame ( body = self . data , \n opcode = opcode , masking_key = mask , \n fin = fin ) . build ( ) \n @ property \n def completed ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n return self . _completed \n @ completed . setter \n def completed ( self , state ) : \n \"\"\"<STR_LIT>\"\"\" \n self . _completed = state \n def extend ( self , data ) : \n \"\"\"<STR_LIT>\"\"\" \n if isinstance ( data , bytes ) : \n self . data += data \n elif isinstance ( data , bytearray ) : \n self . data += bytes ( data ) \n elif isinstance ( data , unicode ) : \n self . data += data . encode ( self . encoding ) \n else : \n raise TypeError ( \"<STR_LIT>\" % type ( data ) ) \n def __len__ ( self ) : \n return len ( self . __unicode__ ( ) ) \n def __str__ ( self ) : \n if py3k : \n return self . data . decode ( self . encoding ) \n return self . data \n def __unicode__ ( self ) : \n return self . data . decode ( self . encoding ) \n class TextMessage ( Message ) : \n def __init__ ( self , text = None ) : \n Message . __init__ ( self , OPCODE_TEXT , text ) \n @ property \n def is_binary ( self ) : \n return False \n @ property \n def is_text ( self ) : \n return True \n class BinaryMessage ( Message ) : \n def __init__ ( self , bytes = None ) : \n Message . __init__ ( self , OPCODE_BINARY , bytes , encoding = None ) \n @ property \n def is_binary ( self ) : \n return True \n @ property \n def is_text ( self ) : \n return False \n def __len__ ( self ) : \n return len ( self . data ) \n class CloseControlMessage ( Message ) : \n def __init__ ( self , code = <NUM_LIT:1000> , reason = '<STR_LIT>' ) : \n data = b\"<STR_LIT>\" \n if code : \n data += struct . pack ( \"<STR_LIT>\" , code ) \n if reason is not None : \n if isinstance ( reason , unicode ) : \n reason = reason . encode ( '<STR_LIT:utf-8>' ) \n data += reason \n Message . __init__ ( self , OPCODE_CLOSE , data , '<STR_LIT:utf-8>' ) \n self . code = code \n self . reason = reason \n def __str__ ( self ) : \n if py3k : \n return self . reason . decode ( '<STR_LIT:utf-8>' ) \n return self . reason \n def __unicode__ ( self ) : \n return self . reason . decode ( self . encoding ) \n class PingControlMessage ( Message ) : \n def __init__ ( self , data = None ) : \n Message . __init__ ( self , OPCODE_PING , data ) \n class PongControlMessage ( Message ) : \n def __init__ ( self , data ) : \n Message . __init__ ( self , OPCODE_PONG , data ) \n", "gt": "__all__"}
{"input": "\n import sys \n import base64 \n import time \n import urllib \n from struct import unpack \n from threading import Lock \n from binascii import hexlify \n from urlparse import urlparse \n from mod_python import apache \n from PyAuthenNTLM2 . ntlm_dc_proxy import NTLM_DC_Proxy \n from PyAuthenNTLM2 . ntlm_ad_proxy import NTLM_AD_Proxy \n <mask0> = True \n try : \n from PyAuthenNTLM2 . ntlm_client import NTLM_Client \n except ImportError : \n use_basic_auth = False \n class CacheConnections : \n def __init__ ( self ) : \n self . _mutex = Lock ( ) \n self . _cache = { } \n def __len__ ( self ) : \n return len ( self . _cache ) \n def remove ( self , id ) : \n self . _mutex . acquire ( ) \n ( proxy , ts ) = self . _cache . get ( id , ( None , None ) ) \n if proxy : \n proxy . close ( ) \n del self . _cache [ id ] \n self . _mutex . release ( ) \n def add ( self , id , proxy ) : \n self . _mutex . acquire ( ) \n self . _cache [ id ] = ( proxy , int ( time . time ( ) ) ) \n self . _mutex . release ( ) \n def clean ( self ) : \n now = int ( time . time ( ) ) \n self . _mutex . acquire ( ) \n for id , conn in self . _cache . items ( ) : \n if conn [ <NUM_LIT:1> ] + <NUM_LIT> < now : \n conn [ <NUM_LIT:0> ] . close ( ) \n del self . _cache [ id ] \n self . _mutex . release ( ) \n def has_key ( self , id ) : \n return self . _cache . has_key ( id ) \n def get_proxy ( self , id ) : \n self . _mutex . acquire ( ) \n proxy = self . _cache [ id ] [ <NUM_LIT:0> ] \n self . _mutex . release ( ) \n return proxy \n class CacheGroups : \n def __init__ ( self ) : \n self . _mutex = Lock ( ) \n self . _cache = { } \n def __len__ ( self ) : \n return len ( self . _cache ) \n def add ( self , group , user ) : \n self . _mutex . acquire ( ) \n if not self . _cache . has_key ( group ) : \n self . _cache [ group ] = { } \n self . _cache [ group ] [ user ] = int ( time . time ( ) ) \n self . _mutex . release ( ) \n def clean ( self ) : \n now = int ( time . time ( ) ) \n self . _mutex . acquire ( ) \n old = [ ] \n for group , members in self . _cache . items ( ) : \n for user in members : \n if members [ user ] + <NUM_LIT:3> * <NUM_LIT> * <NUM_LIT> < now : \n old . append ( ( group , user ) ) \n for group , user in old : \n del self . _cache [ group ] [ user ] \n self . _mutex . release ( ) \n def has ( self , group , user ) : \n if not self . _cache . has_key ( group ) : \n return False \n return self . _cache [ group ] . has_key ( user ) \n cache = CacheConnections ( ) \n cacheGroups = CacheGroups ( ) \n def ntlm_message_type ( msg ) : \n if not msg . startswith ( '<STR_LIT>' ) or len ( msg ) < <NUM_LIT:12> : \n raise RuntimeError ( \"<STR_LIT>\" % hexlify ( msg ) ) \n msg_type = unpack ( '<STR_LIT>' , msg [ <NUM_LIT:8> : <NUM_LIT:8> + <NUM_LIT:4> ] ) [ <NUM_LIT:0> ] \n if msg_type not in ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) : \n raise RuntimeError ( \"<STR_LIT>\" % msg_type ) \n return msg_type \n def parse_ntlm_authenticate ( msg ) : \n '''<STR_LIT>''' \n NTLMSSP_NEGOTIATE_UNICODE = <NUM_LIT> \n idx = <NUM_LIT> \n length , offset = unpack ( '<STR_LIT>' , msg [ idx : idx + <NUM_LIT:8> ] ) \n domain = msg [ offset : offset + length ] \n idx += <NUM_LIT:8> \n length , offset = unpack ( '<STR_LIT>' , msg [ idx : idx + <NUM_LIT:8> ] ) \n username = msg [ offset : offset + length ] \n idx += <NUM_LIT> \n flags = unpack ( '<STR_LIT>' , msg [ idx : idx + <NUM_LIT:4> ] ) [ <NUM_LIT:0> ] \n if flags & NTLMSSP_NEGOTIATE_UNICODE : \n domain = str ( domain . decode ( '<STR_LIT>' ) ) \n username = str ( username . decode ( '<STR_LIT>' ) ) \n return username , domain \n def set_remote_user ( req , username , domain ) : \n format = req . get_options ( ) . get ( '<STR_LIT>' , '<STR_LIT>' ) . lower ( ) \n if format == '<STR_LIT>' : \n req . user = domain + '<STR_LIT:\\\\>' + username \n else : \n req . user = username \n def decode_http_authorization_header ( auth ) : \n '''<STR_LIT>''' \n ah = auth . split ( '<STR_LIT:U+0020>' ) \n if len ( ah ) == <NUM_LIT:2> : \n b64 = base64 . b64decode ( ah [ <NUM_LIT:1> ] ) \n if ah [ <NUM_LIT:0> ] == '<STR_LIT>' : \n return ( '<STR_LIT>' , b64 ) \n elif ah [ <NUM_LIT:0> ] == '<STR_LIT>' and use_basic_auth : \n ( user , password ) = b64 . split ( '<STR_LIT::>' ) \n return ( '<STR_LIT>' , user , password ) \n return False \n def handle_unauthorized ( req ) : \n '''<STR_LIT>''' \n req . err_headers_out . add ( '<STR_LIT>' , '<STR_LIT>' ) \n if use_basic_auth : \n req . err_headers_out . add ( '<STR_LIT>' , '<STR_LIT>' % req . auth_name ( ) ) \n req . err_headers_out . add ( '<STR_LIT>' , '<STR_LIT>' ) \n return apache . HTTP_UNAUTHORIZED \n def connect_to_proxy ( req , type1 ) : \n '''<STR_LIT>''' \n try : \n domain = req . get_options ( ) [ '<STR_LIT>' ] \n pdc = req . get_options ( ) [ '<STR_LIT>' ] \n bdc = req . get_options ( ) . get ( '<STR_LIT>' , False ) \n except KeyError , e : \n req . log_error ( '<STR_LIT>' % str ( e ) , apache . APLOG_CRIT ) \n raise \n ntlm_challenge = None \n for server in ( pdc , bdc ) : \n if not server : continue \n try : \n if server . startswith ( '<STR_LIT>' ) : \n url = urlparse ( server ) \n decoded_path = urllib . unquote ( url . path ) [ <NUM_LIT:1> : ] \n req . log_error ( '<STR_LIT>' % \n ( url . netloc , domain , decoded_path ) , apache . APLOG_INFO ) \n proxy = NTLM_AD_Proxy ( url . netloc , domain , base = decoded_path ) \n else : \n req . log_error ( '<STR_LIT>' % \n ( server , domain ) , apache . APLOG_INFO ) \n proxy = NTLM_DC_Proxy ( server , domain ) \n ntlm_challenge = proxy . negotiate ( type1 ) \n except Exception , e : \n req . log_error ( '<STR_LIT>' % ( server , str ( e ) ) , apache . APLOG_CRIT ) \n if ntlm_challenge : break \n proxy . close ( ) \n else : \n raise RuntimeError ( \"<STR_LIT>\" ) \n return ( proxy , ntlm_challenge ) \n def handle_type1 ( req , ntlm_message ) : \n '''<STR_LIT>''' \n cache . remove ( req . connection . id ) \n cache . clean ( ) \n try : \n ( proxy , ntlm_challenge ) = connect_to_proxy ( req , ntlm_message ) \n except Exception , e : \n return apache . HTTP_INTERNAL_SERVER_ERROR \n cache . add ( req . connection . id , proxy ) \n req . err_headers_out . add ( '<STR_LIT>' , \"<STR_LIT>\" + base64 . b64encode ( ntlm_challenge ) ) \n return apache . HTTP_UNAUTHORIZED \n def check_authorization ( req , username , proxy ) : \n '''<STR_LIT>''' \n rules = '<STR_LIT>' . join ( req . requires ( ) ) . strip ( ) \n if rules == '<STR_LIT>' or cacheGroups . has ( rules , username ) : \n return True \n groups = [ ] \n for r in req . requires ( ) : \n if r . lower ( ) . startswith ( \"<STR_LIT>\" ) : \n users = [ u . strip ( ) for u in r [ <NUM_LIT:5> : ] . split ( \"<STR_LIT:U+002C>\" ) ] \n if username in users : \n req . log_error ( '<STR_LIT>' % \n ( username , req . unparsed_uri ) , apache . APLOG_INFO ) \n return True \n if r . lower ( ) . startswith ( \"<STR_LIT>\" ) : \n groups += [ g . strip ( ) for g in r [ <NUM_LIT:6> : ] . split ( \"<STR_LIT:U+002C>\" ) ] \n if groups : \n try : \n res = proxy . check_membership ( username , groups ) \n except Exception , e : \n req . log_error ( '<STR_LIT>' % ( username , str ( groups ) , req . unparsed_uri , str ( e ) ) ) \n if res : \n cacheGroups . add ( rules , username ) \n req . log_error ( '<STR_LIT>' % \n ( username , str ( groups ) , req . unparsed_uri ) , apache . APLOG_INFO ) \n return True \n req . log_error ( '<STR_LIT>' % \n ( username , str ( groups ) , req . unparsed_uri ) ) \n else : \n req . log_error ( '<STR_LIT>' % \n ( username , req . unparsed_uri ) ) \n return False \n def handle_type3 ( req , ntlm_message ) : \n '''<STR_LIT>''' \n proxy = cache . get_proxy ( req . connection . id ) \n try : \n user , domain = parse_ntlm_authenticate ( ntlm_message ) \n if not domain : \n domain = req . get_options ( ) . get ( '<STR_LIT>' , req . auth_name ( ) ) \n result = proxy . authenticate ( ntlm_message ) \n except Exception , e : \n req . log_error ( '<STR_LIT>' % str ( e ) , apache . APLOG_CRIT ) \n user , domain = '<STR_LIT>' , '<STR_LIT>' \n result = False \n if not result : \n cache . remove ( req . connection . id ) \n req . log_error ( '<STR_LIT>' % ( \n domain , user , req . unparsed_uri ) ) \n return handle_unauthorized ( req ) \n req . log_error ( '<STR_LIT>' % ( user , domain , req . unparsed_uri ) , apache . APLOG_NOTICE ) \n set_remote_user ( req , user , domain ) \n result = check_authorization ( req , user , proxy ) \n cache . remove ( req . connection . id ) \n if not result : \n return apache . HTTP_FORBIDDEN \n req . connection . notes . add ( '<STR_LIT>' , req . user ) \n return apache . OK \n def handle_basic ( req , user , password ) : \n '''<STR_LIT>''' \n req . log_error ( '<STR_LIT>' % ( req . unparsed_uri ) ) \n domain = req . get_options ( ) . get ( '<STR_LIT>' , req . auth_name ( ) ) \n client = NTLM_Client ( user , domain , password ) \n type1 = client . make_ntlm_negotiate ( ) \n try : \n ( proxy , type2 ) = connect_to_proxy ( req , type1 ) \n except Exception , e : \n return apache . HTTP_INTERNAL_SERVER_ERROR \n client . parse_ntlm_challenge ( type2 ) \n type3 = client . make_ntlm_authenticate ( ) \n if not proxy . authenticate ( type3 ) : \n proxy . close ( ) \n req . log_error ( '<STR_LIT>' % ( \n user , domain , req . unparsed_uri ) ) \n return handle_unauthorized ( req ) \n req . log_error ( '<STR_LIT>' % ( user , domain , req . unparsed_uri ) , apache . APLOG_NOTICE ) \n set_remote_user ( req , user , domain ) \n result = check_authorization ( req , user , proxy ) \n proxy . close ( ) \n if not result : \n return apache . HTTP_FORBIDDEN \n req . connection . notes . add ( '<STR_LIT>' , user + password ) \n return apache . OK \n def authenhandler ( req ) : \n '''<STR_LIT>''' \n req . log_error ( \"<STR_LIT>\" % ( \n req . connection . id , req . method , req . unparsed_uri , len ( cache ) ) , apache . APLOG_INFO ) \n auth_headers = req . headers_in . get ( '<STR_LIT>' , [ ] ) \n if not isinstance ( auth_headers , list ) : \n auth_headers = [ auth_headers ] \n user = req . connection . notes . get ( '<STR_LIT>' , None ) \n if user : \n req . user = user \n if auth_headers : \n req . log_error ( '<STR_LIT>' % ( \n req . connection . id , req . method , req . clength , auth_headers ) , apache . APLOG_INFO ) \n if req . method != '<STR_LIT:POST>' or req . clength > <NUM_LIT:0> : \n return apache . OK \n else : \n return apache . OK \n if not auth_headers : \n return handle_unauthorized ( req ) \n try : \n for ah in auth_headers : \n ah_data = decode_http_authorization_header ( ah ) \n if ah_data : \n break \n except : \n ah_data = False \n if not ah_data : \n req . log_error ( '<STR_LIT>' % req . unparsed_uri , apache . APLOG_ERR ) \n return apache . HTTP_BAD_REQUEST \n if ah_data [ <NUM_LIT:0> ] == '<STR_LIT>' : \n userpwd = req . connection . notes . get ( '<STR_LIT>' , None ) \n if userpwd : \n if userpwd != ah_data [ <NUM_LIT:1> ] + ah_data [ <NUM_LIT:2> ] : \n return handle_unauthorized ( req ) \n domain = req . get_options ( ) . get ( '<STR_LIT>' , req . auth_name ( ) ) \n set_remote_user ( req , ah_data [ <NUM_LIT:1> ] , domain ) \n return apache . OK \n return handle_basic ( req , ah_data [ <NUM_LIT:1> ] , ah_data [ <NUM_LIT:2> ] ) \n try : \n ntlm_version = ntlm_message_type ( ah_data [ <NUM_LIT:1> ] ) \n if ntlm_version == <NUM_LIT:1> : \n return handle_type1 ( req , ah_data [ <NUM_LIT:1> ] ) \n if ntlm_version == <NUM_LIT:3> : \n if cache . has_key ( req . connection . id ) : \n return handle_type3 ( req , ah_data [ <NUM_LIT:1> ] ) \n req . log_error ( '<STR_LIT>' % \n ( req . unparsed_uri ) , apache . APLOG_INFO ) \n return handle_unauthorized ( req ) \n error = '<STR_LIT>' \n except Exception , e : \n error = str ( e ) \n req . log_error ( '<STR_LIT>' % \n ( req . unparsed_uri , error ) , apache . APLOG_ERR ) \n return apache . HTTP_BAD_REQUEST \n", "gt": "use_basic_auth"}
{"input": "\n from celery import Celery \n def create_celery_app ( app ) : \n if app . config . get ( '<STR_LIT>' ) : \n app . celery = Celery ( __name__ , broker = app . config [ '<STR_LIT>' ] ) \n app . celery . conf . update ( app . config ) \n <mask0> = app . celery . Task \n class ContextTask ( taskbase ) : \n abstract = True \n def __call__ ( self , * args , ** kwargs ) : \n with app . app_context ( ) : \n return taskbase . __call__ ( self , * args , ** kwargs ) \n app . celery . Task = ContextTask \n", "gt": "taskbase"}
{"input": "\n import unittest \n import os \n import sys \n import json \n sys . path . append ( os . path . dirname ( os . path . realpath ( __file__ ) . rsplit ( '<STR_LIT:/>' , <NUM_LIT:2> ) [ <NUM_LIT:0> ] ) ) \n from app import create_app \n <mask0> = create_app ( '<STR_LIT>' ) \n add_data = \"\"\"<STR_LIT>\"\"\" \n update_data = \"\"\"<STR_LIT>\"\"\" \n class TestUsers ( unittest . TestCase ) : \n def setUp ( self ) : \n self . app = app . test_client ( ) \n def test_01_add ( self ) : \n rv = self . app . post ( '<STR_LIT>' , data = add_data , \n content_type = \"<STR_LIT:application/json>\" ) \n assert rv . status_code == <NUM_LIT> \n def test_02_read_update ( self ) : \n request = self . app . get ( '<STR_LIT>' ) \n dict = json . loads ( request . data . decode ( '<STR_LIT:utf-8>' ) ) \n id = dict [ '<STR_LIT:data>' ] [ <NUM_LIT:0> ] [ '<STR_LIT:id>' ] \n rv = self . app . patch ( '<STR_LIT>' . format ( id ) , \n data = update_data , content_type = \"<STR_LIT:application/json>\" ) \n assert rv . status_code == <NUM_LIT:200> \n def test_03_delete ( self ) : \n request = self . app . get ( '<STR_LIT>' ) \n dict = json . loads ( request . data . decode ( '<STR_LIT:utf-8>' ) ) \n id = dict [ '<STR_LIT:data>' ] [ <NUM_LIT:0> ] [ '<STR_LIT:id>' ] \n rv = self . app . delete ( '<STR_LIT>' . format ( id ) ) \n assert rv . status_code == <NUM_LIT> \n if __name__ == '<STR_LIT:__main__>' : \n unittest . main ( ) \n", "gt": "app"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n def tokenProgressFunc ( state = \"<STR_LIT>\" , action = None , text = None , tick = <NUM_LIT:0> ) : \n \"\"\"<STR_LIT>\"\"\" \n print ( \"<STR_LIT>\" % ( state , str ( title ) , str ( text ) , str ( tick ) ) ) \n def build ( \n documentPath , \n outputUFOFormatVersion = <NUM_LIT:2> , \n roundGeometry = True , \n verbose = True , \n logPath = None , \n progressFunc = None , \n ) : \n \"\"\"<STR_LIT>\"\"\" \n from mutatorMath . ufo . document import DesignSpaceDocumentReader \n import os , glob \n if os . path . isdir ( documentPath ) : \n <mask0> = glob . glob ( os . path . join ( documentPath , \"<STR_LIT>\" ) ) \n else : \n todo = [ documentPath ] \n results = [ ] \n for path in todo : \n reader = DesignSpaceDocumentReader ( \n path , \n ufoVersion = outputUFOFormatVersion , \n roundGeometry = roundGeometry , \n verbose = verbose , \n logPath = logPath , \n progressFunc = progressFunc \n ) \n reader . process ( ) \n results . append ( reader . results ) \n reader = None \n return results \n", "gt": "todo"}
{"input": "\n import os \n from django . conf import settings \n from django . http import HttpResponse \n class HttpResponseServiceUnavailable ( HttpResponse ) : \n <mask0> = <NUM_LIT> \n class TooBusyMiddleware ( object ) : \n def process_request ( self , request ) : \n one , five , fifteen = os . getloadavg ( ) \n if one > settings . TOO_BUSY_LOAD_AVERAGE : \n return HttpResponseServiceUnavailable ( \"\"\"<STR_LIT>\"\"\" ) \n return None \n", "gt": "status_code"}
{"input": "\n from os . path import dirname , join \n from django . test import TestCase \n from chronam . core . ocr_extractor import ocr_extractor \n class OcrExtractorTests ( TestCase ) : \n def test_extractor ( self ) : \n <mask0> = join ( dirname ( dirname ( __file__ ) ) , '<STR_LIT>' ) \n ocr_file = join ( dir , '<STR_LIT>' ) \n text , coord_info = ocr_extractor ( ocr_file ) \n coords = coord_info [ \"<STR_LIT>\" ] \n expected_text = { \"<STR_LIT>\" : file ( join ( dir , '<STR_LIT>' ) ) . read ( ) . decode ( '<STR_LIT:utf-8>' ) } \n self . assertEqual ( text , expected_text ) \n self . assertEqual ( len ( coords . keys ( ) ) , <NUM_LIT> ) \n self . assertEqual ( len ( coords [ '<STR_LIT>' ] ) , <NUM_LIT:3> ) \n self . assertTrue ( coords . has_key ( '<STR_LIT>' ) ) \n self . assertTrue ( not coords . has_key ( '<STR_LIT>' ) ) \n", "gt": "dir"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import logging \n from . tests import * \n <mask0> = logging . getLogger ( \"<STR_LIT>\" ) \n logger . setLevel ( logging . DEBUG ) \n handler = logging . StreamHandler ( ) \n formatter = logging . Formatter ( \"<STR_LIT>\" ) \n handler . setFormatter ( formatter ) \n logger . addHandler ( handler ) \n", "gt": "logger"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n from __future__ import print_function \n import argparse \n import datetime \n import json \n import multiprocessing \n import os \n import random \n import sys \n import threading \n import time \n import numpy as np \n from PIL import Image \n import six \n import six . moves . cPickle as pickle \n from six . moves import queue \n import chainer \n from chainer import computational_graph \n from chainer import cuda \n from chainer import optimizers \n from chainer import serializers \n <mask0> = argparse . ArgumentParser ( \n description = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT:train>' , help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , default = '<STR_LIT>' , \n help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , default = '<STR_LIT>' , \n help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , type = int , default = <NUM_LIT:32> , \n help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , type = int , default = <NUM_LIT> , \n help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , default = <NUM_LIT:10> , type = int , \n help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , default = - <NUM_LIT:1> , type = int , \n help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , default = <NUM_LIT:20> , type = int , \n help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , default = '<STR_LIT:.>' , \n help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , default = '<STR_LIT>' , \n help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , default = '<STR_LIT:state>' , \n help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , default = '<STR_LIT>' , \n help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , default = '<STR_LIT>' , \n help = '<STR_LIT>' ) \n args = parser . parse_args ( ) \n if args . gpu >= <NUM_LIT:0> : \n cuda . check_cuda_available ( ) \n xp = cuda . cupy if args . gpu >= <NUM_LIT:0> else np \n assert <NUM_LIT> % args . val_batchsize == <NUM_LIT:0> \n def load_image_list ( path , root ) : \n tuples = [ ] \n for line in open ( path ) : \n pair = line . strip ( ) . split ( ) \n tuples . append ( ( os . path . join ( root , pair [ <NUM_LIT:0> ] ) , np . int32 ( pair [ <NUM_LIT:1> ] ) ) ) \n return tuples \n train_list = load_image_list ( args . train , args . root ) \n val_list = load_image_list ( args . val , args . root ) \n mean_image = pickle . load ( open ( args . mean , '<STR_LIT:rb>' ) ) \n if args . arch == '<STR_LIT>' : \n import nin \n model = nin . NIN ( ) \n elif args . arch == '<STR_LIT>' : \n import alex \n model = alex . Alex ( ) \n elif args . arch == '<STR_LIT>' : \n import alexbn \n model = alexbn . AlexBN ( ) \n elif args . arch == '<STR_LIT>' : \n import googlenet \n model = googlenet . GoogLeNet ( ) \n elif args . arch == '<STR_LIT>' : \n import googlenetbn \n model = googlenetbn . GoogLeNetBN ( ) \n else : \n raise ValueError ( '<STR_LIT>' ) \n if args . gpu >= <NUM_LIT:0> : \n cuda . get_device ( args . gpu ) . use ( ) \n model . to_gpu ( ) \n optimizer = optimizers . MomentumSGD ( lr = <NUM_LIT> , momentum = <NUM_LIT> ) \n optimizer . setup ( model ) \n if args . initmodel : \n print ( '<STR_LIT>' , args . initmodel ) \n serializers . load_hdf5 ( args . initmodel , model ) \n if args . resume : \n print ( '<STR_LIT>' , args . resume ) \n serializers . load_hdf5 ( args . resume , optimizer ) \n data_q = queue . Queue ( maxsize = <NUM_LIT:1> ) \n res_q = queue . Queue ( ) \n cropwidth = <NUM_LIT> - model . insize \n def read_image ( path , center = False , flip = False ) : \n image = np . asarray ( Image . open ( path ) ) . transpose ( <NUM_LIT:2> , <NUM_LIT:0> , <NUM_LIT:1> ) \n if center : \n top = left = cropwidth / <NUM_LIT:2> \n else : \n top = random . randint ( <NUM_LIT:0> , cropwidth - <NUM_LIT:1> ) \n left = random . randint ( <NUM_LIT:0> , cropwidth - <NUM_LIT:1> ) \n bottom = model . insize + top \n right = model . insize + left \n image = image [ : , top : bottom , left : right ] . astype ( np . float32 ) \n image -= mean_image [ : , top : bottom , left : right ] \n image /= <NUM_LIT:255> \n if flip and random . randint ( <NUM_LIT:0> , <NUM_LIT:1> ) == <NUM_LIT:0> : \n return image [ : , : , : : - <NUM_LIT:1> ] \n else : \n return image \n def feed_data ( ) : \n i = <NUM_LIT:0> \n count = <NUM_LIT:0> \n x_batch = np . ndarray ( \n ( args . batchsize , <NUM_LIT:3> , model . insize , model . insize ) , dtype = np . float32 ) \n y_batch = np . ndarray ( ( args . batchsize , ) , dtype = np . int32 ) \n val_x_batch = np . ndarray ( \n ( args . val_batchsize , <NUM_LIT:3> , model . insize , model . insize ) , dtype = np . float32 ) \n val_y_batch = np . ndarray ( ( args . val_batchsize , ) , dtype = np . int32 ) \n batch_pool = [ None ] * args . batchsize \n val_batch_pool = [ None ] * args . val_batchsize \n pool = multiprocessing . Pool ( args . loaderjob ) \n data_q . put ( '<STR_LIT:train>' ) \n for epoch in six . moves . range ( <NUM_LIT:1> , <NUM_LIT:1> + args . epoch ) : \n print ( '<STR_LIT>' , epoch , file = sys . stderr ) \n print ( '<STR_LIT>' , optimizer . lr , file = sys . stderr ) \n perm = np . random . permutation ( len ( train_list ) ) \n for idx in perm : \n path , label = train_list [ idx ] \n batch_pool [ i ] = pool . apply_async ( read_image , ( path , False , True ) ) \n y_batch [ i ] = label \n i += <NUM_LIT:1> \n if i == args . batchsize : \n for j , x in enumerate ( batch_pool ) : \n x_batch [ j ] = x . get ( ) \n data_q . put ( ( x_batch . copy ( ) , y_batch . copy ( ) ) ) \n i = <NUM_LIT:0> \n count += <NUM_LIT:1> \n if count % <NUM_LIT:1000> == <NUM_LIT:0> : \n data_q . put ( '<STR_LIT>' ) \n j = <NUM_LIT:0> \n for path , label in val_list : \n val_batch_pool [ j ] = pool . apply_async ( \n read_image , ( path , True , False ) ) \n val_y_batch [ j ] = label \n j += <NUM_LIT:1> \n if j == args . val_batchsize : \n for k , x in enumerate ( val_batch_pool ) : \n val_x_batch [ k ] = x . get ( ) \n data_q . put ( ( val_x_batch . copy ( ) , val_y_batch . copy ( ) ) ) \n j = <NUM_LIT:0> \n data_q . put ( '<STR_LIT:train>' ) \n optimizer . lr *= <NUM_LIT> \n pool . close ( ) \n pool . join ( ) \n data_q . put ( '<STR_LIT:end>' ) \n def log_result ( ) : \n train_count = <NUM_LIT:0> \n train_cur_loss = <NUM_LIT:0> \n train_cur_accuracy = <NUM_LIT:0> \n begin_at = time . time ( ) \n val_begin_at = None \n while True : \n result = res_q . get ( ) \n if result == '<STR_LIT:end>' : \n print ( file = sys . stderr ) \n break \n elif result == '<STR_LIT:train>' : \n print ( file = sys . stderr ) \n train = True \n if val_begin_at is not None : \n begin_at += time . time ( ) - val_begin_at \n val_begin_at = None \n continue \n elif result == '<STR_LIT>' : \n print ( file = sys . stderr ) \n train = False \n val_count = val_loss = val_accuracy = <NUM_LIT:0> \n val_begin_at = time . time ( ) \n continue \n loss , accuracy = result \n if train : \n train_count += <NUM_LIT:1> \n duration = time . time ( ) - begin_at \n throughput = train_count * args . batchsize / duration \n sys . stderr . write ( \n '<STR_LIT>' \n . format ( train_count , train_count * args . batchsize , \n datetime . timedelta ( seconds = duration ) , throughput ) ) \n train_cur_loss += loss \n train_cur_accuracy += accuracy \n if train_count % <NUM_LIT:1000> == <NUM_LIT:0> : \n mean_loss = train_cur_loss / <NUM_LIT:1000> \n mean_error = <NUM_LIT:1> - train_cur_accuracy / <NUM_LIT:1000> \n print ( file = sys . stderr ) \n print ( json . dumps ( { '<STR_LIT:type>' : '<STR_LIT:train>' , '<STR_LIT>' : train_count , \n '<STR_LIT:error>' : mean_error , '<STR_LIT>' : mean_loss } ) ) \n sys . stdout . flush ( ) \n train_cur_loss = <NUM_LIT:0> \n train_cur_accuracy = <NUM_LIT:0> \n else : \n val_count += args . val_batchsize \n duration = time . time ( ) - val_begin_at \n throughput = val_count / duration \n sys . stderr . write ( \n '<STR_LIT>' \n . format ( val_count / args . val_batchsize , val_count , \n datetime . timedelta ( seconds = duration ) , throughput ) ) \n val_loss += loss \n val_accuracy += accuracy \n if val_count == <NUM_LIT> : \n mean_loss = val_loss * args . val_batchsize / <NUM_LIT> \n mean_error = <NUM_LIT:1> - val_accuracy * args . val_batchsize / <NUM_LIT> \n print ( file = sys . stderr ) \n print ( json . dumps ( { '<STR_LIT:type>' : '<STR_LIT>' , '<STR_LIT>' : train_count , \n '<STR_LIT:error>' : mean_error , '<STR_LIT>' : mean_loss } ) ) \n sys . stdout . flush ( ) \n def train_loop ( ) : \n graph_generated = False \n while True : \n while data_q . empty ( ) : \n time . sleep ( <NUM_LIT:0.1> ) \n inp = data_q . get ( ) \n if inp == '<STR_LIT:end>' : \n res_q . put ( '<STR_LIT:end>' ) \n break \n elif inp == '<STR_LIT:train>' : \n res_q . put ( '<STR_LIT:train>' ) \n model . train = True \n continue \n elif inp == '<STR_LIT>' : \n res_q . put ( '<STR_LIT>' ) \n serializers . save_hdf5 ( args . out , model ) \n serializers . save_hdf5 ( args . outstate , optimizer ) \n model . train = False \n continue \n volatile = '<STR_LIT>' if model . train else '<STR_LIT>' \n x = chainer . Variable ( xp . asarray ( inp [ <NUM_LIT:0> ] ) , volatile = volatile ) \n t = chainer . Variable ( xp . asarray ( inp [ <NUM_LIT:1> ] ) , volatile = volatile ) \n if model . train : \n optimizer . update ( model , x , t ) \n if not graph_generated : \n with open ( '<STR_LIT>' , '<STR_LIT:w>' ) as o : \n o . write ( computational_graph . build_computational_graph ( \n ( model . loss , ) ) . dump ( ) ) \n print ( '<STR_LIT>' , file = sys . stderr ) \n graph_generated = True \n else : \n model ( x , t ) \n res_q . put ( ( float ( model . loss . data ) , float ( model . accuracy . data ) ) ) \n del x , t \n feeder = threading . Thread ( target = feed_data ) \n feeder . daemon = True \n feeder . start ( ) \n logger = threading . Thread ( target = log_result ) \n logger . daemon = True \n logger . start ( ) \n train_loop ( ) \n feeder . join ( ) \n logger . join ( ) \n serializers . save_hdf5 ( args . out , model ) \n serializers . save_hdf5 ( args . outstate , optimizer ) \n", "gt": "parser"}
{"input": "\n import sys , os \n sys . path . insert ( <NUM_LIT:0> , os . path . abspath ( '<STR_LIT:..>' ) ) \n import local_settings \n <mask0> = [ '<STR_LIT>' , '<STR_LIT>' ] \n templates_path = [ '<STR_LIT>' ] \n source_suffix = '<STR_LIT>' \n master_doc = '<STR_LIT:index>' \n project = u'<STR_LIT>' \n copyright = u'<STR_LIT>' \n html_show_copyright = False \n import djoauth2 \n version = djoauth2 . __version__ \n release = djoauth2 . __version__ \n exclude_patterns = [ '<STR_LIT>' ] \n pygments_style = '<STR_LIT>' \n html_theme = '<STR_LIT:default>' \n html_static_path = [ '<STR_LIT>' ] \n htmlhelp_basename = '<STR_LIT>' \n latex_elements = { \n } \n latex_documents = [ \n ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , \n u'<STR_LIT>' , '<STR_LIT>' ) , \n ] \n man_pages = [ \n ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , \n [ u'<STR_LIT>' ] , <NUM_LIT:1> ) \n ] \n texinfo_documents = [ \n ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , \n u'<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' ) , \n ] \n epub_title = u'<STR_LIT>' \n epub_author = u'<STR_LIT>' \n epub_publisher = u'<STR_LIT>' \n epub_copyright = u'<STR_LIT>' \n", "gt": "extensions"}
{"input": "\n import asyncio \n from zeroservices import ZeroMQMedium , ResourceService \n from zeroservices . services import get_http_interface \n from zeroservices . discovery import UdpDiscoveryMedium \n if __name__ == '<STR_LIT:__main__>' : \n <mask0> = asyncio . get_event_loop ( ) \n medium = ZeroMQMedium ( loop , UdpDiscoveryMedium ) \n service = ResourceService ( '<STR_LIT>' , medium ) \n application = get_http_interface ( service , loop , port = <NUM_LIT> , allowed_origins = \"<STR_LIT:*>\" ) \n application = loop . run_until_complete ( application ) \n loop . run_until_complete ( service . start ( ) ) \n loop . run_forever ( ) \n", "gt": "loop"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import argparse \n import sys \n from trello import TrelloClient \n from slugify import slugify \n from matterllo . utils import config \n from matterllo . utils import logger \n <mask0> = config ( ) \n LOGGING = logger ( ) \n def main ( ) : \n try : \n parser = argparse . ArgumentParser ( description = \"<STR_LIT>\" ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , action = '<STR_LIT:store_true>' , help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , action = '<STR_LIT:store_true>' , help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , action = '<STR_LIT:store_true>' , help = '<STR_LIT>' ) \n args = parser . parse_args ( ) \n if not args . cleanup and not args . update and not args . init : \n print parser . print_help ( ) \n sys . exit ( <NUM_LIT:0> ) \n client = TrelloClient ( api_key = SETTINGS [ '<STR_LIT>' ] , token = SETTINGS [ '<STR_LIT>' ] ) \n trello_boards = client . list_boards ( ) \n boards_name = [ slugify ( b [ '<STR_LIT:name>' ] ) for b in SETTINGS . get ( '<STR_LIT>' , { } ) . values ( ) ] \n if args . cleanup or args . init : \n result = [ h . delete ( ) for h in client . list_hooks ( ) ] \n LOGGING . info ( '<STR_LIT>' . format ( len ( result ) ) ) \n if args . update or args . init : \n for board in trello_boards : \n board_name = slugify ( board . name ) \n if board_name not in boards_name : \n continue \n LOGGING . info ( '<STR_LIT>' . format ( board_name ) ) \n url = SETTINGS [ '<STR_LIT>' ] + '<STR_LIT>' \n result = client . create_hook ( url , board . id ) \n LOGGING . info ( '<STR_LIT>' . format ( board_name , result ) ) \n except Exception as e : \n LOGGING . error ( '<STR_LIT>' . format ( e ) ) \n sys . exit ( <NUM_LIT:1> ) \n if __name__ == '<STR_LIT:__main__>' : \n main ( ) \n", "gt": "SETTINGS"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n from contextlib import contextmanager \n import sys \n import zlib \n try : \n from . import ssl_compat \n except <mask0> : \n ssl_compat = None \n _ver = sys . version_info \n is_py2 = _ver [ <NUM_LIT:0> ] == <NUM_LIT:2> \n is_py2_7_9_or_later = _ver [ <NUM_LIT:0> ] >= <NUM_LIT:2> and _ver [ <NUM_LIT:1> ] >= <NUM_LIT:7> and _ver [ <NUM_LIT:2> ] >= <NUM_LIT:9> \n is_py3 = _ver [ <NUM_LIT:0> ] == <NUM_LIT:3> \n is_py3_3 = is_py3 and _ver [ <NUM_LIT:1> ] == <NUM_LIT:3> \n @ contextmanager \n def ignore_missing ( ) : \n try : \n yield \n except ( AttributeError , NotImplementedError ) : \n pass \n if is_py2 : \n if is_py2_7_9_or_later : \n import ssl \n else : \n ssl = ssl_compat \n from urllib import urlencode \n from urlparse import urlparse , urlsplit \n from itertools import imap \n def to_byte ( char ) : \n return ord ( char ) \n def decode_hex ( b ) : \n return b . decode ( '<STR_LIT>' ) \n def write_to_stdout ( data ) : \n sys . stdout . write ( data + '<STR_LIT:\\n>' ) \n sys . stdout . flush ( ) \n def zlib_compressobj ( level = <NUM_LIT:6> , method = zlib . DEFLATED , wbits = <NUM_LIT:15> , memlevel = <NUM_LIT:8> , \n strategy = zlib . Z_DEFAULT_STRATEGY ) : \n return zlib . compressobj ( level , method , wbits , memlevel , strategy ) \n unicode = unicode \n bytes = str \n elif is_py3 : \n from urllib . parse import urlencode , urlparse , urlsplit \n imap = map \n def to_byte ( char ) : \n return char \n def decode_hex ( b ) : \n return bytes . fromhex ( b ) \n def write_to_stdout ( data ) : \n sys . stdout . buffer . write ( data + b'<STR_LIT:\\n>' ) \n sys . stdout . buffer . flush ( ) \n zlib_compressobj = zlib . compressobj \n if is_py3_3 : \n ssl = ssl_compat \n else : \n import ssl \n unicode = str \n bytes = bytes \n", "gt": "ImportError"}
{"input": "\n \"\"\"<STR_LIT>\"\"\" \n import threading \n import socket \n import sys \n from hyper import HTTP20Connection \n from hyper . compat import ssl \n from hyper . http11 . connection import HTTP11Connection \n from hpack . hpack import Encoder \n from hpack . huffman import HuffmanEncoder \n from hpack . huffman_constants import ( \n REQUEST_CODES , REQUEST_CODES_LENGTH \n ) \n from hyper . tls import NPN_PROTOCOL \n class SocketServerThread ( threading . Thread ) : \n \"\"\"<STR_LIT>\"\"\" \n def __init__ ( self , \n socket_handler , \n host = '<STR_LIT:localhost>' , \n ready_event = None , \n h2 = True , \n secure = True ) : \n threading . Thread . __init__ ( self ) \n self . socket_handler = socket_handler \n self . host = host \n self . secure = secure \n self . ready_event = ready_event \n self . daemon = True \n if self . secure : \n self . cxt = ssl . SSLContext ( ssl . PROTOCOL_SSLv23 ) \n if ssl . HAS_NPN and h2 : \n self . cxt . set_npn_protocols ( [ NPN_PROTOCOL ] ) \n self . cxt . load_cert_chain ( certfile = '<STR_LIT>' , \n keyfile = '<STR_LIT>' ) \n def _start_server ( self ) : \n <mask0> = socket . socket ( ) \n if sys . platform != '<STR_LIT:win32>' : \n sock . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEADDR , <NUM_LIT:1> ) \n if self . secure : \n sock = self . cxt . wrap_socket ( sock , server_side = True ) \n sock . bind ( ( self . host , <NUM_LIT:0> ) ) \n self . port = sock . getsockname ( ) [ <NUM_LIT:1> ] \n sock . listen ( <NUM_LIT:1> ) \n if self . ready_event : \n self . ready_event . set ( ) \n self . socket_handler ( sock ) \n sock . close ( ) \n def _wrap_socket ( self , sock ) : \n raise NotImplementedError ( ) \n def run ( self ) : \n self . server = self . _start_server ( ) \n class SocketLevelTest ( object ) : \n \"\"\"<STR_LIT>\"\"\" \n def set_up ( self , secure = True , proxy = False ) : \n self . host = None \n self . port = None \n self . secure = secure if not proxy else False \n self . proxy = proxy \n self . server_thread = None \n def _start_server ( self , socket_handler ) : \n \"\"\"<STR_LIT>\"\"\" \n ready_event = threading . Event ( ) \n self . server_thread = SocketServerThread ( \n socket_handler = socket_handler , \n ready_event = ready_event , \n h2 = self . h2 , \n secure = self . secure \n ) \n self . server_thread . start ( ) \n ready_event . wait ( ) \n self . host = self . server_thread . host \n self . port = self . server_thread . port \n self . secure = self . server_thread . secure \n def get_connection ( self ) : \n if self . h2 : \n if not self . proxy : \n return HTTP20Connection ( self . host , self . port , self . secure ) \n else : \n return HTTP20Connection ( '<STR_LIT>' , secure = self . secure , \n proxy_host = self . host , \n proxy_port = self . port ) \n else : \n if not self . proxy : \n return HTTP11Connection ( self . host , self . port , self . secure ) \n else : \n return HTTP11Connection ( '<STR_LIT>' , secure = self . secure , \n proxy_host = self . host , \n proxy_port = self . port ) \n def get_encoder ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n e = Encoder ( ) \n e . huffman_coder = HuffmanEncoder ( REQUEST_CODES , REQUEST_CODES_LENGTH ) \n return e \n def tear_down ( self ) : \n \"\"\"<STR_LIT>\"\"\" \n self . server_thread . join ( <NUM_LIT:0.1> ) \n", "gt": "sock"}
{"input": "\n import numpy as np \n import lxmls . readers . pos_corpus as pcc \n from os import path \n import pickle \n <mask0> = pcc . PostagCorpus ( ) \n input_data = path . join ( \n path . dirname ( __file__ ) , \n \"<STR_LIT>\" ) \n train_seq = corpus . read_sequence_list_conll ( input_data , max_sent_len = <NUM_LIT:15> , max_nr_sent = <NUM_LIT:1000> ) \n pickle . dump ( ( corpus . word_dict , corpus . tag_dict ) , open ( '<STR_LIT>' , '<STR_LIT:w>' ) ) \n with open ( '<STR_LIT>' , '<STR_LIT:w>' ) as output : \n for seq in train_seq : \n words = [ corpus . word_dict . get_label_name ( seq . x [ i ] ) for i in xrange ( len ( seq ) ) ] \n tags = [ corpus . tag_dict . get_label_name ( seq . y [ i ] ) for i in xrange ( len ( seq ) ) ] \n s = '<STR_LIT:U+0020>' . join ( [ '<STR_LIT:_>' . join ( [ word , tag ] ) for word , tag in zip ( words , tags ) ] ) \n output . write ( s + '<STR_LIT:\\n>' ) \n", "gt": "corpus"}
{"input": "\n import sys \n import numpy as np \n from lxmls . parsing . dependency_reader import * \n from lxmls . parsing . dependency_writer import * \n from lxmls . parsing . dependency_features import * \n from lxmls . parsing . dependency_decoder import * \n from lxmls . util . my_math_utils import * \n class DependencyParser ( ) : \n '''<STR_LIT>''' \n def __init__ ( self ) : \n self . trained = False \n self . projective = False \n self . language = \"<STR_LIT>\" \n self . weights = [ ] \n self . decoder = DependencyDecoder ( ) \n self . reader = DependencyReader ( ) \n self . writer = DependencyWriter ( ) \n self . features = DependencyFeatures ( ) \n def read_data ( self , language ) : \n self . language = language \n self . reader . load ( language ) \n self . features . create_dictionary ( self . reader . train_instances ) \n def train_perceptron ( self , n_epochs ) : \n '''<STR_LIT>''' \n self . weights = np . zeros ( self . features . n_feats ) \n <mask0> = np . zeros ( self . features . n_feats ) \n for epoch in range ( n_epochs ) : \n print \"<STR_LIT>\" . format ( epoch + <NUM_LIT:1> ) \n n_mistakes = <NUM_LIT:0> \n n_tokens = <NUM_LIT:0> \n n_instances = <NUM_LIT:0> \n for instance in self . reader . train_instances : \n feats = self . features . create_features ( instance ) \n scores = self . features . compute_scores ( feats , self . weights ) \n if self . projective : \n heads_pred = self . decoder . parse_proj ( scores ) \n else : \n heads_pred = self . decoder . parse_nonproj ( scores ) \n for m in range ( np . size ( heads_pred ) ) : \n if heads_pred [ m ] != instance . heads [ m ] : \n for f in feats [ instance . heads [ m ] ] [ m ] : \n if f < <NUM_LIT:0> : \n continue \n self . weights [ f ] += <NUM_LIT:1.0> \n for f in feats [ heads_pred [ m ] ] [ m ] : \n if f < <NUM_LIT:0> : \n continue \n self . weights [ f ] -= <NUM_LIT:1.0> \n n_mistakes += <NUM_LIT:1> \n n_tokens += <NUM_LIT:1> \n n_instances += <NUM_LIT:1> \n print \"<STR_LIT>\" . format ( np . double ( n_tokens - n_mistakes ) / np . double ( n_tokens ) ) \n total += self . weights \n self . weights = total / np . double ( n_epochs ) \n def train_crf_sgd ( self , n_epochs , sigma , eta0 = <NUM_LIT> ) : \n '''<STR_LIT>''' \n self . weights = np . zeros ( self . features . n_feats ) \n t = <NUM_LIT:0> \n t0 = <NUM_LIT:1.0> / ( sigma * eta0 ) \n for epoch in range ( n_epochs ) : \n print \"<STR_LIT>\" . format ( epoch + <NUM_LIT:1> ) \n n_mistakes = <NUM_LIT:0> \n n_tokens = <NUM_LIT:0> \n n_instances = <NUM_LIT:0> \n objective = <NUM_LIT:0.0> \n for instance in self . reader . train_instances : \n eta = <NUM_LIT:1.0> / ( sigma * ( t + t0 ) ) \n feats = self . features . create_features ( instance ) \n scores = self . features . compute_scores ( feats , self . weights ) \n marginals , logZ = self . decoder . parse_marginals_nonproj ( scores ) \n self . weights -= eta * sigma * self . weights \n for h in range ( np . size ( marginals , <NUM_LIT:0> ) ) : \n for m in range ( <NUM_LIT:1> , np . size ( marginals , <NUM_LIT:1> ) ) : \n if feats [ h ] [ m ] == None : \n continue \n for f in feats [ h ] [ m ] : \n if f < <NUM_LIT:0> : \n continue \n self . weights [ f ] -= eta * marginals [ h , m ] \n score_corr = <NUM_LIT:0.0> \n for m in range ( <NUM_LIT:1> , np . size ( instance . heads ) ) : \n h = instance . heads [ m ] \n score_corr += scores [ h , m ] \n for f in feats [ h ] [ m ] : \n if f < <NUM_LIT:0> : \n continue \n self . weights [ f ] += eta \n objective += <NUM_LIT:0.5> * sigma * np . dot ( self . weights , self . weights ) - score_corr + logZ \n n_instances += <NUM_LIT:1> \n t += <NUM_LIT:1> \n print \"<STR_LIT>\" . format ( objective / n_instances ) \n def test ( self ) : \n n_mistakes = <NUM_LIT:0> \n n_tokens = <NUM_LIT:0> \n n_instances = <NUM_LIT:0> \n arr_heads_pred = [ ] ; \n for instance in self . reader . test_instances : \n feats = self . features . create_features ( instance ) \n scores = self . features . compute_scores ( feats , self . weights ) \n if self . projective : \n heads_pred = self . decoder . parse_proj ( scores ) \n else : \n heads_pred = self . decoder . parse_nonproj ( scores ) \n for m in range ( np . size ( heads_pred ) ) : \n if heads_pred [ m ] != instance . heads [ m ] : \n for f in feats [ instance . heads [ m ] ] [ m ] : \n if f < <NUM_LIT:0> : \n continue \n for f in feats [ heads_pred [ m ] ] [ m ] : \n if f < <NUM_LIT:0> : \n continue \n n_mistakes += <NUM_LIT:1> \n n_tokens += <NUM_LIT:1> \n n_instances += <NUM_LIT:1> \n arr_heads_pred . append ( heads_pred ) \n print \"<STR_LIT>\" . format ( n_instances , np . double ( n_tokens - n_mistakes ) / np . double ( n_tokens ) ) \n self . writer . save ( self . language , arr_heads_pred ) \n", "gt": "total"}
{"input": "\n from lxmls . sequences . label_dictionary import * \n import pdb \n class IDFeatures : \n '''<STR_LIT>''' \n def __init__ ( self , dataset ) : \n '''<STR_LIT>''' \n self . feature_dict = LabelDictionary ( ) \n self . feature_list = [ ] \n self . add_features = False \n self . dataset = dataset \n self . node_feature_cache = { } \n self . initial_state_feature_cache = { } \n self . final_state_feature_cache = { } \n self . edge_feature_cache = { } \n def get_num_features ( self ) : \n return len ( self . feature_dict ) \n def build_features ( self ) : \n '''<STR_LIT>''' \n self . add_features = True \n for sequence in self . dataset . seq_list : \n initial_features , transition_features , final_features , emission_features = self . get_sequence_features ( sequence ) \n self . feature_list . append ( [ initial_features , transition_features , final_features , emission_features ] ) \n self . add_features = False \n def get_sequence_features ( self , sequence ) : \n '''<STR_LIT>''' \n <mask0> = [ ] \n initial_features = [ ] \n transition_features = [ ] \n final_features = [ ] \n features = [ ] \n features = self . add_initial_features ( sequence , sequence . y [ <NUM_LIT:0> ] , features ) \n initial_features . append ( features ) \n for pos , tag in enumerate ( sequence . y ) : \n features = [ ] \n features = self . add_emission_features ( sequence , pos , sequence . y [ pos ] , features ) \n emission_features . append ( features ) \n if pos > <NUM_LIT:0> : \n prev_tag = sequence . y [ pos - <NUM_LIT:1> ] \n features = [ ] \n features = self . add_transition_features ( sequence , pos - <NUM_LIT:1> , tag , prev_tag , features ) \n transition_features . append ( features ) \n features = [ ] \n features = self . add_final_features ( sequence , sequence . y [ - <NUM_LIT:1> ] , features ) \n final_features . append ( features ) \n return initial_features , transition_features , final_features , emission_features \n def get_emission_features ( self , sequence , pos , y ) : \n all_feat = [ ] \n x = sequence . x [ pos ] \n if ( x not in self . node_feature_cache ) : \n self . node_feature_cache [ x ] = { } \n if ( y not in self . node_feature_cache [ x ] ) : \n node_idx = [ ] \n node_idx = self . add_emission_features ( sequence , pos , y , node_idx ) \n self . node_feature_cache [ x ] [ y ] = node_idx \n idx = self . node_feature_cache [ x ] [ y ] \n all_feat = idx [ : ] \n return all_feat \n def get_transition_features ( self , sequence , pos , y , y_prev ) : \n assert ( pos >= <NUM_LIT:0> and pos < len ( sequence . x ) ) , pdb . set_trace ( ) \n if ( y not in self . edge_feature_cache ) : \n self . edge_feature_cache [ y ] = { } \n if ( y_prev not in self . edge_feature_cache [ y ] ) : \n edge_idx = [ ] \n edge_idx = self . add_transition_features ( sequence , pos , y , y_prev , edge_idx ) \n self . edge_feature_cache [ y ] [ y_prev ] = edge_idx \n return self . edge_feature_cache [ y ] [ y_prev ] \n def get_initial_features ( self , sequence , y ) : \n if ( y not in self . initial_state_feature_cache ) : \n edge_idx = [ ] \n edge_idx = self . add_initial_features ( sequence , y , edge_idx ) \n self . initial_state_feature_cache [ y ] = edge_idx \n return self . initial_state_feature_cache [ y ] \n def get_final_features ( self , sequence , y_prev ) : \n if ( y_prev not in self . final_state_feature_cache ) : \n edge_idx = [ ] \n edge_idx = self . add_final_features ( sequence , y_prev , edge_idx ) \n self . final_state_feature_cache [ y_prev ] = edge_idx \n return self . final_state_feature_cache [ y_prev ] \n def add_initial_features ( self , sequence , y , features ) : \n y_name = self . dataset . y_dict . get_label_name ( y ) \n feat_name = \"<STR_LIT>\" % ( y_name ) \n feat_id = self . add_feature ( feat_name ) \n if ( feat_id != - <NUM_LIT:1> ) : \n features . append ( feat_id ) \n return features \n def add_final_features ( self , sequence , y_prev , features ) : \n y_name = self . dataset . y_dict . get_label_name ( y_prev ) \n feat_name = \"<STR_LIT>\" % ( y_name ) \n feat_id = self . add_feature ( feat_name ) \n if ( feat_id != - <NUM_LIT:1> ) : \n features . append ( feat_id ) \n return features \n def add_emission_features ( self , sequence , pos , y , features ) : \n '''<STR_LIT>''' \n x = sequence . x [ pos ] \n y_name = self . dataset . y_dict . get_label_name ( y ) \n x_name = self . dataset . x_dict . get_label_name ( x ) \n feat_name = \"<STR_LIT>\" % ( x_name , y_name ) \n feat_id = self . add_feature ( feat_name ) \n if feat_id != - <NUM_LIT:1> : \n features . append ( feat_id ) \n return features \n def add_transition_features ( self , sequence , pos , y , y_prev , features ) : \n \"\"\"<STR_LIT>\"\"\" \n assert pos < len ( sequence . x ) - <NUM_LIT:1> , pdb . set_trace ( ) \n y_name = self . dataset . y_dict . get_label_name ( y ) \n y_prev_name = self . dataset . y_dict . get_label_name ( y_prev ) \n feat_name = \"<STR_LIT>\" % ( y_prev_name , y_name ) \n feat_id = self . add_feature ( feat_name ) \n if ( feat_id != - <NUM_LIT:1> ) : \n features . append ( feat_id ) \n return features \n def add_feature ( self , feat_name ) : \n \"\"\"<STR_LIT>\"\"\" \n if ( feat_name in self . feature_dict ) : \n return self . feature_dict [ feat_name ] \n if not self . add_features : \n return - <NUM_LIT:1> \n return self . feature_dict . add ( feat_name ) \n", "gt": "emission_features"}
{"input": "\n '''<STR_LIT>''' \n import os \n try : \n import ogr \n except ImportError : \n from osgeo import ogr \n <mask0> = \"<STR_LIT>\" \n line_datasource = ogr . Open ( line_shp_file ) \n driver = ogr . GetDriverByName ( '<STR_LIT>' ) \n point_shp_file = '<STR_LIT>' \n layer_name = '<STR_LIT>' \n if os . path . exists ( point_shp_file ) : \n driver . DeleteDataSource ( point_shp_file ) \n point_datasource = driver . CreateDataSource ( point_shp_file ) \n layer_count = line_datasource . GetLayerCount ( ) \n for each_layer in range ( layer_count ) : \n layer = line_datasource . GetLayerByIndex ( each_layer ) \n srs = layer . GetSpatialRef ( ) \n point_shp_layer = point_datasource . CreateLayer ( layer_name , srs , ogr . wkbPoint ) \n feature_count = layer . GetFeatureCount ( ) \n for each_feature in range ( feature_count ) : \n line_feature = layer . GetFeature ( each_feature ) \n feature_geom = line_feature . GetGeometryRef ( ) \n if feature_geom . GetGeometryName ( ) != '<STR_LIT>' : \n points = feature_geom . GetPoints ( ) \n for point in points : \n point_geom = ogr . Geometry ( ogr . wkbPoint ) \n point_geom . AddPoint ( point [ <NUM_LIT:0> ] , point [ <NUM_LIT:1> ] ) \n point_feature = ogr . Feature ( point_shp_layer . GetLayerDefn ( ) ) \n point_feature . SetGeometry ( point_geom ) \n point_shp_layer . CreateFeature ( point_feature ) \n", "gt": "line_shp_file"}
{"input": "\n '''<STR_LIT>''' \n try : \n import ogr \n except ImportError : \n from osgeo import ogr \n <mask0> = [ <NUM_LIT:50> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] \n longitudes = [ <NUM_LIT:100> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] \n elevation = <NUM_LIT:0> \n points = ogr . Geometry ( ogr . wkbMultiPoint ) \n point_1 = ogr . Geometry ( ogr . wkbPoint ) \n point_1 . AddPoint ( longitudes [ <NUM_LIT:0> ] , latitudes [ <NUM_LIT:0> ] , elevation ) \n points . AddGeometry ( point_1 ) \n point_2 = ogr . Geometry ( ogr . wkbPoint ) \n point_2 . AddPoint ( longitudes [ <NUM_LIT:1> ] , latitudes [ <NUM_LIT:1> ] , elevation ) \n points . AddGeometry ( point_2 ) \n point_3 = ogr . Geometry ( ogr . wkbPoint ) \n point_3 . AddPoint ( longitudes [ <NUM_LIT:2> ] , latitudes [ <NUM_LIT:2> ] , elevation ) \n points . AddGeometry ( point_3 ) \n point_4 = ogr . Geometry ( ogr . wkbPoint ) \n point_4 . AddPoint ( longitudes [ <NUM_LIT:3> ] , latitudes [ <NUM_LIT:3> ] , elevation ) \n points . AddGeometry ( point_4 ) \n point_5 = ogr . Geometry ( ogr . wkbPoint ) \n point_5 . AddPoint ( longitudes [ <NUM_LIT:4> ] , latitudes [ <NUM_LIT:4> ] , elevation ) \n points . AddGeometry ( point_5 ) \n points . ExportToWkt ( ) \n print points \n", "gt": "latitudes"}
