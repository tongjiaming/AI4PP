<s> from django . utils . translation import ugettext_lazy as _ <EOL> from horizon import tabs <EOL> class NetworkProfileTab ( tabs . Tab ) : <EOL> name = _ ( "<STR_LIT>" ) <EOL> slug = "<STR_LIT>" <EOL> template_name = '<STR_LIT>' <EOL> def get_context_data ( self , request ) : <EOL> return None <EOL> class PolicyProfileTab ( tabs . Tab ) : <EOL> name = _ ( "<STR_LIT>" ) <EOL> slug = "<STR_LIT>" <EOL> template_name = '<STR_LIT>' <EOL> preload = False <EOL> class IndexTabs ( tabs . TabGroup ) : <EOL> slug = "<STR_LIT>" <EOL> tabs = ( NetworkProfileTab , PolicyProfileTab ) </s>
<s> """<STR_LIT>""" <EOL> import weakref <EOL> from eventlet import corolocal <EOL> class WeakLocal ( corolocal . local ) : <EOL> def __getattribute__ ( self , attr ) : <EOL> rval = corolocal . local . __getattribute__ ( self , attr ) <EOL> if rval : <EOL> rval = rval ( ) <EOL> return rval <EOL> def __setattr__ ( self , attr , value ) : <EOL> value = weakref . ref ( value ) <EOL> return corolocal . local . __setattr__ ( self , attr , value ) <EOL> store = WeakLocal ( ) <EOL> weak_store = WeakLocal ( ) <EOL> strong_store = corolocal . local </s>
<s> import eventlet <EOL> eventlet . monkey_patch ( ) <EOL> import contextlib <EOL> import sys <EOL> from oslo . config import cfg <EOL> from openstack_dashboard . openstack . common import log as logging <EOL> from openstack_dashboard . openstack . common import rpc <EOL> from openstack_dashboard . openstack . common . rpc import impl_zmq <EOL> CONF = cfg . CONF <EOL> CONF . register_opts ( rpc . rpc_opts ) <EOL> CONF . register_opts ( impl_zmq . zmq_opts ) <EOL> def main ( ) : <EOL> CONF ( sys . argv [ <NUM_LIT:1> : ] , project = '<STR_LIT>' ) <EOL> logging . setup ( "<STR_LIT>" ) <EOL> with contextlib . closing ( impl_zmq . ZmqProxy ( CONF ) ) as reactor : <EOL> reactor . consume_in_thread ( ) <EOL> reactor . wait ( ) </s>
<s> from openstack_dashboard import api <EOL> from openstack_dashboard . test import helpers as test <EOL> from neutronclient . v2_0 import client <EOL> neutronclient = client . Client <EOL> class VPNaasApiTests ( test . APITestCase ) : <EOL> @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) <EOL> def test_vpnservice_create ( self ) : <EOL> vpnservice1 = self . api_vpnservices . first ( ) <EOL> form_data = { <EOL> '<STR_LIT:name>' : vpnservice1 [ '<STR_LIT:name>' ] , <EOL> '<STR_LIT:description>' : vpnservice1 [ '<STR_LIT:description>' ] , <EOL> '<STR_LIT>' : vpnservice1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : vpnservice1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : vpnservice1 [ '<STR_LIT>' ] <EOL> } <EOL> vpnservice = { '<STR_LIT>' : self . api_vpnservices . first ( ) } <EOL> neutronclient . create_vpnservice ( <EOL> { '<STR_LIT>' : form_data } ) . AndReturn ( vpnservice ) <EOL> self . mox . ReplayAll ( ) <EOL> ret_val = api . vpn . vpnservice_create ( self . request , ** form_data ) <EOL> self . assertIsInstance ( ret_val , api . vpn . VPNService ) <EOL> @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) <EOL> def test_vpnservices_get ( self ) : <EOL> vpnservices = { '<STR_LIT>' : self . vpnservices . list ( ) } <EOL> vpnservices_dict = { '<STR_LIT>' : self . api_vpnservices . list ( ) } <EOL> neutronclient . list_vpnservices ( ) . AndReturn ( vpnservices_dict ) <EOL> self . mox . ReplayAll ( ) <EOL> ret_val = api . vpn . vpnservices_get ( self . request ) <EOL> for ( v , d ) in zip ( ret_val , vpnservices [ '<STR_LIT>' ] ) : <EOL> self . assertIsInstance ( v , api . vpn . VPNService ) <EOL> self . assertTrue ( v . name , d . name ) <EOL> self . assertTrue ( v . id ) <EOL> @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) <EOL> def test_vpnservice_get ( self ) : <EOL> vpnservice1 = self . api_vpnservices . first ( ) <EOL> vpnservice = { '<STR_LIT>' : vpnservice1 } <EOL> neutronclient . show_vpnservice ( <EOL> vpnservice [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) . AndReturn ( vpnservice ) <EOL> self . mox . ReplayAll ( ) <EOL> ret_val = api . vpn . vpnservice_get ( self . request , <EOL> vpnservice [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) <EOL> self . assertIsInstance ( ret_val , api . vpn . VPNService ) <EOL> @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) <EOL> def test_ikepolicy_create ( self ) : <EOL> ikepolicy1 = self . api_ikepolicies . first ( ) <EOL> form_data = { <EOL> '<STR_LIT:name>' : ikepolicy1 [ '<STR_LIT:name>' ] , <EOL> '<STR_LIT:description>' : ikepolicy1 [ '<STR_LIT:description>' ] , <EOL> '<STR_LIT>' : ikepolicy1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ikepolicy1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ikepolicy1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ikepolicy1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ikepolicy1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ikepolicy1 [ '<STR_LIT>' ] <EOL> } <EOL> ikepolicy = { '<STR_LIT>' : self . api_ikepolicies . first ( ) } <EOL> neutronclient . create_ikepolicy ( <EOL> { '<STR_LIT>' : form_data } ) . AndReturn ( ikepolicy ) <EOL> self . mox . ReplayAll ( ) <EOL> ret_val = api . vpn . ikepolicy_create ( self . request , ** form_data ) <EOL> self . assertIsInstance ( ret_val , api . vpn . IKEPolicy ) <EOL> @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) <EOL> def test_ikepolicies_get ( self ) : <EOL> ikepolicies = { '<STR_LIT>' : self . ikepolicies . list ( ) } <EOL> ikepolicies_dict = { '<STR_LIT>' : self . api_ikepolicies . list ( ) } <EOL> neutronclient . list_ikepolicies ( ) . AndReturn ( ikepolicies_dict ) <EOL> self . mox . ReplayAll ( ) <EOL> ret_val = api . vpn . ikepolicies_get ( self . request ) <EOL> for ( v , d ) in zip ( ret_val , ikepolicies [ '<STR_LIT>' ] ) : <EOL> self . assertIsInstance ( v , api . vpn . IKEPolicy ) <EOL> self . assertTrue ( v . name , d . name ) <EOL> self . assertTrue ( v . id ) <EOL> @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) <EOL> def test_ikepolicy_get ( self ) : <EOL> ikepolicy1 = self . api_ikepolicies . first ( ) <EOL> ikepolicy = { '<STR_LIT>' : ikepolicy1 } <EOL> neutronclient . show_ikepolicy ( <EOL> ikepolicy [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) . AndReturn ( ikepolicy ) <EOL> self . mox . ReplayAll ( ) <EOL> ret_val = api . vpn . ikepolicy_get ( self . request , <EOL> ikepolicy [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) <EOL> self . assertIsInstance ( ret_val , api . vpn . IKEPolicy ) <EOL> @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) <EOL> def test_ipsecpolicy_create ( self ) : <EOL> ipsecpolicy1 = self . api_ipsecpolicies . first ( ) <EOL> form_data = { <EOL> '<STR_LIT:name>' : ipsecpolicy1 [ '<STR_LIT:name>' ] , <EOL> '<STR_LIT:description>' : ipsecpolicy1 [ '<STR_LIT:description>' ] , <EOL> '<STR_LIT>' : ipsecpolicy1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ipsecpolicy1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ipsecpolicy1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ipsecpolicy1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ipsecpolicy1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ipsecpolicy1 [ '<STR_LIT>' ] <EOL> } <EOL> ipsecpolicy = { '<STR_LIT>' : self . api_ipsecpolicies . first ( ) } <EOL> neutronclient . create_ipsecpolicy ( <EOL> { '<STR_LIT>' : form_data } ) . AndReturn ( ipsecpolicy ) <EOL> self . mox . ReplayAll ( ) <EOL> ret_val = api . vpn . ipsecpolicy_create ( self . request , ** form_data ) <EOL> self . assertIsInstance ( ret_val , api . vpn . IPSecPolicy ) <EOL> @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) <EOL> def test_ipsecpolicies_get ( self ) : <EOL> ipsecpolicies = { '<STR_LIT>' : self . ipsecpolicies . list ( ) } <EOL> ipsecpolicies_dict = { '<STR_LIT>' : self . api_ipsecpolicies . list ( ) } <EOL> neutronclient . list_ipsecpolicies ( ) . AndReturn ( ipsecpolicies_dict ) <EOL> self . mox . ReplayAll ( ) <EOL> ret_val = api . vpn . ipsecpolicies_get ( self . request ) <EOL> for ( v , d ) in zip ( ret_val , ipsecpolicies [ '<STR_LIT>' ] ) : <EOL> self . assertIsInstance ( v , api . vpn . IPSecPolicy ) <EOL> self . assertTrue ( v . name , d . name ) <EOL> self . assertTrue ( v . id ) <EOL> @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) <EOL> def test_ipsecpolicy_get ( self ) : <EOL> ipsecpolicy1 = self . api_ipsecpolicies . first ( ) <EOL> ipsecpolicy = { '<STR_LIT>' : ipsecpolicy1 } <EOL> neutronclient . show_ipsecpolicy ( <EOL> ipsecpolicy [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) . AndReturn ( ipsecpolicy ) <EOL> self . mox . ReplayAll ( ) <EOL> ret_val = api . vpn . ipsecpolicy_get ( self . request , <EOL> ipsecpolicy [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) <EOL> self . assertIsInstance ( ret_val , api . vpn . IPSecPolicy ) <EOL> @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) <EOL> def test_ipsecsiteconnection_create ( self ) : <EOL> ipsecsiteconnection1 = self . api_ipsecsiteconnections . first ( ) <EOL> form_data = { <EOL> '<STR_LIT:name>' : ipsecsiteconnection1 [ '<STR_LIT:name>' ] , <EOL> '<STR_LIT:description>' : ipsecsiteconnection1 [ '<STR_LIT:description>' ] , <EOL> '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : ipsecsiteconnection1 [ '<STR_LIT>' ] <EOL> } <EOL> ipsecsiteconnection = { '<STR_LIT>' : <EOL> self . api_ipsecsiteconnections . first ( ) } <EOL> neutronclient . create_ipsec_site_connection ( <EOL> { '<STR_LIT>' : <EOL> form_data } ) . AndReturn ( ipsecsiteconnection ) <EOL> self . mox . ReplayAll ( ) <EOL> ret_val = api . vpn . ipsecsiteconnection_create ( <EOL> self . request , ** form_data ) <EOL> self . assertIsInstance ( ret_val , api . vpn . IPSecSiteConnection ) <EOL> @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) <EOL> def test_ipsecsiteconnections_get ( self ) : <EOL> ipsecsiteconnections = { <EOL> '<STR_LIT>' : self . ipsecsiteconnections . list ( ) } <EOL> ipsecsiteconnections_dict = { <EOL> '<STR_LIT>' : self . api_ipsecsiteconnections . list ( ) } <EOL> neutronclient . list_ipsec_site_connections ( ) . AndReturn ( <EOL> ipsecsiteconnections_dict ) <EOL> self . mox . ReplayAll ( ) <EOL> ret_val = api . vpn . ipsecsiteconnections_get ( self . request ) <EOL> for ( v , d ) in zip ( ret_val , <EOL> ipsecsiteconnections [ '<STR_LIT>' ] ) : <EOL> self . assertIsInstance ( v , api . vpn . IPSecSiteConnection ) <EOL> self . assertTrue ( v . name , d . name ) <EOL> self . assertTrue ( v . id ) <EOL> @ test . create_stubs ( { neutronclient : ( '<STR_LIT>' , ) } ) <EOL> def test_ipsecsiteconnection_get ( self ) : <EOL> ipsecsiteconnection1 = self . api_ipsecsiteconnections . first ( ) <EOL> ipsecsiteconnection = { '<STR_LIT>' : ipsecsiteconnection1 } <EOL> neutronclient . show_ipsec_site_connection ( <EOL> ipsecsiteconnection [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) . AndReturn ( <EOL> ipsecsiteconnection ) <EOL> self . mox . ReplayAll ( ) <EOL> ret_val = api . vpn . ipsecsiteconnection_get ( self . request , <EOL> ipsecsiteconnection [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) <EOL> self . assertIsInstance ( ret_val , api . vpn . IPSecSiteConnection ) </s>
<s> from horizon import tables <EOL> from openstack_dashboard . usage import base <EOL> class UsageView ( tables . DataTableView ) : <EOL> usage_class = None <EOL> show_terminated = True <EOL> def __init__ ( self , * args , ** kwargs ) : <EOL> super ( UsageView , self ) . __init__ ( * args , ** kwargs ) <EOL> if not issubclass ( self . usage_class , base . BaseUsage ) : <EOL> raise AttributeError ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> def get_template_names ( self ) : <EOL> if self . request . GET . get ( '<STR_LIT>' , '<STR_LIT:html>' ) == '<STR_LIT>' : <EOL> return "<STR_LIT:.>" . join ( ( self . template_name . rsplit ( '<STR_LIT:.>' , <NUM_LIT:1> ) [ <NUM_LIT:0> ] , '<STR_LIT>' ) ) <EOL> return self . template_name <EOL> def get_content_type ( self ) : <EOL> if self . request . GET . get ( '<STR_LIT>' , '<STR_LIT:html>' ) == '<STR_LIT>' : <EOL> return "<STR_LIT>" <EOL> return "<STR_LIT>" <EOL> def get_data ( self ) : <EOL> project_id = self . kwargs . get ( '<STR_LIT>' , self . request . user . tenant_id ) <EOL> self . usage = self . usage_class ( self . request , project_id ) <EOL> self . usage . summarize ( * self . usage . get_date_range ( ) ) <EOL> self . usage . get_limits ( ) <EOL> self . kwargs [ '<STR_LIT>' ] = self . usage <EOL> return self . usage . usage_list <EOL> def get_context_data ( self , ** kwargs ) : <EOL> context = super ( UsageView , self ) . get_context_data ( ** kwargs ) <EOL> context [ '<STR_LIT>' ] . kwargs [ '<STR_LIT>' ] = self . usage <EOL> context [ '<STR_LIT>' ] = self . usage . form <EOL> context [ '<STR_LIT>' ] = self . usage <EOL> return context <EOL> def render_to_response ( self , context , ** response_kwargs ) : <EOL> if self . request . GET . get ( '<STR_LIT>' , '<STR_LIT:html>' ) == '<STR_LIT>' : <EOL> render_class = self . csv_response_class <EOL> response_kwargs . setdefault ( "<STR_LIT:filename>" , "<STR_LIT>" ) <EOL> else : <EOL> render_class = self . response_class <EOL> resp = render_class ( request = self . request , <EOL> template = self . get_template_names ( ) , <EOL> context = context , <EOL> content_type = self . get_content_type ( ) , <EOL> ** response_kwargs ) <EOL> return resp </s>
<s> from enum import IntEnum <EOL> from . component import Component <EOL> from . object import field <EOL> class ReflectionProbeUsage ( IntEnum ) : <EOL> Off = <NUM_LIT:0> <EOL> BlendProbes = <NUM_LIT:1> <EOL> BlendProbesAndSkybox = <NUM_LIT:2> <EOL> Simple = <NUM_LIT:3> <EOL> class ShadowCastingMode ( IntEnum ) : <EOL> Off = <NUM_LIT:0> <EOL> On = <NUM_LIT:1> <EOL> TwoSided = <NUM_LIT:2> <EOL> ShadowsOnly = <NUM_LIT:3> <EOL> class Renderer ( Component ) : <EOL> enabled = field ( "<STR_LIT>" , bool ) <EOL> lightmap_index = field ( "<STR_LIT>" ) <EOL> materials = field ( "<STR_LIT>" ) <EOL> probe_anchor = field ( "<STR_LIT>" ) <EOL> receive_shadows = field ( "<STR_LIT>" , bool ) <EOL> reflection_probe_usage = field ( "<STR_LIT>" , ReflectionProbeUsage ) <EOL> shadow_casting_mode = field ( "<STR_LIT>" , ShadowCastingMode ) <EOL> sorting_layer_id = field ( "<STR_LIT>" ) <EOL> sorting_order = field ( "<STR_LIT>" ) <EOL> use_light_probes = field ( "<STR_LIT>" , bool ) <EOL> lightmap_index_dynamic = field ( "<STR_LIT>" ) <EOL> lightmap_tiling_offset = field ( "<STR_LIT>" ) <EOL> lightmap_tiling_offset_dynamic = field ( "<STR_LIT>" ) <EOL> static_batch_root = field ( "<STR_LIT>" ) <EOL> subset_indices = field ( "<STR_LIT>" ) <EOL> @ property <EOL> def material ( self ) : <EOL> return self . materials [ <NUM_LIT:0> ] <EOL> class ParticleSystemRenderMode ( IntEnum ) : <EOL> Billboard = <NUM_LIT:0> <EOL> Stretch = <NUM_LIT:1> <EOL> HorizontalBillboard = <NUM_LIT:2> <EOL> VerticalBillboard = <NUM_LIT:3> <EOL> Mesh = <NUM_LIT:4> <EOL> class ParticleSystemSortMode ( IntEnum ) : <EOL> None_ = <NUM_LIT:0> <EOL> Distance = <NUM_LIT:1> <EOL> OldestInFront = <NUM_LIT:2> <EOL> YoungestInFront = <NUM_LIT:3> <EOL> class MeshRenderer ( Component ) : <EOL> pass <EOL> class ParticleRenderer ( Renderer ) : <EOL> camera_velocity_scale = field ( "<STR_LIT>" ) <EOL> length_scale = field ( "<STR_LIT>" ) <EOL> max_particle_size = field ( "<STR_LIT>" ) <EOL> velocity_scale = field ( "<STR_LIT>" ) <EOL> stretch_particles = field ( "<STR_LIT>" ) <EOL> uv_animation = field ( "<STR_LIT>" ) <EOL> class ParticleSystemRenderer ( Renderer ) : <EOL> camera_velocity_scale = field ( "<STR_LIT>" ) <EOL> length_scale = field ( "<STR_LIT>" ) <EOL> max_particle_size = field ( "<STR_LIT>" ) <EOL> mesh = field ( "<STR_LIT>" ) <EOL> mesh1 = field ( "<STR_LIT>" ) <EOL> mesh2 = field ( "<STR_LIT>" ) <EOL> mesh3 = field ( "<STR_LIT>" ) <EOL> normal_direction = field ( "<STR_LIT>" ) <EOL> render_mode = field ( "<STR_LIT>" , ParticleSystemRenderMode ) <EOL> sort_mode = field ( "<STR_LIT>" , ParticleSystemSortMode ) <EOL> sorting_fudge = field ( "<STR_LIT>" ) <EOL> velocity_scale = field ( "<STR_LIT>" ) </s>
<s> from ConfigParser import * <EOL> from StringIO import * <EOL> from Log import Log <EOL> import datetime <EOL> class Config : <EOL> @ staticmethod <EOL> def LoadConfig ( ) : <EOL> Config . parser = ConfigParser ( ) <EOL> try : <EOL> sconff = open ( CONFIG_FILE , "<STR_LIT:r>" ) <EOL> except : <EOL> Log . warn ( "<STR_LIT>" ) <EOL> return <EOL> sconf = StringIO ( ) <EOL> sconf . write ( "<STR_LIT>" ) <EOL> sconf . write ( sconff . read ( ) ) <EOL> sconf . seek ( <NUM_LIT:0> ) <EOL> Config . parser . readfp ( sconf ) <EOL> sconff . close ( ) <EOL> sconf . close ( ) <EOL> return <EOL> @ staticmethod <EOL> def GetBoardsFile ( ) : <EOL> return BOARDS_FILE <EOL> @ staticmethod <EOL> def GetInt ( name , defval ) : <EOL> if ( Config . parser . has_option ( '<STR_LIT>' , name ) ) : <EOL> return Config . parser . getint ( '<STR_LIT>' , name ) <EOL> else : <EOL> return defval <EOL> @ staticmethod <EOL> def GetString ( name , defval ) : <EOL> if ( Config . parser . has_option ( '<STR_LIT>' , name ) ) : <EOL> val = Config . parser . get ( '<STR_LIT>' , name ) <EOL> if ( val [ <NUM_LIT:0> ] == '<STR_LIT:">' and val . endswith ( '<STR_LIT:">' ) ) : <EOL> val = val [ <NUM_LIT:1> : - <NUM_LIT:1> ] <EOL> return val . decode ( '<STR_LIT>' ) <EOL> else : <EOL> return defval <EOL> BBS_ROOT = '<STR_LIT>' <EOL> BBS_XMPP_CERT_FILE = BBS_ROOT + "<STR_LIT>" <EOL> BBS_XMPP_KEY_FILE = BBS_ROOT + "<STR_LIT>" <EOL> BOARDS_FILE = BBS_ROOT + '<STR_LIT>' <EOL> STRLEN = <NUM_LIT> <EOL> ARTICLE_TITLE_LEN = <NUM_LIT> <EOL> BM_LEN = <NUM_LIT> <EOL> MAXBOARD = <NUM_LIT> <EOL> CONFIG_FILE = BBS_ROOT + '<STR_LIT>' <EOL> FILENAME_LEN = <NUM_LIT:20> <EOL> OWNER_LEN = <NUM_LIT:30> <EOL> SESSIONID_LEN = <NUM_LIT:32> <EOL> REFRESH_TOKEN_LEN = <NUM_LIT> <EOL> NAMELEN = <NUM_LIT> <EOL> IDLEN = <NUM_LIT:12> <EOL> MD5PASSLEN = <NUM_LIT:16> <EOL> OLDPASSLEN = <NUM_LIT> <EOL> MOBILE_NUMBER_LEN = <NUM_LIT> <EOL> MAXCLUB = <NUM_LIT> <EOL> MAXUSERS = <NUM_LIT> <EOL> MAX_MSG_SIZE = <NUM_LIT> <EOL> MAXFRIENDS = <NUM_LIT> <EOL> MAXMESSAGE = <NUM_LIT:5> <EOL> MAXSIGLINES = <NUM_LIT:6> <EOL> IPLEN = <NUM_LIT:16> <EOL> DEFAULTBOARD = "<STR_LIT>" <EOL> BLESS_BOARD = "<STR_LIT>" <EOL> QUOTED_LINES = <NUM_LIT:10> <EOL> MAXACTIVE = <NUM_LIT> <EOL> USHM_SIZE = MAXACTIVE + <NUM_LIT:10> <EOL> UTMP_HASHSIZE = USHM_SIZE * <NUM_LIT:4> <EOL> UCACHE_SEMLOCK = <NUM_LIT:0> <EOL> LEN_FRIEND_EXP = <NUM_LIT:15> <EOL> REFRESH_TIME = <NUM_LIT:30> <EOL> USER_TITLE_LEN = <NUM_LIT> <EOL> SESSION_TIMEOUT = datetime . timedelta ( <NUM_LIT:30> ) <EOL> SESSION_TIMEOUT_SECONDS = <NUM_LIT> * <NUM_LIT:30> <EOL> XMPP_IDLE_TIME = <NUM_LIT> <EOL> XMPP_LONG_IDLE_TIME = <NUM_LIT> <EOL> XMPP_UPDATE_TIME_INTERVAL = <NUM_LIT:10> <EOL> XMPP_PING_TIME_INTERVAL = <NUM_LIT> <EOL> PUBLIC_SHMKEY = <NUM_LIT> <EOL> MAX_ATTACHSIZE = <NUM_LIT:20> * <NUM_LIT> * <NUM_LIT> <EOL> BMDEL_DECREASE = True <EOL> SYSMAIL_BOARD = "<STR_LIT>" <EOL> ADD_EDITMARK = True <EOL> SEARCH_COUNT_LIMIT = <NUM_LIT:20> <EOL> MAIL_SIZE_LIMIT = - <NUM_LIT:1> <EOL> SEC_DELETED_OLDHOME = <NUM_LIT> * <NUM_LIT> * <NUM_LIT:3> <EOL> SELF_INTRO_MAX_LEN = <NUM_LIT> </s>
<s> import re <EOL> import os <EOL> import stat <EOL> import json <EOL> import struct <EOL> import time <EOL> import Config <EOL> import Board <EOL> import Post <EOL> import BoardManager <EOL> from Util import Util <EOL> from Log import Log <EOL> from errors import * <EOL> DEFAULT_DIGEST_LIST_COUNT = <NUM_LIT:20> <EOL> class DigestItem : <EOL> def __init__ ( self , basepath ) : <EOL> self . basepath = basepath <EOL> self . title = '<STR_LIT>' <EOL> self . host = '<STR_LIT>' <EOL> self . port = <NUM_LIT:0> <EOL> self . attachpos = <NUM_LIT:0> <EOL> self . fname = '<STR_LIT>' <EOL> self . mtitle = '<STR_LIT>' <EOL> self . items = [ ] <EOL> self . update_time = <NUM_LIT:0> <EOL> self . id = <NUM_LIT:0> <EOL> self . sysop_only = <NUM_LIT:0> <EOL> self . bms_only = <NUM_LIT:0> <EOL> self . zixia_only = <NUM_LIT:0> <EOL> def IsDir ( self ) : <EOL> try : <EOL> st = os . stat ( self . realpath ( ) ) <EOL> return stat . S_ISDIR ( st . st_mode ) <EOL> except : <EOL> return False <EOL> def IsFile ( self ) : <EOL> try : <EOL> st = os . stat ( self . realpath ( ) ) <EOL> return stat . S_ISREG ( st . st_mode ) <EOL> except : <EOL> return False <EOL> def GetModTime ( self ) : <EOL> try : <EOL> st = os . stat ( self . realpath ( ) ) <EOL> mtime = st . st_mtime <EOL> except : <EOL> mtime = time . time ( ) <EOL> return mtime <EOL> def names_path ( self ) : <EOL> return "<STR_LIT>" % self . realpath ( ) <EOL> def realpath ( self ) : <EOL> return "<STR_LIT>" % ( Config . BBS_ROOT , self . path ( ) ) <EOL> def path ( self ) : <EOL> if ( self . fname ) : <EOL> return "<STR_LIT>" % ( self . basepath , self . fname ) <EOL> else : <EOL> return self . basepath <EOL> def CheckUpdate ( self ) : <EOL> try : <EOL> stat = os . stat ( self . names_path ( ) ) <EOL> if ( stat . st_mtime > self . update_time ) : <EOL> self . LoadNames ( ) <EOL> except : <EOL> return False <EOL> return True <EOL> def LoadNames ( self ) : <EOL> try : <EOL> f = open ( self . names_path ( ) , "<STR_LIT:r>" ) <EOL> except IOError : <EOL> return <NUM_LIT:0> <EOL> stat = os . fstat ( f . fileno ( ) ) <EOL> self . update_time = stat . st_mtime <EOL> item = DigestItem ( self . path ( ) ) <EOL> hostname = '<STR_LIT>' <EOL> _id = <NUM_LIT:0> <EOL> bms_only = <NUM_LIT:0> <EOL> sysop_only = <NUM_LIT:0> <EOL> zixia_only = <NUM_LIT:0> <EOL> while ( True ) : <EOL> line = f . readline ( ) <EOL> if ( line == "<STR_LIT>" ) : break <EOL> npos = line . find ( "<STR_LIT:\n>" ) <EOL> if ( npos != - <NUM_LIT:1> ) : line = line [ : npos ] <EOL> if ( line [ : <NUM_LIT:1> ] == '<STR_LIT:#>' ) : <EOL> if ( line [ : <NUM_LIT:8> ] == "<STR_LIT>" ) : <EOL> if ( not self . mtitle ) : <EOL> self . mtitle = line [ <NUM_LIT:8> : ] <EOL> result = re . match ( '<STR_LIT>' , line ) <EOL> if ( result ) : <EOL> key = result . group ( <NUM_LIT:1> ) <EOL> value = result . group ( <NUM_LIT:2> ) <EOL> if ( key == "<STR_LIT:Name>" ) : <EOL> item . title = value <EOL> item . attachpos = <NUM_LIT:0> <EOL> elif ( key == "<STR_LIT>" ) : <EOL> if ( value [ : <NUM_LIT:2> ] == "<STR_LIT>" ) : <EOL> item . fname = value [ <NUM_LIT:2> : ] <EOL> else : <EOL> item . fname = value <EOL> if ( item . fname . find ( "<STR_LIT:..>" ) != - <NUM_LIT:1> ) : <EOL> continue <EOL> if ( item . title . find ( "<STR_LIT>" ) != - <NUM_LIT:1> ) : <EOL> bms_only += <NUM_LIT:1> <EOL> elif ( item . title . find ( "<STR_LIT>" ) != - <NUM_LIT:1> ) : <EOL> sysop_only += <NUM_LIT:1> <EOL> elif ( item . title . find ( "<STR_LIT>" ) != - <NUM_LIT:1> ) : <EOL> zixia_only += <NUM_LIT:1> <EOL> if ( item . fname . find ( "<STR_LIT>" ) != - <NUM_LIT:1> ) : <EOL> parts = re . split ( '<STR_LIT>' , item . fname ) <EOL> newparts = [ ] <EOL> for part in parts : <EOL> if ( part ) : <EOL> newparts += [ part ] <EOL> hostname = newparts [ <NUM_LIT:0> ] <EOL> item . fname = newparts [ <NUM_LIT:1> ] <EOL> try : <EOL> item . port = int ( newparts [ <NUM_LIT:2> ] ) <EOL> except : <EOL> item . port = <NUM_LIT:0> <EOL> item . id = _id <EOL> _id += <NUM_LIT:1> <EOL> item . bms_only = bms_only <EOL> item . sysop_only = sysop_only <EOL> item . zixia_only = zixia_only <EOL> item . host = hostname <EOL> self . items += [ item ] <EOL> item = DigestItem ( self . path ( ) ) <EOL> hostname = '<STR_LIT>' <EOL> elif ( key == "<STR_LIT>" ) : <EOL> hostname = value <EOL> elif ( key == "<STR_LIT>" ) : <EOL> try : <EOL> item . port = int ( value ) <EOL> except : <EOL> item . port = <NUM_LIT:0> <EOL> elif ( key == "<STR_LIT>" ) : <EOL> try : <EOL> item . attachpos = int ( value ) <EOL> except : <EOL> item . attachpos = <NUM_LIT:0> <EOL> f . close ( ) <EOL> return <NUM_LIT:1> <EOL> def GetItem ( self , user , route , has_perm = False , need_perm = False ) : <EOL> self . CheckUpdate ( ) <EOL> if ( self . mtitle . find ( "<STR_LIT>" ) != - <NUM_LIT:1> ) : <EOL> if ( Board . Board . IsBM ( user , self . mtitle [ <NUM_LIT:4> : ] , ) or user . IsSysop ( ) ) : <EOL> has_perm = True <EOL> elif ( need_perm and not has_perm ) : <EOL> return None <EOL> if ( self . mtitle . find ( "<STR_LIT>" ) != - <NUM_LIT:1> <EOL> or self . mtitle . find ( "<STR_LIT>" ) != - <NUM_LIT:1> <EOL> or self . mtitle . find ( "<STR_LIT>" ) != - <NUM_LIT:1> ) : <EOL> need_perm = True <EOL> if ( len ( route ) == <NUM_LIT:0> ) : <EOL> return self <EOL> target = route [ <NUM_LIT:0> ] - <NUM_LIT:1> <EOL> _id = target <EOL> if ( _id >= len ( self . items ) ) : <EOL> return None <EOL> while ( self . items [ _id ] . EffectiveId ( user ) < target ) : <EOL> _id += <NUM_LIT:1> <EOL> if ( _id >= len ( self . items ) ) : <EOL> return None <EOL> item = self . items [ _id ] <EOL> item . mtitle = item . title <EOL> if ( len ( route ) == <NUM_LIT:1> ) : <EOL> return item <EOL> else : <EOL> if ( item . IsDir ( ) ) : <EOL> if ( not item . CheckUpdate ( ) ) : <EOL> return None <EOL> return item . GetItem ( user , route [ <NUM_LIT:1> : ] , has_perm , need_perm ) <EOL> else : <EOL> return None <EOL> def GetRange ( self , user , route , start , end , has_perm = False , need_perm = False ) : <EOL> self . CheckUpdate ( ) <EOL> firstitem = self . GetItem ( user , route + [ start ] , has_perm , need_perm ) <EOL> if ( not firstitem ) : <EOL> return [ ] <EOL> parent = self . GetItem ( user , route , has_perm , need_perm ) <EOL> if ( not parent ) : <EOL> return [ ] <EOL> if ( not parent . IsDir ( ) ) : <EOL> return [ ] <EOL> result = [ ] <EOL> _id = start - <NUM_LIT:1> <EOL> for i in range ( start , end + <NUM_LIT:1> ) : <EOL> target = i - <NUM_LIT:1> <EOL> if ( _id >= len ( parent . items ) ) : <EOL> return [ ] <EOL> while ( parent . items [ _id ] . EffectiveId ( user ) < target ) : <EOL> _id += <NUM_LIT:1> <EOL> if ( _id >= len ( parent . items ) ) : <EOL> return result <EOL> item = parent . items [ _id ] <EOL> item . mtitle = item . title <EOL> result += [ item ] <EOL> return result <EOL> def EffectiveId ( self , user ) : <EOL> _id = self . id <EOL> if ( user . IsSysop ( ) ) : <EOL> return _id <EOL> if ( not user . IsSysop ( ) ) : <EOL> _id -= self . sysop_only <EOL> if ( not user . IsBM ( ) ) : <EOL> _id -= self . bms_only <EOL> if ( not user . IsSECANC ( ) ) : <EOL> _id -= self . zixia_only <EOL> return _id <EOL> def GetInfo ( self ) : <EOL> info = { } <EOL> info [ '<STR_LIT>' ] = Util . gbkDec ( self . mtitle ) <EOL> info [ '<STR_LIT:title>' ] = Util . gbkDec ( self . title ) <EOL> info [ '<STR_LIT>' ] = self . attachpos <EOL> if ( self . host != '<STR_LIT>' ) : <EOL> info [ '<STR_LIT:host>' ] = self . host <EOL> info [ '<STR_LIT:port>' ] = self . port <EOL> info [ '<STR_LIT:type>' ] = '<STR_LIT>' <EOL> elif ( self . IsDir ( ) ) : <EOL> info [ '<STR_LIT:type>' ] = '<STR_LIT>' <EOL> elif ( self . IsFile ( ) ) : <EOL> info [ '<STR_LIT:type>' ] = '<STR_LIT:file>' <EOL> else : <EOL> info [ '<STR_LIT:type>' ] = '<STR_LIT>' <EOL> info [ '<STR_LIT>' ] = int ( self . GetModTime ( ) ) <EOL> return info <EOL> def GetInfoForUser ( self , user ) : <EOL> info = self . GetInfo ( ) <EOL> info [ '<STR_LIT:id>' ] = self . EffectiveId ( user ) + <NUM_LIT:1> <EOL> return info <EOL> def GetAttachLink ( self , session ) : <EOL> _hash = Util . HashGen ( self . path ( ) , "<STR_LIT>" ) <EOL> filename = '<STR_LIT>' <EOL> for i in range ( <NUM_LIT:2> ) : <EOL> filename += "<STR_LIT>" % struct . unpack ( '<STR_LIT>' , _hash [ i * <NUM_LIT:4> : ( i + <NUM_LIT:1> ) * <NUM_LIT:4> ] ) <EOL> link = "<STR_LIT>" % ( session . GetMirror ( Config . Config . GetInt ( '<STR_LIT>' , <NUM_LIT> ) ) , filename ) <EOL> linkfile = "<STR_LIT>" % ( Config . BBS_ROOT , filename ) <EOL> target = "<STR_LIT>" % self . path ( ) <EOL> try : <EOL> os . symlink ( target , linkfile ) <EOL> except : <EOL> pass <EOL> return link <EOL> class Digest : <EOL> root = DigestItem ( "<STR_LIT>" ) <EOL> def __init__ ( self , board , path ) : <EOL> self . board = board <EOL> self . path = path <EOL> self . root = DigestItem ( self . path ) <EOL> @ staticmethod <EOL> def GET ( svc , session , params , action ) : <EOL> if ( session is None ) : raise Unauthorized ( '<STR_LIT>' ) <EOL> if not session . CheckScope ( '<STR_LIT>' ) : raise NoPerm ( "<STR_LIT>" ) <EOL> user = session . GetUser ( ) <EOL> boardname = svc . get_str ( params , '<STR_LIT>' , '<STR_LIT>' ) <EOL> if ( boardname ) : <EOL> board = BoardManager . BoardManager . GetBoard ( boardname ) <EOL> if ( board is None ) : raise NotFound ( '<STR_LIT>' % boardname ) <EOL> if ( not board . CheckReadPerm ( user ) ) : <EOL> raise NoPerm ( '<STR_LIT>' ) <EOL> basenode = board . digest . root <EOL> has_perm = user . IsDigestMgr ( ) or user . IsSysop ( ) or user . IsSuperBM ( ) <EOL> else : <EOL> basenode = Digest . root <EOL> has_perm = user . IsDigestMgr ( ) <EOL> if ( action == "<STR_LIT:list>" ) : <EOL> route = svc . get_str ( params , '<STR_LIT>' ) <EOL> start = svc . get_int ( params , '<STR_LIT:start>' , <NUM_LIT:1> ) <EOL> end = svc . get_int ( params , '<STR_LIT:end>' , start + DEFAULT_DIGEST_LIST_COUNT - <NUM_LIT:1> ) <EOL> Digest . List ( svc , basenode , route , start , end , session , has_perm ) <EOL> return <EOL> elif ( action == "<STR_LIT>" ) : <EOL> route = svc . get_str ( params , '<STR_LIT>' ) <EOL> start = svc . get_int ( params , '<STR_LIT:start>' , <NUM_LIT:0> ) <EOL> count = svc . get_int ( params , '<STR_LIT:count>' , <NUM_LIT:0> ) <EOL> Digest . View ( svc , basenode , route , session , has_perm , start , count ) <EOL> return <EOL> else : <EOL> raise WrongArgs ( '<STR_LIT>' % action ) <EOL> @ staticmethod <EOL> def ParseRoute ( route ) : <EOL> ret = [ ] <EOL> items = re . split ( '<STR_LIT:->' , route ) <EOL> items = items [ <NUM_LIT:1> : ] <EOL> for item in items : <EOL> try : <EOL> ret += [ int ( item ) ] <EOL> except : <EOL> raise WrongArgs ( '<STR_LIT>' % item ) <EOL> return ret <EOL> @ staticmethod <EOL> def List ( svc , basenode , route , start , end , session , has_perm ) : <EOL> route_array = Digest . ParseRoute ( route ) <EOL> parent = basenode . GetItem ( session . GetUser ( ) , route_array , has_perm ) <EOL> if ( not parent ) : <EOL> raise WrongArgs ( '<STR_LIT>' % route ) <EOL> if ( not parent . IsDir ( ) ) : <EOL> raise WrongArgs ( '<STR_LIT>' % route ) <EOL> items = basenode . GetRange ( session . GetUser ( ) , route_array , start , end , has_perm ) <EOL> result = { } <EOL> result [ '<STR_LIT>' ] = parent . GetInfoForUser ( session . GetUser ( ) ) <EOL> result [ '<STR_LIT:count>' ] = len ( items ) <EOL> result_list = [ ] <EOL> for item in items : <EOL> result_list += [ item . GetInfoForUser ( session . GetUser ( ) ) ] <EOL> result [ '<STR_LIT>' ] = result_list <EOL> svc . writedata ( json . dumps ( result ) ) <EOL> @ staticmethod <EOL> def View ( svc , basenode , route , session , has_perm , start , count ) : <EOL> route_array = Digest . ParseRoute ( route ) <EOL> item = basenode . GetItem ( session . GetUser ( ) , route_array , has_perm ) <EOL> if ( not item ) : <EOL> raise WrongArgs ( '<STR_LIT>' % route ) <EOL> if ( not item . IsFile ( ) ) : <EOL> raise WrongArgs ( '<STR_LIT>' % route ) <EOL> result = { } <EOL> result [ '<STR_LIT>' ] = item . GetInfoForUser ( session . GetUser ( ) ) <EOL> postinfo = Post . Post ( item . realpath ( ) , None ) <EOL> ( result [ '<STR_LIT:content>' ] , result [ '<STR_LIT>' ] ) = postinfo . GetContent ( start , count ) <EOL> attachlist = postinfo . GetAttachListByType ( ) <EOL> result [ '<STR_LIT>' ] = attachlist [ <NUM_LIT:0> ] <EOL> result [ '<STR_LIT>' ] = attachlist [ <NUM_LIT:1> ] <EOL> if ( attachlist [ <NUM_LIT:0> ] or attachlist [ <NUM_LIT:1> ] ) : <EOL> result [ '<STR_LIT>' ] = item . GetAttachLink ( session ) <EOL> svc . writedata ( json . dumps ( result ) ) </s>
<s> import time <EOL> import UserManager <EOL> import UserInfo <EOL> from Session import Session <EOL> from Log import Log <EOL> import UCache <EOL> import Config <EOL> import MsgBox <EOL> import xmpp <EOL> import modes <EOL> import Util <EOL> import traceback <EOL> import os <EOL> from xmpp . features import NoRoute <EOL> __disco_info_ns__ = '<STR_LIT>' <EOL> __disco_items_ns__ = '<STR_LIT>' <EOL> __vcard_ns__ = '<STR_LIT>' <EOL> STEAL_AFTER_SEEN = <NUM_LIT:3> <EOL> def elem_to_str ( elem ) : <EOL> return "<STR_LIT>" % ( elem . tag , elem . attrib , elem . text ) <EOL> class XMPPServer ( xmpp . Plugin ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , rosters , host ) : <EOL> self . probed = False <EOL> self . _closed = False <EOL> self . rosters = rosters <EOL> self . _session = None <EOL> self . rosters . set_resources ( self . get_resources ( ) ) <EOL> self . _fixedjid = UCache . UCache . formalize_jid ( unicode ( self . authJID ) ) <EOL> self . _userid = self . _fixedjid . partition ( '<STR_LIT:@>' ) [ <NUM_LIT:0> ] . encode ( "<STR_LIT>" ) <EOL> if ( not self . rosters . allow_login ( self . authJID . bare ) ) : <EOL> Log . warn ( "<STR_LIT>" % self . _userid ) <EOL> self . stream_error ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> return <EOL> Log . info ( "<STR_LIT>" % unicode ( self . authJID ) ) <EOL> if self . authJID . resource [ : - <NUM_LIT:8> ] != "<STR_LIT>" and len ( self . authJID . resource ) > <NUM_LIT:8> : <EOL> try : <EOL> routes = self . routes ( self . authJID . bare ) <EOL> for route in routes : <EOL> jid = route [ <NUM_LIT:0> ] <EOL> if jid . resource [ : - <NUM_LIT:8> ] == self . authJID . resource [ : - <NUM_LIT:8> ] : <EOL> if jid . resource != self . authJID . resource : <EOL> Log . info ( "<STR_LIT>" % ( jid . full , route [ <NUM_LIT:1> ] ) ) <EOL> route [ <NUM_LIT:1> ] . stream_error ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> else : <EOL> Log . info ( "<STR_LIT>" % ( jid . full , route [ <NUM_LIT:1> ] ) ) <EOL> except NoRoute : <EOL> pass <EOL> Log . debug ( "<STR_LIT>" % self . authJID . full ) <EOL> self . _user = UserManager . UserManager . LoadUser ( self . _userid ) <EOL> if ( self . _user == None ) : <EOL> raise Exception ( "<STR_LIT>" ) <EOL> self . _peer_addr = self . getpeername ( ) <EOL> self . _session = Session ( self . _user , self . _peer_addr [ <NUM_LIT:0> ] ) <EOL> self . _session . RecordLogin ( ) <EOL> self . _userinfo = self . _session . Register ( ) <EOL> self . _loginid = self . _session . utmpent <EOL> self . _hostname = host <EOL> self . bind ( xmpp . ReceivedCloseStream , self . recv_close ) <EOL> self . bind ( xmpp . StreamClosed , self . stream_closed ) <EOL> self . bind ( xmpp . SentCloseStream , self . sent_close ) <EOL> self . rosters . register_conn ( self ) <EOL> msgbox = MsgBox . MsgBox ( self . _userid ) <EOL> if self . rosters . get_xmpp_read ( self . _user . GetUID ( ) ) is None : <EOL> self . rosters . set_xmpp_read ( self . _user . GetUID ( ) , msgbox . GetMsgCount ( all = False ) - msgbox . GetUnreadCount ( ) ) <EOL> self . check_msg ( ) <EOL> def get_loginid ( self ) : <EOL> return self . _loginid <EOL> def recv_close ( self ) : <EOL> Log . debug ( "<STR_LIT>" % self . authJID . full ) <EOL> return self . close ( ) <EOL> def stream_closed ( self ) : <EOL> Log . debug ( "<STR_LIT>" % self . authJID . full ) <EOL> return self . close ( ) <EOL> def sent_close ( self ) : <EOL> Log . debug ( "<STR_LIT>" % self . authJID . full ) <EOL> return self . close ( ) <EOL> def close ( self ) : <EOL> if ( self . _closed ) : <EOL> Log . debug ( "<STR_LIT>" ) <EOL> return <EOL> self . _closed = True <EOL> Log . info ( "<STR_LIT>" % unicode ( self . authJID ) ) <EOL> if ( self . _session ) : <EOL> self . _session . Unregister ( ) <EOL> self . unbind_res ( ) <EOL> self . rosters . unregister_conn ( self ) <EOL> @ xmpp . iq ( '<STR_LIT>' ) <EOL> def ping ( self , iq ) : <EOL> """<STR_LIT>""" <EOL> self . refresh ( ) <EOL> return self . iq ( '<STR_LIT:result>' , iq ) <EOL> @ xmpp . stanza ( '<STR_LIT:message>' ) <EOL> def message ( self , elem ) : <EOL> """<STR_LIT>""" <EOL> to_jid = elem . get ( '<STR_LIT:to>' ) <EOL> from_jid = elem . get ( '<STR_LIT>' ) <EOL> if ( from_jid == None ) : <EOL> return <EOL> text_body = None <EOL> for child in elem : <EOL> if ( child . tag . endswith ( '<STR_LIT>' ) ) : <EOL> text_body = child . text <EOL> if ( text_body == None ) : <EOL> return <EOL> ret = self . rosters . send_msg ( from_jid , to_jid , text_body ) <EOL> if ( ret <= <NUM_LIT:0> ) : <EOL> Log . warn ( "<STR_LIT>" % ( to_jid , from_jid , ret ) ) <EOL> errors = { <EOL> - <NUM_LIT:1> : "<STR_LIT>" , <EOL> - <NUM_LIT:11> : "<STR_LIT>" , <EOL> - <NUM_LIT:12> : "<STR_LIT>" , <EOL> - <NUM_LIT> : "<STR_LIT>" , <EOL> - <NUM_LIT> : "<STR_LIT>" , <EOL> - <NUM_LIT:2> : "<STR_LIT>" , <EOL> - <NUM_LIT> : "<STR_LIT>" } <EOL> if ( ret in errors ) : <EOL> elem = self . E . message ( { '<STR_LIT>' : to_jid , <EOL> '<STR_LIT:to>' : from_jid , <EOL> '<STR_LIT:type>' : '<STR_LIT:error>' } , <EOL> self . E . body ( errors [ ret ] ) ) <EOL> self . recv ( from_jid , elem ) <EOL> def make_jid ( self , userid ) : <EOL> return "<STR_LIT>" % ( userid , self . _hostname ) <EOL> def refresh ( self ) : <EOL> self . _userinfo . freshtime = int ( time . time ( ) ) <EOL> self . _userinfo . save ( ) <EOL> def ping_result ( self , iq ) : <EOL> self . refresh ( ) <EOL> def ping_client ( self ) : <EOL> try : <EOL> pingelem = self . E . ping ( xmlns = '<STR_LIT>' ) <EOL> return self . iq ( '<STR_LIT>' , self . ping_result , pingelem ) <EOL> except Exception as e : <EOL> Log . debug ( "<STR_LIT>" % ( self . authJID , e ) ) <EOL> Log . debug ( traceback . format_exc ( ) ) <EOL> return False <EOL> def get_uid ( self ) : <EOL> return self . _user . GetUID ( ) <EOL> def recv_msg ( self , from_ , msgtext ) : <EOL> elem = self . E . message ( { '<STR_LIT>' : from_ , '<STR_LIT:to>' : unicode ( self . authJID ) } , <EOL> self . E . body ( msgtext ) ) <EOL> self . recv ( unicode ( self . authJID ) , elem ) <EOL> def check_msg ( self ) : <EOL> Log . debug ( "<STR_LIT>" % self . _userid ) <EOL> msgbox = MsgBox . MsgBox ( self . _userid ) <EOL> msg_count = msgbox . GetMsgCount ( all = False ) <EOL> my_pid = os . getpid ( ) <EOL> xmpp_read = self . rosters . get_xmpp_read ( self . _user . GetUID ( ) ) <EOL> if xmpp_read > msg_count : <EOL> xmpp_read = <NUM_LIT:0> <EOL> Log . debug ( "<STR_LIT>" % ( msg_count , xmpp_read ) ) <EOL> self . rosters . set_xmpp_read ( self . _user . GetUID ( ) , msg_count ) <EOL> if xmpp_read < msg_count : <EOL> return xmpp_read <EOL> else : <EOL> return - <NUM_LIT:1> <EOL> def deliver_msg ( self , start ) : <EOL> Log . debug ( "<STR_LIT>" % unicode ( self . authJID ) ) <EOL> msgbox = MsgBox . MsgBox ( self . _userid ) <EOL> msg_count = msgbox . GetMsgCount ( all = False ) <EOL> my_pid = os . getpid ( ) <EOL> for i in range ( start , msg_count ) : <EOL> msghead = msgbox . LoadMsgHead ( i , all = False ) <EOL> if msghead . topid == my_pid : <EOL> msgtext = msgbox . LoadMsgText ( msghead ) <EOL> self . recv_msg ( self . make_jid ( msghead . id ) , msgtext ) <EOL> def steal_msg ( self ) : <EOL> Log . debug ( "<STR_LIT>" % self . _userid ) <EOL> msgbox = MsgBox . MsgBox ( self . _userid ) <EOL> msg_count = msgbox . GetMsgCount ( all = False ) <EOL> msg_unread = msgbox . GetUnreadCount ( ) <EOL> read_count = msg_count - msg_unread <EOL> my_pid = os . getpid ( ) <EOL> term_read = self . rosters . get_term_read ( self . get_uid ( ) ) <EOL> term_stealed = self . rosters . get_term_stealed ( self . get_uid ( ) ) <EOL> all_xmpp = True <EOL> new_unread = { } <EOL> for i in range ( read_count - <NUM_LIT:1> , msg_count ) : <EOL> if i < <NUM_LIT:0> : <EOL> continue <EOL> msghead = msgbox . LoadMsgHead ( i , all = False ) <EOL> if i >= read_count and all_xmpp : <EOL> if msghead . topid == my_pid : <EOL> msgbox . GetUnreadMsg ( ) <EOL> else : <EOL> all_xmpp = False <EOL> if msghead . topid == my_pid : <EOL> continue <EOL> if i < read_count : <EOL> session = self . rosters . find_session ( self . authJID . bare , msghead . topid ) <EOL> if session is None or session . get_mode ( ) != modes . MSG : <EOL> continue <EOL> Log . debug ( "<STR_LIT>" % i ) <EOL> if msghead . topid not in new_unread : <EOL> Log . debug ( "<STR_LIT>" % ( msghead . topid , i ) ) <EOL> new_unread [ msghead . topid ] = i <EOL> final_unread = { } <EOL> to_steal = { } <EOL> to_steal_begin = msg_count <EOL> for pid in term_read : <EOL> if pid in new_unread : <EOL> if new_unread [ pid ] == term_read [ pid ] [ <NUM_LIT:0> ] : <EOL> final_unread [ pid ] = ( term_read [ pid ] [ <NUM_LIT:0> ] , term_read [ pid ] [ <NUM_LIT:1> ] + <NUM_LIT:1> ) <EOL> Log . debug ( "<STR_LIT>" % ( new_unread [ pid ] , pid , term_read [ pid ] [ <NUM_LIT:1> ] + <NUM_LIT:1> ) ) <EOL> if final_unread [ pid ] [ <NUM_LIT:1> ] > STEAL_AFTER_SEEN : <EOL> to_steal [ pid ] = final_unread [ pid ] <EOL> Log . debug ( "<STR_LIT>" % ( to_steal [ pid ] [ <NUM_LIT:0> ] , pid ) ) <EOL> if pid in term_stealed : <EOL> steal_begin = max ( final_unread [ pid ] [ <NUM_LIT:0> ] , term_stealed [ pid ] + <NUM_LIT:1> ) <EOL> else : <EOL> steal_begin = final_unread [ pid ] [ <NUM_LIT:0> ] <EOL> if steal_begin < to_steal_begin : <EOL> to_steal_begin = steal_begin <EOL> else : <EOL> final_unread [ pid ] = ( new_unread [ pid ] , <NUM_LIT:1> ) <EOL> Log . debug ( "<STR_LIT>" % ( term_read [ pid ] [ <NUM_LIT:0> ] , new_unread [ pid ] , pid ) ) <EOL> else : <EOL> Log . debug ( "<STR_LIT>" % pid ) <EOL> pass <EOL> for pid in new_unread : <EOL> if pid not in term_read : <EOL> Log . debug ( "<STR_LIT>" % ( new_unread [ pid ] , pid ) ) <EOL> final_unread [ pid ] = ( new_unread [ pid ] , <NUM_LIT:1> ) <EOL> if to_steal : <EOL> Log . debug ( "<STR_LIT>" % to_steal_begin ) <EOL> for i in range ( to_steal_begin , msg_count ) : <EOL> msghead = msgbox . LoadMsgHead ( i , all = False ) <EOL> if msghead . topid == my_pid : <EOL> Log . debug ( "<STR_LIT>" % ( i , msghead . topid ) ) <EOL> msgbox . GetUnreadMsg ( ) <EOL> elif msghead . topid in to_steal : <EOL> if msghead . topid not in term_stealed or i > term_stealed [ msghead . topid ] : <EOL> Log . debug ( "<STR_LIT>" % ( i , msghead . topid ) ) <EOL> msgtext = msgbox . LoadMsgText ( msghead ) <EOL> self . recv_msg ( self . make_jid ( msghead . id ) , msgtext ) <EOL> term_stealed [ msghead . topid ] = i <EOL> else : <EOL> Log . debug ( "<STR_LIT>" % ( i , msghead . topid ) ) <EOL> self . rosters . set_term_read ( self . get_uid ( ) , final_unread ) <EOL> @ xmpp . stanza ( '<STR_LIT>' ) <EOL> def presence ( self , elem ) : <EOL> """<STR_LIT>""" <EOL> Log . warn ( "<STR_LIT>" % ( self . authJID , elem_to_str ( elem ) ) ) <EOL> if self . authJID == elem . get ( '<STR_LIT>' ) : <EOL> if ( elem . get ( '<STR_LIT:to>' ) == None or ( not self . authJID . match_bare ( elem . get ( '<STR_LIT:to>' ) ) ) ) : <EOL> return self . send_presence ( elem ) <EOL> self . recv_presence ( elem ) <EOL> def send_presence ( self , elem ) : <EOL> Log . warn ( "<STR_LIT>" % ( self . authJID , elem_to_str ( elem ) ) ) <EOL> direct = elem . get ( '<STR_LIT:to>' ) <EOL> if not direct : <EOL> self . rosters . broadcast ( self , elem ) <EOL> if elem . get ( '<STR_LIT:type>' ) != '<STR_LIT>' : <EOL> self . recv_presence ( elem ) <EOL> if not self . probed : <EOL> self . probed = True <EOL> self . rosters . probe ( self ) <EOL> elif not self . rosters . send ( self , direct , elem ) : <EOL> self . send ( direct , elem ) <EOL> def recv_presence ( self , elem ) : <EOL> Log . warn ( "<STR_LIT>" % ( self . authJID , elem_to_str ( elem ) ) ) <EOL> if not self . rosters . recv ( self , elem ) : <EOL> Log . warn ( "<STR_LIT>" ) <EOL> self . write ( elem ) <EOL> @ xmpp . iq ( '<STR_LIT>' ) <EOL> def roster ( self , iq ) : <EOL> """<STR_LIT>""" <EOL> roster = self . rosters . get ( self ) <EOL> method = getattr ( self , '<STR_LIT>' % iq . get ( '<STR_LIT:type>' ) ) <EOL> return method and method ( iq , roster ) <EOL> def get_roster ( self , iq , roster ) : <EOL> query = self . E . query ( { '<STR_LIT>' : '<STR_LIT>' } ) <EOL> for item in roster . items ( ) : <EOL> query . append ( item ) <EOL> return self . iq ( '<STR_LIT:result>' , iq , query ) <EOL> def set_roster ( self , iq , roster ) : <EOL> query = self . E . query ( xmlns = '<STR_LIT>' ) <EOL> for item in iq [ <NUM_LIT:0> ] : <EOL> result = roster . set ( item ) <EOL> if result is not None : <EOL> query . append ( result ) <EOL> if len ( query ) > <NUM_LIT:0> : <EOL> self . push ( roster , query ) <EOL> return self . iq ( '<STR_LIT:result>' , iq ) <EOL> def push ( self , roster , query ) : <EOL> """<STR_LIT>""" <EOL> for jid in roster . requests ( ) : <EOL> for ( to , route ) in self . routes ( jid ) : <EOL> route . iq ( '<STR_LIT>' , self . ignore , query ) <EOL> def ignore ( self , iq ) : <EOL> """<STR_LIT>""" <EOL> @ xmpp . iq ( '<STR_LIT>' ) <EOL> def vcard ( self , iq ) : <EOL> """<STR_LIT>""" <EOL> if iq . get ( '<STR_LIT:type>' ) == '<STR_LIT>' : <EOL> if ( iq . get ( '<STR_LIT:to>' ) == None ) : <EOL> target = iq . get ( '<STR_LIT>' ) <EOL> else : <EOL> target = iq . get ( '<STR_LIT:to>' ) <EOL> form_target = UCache . UCache . formalize_jid ( target ) <EOL> name = form_target . partition ( '<STR_LIT:@>' ) [ <NUM_LIT:0> ] <EOL> user = UserManager . UserManager . LoadUser ( name ) <EOL> info = user . GetInfo ( ) <EOL> desc = '''<STR_LIT>''' % ( info [ '<STR_LIT>' ] , info [ '<STR_LIT>' ] , info [ '<STR_LIT>' ] , <EOL> info [ '<STR_LIT>' ] , info [ '<STR_LIT>' ] , info [ '<STR_LIT>' ] , info [ '<STR_LIT>' ] ) <EOL> if ( '<STR_LIT>' in info ) : <EOL> desc += "<STR_LIT>" % ( info [ '<STR_LIT>' ] . replace ( '<STR_LIT:\n>' , '<STR_LIT:\r\n>' ) ) <EOL> vcard = self . E . vCard ( { '<STR_LIT>' : '<STR_LIT>' } , <EOL> self . E ( '<STR_LIT>' , name ) , <EOL> self . E ( '<STR_LIT>' , Util . Util . RemoveTags ( info [ '<STR_LIT>' ] ) ) , <EOL> self . E ( '<STR_LIT>' , Util . Util . RemoveTags ( desc ) ) ) <EOL> if ( iq . get ( '<STR_LIT:to>' ) == None ) : <EOL> return self . iq ( '<STR_LIT:result>' , iq , vcard ) <EOL> else : <EOL> return self . iq ( '<STR_LIT:result>' , iq , vcard , { '<STR_LIT>' : iq . get ( '<STR_LIT:to>' ) } ) <EOL> @ xmpp . iq ( '<STR_LIT>' % __disco_info_ns__ ) <EOL> def disco_info ( self , iq ) : <EOL> """<STR_LIT>""" <EOL> target = iq . get ( '<STR_LIT:to>' ) <EOL> if ( target . find ( '<STR_LIT:@>' ) < <NUM_LIT:0> ) : <EOL> query = self . E . query ( { '<STR_LIT>' : __disco_info_ns__ } , <EOL> self . E . identity ( { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:type>' : '<STR_LIT>' , <EOL> '<STR_LIT:name>' : Config . Config . GetString ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> } ) ) <EOL> features = [ __disco_info_ns__ , __disco_items_ns__ , __vcard_ns__ ] <EOL> for feature in features : <EOL> query . append ( self . E . feature ( { '<STR_LIT>' : feature } ) ) <EOL> else : <EOL> query = self . E . query ( { '<STR_LIT>' : __disco_info_ns__ } , <EOL> self . E . identity ( { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:type>' : '<STR_LIT>' , <EOL> '<STR_LIT:name>' : Config . Config . GetString ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> } ) ) <EOL> features = [ __disco_info_ns__ , __disco_items_ns__ , __vcard_ns__ ] <EOL> for feature in features : <EOL> query . append ( self . E . feature ( { '<STR_LIT>' : feature } ) ) <EOL> return self . iq ( '<STR_LIT:result>' , iq , query , { '<STR_LIT>' : target } ) <EOL> @ xmpp . iq ( '<STR_LIT>' % __disco_items_ns__ ) <EOL> def disco_items ( self , iq ) : <EOL> """<STR_LIT>""" <EOL> target = iq . get ( '<STR_LIT:to>' ) <EOL> if ( target . find ( '<STR_LIT:@>' ) < <NUM_LIT:0> ) : <EOL> query = self . E . query ( { '<STR_LIT>' : __disco_items_ns__ } ) <EOL> else : <EOL> query = self . E . query ( { '<STR_LIT>' : __disco_items_ns__ } ) <EOL> return self . iq ( '<STR_LIT:result>' , iq , query , { '<STR_LIT>' : target } ) </s>
<s> from __future__ import print_function <EOL> from __future__ import unicode_literals <EOL> from __future__ import division <EOL> from __future__ import absolute_import <EOL> from builtins import range <EOL> from future import standard_library <EOL> standard_library . install_aliases ( ) <EOL> import sys <EOL> PYTHON_VERSION = sys . version_info [ : <NUM_LIT:3> ] <EOL> PY2 = ( PYTHON_VERSION [ <NUM_LIT:0> ] == <NUM_LIT:2> ) <EOL> if PY2 : <EOL> if PYTHON_VERSION < ( <NUM_LIT:2> , <NUM_LIT:7> , <NUM_LIT:9> ) : <EOL> raise Exception ( '<STR_LIT>' ) <EOL> elif PYTHON_VERSION < ( <NUM_LIT:3> , <NUM_LIT:4> ) : <EOL> raise Exception ( '<STR_LIT>' ) <EOL> import hpOneView as hpov <EOL> from pprint import pprint <EOL> import json <EOL> from hpOneView . common import uri <EOL> import hpOneView . profile as profile <EOL> def acceptEULA ( con ) : <EOL> con . get_eula_status ( ) <EOL> try : <EOL> if con . get_eula_status ( ) is True : <EOL> print ( '<STR_LIT>' ) <EOL> con . set_eula ( '<STR_LIT>' ) <EOL> except Exception as e : <EOL> print ( '<STR_LIT>' ) <EOL> print ( e ) <EOL> def login ( con , credential ) : <EOL> try : <EOL> con . login ( credential ) <EOL> except : <EOL> print ( '<STR_LIT>' ) <EOL> def get_eg_uri_from_arg ( srv , name ) : <EOL> if srv and name : <EOL> if name . startswith ( '<STR_LIT>' ) and uri [ '<STR_LIT>' ] in name : <EOL> return name <EOL> else : <EOL> egs = srv . get_enclosure_groups ( ) <EOL> for eg in egs : <EOL> if eg [ '<STR_LIT:name>' ] == name : <EOL> return eg [ '<STR_LIT>' ] <EOL> return None <EOL> def get_sht_from_arg ( srv , name ) : <EOL> if srv and name : <EOL> if name . startswith ( '<STR_LIT>' ) and uri [ '<STR_LIT>' ] in name : <EOL> return name <EOL> else : <EOL> shts = srv . get_server_hardware_types ( ) <EOL> for sht in shts : <EOL> if sht [ '<STR_LIT:name>' ] == name : <EOL> return sht <EOL> return None <EOL> def define_profile_template ( <EOL> srv , <EOL> name , <EOL> desc , <EOL> sp_desc , <EOL> server_hwt , <EOL> enc_group , <EOL> affinity , <EOL> hide_flexnics , <EOL> conn_list , <EOL> fw_settings , <EOL> boot , <EOL> bootmode ) : <EOL> if conn_list : <EOL> conn = json . loads ( open ( conn_list ) . read ( ) ) <EOL> else : <EOL> conn = [ ] <EOL> profile_template = srv . create_server_profile_template ( <EOL> name = name , <EOL> description = desc , <EOL> serverProfileDescription = sp_desc , <EOL> serverHardwareTypeUri = server_hwt , <EOL> enclosureGroupUri = enc_group , <EOL> affinity = affinity , <EOL> hideUnusedFlexNics = hide_flexnics , <EOL> profileConnectionV4 = conn , <EOL> firmwareSettingsV3 = fw_settings , <EOL> bootSettings = boot , <EOL> bootModeSetting = bootmode ) <EOL> if '<STR_LIT>' in profile_template : <EOL> print ( '<STR_LIT>' , profile_template [ '<STR_LIT:name>' ] ) <EOL> print ( '<STR_LIT>' , profile_template [ '<STR_LIT:type>' ] ) <EOL> print ( '<STR_LIT>' , profile_template [ '<STR_LIT:description>' ] ) <EOL> print ( '<STR_LIT>' , profile_template [ '<STR_LIT>' ] ) <EOL> print ( '<STR_LIT>' ) <EOL> for connection in profile_template [ '<STR_LIT>' ] : <EOL> print ( '<STR_LIT>' , connection [ '<STR_LIT:name>' ] ) <EOL> print ( '<STR_LIT>' , connection [ '<STR_LIT>' ] ) <EOL> print ( '<STR_LIT>' , connection [ '<STR_LIT>' ] ) <EOL> print ( '<STR_LIT>' ) <EOL> print ( '<STR_LIT>' , profile_template [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) <EOL> print ( '<STR_LIT>' , profile_template [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) <EOL> print ( '<STR_LIT>' , profile_template [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) <EOL> print ( '<STR_LIT>' ) <EOL> print ( '<STR_LIT>' , profile_template [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) <EOL> print ( '<STR_LIT>' , profile_template [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) <EOL> print ( '<STR_LIT>' ) <EOL> print ( '<STR_LIT>' , profile_template [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) <EOL> print ( '<STR_LIT>' , profile_template [ '<STR_LIT>' ] [ '<STR_LIT>' ] , '<STR_LIT:\n>' ) <EOL> else : <EOL> pprint ( profile_template ) <EOL> def main ( ) : <EOL> parser = argparse . ArgumentParser ( add_help = True , <EOL> formatter_class = argparse . RawTextHelpFormatter , <EOL> description = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:host>' , required = True , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:user>' , required = False , <EOL> default = '<STR_LIT>' , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = True , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT:-c>' , dest = '<STR_LIT>' , required = False , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:name>' , <EOL> required = True , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , <EOL> required = False , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , <EOL> required = False , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = True , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = True , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , <EOL> required = False , choices = [ '<STR_LIT>' , '<STR_LIT>' ] , <EOL> default = '<STR_LIT>' , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , <EOL> required = False , choices = [ '<STR_LIT:true>' , '<STR_LIT:false>' ] , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , <EOL> required = False , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , <EOL> action = '<STR_LIT:store_true>' , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , <EOL> nargs = '<STR_LIT:+>' , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , <EOL> choices = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] , <EOL> default = '<STR_LIT>' , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , <EOL> choices = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' ] , <EOL> default = '<STR_LIT>' , <EOL> help = '''<STR_LIT>''' ) <EOL> args = parser . parse_args ( ) <EOL> credential = { '<STR_LIT>' : args . user , '<STR_LIT:password>' : args . passwd } <EOL> con = hpov . connection ( args . host ) <EOL> srv = hpov . servers ( con ) <EOL> sts = hpov . settings ( con ) <EOL> if args . proxy : <EOL> con . set_proxy ( args . proxy . split ( '<STR_LIT::>' ) [ <NUM_LIT:0> ] , args . proxy . split ( '<STR_LIT::>' ) [ <NUM_LIT:1> ] ) <EOL> if args . cert : <EOL> con . set_trusted_ssl_bundle ( args . cert ) <EOL> login ( con , credential ) <EOL> acceptEULA ( con ) <EOL> eg_uri = get_eg_uri_from_arg ( srv , args . enc_group ) <EOL> sht = get_sht_from_arg ( srv , args . server_hwt ) <EOL> fw_settings = profile . make_firmware_dict ( sts , args . baseline ) <EOL> boot , bootmode = profile . make_boot_settings_dict ( srv , sht , args . disable_manage_boot , <EOL> args . boot_order , args . boot_mode , args . pxe ) <EOL> define_profile_template ( srv , <EOL> args . name , <EOL> args . desc , <EOL> args . sp_desc , <EOL> sht [ '<STR_LIT>' ] , <EOL> eg_uri , <EOL> args . affinity , <EOL> args . hide_flexnics , <EOL> args . conn_list , <EOL> fw_settings , <EOL> boot , <EOL> bootmode ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> import argparse <EOL> sys . exit ( main ( ) ) </s>
<s> from __future__ import print_function <EOL> from __future__ import unicode_literals <EOL> from __future__ import division <EOL> from __future__ import absolute_import <EOL> from builtins import range <EOL> from future import standard_library <EOL> standard_library . install_aliases ( ) <EOL> import sys <EOL> PYTHON_VERSION = sys . version_info [ : <NUM_LIT:3> ] <EOL> PY2 = ( PYTHON_VERSION [ <NUM_LIT:0> ] == <NUM_LIT:2> ) <EOL> if PY2 : <EOL> if PYTHON_VERSION < ( <NUM_LIT:2> , <NUM_LIT:7> , <NUM_LIT:9> ) : <EOL> raise Exception ( '<STR_LIT>' ) <EOL> elif PYTHON_VERSION < ( <NUM_LIT:3> , <NUM_LIT:4> ) : <EOL> raise Exception ( '<STR_LIT>' ) <EOL> import hpOneView as hpov <EOL> from pprint import pprint <EOL> def acceptEULA ( con ) : <EOL> con . get_eula_status ( ) <EOL> try : <EOL> if con . get_eula_status ( ) is True : <EOL> print ( "<STR_LIT>" ) <EOL> con . set_eula ( '<STR_LIT>' ) <EOL> except Exception as e : <EOL> print ( '<STR_LIT>' ) <EOL> print ( e ) <EOL> def login ( con , credential ) : <EOL> try : <EOL> con . login ( credential ) <EOL> except : <EOL> print ( '<STR_LIT>' ) <EOL> def get_address_pools ( con , srv , types ) : <EOL> if types == '<STR_LIT>' or types == '<STR_LIT>' : <EOL> vmac = srv . get_vmac_pool ( ) <EOL> print ( ) <EOL> for key in sorted ( vmac ) : <EOL> print ( '<STR_LIT>' . format ( key , vmac [ key ] ) ) <EOL> if '<STR_LIT>' in vmac : <EOL> for uri in vmac [ '<STR_LIT>' ] : <EOL> ranges = con . get ( uri ) <EOL> print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) <EOL> print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) <EOL> print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) <EOL> if types == '<STR_LIT>' or types == '<STR_LIT>' : <EOL> vwwn = srv . get_vwwn_pool ( ) <EOL> print ( ) <EOL> for key in sorted ( vwwn ) : <EOL> print ( '<STR_LIT>' . format ( key , vwwn [ key ] ) ) <EOL> if '<STR_LIT>' in vwwn : <EOL> for uri in vwwn [ '<STR_LIT>' ] : <EOL> ranges = con . get ( uri ) <EOL> print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) <EOL> print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) <EOL> print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) <EOL> if types == '<STR_LIT>' or types == '<STR_LIT>' : <EOL> vsn = srv . get_vsn_pool ( ) <EOL> print ( ) <EOL> for key in sorted ( vsn ) : <EOL> print ( '<STR_LIT>' . format ( key , vsn [ key ] ) ) <EOL> if '<STR_LIT>' in vsn : <EOL> for uri in vsn [ '<STR_LIT>' ] : <EOL> ranges = con . get ( uri ) <EOL> print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) <EOL> print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) <EOL> print ( '<STR_LIT>' , ranges [ '<STR_LIT>' ] ) <EOL> def main ( ) : <EOL> parser = argparse . ArgumentParser ( add_help = True , <EOL> formatter_class = argparse . RawTextHelpFormatter , <EOL> description = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:host>' , required = True , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:user>' , required = False , <EOL> default = '<STR_LIT>' , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = True , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT:-c>' , dest = '<STR_LIT>' , required = False , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , <EOL> default = '<STR_LIT>' , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , <EOL> choices = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] , default = '<STR_LIT>' , <EOL> help = '''<STR_LIT>''' ) <EOL> args = parser . parse_args ( ) <EOL> credential = { '<STR_LIT>' : args . domain . upper ( ) , '<STR_LIT>' : args . user , '<STR_LIT:password>' : args . passwd } <EOL> con = hpov . connection ( args . host ) <EOL> srv = hpov . servers ( con ) <EOL> if args . proxy : <EOL> con . set_proxy ( args . proxy . split ( '<STR_LIT::>' ) [ <NUM_LIT:0> ] , args . proxy . split ( '<STR_LIT::>' ) [ <NUM_LIT:1> ] ) <EOL> if args . cert : <EOL> con . set_trusted_ssl_bundle ( args . cert ) <EOL> login ( con , credential ) <EOL> acceptEULA ( con ) <EOL> get_address_pools ( con , srv , args . types ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> import sys <EOL> import argparse <EOL> sys . exit ( main ( ) ) </s>
<s> from __future__ import print_function <EOL> from __future__ import unicode_literals <EOL> from __future__ import division <EOL> from __future__ import absolute_import <EOL> from builtins import range <EOL> from future import standard_library <EOL> standard_library . install_aliases ( ) <EOL> import sys <EOL> import re <EOL> PYTHON_VERSION = sys . version_info [ : <NUM_LIT:3> ] <EOL> PY2 = ( PYTHON_VERSION [ <NUM_LIT:0> ] == <NUM_LIT:2> ) <EOL> if PY2 : <EOL> if PYTHON_VERSION < ( <NUM_LIT:2> , <NUM_LIT:7> , <NUM_LIT:9> ) : <EOL> raise Exception ( '<STR_LIT>' ) <EOL> elif PYTHON_VERSION < ( <NUM_LIT:3> , <NUM_LIT:4> ) : <EOL> raise Exception ( '<STR_LIT>' ) <EOL> import hpOneView as hpov <EOL> from pprint import pprint <EOL> def acceptEULA ( con ) : <EOL> con . get_eula_status ( ) <EOL> try : <EOL> if con . get_eula_status ( ) is True : <EOL> print ( '<STR_LIT>' ) <EOL> con . set_eula ( '<STR_LIT>' ) <EOL> except Exception as e : <EOL> print ( '<STR_LIT>' ) <EOL> print ( e ) <EOL> def login ( con , credential ) : <EOL> try : <EOL> con . login ( credential ) <EOL> except : <EOL> print ( '<STR_LIT>' ) <EOL> def get_managed_sans ( fcs ) : <EOL> sans = fcs . get_managed_sans ( ) <EOL> pprint ( sans ) <EOL> def main ( ) : <EOL> parser = argparse . ArgumentParser ( add_help = True , <EOL> formatter_class = argparse . RawTextHelpFormatter , <EOL> description = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:host>' , required = True , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:user>' , required = False , <EOL> default = '<STR_LIT>' , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = True , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT:-c>' , dest = '<STR_LIT>' , required = False , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , <EOL> default = '<STR_LIT>' , <EOL> help = '''<STR_LIT>''' ) <EOL> args = parser . parse_args ( ) <EOL> credential = { '<STR_LIT>' : args . domain . upper ( ) , '<STR_LIT>' : args . user , '<STR_LIT:password>' : args . passwd } <EOL> con = hpov . connection ( args . host ) <EOL> fcs = hpov . fcsans ( con ) <EOL> if args . proxy : <EOL> con . set_proxy ( args . proxy . split ( '<STR_LIT::>' ) [ <NUM_LIT:0> ] , args . proxy . split ( '<STR_LIT::>' ) [ <NUM_LIT:1> ] ) <EOL> if args . cert : <EOL> con . set_trusted_ssl_bundle ( args . cert ) <EOL> login ( con , credential ) <EOL> acceptEULA ( con ) <EOL> get_managed_sans ( fcs ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> import sys <EOL> import argparse <EOL> sys . exit ( main ( ) ) </s>
<s> from __future__ import print_function <EOL> from __future__ import unicode_literals <EOL> from __future__ import division <EOL> from __future__ import absolute_import <EOL> from builtins import range <EOL> from future import standard_library <EOL> standard_library . install_aliases ( ) <EOL> import sys <EOL> PYTHON_VERSION = sys . version_info [ : <NUM_LIT:3> ] <EOL> PY2 = ( PYTHON_VERSION [ <NUM_LIT:0> ] == <NUM_LIT:2> ) <EOL> if PY2 : <EOL> if PYTHON_VERSION < ( <NUM_LIT:2> , <NUM_LIT:7> , <NUM_LIT:9> ) : <EOL> raise Exception ( '<STR_LIT>' ) <EOL> elif PYTHON_VERSION < ( <NUM_LIT:3> , <NUM_LIT:4> ) : <EOL> raise Exception ( '<STR_LIT>' ) <EOL> import hpOneView as hpov <EOL> from pprint import pprint <EOL> def acceptEULA ( con ) : <EOL> con . get_eula_status ( ) <EOL> try : <EOL> if con . get_eula_status ( ) is True : <EOL> print ( '<STR_LIT>' ) <EOL> con . set_eula ( '<STR_LIT>' ) <EOL> except Exception as e : <EOL> print ( '<STR_LIT>' ) <EOL> print ( e ) <EOL> def login ( con , credential ) : <EOL> try : <EOL> con . login ( credential ) <EOL> except : <EOL> print ( '<STR_LIT>' ) <EOL> def getpolicy ( sts ) : <EOL> policy = sts . get_storage_vol_template_policy ( ) <EOL> print ( policy [ '<STR_LIT:value>' ] ) <EOL> def main ( ) : <EOL> parser = argparse . ArgumentParser ( add_help = True , <EOL> formatter_class = argparse . RawTextHelpFormatter , <EOL> description = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:host>' , required = True , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT:user>' , required = False , <EOL> default = '<STR_LIT>' , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = True , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT:-c>' , dest = '<STR_LIT>' , required = False , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , <EOL> help = '''<STR_LIT>''' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , required = False , <EOL> default = '<STR_LIT>' , <EOL> help = '''<STR_LIT>''' ) <EOL> args = parser . parse_args ( ) <EOL> credential = { '<STR_LIT>' : args . domain . upper ( ) , '<STR_LIT>' : args . user , '<STR_LIT:password>' : args . passwd } <EOL> con = hpov . connection ( args . host ) <EOL> sts = hpov . settings ( con ) <EOL> if args . proxy : <EOL> con . set_proxy ( args . proxy . split ( '<STR_LIT::>' ) [ <NUM_LIT:0> ] , args . proxy . split ( '<STR_LIT::>' ) [ <NUM_LIT:1> ] ) <EOL> if args . cert : <EOL> con . set_trusted_ssl_bundle ( args . cert ) <EOL> login ( con , credential ) <EOL> acceptEULA ( con ) <EOL> getpolicy ( sts ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> import sys <EOL> import argparse <EOL> sys . exit ( main ( ) ) </s>
<s> """<STR_LIT>""" <EOL> from __future__ import unicode_literals <EOL> from __future__ import print_function <EOL> from __future__ import division <EOL> from __future__ import absolute_import <EOL> from future import standard_library <EOL> standard_library . install_aliases ( ) <EOL> from pprint import pprint <EOL> __title__ = '<STR_LIT>' <EOL> __version__ = '<STR_LIT>' <EOL> __copyright__ = '<STR_LIT>' '<STR_LIT>' <EOL> __license__ = '<STR_LIT>' <EOL> __status__ = '<STR_LIT>' <EOL> from hpOneView . common import * <EOL> from hpOneView . connection import * <EOL> from hpOneView . activity import * <EOL> from hpOneView . exceptions import * <EOL> class servers ( object ) : <EOL> def __init__ ( self , con ) : <EOL> self . _con = con <EOL> self . _activity = activity ( con ) <EOL> def get_connections ( self , filter = '<STR_LIT>' ) : <EOL> """<STR_LIT>""" <EOL> return get_members ( self . _con . get ( uri [ '<STR_LIT>' ] + filter ) ) <EOL> def get_connection ( self , server ) : <EOL> """<STR_LIT>""" <EOL> body = self . _con . get ( server [ '<STR_LIT>' ] ) <EOL> return body <EOL> def get_server_by_bay ( self , baynum ) : <EOL> servers = get_members ( self . _con . get ( uri [ '<STR_LIT>' ] ) ) <EOL> for server in servers : <EOL> if server [ '<STR_LIT>' ] == baynum : <EOL> return server <EOL> def get_server_by_name ( self , name ) : <EOL> servers = get_members ( self . _con . get ( uri [ '<STR_LIT>' ] ) ) <EOL> for server in servers : <EOL> if server [ '<STR_LIT:name>' ] == name : <EOL> return server <EOL> def get_available_servers ( self , server_hardware_type = None , <EOL> enclosure_group = None , server_profile = None ) : <EOL> filters = [ ] <EOL> if server_hardware_type : <EOL> filters . append ( '<STR_LIT>' + server_hardware_type [ '<STR_LIT>' ] ) <EOL> if enclosure_group : <EOL> filters . append ( '<STR_LIT>' + enclosure_group [ '<STR_LIT>' ] ) <EOL> if server_profile : <EOL> filters . append ( '<STR_LIT>' + server_profile [ '<STR_LIT>' ] ) <EOL> query_string = '<STR_LIT>' <EOL> if filters : <EOL> query_string = '<STR_LIT:?>' + '<STR_LIT:&>' . join ( filters ) <EOL> return self . _con . get ( uri [ '<STR_LIT>' ] + query_string ) <EOL> def get_servers ( self ) : <EOL> return get_members ( self . _con . get ( uri [ '<STR_LIT>' ] ) ) <EOL> def get_utilization ( self , server ) : <EOL> """<STR_LIT>""" <EOL> body = self . _con . get ( server [ '<STR_LIT>' ] + '<STR_LIT>' ) <EOL> return body <EOL> def get_env_conf ( self , server ) : <EOL> """<STR_LIT>""" <EOL> body = self . _con . get ( server [ '<STR_LIT>' ] + '<STR_LIT>' ) <EOL> return body <EOL> def set_server_powerstate ( self , server , state , force = False , blocking = True , <EOL> verbose = False ) : <EOL> if state == '<STR_LIT>' and force is True : <EOL> powerRequest = make_powerstate_dict ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> elif state == '<STR_LIT>' and force is False : <EOL> powerRequest = make_powerstate_dict ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> elif state == '<STR_LIT>' : <EOL> powerRequest = make_powerstate_dict ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> elif state == '<STR_LIT>' : <EOL> powerRequest = make_powerstate_dict ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> task , body = self . _con . put ( server [ '<STR_LIT>' ] + '<STR_LIT>' , powerRequest ) <EOL> if blocking is True : <EOL> task = self . _activity . wait4task ( task , tout = <NUM_LIT> , verbose = verbose ) <EOL> return task <EOL> def delete_server ( self , server , force = False , blocking = True , verbose = False ) : <EOL> if force : <EOL> task , body = self . _con . delete ( server [ '<STR_LIT>' ] + '<STR_LIT>' ) <EOL> else : <EOL> task , body = self . _con . delete ( server [ '<STR_LIT>' ] ) <EOL> if blocking is True : <EOL> task = self . _activity . wait4task ( task , tout = <NUM_LIT> , verbose = verbose ) <EOL> return task <EOL> def update_server ( self , server ) : <EOL> task , body = self . _con . put ( server [ '<STR_LIT>' ] , server ) <EOL> return body <EOL> def add_server ( self , server , blocking = True , verbose = False ) : <EOL> task , body = self . _con . post ( uri [ '<STR_LIT>' ] , server ) <EOL> if blocking is True : <EOL> task = self . _activity . wait4task ( task , tout = <NUM_LIT> , verbose = verbose ) <EOL> if '<STR_LIT:type>' in task and task [ '<STR_LIT:type>' ] . startswith ( '<STR_LIT>' ) : <EOL> entity = self . _activity . get_task_associated_resource ( task ) <EOL> server = self . _con . get ( entity [ '<STR_LIT>' ] ) <EOL> return server <EOL> return task <EOL> def get_server_schema ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . _con . get ( uri [ '<STR_LIT>' ] + '<STR_LIT>' ) <EOL> def get_bios ( self , server ) : <EOL> """<STR_LIT>""" <EOL> return self . _con . get ( server [ '<STR_LIT>' ] + '<STR_LIT>' ) <EOL> def get_ilo_sso_url ( self , server ) : <EOL> """<STR_LIT>""" <EOL> return self . _con . get ( server [ '<STR_LIT>' ] + '<STR_LIT>' ) <EOL> def get_java_remote_console_url ( self , server ) : <EOL> """<STR_LIT>""" <EOL> return self . _con . get ( server [ '<STR_LIT>' ] + '<STR_LIT>' ) <EOL> def get_remote_console_url ( self , server ) : <EOL> """<STR_LIT>""" <EOL> return self . _con . get ( server [ '<STR_LIT>' ] + '<STR_LIT>' ) <EOL> def get_server_hardware_types ( self ) : <EOL> """<STR_LIT>""" <EOL> body = self . _con . get ( uri [ '<STR_LIT>' ] ) <EOL> return get_members ( body ) <EOL> def remove_server_hardware_type ( self , server_hardware_type , force = False , blocking = True , verbose = False ) : <EOL> """<STR_LIT>""" <EOL> if force : <EOL> task , body = self . _con . delete ( server_hardware_type [ '<STR_LIT>' ] + '<STR_LIT>' ) <EOL> else : <EOL> task , body = self . _con . delete ( server_hardware_type [ '<STR_LIT>' ] ) <EOL> if blocking is True : <EOL> task = self . _activity . wait4task ( task , tout = <NUM_LIT> , verbose = verbose ) <EOL> return task <EOL> def get_server_type_schema ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . _con . get ( uri [ '<STR_LIT>' ] + '<STR_LIT>' ) <EOL> def get_server_hardware_type ( self , server_type ) : <EOL> """<STR_LIT>""" <EOL> return self . _con . get ( server_type [ '<STR_LIT>' ] ) <EOL> def set_server_hardware_type ( self , server_hardware_type , name , description ) : <EOL> """<STR_LIT>""" <EOL> request = make_server_type_dict ( name , description ) <EOL> task , body = self . _con . put ( server_hardware_type [ '<STR_LIT>' ] , request ) <EOL> return task <EOL> def create_server_profile ( self , <EOL> affinity = '<STR_LIT>' , <EOL> biosSettings = None , <EOL> bootSettings = None , <EOL> bootModeSetting = None , <EOL> profileConnectionV4 = None , <EOL> description = None , <EOL> firmwareSettingsV3 = None , <EOL> hideUnusedFlexNics = True , <EOL> localStorageSettingsV3 = None , <EOL> macType = '<STR_LIT>' , <EOL> name = None , <EOL> sanStorageV3 = None , <EOL> serialNumber = None , <EOL> serialNumberType = '<STR_LIT>' , <EOL> serverHardwareTypeUri = None , <EOL> serverHardwareUri = None , <EOL> serverProfileTemplateUri = None , <EOL> uuid = None , <EOL> wwnType = '<STR_LIT>' , <EOL> blocking = True , verbose = False ) : <EOL> """<STR_LIT>""" <EOL> profile = make_ServerProfileV5 ( affinity , biosSettings , bootSettings , <EOL> bootModeSetting , profileConnectionV4 , <EOL> description , firmwareSettingsV3 , <EOL> hideUnusedFlexNics , <EOL> localStorageSettingsV3 , macType , name , <EOL> sanStorageV3 , serialNumber , <EOL> serialNumberType , serverHardwareTypeUri , <EOL> serverHardwareUri , <EOL> serverProfileTemplateUri , uuid , wwnType ) <EOL> task , body = self . _con . post ( uri [ '<STR_LIT>' ] , profile ) <EOL> if profile [ '<STR_LIT>' ] is None : <EOL> tout = <NUM_LIT> <EOL> else : <EOL> tout = <NUM_LIT> <EOL> if blocking is True : <EOL> task = self . _activity . wait4task ( task , tout , verbose = verbose ) <EOL> if '<STR_LIT:type>' in task and task [ '<STR_LIT:type>' ] . startswith ( '<STR_LIT>' ) : <EOL> entity = self . _activity . get_task_associated_resource ( task ) <EOL> profile = self . _con . get ( entity [ '<STR_LIT>' ] ) <EOL> return profile <EOL> return task <EOL> def post_server_profile ( self , profile , blocking = True , verbose = False ) : <EOL> """<STR_LIT>""" <EOL> task , body = self . _con . post ( uri [ '<STR_LIT>' ] , profile ) <EOL> if profile [ '<STR_LIT>' ] is None : <EOL> tout = <NUM_LIT> <EOL> else : <EOL> tout = <NUM_LIT> <EOL> if blocking is True : <EOL> task = self . _activity . wait4task ( task , tout , verbose = verbose ) <EOL> if '<STR_LIT:type>' in task and task [ '<STR_LIT:type>' ] . startswith ( '<STR_LIT>' ) : <EOL> entity = self . _activity . get_task_associated_resource ( task ) <EOL> profile = self . _con . get ( entity [ '<STR_LIT>' ] ) <EOL> return profile <EOL> return task <EOL> def remove_server_profile ( self , profile , force = False , blocking = True , verbose = False ) : <EOL> if force : <EOL> task , body = self . _con . delete ( profile [ '<STR_LIT>' ] + '<STR_LIT>' ) <EOL> else : <EOL> task , body = self . _con . delete ( profile [ '<STR_LIT>' ] ) <EOL> if blocking is True : <EOL> task = self . _activity . wait4task ( task , tout = <NUM_LIT> , verbose = verbose ) <EOL> return task <EOL> def get_server_profiles ( self ) : <EOL> body = self . _con . get ( uri [ '<STR_LIT>' ] ) <EOL> return get_members ( body ) <EOL> def update_server_profile ( self , profile , blocking = True , verbose = False ) : <EOL> task , body = self . _con . put ( profile [ '<STR_LIT>' ] , profile ) <EOL> try : <EOL> if profile [ '<STR_LIT>' ] [ '<STR_LIT>' ] is None : <EOL> tout = <NUM_LIT> <EOL> else : <EOL> tout = <NUM_LIT> <EOL> except Exception : <EOL> tout = <NUM_LIT> <EOL> if blocking is True : <EOL> task = self . _activity . wait4task ( task , tout = tout , verbose = verbose ) <EOL> profileResource = self . _activity . get_task_associated_resource ( task ) <EOL> profile = self . _con . get ( profileResource [ '<STR_LIT>' ] ) <EOL> return profile <EOL> def update_server_profile_from_template ( self , profile , blocking = True , verbose = False ) : <EOL> patch_request = [ { '<STR_LIT>' : '<STR_LIT:replace>' , '<STR_LIT:path>' : '<STR_LIT>' , '<STR_LIT:value>' : '<STR_LIT>' } ] <EOL> task , body = self . _con . patch ( profile [ '<STR_LIT>' ] , patch_request ) <EOL> try : <EOL> if profile [ '<STR_LIT>' ] [ '<STR_LIT>' ] is None : <EOL> tout = <NUM_LIT> <EOL> else : <EOL> tout = <NUM_LIT> <EOL> except Exception : <EOL> tout = <NUM_LIT> <EOL> if blocking is True : <EOL> task = self . _activity . wait4task ( task , tout = tout , verbose = verbose ) <EOL> profileResource = self . _activity . get_task_associated_resource ( task ) <EOL> profile = self . _con . get ( profileResource [ '<STR_LIT>' ] ) <EOL> return profile <EOL> def get_server_profile_by_name ( self , name ) : <EOL> body = self . _con . get_entity_byfield ( uri [ '<STR_LIT>' ] , '<STR_LIT:name>' , name ) <EOL> return body <EOL> def get_profile_message ( self , profile ) : <EOL> """<STR_LIT>""" <EOL> message = self . _con . get ( profile [ '<STR_LIT>' ] + '<STR_LIT>' ) <EOL> return message <EOL> def get_profile_compliance_preview ( self , profile ) : <EOL> """<STR_LIT>""" <EOL> return self . _con . get ( profile [ '<STR_LIT>' ] + '<STR_LIT>' ) <EOL> def create_server_profile_template ( <EOL> self , <EOL> name = None , <EOL> description = None , <EOL> serverProfileDescription = None , <EOL> serverHardwareTypeUri = None , <EOL> enclosureGroupUri = None , <EOL> affinity = None , <EOL> hideUnusedFlexNics = None , <EOL> profileConnectionV4 = None , <EOL> firmwareSettingsV3 = None , <EOL> bootSettings = None , <EOL> bootModeSetting = None , <EOL> blocking = True , <EOL> verbose = False ) : <EOL> """<STR_LIT>""" <EOL> profile_template = make_ServerProfileTemplateV1 ( name , <EOL> description , <EOL> serverProfileDescription , <EOL> serverHardwareTypeUri , <EOL> enclosureGroupUri , <EOL> affinity , <EOL> hideUnusedFlexNics , <EOL> profileConnectionV4 , <EOL> firmwareSettingsV3 , <EOL> bootSettings , <EOL> bootModeSetting ) <EOL> task , body = self . _con . post ( uri [ '<STR_LIT>' ] , profile_template ) <EOL> tout = <NUM_LIT> <EOL> if blocking is True : <EOL> task = self . _activity . wait4task ( task , tout , verbose = verbose ) <EOL> if '<STR_LIT:type>' in task and task [ '<STR_LIT:type>' ] . startswith ( '<STR_LIT>' ) : <EOL> entity = self . _activity . get_task_associated_resource ( task ) <EOL> profile_template = self . _con . get ( entity [ '<STR_LIT>' ] ) <EOL> return profile_template <EOL> return task <EOL> def remove_server_profile_template ( self , profile_template , blocking = True , verbose = False ) : <EOL> task , body = self . _con . delete ( profile_template [ '<STR_LIT>' ] ) <EOL> if blocking is True : <EOL> task = self . _activity . wait4task ( task , tout = <NUM_LIT> , verbose = verbose ) <EOL> return task <EOL> return body <EOL> def get_server_profile_templates ( self ) : <EOL> body = self . _con . get ( uri [ '<STR_LIT>' ] ) <EOL> return get_members ( body ) <EOL> def get_server_profile_template_by_name ( self , name ) : <EOL> body = self . _con . get_entity_byfield ( uri [ '<STR_LIT>' ] , '<STR_LIT:name>' , name ) <EOL> return body <EOL> def update_server_profile_template ( self , profile_template , blocking = True , verbose = False ) : <EOL> task , body = self . _con . put ( profile_template [ '<STR_LIT>' ] , profile_template ) <EOL> tout = <NUM_LIT> <EOL> if blocking is True : <EOL> task = self . _activity . wait4task ( task , tout = tout , verbose = verbose ) <EOL> profileTemplateResource = self . _activity . get_task_associated_resource ( task ) <EOL> profile = self . _con . get ( profileTemplateResource [ '<STR_LIT>' ] ) <EOL> return profile_template <EOL> def get_server_profile_from_template ( self , profile_template ) : <EOL> profile = self . _con . get ( profile_template [ '<STR_LIT>' ] + '<STR_LIT>' ) <EOL> return profile <EOL> def get_enclosures ( self ) : <EOL> body = self . _con . get ( uri [ '<STR_LIT>' ] ) <EOL> return get_members ( body ) <EOL> def add_enclosure ( self , enclosure , blocking = True , verbose = False ) : <EOL> task , body = self . _con . post ( uri [ '<STR_LIT>' ] , enclosure ) <EOL> if enclosure [ '<STR_LIT:state>' ] is '<STR_LIT>' : <EOL> tout = <NUM_LIT> <EOL> elif enclosure [ '<STR_LIT>' ] is None : <EOL> tout = <NUM_LIT> <EOL> else : <EOL> tout = <NUM_LIT> <EOL> if blocking is True : <EOL> task = self . _activity . wait4task ( task , tout , verbose = verbose ) <EOL> if '<STR_LIT:type>' in task and task [ '<STR_LIT:type>' ] . startswith ( '<STR_LIT>' ) : <EOL> entity = self . _activity . get_task_associated_resource ( task ) <EOL> enclosure = self . _con . get ( entity [ '<STR_LIT>' ] ) <EOL> return enclosure <EOL> return task <EOL> def remove_enclosure ( self , enclosure , force = False , blocking = True , <EOL> verbose = False ) : <EOL> if force : <EOL> task , body = self . _con . delete ( enclosure [ '<STR_LIT>' ] + '<STR_LIT>' ) <EOL> else : <EOL> task , body = self . _con . delete ( enclosure [ '<STR_LIT>' ] ) <EOL> if blocking is True : <EOL> task = self . _activity . wait4task ( task , tout = <NUM_LIT> , verbose = verbose ) <EOL> return task <EOL> def create_enclosure_group ( self , associatedLIGs , name , <EOL> powerMode = '<STR_LIT>' ) : <EOL> """<STR_LIT>""" <EOL> egroup = make_EnclosureGroupV200 ( associatedLIGs , name , powerMode ) <EOL> task , body = self . _con . post ( uri [ '<STR_LIT>' ] , egroup ) <EOL> return body <EOL> def delete_enclosure_group ( self , egroup ) : <EOL> self . _con . delete ( egroup [ '<STR_LIT>' ] ) <EOL> def get_enclosure_groups ( self ) : <EOL> return get_members ( self . _con . get ( uri [ '<STR_LIT>' ] ) ) <EOL> def update_enclosure_group ( self , enclosuregroup ) : <EOL> task , body = self . _con . put ( enclosuregroup [ '<STR_LIT>' ] , enclosuregroup ) <EOL> return body <EOL> def get_pool ( self , pooltype ) : <EOL> body = self . _con . get ( uri [ '<STR_LIT>' ] + '<STR_LIT:/>' + pooltype ) <EOL> return body <EOL> def get_vmac_pool ( self ) : <EOL> body = self . _con . get ( uri [ '<STR_LIT>' ] ) <EOL> return body <EOL> def get_vwwn_pool ( self ) : <EOL> body = self . _con . get ( uri [ '<STR_LIT>' ] ) <EOL> return body <EOL> def get_vsn_pool ( self ) : <EOL> body = self . _con . get ( uri [ '<STR_LIT>' ] ) <EOL> return body <EOL> def get_profile_networks ( self ) : <EOL> body = self . _con . get ( uri [ '<STR_LIT>' ] ) <EOL> return body <EOL> def get_profile_schema ( self ) : <EOL> return self . _con . get ( uri [ '<STR_LIT>' ] ) <EOL> def get_profile_available_servers ( self ) : <EOL> body = self . _con . get ( uri [ '<STR_LIT>' ] ) <EOL> return body <EOL> def get_profile_available_storage_systems ( self ) : <EOL> body = self . _con . get ( uri [ '<STR_LIT>' ] ) <EOL> return body <EOL> def get_profile_ports ( self ) : <EOL> body = self . _con . get ( uri [ '<STR_LIT>' ] ) <EOL> return body <EOL> def allocate_pool_ids ( self , url , count ) : <EOL> allocatorUrl = '<STR_LIT>' % url <EOL> allocatorBody = { '<STR_LIT:count>' : count } <EOL> task , body = self . _con . put ( allocatorUrl , allocatorBody ) <EOL> return body <EOL> def release_pool_ids ( self , url , idList ) : <EOL> collectorUrl = '<STR_LIT>' % url <EOL> collectorBody = { '<STR_LIT>' : idList } <EOL> task , body = self . _con . put ( collectorUrl , collectorBody ) <EOL> return body <EOL> def allocate_range_ids ( self , allocatorUrl , count ) : <EOL> task , body = self . _con . put ( allocatorUrl , { '<STR_LIT:count>' : count } ) <EOL> return body <EOL> def release_range_ids ( self , collectorUrl , idList ) : <EOL> task , body = self . _con . put ( collectorUrl , { '<STR_LIT>' : idList } ) <EOL> return body <EOL> def enable_range ( self , url ) : <EOL> prange = self . _con . get ( url ) <EOL> prange [ '<STR_LIT>' ] = True <EOL> task , body = self . _con . put ( url , prange ) <EOL> return body <EOL> def disable_range ( self , url ) : <EOL> prange = self . _con . get ( url ) <EOL> prange [ '<STR_LIT>' ] = False <EOL> task , body = self . _con . put ( url , prange ) <EOL> return body </s>
<s> """<STR_LIT>""" <EOL> import os <EOL> import re <EOL> import sys <EOL> import json <EOL> import locale <EOL> import zipfile <EOL> import logging <EOL> import textwrap <EOL> import validictory <EOL> from . sharedtypes import JSONEncoder <EOL> from ilorest . rest . v1_helper import ( RisObject ) <EOL> LOGGER = logging . getLogger ( __name__ ) <EOL> class ValidationError ( Exception ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> class SchemaValidationError ( ValidationError ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> class RegistryValidationError ( ValidationError ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , msg , regentry = None , selector = None ) : <EOL> super ( RegistryValidationError , self ) . __init__ ( msg ) <EOL> self . reg = regentry <EOL> self . sel = selector <EOL> class UnknownValidatorError ( Exception ) : <EOL> """<STR_LIT>""" <EOL> """<STR_LIT>""" <EOL> class ValidationManager ( object ) : <EOL> """<STR_LIT>""" <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , local_path , bios_local_path , romfamily = None , biosversion = None , iloversion = None , monolith = None ) : <EOL> super ( ValidationManager , self ) . __init__ ( ) <EOL> defaultilopath = None <EOL> defaultbiospath = None <EOL> schemamainfolder = None <EOL> if float ( iloversion ) < <NUM_LIT> : <EOL> if os . name == '<STR_LIT>' : <EOL> defaultilopath = r"<STR_LIT>" <EOL> defaultbiospath = r"<STR_LIT>" <EOL> schemamainfolder = os . path . dirname ( sys . executable ) <EOL> else : <EOL> defaultilopath = "<STR_LIT>" <EOL> defaultbiospath = "<STR_LIT>" <EOL> schemamainfolder = "<STR_LIT>" <EOL> if not local_path : <EOL> if not os . path . isdir ( defaultilopath ) : <EOL> ilozip = self . getiloziplocation ( schemamainfolder , iloversion ) <EOL> if ilozip and os . path . exists ( ilozip ) : <EOL> with zipfile . ZipFile ( os . path . join ( schemamainfolder , ilozip ) , "<STR_LIT:r>" ) as zfile : <EOL> zfile . extractall ( os . path . join ( schemamainfolder , "<STR_LIT>" ) ) <EOL> local_path = os . path . join ( schemamainfolder , u'<STR_LIT>' ) <EOL> else : <EOL> raise SchemaValidationError ( u'<STR_LIT>' '<STR_LIT>' '<STR_LIT>' '<STR_LIT>' ) <EOL> else : <EOL> local_path = defaultilopath <EOL> else : <EOL> if not os . path . isdir ( local_path ) : <EOL> raise SchemaValidationError ( u"<STR_LIT>" <EOL> "<STR_LIT>" % local_path ) <EOL> if not bios_local_path : <EOL> if not os . path . isdir ( defaultbiospath ) : <EOL> bioszip = self . getbiosziplocation ( romfamily , schemamainfolder , biosversion ) <EOL> if bioszip and os . path . exists ( bioszip ) : <EOL> with zipfile . ZipFile ( <EOL> os . path . join ( schemamainfolder , bioszip ) , "<STR_LIT:r>" ) as zfile : <EOL> zfile . extractall ( os . path . join ( schemamainfolder , "<STR_LIT>" ) ) <EOL> bios_local_path = os . path . join ( schemamainfolder , u'<STR_LIT>' ) <EOL> else : <EOL> raise SchemaValidationError ( u'<STR_LIT>' '<STR_LIT>' '<STR_LIT>' '<STR_LIT>' ) <EOL> else : <EOL> bios_local_path = defaultbiospath <EOL> else : <EOL> if not os . path . isdir ( bios_local_path ) : <EOL> raise SchemaValidationError ( u"<STR_LIT>" "<STR_LIT>" % bios_local_path ) <EOL> else : <EOL> if monolith . is_redfish : <EOL> local_path = "<STR_LIT>" <EOL> bios_local_path = "<STR_LIT>" <EOL> else : <EOL> local_path = "<STR_LIT>" <EOL> bios_local_path = "<STR_LIT>" <EOL> self . _schema_locations = list ( ) <EOL> self . _classes = list ( ) <EOL> self . _registry_locations = list ( ) <EOL> self . _classes_registry = list ( ) <EOL> self . _bios_schema_locations = list ( ) <EOL> self . _bios_classes = list ( ) <EOL> self . _bios_registry_locations = list ( ) <EOL> self . _bios_classes_registry = list ( ) <EOL> self . _ilo_messages = list ( ) <EOL> self . _base_messages = list ( ) <EOL> self . _hpcommon_messages = list ( ) <EOL> self . _iloevents_messages = list ( ) <EOL> self . _errors = list ( ) <EOL> if monolith . is_redfish : <EOL> self . _schemaid = [ "<STR_LIT>" , "<STR_LIT>" ] <EOL> self . _regid = [ "<STR_LIT>" , "<STR_LIT>" ] <EOL> else : <EOL> self . _schemaid = [ "<STR_LIT>" , "<STR_LIT>" ] <EOL> self . _regid = [ "<STR_LIT>" , "<STR_LIT>" ] <EOL> if local_path : <EOL> self . add_location ( schema_path = local_path , monolith = monolith ) <EOL> self . add_location ( registry_path = local_path , monolith = monolith ) <EOL> if bios_local_path : <EOL> self . add_location ( schema_path = bios_local_path , biossection = True , monolith = monolith ) <EOL> self . add_location ( registry_path = bios_local_path , biossection = True , monolith = monolith ) <EOL> def getbiosziplocation ( self , romfamily , schemadir , biosversion ) : <EOL> """<STR_LIT>""" <EOL> foundfile = None <EOL> currentver = None <EOL> tempstr = "<STR_LIT>" + romfamily + "<STR_LIT:->" + biosversion <EOL> for _ , _ , filenames in os . walk ( schemadir ) : <EOL> for filename in filenames : <EOL> if tempstr in filename : <EOL> regentry = re . compile ( '<STR_LIT>' % tempstr ) <EOL> mentry = regentry . search ( filename ) <EOL> if mentry and currentver : <EOL> if currentver < mentry . group ( <NUM_LIT:1> ) : <EOL> foundfile = filename <EOL> currentver = mentry . group ( <NUM_LIT:1> ) <EOL> elif mentry and not currentver : <EOL> foundfile = filename <EOL> currentver = mentry . group ( <NUM_LIT:1> ) <EOL> if foundfile : <EOL> return os . path . join ( schemadir , foundfile ) <EOL> else : <EOL> return None <EOL> def getiloziplocation ( self , schemadir , iloversion ) : <EOL> """<STR_LIT>""" <EOL> if float ( iloversion ) < <NUM_LIT> : <EOL> iloversion = u'<STR_LIT>' <EOL> tempstr = "<STR_LIT>" + iloversion . replace ( "<STR_LIT:.>" , "<STR_LIT>" ) <EOL> for _ , _ , filenames in os . walk ( schemadir ) : <EOL> for filename in filenames : <EOL> if tempstr in filename : <EOL> return os . path . join ( schemadir , filename ) <EOL> return None <EOL> def add_location ( self , schema_path = None , registry_path = None , <EOL> biossection = False , monolith = None ) : <EOL> """<STR_LIT>""" <EOL> """<STR_LIT>""" <EOL> if schema_path : <EOL> if not biossection : <EOL> self . _schema_locations . append ( schema_path ) <EOL> self . _update_location_map ( monolith = monolith ) <EOL> else : <EOL> self . _bios_schema_locations . append ( schema_path ) <EOL> self . _update_location_map ( biossection = True , monolith = monolith ) <EOL> elif registry_path : <EOL> if not biossection : <EOL> self . _registry_locations . append ( registry_path ) <EOL> self . _update_location_map ( registries = True , monolith = monolith ) <EOL> else : <EOL> self . _bios_registry_locations . append ( registry_path ) <EOL> self . _update_location_map ( biossection = True , registries = True , monolith = monolith ) <EOL> else : <EOL> raise ValueError ( u"<STR_LIT>" "<STR_LIT>" ) <EOL> def _update_location_map ( self , biossection = False , registries = False , <EOL> monolith = None ) : <EOL> """<STR_LIT>""" <EOL> locationslist = list ( ) <EOL> pathjoinstr = None <EOL> if not registries : <EOL> pathjoinstr = "<STR_LIT>" <EOL> if not biossection : <EOL> locationslist = self . _schema_locations <EOL> else : <EOL> locationslist = self . _bios_schema_locations <EOL> else : <EOL> pathjoinstr = "<STR_LIT>" <EOL> if not biossection : <EOL> locationslist = self . _registry_locations <EOL> else : <EOL> locationslist = self . _bios_registry_locations <EOL> for location in locationslist : <EOL> if monolith : <EOL> self . new_load_file ( monolith , root = location , biossection = biossection , registries = registries ) <EOL> elif self . _is_local ( location ) : <EOL> for root , _ , filenames in os . walk ( os . path . join ( location , <EOL> pathjoinstr ) ) : <EOL> for filename in filenames : <EOL> fqpath = os . path . abspath ( os . path . join ( os . path . normpath ( root ) , filename ) ) <EOL> if self . load_file ( fqpath , root = location , biossection = biossection , registries = registries ) : <EOL> LOGGER . info ( "<STR_LIT>" , fqpath ) <EOL> def new_load_file ( self , monolith , root = None , biossection = False , registries = False ) : <EOL> """<STR_LIT>""" <EOL> classesdataholder = [ ] <EOL> for itemtype in monolith . types : <EOL> if itemtype . startswith ( "<STR_LIT>" ) or itemtype . startswith ( "<STR_LIT>" ) and u'<STR_LIT>' in monolith . types [ itemtype ] : <EOL> for instance in monolith . types [ itemtype ] [ u'<STR_LIT>' ] : <EOL> if self . _schemaid [ <NUM_LIT:0> ] in instance . resp . request . path . lower ( ) or self . _regid [ <NUM_LIT:0> ] in instance . resp . request . path . lower ( ) : <EOL> if not registries and self . _schemaid [ <NUM_LIT:0> ] in instance . resp . request . path . lower ( ) : <EOL> if classesdataholder : <EOL> if self . _schemaid [ <NUM_LIT:1> ] in instance . resp . dict : <EOL> classesdataholder [ <NUM_LIT:0> ] [ self . _schemaid [ <NUM_LIT:1> ] ] . extend ( instance . resp . dict [ self . _schemaid [ <NUM_LIT:1> ] ] ) <EOL> else : <EOL> classesdataholder . append ( instance . resp . dict ) <EOL> elif registries and self . _regid [ <NUM_LIT:0> ] in instance . resp . request . path . lower ( ) : <EOL> if classesdataholder : <EOL> if monolith . is_redfish : <EOL> classesdataholder [ <NUM_LIT:0> ] [ self . _regid [ <NUM_LIT:1> ] ] . extend ( instance . resp . dict [ self . _regid [ <NUM_LIT:1> ] ] ) <EOL> else : <EOL> classesdataholder . append ( instance . resp . dict ) <EOL> if classesdataholder : <EOL> classesdataholder = classesdataholder [ <NUM_LIT:0> ] <EOL> try : <EOL> if monolith . _typestring in classesdataholder and ( '<STR_LIT>' in classesdataholder [ monolith . _typestring ] or ( '<STR_LIT>' in classesdataholder [ monolith . _typestring ] and monolith . is_redfish ) ) : <EOL> newclass = Classes . parse ( classesdataholder ) <EOL> newclass . set_root ( root ) <EOL> if not registries : <EOL> if not biossection : <EOL> self . _classes . append ( newclass ) <EOL> else : <EOL> self . _bios_classes . append ( newclass ) <EOL> else : <EOL> if not biossection : <EOL> self . _classes_registry . append ( newclass ) <EOL> else : <EOL> self . _bios_classes_registry . append ( newclass ) <EOL> except BaseException : <EOL> pass <EOL> else : <EOL> pass <EOL> def load_file ( self , filepath , root = None , biossection = False , <EOL> registries = False , datareturn = False ) : <EOL> """<STR_LIT>""" <EOL> result = False <EOL> if os . path . isfile ( filepath ) : <EOL> try : <EOL> filehand = open ( filepath , '<STR_LIT:r>' ) <EOL> data = json . load ( filehand ) <EOL> if datareturn : <EOL> return data <EOL> if u'<STR_LIT>' in data and data [ u'<STR_LIT>' ] == '<STR_LIT>' : <EOL> if biossection and registries : <EOL> itemsreturn = self . bios_helper_function ( data , root ) <EOL> data [ "<STR_LIT>" ] = itemsreturn <EOL> newclass = Classes . parse ( data ) <EOL> newclass . set_root ( root ) <EOL> if not registries : <EOL> if not biossection : <EOL> self . _classes . append ( newclass ) <EOL> else : <EOL> self . _bios_classes . append ( newclass ) <EOL> else : <EOL> if not biossection : <EOL> self . _classes_registry . append ( newclass ) <EOL> else : <EOL> self . _bios_classes_registry . append ( newclass ) <EOL> result = True <EOL> except BaseException : <EOL> pass <EOL> else : <EOL> pass <EOL> finally : <EOL> filehand . close ( ) <EOL> return result <EOL> def bios_helper_function ( self , data , root ) : <EOL> """<STR_LIT>""" <EOL> folderentries = data [ "<STR_LIT>" ] <EOL> datareturn = list ( ) <EOL> for entry in folderentries [ "<STR_LIT>" ] : <EOL> joinstr = entry [ "<STR_LIT>" ] <EOL> if os . name == '<STR_LIT>' and joinstr [ <NUM_LIT:0> ] == "<STR_LIT:/>" : <EOL> joinstr = joinstr . replace ( "<STR_LIT:/>" , "<STR_LIT:\\>" ) [ <NUM_LIT:1> : ] <EOL> elif joinstr [ <NUM_LIT:0> ] == "<STR_LIT:/>" : <EOL> joinstr = joinstr [ <NUM_LIT:1> : ] <EOL> for root , _ , filenames in os . walk ( os . path . join ( root , joinstr ) ) : <EOL> for filename in filenames : <EOL> fqpath = os . path . abspath ( os . path . join ( os . path . normpath ( root ) , filename ) ) <EOL> datareturn . append ( self . load_file ( fqpath , root = root , biossection = True , registries = True , datareturn = True ) ) <EOL> LOGGER . info ( "<STR_LIT>" , fqpath ) <EOL> return datareturn <EOL> def validate ( self , item , selector = None , currdict = None , monolith = None , <EOL> newarg = None , checkall = False , regloc = None ) : <EOL> """<STR_LIT>""" <EOL> """<STR_LIT>""" <EOL> if regloc : <EOL> attrreg = RepoRegistryEntry ( regloc ) <EOL> else : <EOL> attrreg = self . find_schema ( schname = item [ monolith . _typestring ] ) <EOL> if attrreg : <EOL> tempvalue = attrreg . validate ( item , self . _errors , selector = selector , <EOL> currdict = currdict , monolith = monolith , <EOL> newarg = newarg , checkall = checkall ) <EOL> if tempvalue is True : <EOL> return False <EOL> elif tempvalue : <EOL> self . _errors = tempvalue <EOL> return True <EOL> def bios_validate ( self , item , regname , selector = None , currdict = None , <EOL> checkall = False , monolith = None ) : <EOL> """<STR_LIT>""" <EOL> """<STR_LIT>""" <EOL> attrreg = self . find_bios_registry ( regname = regname ) <EOL> if attrreg : <EOL> tempvalue = attrreg . validate_bios_version ( item , self . _errors , selector = selector , currdict = currdict , checkall = checkall , monolith = monolith ) <EOL> if tempvalue == '<STR_LIT>' : <EOL> return tempvalue <EOL> elif tempvalue == '<STR_LIT>' : <EOL> return tempvalue <EOL> elif tempvalue : <EOL> self . _errors = tempvalue <EOL> return True <EOL> def bios_info ( self , item , regname , selector ) : <EOL> """<STR_LIT>""" <EOL> """<STR_LIT>""" <EOL> attrreg = self . find_bios_registry ( regname = regname ) <EOL> if attrreg : <EOL> if attrreg . validate_bios_version ( item , self . _errors , selector = selector ) : <EOL> return False <EOL> return True <EOL> def find_schema ( self , schname ) : <EOL> """<STR_LIT>""" <EOL> """<STR_LIT>""" <EOL> for cls in self . _classes : <EOL> found = cls . find_schema ( schname = schname ) <EOL> if found : <EOL> return found <EOL> return None <EOL> def find_registry ( self , regname ) : <EOL> """<STR_LIT>""" <EOL> """<STR_LIT>""" <EOL> for cls in self . _classes_registry : <EOL> found = cls . find_registry ( regname = regname ) <EOL> if found : <EOL> return found <EOL> return None <EOL> def find_bios_registry ( self , regname ) : <EOL> """<STR_LIT>""" <EOL> """<STR_LIT>""" <EOL> for cls in self . _bios_classes_registry : <EOL> found = cls . find_bios_registry ( regname = regname ) <EOL> if found : <EOL> return found <EOL> return None <EOL> def get_errors ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . _errors <EOL> def _is_local ( self , path ) : <EOL> """<STR_LIT>""" <EOL> if u'<STR_LIT>' in path : <EOL> return False <EOL> return True <EOL> class Classes ( RisObject ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , item ) : <EOL> super ( Classes , self ) . __init__ ( item ) <EOL> self . _root = None <EOL> def set_root ( self , newroot ) : <EOL> """<STR_LIT>""" <EOL> self . _root = newroot <EOL> def find_schema ( self , schname ) : <EOL> """<STR_LIT>""" <EOL> result = None <EOL> if hasattr ( self , '<STR_LIT>' ) and isinstance ( self . Items , list ) : <EOL> for entry in self . Items : <EOL> if entry and u'<STR_LIT>' in entry and entry [ u'<STR_LIT>' ] . lower ( ) == schname . lower ( ) : <EOL> regentry = RepoRegistryEntry . parse ( entry ) <EOL> regentry . set_root ( self . _root ) <EOL> result = regentry <EOL> break <EOL> elif hasattr ( self , '<STR_LIT>' ) and isinstance ( self . Members , list ) : <EOL> schname = schname . split ( '<STR_LIT:.>' ) [ - <NUM_LIT:1> ] <EOL> for entry in self . Members : <EOL> schlink = entry [ u'<STR_LIT>' ] . split ( '<STR_LIT:/>' ) <EOL> schlink = schlink [ len ( schlink ) - <NUM_LIT:2> ] <EOL> if schname . lower ( ) == schlink . lower ( ) : <EOL> result = entry <EOL> break <EOL> return result <EOL> def find_registry ( self , regname ) : <EOL> """<STR_LIT>""" <EOL> result = None <EOL> if hasattr ( self , '<STR_LIT>' ) and isinstance ( self . Items , list ) : <EOL> for entry in self . Items : <EOL> if entry and ( u'<STR_LIT>' in entry and <EOL> entry [ u'<STR_LIT>' ] . lower ( ) . startswith ( regname . lower ( ) ) ) : <EOL> regentry = RepoRegistryEntry . parse ( entry ) <EOL> regentry . set_root ( self . _root ) <EOL> result = regentry <EOL> break <EOL> elif hasattr ( self , '<STR_LIT>' ) and isinstance ( self . Members , list ) : <EOL> regname = regname . split ( '<STR_LIT:.>' ) [ - <NUM_LIT:1> ] <EOL> for entry in self . Members : <EOL> reglink = entry [ u'<STR_LIT>' ] . split ( '<STR_LIT:/>' ) <EOL> reglink = reglink [ len ( reglink ) - <NUM_LIT:2> ] <EOL> if regname . lower ( ) == reglink . lower ( ) : <EOL> result = entry <EOL> break <EOL> return result <EOL> def find_bios_schema ( self , schname ) : <EOL> """<STR_LIT>""" <EOL> result = None <EOL> if hasattr ( self , '<STR_LIT>' ) and isinstance ( self . Items , list ) : <EOL> for entry in self . Items : <EOL> if ( u'<STR_LIT>' in entry and entry [ u'<STR_LIT>' ] . lower ( ) == <EOL> schname . lower ( ) ) : <EOL> regentry = RepoRegistryEntry . parse ( entry ) <EOL> regentry . set_root ( self . _root ) <EOL> result = regentry <EOL> break <EOL> return result <EOL> def find_bios_registry ( self , regname ) : <EOL> """<STR_LIT>""" <EOL> result = None <EOL> if hasattr ( self , '<STR_LIT>' ) and isinstance ( self . Items , list ) : <EOL> for entry in self . Items : <EOL> if entry and ( u'<STR_LIT>' in entry and regname . lower ( ) in entry [ u'<STR_LIT>' ] . lower ( ) ) : <EOL> regentry = RepoRegistryEntry . parse ( entry ) <EOL> regentry . set_root ( self . _root ) <EOL> result = regentry <EOL> break <EOL> return result <EOL> class RepoBaseEntry ( RisObject ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , d ) : <EOL> super ( RepoBaseEntry , self ) . __init__ ( d ) <EOL> self . _root = None <EOL> def set_root ( self , newroot ) : <EOL> """<STR_LIT>""" <EOL> self . _root = newroot <EOL> def _read_location_file ( self , currloc , errlist ) : <EOL> """<STR_LIT>""" <EOL> result = None <EOL> if u'<STR_LIT>' in currloc : <EOL> root = os . path . normpath ( self . _root ) <EOL> xref = os . path . normpath ( currloc . Uri . extref ) . lstrip ( os . path . sep ) <EOL> fqpath = os . path . join ( root , xref ) <EOL> if not os . path . isfile ( fqpath ) : <EOL> errlist . append ( SchemaValidationError ( <EOL> u"<STR_LIT>" % fqpath ) ) <EOL> else : <EOL> result = None <EOL> if fqpath . endswith ( '<STR_LIT>' ) : <EOL> result = open ( fqpath ) . read ( ) <EOL> return result <EOL> class RepoRegistryEntry ( RepoBaseEntry ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , d ) : <EOL> super ( RepoRegistryEntry , self ) . __init__ ( d ) <EOL> def validate ( self , tdict , errlist = None , selector = None , currdict = None , checkall = False , monolith = None , newarg = None ) : <EOL> """<STR_LIT>""" <EOL> if not errlist : <EOL> errlist = list ( ) <EOL> reg = self . get_registry_model ( errlist = errlist , currdict = currdict , monolith = monolith , newarg = newarg ) <EOL> if reg and not checkall : <EOL> try : <EOL> if reg [ selector ] . readonly : <EOL> return True <EOL> except BaseException : <EOL> pass <EOL> else : <EOL> pass <EOL> results = reg . validate_attribute_values ( tdict ) <EOL> errlist . extend ( results ) <EOL> elif checkall and selector is None : <EOL> results = reg . validate_attribute_values ( tdict ) <EOL> errlist . extend ( results ) <EOL> else : <EOL> errlist . append ( RegistryValidationError ( u'<STR_LIT>' '<STR_LIT>' ) ) <EOL> if errlist : <EOL> return errlist <EOL> def validate_bios_version ( self , tdict , errlist = None , selector = None , checkall = False , currdict = None , monolith = None ) : <EOL> """<STR_LIT>""" <EOL> if not errlist : <EOL> errlist = list ( ) <EOL> reg = self . get_registry_model_bios_version ( errlist = errlist , currdict = currdict , monolith = monolith ) <EOL> if reg and not checkall : <EOL> for item in reg . Attributes : <EOL> if not item [ "<STR_LIT:Name>" ] == selector : <EOL> continue <EOL> if item [ "<STR_LIT>" ] is True : <EOL> return '<STR_LIT>' <EOL> try : <EOL> if item [ "<STR_LIT>" ] is True : <EOL> return '<STR_LIT>' <EOL> except BaseException : <EOL> continue <EOL> else : <EOL> continue <EOL> results = reg . validate_att_val_bios ( tdict ) <EOL> errlist . extend ( results ) <EOL> elif checkall and selector is None : <EOL> results = reg . validate_att_val_bios ( tdict ) <EOL> errlist . extend ( results ) <EOL> else : <EOL> errlist . append ( RegistryValidationError ( u'<STR_LIT>' '<STR_LIT>' ) ) <EOL> if errlist : <EOL> return errlist <EOL> def validate_deprecated ( self , tdict , errlist = None ) : <EOL> """<STR_LIT>""" <EOL> if not errlist : <EOL> errlist = list ( ) <EOL> if not hasattr ( self , u'<STR_LIT>' ) : <EOL> errlist . append ( RegistryValidationError ( u'<STR_LIT>' '<STR_LIT>' ) ) <EOL> return errlist <EOL> currloc = None <EOL> defloc = None <EOL> langcode = '<STR_LIT>' <EOL> for loc in self . Location : <EOL> for loclang in loc . keys ( ) : <EOL> if loclang . lower ( ) == langcode . lower ( ) : <EOL> currloc = loc [ loclang ] <EOL> break <EOL> elif loclang . lower ( ) == u'<STR_LIT:default>' : <EOL> defloc = loc [ loclang ] <EOL> if not currloc : <EOL> currloc = defloc <EOL> if not currloc : <EOL> errlist . append ( RegistryValidationError ( u'<STR_LIT>' '<STR_LIT>' ) ) <EOL> return <EOL> location_file = self . _read_location_file ( currloc , errlist = errlist ) <EOL> if not location_file : <EOL> errlist . append ( RegistryValidationError ( u'<STR_LIT>' ) ) <EOL> else : <EOL> jsonreg = json . loads ( location_file ) <EOL> if u'<STR_LIT>' in jsonreg : <EOL> if u'<STR_LIT>' in jsonreg and jsonreg [ u'<STR_LIT>' ] == u'<STR_LIT>' : <EOL> reg = HpPropertiesRegistry . parse ( jsonreg [ u'<STR_LIT>' ] ) <EOL> results = reg . validate_attribute_values ( tdict ) <EOL> errlist . extend ( results ) <EOL> def get_registry_model ( self , currdict = None , monolith = None , errlist = None , skipcommit = False , searchtype = None , newarg = None , latestschema = None ) : <EOL> """<STR_LIT>""" <EOL> if not errlist : <EOL> errlist = list ( ) <EOL> if not hasattr ( self , u'<STR_LIT>' ) : <EOL> errlist . append ( RegistryValidationError ( <EOL> u'<STR_LIT>' ) ) <EOL> return None <EOL> currloc = None <EOL> defloc = "<STR_LIT>" <EOL> langcode = list ( locale . getdefaultlocale ( ) ) <EOL> if not langcode [ <NUM_LIT:0> ] : <EOL> langcode [ <NUM_LIT:0> ] = "<STR_LIT>" <EOL> for loc in self . Location : <EOL> locationlanguage = loc [ "<STR_LIT>" ] . lower ( ) <EOL> locationlanguage = locationlanguage . replace ( "<STR_LIT:->" , "<STR_LIT:_>" ) <EOL> if locationlanguage in langcode [ <NUM_LIT:0> ] . lower ( ) : <EOL> currloc = loc <EOL> break <EOL> if not currloc : <EOL> currloc = defloc <EOL> if not currloc : <EOL> errlist . append ( RegistryValidationError ( u'<STR_LIT>' '<STR_LIT:location>' ) ) <EOL> return None <EOL> if not searchtype : <EOL> searchtype = "<STR_LIT>" <EOL> location_file = None <EOL> if currdict and monolith : <EOL> for itemtype in monolith . types : <EOL> if itemtype . lower ( ) . startswith ( searchtype . lower ( ) ) and u'<STR_LIT>' in monolith . types [ itemtype ] : <EOL> for instance in monolith . types [ itemtype ] [ u'<STR_LIT>' ] : <EOL> try : <EOL> if monolith . is_redfish : <EOL> currtype = currdict [ instance . _typestring ] . split ( '<STR_LIT:#>' ) [ - <NUM_LIT:1> ] <EOL> currtype = currtype . split ( '<STR_LIT:.>' ) [ <NUM_LIT:0> ] + '<STR_LIT:.>' <EOL> else : <EOL> currtype = currdict [ instance . _typestring ] <EOL> if latestschema : <EOL> currtype = currdict [ instance . _typestring ] . split ( '<STR_LIT:.>' ) [ : <NUM_LIT:1> ] <EOL> insttype = instance . resp . dict [ "<STR_LIT:title>" ] . split ( '<STR_LIT:.>' ) [ : <NUM_LIT:1> ] <EOL> if currtype == insttype or currtype == instance . resp . dict [ "<STR_LIT>" ] . split ( '<STR_LIT:.>' ) [ : <NUM_LIT:1> ] : <EOL> location_file = instance . resp . dict <EOL> break <EOL> elif searchtype == "<STR_LIT>" and instance . resp . dict [ "<STR_LIT:title>" ] . startswith ( currtype ) or "<STR_LIT>" in instance . resp . dict . keys ( ) and currdict [ instance . _typestring ] == instance . resp . dict [ "<STR_LIT>" ] : <EOL> location_file = instance . resp . dict <EOL> break <EOL> elif searchtype != "<STR_LIT>" and currdict [ instance . _typestring ] in instance . resp . dict [ "<STR_LIT>" ] : <EOL> location_file = instance . resp . dict <EOL> break <EOL> except BaseException : <EOL> pass <EOL> else : <EOL> pass <EOL> if location_file : <EOL> break <EOL> else : <EOL> location_file = self . _read_location_file ( currloc , errlist = errlist ) <EOL> if not location_file : <EOL> errlist . append ( RegistryValidationError ( u'<STR_LIT>' ) ) <EOL> else : <EOL> if currdict and monolith : <EOL> jsonreg = json . loads ( json . dumps ( location_file , indent = <NUM_LIT:2> , cls = JSONEncoder ) ) <EOL> else : <EOL> jsonreg = json . loads ( location_file ) <EOL> if skipcommit : <EOL> return jsonreg [ "<STR_LIT>" ] <EOL> if u'<STR_LIT>' in jsonreg : <EOL> regitem = jsonreg [ u'<STR_LIT>' ] <EOL> reg = HpPropertiesRegistry . parse ( regitem ) <EOL> if newarg : <EOL> regcopy = reg <EOL> for arg in newarg [ : - <NUM_LIT:1> ] : <EOL> try : <EOL> if '<STR_LIT>' in regcopy [ arg ] . iterkeys ( ) and ( '<STR_LIT>' in regcopy [ arg ] . iterkeys ( ) ) : <EOL> regcopy [ arg ] [ '<STR_LIT>' ] . update ( regcopy [ arg ] [ '<STR_LIT>' ] ) <EOL> regcopy = regcopy [ arg ] [ "<STR_LIT>" ] <EOL> for pattern in regcopy . iterkeys ( ) : <EOL> test = re . compile ( pattern ) <EOL> nextarg = newarg [ newarg . index ( arg ) + <NUM_LIT:1> ] <EOL> match = test . match ( nextarg ) <EOL> if match : <EOL> regcopy [ nextarg ] = regcopy . pop ( pattern ) <EOL> break <EOL> elif '<STR_LIT>' in regcopy [ arg ] : <EOL> oneof = regcopy [ arg ] [ '<STR_LIT>' ] <EOL> for item in oneof : <EOL> regcopy = item [ '<STR_LIT>' ] <EOL> if not arg == newarg [ - <NUM_LIT:1> ] : <EOL> try : <EOL> nextitem = newarg [ newarg . index ( arg ) + <NUM_LIT:1> ] <EOL> regcopy [ nextitem ] <EOL> break <EOL> except Exception : <EOL> continue <EOL> else : <EOL> regcopy = regcopy [ arg ] [ "<STR_LIT>" ] <EOL> except Exception : <EOL> try : <EOL> regcopy = regcopy [ arg ] [ '<STR_LIT>' ] <EOL> for pattern in regcopy . iterkeys ( ) : <EOL> test = re . compile ( pattern ) <EOL> nextarg = newarg [ newarg . index ( arg ) + <NUM_LIT:1> ] <EOL> match = test . match ( nextarg ) <EOL> if match : <EOL> patterninfo = regcopy . pop ( pattern ) <EOL> regcopy [ nextarg ] = patterninfo <EOL> except BaseException : <EOL> return None <EOL> reg = regcopy <EOL> return reg <EOL> return None <EOL> def get_registry_model_bios_version ( self , currdict = None , monolith = None , errlist = None ) : <EOL> """<STR_LIT>""" <EOL> """<STR_LIT>""" <EOL> if not errlist : <EOL> errlist = list ( ) <EOL> if not hasattr ( self , u'<STR_LIT>' ) : <EOL> errlist . append ( RegistryValidationError ( <EOL> u'<STR_LIT>' ) ) <EOL> return None <EOL> currloc = None <EOL> defloc = "<STR_LIT>" <EOL> langcode = list ( locale . getdefaultlocale ( ) ) <EOL> if not langcode [ <NUM_LIT:0> ] : <EOL> langcode [ <NUM_LIT:0> ] = "<STR_LIT>" <EOL> for loc in self . Location : <EOL> locationlanguage = loc [ "<STR_LIT>" ] . lower ( ) <EOL> locationlanguage = locationlanguage . replace ( "<STR_LIT:->" , "<STR_LIT:_>" ) <EOL> if locationlanguage in langcode [ <NUM_LIT:0> ] . lower ( ) : <EOL> currloc = loc <EOL> break <EOL> if not currloc : <EOL> currloc = defloc <EOL> if not currloc : <EOL> errlist . append ( RegistryValidationError ( <EOL> u'<STR_LIT>' ) ) <EOL> return None <EOL> location_file = None <EOL> if currdict and monolith : <EOL> for itemtype in monolith . types : <EOL> if "<STR_LIT>" in itemtype and u'<STR_LIT>' in monolith . types [ itemtype ] : <EOL> for instance in monolith . types [ itemtype ] [ u'<STR_LIT>' ] : <EOL> location_file = instance . resp . dict <EOL> break <EOL> if location_file : <EOL> break <EOL> else : <EOL> location_file = self . _read_location_file ( currloc , errlist = errlist ) <EOL> if not location_file : <EOL> errlist . append ( RegistryValidationError ( u'<STR_LIT>' ) ) <EOL> else : <EOL> if currdict and monolith : <EOL> jsonreg = json . loads ( json . dumps ( location_file , indent = <NUM_LIT:2> , cls = JSONEncoder ) ) <EOL> else : <EOL> jsonreg = json . loads ( location_file ) <EOL> if u'<STR_LIT>' in jsonreg : <EOL> regitem = jsonreg [ u'<STR_LIT>' ] <EOL> reg = HpPropertiesRegistry . parse ( regitem ) <EOL> return reg <EOL> return None <EOL> class RepoSchemaEntry ( RepoBaseEntry ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , item ) : <EOL> super ( RepoSchemaEntry , self ) . __init__ ( item ) <EOL> self . _root = None <EOL> def set_root ( self , newroot ) : <EOL> """<STR_LIT>""" <EOL> self . _root = newroot <EOL> def _read_location_file ( self , currloc , errlist ) : <EOL> """<STR_LIT>""" <EOL> if u'<STR_LIT>' in currloc and u'<STR_LIT>' in currloc : <EOL> fqpath = os . path . join ( self . _root , currloc . ArchiveUri . xref . lstrip ( os . path . sep ) ) <EOL> if not os . path . isfile ( fqpath ) : <EOL> errlist . append ( SchemaValidationError ( u"<STR_LIT>" "<STR_LIT>" % fqpath ) ) <EOL> else : <EOL> archive_file = currloc . ArchiveFile <EOL> archive_fh = None <EOL> result = None <EOL> if fqpath . endswith ( '<STR_LIT>' ) : <EOL> archive_fh = zipfile . ZipFile ( fqpath ) <EOL> infolist = archive_fh . infolist ( ) <EOL> for i in infolist : <EOL> if i . filename . lower ( ) == archive_file . lower ( ) : <EOL> jsonsch_fh = archive_fh . open ( i ) <EOL> result = jsonsch_fh . read ( ) <EOL> jsonsch_fh . close ( ) <EOL> archive_fh . close ( ) <EOL> return result <EOL> def validate ( self , tdict , errlist = None ) : <EOL> """<STR_LIT>""" <EOL> if not errlist : <EOL> errlist = list ( ) <EOL> result = list ( ) <EOL> if not hasattr ( self , u'<STR_LIT>' ) : <EOL> result . append ( SchemaValidationError ( u'<STR_LIT>' '<STR_LIT>' ) ) <EOL> return result <EOL> currloc = None <EOL> defloc = None <EOL> langcode = '<STR_LIT>' <EOL> for loc in self . Location : <EOL> for loclang in loc . keys ( ) : <EOL> if loclang . lower ( ) == langcode . lower ( ) : <EOL> currloc = loc [ loclang ] <EOL> break <EOL> elif loclang . lower ( ) == u'<STR_LIT:default>' : <EOL> defloc = loc [ loclang ] <EOL> if not currloc : <EOL> currloc = defloc <EOL> if not currloc : <EOL> result . append ( SchemaValidationError ( <EOL> u'<STR_LIT>' ) ) <EOL> return <EOL> location_file = self . _read_location_file ( currloc , errlist = result ) <EOL> if not location_file : <EOL> result . append ( SchemaValidationError ( u'<STR_LIT>' ) ) <EOL> else : <EOL> jsonsch = json . loads ( location_file ) <EOL> validictory . validate ( tdict , jsonsch ) <EOL> class HpPropertiesRegistry ( RisObject ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , d ) : <EOL> super ( HpPropertiesRegistry , self ) . __init__ ( d ) <EOL> def validate_attribute_values ( self , tdict ) : <EOL> """<STR_LIT>""" <EOL> result = list ( ) <EOL> for tkey in tdict : <EOL> try : <EOL> if self [ tkey ] and hasattr ( self [ tkey ] , "<STR_LIT:type>" ) : <EOL> temp = self . validate_attribute ( self [ tkey ] , tdict [ tkey ] , tkey ) <EOL> for err in temp : <EOL> if isinstance ( err , RegistryValidationError ) : <EOL> if err . reg : <EOL> err . sel = tkey <EOL> result . extend ( temp ) <EOL> except Exception : <EOL> pass <EOL> return result <EOL> def validate_att_val_bios ( self , tdict ) : <EOL> """<STR_LIT>""" <EOL> result = list ( ) <EOL> for tkey in tdict : <EOL> for item in self . Attributes : <EOL> try : <EOL> if item [ "<STR_LIT:Name>" ] == tkey and hasattr ( item , "<STR_LIT>" ) : <EOL> temp = self . validate_attribute ( item , tdict [ tkey ] , tkey ) <EOL> for err in temp : <EOL> if isinstance ( err , RegistryValidationError ) : <EOL> if err . reg : <EOL> err . sel = tkey <EOL> result . extend ( temp ) <EOL> break <EOL> except Exception : <EOL> pass <EOL> return result <EOL> def get_validator ( self , attrname , newargs = None , oneof = None ) : <EOL> """<STR_LIT>""" <EOL> if oneof : <EOL> self = oneof <EOL> if newargs : <EOL> for arg in newargs : <EOL> try : <EOL> self = self [ '<STR_LIT>' ] <EOL> except Exception : <EOL> pass <EOL> if not hasattr ( self , arg ) : <EOL> return None <EOL> elif not arg == newargs [ - <NUM_LIT:1> ] : <EOL> self = self [ arg ] <EOL> if not hasattr ( self , attrname ) : <EOL> return None <EOL> validator = None <EOL> if EnumValidator . is_type ( self [ attrname ] ) : <EOL> validator = EnumValidator . parse ( self [ attrname ] ) <EOL> elif StringValidator . is_type ( self [ attrname ] ) : <EOL> validator = StringValidator . parse ( self [ attrname ] ) <EOL> elif ObjectValidator . is_type ( self [ attrname ] ) : <EOL> validator = ObjectValidator . parse ( self [ attrname ] ) <EOL> elif IntegerValidator . is_type ( self [ attrname ] ) : <EOL> validator = IntegerValidator . parse ( self [ attrname ] ) <EOL> elif BoolValidator . is_type ( self [ attrname ] ) : <EOL> validator = BoolValidator . parse ( self [ attrname ] ) <EOL> elif PasswordValidator . is_type ( self [ attrname ] ) : <EOL> validator = PasswordValidator . parse ( self [ attrname ] ) <EOL> elif u'<STR_LIT>' in self [ attrname ] . keys ( ) : <EOL> for item in self [ attrname ] [ '<STR_LIT>' ] : <EOL> validator = self . get_validator ( attrname , newargs , HpPropertiesRegistry ( { attrname : item } ) ) <EOL> if validator : <EOL> break <EOL> return validator <EOL> def get_validator_bios ( self , attrname ) : <EOL> """<STR_LIT>""" <EOL> for item in self . Attributes : <EOL> if item [ "<STR_LIT:Name>" ] == attrname : <EOL> validator = None <EOL> if EnumValidator . is_type ( item ) : <EOL> validator = EnumValidator . parse ( item ) <EOL> elif StringValidator . is_type ( item ) : <EOL> validator = StringValidator . parse ( item ) <EOL> elif IntegerValidator . is_type ( item ) : <EOL> validator = IntegerValidator . parse ( item ) <EOL> elif BoolValidator . is_type ( item ) : <EOL> validator = BoolValidator . parse ( item ) <EOL> elif ObjectValidator . is_type ( item ) : <EOL> validator = ObjectValidator . parse ( item ) <EOL> elif PasswordValidator . is_type ( item ) : <EOL> validator = PasswordValidator . parse ( item ) <EOL> return validator <EOL> return None <EOL> def validate_attribute ( self , attrentry , attrval , name ) : <EOL> """<STR_LIT>""" <EOL> result = list ( ) <EOL> validator = None <EOL> if EnumValidator . is_type ( attrentry ) : <EOL> validator = EnumValidator . parse ( attrentry ) <EOL> elif StringValidator . is_type ( attrentry ) : <EOL> validator = StringValidator . parse ( attrentry ) <EOL> elif IntegerValidator . is_type ( attrentry ) : <EOL> validator = IntegerValidator . parse ( attrentry ) <EOL> elif BoolValidator . is_type ( attrentry ) : <EOL> validator = BoolValidator . parse ( attrentry ) <EOL> elif ObjectValidator . is_type ( attrentry ) : <EOL> validator = ObjectValidator . parse ( attrentry ) <EOL> elif PasswordValidator . is_type ( attrentry ) : <EOL> validator = PasswordValidator . parse ( attrentry ) <EOL> else : <EOL> raise UnknownValidatorError ( attrentry ) <EOL> if validator : <EOL> result . extend ( validator . validate ( attrval , name ) ) <EOL> return result <EOL> class BaseValidator ( RisObject ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , d ) : <EOL> super ( BaseValidator , self ) . __init__ ( d ) <EOL> def validate ( self ) : <EOL> """<STR_LIT>""" <EOL> raise RuntimeError ( u'<STR_LIT>' '<STR_LIT:class>' ) <EOL> class EnumValidator ( BaseValidator ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , d ) : <EOL> super ( EnumValidator , self ) . __init__ ( d ) <EOL> @ staticmethod <EOL> def is_type ( attrentry ) : <EOL> """<STR_LIT>""" <EOL> if u'<STR_LIT:type>' in attrentry : <EOL> if isinstance ( attrentry [ u'<STR_LIT:type>' ] , list ) : <EOL> for item in attrentry [ u'<STR_LIT:type>' ] : <EOL> if item . lower ( ) == u'<STR_LIT>' : <EOL> return True <EOL> elif u'<STR_LIT>' in attrentry and item . lower ( ) == u'<STR_LIT:string>' : <EOL> return True <EOL> elif u'<STR_LIT>' in attrentry and attrentry [ u'<STR_LIT:type>' ] == "<STR_LIT>" : <EOL> for key , value in attrentry [ u'<STR_LIT>' ] . iteritems ( ) : <EOL> if key . lower ( ) == "<STR_LIT:type>" and value . lower ( ) == u'<STR_LIT:string>' : <EOL> return True <EOL> else : <EOL> if attrentry [ u'<STR_LIT:type>' ] . lower ( ) == u'<STR_LIT>' : <EOL> return True <EOL> elif u'<STR_LIT>' in attrentry and attrentry [ u'<STR_LIT:type>' ] . lower ( ) == u'<STR_LIT:string>' : <EOL> return True <EOL> elif u'<STR_LIT>' in attrentry : <EOL> if attrentry [ u'<STR_LIT>' ] . lower ( ) == u'<STR_LIT>' : <EOL> return True <EOL> return False <EOL> def validate ( self , newval , name ) : <EOL> """<STR_LIT>""" <EOL> result = list ( ) <EOL> try : <EOL> for possibleval in self . enum : <EOL> if possibleval . lower ( ) == newval . lower ( ) : <EOL> return result <EOL> except Exception : <EOL> for possibleval in self . Value : <EOL> if possibleval . ValueName . lower ( ) == str ( newval ) . lower ( ) : <EOL> return result <EOL> result . append ( RegistryValidationError ( u"<STR_LIT>" <EOL> "<STR_LIT>" % ( newval , name ) , <EOL> regentry = self ) ) <EOL> return result <EOL> def print_help ( self , name , out = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> wrapper = textwrap . TextWrapper ( ) <EOL> wrapper . initial_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> <EOL> wrapper . subsequent_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT:%s>' % name ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT:description>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT:type>' in self and isinstance ( self [ u'<STR_LIT:type>' ] , list ) : <EOL> out . write ( u'<STR_LIT>' ) <EOL> for item in self [ u'<STR_LIT:type>' ] : <EOL> out . write ( '<STR_LIT>' % wrapper . fill ( '<STR_LIT:%s>' % item ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT:type>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> out . write ( u'<STR_LIT>' ) <EOL> try : <EOL> for possibleval in self . enum : <EOL> out . write ( '<STR_LIT>' % possibleval ) <EOL> except Exception : <EOL> for possibleval in self . Value : <EOL> out . write ( '<STR_LIT>' % possibleval ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> class BoolValidator ( BaseValidator ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , d ) : <EOL> super ( BoolValidator , self ) . __init__ ( d ) <EOL> @ staticmethod <EOL> def is_type ( attrentry ) : <EOL> """<STR_LIT>""" <EOL> if u'<STR_LIT:type>' in attrentry : <EOL> if isinstance ( attrentry [ u'<STR_LIT:type>' ] , list ) : <EOL> for item in attrentry [ u'<STR_LIT:type>' ] : <EOL> if item . lower ( ) == u'<STR_LIT>' : <EOL> return True <EOL> elif attrentry [ u'<STR_LIT:type>' ] == "<STR_LIT>" : <EOL> for key , value in attrentry [ u'<STR_LIT>' ] . iteritems ( ) : <EOL> if key . lower ( ) == "<STR_LIT:type>" and value . lower ( ) == u'<STR_LIT>' : <EOL> return True <EOL> else : <EOL> if attrentry [ u'<STR_LIT:type>' ] . lower ( ) == u'<STR_LIT>' : <EOL> return True <EOL> elif u'<STR_LIT>' in attrentry : <EOL> if attrentry [ u'<STR_LIT>' ] . lower ( ) == u'<STR_LIT>' : <EOL> return True <EOL> return False <EOL> def validate ( self , newval , name ) : <EOL> """<STR_LIT>""" <EOL> result = list ( ) <EOL> if newval is False or newval is True : <EOL> return result <EOL> result . append ( <EOL> RegistryValidationError ( <EOL> u"<STR_LIT>" % ( newval , name ) , <EOL> regentry = self <EOL> ) <EOL> ) <EOL> return result <EOL> def print_help ( self , name , out = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> wrapper = textwrap . TextWrapper ( ) <EOL> wrapper . initial_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> <EOL> wrapper . subsequent_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT:%s>' % name ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT:description>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT:type>' in self and isinstance ( self [ u'<STR_LIT:type>' ] , list ) : <EOL> out . write ( u'<STR_LIT>' ) <EOL> for item in self [ u'<STR_LIT:type>' ] : <EOL> out . write ( '<STR_LIT>' % wrapper . fill ( '<STR_LIT:%s>' % item ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT:type>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> class StringValidator ( BaseValidator ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , d ) : <EOL> super ( StringValidator , self ) . __init__ ( d ) <EOL> @ staticmethod <EOL> def is_type ( attrentry ) : <EOL> """<STR_LIT>""" <EOL> if u'<STR_LIT:type>' in attrentry : <EOL> if isinstance ( attrentry [ u'<STR_LIT:type>' ] , list ) : <EOL> for item in attrentry [ u'<STR_LIT:type>' ] : <EOL> if item . lower ( ) == u'<STR_LIT:string>' : <EOL> return True <EOL> elif attrentry [ u'<STR_LIT:type>' ] == "<STR_LIT>" : <EOL> for key , value in attrentry [ u'<STR_LIT>' ] . iteritems ( ) : <EOL> if key . lower ( ) == "<STR_LIT:type>" and u'<STR_LIT:string>' in value : <EOL> return True <EOL> else : <EOL> if attrentry [ u'<STR_LIT:type>' ] . lower ( ) == u'<STR_LIT:string>' : <EOL> return True <EOL> elif u'<STR_LIT>' in attrentry : <EOL> if attrentry [ u'<STR_LIT>' ] . lower ( ) == u'<STR_LIT:string>' : <EOL> return True <EOL> return False <EOL> def validate ( self , newval , name ) : <EOL> """<STR_LIT>""" <EOL> result = list ( ) <EOL> if u'<STR_LIT>' in self : <EOL> if len ( newval ) < int ( self [ u'<STR_LIT>' ] ) : <EOL> result . append ( RegistryValidationError ( <EOL> u"<STR_LIT>" % <EOL> ( self . Name , int ( self [ u'<STR_LIT>' ] ) ) , regentry = self ) ) <EOL> if u'<STR_LIT>' in self : <EOL> if len ( newval ) > int ( self [ u'<STR_LIT>' ] ) : <EOL> result . append ( RegistryValidationError ( <EOL> u"<STR_LIT>" % <EOL> ( self . Name , int ( self [ u'<STR_LIT>' ] ) ) , regentry = self ) ) <EOL> if u'<STR_LIT>' in self : <EOL> if self [ u'<STR_LIT>' ] : <EOL> pat = re . compile ( self [ u'<STR_LIT>' ] ) <EOL> if newval and not pat . match ( newval ) : <EOL> result . append ( RegistryValidationError ( <EOL> u"<STR_LIT>" <EOL> "<STR_LIT>" % ( self ) , regentry = self ) ) <EOL> return result <EOL> def print_help ( self , name , out = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> wrapper = textwrap . TextWrapper ( ) <EOL> wrapper . initial_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> <EOL> wrapper . subsequent_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT:%s>' % name ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT:description>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT:type>' in self and isinstance ( self [ u'<STR_LIT:type>' ] , list ) : <EOL> out . write ( u'<STR_LIT>' ) <EOL> for item in self [ u'<STR_LIT:type>' ] : <EOL> out . write ( '<STR_LIT>' % wrapper . fill ( '<STR_LIT:%s>' % item ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT:type>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> class IntegerValidator ( BaseValidator ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , d ) : <EOL> super ( IntegerValidator , self ) . __init__ ( d ) <EOL> @ staticmethod <EOL> def is_type ( attrentry ) : <EOL> """<STR_LIT>""" <EOL> if u'<STR_LIT:type>' in attrentry : <EOL> if isinstance ( attrentry [ u'<STR_LIT:type>' ] , list ) : <EOL> for item in attrentry [ u'<STR_LIT:type>' ] : <EOL> if item . lower ( ) == u'<STR_LIT>' or item . lower ( ) == u'<STR_LIT>' : <EOL> return True <EOL> elif attrentry [ u'<STR_LIT:type>' ] == "<STR_LIT>" : <EOL> for key , value in attrentry [ u'<STR_LIT>' ] . iteritems ( ) : <EOL> if key . lower ( ) == "<STR_LIT:type>" : <EOL> if value . lower ( ) == u'<STR_LIT>' or value . lower ( ) == u'<STR_LIT>' : <EOL> return True <EOL> else : <EOL> if attrentry [ u'<STR_LIT:type>' ] . lower ( ) == u'<STR_LIT>' or attrentry [ u'<STR_LIT:type>' ] . lower ( ) . lower ( ) == u'<STR_LIT>' : <EOL> return True <EOL> elif u'<STR_LIT>' in attrentry : <EOL> if attrentry [ u'<STR_LIT>' ] . lower ( ) == u'<STR_LIT>' : <EOL> return True <EOL> return False <EOL> def validate ( self , newval , name ) : <EOL> """<STR_LIT>""" <EOL> result = list ( ) <EOL> intval = int ( newval ) <EOL> pat = re . compile ( r'<STR_LIT>' ) <EOL> if newval and not pat . match ( intval ) : <EOL> result . append ( <EOL> RegistryValidationError ( <EOL> u"<STR_LIT>" % ( self ) , <EOL> regentry = self <EOL> ) <EOL> ) <EOL> return result <EOL> if u'<STR_LIT>' in self : <EOL> if intval < int ( self [ u'<STR_LIT>' ] ) : <EOL> result . append ( RegistryValidationError ( u"<STR_LIT>" "<STR_LIT>" % ( self . Name , int ( self [ u'<STR_LIT>' ] ) ) , regentry = self ) ) <EOL> if u'<STR_LIT>' in self : <EOL> if intval > int ( self [ u'<STR_LIT>' ] ) : <EOL> result . append ( RegistryValidationError ( u"<STR_LIT>" "<STR_LIT>" % ( self . Name , int ( self [ u'<STR_LIT>' ] ) ) , regentry = self ) ) <EOL> return result <EOL> def print_help ( self , name , out = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> wrapper = textwrap . TextWrapper ( ) <EOL> wrapper . initial_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> <EOL> wrapper . subsequent_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT:%s>' % name ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT:description>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT:type>' in self and isinstance ( self [ u'<STR_LIT:type>' ] , list ) : <EOL> out . write ( u'<STR_LIT>' ) <EOL> for item in self [ u'<STR_LIT:type>' ] : <EOL> out . write ( '<STR_LIT>' % wrapper . fill ( '<STR_LIT:%s>' % item ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT:type>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> class ObjectValidator ( BaseValidator ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , d ) : <EOL> super ( ObjectValidator , self ) . __init__ ( d ) <EOL> @ staticmethod <EOL> def is_type ( attrentry ) : <EOL> """<STR_LIT>""" <EOL> if u'<STR_LIT:type>' in attrentry : <EOL> if isinstance ( attrentry [ u'<STR_LIT:type>' ] , list ) : <EOL> for item in attrentry [ u'<STR_LIT:type>' ] : <EOL> if item . lower ( ) == u'<STR_LIT:object>' : <EOL> return True <EOL> elif attrentry [ u'<STR_LIT:type>' ] == "<STR_LIT>" : <EOL> for key , value in attrentry [ u'<STR_LIT>' ] . iteritems ( ) : <EOL> if key . lower ( ) == "<STR_LIT:type>" and value . lower ( ) == u'<STR_LIT:object>' : <EOL> return True <EOL> elif key . lower ( ) == "<STR_LIT>" : <EOL> try : <EOL> if value [ <NUM_LIT:0> ] [ u'<STR_LIT:type>' ] == u'<STR_LIT:object>' : <EOL> return True <EOL> except Exception : <EOL> continue <EOL> else : <EOL> if attrentry [ u'<STR_LIT:type>' ] . lower ( ) == u'<STR_LIT:object>' : <EOL> return True <EOL> elif u'<STR_LIT>' in attrentry : <EOL> if attrentry [ u'<STR_LIT>' ] . lower ( ) == u'<STR_LIT:object>' : <EOL> return True <EOL> return False <EOL> def validate ( self , newval , name ) : <EOL> """<STR_LIT>""" <EOL> result = list ( ) <EOL> return result <EOL> def print_help ( self , name , out = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> wrapper = textwrap . TextWrapper ( ) <EOL> wrapper . initial_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> <EOL> wrapper . subsequent_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT:%s>' % name ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT:description>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT:type>' in self and isinstance ( self [ u'<STR_LIT:type>' ] , list ) : <EOL> out . write ( u'<STR_LIT>' ) <EOL> for item in self [ u'<STR_LIT:type>' ] : <EOL> out . write ( '<STR_LIT>' % wrapper . fill ( '<STR_LIT:%s>' % item ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT:type>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> class PasswordValidator ( BaseValidator ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , d ) : <EOL> super ( PasswordValidator , self ) . __init__ ( d ) <EOL> @ staticmethod <EOL> def is_type ( attrentry ) : <EOL> """<STR_LIT>""" <EOL> if u'<STR_LIT:type>' in attrentry : <EOL> if isinstance ( attrentry [ u'<STR_LIT:type>' ] , list ) : <EOL> for item in attrentry [ u'<STR_LIT:type>' ] : <EOL> if item . lower ( ) == u'<STR_LIT:password>' : <EOL> return True <EOL> elif attrentry [ u'<STR_LIT:type>' ] == "<STR_LIT>" : <EOL> for key , value in attrentry [ u'<STR_LIT>' ] . iteritems ( ) : <EOL> if key . lower ( ) == "<STR_LIT:type>" and value . lower ( ) == u'<STR_LIT:password>' : <EOL> return True <EOL> else : <EOL> if attrentry [ u'<STR_LIT:type>' ] . lower ( ) == u'<STR_LIT:password>' : <EOL> return True <EOL> elif u'<STR_LIT>' in attrentry : <EOL> if attrentry [ u'<STR_LIT>' ] . lower ( ) == u'<STR_LIT:password>' : <EOL> return True <EOL> return False <EOL> def validate ( self , newval , name ) : <EOL> """<STR_LIT>""" <EOL> result = list ( ) <EOL> if newval is None : <EOL> return result <EOL> if u'<STR_LIT>' in self : <EOL> if len ( newval ) < int ( self [ u'<STR_LIT>' ] ) : <EOL> result . append ( RegistryValidationError ( u"<STR_LIT>" "<STR_LIT>" % ( self . Name , int ( self [ u'<STR_LIT>' ] ) ) , regentry = self ) ) <EOL> if u'<STR_LIT>' in self : <EOL> if len ( newval ) > int ( self [ u'<STR_LIT>' ] ) : <EOL> result . append ( RegistryValidationError ( u"<STR_LIT>" "<STR_LIT>" % ( self . Name , int ( self [ u'<STR_LIT>' ] ) ) , regentry = self ) ) <EOL> if u'<STR_LIT>' in self : <EOL> if self [ u'<STR_LIT>' ] : <EOL> pat = re . compile ( self [ u'<STR_LIT>' ] ) <EOL> if newval and not pat . match ( newval ) : <EOL> result . append ( RegistryValidationError ( u"<STR_LIT>" "<STR_LIT>" "<STR_LIT>" % ( self ) , regentry = self ) ) <EOL> return result <EOL> def print_help ( self , name , out = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> wrapper = textwrap . TextWrapper ( ) <EOL> wrapper . initial_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> <EOL> wrapper . subsequent_indent = '<STR_LIT:U+0020>' * <NUM_LIT:4> <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT:%s>' % name ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT:description>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT:type>' in self and isinstance ( self [ u'<STR_LIT:type>' ] , list ) : <EOL> out . write ( u'<STR_LIT>' ) <EOL> for item in self [ u'<STR_LIT:type>' ] : <EOL> out . write ( '<STR_LIT>' % wrapper . fill ( '<STR_LIT:%s>' % item ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT:type>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> if u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) <EOL> elif u'<STR_LIT>' in self : <EOL> out . write ( u'<STR_LIT>' ) <EOL> out . write ( '<STR_LIT:%s>' % wrapper . fill ( '<STR_LIT>' % self ) ) <EOL> out . write ( '<STR_LIT:\n>' ) </s>
<s> from . constants import MILLI_MICROS , SECOND_MICROS , MINUTE_MICROS <EOL> import calendar <EOL> from datetime import datetime <EOL> from dateutil import parser <EOL> from dateutil . tz import tzlocal <EOL> from . error import TimeConstructionError <EOL> from . sanedelta import SaneDelta <EOL> import pytz <EOL> MICROS_TRANSLATIONS = ( <EOL> ( ( '<STR_LIT:m>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) , MINUTE_MICROS ) , <EOL> ( ( '<STR_LIT:s>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) , SECOND_MICROS ) , <EOL> ( ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) , MILLI_MICROS ) , <EOL> ( ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) , <NUM_LIT:1> ) ) <EOL> MICROS_TRANSLATION_HASH = dict ( ( alt , v ) for k , v in MICROS_TRANSLATIONS for alt in k ) <EOL> class SaneTime ( object ) : <EOL> """<STR_LIT>""" <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , * args , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> super ( time , self ) . __init__ ( ) <EOL> uss = set ( ) <EOL> tzs = set ( ) <EOL> naive_dt = None <EOL> avoid_localize = False <EOL> for k , v in kwargs . iteritems ( ) : <EOL> if k in ( '<STR_LIT>' , '<STR_LIT>' ) : <EOL> tzs . add ( SaneTime . to_timezone ( v ) ) <EOL> elif k in MICROS_TRANSLATION_HASH : <EOL> uss . add ( MICROS_TRANSLATION_HASH [ k ] * v ) <EOL> else : <EOL> raise TimeConstructionError ( "<STR_LIT>" % ( k , v ) ) <EOL> args = list ( args ) <EOL> if len ( args ) > <NUM_LIT:2> and len ( args ) <= <NUM_LIT:8> : <EOL> args = [ datetime ( * args ) ] <EOL> if len ( args ) == <NUM_LIT:2> : <EOL> tzs . add ( SaneTime . to_timezone ( args . pop ( ) ) ) <EOL> if len ( args ) == <NUM_LIT:1> : <EOL> arg = args . pop ( ) <EOL> if hasattr ( arg , '<STR_LIT>' ) : <EOL> uss . add ( int ( arg ) ) <EOL> if hasattr ( arg , '<STR_LIT>' ) : tzs . add ( arg . tz ) <EOL> elif isinstance ( arg , basestring ) : <EOL> parts = arg . strip ( ) . split ( '<STR_LIT:U+0020>' ) <EOL> if len ( parts ) > <NUM_LIT:1> and parts [ - <NUM_LIT:1> ] . startswith ( '<STR_LIT:+>' ) : <EOL> try : <EOL> tzs . add ( SaneTime . to_timezone ( parts [ - <NUM_LIT:1> ] [ <NUM_LIT:1> : ] ) ) <EOL> arg = '<STR_LIT:U+0020>' . join ( parts [ : - <NUM_LIT:1> ] ) <EOL> except : pass <EOL> utc = arg . endswith ( '<STR_LIT>' ) or arg . endswith ( '<STR_LIT>' ) <EOL> arg = parser . parse ( arg ) <EOL> if arg . tzinfo : <EOL> if utc : <EOL> tzs . add ( pytz . utc ) <EOL> arg = arg . replace ( tzinfo = None ) <EOL> elif isinstance ( arg . tzinfo , tzlocal ) : <EOL> arg = arg . replace ( tzinfo = None ) <EOL> else : <EOL> avoid_localize = True <EOL> arg = arg . astimezone ( pytz . utc ) . replace ( tzinfo = None ) <EOL> if type ( arg ) == datetime : <EOL> naive_dt = arg <EOL> if naive_dt . tzinfo : <EOL> tzs . add ( SaneTime . to_timezone ( str ( naive_dt . tzinfo ) ) ) <EOL> naive_dt = naive_dt . replace ( tzinfo = None ) <EOL> if len ( tzs ) > <NUM_LIT:1> : <EOL> raise TimeConstructionError ( "<STR_LIT>" % ( tzs ) ) <EOL> self . tz = len ( tzs ) and tzs . pop ( ) or pytz . utc <EOL> if naive_dt : <EOL> if avoid_localize : <EOL> uss . add ( SaneTime . utc_datetime_to_us ( naive_dt ) ) <EOL> else : <EOL> uss . add ( SaneTime . utc_datetime_to_us ( self . tz . localize ( naive_dt ) . astimezone ( pytz . utc ) ) ) <EOL> if len ( uss ) == <NUM_LIT:0> : <EOL> uss . add ( SaneTime . utc_datetime_to_us ( datetime . utcnow ( ) ) ) <EOL> if len ( uss ) > <NUM_LIT:1> : <EOL> raise TimeConstructionError ( "<STR_LIT>" % ( uss ) ) <EOL> self . us = uss . pop ( ) <EOL> if len ( args ) > <NUM_LIT:0> : <EOL> raise TimeConstructionError ( "<STR_LIT>" ) <EOL> @ property <EOL> def ms ( self ) : return self . us / MILLI_MICROS <EOL> epoch_milliseconds = epoch_millis = milliseconds = millis = ms <EOL> @ property <EOL> def s ( self ) : return self . us / SECOND_MICROS <EOL> epoch_seconds = epoch_secs = seconds = secs = s <EOL> @ property <EOL> def m ( self ) : return self . us / MINUTE_MICROS <EOL> epoch_minutes = epoch_mins = minutes = mins = m <EOL> @ property <EOL> def micros ( self ) : return self . us <EOL> epoch_microseconds = epoch_micros = microseconds = micros <EOL> @ property <EOL> def tz_name ( self ) : return self . tz . zone <EOL> @ property <EOL> def tz_abbr ( self ) : return self . tz . _tzname <EOL> def set_tz ( self , tz ) : <EOL> self . tz = self . __class__ . to_timezone ( tz ) ; return self <EOL> def with_tz ( self , tz ) : <EOL> return self . __class__ ( self . us , tz ) <EOL> @ property <EOL> def _tuple ( self ) : return ( self . us , self . tz ) <EOL> def strftime ( self , * args , ** kwargs ) : return self . datetime . strftime ( * args , ** kwargs ) <EOL> def __cmp__ ( self , other ) : <EOL> if not hasattr ( other , '<STR_LIT>' ) : other = SaneTime ( other ) <EOL> return cmp ( self . us , int ( other ) ) <EOL> def __hash__ ( self ) : return self . us . __hash__ ( ) <EOL> def __add__ ( self , operand ) : <EOL> if not hasattr ( operand , '<STR_LIT>' ) : operand = SaneTime ( operand ) <EOL> return self . __class__ ( self . us + int ( operand ) , tz = self . tz ) <EOL> def __sub__ ( self , operand ) : <EOL> if not hasattr ( operand , '<STR_LIT>' ) : operand = SaneTime ( operand ) <EOL> if isinstance ( operand , SaneTime ) : return SaneDelta ( self . us - int ( operand ) ) <EOL> return self . __add__ ( - int ( operand ) ) <EOL> def __mul__ ( self , operand ) : <EOL> return self . us * int ( operand ) <EOL> def __div__ ( self , operand ) : <EOL> return self . us / int ( operand ) <EOL> def __int__ ( self ) : return int ( self . us ) <EOL> def __long__ ( self ) : return long ( self . us ) <EOL> def __repr__ ( self ) : return u"<STR_LIT>" % ( self . us , repr ( self . tz ) ) <EOL> def __str__ ( self ) : return unicode ( self ) . encode ( '<STR_LIT:utf-8>' ) <EOL> def __unicode__ ( self ) : <EOL> dt = self . datetime <EOL> micros = u"<STR_LIT>" % dt . microsecond if dt . microsecond else '<STR_LIT>' <EOL> time = u"<STR_LIT>" % ( dt . hour , dt . minute , dt . second , micros ) if dt . microsecond or dt . second or dt . minute or dt . hour else '<STR_LIT>' <EOL> return u"<STR_LIT>" % ( dt . year , dt . month , dt . day , time , dt . tzinfo . zone ) <EOL> def clone ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . __class__ ( self . us , self . tz ) <EOL> @ property <EOL> def ny_str ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . ny_ndt . strftime ( '<STR_LIT>' ) <EOL> @ property <EOL> def utc_datetime ( self ) : return SaneTime . us_to_utc_datetime ( self . us ) <EOL> utc_dt = utc_datetime <EOL> @ property <EOL> def utc_naive_datetime ( self ) : return self . utc_datetime . replace ( tzinfo = None ) <EOL> utc_ndt = utc_naive_datetime <EOL> def to_timezoned_datetime ( self , tz ) : return self . utc_datetime . astimezone ( SaneTime . to_timezone ( tz ) ) <EOL> def to_timezoned_naive_datetime ( self , tz ) : return self . to_timezoned_datetime ( tz ) . replace ( tzinfo = None ) <EOL> @ property <EOL> def datetime ( self ) : return self . to_timezoned_datetime ( self . tz ) <EOL> dt = datetime <EOL> @ property <EOL> def naive_datetime ( self ) : return self . to_timezoned_naive_datetime ( self . tz ) <EOL> ndt = naive_datetime <EOL> @ property <EOL> def ny_datetime ( self ) : return self . to_timezoned_datetime ( '<STR_LIT>' ) <EOL> ny_dt = ny_datetime <EOL> @ property <EOL> def ny_naive_datetime ( self ) : return self . to_timezoned_naive_datetime ( '<STR_LIT>' ) <EOL> ny_ndt = ny_naive_datetime <EOL> @ property <EOL> def year ( self ) : return self . dt . year <EOL> @ property <EOL> def month ( self ) : return self . dt . month <EOL> @ property <EOL> def day ( self ) : return self . dt . day <EOL> @ property <EOL> def hour ( self ) : return self . dt . hour <EOL> @ property <EOL> def minute ( self ) : return self . dt . minute <EOL> @ property <EOL> def second ( self ) : return self . dt . second <EOL> @ property <EOL> def microsecond ( self ) : return self . dt . microsecond <EOL> @ classmethod <EOL> def utc_datetime_to_us ( kls , dt ) : <EOL> return calendar . timegm ( dt . timetuple ( ) ) * <NUM_LIT:1000> ** <NUM_LIT:2> + dt . microsecond <EOL> @ classmethod <EOL> def us_to_utc_datetime ( kls , us ) : <EOL> return pytz . utc . localize ( datetime . utcfromtimestamp ( us / <NUM_LIT:10> ** <NUM_LIT:6> ) ) . replace ( microsecond = us % <NUM_LIT:10> ** <NUM_LIT:6> ) <EOL> @ classmethod <EOL> def to_timezone ( kls , tz ) : <EOL> if not isinstance ( tz , basestring ) : return tz <EOL> return pytz . timezone ( tz ) <EOL> def ntime ( * args , ** kwargs ) : <EOL> if args : <EOL> if args [ <NUM_LIT:0> ] is None : return None <EOL> elif kwargs : <EOL> if None in [ v for k , v in kwargs . iteritems ( ) if k != '<STR_LIT>' ] : return None <EOL> return SaneTime ( * args , ** kwargs ) <EOL> time = sanetime = SaneTime <EOL> nsanetime = ntime </s>
<s> from tastypie . authorization import Authorization <EOL> from openpds . authentication import OAuth2Authentication <EOL> from openpds . core . models import Profile , AuditEntry <EOL> import settings <EOL> import pdb <EOL> import traceback <EOL> class PDSAuthorization ( Authorization ) : <EOL> audit_enabled = True <EOL> scope = "<STR_LIT>" <EOL> requester_uuid = "<STR_LIT>" <EOL> def requester ( self ) : <EOL> return self . requester_uuid <EOL> def trustWrapper ( self , datastore_owner ) : <EOL> print "<STR_LIT>" <EOL> def is_authorized ( self , request , object = None ) : <EOL> authenticator = OAuth2Authentication ( self . scope ) <EOL> if "<STR_LIT>" in request . REQUEST : <EOL> authorized = True <EOL> token = request . REQUEST [ "<STR_LIT>" ] if "<STR_LIT>" in request . REQUEST else request . META [ "<STR_LIT>" ] <EOL> datastore_owner_uuid = request . REQUEST [ "<STR_LIT>" ] <EOL> datastore_owner , ds_owner_created = Profile . objects . get_or_create ( uuid = datastore_owner_uuid ) <EOL> self . requester_uuid = authenticator . get_userinfo_from_token ( token , self . scope ) <EOL> if self . requester_uuid is False or self . requester_uuid is None or len ( self . requester_uuid ) == <NUM_LIT:0> : <EOL> self . requester_uuid = "<STR_LIT>" <EOL> authorized = False <EOL> self . trustWrapper ( datastore_owner ) <EOL> try : <EOL> if ( self . audit_enabled ) : <EOL> audit_entry = AuditEntry ( token = token ) <EOL> audit_entry . method = request . method <EOL> audit_entry . scope = self . scope <EOL> audit_entry . purpose = request . REQUEST [ "<STR_LIT>" ] if "<STR_LIT>" in request . REQUEST else "<STR_LIT>" <EOL> audit_entry . system_entity_toggle = request . REQUEST [ "<STR_LIT>" ] if "<STR_LIT>" in request . REQUEST else False <EOL> audit_entry . datastore_owner = datastore_owner <EOL> audit_entry . requester , created = Profile . objects . get_or_create ( uuid = self . requester_uuid ) <EOL> audit_entry . script = request . path <EOL> audit_entry . save ( ) <EOL> except Exception as e : <EOL> print e <EOL> authorized = False <EOL> return authorized <EOL> return False <EOL> def __init__ ( self , scope , audit_enabled = True ) : <EOL> self . scope = scope <EOL> self . audit_enabled = audit_enabled </s>
<s> """<STR_LIT>""" <EOL> from django import template <EOL> register = template . Library ( ) <EOL> class VerbatimNode ( template . Node ) : <EOL> def __init__ ( self , text ) : <EOL> self . text = text <EOL> def render ( self , context ) : <EOL> return self . text <EOL> @ register . tag <EOL> def verbatim ( parser , token ) : <EOL> text = [ ] <EOL> while <NUM_LIT:1> : <EOL> token = parser . tokens . pop ( <NUM_LIT:0> ) <EOL> if token . contents == '<STR_LIT>' : <EOL> break <EOL> if token . token_type == template . TOKEN_VAR : <EOL> text . append ( '<STR_LIT>' ) <EOL> elif token . token_type == template . TOKEN_BLOCK : <EOL> text . append ( '<STR_LIT>' ) <EOL> text . append ( token . contents ) <EOL> if token . token_type == template . TOKEN_VAR : <EOL> text . append ( '<STR_LIT>' ) <EOL> elif token . token_type == template . TOKEN_BLOCK : <EOL> text . append ( '<STR_LIT>' ) <EOL> return VerbatimNode ( '<STR_LIT>' . join ( text ) ) </s>
<s> from django . shortcuts import render_to_response <EOL> from django . template import RequestContext <EOL> import pdb </s>
<s> from werkzeug . utils import cached_property <EOL> from base import db , Base <EOL> from cluster import Cluster <EOL> class Proxy ( Base ) : <EOL> __tablename__ = '<STR_LIT>' <EOL> host = db . Column ( db . String ( <NUM_LIT:255> ) , nullable = False ) <EOL> port = db . Column ( db . Integer , nullable = False ) <EOL> eru_container_id = db . Column ( db . String ( <NUM_LIT:64> ) , index = True ) <EOL> cluster_id = db . Column ( db . ForeignKey ( Cluster . id ) , index = True ) <EOL> suppress_alert = db . Column ( db . Integer , nullable = False , default = <NUM_LIT:1> ) <EOL> __table_args__ = ( db . Index ( '<STR_LIT:address>' , '<STR_LIT:host>' , '<STR_LIT:port>' , unique = True ) , ) <EOL> @ cached_property <EOL> def eru_deployed ( self ) : <EOL> return self . eru_container_id is not None <EOL> @ cached_property <EOL> def eru_info ( self ) : <EOL> import eru_utils <EOL> if eru_utils . eru_client is None or not self . eru_deployed : <EOL> return None <EOL> return eru_utils . eru_client . get_container ( self . eru_container_id ) <EOL> @ cached_property <EOL> def cluster ( self ) : <EOL> return Cluster . query . get ( self . cluster_id ) <EOL> def get_by_host_port ( host , port ) : <EOL> return db . session . query ( Proxy ) . filter ( <EOL> Proxy . host == host , Proxy . port == port ) . first ( ) <EOL> def del_by_host_port ( host , port ) : <EOL> return db . session . query ( Proxy ) . filter ( <EOL> Proxy . host == host , Proxy . port == port ) . delete ( ) <EOL> def get_or_create ( host , port , cluster_id = None ) : <EOL> p = db . session . query ( Proxy ) . filter ( <EOL> Proxy . host == host , Proxy . port == port ) . first ( ) <EOL> if p is None : <EOL> p = Proxy ( host = host , port = port , cluster_id = cluster_id ) <EOL> db . session . add ( p ) <EOL> db . session . flush ( ) <EOL> return p <EOL> def create_eru_instance ( host , port , cluster_id , eru_container_id ) : <EOL> node = Proxy ( host = host , port = port , eru_container_id = eru_container_id , <EOL> cluster_id = cluster_id ) <EOL> db . session . add ( node ) <EOL> db . session . flush ( ) <EOL> return node <EOL> def delete_eru_instance ( eru_container_id ) : <EOL> db . session . query ( Proxy ) . filter ( <EOL> Proxy . eru_container_id == eru_container_id ) . delete ( ) <EOL> def get_eru_by_container_id ( eru_container_id ) : <EOL> return db . session . query ( Proxy ) . filter ( <EOL> Proxy . eru_container_id == eru_container_id ) . first ( ) <EOL> def list_all ( ) : <EOL> return db . session . query ( Proxy ) . all ( ) <EOL> def list_eru_proxies ( offset , limit ) : <EOL> return db . session . query ( Proxy ) . filter ( <EOL> Proxy . eru_container_id != None ) . order_by ( <EOL> Proxy . id . desc ( ) ) . offset ( offset ) . limit ( limit ) . all ( ) <EOL> def list_ip ( ) : <EOL> return db . session . query ( Proxy . host , Proxy . port ) . all ( ) </s>
<s> from ethereum import tester <EOL> import hydrachain . native_contracts as nc <EOL> from fungible_contract import IOU <EOL> import ethereum . slogging as slogging <EOL> log = slogging . get_logger ( '<STR_LIT>' ) <EOL> def test_iou_template ( ) : <EOL> """<STR_LIT>""" <EOL> nc . registry . register ( IOU ) <EOL> state = tester . state ( ) <EOL> logs = [ ] <EOL> issuer_address = tester . a0 <EOL> issuer_key = tester . k0 <EOL> for evt_class in IOU . events : <EOL> nc . listen_logs ( state , evt_class , callback = lambda e : logs . append ( e ) ) <EOL> iou_address = nc . tester_create_native_contract_instance ( state , issuer_key , IOU ) <EOL> iou_as_issuer = nc . tester_nac ( state , issuer_key , iou_address ) <EOL> iou_as_issuer . init ( ) <EOL> assert iou_as_issuer . balanceOf ( issuer_address ) == <NUM_LIT:0> <EOL> amount_issued = <NUM_LIT> <EOL> iou_as_issuer . issue_funds ( amount_issued , '<STR_LIT>' ) <EOL> assert iou_as_issuer . balanceOf ( issuer_address ) == amount_issued <EOL> iou_as_issuer . issue_funds ( amount_issued , '<STR_LIT>' ) <EOL> assert iou_as_issuer . balanceOf ( issuer_address ) == <NUM_LIT:2> * amount_issued <EOL> assert iou_as_issuer . get_issued_amount ( issuer_address ) == <NUM_LIT:2> * amount_issued <EOL> print logs <EOL> while logs and logs . pop ( ) : <EOL> pass <EOL> nc . registry . unregister ( IOU ) </s>
<s> """<STR_LIT>""" <EOL> import json <EOL> import time <EOL> import urllib2 <EOL> import logging <EOL> from view_controls . view import DrawingTool , Event <EOL> from game_objects . item import Item <EOL> from game_objects . state import TrackerState , TrackerStateEncoder <EOL> from log_parser import LogParser <EOL> from options import Options <EOL> class IsaacTracker ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , logging_level = logging . INFO , read_timer = <NUM_LIT:1> ) : <EOL> self . read_timer = read_timer <EOL> self . file_prefix = "<STR_LIT>" <EOL> self . log = logging . getLogger ( "<STR_LIT>" ) <EOL> self . log . addHandler ( logging . FileHandler ( self . file_prefix + "<STR_LIT>" , mode = '<STR_LIT:w>' ) ) <EOL> self . log . setLevel ( logging_level ) <EOL> with open ( self . file_prefix + "<STR_LIT>" , "<STR_LIT:r>" ) as items_file : <EOL> Item . items_info = json . load ( items_file ) <EOL> with open ( self . file_prefix + '<STR_LIT>' , '<STR_LIT:r>' ) as f : <EOL> self . tracker_version = f . read ( ) <EOL> Options ( ) . load_options ( self . file_prefix + "<STR_LIT>" ) <EOL> def __del__ ( self ) : <EOL> Options ( ) . save_options ( self . file_prefix + "<STR_LIT>" ) <EOL> def check_for_update ( self ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> latest = "<STR_LIT>" <EOL> github_info_json = urllib2 . urlopen ( latest ) . read ( ) <EOL> info = json . loads ( github_info_json ) <EOL> latest_version = info [ "<STR_LIT:name>" ] <EOL> title_text = "<STR_LIT>" + self . tracker_version <EOL> if latest_version != self . tracker_version : <EOL> title_text += "<STR_LIT>" <EOL> return title_text <EOL> except Exception as e : <EOL> self . log . debug ( "<STR_LIT>" + e . message ) <EOL> return "<STR_LIT>" <EOL> def run ( self ) : <EOL> """<STR_LIT>""" <EOL> update_notifier = self . check_for_update ( ) <EOL> framecount = <NUM_LIT:0> <EOL> drawing_tool = DrawingTool ( self . file_prefix ) <EOL> drawing_tool . set_window_title ( update_notifier ) <EOL> parser = LogParser ( self . file_prefix , self . tracker_version ) <EOL> opt = Options ( ) <EOL> log = logging . getLogger ( "<STR_LIT>" ) <EOL> event_result = None <EOL> state = None <EOL> read_from_server = opt . read_from_server <EOL> write_to_server = opt . write_to_server <EOL> state_version = - <NUM_LIT:1> <EOL> twitch_username = None <EOL> new_states_queue = [ ] <EOL> screen_error_message = None <EOL> while event_result != Event . DONE : <EOL> event_result = drawing_tool . handle_events ( ) <EOL> if opt . read_from_server != read_from_server or opt . twitch_name != twitch_username : <EOL> twitch_username = opt . twitch_name <EOL> read_from_server = opt . read_from_server <EOL> new_states_queue = [ ] <EOL> if read_from_server : <EOL> state_version = - <NUM_LIT:1> <EOL> state = None <EOL> drawing_tool . set_window_title ( update_notifier , watching_player = twitch_username , updates_queued = len ( new_states_queue ) ) <EOL> else : <EOL> drawing_tool . set_window_title ( update_notifier ) <EOL> if opt . write_to_server and opt . write_to_server != write_to_server : <EOL> write_to_server = True <EOL> drawing_tool . set_window_title ( update_notifier , uploading = True ) <EOL> if not opt . write_to_server : <EOL> write_to_server = False <EOL> if opt . read_from_server : <EOL> update_timer = <NUM_LIT:2> <EOL> else : <EOL> update_timer = self . read_timer <EOL> if event_result == Event . OPTIONS_UPDATE : <EOL> framecount = <NUM_LIT:0> <EOL> screen_error_message = None <EOL> if state is not None : <EOL> state . modified = True <EOL> if ( framecount % int ( Options ( ) . framerate_limit * update_timer ) == <NUM_LIT:0> ) : <EOL> if opt . read_from_server : <EOL> base_url = opt . trackerserver_url + "<STR_LIT>" + opt . twitch_name <EOL> json_dict = None <EOL> try : <EOL> json_version = urllib2 . urlopen ( base_url + "<STR_LIT>" ) . read ( ) <EOL> if int ( json_version ) > state_version : <EOL> json_state = urllib2 . urlopen ( base_url ) . read ( ) <EOL> json_dict = json . loads ( json_state ) <EOL> new_state = TrackerState . from_json ( json_dict ) <EOL> if new_state is None : <EOL> raise Exception <EOL> state_version = int ( json_version ) <EOL> new_states_queue . append ( ( state_version , new_state ) ) <EOL> drawing_tool . set_window_title ( update_notifier , watching_player = twitch_username , updates_queued = len ( new_states_queue ) , read_delay = opt . read_delay ) <EOL> except Exception : <EOL> state = None <EOL> log . error ( "<STR_LIT>" ) <EOL> import traceback <EOL> log . error ( traceback . format_exc ( ) ) <EOL> if json_dict is not None : <EOL> their_version = "<STR_LIT>" <EOL> if "<STR_LIT>" in json_dict : <EOL> their_version = json_dict [ "<STR_LIT>" ] <EOL> else : <EOL> their_version = "<STR_LIT>" <EOL> if their_version != self . tracker_version : <EOL> screen_error_message = "<STR_LIT>" + their_version + "<STR_LIT>" + self . tracker_version <EOL> else : <EOL> force_draw = state and state . modified <EOL> state = parser . parse ( ) <EOL> if force_draw : <EOL> state . modified = True <EOL> if write_to_server and not opt . trackerserver_authkey : <EOL> screen_error_message = "<STR_LIT>" <EOL> if state is not None and write_to_server and state . modified and screen_error_message is None : <EOL> opener = urllib2 . build_opener ( urllib2 . HTTPHandler ) <EOL> put_url = opt . trackerserver_url + "<STR_LIT>" + opt . trackerserver_authkey <EOL> json_string = json . dumps ( state , cls = TrackerStateEncoder , sort_keys = True ) <EOL> request = urllib2 . Request ( put_url , <EOL> data = json_string ) <EOL> request . add_header ( '<STR_LIT:Content-Type>' , '<STR_LIT:application/json>' ) <EOL> request . get_method = lambda : '<STR_LIT>' <EOL> try : <EOL> result = opener . open ( request ) <EOL> result_json = json . loads ( result . read ( ) ) <EOL> updated_user = result_json [ "<STR_LIT>" ] <EOL> if updated_user is None : <EOL> screen_error_message = "<STR_LIT>" <EOL> else : <EOL> screen_error_message = None <EOL> except Exception as e : <EOL> import traceback <EOL> errmsg = traceback . format_exc ( ) <EOL> log . error ( "<STR_LIT>" ) <EOL> log . error ( errmsg ) <EOL> screen_error_message = "<STR_LIT>" <EOL> if len ( new_states_queue ) > <NUM_LIT:0> : <EOL> ( state_timestamp , new_state ) = new_states_queue [ <NUM_LIT:0> ] <EOL> current_timestamp = int ( time . time ( ) ) <EOL> if current_timestamp - state_timestamp >= opt . read_delay or state is None : <EOL> state = new_state <EOL> new_states_queue . pop ( <NUM_LIT:0> ) <EOL> drawing_tool . set_window_title ( update_notifier , watching_player = twitch_username , updates_queued = len ( new_states_queue ) , read_delay = opt . read_delay ) <EOL> if state is None and screen_error_message is None : <EOL> if read_from_server : <EOL> screen_error_message = "<STR_LIT>" <EOL> else : <EOL> screen_error_message = "<STR_LIT>" <EOL> if screen_error_message is not None : <EOL> drawing_tool . write_error_message ( screen_error_message ) <EOL> else : <EOL> drawing_tool . draw_state ( state ) <EOL> drawing_tool . tick ( ) <EOL> framecount += <NUM_LIT:1> <EOL> drawing_tool . save_window_position ( ) <EOL> def main ( ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> rt = IsaacTracker ( ) <EOL> rt . run ( ) <EOL> except Exception : <EOL> import traceback <EOL> errmsg = traceback . format_exc ( ) <EOL> print ( errmsg ) <EOL> logging . getLogger ( "<STR_LIT>" ) . error ( errmsg ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> main ( ) </s>
<s> from __future__ import division , print_function , unicode_literals <EOL> from collections import OrderedDict <EOL> from brainstorm . layers . base_layer import Layer <EOL> from brainstorm . structure . buffer_structure import ( BufferStructure , <EOL> StructureTemplate ) <EOL> from brainstorm . structure . construction import ConstructionWrapper <EOL> from brainstorm . utils import flatten_all_but_last <EOL> def BatchNorm ( name = None , decay = <NUM_LIT> , epsilon = <NUM_LIT> ) : <EOL> """<STR_LIT>""" <EOL> return ConstructionWrapper . create ( BatchNormLayerImpl , <EOL> name = name , <EOL> decay = decay , <EOL> epsilon = epsilon ) <EOL> class BatchNormLayerImpl ( Layer ) : <EOL> expected_inputs = { '<STR_LIT:default>' : StructureTemplate ( '<STR_LIT:T>' , '<STR_LIT:B>' , '<STR_LIT>' ) } <EOL> expected_kwargs = { '<STR_LIT>' , '<STR_LIT>' } <EOL> def setup ( self , kwargs , in_shapes ) : <EOL> self . epsilon = kwargs . get ( '<STR_LIT>' , <NUM_LIT> ) <EOL> self . decay = kwargs . get ( '<STR_LIT>' , <NUM_LIT> ) <EOL> assert <NUM_LIT:0.0> <= self . decay <= <NUM_LIT:1.0> , "<STR_LIT>" <EOL> outputs = OrderedDict ( ) <EOL> outputs [ '<STR_LIT:default>' ] = in_shapes [ '<STR_LIT:default>' ] <EOL> parameters = OrderedDict ( ) <EOL> buf = BufferStructure ( self . in_shapes [ '<STR_LIT:default>' ] . feature_shape [ - <NUM_LIT:1> ] ) <EOL> parameters [ '<STR_LIT>' ] = buf <EOL> parameters [ '<STR_LIT>' ] = buf <EOL> parameters [ '<STR_LIT>' ] = buf <EOL> parameters [ '<STR_LIT>' ] = buf <EOL> internals = OrderedDict ( ) <EOL> internals [ '<STR_LIT>' ] = buf <EOL> internals [ '<STR_LIT>' ] = self . in_shapes [ '<STR_LIT:default>' ] <EOL> internals [ '<STR_LIT>' ] = self . in_shapes [ '<STR_LIT:default>' ] <EOL> return outputs , parameters , internals <EOL> def forward_pass ( self , buffers , training_pass = True ) : <EOL> _h = self . handler <EOL> sigma_b , centered , x_hat = buffers . internals <EOL> gamma , beta , mu , sigma = buffers . parameters <EOL> inputs = flatten_all_but_last ( buffers . inputs . default ) <EOL> centered = flatten_all_but_last ( centered ) <EOL> x_hat = flatten_all_but_last ( x_hat ) <EOL> out = flatten_all_but_last ( buffers . outputs . default ) <EOL> m = inputs . shape [ <NUM_LIT:0> ] <EOL> if training_pass : <EOL> mu_b = sigma_b <EOL> _h . sum_t ( inputs , <NUM_LIT:0> , mu_b ) <EOL> _h . mult_st ( - <NUM_LIT:1.0> / m , mu_b , mu_b ) <EOL> _h . mult_st ( self . decay , mu , mu ) <EOL> _h . mult_add_st ( <NUM_LIT:1.0> - self . decay , mu_b , mu ) <EOL> mu = mu_b <EOL> _h . add_mv ( inputs , mu . reshape ( ( <NUM_LIT:1> , mu . size ) ) , centered ) <EOL> if training_pass : <EOL> sigma2 = sigma_b <EOL> centered2 = x_hat <EOL> _h . mult_tt ( centered , centered , centered2 ) <EOL> _h . sum_t ( centered2 , <NUM_LIT:0> , sigma2 ) <EOL> _h . mult_st ( <NUM_LIT:1.0> / m , sigma2 , sigma2 ) <EOL> _h . add_st ( self . epsilon , sigma2 , sigma2 ) <EOL> _h . sqrt_t ( sigma2 , sigma_b ) <EOL> _h . mult_st ( self . decay , sigma , sigma ) <EOL> _h . mult_add_st ( <NUM_LIT:1.0> - self . decay , sigma_b , sigma ) <EOL> sigma = sigma_b <EOL> _h . divide_mv ( centered , sigma . reshape ( ( <NUM_LIT:1> , sigma . size ) ) , x_hat ) <EOL> _h . mult_mv ( x_hat , gamma . reshape ( ( <NUM_LIT:1> , gamma . size ) ) , out ) <EOL> _h . add_mv ( out , beta . reshape ( ( <NUM_LIT:1> , beta . size ) ) , out ) <EOL> def backward_pass ( self , buffers ) : <EOL> _h = self . handler <EOL> sigma_b , centered , x_hat = buffers . internals <EOL> gamma = buffers . parameters . gamma <EOL> dgamma = buffers . gradients . gamma <EOL> dbeta = buffers . gradients . beta <EOL> x_hat = flatten_all_but_last ( x_hat ) <EOL> outdeltas = flatten_all_but_last ( buffers . output_deltas . default ) <EOL> indeltas = flatten_all_but_last ( buffers . input_deltas . default ) <EOL> m = outdeltas . shape [ <NUM_LIT:0> ] <EOL> big_tmp = _h . allocate ( x_hat . shape ) <EOL> small_tmp = _h . allocate ( gamma . shape ) <EOL> tmp = big_tmp <EOL> dgamma_tmp = small_tmp <EOL> _h . mult_tt ( outdeltas , x_hat , tmp ) <EOL> _h . sum_t ( tmp , axis = <NUM_LIT:0> , out = dgamma_tmp ) <EOL> _h . add_tt ( dgamma_tmp , dgamma , dgamma ) <EOL> _h . mult_st ( <NUM_LIT:1> / m , dgamma_tmp , dgamma_tmp ) <EOL> term1 = big_tmp <EOL> _h . mult_mv ( x_hat , dgamma_tmp . reshape ( ( <NUM_LIT:1> , gamma . size ) ) , term1 ) <EOL> dbeta_tmp = small_tmp <EOL> _h . sum_t ( outdeltas , axis = <NUM_LIT:0> , out = dbeta_tmp ) <EOL> _h . add_tt ( dbeta_tmp , dbeta , dbeta ) <EOL> _h . mult_st ( <NUM_LIT:1> / m , dbeta_tmp , dbeta_tmp ) <EOL> term2 = big_tmp <EOL> term3 = big_tmp <EOL> _h . subtract_tt ( outdeltas , term1 , term2 ) <EOL> _h . subtract_mv ( term2 , dbeta_tmp . reshape ( ( <NUM_LIT:1> , dbeta . size ) ) , term3 ) <EOL> coeff = small_tmp <EOL> _h . divide_tt ( gamma , sigma_b , coeff ) <EOL> term4 = big_tmp <EOL> _h . mult_mv ( term3 , coeff . reshape ( ( <NUM_LIT:1> , coeff . size ) ) , term4 ) <EOL> _h . add_tt ( term4 , indeltas , indeltas ) </s>
<s> from __future__ import division , print_function , unicode_literals <EOL> from collections import OrderedDict <EOL> import numpy as np <EOL> from brainstorm . describable import Describable <EOL> class Scorer ( Describable ) : <EOL> def __init__ ( self , out_name = '<STR_LIT>' , targets_name = '<STR_LIT>' , mask_name = '<STR_LIT>' , <EOL> name = None ) : <EOL> self . out_name = out_name <EOL> self . targets_name = targets_name <EOL> self . mask_name = mask_name <EOL> self . __name__ = name if name is not None else self . __class__ . __name__ <EOL> def __call__ ( self , true_labels , predicted , mask = None ) : <EOL> pass <EOL> @ staticmethod <EOL> def aggregate ( errors ) : <EOL> errors = np . array ( errors ) <EOL> assert errors . ndim == <NUM_LIT:2> and errors . shape [ <NUM_LIT:1> ] == <NUM_LIT:2> <EOL> return np . sum ( errors [ : , <NUM_LIT:1> ] ) / np . sum ( errors [ : , <NUM_LIT:0> ] ) <EOL> def gather_losses_and_scores ( net , scorers , scores , out_name = '<STR_LIT>' , <EOL> targets_name = '<STR_LIT>' , mask_name = '<STR_LIT>' ) : <EOL> ls = net . get_loss_values ( ) <EOL> for name , loss in ls . items ( ) : <EOL> scores [ name ] . append ( ( net . _buffer_manager . batch_size , loss ) ) <EOL> for sc in scorers : <EOL> name = sc . __name__ <EOL> predicted = net . get ( sc . out_name or out_name or net . output_name ) <EOL> true_labels = net . get_input ( sc . targets_name ) if sc . targets_name else net . get_input ( targets_name ) <EOL> mask = net . get_input ( sc . mask_name ) if sc . mask_name else ( net . get_input ( mask_name ) if mask_name else None ) <EOL> predicted = _flatten_all_but_last ( predicted ) <EOL> true_labels = _flatten_all_but_last ( true_labels ) <EOL> mask = _flatten_all_but_last ( mask ) <EOL> weight = mask . sum ( ) if mask is not None else predicted . shape [ <NUM_LIT:0> ] <EOL> scores [ name ] . append ( ( weight , sc ( true_labels , predicted , mask ) ) ) <EOL> def aggregate_losses_and_scores ( scores , net , scorers ) : <EOL> results = OrderedDict ( ) <EOL> for name in net . get_loss_values ( ) : <EOL> results [ name ] = _weighted_average ( scores [ name ] ) <EOL> for sc in scorers : <EOL> results [ sc . __name__ ] = sc . aggregate ( scores [ sc . __name__ ] ) <EOL> return results <EOL> class Accuracy ( Scorer ) : <EOL> def __call__ ( self , true_labels , predicted , mask = None ) : <EOL> if predicted . shape [ <NUM_LIT:1> ] > <NUM_LIT:1> : <EOL> predicted = predicted . argmax ( <NUM_LIT:1> ) . reshape ( - <NUM_LIT:1> , <NUM_LIT:1> ) <EOL> correct = ( predicted == true_labels ) . astype ( np . float ) <EOL> if mask is not None : <EOL> correct *= mask <EOL> return np . sum ( correct ) <EOL> class Hamming ( Scorer ) : <EOL> def __init__ ( self , threshold = <NUM_LIT:0.5> , out_name = '<STR_LIT>' , targets_name = '<STR_LIT>' , <EOL> mask_name = '<STR_LIT>' , name = None ) : <EOL> super ( Hamming , self ) . __init__ ( out_name , targets_name , mask_name , name ) <EOL> self . threshold = threshold <EOL> def __call__ ( self , true_labels , predicted , mask = None ) : <EOL> correct = np . logical_xor ( predicted < self . threshold , <EOL> true_labels ) . astype ( np . float ) <EOL> if mask is not None : <EOL> correct *= mask <EOL> return np . sum ( correct ) / true_labels . shape [ <NUM_LIT:1> ] <EOL> class MeanSquaredError ( Scorer ) : <EOL> def __call__ ( self , true_labels , predicted , mask = None ) : <EOL> errors = ( true_labels - predicted ) ** <NUM_LIT:2> <EOL> if mask is not None : <EOL> errors *= mask <EOL> return <NUM_LIT:0.5> * np . sum ( errors ) <EOL> def _flatten_all_but_last ( a ) : <EOL> if a is None : <EOL> return None <EOL> return a . reshape ( - <NUM_LIT:1> , a . shape [ - <NUM_LIT:1> ] ) <EOL> def _weighted_average ( errors ) : <EOL> errors = np . array ( errors ) <EOL> assert errors . ndim == <NUM_LIT:2> and errors . shape [ <NUM_LIT:1> ] == <NUM_LIT:2> <EOL> return np . sum ( errors [ : , <NUM_LIT:1> ] * errors [ : , <NUM_LIT:0> ] / np . sum ( errors [ : , <NUM_LIT:0> ] ) ) </s>
<s> from __future__ import division , print_function , unicode_literals <EOL> import pytest <EOL> import six <EOL> from brainstorm . training . schedules import Exponential , Linear , MultiStep <EOL> def test_linear ( ) : <EOL> sch = Linear ( initial_value = <NUM_LIT:1.0> , final_value = <NUM_LIT:0.5> , num_changes = <NUM_LIT:5> ) <EOL> epochs = [ <NUM_LIT:0> ] * <NUM_LIT:2> + [ <NUM_LIT:1> ] * <NUM_LIT:2> + [ <NUM_LIT:2> ] * <NUM_LIT:2> + [ <NUM_LIT:3> ] * <NUM_LIT:2> + [ <NUM_LIT:4> ] * <NUM_LIT:2> <EOL> updates = range ( <NUM_LIT:10> ) <EOL> values = [ sch ( epoch , update , '<STR_LIT>' , <NUM_LIT:1> , None , None , None ) <EOL> for epoch , update in six . moves . zip ( epochs , updates ) ] <EOL> assert values == [ <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] <EOL> values = [ sch ( epoch , update , '<STR_LIT>' , <NUM_LIT:1> , None , None , None ) <EOL> for epoch , update in six . moves . zip ( epochs , updates ) ] <EOL> assert values == [ <NUM_LIT:1.0> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT:0.5> , <NUM_LIT:0.5> , <NUM_LIT:0.5> , <NUM_LIT:0.5> , <NUM_LIT:0.5> ] <EOL> values = [ sch ( epoch , update , '<STR_LIT>' , <NUM_LIT:3> , None , None , None ) <EOL> for epoch , update in six . moves . zip ( epochs , updates ) ] <EOL> assert values == [ <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] <EOL> def test_exponential ( ) : <EOL> sch = Exponential ( initial_value = <NUM_LIT:1.0> , factor = <NUM_LIT> , minimum = <NUM_LIT> ) <EOL> epochs = [ <NUM_LIT:0> ] * <NUM_LIT:4> + [ <NUM_LIT:1> ] * <NUM_LIT:4> + [ <NUM_LIT:2> ] * <NUM_LIT:4> <EOL> updates = range ( <NUM_LIT:12> ) <EOL> values = [ sch ( epoch , update , '<STR_LIT>' , <NUM_LIT:1> , None , None , None ) <EOL> for epoch , update in six . moves . zip ( epochs , updates ) ] <EOL> assert values == [ <NUM_LIT:1.0> ] * <NUM_LIT:4> + [ <NUM_LIT> ] * <NUM_LIT:4> + [ <NUM_LIT> * <NUM_LIT> ] * <NUM_LIT:4> <EOL> values = [ sch ( epoch , update , '<STR_LIT>' , <NUM_LIT:1> , None , None , None ) <EOL> for epoch , update in six . moves . zip ( epochs , updates ) ] <EOL> assert values == [ <NUM_LIT:1.0> * ( <NUM_LIT> ** x ) for x in range ( <NUM_LIT:4> ) ] + [ <NUM_LIT> ] * <NUM_LIT:8> <EOL> values = [ sch ( epoch , update , '<STR_LIT>' , <NUM_LIT:3> , None , None , None ) <EOL> for epoch , update in six . moves . zip ( epochs , updates ) ] <EOL> assert values == [ <NUM_LIT:1.0> ] * <NUM_LIT:3> + [ <NUM_LIT> ] * <NUM_LIT:3> + [ <NUM_LIT> ] * <NUM_LIT:3> + [ <NUM_LIT> ** <NUM_LIT:3> ] * <NUM_LIT:3> <EOL> def test_multistep ( ) : <EOL> sch = MultiStep ( initial_value = <NUM_LIT:1.0> , steps = [ <NUM_LIT:3> , <NUM_LIT:5> , <NUM_LIT:8> ] , <EOL> values = [ <NUM_LIT:0.1> , <NUM_LIT> , <NUM_LIT> ] ) <EOL> epochs = [ <NUM_LIT:0> ] * <NUM_LIT:2> + [ <NUM_LIT:1> ] * <NUM_LIT:2> + [ <NUM_LIT:2> ] * <NUM_LIT:2> + [ <NUM_LIT:3> ] * <NUM_LIT:2> + [ <NUM_LIT:4> ] * <NUM_LIT:2> <EOL> updates = range ( <NUM_LIT:10> ) <EOL> values = [ sch ( epoch , update , '<STR_LIT>' , <NUM_LIT:1> , None , None , None ) <EOL> for epoch , update in six . moves . zip ( epochs , updates ) ] <EOL> assert values == [ <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:0.1> , <NUM_LIT:0.1> , <NUM_LIT:0.1> , <NUM_LIT:0.1> ] <EOL> values = [ sch ( epoch , update , '<STR_LIT>' , <NUM_LIT:1> , None , None , None ) <EOL> for epoch , update in six . moves . zip ( epochs , updates ) ] <EOL> assert values == [ <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:0.1> , <NUM_LIT:0.1> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] <EOL> with pytest . raises ( AssertionError ) : <EOL> _ = sch ( <NUM_LIT:0> , <NUM_LIT:0> , '<STR_LIT>' , <NUM_LIT:3> , None , None , None ) </s>
<s> import os <EOL> import sys <EOL> try : <EOL> from unittest . mock import MagicMock <EOL> except ImportError : <EOL> from mock import Mock as MagicMock <EOL> class Mock ( MagicMock ) : <EOL> @ classmethod <EOL> def __getattr__ ( cls , name ) : <EOL> return Mock ( ) <EOL> MOCK_MODULES = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> sys . modules . update ( ( mod_name , Mock ( ) ) for mod_name in MOCK_MODULES ) <EOL> cwd = os . getcwd ( ) <EOL> parent = os . path . dirname ( cwd ) <EOL> sys . path . insert ( <NUM_LIT:0> , parent ) <EOL> import brainstorm <EOL> extensions = [ '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' ] <EOL> templates_path = [ '<STR_LIT>' ] <EOL> source_suffix = '<STR_LIT>' <EOL> master_doc = '<STR_LIT:index>' <EOL> project = u'<STR_LIT>' <EOL> copyright = u'<STR_LIT>' <EOL> version = brainstorm . __version__ <EOL> release = brainstorm . __version__ <EOL> exclude_patterns = [ '<STR_LIT>' ] <EOL> pygments_style = '<STR_LIT>' <EOL> on_rtd = os . environ . get ( '<STR_LIT>' , None ) == '<STR_LIT:True>' <EOL> if not on_rtd : <EOL> try : <EOL> import sphinx_rtd_theme <EOL> html_theme = '<STR_LIT>' <EOL> html_theme_path = [ sphinx_rtd_theme . get_html_theme_path ( ) ] <EOL> except ImportError : <EOL> html_theme = '<STR_LIT>' <EOL> html_static_path = [ '<STR_LIT>' ] <EOL> htmlhelp_basename = '<STR_LIT>' <EOL> latex_elements = { <EOL> } <EOL> latex_documents = [ <EOL> ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , <EOL> u'<STR_LIT>' , '<STR_LIT>' ) , <EOL> ] <EOL> man_pages = [ <EOL> ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , <EOL> [ u'<STR_LIT>' ] , <NUM_LIT:1> ) <EOL> ] <EOL> texinfo_documents = [ <EOL> ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , <EOL> u'<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' ) , <EOL> ] </s>
<s> from __future__ import division , print_function , unicode_literals <EOL> from sacred . utils import iter_prefixes , join_paths <EOL> class ConfigSummary ( dict ) : <EOL> def __init__ ( self , added = ( ) , modified = ( ) , typechanged = ( ) , <EOL> ignored_fallbacks = ( ) ) : <EOL> super ( ConfigSummary , self ) . __init__ ( ) <EOL> self . added = set ( added ) <EOL> self . modified = set ( modified ) <EOL> self . typechanged = dict ( typechanged ) <EOL> self . ignored_fallbacks = set ( ignored_fallbacks ) <EOL> self . ensure_coherence ( ) <EOL> def update_from ( self , config_mod , path = '<STR_LIT>' ) : <EOL> added = config_mod . added <EOL> updated = config_mod . modified <EOL> typechanged = config_mod . typechanged <EOL> self . added &= { join_paths ( path , a ) for a in added } <EOL> self . modified |= { join_paths ( path , u ) for u in updated } <EOL> self . typechanged . update ( { join_paths ( path , k ) : v <EOL> for k , v in typechanged . items ( ) } ) <EOL> self . ensure_coherence ( ) <EOL> def update_add ( self , config_mod , path = '<STR_LIT>' ) : <EOL> added = config_mod . added <EOL> updated = config_mod . modified <EOL> typechanged = config_mod . typechanged <EOL> self . added |= { join_paths ( path , a ) for a in added } <EOL> self . modified |= { join_paths ( path , u ) for u in updated } <EOL> self . typechanged . update ( { join_paths ( path , k ) : v <EOL> for k , v in typechanged . items ( ) } ) <EOL> self . ensure_coherence ( ) <EOL> def ensure_coherence ( self ) : <EOL> self . modified |= { p for a in self . added for p in iter_prefixes ( a ) } <EOL> self . modified |= { p for u in self . modified for p in iter_prefixes ( u ) } <EOL> self . modified |= { p for t in self . typechanged <EOL> for p in iter_prefixes ( t ) } <EOL> self . added -= set ( self . typechanged . keys ( ) ) <EOL> self . modified -= set ( self . typechanged . keys ( ) ) <EOL> self . modified -= self . added </s>
<s> from __future__ import division , print_function , unicode_literals <EOL> import pytest <EOL> import sacred . optional as opt <EOL> from sacred . config import ConfigDict <EOL> from sacred . config . custom_containers import DogmaticDict , DogmaticList <EOL> @ pytest . fixture <EOL> def conf_dict ( ) : <EOL> cfg = ConfigDict ( { <EOL> "<STR_LIT:a>" : <NUM_LIT:1> , <EOL> "<STR_LIT:b>" : <NUM_LIT> , <EOL> "<STR_LIT:c>" : True , <EOL> "<STR_LIT:d>" : '<STR_LIT:string>' , <EOL> "<STR_LIT:e>" : [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] , <EOL> "<STR_LIT:f>" : { '<STR_LIT:a>' : '<STR_LIT:b>' , '<STR_LIT:c>' : '<STR_LIT:d>' } , <EOL> } ) <EOL> return cfg <EOL> def test_config_dict_returns_dict ( conf_dict ) : <EOL> assert isinstance ( conf_dict ( ) , dict ) <EOL> def test_config_dict_result_contains_keys ( conf_dict ) : <EOL> cfg = conf_dict ( ) <EOL> assert set ( cfg . keys ( ) ) == { '<STR_LIT:a>' , '<STR_LIT:b>' , '<STR_LIT:c>' , '<STR_LIT:d>' , '<STR_LIT:e>' , '<STR_LIT:f>' } <EOL> assert cfg [ '<STR_LIT:a>' ] == <NUM_LIT:1> <EOL> assert cfg [ '<STR_LIT:b>' ] == <NUM_LIT> <EOL> assert cfg [ '<STR_LIT:c>' ] <EOL> assert cfg [ '<STR_LIT:d>' ] == '<STR_LIT:string>' <EOL> assert cfg [ '<STR_LIT:e>' ] == [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] <EOL> assert cfg [ '<STR_LIT:f>' ] == { '<STR_LIT:a>' : '<STR_LIT:b>' , '<STR_LIT:c>' : '<STR_LIT:d>' } <EOL> def test_fixing_values ( conf_dict ) : <EOL> assert conf_dict ( { '<STR_LIT:a>' : <NUM_LIT:100> } ) [ '<STR_LIT:a>' ] == <NUM_LIT:100> <EOL> @ pytest . mark . parametrize ( "<STR_LIT:key>" , [ "<STR_LIT>" , "<STR_LIT>" , <NUM_LIT:12> , "<STR_LIT>" , "<STR_LIT>" ] ) <EOL> def test_config_dict_raises_on_invalid_keys ( key ) : <EOL> with pytest . raises ( KeyError ) : <EOL> ConfigDict ( { key : True } ) <EOL> @ pytest . mark . parametrize ( "<STR_LIT:value>" , [ lambda x : x , pytest , test_fixing_values ] ) <EOL> def test_config_dict_raises_on_invalid_values ( value ) : <EOL> with pytest . raises ( ValueError ) : <EOL> ConfigDict ( { "<STR_LIT>" : value } ) <EOL> def test_fixing_nested_dicts ( conf_dict ) : <EOL> cfg = conf_dict ( { '<STR_LIT:f>' : { '<STR_LIT:c>' : '<STR_LIT:t>' } } ) <EOL> assert cfg [ '<STR_LIT:f>' ] [ '<STR_LIT:a>' ] == '<STR_LIT:b>' <EOL> assert cfg [ '<STR_LIT:f>' ] [ '<STR_LIT:c>' ] == '<STR_LIT:t>' <EOL> def test_adding_values ( conf_dict ) : <EOL> cfg = conf_dict ( { '<STR_LIT:g>' : <NUM_LIT> , '<STR_LIT:h>' : { '<STR_LIT:i>' : <NUM_LIT:10> } } ) <EOL> assert cfg [ '<STR_LIT:g>' ] == <NUM_LIT> <EOL> assert cfg [ '<STR_LIT:h>' ] == { '<STR_LIT:i>' : <NUM_LIT:10> } <EOL> assert cfg . added == { '<STR_LIT:g>' , '<STR_LIT:h>' , '<STR_LIT>' } <EOL> def test_typechange ( conf_dict ) : <EOL> cfg = conf_dict ( { '<STR_LIT:a>' : '<STR_LIT:bar>' , '<STR_LIT:b>' : '<STR_LIT:foo>' , '<STR_LIT:c>' : <NUM_LIT:1> } ) <EOL> assert cfg . typechanged == { '<STR_LIT:a>' : ( int , type ( '<STR_LIT:bar>' ) ) , <EOL> '<STR_LIT:b>' : ( float , type ( '<STR_LIT:foo>' ) ) , <EOL> '<STR_LIT:c>' : ( bool , int ) } <EOL> def test_nested_typechange ( conf_dict ) : <EOL> cfg = conf_dict ( { '<STR_LIT:f>' : { '<STR_LIT:a>' : <NUM_LIT:10> } } ) <EOL> assert cfg . typechanged == { '<STR_LIT>' : ( type ( '<STR_LIT:a>' ) , int ) } <EOL> def is_dogmatic ( a ) : <EOL> if isinstance ( a , ( DogmaticDict , DogmaticList ) ) : <EOL> return True <EOL> elif isinstance ( a , dict ) : <EOL> return any ( is_dogmatic ( v ) for v in a . values ( ) ) <EOL> elif isinstance ( a , ( list , tuple ) ) : <EOL> return any ( is_dogmatic ( v ) for v in a ) <EOL> def test_result_of_conf_dict_is_not_dogmatic ( conf_dict ) : <EOL> cfg = conf_dict ( { '<STR_LIT:e>' : [ <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> ] } ) <EOL> assert not is_dogmatic ( cfg ) <EOL> @ pytest . mark . skipif ( not opt . has_numpy , reason = "<STR_LIT>" ) <EOL> def test_conf_scope_handles_numpy_bools ( ) : <EOL> cfg = ConfigDict ( { <EOL> "<STR_LIT:a>" : opt . np . bool_ ( <NUM_LIT:1> ) <EOL> } ) <EOL> assert '<STR_LIT:a>' in cfg ( ) <EOL> assert cfg ( ) [ '<STR_LIT:a>' ] <EOL> def test_conf_scope_contains_presets ( ) : <EOL> conf_dict = ConfigDict ( { <EOL> "<STR_LIT>" : <NUM_LIT> <EOL> } ) <EOL> cfg = conf_dict ( preset = { '<STR_LIT:a>' : <NUM_LIT> , '<STR_LIT>' : True } ) <EOL> assert set ( cfg . keys ( ) ) == { '<STR_LIT:a>' , '<STR_LIT>' , '<STR_LIT>' } <EOL> assert cfg [ '<STR_LIT:a>' ] == <NUM_LIT> <EOL> assert cfg [ '<STR_LIT>' ] == <NUM_LIT> <EOL> assert cfg [ '<STR_LIT>' ] is True <EOL> def test_conf_scope_does_not_contain_fallback ( ) : <EOL> config_dict = ConfigDict ( { <EOL> "<STR_LIT>" : <NUM_LIT> <EOL> } ) <EOL> cfg = config_dict ( fallback = { '<STR_LIT:a>' : <NUM_LIT> , '<STR_LIT:b>' : <NUM_LIT:10> } ) <EOL> assert set ( cfg . keys ( ) ) == { '<STR_LIT>' } <EOL> def test_fixed_subentry_of_preset ( ) : <EOL> config_dict = ConfigDict ( { } ) <EOL> cfg = config_dict ( preset = { '<STR_LIT:d>' : { '<STR_LIT:a>' : <NUM_LIT:1> , '<STR_LIT:b>' : <NUM_LIT:2> } } , fixed = { '<STR_LIT:d>' : { '<STR_LIT:a>' : <NUM_LIT:10> } } ) <EOL> assert set ( cfg . keys ( ) ) == { '<STR_LIT:d>' } <EOL> assert set ( cfg [ '<STR_LIT:d>' ] . keys ( ) ) == { '<STR_LIT:a>' , '<STR_LIT:b>' } <EOL> assert cfg [ '<STR_LIT:d>' ] [ '<STR_LIT:a>' ] == <NUM_LIT:10> <EOL> assert cfg [ '<STR_LIT:d>' ] [ '<STR_LIT:b>' ] == <NUM_LIT:2> </s>
<s> class PID ( object ) : <EOL> def __init__ ( self ) : <EOL> """<STR_LIT>""" <EOL> self . kd = <NUM_LIT:0> <EOL> self . ki = <NUM_LIT:0> <EOL> self . kp = <NUM_LIT:1> <EOL> self . previous_error = <NUM_LIT:0> <EOL> self . integral_error = <NUM_LIT:0> <EOL> def set_k_values ( self , kp , kd , ki ) : <EOL> self . kp = kp <EOL> self . ki = ki <EOL> self . kd = kd <EOL> def clear_error ( self ) : <EOL> self . previous_error = <NUM_LIT:0> <EOL> self . integeral_error = <NUM_LIT:0> <EOL> def pid ( self , target , process_var , timestep ) : <EOL> current_error = ( target - process_var ) <EOL> p_error = self . kp * current_error <EOL> d_error = self . kd * ( current_error - self . previous_error ) / timestep <EOL> self . integral_error = ( <EOL> current_error + self . previous_error ) / <NUM_LIT:2> + self . integral_error <EOL> i_error = self . ki * self . integral_error <EOL> total_error = p_error + d_error + i_error <EOL> self . previous_error = current_error <EOL> return total_error </s>
<s> """<STR_LIT>""" <EOL> import cmd <EOL> import sys <EOL> import os <EOL> import bot . client . ctrl_client as ctrl_client_mod <EOL> import bot . client . sub_client as sub_client_mod <EOL> class CLI ( cmd . Cmd ) : <EOL> """<STR_LIT>""" <EOL> prompt = "<STR_LIT>" <EOL> def __init__ ( self , ctrl_addr , sub_addr ) : <EOL> """<STR_LIT>""" <EOL> cmd . Cmd . __init__ ( self ) <EOL> try : <EOL> self . ctrl_client = ctrl_client_mod . CtrlClient ( ctrl_addr ) <EOL> except Exception , e : <EOL> print "<STR_LIT>" . format ( ctrl_addr , e ) <EOL> sys . exit ( - <NUM_LIT:1> ) <EOL> try : <EOL> self . sub_client = sub_client_mod . SubClient ( sub_addr ) <EOL> except Exception , e : <EOL> print "<STR_LIT>" . format ( sub_addr , e ) <EOL> sys . exit ( - <NUM_LIT:1> ) <EOL> def default ( self , raw_args ) : <EOL> """<STR_LIT>""" <EOL> obj_name , _ , rest = raw_args . partition ( "<STR_LIT:U+0020>" ) <EOL> if obj_name in self . ctrl_client . objects : <EOL> method_name , _ , params = rest . partition ( "<STR_LIT:U+0020>" ) <EOL> if method_name in self . ctrl_client . objects [ obj_name ] : <EOL> try : <EOL> param_dict = { } <EOL> for param in params . split ( ) : <EOL> key , value = param . split ( "<STR_LIT::>" ) <EOL> try : <EOL> if "<STR_LIT:.>" in value : <EOL> value = float ( value ) <EOL> else : <EOL> value = int ( value ) <EOL> except ValueError : <EOL> if value == "<STR_LIT:True>" : <EOL> value = True <EOL> elif value == "<STR_LIT:False>" : <EOL> value = False <EOL> elif value . startswith ( "<STR_LIT:'>" ) and value . endswith ( "<STR_LIT:'>" ) : <EOL> value = value [ <NUM_LIT:1> : - <NUM_LIT:1> ] <EOL> param_dict [ key ] = value <EOL> except IndexError : <EOL> print "<STR_LIT>" <EOL> return <EOL> except ValueError : <EOL> print "<STR_LIT>" <EOL> return <EOL> result = self . ctrl_client . call ( <EOL> obj_name , method_name , param_dict ) <EOL> print "<STR_LIT>" , result <EOL> else : <EOL> print "<STR_LIT>" , method_name <EOL> else : <EOL> print "<STR_LIT>" , obj_name <EOL> def completenames ( self , text , * ignored ) : <EOL> """<STR_LIT>""" <EOL> cmd_match_names = cmd . Cmd . completenames ( self , text , * ignored ) <EOL> obj_names = self . ctrl_client . objects . keys ( ) <EOL> api_match_names = [ x for x in obj_names if x . startswith ( text ) ] <EOL> return cmd_match_names + api_match_names <EOL> def completedefault ( self , text , line , begidx , endidx ) : <EOL> """<STR_LIT>""" <EOL> obj , _ , rest = line . partition ( "<STR_LIT:U+0020>" ) <EOL> if obj in self . ctrl_client . objects : <EOL> method , _ , params = rest . strip ( ) . partition ( "<STR_LIT:U+0020>" ) <EOL> if method == text : <EOL> method_names = self . ctrl_client . objects [ obj ] <EOL> match_names = [ x for x in method_names if x . startswith ( text ) ] <EOL> return match_names <EOL> def do_list ( self , raw_args ) : <EOL> """<STR_LIT>""" <EOL> print <EOL> print "<STR_LIT>" <EOL> print <EOL> for obj_name , methods in sorted ( self . ctrl_client . objects . items ( ) ) : <EOL> print "<STR_LIT>" . format ( obj_name ) <EOL> for method in methods : <EOL> print "<STR_LIT>" . format ( method ) <EOL> print <EOL> def help_list ( self ) : <EOL> """<STR_LIT>""" <EOL> print "<STR_LIT:list>" <EOL> print "<STR_LIT>" <EOL> def do_ping ( self , raw_args ) : <EOL> """<STR_LIT>""" <EOL> reply_time = self . ctrl_client . ping ( ) <EOL> print "<STR_LIT>" . format ( reply_time ) <EOL> def help_ping ( self ) : <EOL> """<STR_LIT>""" <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> def do_sub_add ( self , raw_args ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> topic = raw_args . split ( ) [ <NUM_LIT:0> ] <EOL> except ( ValueError , IndexError ) : <EOL> print "<STR_LIT>" <EOL> return <EOL> self . sub_client . add_topic ( topic ) <EOL> def help_sub_add ( self ) : <EOL> """<STR_LIT>""" <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> def do_sub_del ( self , raw_args ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> topic = raw_args . split ( ) [ <NUM_LIT:0> ] <EOL> except ( ValueError , IndexError ) : <EOL> print "<STR_LIT>" <EOL> return <EOL> self . sub_client . del_topic ( topic ) <EOL> def help_sub_del ( self ) : <EOL> """<STR_LIT>""" <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> def do_sub ( self , raw_args ) : <EOL> """<STR_LIT>""" <EOL> self . sub_client . print_msgs ( ) <EOL> def help_sub ( self ) : <EOL> """<STR_LIT>""" <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> def do_stop ( self , raw_args ) : <EOL> """<STR_LIT>""" <EOL> self . ctrl_client . stop_full ( ) <EOL> def help_stop ( self ) : <EOL> """<STR_LIT>""" <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> def do_kill ( self , raw_args ) : <EOL> """<STR_LIT>""" <EOL> self . ctrl_client . exit_server ( ) <EOL> def help_kill ( self ) : <EOL> """<STR_LIT>""" <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> def do_die ( self , raw_args ) : <EOL> """<STR_LIT>""" <EOL> print "<STR_LIT>" <EOL> self . ctrl_client . clean_up ( ) <EOL> self . sub_client . clean_up ( ) <EOL> print "<STR_LIT>" <EOL> return True <EOL> def help_die ( self ) : <EOL> """<STR_LIT>""" <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> def do_shell ( self , cmd ) : <EOL> """<STR_LIT>""" <EOL> os . system ( cmd ) <EOL> def help_shell ( self ) : <EOL> """<STR_LIT>""" <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> def do_EOF ( self , raw_args ) : <EOL> """<STR_LIT>""" <EOL> print "<STR_LIT>" <EOL> self . ctrl_client . clean_up ( ) <EOL> self . sub_client . clean_up ( ) <EOL> print "<STR_LIT>" <EOL> return True <EOL> def help_EOF ( self ) : <EOL> """<STR_LIT>""" <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> def help_help ( self ) : <EOL> """<STR_LIT>""" <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> if len ( sys . argv ) == <NUM_LIT:1> : <EOL> print "<STR_LIT>" <EOL> CLI ( "<STR_LIT>" , "<STR_LIT>" ) . cmdloop ( ) <EOL> elif len ( sys . argv ) == <NUM_LIT:3> : <EOL> ctrl_addr = sys . argv [ <NUM_LIT:1> ] <EOL> sub_addr = sys . argv [ <NUM_LIT:2> ] <EOL> CLI ( ctrl_addr , sub_addr ) . cmdloop ( ) <EOL> else : <EOL> print "<STR_LIT>" </s>
<s> """<STR_LIT>""" <EOL> from random import randint <EOL> from os import path <EOL> import bot . lib . lib as lib <EOL> import bot . hardware . servo as s_mod <EOL> import tests . test_bot as test_bot <EOL> class TestPosition ( test_bot . TestBot ) : <EOL> """<STR_LIT>""" <EOL> def setUp ( self ) : <EOL> """<STR_LIT>""" <EOL> super ( TestPosition , self ) . setUp ( ) <EOL> config = path . dirname ( path . realpath ( __file__ ) ) + "<STR_LIT>" <EOL> self . config = lib . get_config ( config ) <EOL> self . pwm_num = self . config [ '<STR_LIT>' ] <EOL> self . setup_pwm ( self . pwm_num , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) <EOL> self . servo = s_mod . Servo ( self . pwm_num ) <EOL> def tearDown ( self ) : <EOL> """<STR_LIT>""" <EOL> super ( TestPosition , self ) . tearDown ( ) <EOL> def test_0 ( self ) : <EOL> """<STR_LIT>""" <EOL> self . servo . position = <NUM_LIT:0> <EOL> assert self . servo . position == <NUM_LIT:0> , self . servo . position <EOL> def test_180 ( self ) : <EOL> """<STR_LIT>""" <EOL> self . servo . position = <NUM_LIT> <EOL> assert self . servo . position == <NUM_LIT> , self . servo . position <EOL> def test_middle ( self ) : <EOL> """<STR_LIT>""" <EOL> self . servo . position = <NUM_LIT> <EOL> assert self . servo . position == <NUM_LIT> , self . servo . position <EOL> def test_series ( self ) : <EOL> """<STR_LIT>""" <EOL> for position in range ( <NUM_LIT:0> , <NUM_LIT> , <NUM_LIT> ) : <EOL> self . servo . position = position <EOL> assert self . servo . position == position , self . servo . position <EOL> def test_manually_confirm ( self ) : <EOL> """<STR_LIT>""" <EOL> for i in range ( <NUM_LIT:10> ) : <EOL> test_pos = randint ( <NUM_LIT:0> , <NUM_LIT> ) <EOL> self . servo . position = test_pos <EOL> cur_pwm = self . get_pwm ( self . pwm_num ) <EOL> duty = int ( cur_pwm [ "<STR_LIT>" ] ) <EOL> read_pos = int ( round ( ( ( duty - <NUM_LIT> ) / <NUM_LIT> ) * <NUM_LIT> ) ) <EOL> assert read_pos == test_pos , "<STR_LIT>" . format ( read_pos , test_pos ) <EOL> def test_over_max ( self ) : <EOL> """<STR_LIT>""" <EOL> self . servo . position = <NUM_LIT> <EOL> assert self . servo . position == <NUM_LIT> , "<STR_LIT>" . format ( self . servo . position ) <EOL> def test_under_min ( self ) : <EOL> """<STR_LIT>""" <EOL> self . servo . position = - <NUM_LIT:1> <EOL> assert self . servo . position == <NUM_LIT:0> , "<STR_LIT>" . format ( self . servo . position ) </s>
<s> from django . contrib . syndication . views import Feed as SyndicationFeed <EOL> from django . core . urlresolvers import reverse <EOL> from django . conf import settings <EOL> from lifestream . models import Lifestream , Item <EOL> class RecentItemsFeed ( SyndicationFeed ) : <EOL> title = "<STR_LIT>" <EOL> description = "<STR_LIT>" <EOL> def link ( self , obj ) : <EOL> return reverse ( '<STR_LIT>' , kwargs = { <EOL> '<STR_LIT>' : obj . slug , <EOL> } ) <EOL> def get_object ( self , bits ) : <EOL> return Lifestream . objects . get ( slug = bits [ <NUM_LIT:0> ] ) <EOL> def items ( self , obj ) : <EOL> return Item . objects . published ( ) . filter ( feed__lifestream = obj ) [ : <NUM_LIT:10> ] <EOL> def item_pubdate ( self , item ) : <EOL> return item . date <EOL> def item_categories ( self , item ) : <EOL> def item_categories ( self , item ) : <EOL> if '<STR_LIT>' in settings . INSTALLED_APPS : <EOL> return [ tag . name for tag in item . tag_set ] <EOL> else : <EOL> return [ ] </s>
<s> """<STR_LIT>""" <EOL> from functools import update_wrapper <EOL> from google . appengine . api import users <EOL> from werkzeug import redirect <EOL> from werkzeug . exceptions import Forbidden <EOL> from kay . utils import ( <EOL> create_login_url , create_logout_url <EOL> ) <EOL> from kay . utils . decorators import auto_adapt_to_methods <EOL> def login_required ( func ) : <EOL> def inner ( request , * args , ** kwargs ) : <EOL> if request . user . is_anonymous ( ) : <EOL> if request . is_xhr : <EOL> return Forbidden ( ) <EOL> else : <EOL> return redirect ( create_login_url ( request . url ) ) <EOL> return func ( request , * args , ** kwargs ) <EOL> update_wrapper ( inner , func ) <EOL> return inner <EOL> login_required = auto_adapt_to_methods ( login_required ) <EOL> def admin_required ( func ) : <EOL> def inner ( request , * args , ** kwargs ) : <EOL> if not request . user . is_admin : <EOL> if request . user . is_anonymous ( ) : <EOL> return redirect ( create_login_url ( request . url ) ) <EOL> else : <EOL> raise Forbidden ( <EOL> description = <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' % <EOL> create_logout_url ( request . url ) <EOL> ) <EOL> return func ( request , * args , ** kwargs ) <EOL> update_wrapper ( inner , func ) <EOL> return inner <EOL> admin_required = auto_adapt_to_methods ( admin_required ) </s>
<s> """<STR_LIT>""" <EOL> PARSE_ERROR = - <NUM_LIT> <EOL> INVALID_REQUEST = - <NUM_LIT> <EOL> METHOD_NOT_FOUND = - <NUM_LIT> <EOL> INVALID_PARAMS = - <NUM_LIT> <EOL> INTERNAL_ERROR = - <NUM_LIT> <EOL> errors = { } <EOL> errors [ PARSE_ERROR ] = "<STR_LIT>" <EOL> errors [ INVALID_REQUEST ] = "<STR_LIT>" <EOL> errors [ METHOD_NOT_FOUND ] = "<STR_LIT>" <EOL> errors [ INVALID_PARAMS ] = "<STR_LIT>" <EOL> errors [ INTERNAL_ERROR ] = "<STR_LIT>" <EOL> try : <EOL> import json <EOL> except ImportError : <EOL> try : <EOL> import django . utils . simplejson as json <EOL> except ImportError : <EOL> import simplejson as json <EOL> import sys <EOL> import logging <EOL> import itertools <EOL> from werkzeug import Request , Response <EOL> from werkzeug import exceptions <EOL> class JsonRpcApplication ( object ) : <EOL> def __init__ ( self , methods = None ) : <EOL> if methods is not None : <EOL> self . methods = methods <EOL> else : <EOL> self . methods = { } <EOL> def add_module ( self , mod , namespace = None ) : <EOL> if namespace is None : <EOL> namespace = mod . __name__ <EOL> for k , v in ( ( k , v ) for k , v in mod . __dict__ . iteritems ( ) <EOL> if not k . startswith ( '<STR_LIT:_>' ) and callable ( v ) ) : <EOL> self . add ( namespace + '<STR_LIT:.>' + k , v ) <EOL> def add ( self , name , func ) : <EOL> self . methods [ name ] = func <EOL> def process ( self , data ) : <EOL> if data . get ( '<STR_LIT>' ) != "<STR_LIT>" : <EOL> return { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:id>' : data . get ( '<STR_LIT:id>' ) , <EOL> '<STR_LIT:error>' : { '<STR_LIT:code>' : INVALID_REQUEST , <EOL> '<STR_LIT:message>' : errors [ INVALID_REQUEST ] } } <EOL> if '<STR_LIT>' not in data : <EOL> return { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:id>' : data . get ( '<STR_LIT:id>' ) , <EOL> '<STR_LIT:error>' : { '<STR_LIT:code>' : INVALID_REQUEST , <EOL> '<STR_LIT:message>' : errors [ INVALID_REQUEST ] } } <EOL> methodname = data [ '<STR_LIT>' ] <EOL> if not isinstance ( methodname , basestring ) : <EOL> return { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:id>' : data . get ( '<STR_LIT:id>' ) , <EOL> '<STR_LIT:error>' : { '<STR_LIT:code>' : INVALID_REQUEST , <EOL> '<STR_LIT:message>' : errors [ INVALID_REQUEST ] } } <EOL> if methodname . startswith ( '<STR_LIT:_>' ) : <EOL> return { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:id>' : data . get ( '<STR_LIT:id>' ) , <EOL> '<STR_LIT:error>' : { '<STR_LIT:code>' : METHOD_NOT_FOUND , <EOL> '<STR_LIT:message>' : errors [ METHOD_NOT_FOUND ] } } <EOL> if methodname not in self . methods : <EOL> return { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:id>' : data . get ( '<STR_LIT:id>' ) , <EOL> '<STR_LIT:error>' : { '<STR_LIT:code>' : METHOD_NOT_FOUND , <EOL> '<STR_LIT:message>' : errors [ METHOD_NOT_FOUND ] } } <EOL> method = self . methods [ methodname ] <EOL> try : <EOL> params = data . get ( '<STR_LIT>' , [ ] ) <EOL> if isinstance ( params , list ) : <EOL> result = method ( * params ) <EOL> elif isinstance ( params , dict ) : <EOL> result = method ( ** dict ( [ ( str ( k ) , v ) for k , v in params . iteritems ( ) ] ) ) <EOL> else : <EOL> return { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:id>' : data . get ( '<STR_LIT:id>' ) , <EOL> '<STR_LIT:error>' : { '<STR_LIT:code>' : INVALID_REQUEST , <EOL> '<STR_LIT:message>' : errors [ INVALID_REQUEST ] } } <EOL> resdata = None <EOL> if data . get ( '<STR_LIT:id>' ) : <EOL> resdata = { <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:id>' : data . get ( '<STR_LIT:id>' ) , <EOL> '<STR_LIT:result>' : result , <EOL> } <EOL> return resdata <EOL> except Exception , e : <EOL> return { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:id>' : data . get ( '<STR_LIT:id>' ) , <EOL> '<STR_LIT:error>' : { '<STR_LIT:code>' : INTERNAL_ERROR , <EOL> '<STR_LIT:message>' : errors [ INTERNAL_ERROR ] , <EOL> '<STR_LIT:data>' : str ( e ) } } <EOL> def __call__ ( self , environ , start_response ) : <EOL> request = Request ( environ ) <EOL> if request . method != "<STR_LIT:POST>" : <EOL> raise exceptions . MethodNotAllowed <EOL> if not request . content_type . startswith ( '<STR_LIT:application/json>' ) : <EOL> raise exceptions . BadRequest <EOL> try : <EOL> data = json . loads ( request . data ) <EOL> except ValueError , e : <EOL> resdata = { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:id>' : None , <EOL> '<STR_LIT:error>' : { '<STR_LIT:code>' : PARSE_ERROR , <EOL> '<STR_LIT:message>' : errors [ PARSE_ERROR ] } } <EOL> else : <EOL> if isinstance ( data , dict ) : <EOL> resdata = self . process ( data ) <EOL> elif isinstance ( data , list ) : <EOL> if len ( [ x for x in data if not isinstance ( x , dict ) ] ) : <EOL> resdata = { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:id>' : None , <EOL> '<STR_LIT:error>' : { '<STR_LIT:code>' : INVALID_REQUEST , <EOL> '<STR_LIT:message>' : errors [ INVALID_REQUEST ] } } <EOL> else : <EOL> resdata = [ d for d in ( self . process ( d ) for d in data ) <EOL> if d is not None ] <EOL> response = Response ( content_type = "<STR_LIT:application/json>" ) <EOL> if resdata : <EOL> response . headers [ "<STR_LIT>" ] = "<STR_LIT>" <EOL> response . headers [ "<STR_LIT>" ] = "<STR_LIT>" <EOL> response . headers [ "<STR_LIT>" ] = "<STR_LIT>" <EOL> response . data = json . dumps ( resdata ) <EOL> return response ( environ , start_response ) <EOL> def getmod ( modname ) : <EOL> try : <EOL> __import__ ( modname ) <EOL> except ImportError , e : <EOL> logging . warn ( "<STR_LIT>" % e ) <EOL> return None <EOL> mod = sys . modules [ modname ] <EOL> return mod <EOL> def HTTPExceptionMiddleware ( app ) : <EOL> def wrap ( environ , start_response ) : <EOL> try : <EOL> return app ( environ , start_response ) <EOL> except exceptions . HTTPException , e : <EOL> return e ( environ , start_response ) <EOL> return wrap <EOL> def make_application ( methods ) : <EOL> app = JsonRpcApplication ( ) <EOL> for name , value in methods . iteritems ( ) : <EOL> if "<STR_LIT::>" in value : <EOL> modname , funcname = value . split ( "<STR_LIT::>" , <NUM_LIT:1> ) <EOL> mod = getmod ( modname ) <EOL> if mod : <EOL> app . add ( name , getattr ( mod , funcname ) ) <EOL> else : <EOL> modname = value <EOL> mod = getmod ( modname ) <EOL> if mod : <EOL> app . add_module ( mod , name ) <EOL> app = HTTPExceptionMiddleware ( app ) <EOL> return app </s>
<s> """<STR_LIT>""" <EOL> import re <EOL> from jinja2 . runtime import Undefined <EOL> __test__ = False <EOL> number_re = re . compile ( r'<STR_LIT>' ) <EOL> regex_type = type ( number_re ) <EOL> try : <EOL> test_callable = callable <EOL> except NameError : <EOL> def test_callable ( x ) : <EOL> return hasattr ( x , '<STR_LIT>' ) <EOL> def test_odd ( value ) : <EOL> """<STR_LIT>""" <EOL> return value % <NUM_LIT:2> == <NUM_LIT:1> <EOL> def test_even ( value ) : <EOL> """<STR_LIT>""" <EOL> return value % <NUM_LIT:2> == <NUM_LIT:0> <EOL> def test_divisibleby ( value , num ) : <EOL> """<STR_LIT>""" <EOL> return value % num == <NUM_LIT:0> <EOL> def test_defined ( value ) : <EOL> """<STR_LIT>""" <EOL> return not isinstance ( value , Undefined ) <EOL> def test_undefined ( value ) : <EOL> """<STR_LIT>""" <EOL> return isinstance ( value , Undefined ) <EOL> def test_none ( value ) : <EOL> """<STR_LIT>""" <EOL> return value is None <EOL> def test_lower ( value ) : <EOL> """<STR_LIT>""" <EOL> return unicode ( value ) . islower ( ) <EOL> def test_upper ( value ) : <EOL> """<STR_LIT>""" <EOL> return unicode ( value ) . isupper ( ) <EOL> def test_string ( value ) : <EOL> """<STR_LIT>""" <EOL> return isinstance ( value , basestring ) <EOL> def test_number ( value ) : <EOL> """<STR_LIT>""" <EOL> return isinstance ( value , ( int , long , float , complex ) ) <EOL> def test_sequence ( value ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> len ( value ) <EOL> value . __getitem__ <EOL> except : <EOL> return False <EOL> return True <EOL> def test_sameas ( value , other ) : <EOL> """<STR_LIT>""" <EOL> return value is other <EOL> def test_iterable ( value ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> iter ( value ) <EOL> except TypeError : <EOL> return False <EOL> return True <EOL> def test_escaped ( value ) : <EOL> """<STR_LIT>""" <EOL> return hasattr ( value , '<STR_LIT>' ) <EOL> TESTS = { <EOL> '<STR_LIT>' : test_odd , <EOL> '<STR_LIT>' : test_even , <EOL> '<STR_LIT>' : test_divisibleby , <EOL> '<STR_LIT>' : test_defined , <EOL> '<STR_LIT>' : test_undefined , <EOL> '<STR_LIT:none>' : test_none , <EOL> '<STR_LIT>' : test_lower , <EOL> '<STR_LIT>' : test_upper , <EOL> '<STR_LIT:string>' : test_string , <EOL> '<STR_LIT>' : test_number , <EOL> '<STR_LIT>' : test_sequence , <EOL> '<STR_LIT>' : test_iterable , <EOL> '<STR_LIT>' : test_callable , <EOL> '<STR_LIT>' : test_sameas , <EOL> '<STR_LIT>' : test_escaped <EOL> } </s>
<s> """<STR_LIT>""" <EOL> import re <EOL> import codecs <EOL> import mimetypes <EOL> from werkzeug . _internal import _proxy_repr , _missing , _empty_stream <EOL> _locale_delim_re = re . compile ( r'<STR_LIT>' ) <EOL> def is_immutable ( self ) : <EOL> raise TypeError ( '<STR_LIT>' % self . __class__ . __name__ ) <EOL> def iter_multi_items ( mapping ) : <EOL> """<STR_LIT>""" <EOL> if isinstance ( mapping , MultiDict ) : <EOL> for item in mapping . iteritems ( multi = True ) : <EOL> yield item <EOL> elif isinstance ( mapping , dict ) : <EOL> for key , value in mapping . iteritems ( ) : <EOL> if isinstance ( value , ( tuple , list ) ) : <EOL> for value in value : <EOL> yield key , value <EOL> else : <EOL> yield key , value <EOL> else : <EOL> for item in mapping : <EOL> yield item <EOL> class ImmutableListMixin ( object ) : <EOL> """<STR_LIT>""" <EOL> def __reduce_ex__ ( self , protocol ) : <EOL> return type ( self ) , ( list ( self ) , ) <EOL> def __delitem__ ( self , key ) : <EOL> is_immutable ( self ) <EOL> def __delslice__ ( self , i , j ) : <EOL> is_immutable ( self ) <EOL> def __iadd__ ( self , other ) : <EOL> is_immutable ( self ) <EOL> __imul__ = __iadd__ <EOL> def __setitem__ ( self , key , value ) : <EOL> is_immutable ( self ) <EOL> def __setslice__ ( self , i , j , value ) : <EOL> is_immutable ( self ) <EOL> def append ( self , item ) : <EOL> is_immutable ( self ) <EOL> remove = append <EOL> def extend ( self , iterable ) : <EOL> is_immutable ( self ) <EOL> def insert ( self , pos , value ) : <EOL> is_immutable ( self ) <EOL> def pop ( self , index = - <NUM_LIT:1> ) : <EOL> is_immutable ( self ) <EOL> def reverse ( self ) : <EOL> is_immutable ( self ) <EOL> def sort ( self , cmp = None , key = None , reverse = None ) : <EOL> is_immutable ( self ) <EOL> class ImmutableList ( ImmutableListMixin , list ) : <EOL> """<STR_LIT>""" <EOL> __repr__ = _proxy_repr ( list ) <EOL> class ImmutableDictMixin ( object ) : <EOL> """<STR_LIT>""" <EOL> def __reduce_ex__ ( self , protocol ) : <EOL> return type ( self ) , ( dict ( self ) , ) <EOL> def setdefault ( self , key , default = None ) : <EOL> is_immutable ( self ) <EOL> def update ( self , * args , ** kwargs ) : <EOL> is_immutable ( self ) <EOL> def pop ( self , key , default = None ) : <EOL> is_immutable ( self ) <EOL> def popitem ( self ) : <EOL> is_immutable ( self ) <EOL> def __setitem__ ( self , key , value ) : <EOL> is_immutable ( self ) <EOL> def __delitem__ ( self , key ) : <EOL> is_immutable ( self ) <EOL> def clear ( self ) : <EOL> is_immutable ( self ) <EOL> class ImmutableMultiDictMixin ( ImmutableDictMixin ) : <EOL> """<STR_LIT>""" <EOL> def __reduce_ex__ ( self , protocol ) : <EOL> return type ( self ) , ( self . items ( multi = True ) , ) <EOL> def add ( self , key , value ) : <EOL> is_immutable ( self ) <EOL> def popitemlist ( self ) : <EOL> is_immutable ( self ) <EOL> def poplist ( self , key ) : <EOL> is_immutable ( self ) <EOL> def setlist ( self , key , new_list ) : <EOL> is_immutable ( self ) <EOL> def setlistdefault ( self , key , default_list = None ) : <EOL> is_immutable ( self ) <EOL> class UpdateDictMixin ( object ) : <EOL> """<STR_LIT>""" <EOL> on_update = None <EOL> def calls_update ( name ) : <EOL> def oncall ( self , * args , ** kw ) : <EOL> rv = getattr ( super ( UpdateDictMixin , self ) , name ) ( * args , ** kw ) <EOL> if self . on_update is not None : <EOL> self . on_update ( self ) <EOL> return rv <EOL> oncall . __name__ = name <EOL> return oncall <EOL> __setitem__ = calls_update ( '<STR_LIT>' ) <EOL> __delitem__ = calls_update ( '<STR_LIT>' ) <EOL> clear = calls_update ( '<STR_LIT>' ) <EOL> pop = calls_update ( '<STR_LIT>' ) <EOL> popitem = calls_update ( '<STR_LIT>' ) <EOL> setdefault = calls_update ( '<STR_LIT>' ) <EOL> update = calls_update ( '<STR_LIT>' ) <EOL> del calls_update <EOL> class TypeConversionDict ( dict ) : <EOL> """<STR_LIT>""" <EOL> def get ( self , key , default = None , type = None ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> rv = self [ key ] <EOL> if type is not None : <EOL> rv = type ( rv ) <EOL> except ( KeyError , ValueError ) : <EOL> rv = default <EOL> return rv <EOL> class ImmutableTypeConversionDict ( ImmutableDictMixin , TypeConversionDict ) : <EOL> """<STR_LIT>""" <EOL> def copy ( self ) : <EOL> """<STR_LIT>""" <EOL> return TypeConversionDict ( self ) <EOL> def __copy__ ( self ) : <EOL> return self <EOL> class MultiDict ( TypeConversionDict ) : <EOL> """<STR_LIT>""" <EOL> KeyError = None <EOL> def __init__ ( self , mapping = None ) : <EOL> if isinstance ( mapping , MultiDict ) : <EOL> dict . __init__ ( self , ( ( k , l [ : ] ) for k , l in mapping . iterlists ( ) ) ) <EOL> elif isinstance ( mapping , dict ) : <EOL> tmp = { } <EOL> for key , value in mapping . iteritems ( ) : <EOL> if isinstance ( value , ( tuple , list ) ) : <EOL> value = list ( value ) <EOL> else : <EOL> value = [ value ] <EOL> tmp [ key ] = value <EOL> dict . __init__ ( self , tmp ) <EOL> else : <EOL> tmp = { } <EOL> for key , value in mapping or ( ) : <EOL> tmp . setdefault ( key , [ ] ) . append ( value ) <EOL> dict . __init__ ( self , tmp ) <EOL> def __getstate__ ( self ) : <EOL> return dict ( self . lists ( ) ) <EOL> def __setstate__ ( self , value ) : <EOL> dict . clear ( self ) <EOL> dict . update ( self , value ) <EOL> def __iter__ ( self ) : <EOL> return self . iterkeys ( ) <EOL> def __getitem__ ( self , key ) : <EOL> """<STR_LIT>""" <EOL> if key in self : <EOL> return dict . __getitem__ ( self , key ) [ <NUM_LIT:0> ] <EOL> raise self . KeyError ( key ) <EOL> def __setitem__ ( self , key , value ) : <EOL> """<STR_LIT>""" <EOL> dict . __setitem__ ( self , key , [ value ] ) <EOL> def add ( self , key , value ) : <EOL> """<STR_LIT>""" <EOL> dict . setdefault ( self , key , [ ] ) . append ( value ) <EOL> def getlist ( self , key , type = None ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> rv = dict . __getitem__ ( self , key ) <EOL> except KeyError : <EOL> return [ ] <EOL> if type is None : <EOL> return list ( rv ) <EOL> result = [ ] <EOL> for item in rv : <EOL> try : <EOL> result . append ( type ( item ) ) <EOL> except ValueError : <EOL> pass <EOL> return result <EOL> def setlist ( self , key , new_list ) : <EOL> """<STR_LIT>""" <EOL> dict . __setitem__ ( self , key , list ( new_list ) ) <EOL> def setdefault ( self , key , default = None ) : <EOL> """<STR_LIT>""" <EOL> if key not in self : <EOL> self [ key ] = default <EOL> else : <EOL> default = self [ key ] <EOL> return default <EOL> def setlistdefault ( self , key , default_list = None ) : <EOL> """<STR_LIT>""" <EOL> if key not in self : <EOL> default_list = list ( default_list or ( ) ) <EOL> dict . __setitem__ ( self , key , default_list ) <EOL> else : <EOL> default_list = dict . __getitem__ ( self , key ) <EOL> return default_list <EOL> def items ( self , multi = False ) : <EOL> """<STR_LIT>""" <EOL> return list ( self . iteritems ( multi ) ) <EOL> def lists ( self ) : <EOL> """<STR_LIT>""" <EOL> return list ( self . iterlists ( ) ) <EOL> def values ( self ) : <EOL> """<STR_LIT>""" <EOL> return [ self [ key ] for key in self . iterkeys ( ) ] <EOL> def listvalues ( self ) : <EOL> """<STR_LIT>""" <EOL> return list ( self . iterlistvalues ( ) ) <EOL> def iteritems ( self , multi = False ) : <EOL> """<STR_LIT>""" <EOL> for key , values in dict . iteritems ( self ) : <EOL> if multi : <EOL> for value in values : <EOL> yield key , value <EOL> else : <EOL> yield key , values [ <NUM_LIT:0> ] <EOL> def iterlists ( self ) : <EOL> """<STR_LIT>""" <EOL> for key , values in dict . iteritems ( self ) : <EOL> yield key , list ( values ) <EOL> def itervalues ( self ) : <EOL> """<STR_LIT>""" <EOL> for values in dict . itervalues ( self ) : <EOL> yield values [ <NUM_LIT:0> ] <EOL> def iterlistvalues ( self ) : <EOL> """<STR_LIT>""" <EOL> for values in dict . itervalues ( self ) : <EOL> yield list ( values ) <EOL> def copy ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . __class__ ( self ) <EOL> def to_dict ( self , flat = True ) : <EOL> """<STR_LIT>""" <EOL> if flat : <EOL> return dict ( self . iteritems ( ) ) <EOL> return dict ( self . lists ( ) ) <EOL> def update ( self , other_dict ) : <EOL> """<STR_LIT>""" <EOL> for key , value in iter_multi_items ( other_dict ) : <EOL> MultiDict . add ( self , key , value ) <EOL> def pop ( self , key , default = _missing ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> return dict . pop ( self , key ) [ <NUM_LIT:0> ] <EOL> except KeyError , e : <EOL> if default is not _missing : <EOL> return default <EOL> raise self . KeyError ( str ( e ) ) <EOL> def popitem ( self ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> item = dict . popitem ( self ) <EOL> return ( item [ <NUM_LIT:0> ] , item [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] ) <EOL> except KeyError , e : <EOL> raise self . KeyError ( str ( e ) ) <EOL> def poplist ( self , key ) : <EOL> """<STR_LIT>""" <EOL> return dict . pop ( self , key , [ ] ) <EOL> def popitemlist ( self ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> return dict . popitem ( self ) <EOL> except KeyError , e : <EOL> raise self . KeyError ( str ( e ) ) <EOL> def __repr__ ( self ) : <EOL> return '<STR_LIT>' % ( self . __class__ . __name__ , self . items ( multi = True ) ) <EOL> class _omd_bucket ( object ) : <EOL> """<STR_LIT>""" <EOL> __slots__ = ( '<STR_LIT>' , '<STR_LIT:key>' , '<STR_LIT:value>' , '<STR_LIT>' ) <EOL> def __init__ ( self , omd , key , value ) : <EOL> self . prev = omd . _last_bucket <EOL> self . key = key <EOL> self . value = value <EOL> self . next = None <EOL> if omd . _first_bucket is None : <EOL> omd . _first_bucket = self <EOL> if omd . _last_bucket is not None : <EOL> omd . _last_bucket . next = self <EOL> omd . _last_bucket = self <EOL> def unlink ( self , omd ) : <EOL> if self . prev : <EOL> self . prev . next = self . next <EOL> if self . next : <EOL> self . next . prev = self . prev <EOL> if omd . _first_bucket is self : <EOL> omd . _first_bucket = self . next <EOL> if omd . _last_bucket is self : <EOL> omd . _last_bucket = self . prev <EOL> class OrderedMultiDict ( MultiDict ) : <EOL> """<STR_LIT>""" <EOL> KeyError = None <EOL> def __init__ ( self , mapping = None ) : <EOL> dict . __init__ ( self ) <EOL> self . _first_bucket = self . _last_bucket = None <EOL> if mapping is not None : <EOL> OrderedMultiDict . update ( self , mapping ) <EOL> def __eq__ ( self , other ) : <EOL> if not isinstance ( other , MultiDict ) : <EOL> return NotImplemented <EOL> if isinstance ( other , OrderedMultiDict ) : <EOL> iter1 = self . iteritems ( multi = True ) <EOL> iter2 = other . iteritems ( multi = True ) <EOL> try : <EOL> for k1 , v1 in iter1 : <EOL> k2 , v2 = iter2 . next ( ) <EOL> if k1 != k2 or v1 != v2 : <EOL> return False <EOL> except StopIteration : <EOL> return False <EOL> try : <EOL> iter2 . next ( ) <EOL> except StopIteration : <EOL> return True <EOL> return False <EOL> if len ( self ) != len ( other ) : <EOL> return False <EOL> for key , values in self . iterlists ( ) : <EOL> if other . getlist ( key ) != values : <EOL> return False <EOL> return True <EOL> def __ne__ ( self , other ) : <EOL> return not self . __eq__ ( other ) <EOL> def __reduce_ex__ ( self , protocol ) : <EOL> return type ( self ) , ( self . items ( multi = True ) , ) <EOL> def __getstate__ ( self ) : <EOL> return self . items ( multi = True ) <EOL> def __setstate__ ( self , values ) : <EOL> dict . clear ( self ) <EOL> for key , value in values : <EOL> self . add ( key , value ) <EOL> def __getitem__ ( self , key ) : <EOL> if key in self : <EOL> return dict . __getitem__ ( self , key ) [ <NUM_LIT:0> ] . value <EOL> raise self . KeyError ( key ) <EOL> def __setitem__ ( self , key , value ) : <EOL> self . poplist ( key ) <EOL> self . add ( key , value ) <EOL> def __delitem__ ( self , key ) : <EOL> self . pop ( key ) <EOL> def iterkeys ( self ) : <EOL> return ( key for key , value in self . iteritems ( ) ) <EOL> def itervalues ( self ) : <EOL> return ( value for key , value in self . iteritems ( ) ) <EOL> def iteritems ( self , multi = False ) : <EOL> ptr = self . _first_bucket <EOL> if multi : <EOL> while ptr is not None : <EOL> yield ptr . key , ptr . value <EOL> ptr = ptr . next <EOL> else : <EOL> returned_keys = set ( ) <EOL> while ptr is not None : <EOL> if ptr . key not in returned_keys : <EOL> returned_keys . add ( ptr . key ) <EOL> yield ptr . key , ptr . value <EOL> ptr = ptr . next <EOL> def iterlists ( self ) : <EOL> returned_keys = set ( ) <EOL> ptr = self . _first_bucket <EOL> while ptr is not None : <EOL> if ptr . key not in returned_keys : <EOL> yield ptr . key , self . getlist ( ptr . key ) <EOL> returned_keys . add ( ptr . key ) <EOL> ptr = ptr . next <EOL> def iterlistvalues ( self ) : <EOL> for key , values in self . iterlists ( ) : <EOL> yield values <EOL> def add ( self , key , value ) : <EOL> dict . setdefault ( self , key , [ ] ) . append ( _omd_bucket ( self , key , value ) ) <EOL> def getlist ( self , key , type = None ) : <EOL> try : <EOL> rv = dict . __getitem__ ( self , key ) <EOL> except KeyError : <EOL> return [ ] <EOL> if type is None : <EOL> return [ x . value for x in rv ] <EOL> result = [ ] <EOL> for item in rv : <EOL> try : <EOL> result . append ( type ( item . value ) ) <EOL> except ValueError : <EOL> pass <EOL> return result <EOL> def setlist ( self , key , new_list ) : <EOL> self . poplist ( key ) <EOL> for value in new_list : <EOL> self . add ( key , value ) <EOL> def setlistdefault ( self , key , default_list = None ) : <EOL> raise TypeError ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> def update ( self , mapping ) : <EOL> for key , value in iter_multi_items ( mapping ) : <EOL> OrderedMultiDict . add ( self , key , value ) <EOL> def poplist ( self , key ) : <EOL> buckets = dict . pop ( self , key , ( ) ) <EOL> for bucket in buckets : <EOL> bucket . unlink ( self ) <EOL> return [ x . value for x in buckets ] <EOL> def pop ( self , key , default = _missing ) : <EOL> try : <EOL> buckets = dict . pop ( self , key ) <EOL> except KeyError , e : <EOL> if default is not _missing : <EOL> return default <EOL> raise self . KeyError ( str ( e ) ) <EOL> for bucket in buckets : <EOL> bucket . unlink ( self ) <EOL> return buckets [ <NUM_LIT:0> ] . value <EOL> def popitem ( self ) : <EOL> try : <EOL> key , buckets = dict . popitem ( self ) <EOL> except KeyError , e : <EOL> raise self . KeyError ( str ( e ) ) <EOL> for bucket in buckets : <EOL> bucket . unlink ( self ) <EOL> return key , buckets [ <NUM_LIT:0> ] . value <EOL> def popitemlist ( self ) : <EOL> try : <EOL> key , buckets = dict . popitem ( self ) <EOL> except KeyError , e : <EOL> raise self . KeyError ( str ( e ) ) <EOL> for bucket in buckets : <EOL> bucket . unlink ( self ) <EOL> return key , [ x . value for x in buckets ] <EOL> def _options_header_vkw ( value , kw ) : <EOL> if not kw : <EOL> return value <EOL> return dump_options_header ( value , dict ( ( k . replace ( '<STR_LIT:_>' , '<STR_LIT:->' ) , v ) <EOL> for k , v in kw . items ( ) ) ) <EOL> class Headers ( object ) : <EOL> """<STR_LIT>""" <EOL> KeyError = None <EOL> def __init__ ( self , defaults = None , _list = None ) : <EOL> if _list is None : <EOL> _list = [ ] <EOL> self . _list = _list <EOL> if defaults is not None : <EOL> if isinstance ( defaults , ( list , Headers ) ) : <EOL> self . _list . extend ( defaults ) <EOL> else : <EOL> self . extend ( defaults ) <EOL> @ classmethod <EOL> def linked ( cls , headerlist ) : <EOL> """<STR_LIT>""" <EOL> return cls ( _list = headerlist ) <EOL> def __getitem__ ( self , key , _index_operation = True ) : <EOL> if _index_operation : <EOL> if isinstance ( key , ( int , long ) ) : <EOL> return self . _list [ key ] <EOL> elif isinstance ( key , slice ) : <EOL> return self . __class__ ( self . _list [ key ] ) <EOL> ikey = key . lower ( ) <EOL> for k , v in self . _list : <EOL> if k . lower ( ) == ikey : <EOL> return v <EOL> raise self . KeyError ( key ) <EOL> def __eq__ ( self , other ) : <EOL> return other . __class__ is self . __class__ and set ( other . _list ) == set ( self . _list ) <EOL> def __ne__ ( self , other ) : <EOL> return not self . __eq__ ( other ) <EOL> def get ( self , key , default = None , type = None ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> rv = self . __getitem__ ( key , _index_operation = False ) <EOL> except KeyError : <EOL> return default <EOL> if type is None : <EOL> return rv <EOL> try : <EOL> return type ( rv ) <EOL> except ValueError : <EOL> return default <EOL> def getlist ( self , key , type = None ) : <EOL> """<STR_LIT>""" <EOL> ikey = key . lower ( ) <EOL> result = [ ] <EOL> for k , v in self : <EOL> if k . lower ( ) == ikey : <EOL> if type is not None : <EOL> try : <EOL> v = type ( v ) <EOL> except ValueError : <EOL> continue <EOL> result . append ( v ) <EOL> return result <EOL> def get_all ( self , name ) : <EOL> """<STR_LIT>""" <EOL> return self . getlist ( name ) <EOL> def iteritems ( self , lower = False ) : <EOL> for key , value in self : <EOL> if lower : <EOL> key = key . lower ( ) <EOL> yield key , value <EOL> def iterkeys ( self , lower = False ) : <EOL> for key , _ in self . iteritems ( lower ) : <EOL> yield key <EOL> def itervalues ( self ) : <EOL> for _ , value in self . iteritems ( ) : <EOL> yield value <EOL> def keys ( self , lower = False ) : <EOL> return list ( self . iterkeys ( lower ) ) <EOL> def values ( self ) : <EOL> return list ( self . itervalues ( ) ) <EOL> def items ( self , lower = False ) : <EOL> return list ( self . iteritems ( lower ) ) <EOL> def extend ( self , iterable ) : <EOL> """<STR_LIT>""" <EOL> if isinstance ( iterable , dict ) : <EOL> for key , value in iterable . iteritems ( ) : <EOL> if isinstance ( value , ( tuple , list ) ) : <EOL> for v in value : <EOL> self . add ( key , v ) <EOL> else : <EOL> self . add ( key , value ) <EOL> else : <EOL> for key , value in iterable : <EOL> self . add ( key , value ) <EOL> def __delitem__ ( self , key , _index_operation = True ) : <EOL> if _index_operation and isinstance ( key , ( int , long , slice ) ) : <EOL> del self . _list [ key ] <EOL> return <EOL> key = key . lower ( ) <EOL> new = [ ] <EOL> for k , v in self . _list : <EOL> if k . lower ( ) != key : <EOL> new . append ( ( k , v ) ) <EOL> self . _list [ : ] = new <EOL> def remove ( self , key ) : <EOL> """<STR_LIT>""" <EOL> return self . __delitem__ ( key , _index_operation = False ) <EOL> def pop ( self , key = None , default = _missing ) : <EOL> """<STR_LIT>""" <EOL> if key is None : <EOL> return self . _list . pop ( ) <EOL> if isinstance ( key , ( int , long ) ) : <EOL> return self . _list . pop ( key ) <EOL> try : <EOL> rv = self [ key ] <EOL> self . remove ( key ) <EOL> except KeyError : <EOL> if default is not _missing : <EOL> return default <EOL> raise <EOL> return rv <EOL> def popitem ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . pop ( ) <EOL> def __contains__ ( self , key ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> self . __getitem__ ( key , _index_operation = False ) <EOL> except KeyError : <EOL> return False <EOL> return True <EOL> has_key = __contains__ <EOL> def __iter__ ( self ) : <EOL> """<STR_LIT>""" <EOL> return iter ( self . _list ) <EOL> def __len__ ( self ) : <EOL> return len ( self . _list ) <EOL> def add ( self , _key , _value , ** kw ) : <EOL> """<STR_LIT>""" <EOL> self . _list . append ( ( _key , _options_header_vkw ( _value , kw ) ) ) <EOL> def add_header ( self , _key , _value , ** _kw ) : <EOL> """<STR_LIT>""" <EOL> self . add ( _key , _value , ** _kw ) <EOL> def clear ( self ) : <EOL> """<STR_LIT>""" <EOL> del self . _list [ : ] <EOL> def set ( self , _key , _value , ** kw ) : <EOL> """<STR_LIT>""" <EOL> lc_key = _key . lower ( ) <EOL> _value = _options_header_vkw ( _value , kw ) <EOL> for idx , ( old_key , old_value ) in enumerate ( self . _list ) : <EOL> if old_key . lower ( ) == lc_key : <EOL> self . _list [ idx ] = ( _key , _value ) <EOL> break <EOL> else : <EOL> return self . add ( _key , _value ) <EOL> self . _list [ idx + <NUM_LIT:1> : ] = [ ( k , v ) for k , v in self . _list [ idx + <NUM_LIT:1> : ] <EOL> if k . lower ( ) != lc_key ] <EOL> def setdefault ( self , key , value ) : <EOL> """<STR_LIT>""" <EOL> if key in self : <EOL> return self [ key ] <EOL> self . set ( key , value ) <EOL> return value <EOL> def __setitem__ ( self , key , value ) : <EOL> """<STR_LIT>""" <EOL> if isinstance ( key , ( slice , int , long ) ) : <EOL> self . _list [ key ] = value <EOL> else : <EOL> self . set ( key , value ) <EOL> def to_list ( self , charset = '<STR_LIT:utf-8>' ) : <EOL> """<STR_LIT>""" <EOL> result = [ ] <EOL> for k , v in self : <EOL> if isinstance ( v , unicode ) : <EOL> v = v . encode ( charset ) <EOL> else : <EOL> v = str ( v ) <EOL> result . append ( ( k , v ) ) <EOL> return result <EOL> def copy ( self ) : <EOL> return self . __class__ ( self . _list ) <EOL> def __copy__ ( self ) : <EOL> return self . copy ( ) <EOL> def __str__ ( self , charset = '<STR_LIT:utf-8>' ) : <EOL> """<STR_LIT>""" <EOL> strs = [ ] <EOL> for key , value in self . to_list ( charset ) : <EOL> strs . append ( '<STR_LIT>' % ( key , value ) ) <EOL> strs . append ( '<STR_LIT:\r\n>' ) <EOL> return '<STR_LIT:\r\n>' . join ( strs ) <EOL> def __repr__ ( self ) : <EOL> return '<STR_LIT>' % ( <EOL> self . __class__ . __name__ , <EOL> list ( self ) <EOL> ) <EOL> class ImmutableHeadersMixin ( object ) : <EOL> """<STR_LIT>""" <EOL> def __delitem__ ( self , key ) : <EOL> is_immutable ( self ) <EOL> def __setitem__ ( self , key , value ) : <EOL> is_immutable ( self ) <EOL> set = __setitem__ <EOL> def add ( self , item ) : <EOL> is_immutable ( self ) <EOL> remove = add_header = add <EOL> def extend ( self , iterable ) : <EOL> is_immutable ( self ) <EOL> def insert ( self , pos , value ) : <EOL> is_immutable ( self ) <EOL> def pop ( self , index = - <NUM_LIT:1> ) : <EOL> is_immutable ( self ) <EOL> def popitem ( self ) : <EOL> is_immutable ( self ) <EOL> def setdefault ( self , key , default ) : <EOL> is_immutable ( self ) <EOL> class EnvironHeaders ( ImmutableHeadersMixin , Headers ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , environ ) : <EOL> self . environ = environ <EOL> @ classmethod <EOL> def linked ( cls , environ ) : <EOL> raise TypeError ( '<STR_LIT>' <EOL> '<STR_LIT>' % cls . __name__ ) <EOL> def __eq__ ( self , other ) : <EOL> return self . environ is other . environ <EOL> def __getitem__ ( self , key , _index_operation = False ) : <EOL> key = key . upper ( ) . replace ( '<STR_LIT:->' , '<STR_LIT:_>' ) <EOL> if key in ( '<STR_LIT>' , '<STR_LIT>' ) : <EOL> return self . environ [ key ] <EOL> return self . environ [ '<STR_LIT>' + key ] <EOL> def __len__ ( self ) : <EOL> return len ( list ( iter ( self ) ) ) <EOL> def __iter__ ( self ) : <EOL> for key , value in self . environ . iteritems ( ) : <EOL> if key . startswith ( '<STR_LIT>' ) and key not in ( '<STR_LIT>' , '<STR_LIT>' ) : <EOL> yield key [ <NUM_LIT:5> : ] . replace ( '<STR_LIT:_>' , '<STR_LIT:->' ) . title ( ) , value <EOL> elif key in ( '<STR_LIT>' , '<STR_LIT>' ) : <EOL> yield key . replace ( '<STR_LIT:_>' , '<STR_LIT:->' ) . title ( ) , value <EOL> def copy ( self ) : <EOL> raise TypeError ( '<STR_LIT>' % self . __class__ . __name__ ) <EOL> class CombinedMultiDict ( ImmutableMultiDictMixin , MultiDict ) : <EOL> """<STR_LIT>""" <EOL> def __reduce_ex__ ( self , protocol ) : <EOL> return type ( self ) , ( self . dicts , ) <EOL> def __init__ ( self , dicts = None ) : <EOL> self . dicts = dicts or [ ] <EOL> @ classmethod <EOL> def fromkeys ( cls ) : <EOL> raise TypeError ( '<STR_LIT>' % <EOL> cls . __name__ ) <EOL> def __getitem__ ( self , key ) : <EOL> for d in self . dicts : <EOL> if key in d : <EOL> return d [ key ] <EOL> raise self . KeyError ( key ) <EOL> def get ( self , key , default = None , type = None ) : <EOL> for d in self . dicts : <EOL> if key in d : <EOL> if type is not None : <EOL> try : <EOL> return type ( d [ key ] ) <EOL> except ValueError : <EOL> continue <EOL> return d [ key ] <EOL> return default <EOL> def getlist ( self , key , type = None ) : <EOL> rv = [ ] <EOL> for d in self . dicts : <EOL> rv . extend ( d . getlist ( key , type ) ) <EOL> return rv <EOL> def keys ( self ) : <EOL> rv = set ( ) <EOL> for d in self . dicts : <EOL> rv . update ( d . keys ( ) ) <EOL> return list ( rv ) <EOL> def iteritems ( self , multi = False ) : <EOL> found = set ( ) <EOL> for d in self . dicts : <EOL> for key , value in d . iteritems ( multi ) : <EOL> if multi : <EOL> yield key , value <EOL> elif key not in found : <EOL> found . add ( key ) <EOL> yield key , value <EOL> def itervalues ( self ) : <EOL> for key , value in self . iteritems ( ) : <EOL> yield value <EOL> def values ( self ) : <EOL> return list ( self . itervalues ( ) ) <EOL> def items ( self , multi = False ) : <EOL> return list ( self . iteritems ( multi ) ) <EOL> def iterlists ( self ) : <EOL> rv = { } <EOL> for d in self . dicts : <EOL> for key , values in d . iterlists ( ) : <EOL> rv . setdefault ( key , [ ] ) . extend ( values ) <EOL> return rv . iteritems ( ) <EOL> def lists ( self ) : <EOL> return list ( self . iterlists ( ) ) <EOL> def iterlistvalues ( self ) : <EOL> return ( x [ <NUM_LIT:0> ] for x in self . lists ( ) ) <EOL> def listvalues ( self ) : <EOL> return list ( self . iterlistvalues ( ) ) <EOL> def iterkeys ( self ) : <EOL> return iter ( self . keys ( ) ) <EOL> __iter__ = iterkeys <EOL> def copy ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . __class__ ( self . dicts [ : ] ) <EOL> def to_dict ( self , flat = True ) : <EOL> """<STR_LIT>""" <EOL> rv = { } <EOL> for d in reversed ( self . dicts ) : <EOL> rv . update ( d . to_dict ( flat ) ) <EOL> return rv <EOL> def __len__ ( self ) : <EOL> return len ( self . keys ( ) ) <EOL> def __contains__ ( self , key ) : <EOL> for d in self . dicts : <EOL> if key in d : <EOL> return True <EOL> return False <EOL> has_key = __contains__ <EOL> def __repr__ ( self ) : <EOL> return '<STR_LIT>' % ( self . __class__ . __name__ , self . dicts ) <EOL> class FileMultiDict ( MultiDict ) : <EOL> """<STR_LIT>""" <EOL> def add_file ( self , name , file , filename = None , content_type = None ) : <EOL> """<STR_LIT>""" <EOL> if isinstance ( file , FileStorage ) : <EOL> self [ name ] = file <EOL> return <EOL> if isinstance ( file , basestring ) : <EOL> if filename is None : <EOL> filename = file <EOL> file = open ( file , '<STR_LIT:rb>' ) <EOL> if filename and content_type is None : <EOL> content_type = mimetypes . guess_type ( filename ) [ <NUM_LIT:0> ] or '<STR_LIT>' <EOL> self [ name ] = FileStorage ( file , filename , name , content_type ) <EOL> class ImmutableDict ( ImmutableDictMixin , dict ) : <EOL> """<STR_LIT>""" <EOL> __repr__ = _proxy_repr ( dict ) <EOL> def copy ( self ) : <EOL> """<STR_LIT>""" <EOL> return dict ( self ) <EOL> def __copy__ ( self ) : <EOL> return self <EOL> class ImmutableMultiDict ( ImmutableMultiDictMixin , MultiDict ) : <EOL> """<STR_LIT>""" <EOL> def copy ( self ) : <EOL> """<STR_LIT>""" <EOL> return MultiDict ( self ) <EOL> def __copy__ ( self ) : <EOL> return self <EOL> class ImmutableOrderedMultiDict ( ImmutableMultiDictMixin , OrderedMultiDict ) : <EOL> """<STR_LIT>""" <EOL> def copy ( self ) : <EOL> """<STR_LIT>""" <EOL> return OrderedMultiDict ( self ) <EOL> def __copy__ ( self ) : <EOL> return self <EOL> class Accept ( ImmutableList ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , values = ( ) ) : <EOL> if values is None : <EOL> list . __init__ ( self ) <EOL> self . provided = False <EOL> elif isinstance ( values , Accept ) : <EOL> self . provided = values . provided <EOL> list . __init__ ( self , values ) <EOL> else : <EOL> self . provided = True <EOL> values = [ ( a , b ) for b , a in values ] <EOL> values . sort ( ) <EOL> values . reverse ( ) <EOL> list . __init__ ( self , [ ( a , b ) for b , a in values ] ) <EOL> def _value_matches ( self , value , item ) : <EOL> """<STR_LIT>""" <EOL> return item == '<STR_LIT:*>' or item . lower ( ) == value . lower ( ) <EOL> def __getitem__ ( self , key ) : <EOL> """<STR_LIT>""" <EOL> if isinstance ( key , basestring ) : <EOL> return self . quality ( key ) <EOL> return list . __getitem__ ( self , key ) <EOL> def quality ( self , key ) : <EOL> """<STR_LIT>""" <EOL> for item , quality in self : <EOL> if self . _value_matches ( key , item ) : <EOL> return quality <EOL> return <NUM_LIT:0> <EOL> def __contains__ ( self , value ) : <EOL> for item , quality in self : <EOL> if self . _value_matches ( value , item ) : <EOL> return True <EOL> return False <EOL> def __repr__ ( self ) : <EOL> return '<STR_LIT>' % ( <EOL> self . __class__ . __name__ , <EOL> '<STR_LIT:U+002CU+0020>' . join ( '<STR_LIT>' % ( x , y ) for x , y in self ) <EOL> ) <EOL> def index ( self , key ) : <EOL> """<STR_LIT>""" <EOL> if isinstance ( key , basestring ) : <EOL> for idx , ( item , quality ) in enumerate ( self ) : <EOL> if self . _value_matches ( key , item ) : <EOL> return idx <EOL> raise ValueError ( key ) <EOL> return list . index ( self , key ) <EOL> def find ( self , key ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> return self . index ( key ) <EOL> except ValueError : <EOL> return - <NUM_LIT:1> <EOL> def values ( self ) : <EOL> """<STR_LIT>""" <EOL> return list ( self . itervalues ( ) ) <EOL> def itervalues ( self ) : <EOL> """<STR_LIT>""" <EOL> for item in self : <EOL> yield item [ <NUM_LIT:0> ] <EOL> def to_header ( self ) : <EOL> """<STR_LIT>""" <EOL> result = [ ] <EOL> for value , quality in self : <EOL> if quality != <NUM_LIT:1> : <EOL> value = '<STR_LIT>' % ( value , quality ) <EOL> result . append ( value ) <EOL> return '<STR_LIT:U+002C>' . join ( result ) <EOL> def __str__ ( self ) : <EOL> return self . to_header ( ) <EOL> def best_match ( self , matches , default = None ) : <EOL> """<STR_LIT>""" <EOL> best_quality = - <NUM_LIT:1> <EOL> result = default <EOL> for server_item in matches : <EOL> for client_item , quality in self : <EOL> if quality <= best_quality : <EOL> break <EOL> if self . _value_matches ( client_item , server_item ) : <EOL> best_quality = quality <EOL> result = server_item <EOL> return result <EOL> @ property <EOL> def best ( self ) : <EOL> """<STR_LIT>""" <EOL> if self : <EOL> return self [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] <EOL> class MIMEAccept ( Accept ) : <EOL> """<STR_LIT>""" <EOL> def _value_matches ( self , value , item ) : <EOL> def _normalize ( x ) : <EOL> x = x . lower ( ) <EOL> return x == '<STR_LIT:*>' and ( '<STR_LIT:*>' , '<STR_LIT:*>' ) or x . split ( '<STR_LIT:/>' , <NUM_LIT:1> ) <EOL> if '<STR_LIT:/>' not in value : <EOL> raise ValueError ( '<STR_LIT>' % value ) <EOL> value_type , value_subtype = _normalize ( value ) <EOL> if value_type == '<STR_LIT:*>' and value_subtype != '<STR_LIT:*>' : <EOL> raise ValueError ( '<STR_LIT>' % value ) <EOL> if '<STR_LIT:/>' not in item : <EOL> return False <EOL> item_type , item_subtype = _normalize ( item ) <EOL> if item_type == '<STR_LIT:*>' and item_subtype != '<STR_LIT:*>' : <EOL> return False <EOL> return ( <EOL> ( item_type == item_subtype == '<STR_LIT:*>' or <EOL> value_type == value_subtype == '<STR_LIT:*>' ) or <EOL> ( item_type == value_type and ( item_subtype == '<STR_LIT:*>' or <EOL> value_subtype == '<STR_LIT:*>' or <EOL> item_subtype == value_subtype ) ) <EOL> ) <EOL> @ property <EOL> def accept_html ( self ) : <EOL> """<STR_LIT>""" <EOL> return ( <EOL> '<STR_LIT>' in self or <EOL> '<STR_LIT>' in self or <EOL> self . accept_xhtml <EOL> ) <EOL> @ property <EOL> def accept_xhtml ( self ) : <EOL> """<STR_LIT>""" <EOL> return ( <EOL> '<STR_LIT>' in self or <EOL> '<STR_LIT>' in self <EOL> ) <EOL> class LanguageAccept ( Accept ) : <EOL> """<STR_LIT>""" <EOL> def _value_matches ( self , value , item ) : <EOL> def _normalize ( language ) : <EOL> return _locale_delim_re . split ( language . lower ( ) ) <EOL> return item == '<STR_LIT:*>' or _normalize ( value ) == _normalize ( item ) <EOL> class CharsetAccept ( Accept ) : <EOL> """<STR_LIT>""" <EOL> def _value_matches ( self , value , item ) : <EOL> def _normalize ( name ) : <EOL> try : <EOL> return codecs . lookup ( name ) . name <EOL> except LookupError : <EOL> return name . lower ( ) <EOL> return item == '<STR_LIT:*>' or _normalize ( value ) == _normalize ( item ) <EOL> def cache_property ( key , empty , type ) : <EOL> """<STR_LIT>""" <EOL> return property ( lambda x : x . _get_cache_value ( key , empty , type ) , <EOL> lambda x , v : x . _set_cache_value ( key , v , type ) , <EOL> lambda x : x . _del_cache_value ( key ) , <EOL> '<STR_LIT>' % key ) <EOL> class _CacheControl ( UpdateDictMixin , dict ) : <EOL> """<STR_LIT>""" <EOL> no_cache = cache_property ( '<STR_LIT>' , '<STR_LIT:*>' , None ) <EOL> no_store = cache_property ( '<STR_LIT>' , None , bool ) <EOL> max_age = cache_property ( '<STR_LIT>' , - <NUM_LIT:1> , int ) <EOL> no_transform = cache_property ( '<STR_LIT>' , None , None ) <EOL> def __init__ ( self , values = ( ) , on_update = None ) : <EOL> dict . __init__ ( self , values or ( ) ) <EOL> self . on_update = on_update <EOL> self . provided = values is not None <EOL> def _get_cache_value ( self , key , empty , type ) : <EOL> """<STR_LIT>""" <EOL> if type is bool : <EOL> return key in self <EOL> if key in self : <EOL> value = self [ key ] <EOL> if value is None : <EOL> return empty <EOL> elif type is not None : <EOL> try : <EOL> value = type ( value ) <EOL> except ValueError : <EOL> pass <EOL> return value <EOL> def _set_cache_value ( self , key , value , type ) : <EOL> """<STR_LIT>""" <EOL> if type is bool : <EOL> if value : <EOL> self [ key ] = None <EOL> else : <EOL> self . pop ( key , None ) <EOL> else : <EOL> if value is None : <EOL> self . pop ( key ) <EOL> elif value is True : <EOL> self [ key ] = None <EOL> else : <EOL> self [ key ] = value <EOL> def _del_cache_value ( self , key ) : <EOL> """<STR_LIT>""" <EOL> if key in self : <EOL> del self [ key ] <EOL> def to_header ( self ) : <EOL> """<STR_LIT>""" <EOL> return dump_header ( self ) <EOL> def __str__ ( self ) : <EOL> return self . to_header ( ) <EOL> def __repr__ ( self ) : <EOL> return '<STR_LIT>' % ( <EOL> self . __class__ . __name__ , <EOL> self . to_header ( ) <EOL> ) <EOL> class RequestCacheControl ( ImmutableDictMixin , _CacheControl ) : <EOL> """<STR_LIT>""" <EOL> max_stale = cache_property ( '<STR_LIT>' , '<STR_LIT:*>' , int ) <EOL> min_fresh = cache_property ( '<STR_LIT>' , '<STR_LIT:*>' , int ) <EOL> no_transform = cache_property ( '<STR_LIT>' , None , None ) <EOL> only_if_cached = cache_property ( '<STR_LIT>' , None , bool ) <EOL> class ResponseCacheControl ( _CacheControl ) : <EOL> """<STR_LIT>""" <EOL> public = cache_property ( '<STR_LIT>' , None , bool ) <EOL> private = cache_property ( '<STR_LIT>' , '<STR_LIT:*>' , None ) <EOL> must_revalidate = cache_property ( '<STR_LIT>' , None , bool ) <EOL> proxy_revalidate = cache_property ( '<STR_LIT>' , None , bool ) <EOL> s_maxage = cache_property ( '<STR_LIT>' , None , None ) <EOL> _CacheControl . cache_property = staticmethod ( cache_property ) <EOL> class CallbackDict ( UpdateDictMixin , dict ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , initial = None , on_update = None ) : <EOL> dict . __init__ ( self , initial or ( ) ) <EOL> self . on_update = on_update <EOL> def __repr__ ( self ) : <EOL> return '<STR_LIT>' % ( <EOL> self . __class__ . __name__ , <EOL> dict . __repr__ ( self ) <EOL> ) <EOL> class HeaderSet ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , headers = None , on_update = None ) : <EOL> self . _headers = list ( headers or ( ) ) <EOL> self . _set = set ( [ x . lower ( ) for x in self . _headers ] ) <EOL> self . on_update = on_update <EOL> def add ( self , header ) : <EOL> """<STR_LIT>""" <EOL> self . update ( ( header , ) ) <EOL> def remove ( self , header ) : <EOL> """<STR_LIT>""" <EOL> key = header . lower ( ) <EOL> if key not in self . _set : <EOL> raise KeyError ( header ) <EOL> self . _set . remove ( key ) <EOL> for idx , key in enumerate ( self . _headers ) : <EOL> if key . lower ( ) == header : <EOL> del self . _headers [ idx ] <EOL> break <EOL> if self . on_update is not None : <EOL> self . on_update ( self ) <EOL> def update ( self , iterable ) : <EOL> """<STR_LIT>""" <EOL> inserted_any = False <EOL> for header in iterable : <EOL> key = header . lower ( ) <EOL> if key not in self . _set : <EOL> self . _headers . append ( header ) <EOL> self . _set . add ( key ) <EOL> inserted_any = True <EOL> if inserted_any and self . on_update is not None : <EOL> self . on_update ( self ) <EOL> def discard ( self , header ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> return self . remove ( header ) <EOL> except KeyError : <EOL> pass <EOL> def find ( self , header ) : <EOL> """<STR_LIT>""" <EOL> header = header . lower ( ) <EOL> for idx , item in enumerate ( self . _headers ) : <EOL> if item . lower ( ) == header : <EOL> return idx <EOL> return - <NUM_LIT:1> <EOL> def index ( self , header ) : <EOL> """<STR_LIT>""" <EOL> rv = self . find ( header ) <EOL> if rv < <NUM_LIT:0> : <EOL> raise IndexError ( header ) <EOL> return rv <EOL> def clear ( self ) : <EOL> """<STR_LIT>""" <EOL> self . _set . clear ( ) <EOL> del self . _headers [ : ] <EOL> if self . on_update is not None : <EOL> self . on_update ( self ) <EOL> def as_set ( self , preserve_casing = False ) : <EOL> """<STR_LIT>""" <EOL> if preserve_casing : <EOL> return set ( self . _headers ) <EOL> return set ( self . _set ) <EOL> def to_header ( self ) : <EOL> """<STR_LIT>""" <EOL> return '<STR_LIT:U+002CU+0020>' . join ( map ( quote_header_value , self . _headers ) ) <EOL> def __getitem__ ( self , idx ) : <EOL> return self . _headers [ idx ] <EOL> def __delitem__ ( self , idx ) : <EOL> rv = self . _headers . pop ( idx ) <EOL> self . _set . remove ( rv . lower ( ) ) <EOL> if self . on_update is not None : <EOL> self . on_update ( self ) <EOL> def __setitem__ ( self , idx , value ) : <EOL> old = self . _headers [ idx ] <EOL> self . _set . remove ( old . lower ( ) ) <EOL> self . _headers [ idx ] = value <EOL> self . _set . add ( value . lower ( ) ) <EOL> if self . on_update is not None : <EOL> self . on_update ( self ) <EOL> def __contains__ ( self , header ) : <EOL> return header . lower ( ) in self . _set <EOL> def __len__ ( self ) : <EOL> return len ( self . _set ) <EOL> def __iter__ ( self ) : <EOL> return iter ( self . _headers ) <EOL> def __nonzero__ ( self ) : <EOL> return bool ( self . _set ) <EOL> def __str__ ( self ) : <EOL> return self . to_header ( ) <EOL> def __repr__ ( self ) : <EOL> return '<STR_LIT>' % ( <EOL> self . __class__ . __name__ , <EOL> self . _headers <EOL> ) <EOL> class ETags ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , strong_etags = None , weak_etags = None , star_tag = False ) : <EOL> self . _strong = frozenset ( not star_tag and strong_etags or ( ) ) <EOL> self . _weak = frozenset ( weak_etags or ( ) ) <EOL> self . star_tag = star_tag <EOL> def as_set ( self , include_weak = False ) : <EOL> """<STR_LIT>""" <EOL> rv = set ( self . _strong ) <EOL> if include_weak : <EOL> rv . update ( self . _weak ) <EOL> return rv <EOL> def is_weak ( self , etag ) : <EOL> """<STR_LIT>""" <EOL> return etag in self . _weak <EOL> def contains_weak ( self , etag ) : <EOL> """<STR_LIT>""" <EOL> return self . is_weak ( etag ) or self . contains ( etag ) <EOL> def contains ( self , etag ) : <EOL> """<STR_LIT>""" <EOL> if self . star_tag : <EOL> return True <EOL> return etag in self . _strong <EOL> def contains_raw ( self , etag ) : <EOL> """<STR_LIT>""" <EOL> etag , weak = unquote_etag ( etag ) <EOL> if weak : <EOL> return self . contains_weak ( etag ) <EOL> return self . contains ( etag ) <EOL> def to_header ( self ) : <EOL> """<STR_LIT>""" <EOL> if self . star_tag : <EOL> return '<STR_LIT:*>' <EOL> return '<STR_LIT:U+002CU+0020>' . join ( <EOL> [ '<STR_LIT>' % x for x in self . _strong ] + <EOL> [ '<STR_LIT>' % x for x in self . _weak ] <EOL> ) <EOL> def __call__ ( self , etag = None , data = None , include_weak = False ) : <EOL> if [ etag , data ] . count ( None ) != <NUM_LIT:1> : <EOL> raise TypeError ( '<STR_LIT>' ) <EOL> if etag is None : <EOL> etag = generate_etag ( data ) <EOL> if include_weak : <EOL> if etag in self . _weak : <EOL> return True <EOL> return etag in self . _strong <EOL> def __nonzero__ ( self ) : <EOL> return bool ( self . star_tag or self . _strong ) <EOL> def __str__ ( self ) : <EOL> return self . to_header ( ) <EOL> def __iter__ ( self ) : <EOL> return iter ( self . _strong ) <EOL> def __contains__ ( self , etag ) : <EOL> return self . contains ( etag ) <EOL> def __repr__ ( self ) : <EOL> return '<STR_LIT>' % ( self . __class__ . __name__ , str ( self ) ) <EOL> class Authorization ( ImmutableDictMixin , dict ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , auth_type , data = None ) : <EOL> dict . __init__ ( self , data or { } ) <EOL> self . type = auth_type <EOL> username = property ( lambda x : x . get ( '<STR_LIT:username>' ) , doc = '''<STR_LIT>''' ) <EOL> password = property ( lambda x : x . get ( '<STR_LIT:password>' ) , doc = '''<STR_LIT>''' ) <EOL> realm = property ( lambda x : x . get ( '<STR_LIT>' ) , doc = '''<STR_LIT>''' ) <EOL> nonce = property ( lambda x : x . get ( '<STR_LIT>' ) , doc = '''<STR_LIT>''' ) <EOL> uri = property ( lambda x : x . get ( '<STR_LIT>' ) , doc = '''<STR_LIT>''' ) <EOL> nc = property ( lambda x : x . get ( '<STR_LIT>' ) , doc = '''<STR_LIT>''' ) <EOL> cnonce = property ( lambda x : x . get ( '<STR_LIT>' ) , doc = '''<STR_LIT>''' ) <EOL> response = property ( lambda x : x . get ( '<STR_LIT>' ) , doc = '''<STR_LIT>''' ) <EOL> opaque = property ( lambda x : x . get ( '<STR_LIT>' ) , doc = '''<STR_LIT>''' ) <EOL> @ property <EOL> def qop ( self ) : <EOL> """<STR_LIT>""" <EOL> def on_update ( header_set ) : <EOL> if not header_set and '<STR_LIT>' in self : <EOL> del self [ '<STR_LIT>' ] <EOL> elif header_set : <EOL> self [ '<STR_LIT>' ] = header_set . to_header ( ) <EOL> return parse_set_header ( self . get ( '<STR_LIT>' ) , on_update ) <EOL> class WWWAuthenticate ( UpdateDictMixin , dict ) : <EOL> """<STR_LIT>""" <EOL> _require_quoting = frozenset ( [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> def __init__ ( self , auth_type = None , values = None , on_update = None ) : <EOL> dict . __init__ ( self , values or ( ) ) <EOL> if auth_type : <EOL> self [ '<STR_LIT>' ] = auth_type <EOL> self . on_update = on_update <EOL> def set_basic ( self , realm = '<STR_LIT>' ) : <EOL> """<STR_LIT>""" <EOL> dict . clear ( self ) <EOL> dict . update ( self , { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : realm } ) <EOL> if self . on_update : <EOL> self . on_update ( self ) <EOL> def set_digest ( self , realm , nonce , qop = ( '<STR_LIT>' , ) , opaque = None , <EOL> algorithm = None , stale = False ) : <EOL> """<STR_LIT>""" <EOL> d = { <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : realm , <EOL> '<STR_LIT>' : nonce , <EOL> '<STR_LIT>' : dump_header ( qop ) <EOL> } <EOL> if stale : <EOL> d [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> if opaque is not None : <EOL> d [ '<STR_LIT>' ] = opaque <EOL> if algorithm is not None : <EOL> d [ '<STR_LIT>' ] = algorithm <EOL> dict . clear ( self ) <EOL> dict . update ( self , d ) <EOL> if self . on_update : <EOL> self . on_update ( self ) <EOL> def to_header ( self ) : <EOL> """<STR_LIT>""" <EOL> d = dict ( self ) <EOL> auth_type = d . pop ( '<STR_LIT>' , None ) or '<STR_LIT>' <EOL> return '<STR_LIT>' % ( auth_type . title ( ) , '<STR_LIT:U+002CU+0020>' . join ( [ <EOL> '<STR_LIT>' % ( key , quote_header_value ( value , <EOL> allow_token = key not in self . _require_quoting ) ) <EOL> for key , value in d . iteritems ( ) <EOL> ] ) ) <EOL> def __str__ ( self ) : <EOL> return self . to_header ( ) <EOL> def __repr__ ( self ) : <EOL> return '<STR_LIT>' % ( <EOL> self . __class__ . __name__ , <EOL> self . to_header ( ) <EOL> ) <EOL> def auth_property ( name , doc = None ) : <EOL> """<STR_LIT>""" <EOL> def _set_value ( self , value ) : <EOL> if value is None : <EOL> self . pop ( name , None ) <EOL> else : <EOL> self [ name ] = str ( value ) <EOL> return property ( lambda x : x . get ( name ) , _set_value , doc = doc ) <EOL> def _set_property ( name , doc = None ) : <EOL> def fget ( self ) : <EOL> def on_update ( header_set ) : <EOL> if not header_set and name in self : <EOL> del self [ name ] <EOL> elif header_set : <EOL> self [ name ] = header_set . to_header ( ) <EOL> return parse_set_header ( self . get ( name ) , on_update ) <EOL> return property ( fget , doc = doc ) <EOL> type = auth_property ( '<STR_LIT>' , doc = '''<STR_LIT>''' ) <EOL> realm = auth_property ( '<STR_LIT>' , doc = '''<STR_LIT>''' ) <EOL> domain = _set_property ( '<STR_LIT>' , doc = '''<STR_LIT>''' ) <EOL> nonce = auth_property ( '<STR_LIT>' , doc = '''<STR_LIT>''' ) <EOL> opaque = auth_property ( '<STR_LIT>' , doc = '''<STR_LIT>''' ) <EOL> algorithm = auth_property ( '<STR_LIT>' , doc = '''<STR_LIT>''' ) <EOL> qop = _set_property ( '<STR_LIT>' , doc = '''<STR_LIT>''' ) <EOL> def _get_stale ( self ) : <EOL> val = self . get ( '<STR_LIT>' ) <EOL> if val is not None : <EOL> return val . lower ( ) == '<STR_LIT:true>' <EOL> def _set_stale ( self , value ) : <EOL> if value is None : <EOL> self . pop ( '<STR_LIT>' , None ) <EOL> else : <EOL> self [ '<STR_LIT>' ] = value and '<STR_LIT>' or '<STR_LIT>' <EOL> stale = property ( _get_stale , _set_stale , doc = '''<STR_LIT>''' ) <EOL> del _get_stale , _set_stale <EOL> auth_property = staticmethod ( auth_property ) <EOL> del _set_property <EOL> class FileStorage ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , stream = None , filename = None , name = None , <EOL> content_type = '<STR_LIT>' , content_length = - <NUM_LIT:1> , <EOL> headers = None ) : <EOL> self . name = name <EOL> self . stream = stream or _empty_stream <EOL> self . filename = filename or getattr ( stream , '<STR_LIT:name>' , None ) <EOL> self . content_type = content_type <EOL> self . content_length = content_length <EOL> if headers is None : <EOL> headers = Headers ( ) <EOL> self . headers = headers <EOL> def save ( self , dst , buffer_size = <NUM_LIT> ) : <EOL> """<STR_LIT>""" <EOL> from shutil import copyfileobj <EOL> close_dst = False <EOL> if isinstance ( dst , basestring ) : <EOL> dst = file ( dst , '<STR_LIT:wb>' ) <EOL> close_dst = True <EOL> try : <EOL> copyfileobj ( self . stream , dst , buffer_size ) <EOL> finally : <EOL> if close_dst : <EOL> dst . close ( ) <EOL> def close ( self ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> self . stream . close ( ) <EOL> except : <EOL> pass <EOL> def __nonzero__ ( self ) : <EOL> return bool ( self . filename ) <EOL> def __getattr__ ( self , name ) : <EOL> return getattr ( self . stream , name ) <EOL> def __iter__ ( self ) : <EOL> return iter ( self . readline , '<STR_LIT>' ) <EOL> def __repr__ ( self ) : <EOL> return '<STR_LIT>' % ( <EOL> self . __class__ . __name__ , <EOL> self . filename , <EOL> self . content_type <EOL> ) <EOL> from werkzeug . http import dump_options_header , dump_header , generate_etag , quote_header_value , parse_set_header , unquote_etag <EOL> from werkzeug . exceptions import BadRequest <EOL> for _cls in MultiDict , OrderedMultiDict , CombinedMultiDict , Headers , EnvironHeaders : <EOL> _cls . KeyError = BadRequest . wrap ( KeyError , _cls . __name__ + '<STR_LIT>' ) <EOL> del _cls </s>
<s> """<STR_LIT>""" <EOL> import sys <EOL> import os <EOL> from werkzeug . utils import import_string <EOL> from kay . management . shell import ( <EOL> rshell , shell , clear_datastore , create_user , <EOL> ) <EOL> from kay . management . runserver import runserver_passthru_argv <EOL> from kay . management . startapp import startapp <EOL> from kay . management . startapp import startproject <EOL> from kay . management . appcfg import do_appcfg_passthru_argv <EOL> from kay . management . bulkloader import ( <EOL> do_bulkloader_passthru_argv , dump_all , restore_all , <EOL> ) <EOL> from kay . management . test import do_runtest <EOL> from kay . management . preparse import do_preparse_bundle <EOL> from kay . management . preparse import do_preparse_apps <EOL> from kay . management . extract_messages import do_extract_messages <EOL> from kay . management . add_translations import do_add_translations <EOL> from kay . management . update_translations import do_update_translations <EOL> from kay . management . compile_translations import do_compile_translations <EOL> from kay . management . wxadmin import do_wxadmin <EOL> from kay . management . compile_media import do_compile_media <EOL> from kay . conf import settings <EOL> action_dump_all = dump_all <EOL> action_restore_all = restore_all <EOL> action_shell = shell <EOL> action_rshell = rshell <EOL> action_startapp = startapp <EOL> action_startproject = startproject <EOL> action_test = do_runtest <EOL> action_preparse_bundle = do_preparse_bundle <EOL> action_preparse_apps = do_preparse_apps <EOL> action_extract_messages = do_extract_messages <EOL> action_add_translations = do_add_translations <EOL> action_update_translations = do_update_translations <EOL> action_compile_translations = do_compile_translations <EOL> action_appcfg = do_appcfg_passthru_argv <EOL> action_runserver = runserver_passthru_argv <EOL> action_bulkloader = do_bulkloader_passthru_argv <EOL> action_clear_datastore = clear_datastore <EOL> action_create_user = create_user <EOL> action_wxadmin = do_wxadmin <EOL> action_compile_media = do_compile_media <EOL> additional_actions = [ ] <EOL> for app in settings . INSTALLED_APPS : <EOL> try : <EOL> appmod = import_string ( app ) <EOL> if not os . path . exists ( os . path . join ( os . path . dirname ( appmod . __file__ ) , <EOL> '<STR_LIT>' ) ) : <EOL> continue <EOL> management_mod = import_string ( "<STR_LIT>" % app ) <EOL> for name , val in vars ( management_mod ) . iteritems ( ) : <EOL> if name . startswith ( "<STR_LIT>" ) : <EOL> locals ( ) [ name ] = getattr ( management_mod , name ) <EOL> additional_actions . append ( name ) <EOL> except Exception , e : <EOL> import traceback <EOL> sys . stderr . write ( '<STR_LIT:\n>' . join ( traceback . format_exception ( * ( sys . exc_info ( ) ) ) ) ) <EOL> pass <EOL> __all__ = [ <EOL> '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , <EOL> ] + additional_actions <EOL> def print_status ( msg ) : <EOL> print ( msg ) <EOL> sys . stdout . flush ( ) </s>
<s> """<STR_LIT>""" <EOL> from kay . routing import ( <EOL> ViewGroup , Rule <EOL> ) <EOL> view_groups = [ <EOL> ViewGroup ( <EOL> Rule ( '<STR_LIT>' , endpoint = '<STR_LIT>' , <EOL> view = ( '<STR_LIT>' , ( ) , { } ) ) , <EOL> Rule ( '<STR_LIT>' , endpoint = '<STR_LIT>' , <EOL> view = ( '<STR_LIT>' , ( ) , { } ) ) , <EOL> Rule ( '<STR_LIT>' , endpoint = '<STR_LIT>' , <EOL> view = '<STR_LIT>' ) , <EOL> ) <EOL> ] </s>
<s> """<STR_LIT>""" <EOL> from google . appengine . ext import db <EOL> from kay . utils . forms import ValidationError <EOL> from kay . utils . forms . modelform import ModelForm <EOL> class MaxLengthValidator ( object ) : <EOL> def __init__ ( self , length ) : <EOL> self . length = length <EOL> def __call__ ( self , val ) : <EOL> if len ( val ) > self . length : <EOL> raise ValidationError ( "<STR_LIT>" ) <EOL> return True <EOL> class TestModel ( db . Model ) : <EOL> number = db . IntegerProperty ( required = True ) <EOL> data_field = db . StringProperty ( required = True , <EOL> validator = MaxLengthValidator ( <NUM_LIT:20> ) ) <EOL> is_active = db . BooleanProperty ( required = True ) <EOL> string_list_field = db . StringListProperty ( required = True ) <EOL> class TestModel2 ( db . Model ) : <EOL> number = db . IntegerProperty ( required = True ) <EOL> data_field = db . StringProperty ( required = True , <EOL> validator = MaxLengthValidator ( <NUM_LIT:20> ) ) <EOL> is_active = db . BooleanProperty ( required = True ) <EOL> string_list_field = db . StringListProperty ( required = True ) <EOL> class TestModelForm ( ModelForm ) : <EOL> csrf_protected = False <EOL> class Meta ( ) : <EOL> model = TestModel <EOL> def __init__ ( self , instance = None , initial = None ) : <EOL> super ( TestModelForm , self ) . __init__ ( instance , initial ) <EOL> self . string_list_field . min_size = <NUM_LIT:1> <EOL> class JsonTestModel ( db . Model ) : <EOL> s = db . StringProperty ( ) <EOL> i = db . IntegerProperty ( ) <EOL> b = db . BooleanProperty ( ) <EOL> l = db . StringListProperty ( ) <EOL> r = db . ReferenceProperty ( ) <EOL> class ModelFormTestModel ( db . Model ) : <EOL> s_name = db . StringProperty ( ) <EOL> zip_code = db . StringProperty ( ) <EOL> addr = db . StringProperty ( ) <EOL> class ModelFormTestForm ( ModelForm ) : <EOL> csrf_protected = False <EOL> class Meta : <EOL> model = ModelFormTestModel <EOL> fields = ( '<STR_LIT>' ) <EOL> class ValidationTestModel ( db . Model ) : <EOL> slist = db . StringListProperty ( ) <EOL> class ValidationTestForm ( ModelForm ) : <EOL> csrf_protected = False <EOL> class Meta : <EOL> model = ValidationTestModel <EOL> def context_validate ( self , data ) : <EOL> raise ValidationError ( "<STR_LIT>" ) </s>
<s> """<STR_LIT>""" <EOL> import re <EOL> import sys <EOL> from os import path , listdir , mkdir <EOL> def compile_file ( env , src_path , dst_path , encoding = '<STR_LIT:utf-8>' , base_dir = '<STR_LIT>' ) : <EOL> """<STR_LIT>""" <EOL> src_file = file ( src_path , '<STR_LIT:r>' ) <EOL> try : <EOL> source = src_file . read ( ) . decode ( encoding ) <EOL> except Exception , e : <EOL> sys . stderr . write ( "<STR_LIT>" <EOL> "<STR_LIT>" % src_path ) <EOL> raise <EOL> src_file . close ( ) <EOL> name = src_path . replace ( base_dir , '<STR_LIT>' ) <EOL> raw = env . compile ( source , name = name , filename = name , raw = True ) <EOL> dst_file = open ( dst_path , '<STR_LIT:wb>' ) <EOL> dst_file . write ( raw ) <EOL> dst_file . close ( ) <EOL> def compile_dir ( env , src_path , dst_path , pattern = r'<STR_LIT>' , <EOL> encoding = '<STR_LIT:utf-8>' , base_dir = None , <EOL> negative_pattern = r'<STR_LIT>' ) : <EOL> """<STR_LIT>""" <EOL> if base_dir is None : <EOL> base_dir = src_path <EOL> for filename in listdir ( src_path ) : <EOL> if filename . startswith ( "<STR_LIT:.>" ) : <EOL> continue <EOL> src_name = path . join ( src_path , filename ) <EOL> dst_name = path . join ( dst_path , filename ) <EOL> if path . isdir ( src_name ) : <EOL> if not path . isdir ( dst_name ) : <EOL> mkdir ( dst_name ) <EOL> compile_dir ( env , src_name , dst_name , encoding = encoding , <EOL> base_dir = base_dir ) <EOL> elif path . isfile ( src_name ) and re . match ( pattern , filename ) and not re . match ( negative_pattern , filename ) : <EOL> compile_file ( env , src_name , dst_name , encoding = encoding , <EOL> base_dir = base_dir ) </s>
<s> """<STR_LIT>""" <EOL> import api <EOL> import random <EOL> import imp <EOL> import shutil <EOL> import os <EOL> from os import path <EOL> from functools import partial <EOL> from bson import json_util <EOL> from api . common import InternalException , SevereInternalException <EOL> log = api . logger . use ( __name__ ) <EOL> modifiable_problem_fields = [ "<STR_LIT:description>" ] <EOL> seed = "<STR_LIT>" <EOL> def is_autogen_problem ( pid ) : <EOL> """<STR_LIT>""" <EOL> return api . problem . get_problem ( pid = pid ) . get ( "<STR_LIT>" , False ) <EOL> def get_metadata_path ( pid , n ) : <EOL> """<STR_LIT>""" <EOL> return path . join ( get_instance_path ( pid , n = n , public = False ) , "<STR_LIT>" ) <EOL> def write_metadata ( pid , n , data ) : <EOL> """<STR_LIT>""" <EOL> metadata_path = get_metadata_path ( pid , n ) <EOL> with open ( metadata_path , "<STR_LIT:w>" ) as f : <EOL> f . write ( json_util . dumps ( data ) ) <EOL> @ api . cache . memoize ( timeout = <NUM_LIT> , fast = True ) <EOL> def read_metadata ( pid , n ) : <EOL> """<STR_LIT>""" <EOL> metadata_path = get_metadata_path ( pid , n ) <EOL> with open ( metadata_path , "<STR_LIT:r>" ) as f : <EOL> return json_util . loads ( f . read ( ) ) <EOL> def build_problem_instances ( pid , instances ) : <EOL> """<STR_LIT>""" <EOL> problem = api . problem . get_problem ( pid = pid ) <EOL> if not is_autogen_problem ( pid ) : <EOL> raise InternalException ( "<STR_LIT>" . format ( problem [ "<STR_LIT:name>" ] ) ) <EOL> previous_state = seed_generator ( "<STR_LIT>" , pid ) <EOL> instance_path , static_instance_path = get_instance_path ( pid ) , get_static_instance_path ( pid ) <EOL> for autogen_path in [ instance_path , static_instance_path ] : <EOL> log . debug ( "<STR_LIT>" , autogen_path ) <EOL> if not path . isdir ( autogen_path ) : <EOL> log . debug ( "<STR_LIT>" ) <EOL> os . makedirs ( autogen_path ) <EOL> for n in range ( instances ) : <EOL> log . debug ( "<STR_LIT>" , problem [ "<STR_LIT:name>" ] , str ( n ) ) <EOL> build = get_generator ( pid ) . generate ( random , pid , api . autogen_tools , n ) <EOL> autogen_instance_path = get_instance_path ( pid , n = n ) <EOL> file_type_paths = { <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : get_instance_path ( pid , n = n , public = True ) , <EOL> "<STR_LIT>" : get_instance_path ( pid , n = n , public = False ) <EOL> } , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : get_static_instance_path ( pid , public = True ) , <EOL> "<STR_LIT>" : get_static_instance_path ( pid , public = False ) <EOL> } <EOL> } <EOL> for _ , file_types in file_type_paths . items ( ) : <EOL> for _ , autogen_path in file_types . items ( ) : <EOL> if not path . isdir ( autogen_path ) : <EOL> os . makedirs ( autogen_path ) <EOL> problem_updates = build . get ( "<STR_LIT>" , None ) <EOL> if problem_updates is None : <EOL> raise InternalException ( "<STR_LIT>" . format ( problem [ "<STR_LIT>" ] ) ) <EOL> write_metadata ( pid , n , problem_updates ) <EOL> for file_type , listings in build . items ( ) : <EOL> destination_type = file_type_paths . get ( file_type , None ) <EOL> if destination_type is not None : <EOL> for listing in listings : <EOL> destination = destination_type . get ( listing , None ) <EOL> if destination is not None : <EOL> files = listings [ listing ] <EOL> for f , name in files : <EOL> if path . isfile ( f ) : <EOL> shutil . copyfile ( f , path . join ( destination , name ) ) <EOL> elif path . isdir ( f ) : <EOL> shutil . copytree ( f , autogen_instance_path ) <EOL> api . autogen_tools . clear_build_directories ( ) <EOL> log . debug ( "<STR_LIT>" ) <EOL> random . setstate ( previous_state ) <EOL> def get_generator_path ( pid ) : <EOL> """<STR_LIT>""" <EOL> problem = api . problem . get_problem ( pid = pid ) <EOL> if not is_autogen_problem ( pid ) : <EOL> raise InternalException ( "<STR_LIT>" ) <EOL> if not problem . get ( "<STR_LIT>" , False ) : <EOL> raise InternalException ( "<STR_LIT>" . format ( problem [ "<STR_LIT:name>" ] ) ) <EOL> return path . join ( api . problem . grader_base_path , problem [ "<STR_LIT>" ] ) <EOL> def get_generator ( pid ) : <EOL> """<STR_LIT>""" <EOL> generator_path = get_generator_path ( pid ) <EOL> if not path . isfile ( generator_path ) : <EOL> raise InternalException ( "<STR_LIT>" . format ( generator_path ) ) <EOL> return imp . load_source ( generator_path [ : - <NUM_LIT:3> ] , generator_path ) <EOL> def get_seed ( pid , tid ) : <EOL> """<STR_LIT>""" <EOL> return seed + tid + pid <EOL> def seed_generator ( pid , tid ) : <EOL> """<STR_LIT>""" <EOL> previous_state = random . getstate ( ) <EOL> random . seed ( get_seed ( pid , tid ) ) <EOL> return previous_state <EOL> @ api . cache . memoize ( timeout = <NUM_LIT> , fast = True ) <EOL> def get_instance_number ( pid , tid ) : <EOL> """<STR_LIT>""" <EOL> previous_state = seed_generator ( tid , pid ) <EOL> total_instances = get_number_of_instances ( pid ) <EOL> if total_instances == <NUM_LIT:0> : <EOL> raise InternalException ( "<STR_LIT>" . format ( pid ) ) <EOL> instance_number = random . randint ( <NUM_LIT:0> , total_instances - <NUM_LIT:1> ) <EOL> random . setstate ( previous_state ) <EOL> return instance_number <EOL> @ api . cache . memoize ( timeout = <NUM_LIT> , fast = True ) <EOL> def get_number_of_instances ( pid ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> return [ dirname . isdigit ( ) for dirname in os . listdir ( get_instance_path ( pid , public = False ) ) ] . count ( True ) <EOL> except FileNotFoundError : <EOL> raise InternalException ( "<STR_LIT>" ) <EOL> def get_static_instance_path ( pid , public = True ) : <EOL> """<STR_LIT>""" <EOL> return path . abspath ( path . join ( get_instance_path ( pid , public = public ) , "<STR_LIT>" ) ) <EOL> def get_instance_path ( pid , n = "<STR_LIT>" , public = True ) : <EOL> """<STR_LIT>""" <EOL> generator_path = get_generator_path ( pid ) <EOL> name = api . problem . get_problem ( pid ) [ "<STR_LIT:name>" ] <EOL> instance_path = path . join ( path . dirname ( generator_path ) , "<STR_LIT>" , name , str ( n ) ) <EOL> if public : <EOL> instance_path = path . join ( instance_path , "<STR_LIT>" ) <EOL> return path . abspath ( instance_path ) <EOL> @ api . cache . memoize ( timeout = <NUM_LIT> , fast = True ) <EOL> def get_problem_instance ( pid , tid ) : <EOL> """<STR_LIT>""" <EOL> problem = api . problem . get_problem ( pid = pid ) <EOL> n = get_instance_number ( pid , tid ) <EOL> metadata = read_metadata ( pid , n ) <EOL> if not set ( metadata ) . issubset ( modifiable_problem_fields ) : <EOL> invalid_keys = set ( metadata ) . difference ( modifiable_problem_fields ) <EOL> raise InternalException ( "<STR_LIT>" . format ( pid , invalid_keys ) ) <EOL> problem . update ( metadata ) <EOL> return problem <EOL> def grade_problem_instance ( pid , tid , key ) : <EOL> """<STR_LIT>""" <EOL> if not is_autogen_problem ( pid ) : <EOL> raise InternalException ( "<STR_LIT>" . format ( pid ) ) <EOL> problem = api . problem . get_problem ( pid ) <EOL> n = get_instance_number ( pid , tid ) <EOL> grader_problem_instance = GraderProblemInstance ( pid , tid , n ) <EOL> grader = api . problem . get_grader ( pid ) <EOL> try : <EOL> correct , message = grader . grade ( grader_problem_instance , key ) <EOL> except Exception as e : <EOL> raise SevereInternalException ( "<STR_LIT>" . format ( pid , str ( e ) ) ) <EOL> return { <EOL> "<STR_LIT>" : correct , <EOL> "<STR_LIT>" : problem [ "<STR_LIT>" ] , <EOL> "<STR_LIT:message>" : message <EOL> } <EOL> class GraderProblemInstance ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , pid , tid , n ) : <EOL> self . instance = n <EOL> self . get_instance_path = partial ( get_instance_path , pid , n = n ) <EOL> self . seed_generator = partial ( seed_generator , pid , tid ) <EOL> self . write_metadata = partial ( write_metadata , pid , n ) <EOL> self . read_metadata = partial ( read_metadata , pid ) </s>
<s> """<STR_LIT>""" <EOL> def generate ( random , pid , tools , n ) : <EOL> """<STR_LIT>""" <EOL> f = open ( "<STR_LIT>" , "<STR_LIT:w>" ) <EOL> k = str ( random . randint ( <NUM_LIT:0> , <NUM_LIT:1000> ) ) <EOL> f . write ( k ) <EOL> f . close ( ) <EOL> return { <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : [ ( "<STR_LIT>" , "<STR_LIT>" ) ] , <EOL> "<STR_LIT>" : [ ( "<STR_LIT>" , "<STR_LIT>" ) ] <EOL> } , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : [ ( "<STR_LIT>" , "<STR_LIT>" ) ] , <EOL> "<STR_LIT>" : [ ( "<STR_LIT>" , "<STR_LIT>" ) ] <EOL> } , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT:description>" : "<STR_LIT>" + k + "<STR_LIT>" <EOL> } <EOL> } </s>
<s> import IECore <EOL> import GafferUI <EOL> import GafferScene <EOL> import GafferSceneUI <EOL> import os <EOL> scriptNode = script <EOL> scriptWindow = GafferUI . ScriptWindow . acquire ( script ) <EOL> layout = eval ( "<STR_LIT>" ) <EOL> scriptWindow . setLayout ( layout ) <EOL> scriptWindow . _Widget__qtWidget . resize ( <NUM_LIT> , <NUM_LIT> ) <EOL> for nodeName in [ '<STR_LIT>' ] : <EOL> script . selection ( ) . add ( script . descendant ( nodeName ) ) <EOL> script . context ( ) [ "<STR_LIT>" ] = GafferScene . PathMatcherData ( GafferScene . PathMatcher ( [ '<STR_LIT:/>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) ) <EOL> script . context ( ) [ "<STR_LIT>" ] = IECore . StringVectorData ( [ "<STR_LIT>" ] ) </s>
<s> import os <EOL> import glob <EOL> import IECore <EOL> class convertAnimCache ( IECore . Op ) : <EOL> def __init__ ( self ) : <EOL> IECore . Op . __init__ ( self , "<STR_LIT>" , IECore . FileSequenceParameter ( "<STR_LIT:result>" , "<STR_LIT>" ) ) <EOL> self . parameters ( ) . addParameters ( <EOL> [ <EOL> IECore . FileSequenceParameter ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> defaultValue = "<STR_LIT>" , <EOL> allowEmptyString = False , <EOL> check = IECore . FileSequenceParameter . CheckType . MustExist , <EOL> extensions = "<STR_LIT>" , <EOL> ) , <EOL> IECore . FileSequenceParameter ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> defaultValue = "<STR_LIT>" , <EOL> allowEmptyString = False , <EOL> extensions = "<STR_LIT>" , <EOL> ) , <EOL> ] , <EOL> ) <EOL> def doOperation ( self , args ) : <EOL> src = self . parameters ( ) [ "<STR_LIT>" ] . getFileSequenceValue ( ) <EOL> dst = self . parameters ( ) [ "<STR_LIT>" ] . getFileSequenceValue ( ) <EOL> if isinstance ( dst . frameList , IECore . EmptyFrameList ) : <EOL> dst . frameList = src . frameList <EOL> for ( sf , df ) in zip ( src . fileNames ( ) , dst . fileNames ( ) ) : <EOL> sc = IECore . AttributeCache ( sf , IECore . IndexedIOOpenMode . Read ) <EOL> dc = IECore . AttributeCache ( df , IECore . IndexedIOOpenMode . Write ) <EOL> combinedBound = IECore . Box3f ( ) <EOL> for objectName in sc . objects ( ) : <EOL> p = b = None <EOL> with IECore . IgnoredExceptions ( Exception ) : <EOL> p = sc . read ( objectName , "<STR_LIT>" ) <EOL> b = sc . read ( objectName , "<STR_LIT>" ) <EOL> if p is not None and b is not None : <EOL> combinedBound . extendBy ( b . value ) <EOL> dc . write ( "<STR_LIT:->" + objectName , "<STR_LIT>" , p ) <EOL> dc . write ( "<STR_LIT:->" + objectName , "<STR_LIT>" , b ) <EOL> dc . write ( "<STR_LIT:->" , "<STR_LIT>" , IECore . Box3fData ( combinedBound ) ) <EOL> return args [ "<STR_LIT>" ] . value <EOL> IECore . registerRunTimeTyped ( convertAnimCache ) </s>
<s> import os <EOL> import unittest <EOL> import subprocess32 as subprocess <EOL> import IECore <EOL> import Gaffer <EOL> import GafferTest <EOL> import GafferScene <EOL> import GafferAppleseed <EOL> import GafferAppleseedTest <EOL> class AppleseedRenderTest ( GafferTest . TestCase ) : <EOL> def setUp ( self ) : <EOL> GafferTest . TestCase . setUp ( self ) <EOL> self . __scriptFileName = self . temporaryDirectory ( ) + "<STR_LIT>" <EOL> def testExecute ( self ) : <EOL> s = Gaffer . ScriptNode ( ) <EOL> s [ "<STR_LIT>" ] = GafferScene . Plane ( ) <EOL> s [ "<STR_LIT>" ] = GafferAppleseed . AppleseedRender ( ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT>" ] = Gaffer . Expression ( ) <EOL> s [ "<STR_LIT>" ] . setExpression ( "<STR_LIT>" + self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] . setValue ( self . __scriptFileName ) <EOL> s . save ( ) <EOL> p = subprocess . Popen ( <EOL> "<STR_LIT>" + self . __scriptFileName + "<STR_LIT>" , <EOL> shell = True , <EOL> stderr = subprocess . PIPE , <EOL> ) <EOL> p . wait ( ) <EOL> self . failIf ( p . returncode ) <EOL> for i in range ( <NUM_LIT:1> , <NUM_LIT:4> ) : <EOL> self . failUnless ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" % i ) ) <EOL> def testWaitForImage ( self ) : <EOL> s = Gaffer . ScriptNode ( ) <EOL> s [ "<STR_LIT>" ] = GafferScene . Plane ( ) <EOL> s [ "<STR_LIT>" ] = GafferScene . Outputs ( ) <EOL> s [ "<STR_LIT>" ] . addOutput ( <EOL> "<STR_LIT>" , <EOL> IECore . Display ( <EOL> self . temporaryDirectory ( ) + "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> { } <EOL> ) <EOL> ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT>" ] = GafferAppleseed . AppleseedRender ( ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] . setValue ( self . __scriptFileName ) <EOL> s . save ( ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . execute ( ) <EOL> self . failUnless ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" ) ) <EOL> def testExecuteWithStringSubstitutions ( self ) : <EOL> s = Gaffer . ScriptNode ( ) <EOL> s [ "<STR_LIT>" ] = GafferScene . Plane ( ) <EOL> s [ "<STR_LIT>" ] = GafferAppleseed . AppleseedRender ( ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] . setValue ( self . __scriptFileName ) <EOL> s . save ( ) <EOL> p = subprocess . Popen ( <EOL> "<STR_LIT>" + self . __scriptFileName + "<STR_LIT>" , <EOL> shell = True , <EOL> stderr = subprocess . PIPE , <EOL> ) <EOL> p . wait ( ) <EOL> self . failIf ( p . returncode ) <EOL> for i in range ( <NUM_LIT:1> , <NUM_LIT:4> ) : <EOL> self . failUnless ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" % i ) ) <EOL> def testImageOutput ( self ) : <EOL> s = Gaffer . ScriptNode ( ) <EOL> s [ "<STR_LIT>" ] = GafferScene . Plane ( ) <EOL> s [ "<STR_LIT>" ] = GafferScene . Outputs ( ) <EOL> s [ "<STR_LIT>" ] . addOutput ( <EOL> "<STR_LIT>" , <EOL> IECore . Display ( <EOL> self . temporaryDirectory ( ) + "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> { } <EOL> ) <EOL> ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT>" ] = GafferAppleseed . AppleseedRender ( ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] . setValue ( self . __scriptFileName ) <EOL> s . save ( ) <EOL> c = Gaffer . Context ( ) <EOL> for i in range ( <NUM_LIT:1> , <NUM_LIT:4> ) : <EOL> c . setFrame ( i ) <EOL> with c : <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . execute ( ) <EOL> for i in range ( <NUM_LIT:1> , <NUM_LIT:4> ) : <EOL> self . failUnless ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" % i ) ) <EOL> def testTypeNamePrefixes ( self ) : <EOL> self . assertTypeNamesArePrefixed ( GafferAppleseed ) <EOL> self . assertTypeNamesArePrefixed ( GafferAppleseedTest ) <EOL> def testDefaultNames ( self ) : <EOL> self . assertDefaultNamesAreCorrect ( GafferAppleseed ) <EOL> self . assertDefaultNamesAreCorrect ( GafferAppleseedTest ) <EOL> def testNodesConstructWithDefaultValues ( self ) : <EOL> self . assertNodesConstructWithDefaultValues ( GafferAppleseed ) <EOL> self . assertNodesConstructWithDefaultValues ( GafferAppleseedTest ) <EOL> def testDirectoryCreation ( self ) : <EOL> s = Gaffer . ScriptNode ( ) <EOL> s [ "<STR_LIT>" ] . addMember ( "<STR_LIT>" , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] . addMember ( "<STR_LIT>" , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] = GafferScene . Plane ( ) <EOL> s [ "<STR_LIT>" ] = GafferScene . Outputs ( ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT>" ] . addOutput ( <EOL> "<STR_LIT>" , <EOL> IECore . Display ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> { } <EOL> ) <EOL> ) <EOL> s [ "<STR_LIT>" ] = GafferAppleseed . AppleseedRender ( ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( "<STR_LIT>" ) <EOL> self . assertFalse ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" ) ) <EOL> self . assertFalse ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" ) ) <EOL> self . assertFalse ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" ) ) <EOL> self . assertFalse ( os . path . exists ( self . __scriptFileName ) ) <EOL> s [ "<STR_LIT>" ] . setValue ( self . __scriptFileName ) <EOL> s . save ( ) <EOL> with s . context ( ) : <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . execute ( ) <EOL> self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" ) ) <EOL> self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" ) ) <EOL> self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" ) ) <EOL> self . assertTrue ( os . path . exists ( self . __scriptFileName ) ) <EOL> with s . context ( ) : <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . execute ( ) <EOL> self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" ) ) <EOL> self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" ) ) <EOL> self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" ) ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> import GafferUITest <EOL> import GafferScene <EOL> import GafferSceneUI <EOL> import GafferArnold <EOL> import GafferArnoldUI <EOL> class DocumentationTest ( GafferUITest . TestCase ) : <EOL> def test ( self ) : <EOL> self . maxDiff = None <EOL> self . assertNodesAreDocumented ( <EOL> GafferArnold , <EOL> additionalTerminalPlugTypes = ( GafferScene . ScenePlug , ) <EOL> ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> import IECore <EOL> class parameterChangedCallback ( IECore . Parameterised ) : <EOL> def __init__ ( self ) : <EOL> IECore . Parameterised . __init__ ( self , "<STR_LIT>" ) <EOL> self . parameters ( ) . addParameters ( <EOL> [ <EOL> IECore . IntParameter ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> <NUM_LIT:0> <EOL> ) , <EOL> IECore . IntParameter ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> <NUM_LIT:0> <EOL> ) , <EOL> ] , <EOL> ) <EOL> self . changes = [ ] <EOL> def parameterChanged ( self , parameter ) : <EOL> self . changes . append ( ( parameter , str ( parameter . getValue ( ) ) ) ) <EOL> if parameter . isSame ( self . parameters ( ) [ "<STR_LIT>" ] ) : <EOL> self . parameters ( ) [ "<STR_LIT>" ] . setNumericValue ( self . parameters ( ) [ "<STR_LIT>" ] . getNumericValue ( ) * <NUM_LIT:5> ) <EOL> IECore . registerRunTimeTyped ( parameterChangedCallback ) </s>
<s> import GafferUI <EOL> import GafferCortexUI <EOL> class ToolParameterValueWidget ( GafferCortexUI . ParameterValueWidget ) : <EOL> def __init__ ( self , parameterHandler , parenting = None ) : <EOL> GafferCortexUI . ParameterValueWidget . __init__ ( <EOL> self , <EOL> GafferUI . ToolPlugValueWidget ( parameterHandler . plug ( ) ) , <EOL> parameterHandler , <EOL> parenting = parenting <EOL> ) </s>
<s> import os <EOL> import IECore <EOL> import Gaffer <EOL> import GafferDispatch <EOL> class TextWriter ( GafferDispatch . ExecutableNode ) : <EOL> def __init__ ( self , name = "<STR_LIT>" , requiresSequenceExecution = False ) : <EOL> GafferDispatch . ExecutableNode . __init__ ( self , name ) <EOL> self . __requiresSequenceExecution = requiresSequenceExecution <EOL> self . addChild ( Gaffer . StringPlug ( "<STR_LIT>" , Gaffer . Plug . Direction . In ) ) <EOL> self . addChild ( Gaffer . StringPlug ( "<STR_LIT>" , defaultValue = "<STR_LIT:w>" , direction = Gaffer . Plug . Direction . In ) ) <EOL> self . addChild ( Gaffer . StringPlug ( "<STR_LIT:text>" , Gaffer . Plug . Direction . In ) ) <EOL> def execute ( self ) : <EOL> context = Gaffer . Context . current ( ) <EOL> fileName = self [ "<STR_LIT>" ] . getValue ( ) <EOL> directory = os . path . dirname ( fileName ) <EOL> if directory : <EOL> try : <EOL> os . makedirs ( directory ) <EOL> except OSError : <EOL> if not os . path . isdir ( directory ) : <EOL> raise <EOL> text = self . __processText ( context ) <EOL> with file ( fileName , self [ "<STR_LIT>" ] . getValue ( ) ) as f : <EOL> f . write ( text ) <EOL> def executeSequence ( self , frames ) : <EOL> if not self . __requiresSequenceExecution : <EOL> GafferDispatch . ExecutableNode . executeSequence ( self , frames ) <EOL> return <EOL> context = Gaffer . Context ( Gaffer . Context . current ( ) ) <EOL> fileName = self [ "<STR_LIT>" ] . getValue ( ) <EOL> with file ( fileName , self [ "<STR_LIT>" ] . getValue ( ) ) as f : <EOL> with context : <EOL> for frame in frames : <EOL> context . setFrame ( frame ) <EOL> text = self . __processText ( context ) <EOL> f . write ( text ) <EOL> def hash ( self , context ) : <EOL> h = GafferDispatch . ExecutableNode . hash ( self , context ) <EOL> h . append ( context . getFrame ( ) ) <EOL> h . append ( context . get ( "<STR_LIT>" , IECore . StringVectorData ( ) ) ) <EOL> self [ "<STR_LIT>" ] . hash ( h ) <EOL> self [ "<STR_LIT>" ] . hash ( h ) <EOL> self [ "<STR_LIT:text>" ] . hash ( h ) <EOL> return h <EOL> def requiresSequenceExecution ( self ) : <EOL> return self . __requiresSequenceExecution <EOL> def __processText ( self , context ) : <EOL> text = self [ "<STR_LIT:text>" ] . getValue ( ) <EOL> replace = context . get ( "<STR_LIT>" , IECore . StringVectorData ( ) ) <EOL> if replace and len ( replace ) == <NUM_LIT:2> : <EOL> text = text . replace ( replace [ <NUM_LIT:0> ] , replace [ <NUM_LIT:1> ] ) <EOL> return text <EOL> IECore . registerRunTimeTyped ( TextWriter , typeName = "<STR_LIT>" ) </s>
<s> import os <EOL> import IECore <EOL> import Gaffer <EOL> import GafferImage <EOL> import GafferTest <EOL> import GafferImageTest <EOL> class CopyImageMetadataTest ( GafferImageTest . ImageTestCase ) : <EOL> checkerFile = os . path . expandvars ( "<STR_LIT>" ) <EOL> def test ( self ) : <EOL> r = GafferImage . ImageReader ( ) <EOL> r [ "<STR_LIT>" ] . setValue ( self . checkerFile ) <EOL> inMetadata = r [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) <EOL> d = GafferImage . DeleteImageMetadata ( ) <EOL> d [ "<STR_LIT>" ] . setInput ( r [ "<STR_LIT>" ] ) <EOL> d [ "<STR_LIT>" ] . setValue ( "<STR_LIT:*>" ) <EOL> m = GafferImage . CopyImageMetadata ( ) <EOL> m [ "<STR_LIT>" ] . setInput ( d [ "<STR_LIT>" ] ) <EOL> m [ "<STR_LIT>" ] . setInput ( r [ "<STR_LIT>" ] ) <EOL> m [ "<STR_LIT>" ] . setValue ( "<STR_LIT>" ) <EOL> metadata = m [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) <EOL> self . assertEqual ( m [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , IECore . CompoundObject ( ) ) <EOL> self . assertEqual ( m [ "<STR_LIT>" ] . image ( ) , d [ "<STR_LIT>" ] . image ( ) ) <EOL> m [ "<STR_LIT>" ] . setValue ( "<STR_LIT>" ) <EOL> metadata = m [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) <EOL> expected = set ( [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] ) <EOL> self . assertEqual ( set ( metadata . keys ( ) ) , expected ) <EOL> for key in metadata . keys ( ) : <EOL> self . assertEqual ( metadata [ key ] , inMetadata [ key ] ) <EOL> m [ "<STR_LIT>" ] . setValue ( True ) <EOL> metadata = m [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) <EOL> expected = set ( [ "<STR_LIT>" , "<STR_LIT>" ] ) <EOL> self . assertEqual ( set ( metadata . keys ( ) ) , expected ) <EOL> for key in metadata . keys ( ) : <EOL> self . assertEqual ( metadata [ key ] , inMetadata [ key ] ) <EOL> def testOverwrite ( self ) : <EOL> r = GafferImage . ImageReader ( ) <EOL> r [ "<STR_LIT>" ] . setValue ( self . checkerFile ) <EOL> inMetadata = r [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) <EOL> a = GafferImage . ImageMetadata ( ) <EOL> a [ "<STR_LIT>" ] . addMember ( "<STR_LIT>" , IECore . StringData ( "<STR_LIT>" ) ) <EOL> m = GafferImage . CopyImageMetadata ( ) <EOL> m [ "<STR_LIT>" ] . setInput ( r [ "<STR_LIT>" ] ) <EOL> m [ "<STR_LIT>" ] . setInput ( a [ "<STR_LIT>" ] ) <EOL> m [ "<STR_LIT>" ] . setValue ( "<STR_LIT>" ) <EOL> metadata = m [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) <EOL> self . assertEqual ( metadata [ "<STR_LIT>" ] , IECore . StringData ( "<STR_LIT>" ) ) <EOL> self . assertEqual ( m [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , inMetadata ) <EOL> self . assertEqual ( m [ "<STR_LIT>" ] . image ( ) , r [ "<STR_LIT>" ] . image ( ) ) <EOL> m [ "<STR_LIT>" ] . setValue ( "<STR_LIT>" ) <EOL> metadata = m [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) <EOL> self . assertTrue ( "<STR_LIT>" in metadata . keys ( ) ) <EOL> self . assertEqual ( metadata [ "<STR_LIT>" ] , IECore . StringData ( "<STR_LIT>" ) ) <EOL> def testDirtyPropogation ( self ) : <EOL> c = GafferImage . Constant ( ) <EOL> r = GafferImage . ImageReader ( ) <EOL> r [ "<STR_LIT>" ] . setValue ( self . checkerFile ) <EOL> inMetadata = r [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) <EOL> m = GafferImage . CopyImageMetadata ( ) <EOL> m [ "<STR_LIT>" ] . setInput ( c [ "<STR_LIT>" ] ) <EOL> m [ "<STR_LIT>" ] . setInput ( r [ "<STR_LIT>" ] ) <EOL> cs = GafferTest . CapturingSlot ( m . plugDirtiedSignal ( ) ) <EOL> m [ "<STR_LIT>" ] . setInput ( c [ "<STR_LIT>" ] ) <EOL> self . assertTrue ( m [ "<STR_LIT>" ] [ "<STR_LIT>" ] in set ( e [ <NUM_LIT:0> ] for e in cs ) ) <EOL> del cs [ : ] <EOL> m [ "<STR_LIT>" ] . setValue ( "<STR_LIT:test>" ) <EOL> self . assertTrue ( m [ "<STR_LIT>" ] [ "<STR_LIT>" ] in set ( e [ <NUM_LIT:0> ] for e in cs ) ) <EOL> del cs [ : ] <EOL> m [ "<STR_LIT>" ] . setValue ( True ) <EOL> self . assertTrue ( m [ "<STR_LIT>" ] [ "<STR_LIT>" ] in set ( e [ <NUM_LIT:0> ] for e in cs ) ) <EOL> def testPassThrough ( self ) : <EOL> c = GafferImage . Constant ( ) <EOL> i = GafferImage . ImageReader ( ) <EOL> i [ "<STR_LIT>" ] . setValue ( self . checkerFile ) <EOL> m = GafferImage . CopyImageMetadata ( ) <EOL> m [ "<STR_LIT>" ] . setInput ( i [ "<STR_LIT>" ] ) <EOL> m [ "<STR_LIT>" ] . setValue ( "<STR_LIT:*>" ) <EOL> self . assertEqual ( i [ "<STR_LIT>" ] [ "<STR_LIT>" ] . hash ( ) , m [ "<STR_LIT>" ] [ "<STR_LIT>" ] . hash ( ) ) <EOL> self . assertEqual ( i [ "<STR_LIT>" ] [ "<STR_LIT>" ] . hash ( ) , m [ "<STR_LIT>" ] [ "<STR_LIT>" ] . hash ( ) ) <EOL> self . assertEqual ( i [ "<STR_LIT>" ] [ "<STR_LIT>" ] . hash ( ) , m [ "<STR_LIT>" ] [ "<STR_LIT>" ] . hash ( ) ) <EOL> self . assertEqual ( i [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , m [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) ) <EOL> self . assertEqual ( i [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , m [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) ) <EOL> self . assertEqual ( i [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , m [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) ) <EOL> context = Gaffer . Context ( ) <EOL> context [ "<STR_LIT>" ] = IECore . V2i ( <NUM_LIT:0> ) <EOL> with context : <EOL> for c in [ "<STR_LIT>" , "<STR_LIT:B>" , "<STR_LIT:A>" ] : <EOL> context [ "<STR_LIT>" ] = c <EOL> self . assertEqual ( i [ "<STR_LIT>" ] [ "<STR_LIT>" ] . hash ( ) , m [ "<STR_LIT>" ] [ "<STR_LIT>" ] . hash ( ) ) <EOL> self . assertEqual ( i [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , m [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> import os <EOL> import unittest <EOL> import IECore <EOL> import Gaffer <EOL> import GafferImage <EOL> import GafferImageTest <EOL> class ObjectToImageTest ( GafferImageTest . ImageTestCase ) : <EOL> fileName = os . path . expandvars ( "<STR_LIT>" ) <EOL> negFileName = os . path . expandvars ( "<STR_LIT>" ) <EOL> def test ( self ) : <EOL> i = IECore . Reader . create ( self . fileName ) . read ( ) <EOL> n = GafferImage . ObjectToImage ( ) <EOL> n [ "<STR_LIT:object>" ] . setValue ( i ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] . image ( ) , i ) <EOL> def testImageWithANegativeDataWindow ( self ) : <EOL> i = IECore . Reader . create ( self . negFileName ) . read ( ) <EOL> n = GafferImage . ObjectToImage ( ) <EOL> n [ "<STR_LIT:object>" ] . setValue ( i ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] . image ( ) , i ) <EOL> def testHashVariesPerTileAndChannel ( self ) : <EOL> n = GafferImage . ObjectToImage ( ) <EOL> n [ "<STR_LIT:object>" ] . setValue ( IECore . Reader . create ( self . fileName ) . read ( ) ) <EOL> self . assertNotEqual ( <EOL> n [ "<STR_LIT>" ] . channelDataHash ( "<STR_LIT:R>" , IECore . V2i ( <NUM_LIT:0> ) ) , <EOL> n [ "<STR_LIT>" ] . channelDataHash ( "<STR_LIT>" , IECore . V2i ( <NUM_LIT:0> ) ) <EOL> ) <EOL> self . assertNotEqual ( <EOL> n [ "<STR_LIT>" ] . channelDataHash ( "<STR_LIT:R>" , IECore . V2i ( <NUM_LIT:0> ) ) , <EOL> n [ "<STR_LIT>" ] . channelDataHash ( "<STR_LIT:R>" , IECore . V2i ( GafferImage . ImagePlug . tileSize ( ) ) ) <EOL> ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> import threading <EOL> import IECore <EOL> import Gaffer <EOL> import GafferUI <EOL> import GafferImage <EOL> __all__ = [ ] <EOL> Gaffer . Metadata . registerNode ( <EOL> GafferImage . Display , <EOL> "<STR_LIT:description>" , <EOL> """<STR_LIT>""" , <EOL> plugs = { <EOL> "<STR_LIT:port>" : [ <EOL> "<STR_LIT:description>" , <EOL> """<STR_LIT>""" , <EOL> ] , <EOL> } <EOL> ) <EOL> __plugsPendingUpdate = [ ] <EOL> __plugsPendingUpdateLock = threading . Lock ( ) <EOL> def __scheduleUpdate ( plug , force = False ) : <EOL> if not force : <EOL> global __plugsPendingUpdate <EOL> global __plugsPendingUpdateLock <EOL> with __plugsPendingUpdateLock : <EOL> for p in __plugsPendingUpdate : <EOL> if plug . isSame ( p ) : <EOL> return <EOL> __plugsPendingUpdate . append ( plug ) <EOL> GafferUI . EventLoop . executeOnUIThread ( lambda : __update ( plug ) ) <EOL> def __update ( plug ) : <EOL> node = plug . node ( ) <EOL> if node : <EOL> updateCountPlug = node [ "<STR_LIT>" ] <EOL> updateCountPlug . setValue ( updateCountPlug . getValue ( ) + <NUM_LIT:1> ) <EOL> global __plugsPendingUpdate <EOL> global __plugsPendingUpdateLock <EOL> with __plugsPendingUpdateLock : <EOL> __plugsPendingUpdate = [ p for p in __plugsPendingUpdate if not p . isSame ( plug ) ] <EOL> __displayDataReceivedConnection = GafferImage . Display . dataReceivedSignal ( ) . connect ( __scheduleUpdate ) <EOL> __displayImageReceivedConnection = GafferImage . Display . imageReceivedSignal ( ) . connect ( IECore . curry ( __scheduleUpdate , force = True ) ) </s>
<s> from _GafferImageUI import * <EOL> import DisplayUI <EOL> from FormatPlugValueWidget import FormatPlugValueWidget <EOL> from ChannelMaskPlugValueWidget import ChannelMaskPlugValueWidget <EOL> import OpenImageIOReaderUI <EOL> import ImageReaderUI <EOL> import ImageViewToolbar <EOL> import ImageTransformUI <EOL> import ConstantUI <EOL> import ImageSwitchUI <EOL> import ColorSpaceUI <EOL> import ImageContextVariablesUI <EOL> import ImageStatsUI <EOL> import DeleteChannelsUI <EOL> import ObjectToImageUI <EOL> import ClampUI <EOL> import ImageWriterUI <EOL> import GradeUI <EOL> import ImageTimeWarpUI <EOL> import ImageSamplerUI <EOL> import MergeUI <EOL> import ImageNodeUI <EOL> import ChannelDataProcessorUI <EOL> import ImageProcessorUI <EOL> import ImageMetadataUI <EOL> import DeleteImageMetadataUI <EOL> import CopyImageMetadataUI <EOL> import ImageLoopUI <EOL> import ShuffleUI <EOL> import PremultiplyUI <EOL> import UnpremultiplyUI <EOL> import CropUI <EOL> import ResizeUI <EOL> import ResampleUI <EOL> import LUTUI <EOL> import CDLUI <EOL> import DisplayTransformUI <EOL> import OffsetUI <EOL> import BlurUI <EOL> import ShapeUI <EOL> import TextUI <EOL> import WarpUI <EOL> import UVWarpUI <EOL> __import__ ( "<STR_LIT>" ) . loadConfig ( "<STR_LIT>" , { } , subdirectory = "<STR_LIT>" ) </s>
<s> import os <EOL> import unittest <EOL> import IECore <EOL> import Gaffer <EOL> import GafferTest <EOL> import GafferScene <EOL> import GafferSceneTest <EOL> import GafferRenderMan <EOL> import GafferRenderManTest <EOL> class RenderManShaderTest ( GafferRenderManTest . RenderManTestCase ) : <EOL> def setUp ( self ) : <EOL> GafferRenderManTest . RenderManTestCase . setUp ( self ) <EOL> GafferRenderMan . RenderManShader . shaderLoader ( ) . clear ( ) <EOL> def test ( self ) : <EOL> n = GafferRenderMan . RenderManShader ( ) <EOL> n . loadShader ( "<STR_LIT>" ) <EOL> self . failUnless ( isinstance ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . FloatPlug ) ) <EOL> self . failUnless ( isinstance ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . FloatPlug ) ) <EOL> self . failUnless ( isinstance ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . FloatPlug ) ) <EOL> self . failUnless ( isinstance ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . FloatPlug ) ) <EOL> self . failUnless ( isinstance ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . Color3fPlug ) ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <NUM_LIT:0.5> ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <NUM_LIT:0.5> ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <NUM_LIT:1> ) <EOL> self . assertAlmostEqual ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <NUM_LIT:0.1> ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , IECore . Color3f ( <NUM_LIT:1> ) ) <EOL> def testSerialisation ( self ) : <EOL> s = Gaffer . ScriptNode ( ) <EOL> s [ "<STR_LIT:n>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT:n>" ] . loadShader ( "<STR_LIT>" ) <EOL> ss = s . serialise ( ) <EOL> s = Gaffer . ScriptNode ( ) <EOL> s . execute ( ss ) <EOL> st = s [ "<STR_LIT:n>" ] . state ( ) <EOL> self . assertEqual ( len ( st ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( st [ <NUM_LIT:0> ] . type , "<STR_LIT>" ) <EOL> self . assertEqual ( st [ <NUM_LIT:0> ] . name , "<STR_LIT>" ) <EOL> self . failUnless ( isinstance ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . FloatPlug ) ) <EOL> self . failUnless ( isinstance ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . FloatPlug ) ) <EOL> self . failUnless ( isinstance ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . FloatPlug ) ) <EOL> self . failUnless ( isinstance ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . FloatPlug ) ) <EOL> self . failUnless ( isinstance ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . Color3fPlug ) ) <EOL> self . assertTrue ( "<STR_LIT>" not in s [ "<STR_LIT:n>" ] ) <EOL> def testShader ( self ) : <EOL> n = GafferRenderMan . RenderManShader ( ) <EOL> n . loadShader ( "<STR_LIT>" ) <EOL> s = n . state ( ) <EOL> self . assertEqual ( len ( s ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . type , "<STR_LIT>" ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . name , "<STR_LIT>" ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] , IECore . FloatData ( <NUM_LIT> ) ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] , IECore . FloatData ( <NUM_LIT> ) ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] , IECore . FloatData ( <NUM_LIT:1> ) ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] , IECore . FloatData ( <NUM_LIT> ) ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] , IECore . Color3fData ( IECore . Color3f ( <NUM_LIT:1> ) ) ) <EOL> def testShaderHash ( self ) : <EOL> n = GafferRenderMan . RenderManShader ( ) <EOL> n . loadShader ( "<STR_LIT>" ) <EOL> h1 = n . stateHash ( ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( <NUM_LIT> ) <EOL> self . assertNotEqual ( n . stateHash ( ) , h1 ) <EOL> def testCoshaderHash ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> self . assertTrue ( "<STR_LIT>" in shaderNode [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . typeId ( ) , Gaffer . Plug . staticTypeId ( ) ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode . loadShader ( coshader ) <EOL> shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( coshaderNode [ "<STR_LIT>" ] ) <EOL> h1 = shaderNode . stateHash ( ) <EOL> coshaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( <NUM_LIT> ) <EOL> self . assertNotEqual ( shaderNode . stateHash ( ) , h1 ) <EOL> def testParameterOrdering ( self ) : <EOL> n = GafferRenderMan . RenderManShader ( ) <EOL> n . loadShader ( "<STR_LIT>" ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . getName ( ) , "<STR_LIT>" ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . getName ( ) , "<STR_LIT>" ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ <NUM_LIT:2> ] . getName ( ) , "<STR_LIT>" ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ <NUM_LIT:3> ] . getName ( ) , "<STR_LIT>" ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ <NUM_LIT:4> ] . getName ( ) , "<STR_LIT>" ) <EOL> n = GafferRenderMan . RenderManShader ( ) <EOL> n . loadShader ( "<STR_LIT>" ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . getName ( ) , "<STR_LIT>" ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . getName ( ) , "<STR_LIT>" ) <EOL> def testCoshader ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> self . assertTrue ( "<STR_LIT>" in shaderNode [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . typeId ( ) , Gaffer . Plug . staticTypeId ( ) ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode . loadShader ( coshader ) <EOL> shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( coshaderNode [ "<STR_LIT>" ] ) <EOL> s = shaderNode . state ( ) <EOL> self . assertEqual ( len ( s ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . name , shader ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] , s [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] ) <EOL> def testInputAcceptance ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode . loadShader ( coshader ) <EOL> random = Gaffer . Random ( ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderNode [ "<STR_LIT>" ] ) ) <EOL> self . assertFalse ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( random [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( random [ "<STR_LIT>" ] ) ) <EOL> self . assertFalse ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderNode [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( coshaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( random [ "<STR_LIT>" ] ) ) <EOL> self . assertFalse ( coshaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderNode [ "<STR_LIT>" ] ) ) <EOL> def testParameterDefaultValue ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . defaultValue ( ) , <NUM_LIT:1> ) <EOL> def testParameterMinMax ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . minValue ( ) , - <NUM_LIT:1> ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . maxValue ( ) , <NUM_LIT:10> ) <EOL> def testReload ( self ) : <EOL> shader1 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader1 ) <EOL> shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( <NUM_LIT:0.1> ) <EOL> shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( "<STR_LIT:test>" ) <EOL> shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( IECore . Color3f ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) ) <EOL> self . assertAlmostEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <NUM_LIT:0.1> ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , "<STR_LIT:test>" ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , IECore . Color3f ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) ) <EOL> shader2 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode . loadShader ( shader2 , keepExistingValues = True ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] . keys ( ) , [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] ) <EOL> self . assertAlmostEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <NUM_LIT:0.1> ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , "<STR_LIT:test>" ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , IECore . Color3f ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) ) <EOL> shaderNode . loadShader ( shader1 , keepExistingValues = True ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] . keys ( ) , [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] ) <EOL> self . assertAlmostEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <NUM_LIT:0.1> ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , "<STR_LIT:test>" ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , IECore . Color3f ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) ) <EOL> shaderNode . loadShader ( shader1 , keepExistingValues = False ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] . keys ( ) , [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , "<STR_LIT>" ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , IECore . Color3f ( <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> ) ) <EOL> def testReloadRemovesOldParameters ( self ) : <EOL> shader2 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader2 ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] . keys ( ) , [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] ) <EOL> shader3 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode . loadShader ( shader3 ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] . keys ( ) , [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] ) <EOL> def testAutomaticReloadOnScriptLoad ( self ) : <EOL> shader1 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" , shaderName = "<STR_LIT>" ) <EOL> s = Gaffer . ScriptNode ( ) <EOL> s [ "<STR_LIT>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT>" ] . loadShader ( shader1 ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( <NUM_LIT:0.1> ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( "<STR_LIT:test>" ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( IECore . Color3f ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) ) <EOL> ss = s . serialise ( ) <EOL> self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" , shaderName = "<STR_LIT>" ) <EOL> GafferRenderMan . RenderManShader . shaderLoader ( ) . clear ( ) <EOL> s = Gaffer . ScriptNode ( ) <EOL> s . execute ( ss ) <EOL> self . assertEqual ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . keys ( ) , [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] ) <EOL> self . assertAlmostEqual ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <NUM_LIT:0.1> ) <EOL> self . assertEqual ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , "<STR_LIT:test>" ) <EOL> self . assertEqual ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , IECore . Color3f ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) ) <EOL> def testReloadPreservesConnections ( self ) : <EOL> n = GafferRenderMan . RenderManShader ( ) <EOL> n . loadShader ( "<STR_LIT>" ) <EOL> random = Gaffer . Random ( ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( random [ "<STR_LIT>" ] ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( random [ "<STR_LIT>" ] ) <EOL> n . loadShader ( "<STR_LIT>" , keepExistingValues = True ) <EOL> self . assertTrue ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getInput ( ) . isSame ( random [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getInput ( ) . isSame ( random [ "<STR_LIT>" ] ) ) <EOL> def testReloadPreservesConnectionsWhenMinMaxOrDefaultChanges ( self ) : <EOL> shader1 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" , shaderName = "<STR_LIT>" ) <EOL> n = GafferRenderMan . RenderManShader ( ) <EOL> n . loadShader ( shader1 ) <EOL> self . assertFalse ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . hasMinValue ( ) ) <EOL> self . assertFalse ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . hasMaxValue ( ) ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . defaultValue ( ) , "<STR_LIT>" ) <EOL> nn = Gaffer . Node ( ) <EOL> nn [ "<STR_LIT>" ] = Gaffer . FloatPlug ( direction = Gaffer . Plug . Direction . Out ) <EOL> nn [ "<STR_LIT>" ] = Gaffer . StringPlug ( direction = Gaffer . Plug . Direction . Out ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( nn [ "<STR_LIT>" ] ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( nn [ "<STR_LIT>" ] ) <EOL> shader2 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" , shaderName = "<STR_LIT>" ) <EOL> GafferRenderMan . RenderManShader . shaderLoader ( ) . clear ( ) <EOL> n . loadShader ( shader1 , keepExistingValues = True ) <EOL> self . assertTrue ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . hasMinValue ( ) ) <EOL> self . assertTrue ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . hasMaxValue ( ) ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . minValue ( ) , - <NUM_LIT:1> ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . maxValue ( ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . defaultValue ( ) , "<STR_LIT>" ) <EOL> self . assertTrue ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getInput ( ) . isSame ( nn [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getInput ( ) . isSame ( nn [ "<STR_LIT>" ] ) ) <EOL> def testReloadPreservesPartialConnectionsWhenMinMaxOrDefaultChanges ( self ) : <EOL> shader1 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" , shaderName = "<STR_LIT>" ) <EOL> n = GafferRenderMan . RenderManShader ( ) <EOL> n . loadShader ( shader1 ) <EOL> nn = Gaffer . Node ( ) <EOL> nn [ "<STR_LIT>" ] = Gaffer . FloatPlug ( direction = Gaffer . Plug . Direction . Out ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . setInput ( nn [ "<STR_LIT>" ] ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . setInput ( nn [ "<STR_LIT>" ] ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:2> ] . setValue ( <NUM_LIT> ) <EOL> shader2 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" , shaderName = "<STR_LIT>" ) <EOL> GafferRenderMan . RenderManShader . shaderLoader ( ) . clear ( ) <EOL> n . loadShader ( shader1 , keepExistingValues = True ) <EOL> self . assertTrue ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . getInput ( ) . isSame ( nn [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . getInput ( ) . isSame ( nn [ "<STR_LIT>" ] ) ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:2> ] . getValue ( ) , <NUM_LIT> ) <EOL> def testReloadPreservesValuesWhenMinMaxOrDefaultChanges ( self ) : <EOL> shader1 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" , shaderName = "<STR_LIT>" ) <EOL> n = GafferRenderMan . RenderManShader ( ) <EOL> n . loadShader ( shader1 ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( <NUM_LIT> ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( "<STR_LIT>" ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( IECore . Color3f ( <NUM_LIT:0.1> , <NUM_LIT> , <NUM_LIT:0.5> ) ) <EOL> shader2 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" , shaderName = "<STR_LIT>" ) <EOL> GafferRenderMan . RenderManShader . shaderLoader ( ) . clear ( ) <EOL> n . loadShader ( shader1 , keepExistingValues = True ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <NUM_LIT> ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , "<STR_LIT>" ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , IECore . Color3f ( <NUM_LIT:0.1> , <NUM_LIT> , <NUM_LIT:0.5> ) ) <EOL> def testOutputParameters ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> n = GafferRenderMan . RenderManShader ( ) <EOL> n . loadShader ( shader ) <EOL> self . failIf ( "<STR_LIT>" in n [ "<STR_LIT>" ] . keys ( ) ) <EOL> def testAssignmentDirtyPropagation ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode . loadShader ( coshader ) <EOL> shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( coshaderNode [ "<STR_LIT>" ] ) <EOL> plane = GafferScene . Plane ( ) <EOL> assignment = GafferScene . ShaderAssignment ( ) <EOL> assignment [ "<STR_LIT>" ] . setInput ( plane [ "<STR_LIT>" ] ) <EOL> assignment [ "<STR_LIT>" ] . setInput ( shaderNode [ "<STR_LIT>" ] ) <EOL> cs = GafferTest . CapturingSlot ( assignment . plugDirtiedSignal ( ) ) <EOL> coshaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( <NUM_LIT:12> ) <EOL> dirtiedNames = [ x [ <NUM_LIT:0> ] . fullName ( ) for x in cs ] <EOL> self . assertEqual ( len ( dirtiedNames ) , <NUM_LIT:3> ) <EOL> self . assertEqual ( dirtiedNames [ <NUM_LIT:0> ] , "<STR_LIT>" ) <EOL> self . assertEqual ( dirtiedNames [ <NUM_LIT:1> ] , "<STR_LIT>" ) <EOL> self . assertEqual ( dirtiedNames [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> def testArrayParameters ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> n = GafferRenderMan . RenderManShader ( ) <EOL> n . loadShader ( shader ) <EOL> expected = { <EOL> "<STR_LIT>" : IECore . FloatVectorData ( [ ] ) , <EOL> "<STR_LIT>" : IECore . FloatVectorData ( [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ] ) , <EOL> "<STR_LIT>" : IECore . StringVectorData ( [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] ) , <EOL> "<STR_LIT>" : IECore . StringVectorData ( [ "<STR_LIT:hello>" , "<STR_LIT>" ] ) , <EOL> "<STR_LIT>" : IECore . Color3fVectorData ( [ IECore . Color3f ( <NUM_LIT:1> ) , IECore . Color3f ( <NUM_LIT:2> ) ] ) , <EOL> "<STR_LIT>" : IECore . Color3fVectorData ( [ IECore . Color3f ( <NUM_LIT:1> ) , IECore . Color3f ( <NUM_LIT:2> ) ] ) , <EOL> "<STR_LIT>" : IECore . V3fVectorData ( [ ] , IECore . GeometricData . Interpretation . Vector ) , <EOL> "<STR_LIT>" : IECore . V3fVectorData ( [ IECore . V3f ( x ) for x in range ( <NUM_LIT:1> , <NUM_LIT:6> ) ] , IECore . GeometricData . Interpretation . Vector ) , <EOL> "<STR_LIT>" : IECore . V3fVectorData ( [ ] , IECore . GeometricData . Interpretation . Point ) , <EOL> "<STR_LIT>" : IECore . V3fVectorData ( [ IECore . V3f ( x ) for x in range ( <NUM_LIT:1> , <NUM_LIT:6> ) ] , IECore . GeometricData . Interpretation . Point ) , <EOL> "<STR_LIT>" : IECore . V3fVectorData ( [ ] , IECore . GeometricData . Interpretation . Normal ) , <EOL> "<STR_LIT>" : IECore . V3fVectorData ( [ IECore . V3f ( x ) for x in range ( <NUM_LIT:1> , <NUM_LIT:6> ) ] , IECore . GeometricData . Interpretation . Normal ) , <EOL> } <EOL> self . assertEqual ( set ( n [ "<STR_LIT>" ] . keys ( ) ) , set ( expected . keys ( ) ) ) <EOL> for name , value in expected . items ( ) : <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ name ] . defaultValue ( ) , value ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] [ name ] . getValue ( ) , value ) <EOL> s = n . state ( ) [ <NUM_LIT:0> ] <EOL> for name , value in expected . items ( ) : <EOL> self . assertEqual ( s . parameters [ name ] , value ) <EOL> def testFixedCoshaderArrayParameters ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> n = GafferRenderMan . RenderManShader ( ) <EOL> n . loadShader ( shader ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] . keys ( ) , [ "<STR_LIT>" , "<STR_LIT>" ] ) <EOL> self . assertTrue ( isinstance ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . ArrayPlug ) ) <EOL> self . assertEqual ( len ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) , <NUM_LIT:4> ) <EOL> self . assertTrue ( isinstance ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . Plug ) ) <EOL> self . assertTrue ( isinstance ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . Plug ) ) <EOL> self . assertTrue ( isinstance ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . Plug ) ) <EOL> self . assertTrue ( isinstance ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . Plug ) ) <EOL> state = n . state ( ) <EOL> self . assertEqual ( state [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] , IECore . StringVectorData ( [ "<STR_LIT>" ] * <NUM_LIT:4> ) ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode . loadShader ( coshader ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( coshaderNode [ "<STR_LIT>" ] ) <EOL> state = n . state ( ) <EOL> self . assertEqual ( state [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] , IECore . StringVectorData ( [ state [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] . value , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] ) ) <EOL> def testCoshaderType ( self ) : <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode . loadShader ( coshader ) <EOL> self . assertEqual ( coshaderNode . state ( ) [ <NUM_LIT:0> ] . type , "<STR_LIT>" ) <EOL> def testCantConnectSurfaceShaderIntoCoshaderInput ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> n1 = GafferRenderMan . RenderManShader ( ) <EOL> n1 . loadShader ( shader ) <EOL> n2 = GafferRenderMan . RenderManShader ( ) <EOL> n2 . loadShader ( "<STR_LIT>" ) <EOL> self . assertFalse ( n1 [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( n2 [ "<STR_LIT>" ] ) ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> n3 = GafferRenderMan . RenderManShader ( ) <EOL> n3 . loadShader ( coshader ) <EOL> self . assertTrue ( n1 [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( n3 [ "<STR_LIT>" ] ) ) <EOL> arrayShader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> n4 = GafferRenderMan . RenderManShader ( ) <EOL> n4 . loadShader ( arrayShader ) <EOL> self . assertFalse ( n4 [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( n2 [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( n4 [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( n3 [ "<STR_LIT>" ] ) ) <EOL> def testConnectionsBetweenParameters ( self ) : <EOL> s = GafferRenderMan . RenderManShader ( ) <EOL> s . loadShader ( "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( <NUM_LIT> ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> shader = s . state ( ) [ <NUM_LIT:0> ] <EOL> self . assertEqual ( shader . parameters [ "<STR_LIT>" ] . value , <NUM_LIT> ) <EOL> self . assertEqual ( shader . parameters [ "<STR_LIT>" ] . value , <NUM_LIT> ) <EOL> def testFixedCoshaderArrayParameterHash ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> n = GafferRenderMan . RenderManShader ( ) <EOL> n . loadShader ( shader ) <EOL> h1 = n . stateHash ( ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode . loadShader ( coshader ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( coshaderNode [ "<STR_LIT>" ] ) <EOL> h2 = n . stateHash ( ) <EOL> self . assertNotEqual ( h2 , h1 ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( coshaderNode [ "<STR_LIT>" ] ) <EOL> h3 = n . stateHash ( ) <EOL> self . assertNotEqual ( h3 , h2 ) <EOL> self . assertNotEqual ( h3 , h1 ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( None ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( coshaderNode [ "<STR_LIT>" ] ) <EOL> h4 = n . stateHash ( ) <EOL> self . assertNotEqual ( h4 , h3 ) <EOL> self . assertNotEqual ( h4 , h2 ) <EOL> self . assertNotEqual ( h4 , h1 ) <EOL> def testDisabling ( self ) : <EOL> s = GafferRenderMan . RenderManShader ( ) <EOL> s . loadShader ( "<STR_LIT>" ) <EOL> stateHash = s . stateHash ( ) <EOL> state = s . state ( ) <EOL> self . assertEqual ( len ( state ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( state [ <NUM_LIT:0> ] . name , "<STR_LIT>" ) <EOL> self . assertTrue ( s [ "<STR_LIT>" ] . isSame ( s . enabledPlug ( ) ) ) <EOL> s [ "<STR_LIT>" ] . setValue ( False ) <EOL> stateHash2 = s . stateHash ( ) <EOL> self . assertNotEqual ( stateHash2 , stateHash ) <EOL> state2 = s . state ( ) <EOL> self . assertEqual ( len ( state2 ) , <NUM_LIT:0> ) <EOL> def testDisablingCoshaders ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode . loadShader ( coshader ) <EOL> shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( coshaderNode [ "<STR_LIT>" ] ) <EOL> s = shaderNode . state ( ) <EOL> self . assertEqual ( len ( s ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . name , shader ) <EOL> h = shaderNode . stateHash ( ) <EOL> coshaderNode [ "<STR_LIT>" ] . setValue ( False ) <EOL> s2 = shaderNode . state ( ) <EOL> self . assertEqual ( len ( s2 ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( s2 [ <NUM_LIT:0> ] . name , shader ) <EOL> self . assertTrue ( "<STR_LIT>" not in s2 [ <NUM_LIT:0> ] . parameters ) <EOL> self . assertNotEqual ( shaderNode . stateHash ( ) , h ) <EOL> def testDisablingCoshaderArrayInputs ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> n = GafferRenderMan . RenderManShader ( ) <EOL> n . loadShader ( shader ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode1 = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode1 . loadShader ( coshader ) <EOL> coshaderNode2 = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode2 . loadShader ( coshader ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . setInput ( coshaderNode1 [ "<STR_LIT>" ] ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:2> ] . setInput ( coshaderNode2 [ "<STR_LIT>" ] ) <EOL> state = n . state ( ) <EOL> h1 = n . stateHash ( ) <EOL> self . assertEqual ( <EOL> state [ <NUM_LIT:2> ] . parameters [ "<STR_LIT>" ] , <EOL> IECore . StringVectorData ( [ <EOL> state [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] . value , <EOL> "<STR_LIT>" , <EOL> state [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] . value , <EOL> "<STR_LIT>" <EOL> ] ) <EOL> ) <EOL> coshaderNode1 [ "<STR_LIT>" ] . setValue ( False ) <EOL> state = n . state ( ) <EOL> self . assertEqual ( <EOL> state [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] , <EOL> IECore . StringVectorData ( [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> state [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] . value , <EOL> "<STR_LIT>" <EOL> ] ) <EOL> ) <EOL> h2 = n . stateHash ( ) <EOL> self . assertNotEqual ( h2 , h1 ) <EOL> coshaderNode2 [ "<STR_LIT>" ] . setValue ( False ) <EOL> state = n . state ( ) <EOL> self . assertEqual ( <EOL> state [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] , <EOL> IECore . StringVectorData ( [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" <EOL> ] ) <EOL> ) <EOL> self . assertNotEqual ( n . stateHash ( ) , h1 ) <EOL> self . assertNotEqual ( n . stateHash ( ) , h2 ) <EOL> def testCorrespondingInput ( self ) : <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode . loadShader ( coshader ) <EOL> self . assertEqual ( coshaderNode . correspondingInput ( coshaderNode [ "<STR_LIT>" ] ) , None ) <EOL> coshader2 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode2 = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode2 . loadShader ( coshader2 ) <EOL> self . assertTrue ( coshaderNode2 . correspondingInput ( coshaderNode2 [ "<STR_LIT>" ] ) . isSame ( coshaderNode2 [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) ) <EOL> def testCoshaderPassThrough ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> passThroughCoshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> passThroughCoshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> passThroughCoshaderNode . loadShader ( passThroughCoshader ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode . loadShader ( coshader ) <EOL> shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( passThroughCoshaderNode [ "<STR_LIT>" ] ) <EOL> passThroughCoshaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( coshaderNode [ "<STR_LIT>" ] ) <EOL> h = shaderNode . stateHash ( ) <EOL> s = shaderNode . state ( ) <EOL> self . assertEqual ( len ( s ) , <NUM_LIT:3> ) <EOL> self . assertEqual ( s [ <NUM_LIT:2> ] . parameters [ "<STR_LIT>" ] , s [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . name , passThroughCoshader ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] , s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) <EOL> passThroughCoshaderNode [ "<STR_LIT>" ] . setValue ( False ) <EOL> s = shaderNode . state ( ) <EOL> self . assertEqual ( len ( s ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] , s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) <EOL> def testSplineParameters ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> n = GafferRenderMan . RenderManShader ( ) <EOL> n . loadShader ( shader ) <EOL> self . assertEqual ( n [ "<STR_LIT>" ] . keys ( ) , [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] ) <EOL> self . assertTrue ( isinstance ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . SplineffPlug ) ) <EOL> self . assertTrue ( isinstance ( n [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . SplinefColor3fPlug ) ) <EOL> self . assertEqual ( <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . defaultValue ( ) , <EOL> IECore . Splineff ( <EOL> IECore . CubicBasisf . catmullRom ( ) , <EOL> [ <EOL> ( <NUM_LIT:0> , <NUM_LIT:0> ) , <EOL> ( <NUM_LIT:0> , <NUM_LIT:0> ) , <EOL> ( <NUM_LIT:1> , <NUM_LIT:1> ) , <EOL> ( <NUM_LIT:1> , <NUM_LIT:1> ) , <EOL> ] <EOL> ) <EOL> ) <EOL> self . assertEqual ( <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . defaultValue ( ) , <EOL> IECore . SplinefColor3f ( <EOL> IECore . CubicBasisf . catmullRom ( ) , <EOL> [ <EOL> ( <NUM_LIT:0> , IECore . Color3f ( <NUM_LIT:0> ) ) , <EOL> ( <NUM_LIT:0> , IECore . Color3f ( <NUM_LIT:0> ) ) , <EOL> ( <NUM_LIT:1> , IECore . Color3f ( <NUM_LIT:1> ) ) , <EOL> ( <NUM_LIT:1> , IECore . Color3f ( <NUM_LIT:1> ) ) , <EOL> ] <EOL> ) <EOL> ) <EOL> floatValue = IECore . Splineff ( <EOL> IECore . CubicBasisf . catmullRom ( ) , <EOL> [ <EOL> ( <NUM_LIT:0> , <NUM_LIT:0> ) , <EOL> ( <NUM_LIT:0> , <NUM_LIT:0> ) , <EOL> ( <NUM_LIT:1> , <NUM_LIT:2> ) , <EOL> ( <NUM_LIT:1> , <NUM_LIT:2> ) , <EOL> ] <EOL> ) <EOL> colorValue = IECore . SplinefColor3f ( <EOL> IECore . CubicBasisf . catmullRom ( ) , <EOL> [ <EOL> ( <NUM_LIT:0> , IECore . Color3f ( <NUM_LIT:0> ) ) , <EOL> ( <NUM_LIT:0> , IECore . Color3f ( <NUM_LIT:0> ) ) , <EOL> ( <NUM_LIT:1> , IECore . Color3f ( <NUM_LIT> ) ) , <EOL> ( <NUM_LIT:1> , IECore . Color3f ( <NUM_LIT> ) ) , <EOL> ] <EOL> ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( floatValue ) <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( colorValue ) <EOL> s = n . state ( ) [ <NUM_LIT:0> ] <EOL> self . assertEqual ( s . parameters [ "<STR_LIT>" ] . value , floatValue ) <EOL> self . assertEqual ( s . parameters [ "<STR_LIT>" ] . value , colorValue ) <EOL> def testSplineParameterSerialisationKeepsExistingValues ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> s = Gaffer . ScriptNode ( ) <EOL> s [ "<STR_LIT:n>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT:n>" ] . loadShader ( shader ) <EOL> s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( <EOL> IECore . Splineff ( <EOL> IECore . CubicBasisf . catmullRom ( ) , <EOL> [ <EOL> ( <NUM_LIT:0> , <NUM_LIT:0> ) , <EOL> ( <NUM_LIT:0> , <NUM_LIT:0> ) , <EOL> ( <NUM_LIT:1> , <NUM_LIT:2> ) , <EOL> ( <NUM_LIT:1> , <NUM_LIT:2> ) , <EOL> ] <EOL> ) <EOL> ) <EOL> self . assertEqual ( <EOL> s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <EOL> IECore . Splineff ( <EOL> IECore . CubicBasisf . catmullRom ( ) , <EOL> [ <EOL> ( <NUM_LIT:0> , <NUM_LIT:0> ) , <EOL> ( <NUM_LIT:0> , <NUM_LIT:0> ) , <EOL> ( <NUM_LIT:1> , <NUM_LIT:2> ) , <EOL> ( <NUM_LIT:1> , <NUM_LIT:2> ) , <EOL> ] <EOL> ) , <EOL> ) <EOL> ss = s . serialise ( ) <EOL> s2 = Gaffer . ScriptNode ( ) <EOL> s2 . execute ( ss ) <EOL> self . assertEqual ( <EOL> s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <EOL> IECore . Splineff ( <EOL> IECore . CubicBasisf . catmullRom ( ) , <EOL> [ <EOL> ( <NUM_LIT:0> , <NUM_LIT:0> ) , <EOL> ( <NUM_LIT:0> , <NUM_LIT:0> ) , <EOL> ( <NUM_LIT:1> , <NUM_LIT:2> ) , <EOL> ( <NUM_LIT:1> , <NUM_LIT:2> ) , <EOL> ] <EOL> ) , <EOL> ) <EOL> def testSplineParameterDefaultValueAnnotation ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> n = GafferRenderMan . RenderManShader ( ) <EOL> n . loadShader ( shader ) <EOL> self . assertEqual ( <EOL> n [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <EOL> IECore . SplinefColor3f ( <EOL> IECore . CubicBasisf . catmullRom ( ) , <EOL> [ <EOL> ( <NUM_LIT:0> , IECore . Color3f ( <NUM_LIT:1> ) ) , <EOL> ( <NUM_LIT:0> , IECore . Color3f ( <NUM_LIT:1> ) ) , <EOL> ( <NUM_LIT:0.5> , IECore . Color3f ( <NUM_LIT:1> , <NUM_LIT:0.5> , <NUM_LIT> ) ) , <EOL> ( <NUM_LIT:1> , IECore . Color3f ( <NUM_LIT:0> ) ) , <EOL> ( <NUM_LIT:1> , IECore . Color3f ( <NUM_LIT:0> ) ) , <EOL> ] <EOL> ) , <EOL> ) <EOL> def testCoshadersInBox ( self ) : <EOL> s = Gaffer . ScriptNode ( ) <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT>" ] . loadShader ( shader ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT>" ] . loadShader ( coshader ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> b = Gaffer . Box . create ( s , Gaffer . StandardSet ( [ s [ "<STR_LIT>" ] ] ) ) <EOL> self . assertTrue ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getInput ( ) . parent ( ) . isSame ( b ) ) <EOL> s = s [ "<STR_LIT>" ] . state ( ) <EOL> self . assertEqual ( len ( s ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] , s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) <EOL> def testShaderInBoxWithExternalCoshader ( self ) : <EOL> s = Gaffer . ScriptNode ( ) <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT>" ] . loadShader ( shader ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT>" ] . loadShader ( coshader ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> b = Gaffer . Box . create ( s , Gaffer . StandardSet ( [ s [ "<STR_LIT>" ] ] ) ) <EOL> self . assertTrue ( b [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getInput ( ) . parent ( ) . isSame ( b ) ) <EOL> s = b [ "<STR_LIT>" ] . state ( ) <EOL> self . assertEqual ( len ( s ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] , s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) <EOL> def testNumericTypeAnnotations ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> self . assertTrue ( isinstance ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . FloatPlug ) ) <EOL> self . assertTrue ( isinstance ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . FloatPlug ) ) <EOL> self . assertTrue ( isinstance ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . IntPlug ) ) <EOL> self . assertTrue ( isinstance ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] , Gaffer . BoolPlug ) ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . defaultValue ( ) , <NUM_LIT> ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . defaultValue ( ) , <NUM_LIT> ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . defaultValue ( ) , <NUM_LIT:10> ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . defaultValue ( ) , True ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <NUM_LIT> ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <NUM_LIT> ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <NUM_LIT:10> ) <EOL> self . assertEqual ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , True ) <EOL> def testCoshaderTypeAnnotations ( self ) : <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode . loadShader ( coshader ) <EOL> coshaderType1 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderType1Node = GafferRenderMan . RenderManShader ( ) <EOL> coshaderType1Node . loadShader ( coshaderType1 ) <EOL> coshaderType2 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderType2Node = GafferRenderMan . RenderManShader ( ) <EOL> coshaderType2Node . loadShader ( coshaderType2 ) <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderNode [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderType1Node [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderType2Node [ "<STR_LIT>" ] ) ) <EOL> self . assertFalse ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderNode [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderType1Node [ "<STR_LIT>" ] ) ) <EOL> self . assertFalse ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderType2Node [ "<STR_LIT>" ] ) ) <EOL> self . assertFalse ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderNode [ "<STR_LIT>" ] ) ) <EOL> self . assertFalse ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderType1Node [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderType2Node [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderNode [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderType1Node [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderType2Node [ "<STR_LIT>" ] ) ) <EOL> self . assertFalse ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderNode [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderType1Node [ "<STR_LIT>" ] ) ) <EOL> self . assertFalse ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderType2Node [ "<STR_LIT>" ] ) ) <EOL> self . assertFalse ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . acceptsInput ( coshaderNode [ "<STR_LIT>" ] ) ) <EOL> self . assertFalse ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . acceptsInput ( coshaderType1Node [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . acceptsInput ( coshaderType2Node [ "<STR_LIT>" ] ) ) <EOL> def testMultipleCoshaderTypeAnnotations ( self ) : <EOL> coshaderType1And2 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderType1And2Node = GafferRenderMan . RenderManShader ( ) <EOL> coshaderType1And2Node . loadShader ( coshaderType1And2 ) <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderType1And2Node [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderType1And2Node [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderType1And2Node [ "<STR_LIT>" ] ) ) <EOL> self . assertFalse ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( coshaderType1And2Node [ "<STR_LIT>" ] ) ) <EOL> def testSplitCoshaderPassThrough ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> S = GafferRenderMan . RenderManShader ( ) <EOL> S . loadShader ( shader ) <EOL> passThroughCoshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> D = GafferRenderMan . RenderManShader ( ) <EOL> D . loadShader ( passThroughCoshader ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> C = GafferRenderMan . RenderManShader ( ) <EOL> C . loadShader ( coshader ) <EOL> S [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . setInput ( C [ "<STR_LIT>" ] ) <EOL> S [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . setInput ( D [ "<STR_LIT>" ] ) <EOL> D [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( C [ "<STR_LIT>" ] ) <EOL> h = S . stateHash ( ) <EOL> s = S . state ( ) <EOL> self . assertEqual ( len ( s ) , <NUM_LIT:3> ) <EOL> self . assertEqual ( s [ <NUM_LIT:2> ] . parameters [ "<STR_LIT>" ] , IECore . StringVectorData ( [ s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] . value , s [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] . value , "<STR_LIT>" , "<STR_LIT>" ] ) ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] , s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . name , passThroughCoshader ) <EOL> D [ "<STR_LIT>" ] . setValue ( False ) <EOL> self . assertNotEqual ( S . stateHash ( ) , h ) <EOL> s = S . state ( ) <EOL> self . assertEqual ( len ( s ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] , IECore . StringVectorData ( [ s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] . value , s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] . value , "<STR_LIT>" , "<STR_LIT>" ] ) ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) <EOL> def testSerialDisabledShaders ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> S = GafferRenderMan . RenderManShader ( ) <EOL> S . loadShader ( shader ) <EOL> passThroughCoshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> D1 = GafferRenderMan . RenderManShader ( ) <EOL> D1 . loadShader ( passThroughCoshader ) <EOL> D2 = GafferRenderMan . RenderManShader ( ) <EOL> D2 . loadShader ( passThroughCoshader ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> C = GafferRenderMan . RenderManShader ( ) <EOL> C . loadShader ( coshader ) <EOL> S [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( D2 [ "<STR_LIT>" ] ) <EOL> D2 [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( D1 [ "<STR_LIT>" ] ) <EOL> D1 [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( C [ "<STR_LIT>" ] ) <EOL> h1 = S . stateHash ( ) <EOL> s = S . state ( ) <EOL> self . assertEqual ( len ( s ) , <NUM_LIT:4> ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . name , passThroughCoshader ) <EOL> self . assertEqual ( s [ <NUM_LIT:2> ] . name , passThroughCoshader ) <EOL> self . assertEqual ( s [ <NUM_LIT:3> ] . name , shader ) <EOL> self . assertEqual ( s [ <NUM_LIT:3> ] . parameters [ "<STR_LIT>" ] , s [ <NUM_LIT:2> ] . parameters [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( s [ <NUM_LIT:2> ] . parameters [ "<STR_LIT>" ] , s [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] , s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] ) <EOL> D2 [ "<STR_LIT>" ] . setValue ( False ) <EOL> h2 = S . stateHash ( ) <EOL> self . assertNotEqual ( h1 , h2 ) <EOL> s = S . state ( ) <EOL> self . assertEqual ( len ( s ) , <NUM_LIT:3> ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . name , passThroughCoshader ) <EOL> self . assertEqual ( s [ <NUM_LIT:2> ] . name , shader ) <EOL> self . assertEqual ( s [ <NUM_LIT:2> ] . parameters [ "<STR_LIT>" ] , s [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] , s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] ) <EOL> D1 [ "<STR_LIT>" ] . setValue ( False ) <EOL> h3 = S . stateHash ( ) <EOL> self . assertNotEqual ( h3 , h2 ) <EOL> self . assertNotEqual ( h3 , h1 ) <EOL> s = S . state ( ) <EOL> self . assertEqual ( len ( s ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . name , coshader ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . name , shader ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] , s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] ) <EOL> def testDynamicCoshaderArrayParameters ( self ) : <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode . loadShader ( coshader ) <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> self . assertEqual ( len ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) , <NUM_LIT:1> ) <EOL> self . assertTrue ( isinstance ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] , Gaffer . Plug ) ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . getInput ( ) is None ) <EOL> shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . setInput ( coshaderNode [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( len ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) , <NUM_LIT:2> ) <EOL> self . assertTrue ( isinstance ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] , Gaffer . Plug ) ) <EOL> self . assertTrue ( isinstance ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] , Gaffer . Plug ) ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . getInput ( ) . isSame ( coshaderNode [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . getInput ( ) is None ) <EOL> shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . setInput ( None ) <EOL> self . assertEqual ( len ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) , <NUM_LIT:1> ) <EOL> self . assertTrue ( isinstance ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] , Gaffer . Plug ) ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . getInput ( ) is None ) <EOL> def testSerialiseDynamicCoshaderArrayParameters ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> s = Gaffer . ScriptNode ( ) <EOL> s [ "<STR_LIT:n>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT:n>" ] . loadShader ( shader ) <EOL> s [ "<STR_LIT:c>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT:c>" ] . loadShader ( coshader ) <EOL> s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . setInput ( s [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . setInput ( s [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:2> ] . setInput ( s [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . setInput ( None ) <EOL> self . assertEqual ( len ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) , <NUM_LIT:4> ) <EOL> s2 = Gaffer . ScriptNode ( ) <EOL> s2 . execute ( s . serialise ( ) ) <EOL> self . assertEqual ( len ( s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) , <NUM_LIT:4> ) <EOL> self . assertTrue ( s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . getInput ( ) . isSame ( s2 [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . getInput ( ) is None ) <EOL> self . assertTrue ( s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:2> ] . getInput ( ) . isSame ( s2 [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:3> ] . getInput ( ) is None ) <EOL> s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:3> ] . setInput ( s2 [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( len ( s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) , <NUM_LIT:5> ) <EOL> self . assertTrue ( s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . getInput ( ) . isSame ( s2 [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . getInput ( ) is None ) <EOL> self . assertTrue ( s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:2> ] . getInput ( ) . isSame ( s2 [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:3> ] . getInput ( ) . isSame ( s2 [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:4> ] . getInput ( ) is None ) <EOL> def testConvertFixedCoshaderArrayToDynamic ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderV2 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> s = Gaffer . ScriptNode ( ) <EOL> s [ "<STR_LIT:n>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT:n>" ] . loadShader ( shader ) <EOL> s [ "<STR_LIT:c>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT:c>" ] . loadShader ( coshader ) <EOL> s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . setInput ( s [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) <EOL> self . assertTrue ( len ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) , <NUM_LIT:4> ) <EOL> s [ "<STR_LIT:n>" ] . loadShader ( shaderV2 , keepExistingValues = True ) <EOL> self . assertTrue ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . getInput ( ) . isSame ( s [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . getInput ( ) is None ) <EOL> s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . setInput ( None ) <EOL> self . assertEqual ( len ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) , <NUM_LIT:1> ) <EOL> self . assertTrue ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . getInput ( ) is None ) <EOL> def testConvertFixedCoshaderArrayToDynamicWithFirstPlugUnconnected ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderV2 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> s = Gaffer . ScriptNode ( ) <EOL> s [ "<STR_LIT:n>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT:n>" ] . loadShader ( shader ) <EOL> s [ "<STR_LIT:c>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT:c>" ] . loadShader ( coshader ) <EOL> s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . setInput ( s [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) <EOL> self . assertTrue ( len ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) , <NUM_LIT:4> ) <EOL> s [ "<STR_LIT:n>" ] . loadShader ( shaderV2 , keepExistingValues = True ) <EOL> self . assertTrue ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . getInput ( ) . isSame ( s [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . getInput ( ) is None ) <EOL> s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . setInput ( None ) <EOL> self . assertEqual ( len ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) , <NUM_LIT:1> ) <EOL> self . assertTrue ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . getInput ( ) is None ) <EOL> def testConvertFixedCoshaderArrayToDynamicDuringLoading ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> s = Gaffer . ScriptNode ( ) <EOL> s [ "<STR_LIT:n>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT:n>" ] . loadShader ( shader ) <EOL> s [ "<STR_LIT:c>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT:c>" ] . loadShader ( coshader ) <EOL> s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . setInput ( s [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) <EOL> self . assertTrue ( len ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) , <NUM_LIT:4> ) <EOL> GafferRenderMan . RenderManShader . shaderLoader ( ) . clear ( ) <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" , shaderName = "<STR_LIT>" ) <EOL> s2 = Gaffer . ScriptNode ( ) <EOL> s2 . execute ( s . serialise ( ) ) <EOL> self . assertTrue ( s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . getInput ( ) . isSame ( s2 [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . getInput ( ) is None ) <EOL> s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . setInput ( None ) <EOL> self . assertEqual ( len ( s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) , <NUM_LIT:1> ) <EOL> self . assertTrue ( s2 [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . getInput ( ) is None ) <EOL> def testHashThroughBox ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> b = Gaffer . Box ( ) <EOL> b . addChild ( Gaffer . Plug ( "<STR_LIT>" ) ) <EOL> b . addChild ( Gaffer . Plug ( "<STR_LIT>" , direction = Gaffer . Plug . Direction . Out ) ) <EOL> intermediateCoshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> intermediateCoshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> intermediateCoshaderNode . loadShader ( intermediateCoshader ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode . loadShader ( coshader ) <EOL> b [ "<STR_LIT>" ] . setInput ( coshaderNode [ "<STR_LIT>" ] ) <EOL> intermediateCoshaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( b [ "<STR_LIT>" ] ) <EOL> b [ "<STR_LIT>" ] . setInput ( intermediateCoshaderNode [ "<STR_LIT>" ] ) <EOL> shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( b [ "<STR_LIT>" ] ) <EOL> h1 = shaderNode . stateHash ( ) <EOL> coshaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( <NUM_LIT> ) <EOL> self . assertNotEqual ( shaderNode . stateHash ( ) , h1 ) <EOL> def testDanglingBoxConnection ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode1 = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode1 . loadShader ( shader ) <EOL> shaderNode2 = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode2 . loadShader ( shader ) <EOL> b = Gaffer . Box ( ) <EOL> b . addChild ( Gaffer . Plug ( "<STR_LIT>" ) ) <EOL> b . addChild ( Gaffer . Plug ( "<STR_LIT>" , direction = Gaffer . Plug . Direction . Out ) ) <EOL> b [ "<STR_LIT>" ] = shaderNode1 <EOL> shaderNode1 [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( b [ "<STR_LIT>" ] ) <EOL> shaderNode2 [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( b [ "<STR_LIT>" ] ) <EOL> def testUnconnectedCustomBoxInput ( self ) : <EOL> class CustomBox ( Gaffer . Box ) : <EOL> def __init__ ( self , name = "<STR_LIT>" ) : <EOL> Gaffer . Box . __init__ ( self , name ) <EOL> IECore . registerRunTimeTyped ( CustomBox ) <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> b = CustomBox ( ) <EOL> b [ "<STR_LIT:s>" ] = GafferRenderMan . RenderManShader ( ) <EOL> b [ "<STR_LIT:s>" ] . loadShader ( shader ) <EOL> b [ "<STR_LIT>" ] = b [ "<STR_LIT:s>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . createCounterpart ( "<STR_LIT>" , Gaffer . Plug . Direction . In ) <EOL> b [ "<STR_LIT:s>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( b [ "<STR_LIT>" ] ) <EOL> s = b [ "<STR_LIT:s>" ] . state ( ) <EOL> self . assertEqual ( len ( s ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . name , shader ) <EOL> self . assertTrue ( b [ "<STR_LIT:s>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getInput ( ) . isSame ( b [ "<STR_LIT>" ] ) ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> c = GafferRenderMan . RenderManShader ( ) <EOL> c . loadShader ( coshader ) <EOL> self . assertTrue ( b [ "<STR_LIT>" ] . acceptsInput ( c [ "<STR_LIT>" ] ) ) <EOL> b [ "<STR_LIT>" ] . setInput ( c [ "<STR_LIT>" ] ) <EOL> s = b [ "<STR_LIT:s>" ] . state ( ) <EOL> self . assertEqual ( len ( s ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( s [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] , s [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] ) <EOL> n = Gaffer . Node ( ) <EOL> n [ "<STR_LIT>" ] = b [ "<STR_LIT>" ] . createCounterpart ( "<STR_LIT>" , Gaffer . Plug . Direction . Out ) <EOL> self . assertFalse ( b [ "<STR_LIT>" ] . acceptsInput ( n [ "<STR_LIT>" ] ) ) <EOL> self . assertRaises ( RuntimeError , b [ "<STR_LIT>" ] . setInput , n [ "<STR_LIT>" ] ) <EOL> b [ "<STR_LIT:s>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( None ) <EOL> self . assertTrue ( b [ "<STR_LIT>" ] . acceptsInput ( n [ "<STR_LIT>" ] ) ) <EOL> b [ "<STR_LIT>" ] . setInput ( n [ "<STR_LIT>" ] ) <EOL> self . assertTrue ( b [ "<STR_LIT>" ] . getInput ( ) . isSame ( n [ "<STR_LIT>" ] ) ) <EOL> self . assertFalse ( b [ "<STR_LIT:s>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( b [ "<STR_LIT>" ] ) ) <EOL> self . assertRaises ( RuntimeError , b [ "<STR_LIT:s>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput , b [ "<STR_LIT>" ] ) <EOL> def testCoshaderSwitching ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode0 = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode0 . loadShader ( coshader ) <EOL> coshaderNode1 = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode1 . loadShader ( coshader ) <EOL> coshaderNode0 [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( <NUM_LIT:0> ) <EOL> coshaderNode1 [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( <NUM_LIT:1> ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> switch = GafferScene . ShaderSwitch ( ) <EOL> switch [ "<STR_LIT>" ] . setInput ( coshaderNode0 [ "<STR_LIT>" ] ) <EOL> switch [ "<STR_LIT>" ] . setInput ( coshaderNode1 [ "<STR_LIT>" ] ) <EOL> shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( switch [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( shaderNode . state ( ) [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] . value , <NUM_LIT:0> ) <EOL> switch [ "<STR_LIT:index>" ] . setValue ( <NUM_LIT:1> ) <EOL> self . assertEqual ( shaderNode . state ( ) [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] . value , <NUM_LIT:1> ) <EOL> switch [ "<STR_LIT>" ] . setValue ( False ) <EOL> self . assertEqual ( shaderNode . state ( ) [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] . value , <NUM_LIT:0> ) <EOL> def testCoshaderTypingPreventsNewInvalidSwitchInputs ( self ) : <EOL> coshaderType1 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderType1Node = GafferRenderMan . RenderManShader ( ) <EOL> coshaderType1Node . loadShader ( coshaderType1 ) <EOL> coshaderType2 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderType2Node = GafferRenderMan . RenderManShader ( ) <EOL> coshaderType2Node . loadShader ( coshaderType2 ) <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> switch = GafferScene . ShaderSwitch ( ) <EOL> switch [ "<STR_LIT>" ] . setInput ( coshaderType1Node [ "<STR_LIT>" ] ) <EOL> shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( switch [ "<STR_LIT>" ] ) <EOL> self . assertFalse ( switch [ "<STR_LIT>" ] . acceptsInput ( coshaderType2Node [ "<STR_LIT>" ] ) ) <EOL> self . assertTrue ( switch [ "<STR_LIT>" ] . acceptsInput ( coshaderType1Node [ "<STR_LIT>" ] ) ) <EOL> def testAcceptInputFromEmptySwitch ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> switch = GafferScene . ShaderSwitch ( ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( switch [ "<STR_LIT>" ] ) ) <EOL> def testCoshaderSwitchingInBox ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> script = Gaffer . ScriptNode ( ) <EOL> script [ "<STR_LIT>" ] = GafferRenderMan . RenderManShader ( ) <EOL> script [ "<STR_LIT>" ] . loadShader ( coshader ) <EOL> script [ "<STR_LIT>" ] = GafferRenderMan . RenderManShader ( ) <EOL> script [ "<STR_LIT>" ] . loadShader ( coshader ) <EOL> script [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( <NUM_LIT:0> ) <EOL> script [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( <NUM_LIT:1> ) <EOL> script [ "<STR_LIT>" ] = GafferRenderMan . RenderManShader ( ) <EOL> script [ "<STR_LIT>" ] . loadShader ( shader ) <EOL> script [ "<STR_LIT>" ] = GafferScene . ShaderSwitch ( ) <EOL> script [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( script [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> script [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( script [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> script [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( script [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( script [ "<STR_LIT>" ] . state ( ) [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] . value , <NUM_LIT:0> ) <EOL> box = Gaffer . Box . create ( script , Gaffer . StandardSet ( script . children ( Gaffer . Node ) ) ) <EOL> self . assertEqual ( box [ "<STR_LIT>" ] . state ( ) [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] . value , <NUM_LIT:0> ) <EOL> promotedIndex = box . promotePlug ( box [ "<STR_LIT>" ] [ "<STR_LIT:index>" ] ) <EOL> self . assertEqual ( box [ "<STR_LIT>" ] . state ( ) [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] . value , <NUM_LIT:0> ) <EOL> promotedIndex . setValue ( <NUM_LIT:1> ) <EOL> self . assertEqual ( box [ "<STR_LIT>" ] . state ( ) [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] . value , <NUM_LIT:1> ) <EOL> def testRepeatability ( self ) : <EOL> s1 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> s2 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> sn1 = GafferRenderMan . RenderManShader ( ) <EOL> sn2 = GafferRenderMan . RenderManShader ( ) <EOL> sn1 . loadShader ( s1 ) <EOL> sn2 . loadShader ( s2 ) <EOL> sn2 [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( sn1 [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( sn2 . stateHash ( ) , sn2 . stateHash ( ) ) <EOL> self . assertEqual ( sn2 . state ( ) , sn2 . state ( ) ) <EOL> def testHandlesAreHumanReadable ( self ) : <EOL> s1 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> s2 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> sn1 = GafferRenderMan . RenderManShader ( "<STR_LIT>" ) <EOL> sn2 = GafferRenderMan . RenderManShader ( "<STR_LIT>" ) <EOL> sn1 . loadShader ( s1 ) <EOL> sn2 . loadShader ( s2 ) <EOL> sn2 [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( sn1 [ "<STR_LIT>" ] ) <EOL> state = sn2 . state ( ) <EOL> self . assertTrue ( "<STR_LIT>" in state [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] . value ) <EOL> def testHandlesAreUniqueEvenIfNodeNamesArent ( self ) : <EOL> s1 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> s2 = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> script = Gaffer . ScriptNode ( ) <EOL> script [ "<STR_LIT>" ] = GafferRenderMan . RenderManShader ( ) <EOL> script [ "<STR_LIT>" ] . loadShader ( s1 ) <EOL> script [ "<STR_LIT>" ] = GafferRenderMan . RenderManShader ( ) <EOL> script [ "<STR_LIT>" ] . loadShader ( s1 ) <EOL> script [ "<STR_LIT>" ] = GafferRenderMan . RenderManShader ( ) <EOL> script [ "<STR_LIT>" ] . loadShader ( s2 ) <EOL> script [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] . setInput ( script [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> script [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ <NUM_LIT:1> ] . setInput ( script [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> box = Gaffer . Box . create ( script , Gaffer . StandardSet ( [ script [ "<STR_LIT>" ] ] ) ) <EOL> box [ "<STR_LIT>" ] . setName ( "<STR_LIT>" ) <EOL> script [ "<STR_LIT>" ] . setName ( "<STR_LIT>" ) <EOL> state = script [ "<STR_LIT>" ] . state ( ) <EOL> self . assertNotEqual ( state [ <NUM_LIT:0> ] . parameters [ "<STR_LIT>" ] , state [ <NUM_LIT:1> ] . parameters [ "<STR_LIT>" ] ) <EOL> def testShaderTypesInState ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode . loadShader ( coshader ) <EOL> shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( coshaderNode [ "<STR_LIT>" ] ) <EOL> state = shaderNode . state ( ) <EOL> self . assertEqual ( state [ <NUM_LIT:0> ] . type , "<STR_LIT>" ) <EOL> self . assertEqual ( state [ <NUM_LIT:1> ] . type , "<STR_LIT>" ) <EOL> def testAssignmentAttributeName ( self ) : <EOL> p = GafferScene . Plane ( ) <EOL> s = GafferRenderMan . RenderManShader ( ) <EOL> s . loadShader ( "<STR_LIT>" ) <EOL> a = GafferScene . ShaderAssignment ( ) <EOL> a [ "<STR_LIT>" ] . setInput ( p [ "<STR_LIT>" ] ) <EOL> a [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( a [ "<STR_LIT>" ] . attributes ( "<STR_LIT>" ) . keys ( ) , [ "<STR_LIT>" ] ) <EOL> def testVolumeShader ( self ) : <EOL> s = GafferRenderMan . RenderManShader ( ) <EOL> s . loadShader ( "<STR_LIT>" ) <EOL> self . assertEqual ( s [ "<STR_LIT:type>" ] . getValue ( ) , "<STR_LIT>" ) <EOL> s [ "<STR_LIT:type>" ] . setValue ( "<STR_LIT>" ) <EOL> s . loadShader ( "<STR_LIT>" , keepExistingValues = True ) <EOL> self . assertEqual ( s [ "<STR_LIT:type>" ] . getValue ( ) , "<STR_LIT>" ) <EOL> s . loadShader ( "<STR_LIT>" , keepExistingValues = False ) <EOL> self . assertEqual ( s [ "<STR_LIT:type>" ] . getValue ( ) , "<STR_LIT>" ) <EOL> def testInputAcceptanceFromDots ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshaderNode = GafferRenderMan . RenderManShader ( ) <EOL> coshaderNode . loadShader ( coshader ) <EOL> dot = Gaffer . Dot ( ) <EOL> dot . setup ( coshaderNode [ "<STR_LIT>" ] ) <EOL> self . assertTrue ( shaderNode [ "<STR_LIT>" ] [ "<STR_LIT>" ] . acceptsInput ( dot [ "<STR_LIT>" ] ) ) <EOL> def testShaderTypeOverride ( self ) : <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> shaderNode = GafferRenderMan . RenderManShader ( ) <EOL> shaderNode . loadShader ( shader ) <EOL> self . assertEqual ( shaderNode [ '<STR_LIT:type>' ] . getValue ( ) , "<STR_LIT>" ) <EOL> def testReferencePromotedCoshader ( self ) : <EOL> s = Gaffer . ScriptNode ( ) <EOL> shader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> coshader = self . compileShader ( os . path . dirname ( __file__ ) + "<STR_LIT>" ) <EOL> s [ "<STR_LIT:b>" ] = Gaffer . Box ( ) <EOL> s [ "<STR_LIT:b>" ] [ "<STR_LIT:s>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT:b>" ] [ "<STR_LIT:s>" ] . loadShader ( shader ) <EOL> p = s [ "<STR_LIT:b>" ] . promotePlug ( s [ "<STR_LIT:b>" ] [ "<STR_LIT:s>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> p . setName ( "<STR_LIT:p>" ) <EOL> s [ "<STR_LIT:c>" ] = GafferRenderMan . RenderManShader ( ) <EOL> s [ "<STR_LIT:c>" ] . loadShader ( coshader ) <EOL> self . assertTrue ( s [ "<STR_LIT:b>" ] [ "<STR_LIT:p>" ] . acceptsInput ( s [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) ) <EOL> s [ "<STR_LIT:b>" ] . exportForReference ( self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> s [ "<STR_LIT:r>" ] = Gaffer . Reference ( ) <EOL> s [ "<STR_LIT:r>" ] . load ( self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> self . assertTrue ( s [ "<STR_LIT:r>" ] [ "<STR_LIT:p>" ] . acceptsInput ( s [ "<STR_LIT:c>" ] [ "<STR_LIT>" ] ) ) <EOL> def testLoadAndGIL ( self ) : <EOL> script = Gaffer . ScriptNode ( ) <EOL> script [ "<STR_LIT>" ] = GafferScene . Plane ( ) <EOL> script [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( IECore . V2i ( <NUM_LIT:20> ) ) <EOL> script [ "<STR_LIT>" ] = GafferScene . Sphere ( ) <EOL> script [ "<STR_LIT>" ] = Gaffer . Expression ( ) <EOL> script [ "<STR_LIT>" ] . setExpression ( "<STR_LIT>" ) <EOL> script [ "<STR_LIT>" ] = GafferScene . Instancer ( ) <EOL> script [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( script [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> script [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( script [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> script [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( "<STR_LIT>" ) <EOL> script [ "<STR_LIT>" ] = GafferRenderMan . RenderManShader ( ) <EOL> script [ "<STR_LIT>" ] = GafferScene . ShaderAssignment ( ) <EOL> script [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( script [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> script [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( script [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> traverseConnection = Gaffer . ScopedConnection ( GafferSceneTest . connectTraverseSceneToPlugDirtiedSignal ( script [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) ) <EOL> script [ "<STR_LIT>" ] . loadShader ( "<STR_LIT>" ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> import os <EOL> import unittest <EOL> import IECore <EOL> import Gaffer <EOL> import GafferImage <EOL> import GafferScene <EOL> import GafferSceneTest <EOL> @ unittest . skipIf ( "<STR_LIT>" in os . environ , "<STR_LIT>" ) <EOL> class OpenGLRenderTest ( GafferSceneTest . SceneTestCase ) : <EOL> def test ( self ) : <EOL> self . assertFalse ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" ) ) <EOL> s = Gaffer . ScriptNode ( ) <EOL> s [ "<STR_LIT>" ] = GafferScene . Plane ( ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( IECore . V3f ( <NUM_LIT:0> , <NUM_LIT:0> , - <NUM_LIT:5> ) ) <EOL> s [ "<STR_LIT:image>" ] = GafferImage . ImageReader ( ) <EOL> s [ "<STR_LIT:image>" ] [ "<STR_LIT>" ] . setValue ( os . path . expandvars ( "<STR_LIT>" ) ) <EOL> s [ "<STR_LIT>" ] = GafferScene . OpenGLShader ( ) <EOL> s [ "<STR_LIT>" ] . loadShader ( "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT:image>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( <NUM_LIT:1> ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue ( IECore . Color4f ( <NUM_LIT:1> ) ) <EOL> s [ "<STR_LIT>" ] = GafferScene . ShaderAssignment ( ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT>" ] = GafferScene . Outputs ( ) <EOL> s [ "<STR_LIT>" ] . addOutput ( <EOL> "<STR_LIT>" , <EOL> IECore . Display ( <EOL> self . temporaryDirectory ( ) + "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> { } <EOL> ) <EOL> ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT>" ] = GafferScene . OpenGLRender ( ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT>" ] . setValue ( self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> s . save ( ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . execute ( ) <EOL> self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" ) ) <EOL> i = IECore . EXRImageReader ( self . temporaryDirectory ( ) + "<STR_LIT>" ) . read ( ) <EOL> e = IECore . ImagePrimitiveEvaluator ( i ) <EOL> r = e . createResult ( ) <EOL> e . pointAtUV ( IECore . V2f ( <NUM_LIT:0.5> ) , r ) <EOL> self . assertAlmostEqual ( r . floatPrimVar ( e . R ( ) ) , <NUM_LIT> , <NUM_LIT:5> ) <EOL> self . assertAlmostEqual ( r . floatPrimVar ( e . G ( ) ) , <NUM_LIT> , <NUM_LIT:5> ) <EOL> self . assertEqual ( r . floatPrimVar ( e . B ( ) ) , <NUM_LIT:0> ) <EOL> def testOutputDirectoryCreation ( self ) : <EOL> s = Gaffer . ScriptNode ( ) <EOL> s [ "<STR_LIT>" ] . addMember ( "<STR_LIT>" , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> s [ "<STR_LIT>" ] = GafferScene . Plane ( ) <EOL> s [ "<STR_LIT>" ] = GafferScene . Outputs ( ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT>" ] . addOutput ( <EOL> "<STR_LIT>" , <EOL> IECore . Display ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> { } <EOL> ) <EOL> ) <EOL> s [ "<STR_LIT>" ] = GafferScene . OpenGLRender ( ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> self . assertFalse ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" ) ) <EOL> self . assertFalse ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" ) ) <EOL> s [ "<STR_LIT>" ] . setValue ( "<STR_LIT>" ) <EOL> with s . context ( ) : <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . execute ( ) <EOL> self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" ) ) <EOL> self . assertTrue ( os . path . exists ( self . temporaryDirectory ( ) + "<STR_LIT>" ) ) <EOL> def testHash ( self ) : <EOL> c = Gaffer . Context ( ) <EOL> c . setFrame ( <NUM_LIT:1> ) <EOL> c2 = Gaffer . Context ( ) <EOL> c2 . setFrame ( <NUM_LIT:2> ) <EOL> s = Gaffer . ScriptNode ( ) <EOL> s [ "<STR_LIT>" ] = GafferScene . Plane ( ) <EOL> s [ "<STR_LIT>" ] = GafferScene . Outputs ( ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> s [ "<STR_LIT>" ] . addOutput ( "<STR_LIT>" , IECore . Display ( "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , { } ) ) <EOL> s [ "<STR_LIT>" ] = GafferScene . OpenGLRender ( ) <EOL> self . assertEqual ( s [ "<STR_LIT>" ] . hash ( c ) , IECore . MurmurHash ( ) ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> self . assertNotEqual ( s [ "<STR_LIT>" ] . hash ( c ) , IECore . MurmurHash ( ) ) <EOL> self . assertNotEqual ( s [ "<STR_LIT>" ] . hash ( c ) , s [ "<STR_LIT>" ] . hash ( c2 ) ) <EOL> current = s [ "<STR_LIT>" ] . hash ( c ) <EOL> c [ "<STR_LIT>" ] = self . temporaryDirectory ( ) + "<STR_LIT>" <EOL> self . assertNotEqual ( s [ "<STR_LIT>" ] . hash ( c ) , current ) <EOL> current = s [ "<STR_LIT>" ] . hash ( c ) <EOL> c [ "<STR_LIT>" ] = self . temporaryDirectory ( ) + "<STR_LIT>" <EOL> self . assertNotEqual ( s [ "<STR_LIT>" ] . hash ( c ) , current ) <EOL> current = s [ "<STR_LIT>" ] . hash ( c ) <EOL> c [ "<STR_LIT>" ] = "<STR_LIT>" <EOL> self . assertEqual ( s [ "<STR_LIT>" ] . hash ( c ) , current ) <EOL> current = s [ "<STR_LIT>" ] . hash ( c ) <EOL> s [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setInput ( s [ "<STR_LIT>" ] [ "<STR_LIT>" ] ) <EOL> self . assertNotEqual ( s [ "<STR_LIT>" ] . hash ( c ) , current ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> import unittest <EOL> import IECore <EOL> import Gaffer <EOL> import GafferTest <EOL> import GafferScene <EOL> import GafferSceneTest <EOL> class SceneTimeWarpTest ( GafferSceneTest . SceneTestCase ) : <EOL> def testConstruct ( self ) : <EOL> s = Gaffer . ScriptNode ( ) <EOL> s [ "<STR_LIT:n>" ] = GafferScene . SceneTimeWarp ( ) <EOL> self . assertEqual ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] . getValue ( ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( s [ "<STR_LIT:n>" ] [ "<STR_LIT>" ] . getValue ( ) , <NUM_LIT:0> ) <EOL> def testRunTimeTyped ( self ) : <EOL> n = GafferScene . SceneTimeWarp ( ) <EOL> self . failUnless ( n . isInstanceOf ( GafferScene . SceneTimeWarp . staticTypeId ( ) ) ) <EOL> self . failUnless ( n . isInstanceOf ( GafferScene . SceneContextProcessor . staticTypeId ( ) ) ) <EOL> self . failUnless ( n . isInstanceOf ( GafferScene . SceneProcessor . staticTypeId ( ) ) ) <EOL> self . failUnless ( n . isInstanceOf ( GafferScene . SceneNode . staticTypeId ( ) ) ) <EOL> self . failUnless ( n . isInstanceOf ( Gaffer . Node . staticTypeId ( ) ) ) <EOL> baseTypeIds = IECore . RunTimeTyped . baseTypeIds ( n . typeId ( ) ) <EOL> self . failUnless ( GafferScene . SceneContextProcessor . staticTypeId ( ) in baseTypeIds ) <EOL> self . failUnless ( GafferScene . SceneProcessor . staticTypeId ( ) in baseTypeIds ) <EOL> self . failUnless ( GafferScene . SceneNode . staticTypeId ( ) in baseTypeIds ) <EOL> self . failUnless ( Gaffer . Node . staticTypeId ( ) in baseTypeIds ) <EOL> def testAffects ( self ) : <EOL> n = GafferScene . SceneTimeWarp ( ) <EOL> c = GafferTest . CapturingSlot ( n . plugDirtiedSignal ( ) ) <EOL> n [ "<STR_LIT>" ] . setValue ( <NUM_LIT:2> ) <EOL> found = False <EOL> for cc in c : <EOL> if cc [ <NUM_LIT:0> ] . isSame ( n [ "<STR_LIT>" ] ) : <EOL> found = True <EOL> self . failUnless ( found ) <EOL> del c [ : ] <EOL> n [ "<STR_LIT>" ] . setValue ( <NUM_LIT:2> ) <EOL> found = False <EOL> for cc in c : <EOL> if cc [ <NUM_LIT:0> ] . isSame ( n [ "<STR_LIT>" ] ) : <EOL> found = True <EOL> self . failUnless ( found ) <EOL> def testNoExtraInputs ( self ) : <EOL> p = GafferScene . Plane ( ) <EOL> n = GafferScene . SceneTimeWarp ( ) <EOL> n [ "<STR_LIT>" ] . setInput ( p [ "<STR_LIT>" ] ) <EOL> self . assertTrue ( "<STR_LIT>" not in n ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> import Gaffer <EOL> import GafferScene <EOL> Gaffer . Metadata . registerNode ( <EOL> GafferScene . Cube , <EOL> "<STR_LIT:description>" , <EOL> """<STR_LIT>""" , <EOL> plugs = { <EOL> "<STR_LIT>" : [ <EOL> "<STR_LIT:description>" , <EOL> """<STR_LIT>""" , <EOL> ] , <EOL> } <EOL> ) </s>
<s> import Gaffer <EOL> import GafferScene <EOL> import GafferUI <EOL> Gaffer . Metadata . registerNode ( <EOL> GafferScene . ObjectSource , <EOL> "<STR_LIT:description>" , <EOL> """<STR_LIT>""" , <EOL> plugs = { <EOL> "<STR_LIT:name>" : [ <EOL> "<STR_LIT:description>" , <EOL> """<STR_LIT>""" , <EOL> ] , <EOL> "<STR_LIT>" : [ <EOL> "<STR_LIT:description>" , <EOL> """<STR_LIT>""" , <EOL> "<STR_LIT>" , "<STR_LIT>" , <EOL> ] , <EOL> "<STR_LIT>" : [ <EOL> "<STR_LIT:description>" , <EOL> """<STR_LIT>""" , <EOL> ] , <EOL> } <EOL> ) </s>
<s> import functools <EOL> import IECore <EOL> import Gaffer <EOL> import GafferUI <EOL> import GafferScene <EOL> import GafferSceneUI <EOL> Gaffer . Metadata . registerNode ( <EOL> GafferSceneUI . SceneView , <EOL> plugs = { <EOL> "<STR_LIT>" : [ <EOL> "<STR_LIT>" , <NUM_LIT:2> , <EOL> "<STR_LIT>" , True , <EOL> "<STR_LIT>" , "<STR_LIT>" , <EOL> ] , <EOL> "<STR_LIT>" : [ <EOL> "<STR_LIT>" , "<STR_LIT>" , <EOL> "<STR_LIT>" , True , <EOL> ] , <EOL> "<STR_LIT>" : [ <EOL> "<STR_LIT>" , "<STR_LIT>" , <EOL> "<STR_LIT>" , True , <EOL> "<STR_LIT>" , "<STR_LIT>" , <EOL> ] , <EOL> "<STR_LIT>" : [ <EOL> "<STR_LIT:description>" , <EOL> """<STR_LIT>""" , <EOL> ] , <EOL> "<STR_LIT>" : [ <EOL> "<STR_LIT:description>" , <EOL> """<STR_LIT>""" , <EOL> ] , <EOL> "<STR_LIT>" : [ <EOL> "<STR_LIT>" , "<STR_LIT>" , <EOL> ] , <EOL> "<STR_LIT>" : [ <EOL> "<STR_LIT>" , "<STR_LIT>" , <EOL> ] , <EOL> } <EOL> ) <EOL> class _ShadingModePlugValueWidget ( GafferUI . PlugValueWidget ) : <EOL> def __init__ ( self , plug , parenting = None ) : <EOL> menuButton = GafferUI . MenuButton ( <EOL> image = "<STR_LIT>" , <EOL> menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __menuDefinition ) ) , <EOL> hasFrame = False , <EOL> ) <EOL> GafferUI . PlugValueWidget . __init__ ( self , menuButton , plug , parenting = parenting ) <EOL> def hasLabel ( self ) : <EOL> return True <EOL> def _updateFromPlug ( self ) : <EOL> pass <EOL> def __menuDefinition ( self ) : <EOL> m = IECore . MenuDefinition ( ) <EOL> currentName = self . getPlug ( ) . getValue ( ) <EOL> for name in [ "<STR_LIT>" ] + GafferSceneUI . SceneView . registeredShadingModes ( ) : <EOL> m . append ( <EOL> "<STR_LIT:/>" + name if name else "<STR_LIT>" , <EOL> { <EOL> "<STR_LIT>" : name == currentName , <EOL> "<STR_LIT>" : functools . partial ( Gaffer . WeakMethod ( self . __setValue ) , name if name != currentName else "<STR_LIT>" ) , <EOL> } <EOL> ) <EOL> if not name : <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : True } ) <EOL> return m <EOL> def __setValue ( self , value , * unused ) : <EOL> self . getPlug ( ) . setValue ( value ) <EOL> class _ExpansionPlugValueWidget ( GafferUI . PlugValueWidget ) : <EOL> def __init__ ( self , plug , parenting = None ) : <EOL> menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __menuDefinition ) ) <EOL> menuButton = GafferUI . MenuButton ( menu = menu , image = "<STR_LIT>" , hasFrame = False ) <EOL> GafferUI . PlugValueWidget . __init__ ( self , menuButton , plug , parenting = parenting ) <EOL> def hasLabel ( self ) : <EOL> return True <EOL> def _updateFromPlug ( self ) : <EOL> pass <EOL> def __menuDefinition ( self ) : <EOL> expandAll = bool ( self . getPlug ( ) . getValue ( ) ) <EOL> m = IECore . MenuDefinition ( ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : self . getPlug ( ) . node ( ) . expandSelection , "<STR_LIT>" : not expandAll , "<STR_LIT>" : "<STR_LIT>" } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : IECore . curry ( self . getPlug ( ) . node ( ) . expandSelection , depth = <NUM_LIT> ) , "<STR_LIT>" : not expandAll , "<STR_LIT>" : "<STR_LIT>" } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : self . getPlug ( ) . node ( ) . collapseSelection , "<STR_LIT>" : not expandAll , "<STR_LIT>" : "<STR_LIT>" } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : True } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : expandAll , "<STR_LIT>" : Gaffer . WeakMethod ( self . __toggleMinimumExpansionDepth ) } ) <EOL> return m <EOL> def __toggleMinimumExpansionDepth ( self , * unused ) : <EOL> self . getPlug ( ) . setValue ( <NUM_LIT:0> if self . getPlug ( ) . getValue ( ) else <NUM_LIT> ) <EOL> class _LookThroughPlugValueWidget ( GafferUI . PlugValueWidget ) : <EOL> def __init__ ( self , plug , parenting = None ) : <EOL> row = GafferUI . ListContainer ( GafferUI . ListContainer . Orientation . Horizontal ) <EOL> GafferUI . PlugValueWidget . __init__ ( self , row , plug , parenting = parenting ) <EOL> with row : <EOL> self . __enabledWidget = GafferUI . BoolPlugValueWidget ( plug [ "<STR_LIT>" ] , displayMode = GafferUI . BoolWidget . DisplayMode . Switch ) <EOL> self . __cameraWidget = GafferSceneUI . ScenePathPlugValueWidget ( <EOL> plug [ "<STR_LIT>" ] , <EOL> path = GafferScene . ScenePath ( <EOL> plug . node ( ) [ "<STR_LIT>" ] , <EOL> plug . node ( ) . getContext ( ) , <EOL> "<STR_LIT:/>" , <EOL> filter = GafferScene . ScenePath . createStandardFilter ( [ "<STR_LIT>" ] , "<STR_LIT>" ) <EOL> ) , <EOL> ) <EOL> self . __cameraWidget . pathWidget ( ) . setFixedCharacterWidth ( <NUM_LIT> ) <EOL> if hasattr ( self . __cameraWidget . pathWidget ( ) . _qtWidget ( ) , "<STR_LIT>" ) : <EOL> self . __cameraWidget . pathWidget ( ) . _qtWidget ( ) . setPlaceholderText ( "<STR_LIT>" ) <EOL> self . _updateFromPlug ( ) <EOL> def _updateFromPlug ( self ) : <EOL> with self . getContext ( ) : <EOL> self . __cameraWidget . setEnabled ( self . getPlug ( ) [ "<STR_LIT>" ] . getValue ( ) ) <EOL> class _GridPlugValueWidget ( GafferUI . PlugValueWidget ) : <EOL> def __init__ ( self , plug , parenting = None ) : <EOL> menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __menuDefinition ) ) <EOL> menuButton = GafferUI . MenuButton ( menu = menu , image = "<STR_LIT>" , hasFrame = False ) <EOL> GafferUI . PlugValueWidget . __init__ ( self , menuButton , plug , parenting = parenting ) <EOL> def hasLabel ( self ) : <EOL> return True <EOL> def _updateFromPlug ( self ) : <EOL> pass <EOL> def __menuDefinition ( self ) : <EOL> m = IECore . MenuDefinition ( ) <EOL> m . append ( <EOL> "<STR_LIT>" , <EOL> { <EOL> "<STR_LIT>" : self . getPlug ( ) [ "<STR_LIT>" ] . getValue ( ) , <EOL> "<STR_LIT>" : self . getPlug ( ) [ "<STR_LIT>" ] . setValue , <EOL> } <EOL> ) <EOL> m . append ( <EOL> "<STR_LIT>" , <EOL> { <EOL> "<STR_LIT>" : self . getPlug ( ) . node ( ) [ "<STR_LIT>" ] [ "<STR_LIT>" ] . getValue ( ) , <EOL> "<STR_LIT>" : self . getPlug ( ) . node ( ) [ "<STR_LIT>" ] [ "<STR_LIT>" ] . setValue , <EOL> } <EOL> ) <EOL> return m </s>
<s> import IECore <EOL> import Gaffer <EOL> class AddNode ( Gaffer . ComputeNode ) : <EOL> def __init__ ( self , name = "<STR_LIT>" ) : <EOL> Gaffer . ComputeNode . __init__ ( self , name ) <EOL> p1 = Gaffer . IntPlug ( "<STR_LIT>" , Gaffer . Plug . Direction . In ) <EOL> p2 = Gaffer . IntPlug ( "<STR_LIT>" , Gaffer . Plug . Direction . In ) <EOL> self . addChild ( Gaffer . BoolPlug ( "<STR_LIT>" , defaultValue = True ) ) <EOL> self . addChild ( p1 ) <EOL> self . addChild ( p2 ) <EOL> p3 = Gaffer . IntPlug ( "<STR_LIT>" , Gaffer . Plug . Direction . Out ) <EOL> self . addChild ( p3 ) <EOL> self . numHashCalls = <NUM_LIT:0> <EOL> self . numComputeCalls = <NUM_LIT:0> <EOL> def enabledPlug ( self ) : <EOL> return self [ "<STR_LIT>" ] <EOL> def correspondingInput ( self , output ) : <EOL> if output . isSame ( self [ "<STR_LIT>" ] ) : <EOL> return self [ "<STR_LIT>" ] <EOL> return Gaffer . ComputeNode . correspondingInput ( self , output ) <EOL> def affects ( self , input ) : <EOL> outputs = Gaffer . ComputeNode . affects ( self , input ) <EOL> if input . getName ( ) in ( "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) : <EOL> outputs . append ( self . getChild ( "<STR_LIT>" ) ) <EOL> return outputs <EOL> def hash ( self , output , context , h ) : <EOL> assert ( output . isSame ( self . getChild ( "<STR_LIT>" ) ) or plug . getFlags ( ) & plug . Flags . Dynamic ) <EOL> self . getChild ( "<STR_LIT>" ) . hash ( h ) <EOL> self . getChild ( "<STR_LIT>" ) . hash ( h ) <EOL> self . getChild ( "<STR_LIT>" ) . hash ( h ) <EOL> self . numHashCalls += <NUM_LIT:1> <EOL> def compute ( self , plug , context ) : <EOL> assert ( plug . isSame ( self . getChild ( "<STR_LIT>" ) ) or plug . getFlags ( ) & plug . Flags . Dynamic ) <EOL> assert ( isinstance ( context , Gaffer . Context ) ) <EOL> assert ( plug . settable ( ) ) <EOL> assert ( not self [ "<STR_LIT>" ] . settable ( ) ) <EOL> assert ( not self [ "<STR_LIT>" ] . settable ( ) ) <EOL> if self [ "<STR_LIT>" ] . getValue ( ) : <EOL> plug . setValue ( self . getChild ( "<STR_LIT>" ) . getValue ( ) + self . getChild ( "<STR_LIT>" ) . getValue ( ) ) <EOL> else : <EOL> plug . setValue ( self . getChild ( "<STR_LIT>" ) . getValue ( ) ) <EOL> self . numComputeCalls += <NUM_LIT:1> <EOL> IECore . registerRunTimeTyped ( AddNode , typeName = "<STR_LIT>" ) </s>
<s> from __future__ import with_statement <EOL> import unittest <EOL> import time <EOL> import datetime <EOL> import pwd <EOL> import grp <EOL> import os <EOL> import IECore <EOL> import Gaffer <EOL> import GafferTest <EOL> class FileSystemPathTest ( GafferTest . TestCase ) : <EOL> def test ( self ) : <EOL> p = Gaffer . FileSystemPath ( __file__ ) <EOL> self . assert_ ( p . isValid ( ) ) <EOL> self . assert_ ( p . isLeaf ( ) ) <EOL> while len ( p ) : <EOL> del p [ - <NUM_LIT:1> ] <EOL> self . assert_ ( p . isValid ( ) ) <EOL> self . assert_ ( not p . isLeaf ( ) ) <EOL> def testIsLeaf ( self ) : <EOL> path = Gaffer . FileSystemPath ( "<STR_LIT>" ) <EOL> self . assert_ ( not path . isLeaf ( ) ) <EOL> def testConstructWithFilter ( self ) : <EOL> p = Gaffer . FileSystemPath ( __file__ ) <EOL> self . failUnless ( p . getFilter ( ) is None ) <EOL> f = Gaffer . FileNamePathFilter ( [ "<STR_LIT>" ] ) <EOL> p = Gaffer . FileSystemPath ( __file__ , filter = f ) <EOL> self . failUnless ( p . getFilter ( ) . isSame ( f ) ) <EOL> def testBrokenSymbolicLinks ( self ) : <EOL> os . symlink ( self . temporaryDirectory ( ) + "<STR_LIT>" , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> d = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) ) <EOL> c = d . children ( ) <EOL> self . assertEqual ( len ( c ) , <NUM_LIT:1> ) <EOL> l = c [ <NUM_LIT:0> ] <EOL> self . assertEqual ( str ( l ) , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> self . assertEqual ( l . isValid ( ) , True ) <EOL> info = l . info ( ) <EOL> self . failUnless ( info is not None ) <EOL> def testSymLinkInfo ( self ) : <EOL> with open ( self . temporaryDirectory ( ) + "<STR_LIT>" , "<STR_LIT:w>" ) as f : <EOL> f . write ( "<STR_LIT>" ) <EOL> os . symlink ( self . temporaryDirectory ( ) + "<STR_LIT>" , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> a = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> l = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> aInfo = a . info ( ) <EOL> self . assertEqual ( aInfo [ "<STR_LIT>" ] , l . info ( ) [ "<STR_LIT>" ] ) <EOL> os . remove ( str ( a ) ) <EOL> self . assertNotEqual ( aInfo [ "<STR_LIT>" ] , l . info ( ) [ "<STR_LIT>" ] ) <EOL> def testCopy ( self ) : <EOL> p = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) ) <EOL> p2 = p . copy ( ) <EOL> self . assertEqual ( p , p2 ) <EOL> self . assertEqual ( str ( p ) , str ( p2 ) ) <EOL> def testEmptyPath ( self ) : <EOL> p = Gaffer . FileSystemPath ( ) <EOL> self . assertEqual ( str ( p ) , "<STR_LIT>" ) <EOL> self . assertTrue ( p . isEmpty ( ) ) <EOL> self . assertFalse ( p . isValid ( ) ) <EOL> def testRelativePath ( self ) : <EOL> os . chdir ( self . temporaryDirectory ( ) ) <EOL> with open ( self . temporaryDirectory ( ) + "<STR_LIT>" , "<STR_LIT:w>" ) as f : <EOL> f . write ( "<STR_LIT>" ) <EOL> p = Gaffer . FileSystemPath ( "<STR_LIT:a>" ) <EOL> self . assertEqual ( str ( p ) , "<STR_LIT:a>" ) <EOL> self . assertFalse ( p . isEmpty ( ) ) <EOL> self . assertTrue ( p . isValid ( ) ) <EOL> p2 = Gaffer . FileSystemPath ( "<STR_LIT>" ) <EOL> self . assertEqual ( str ( p2 ) , "<STR_LIT>" ) <EOL> self . assertFalse ( p2 . isEmpty ( ) ) <EOL> self . assertFalse ( p2 . isValid ( ) ) <EOL> def testRelativePathChildren ( self ) : <EOL> os . chdir ( self . temporaryDirectory ( ) ) <EOL> os . mkdir ( "<STR_LIT>" ) <EOL> with open ( self . temporaryDirectory ( ) + "<STR_LIT>" , "<STR_LIT:w>" ) as f : <EOL> f . write ( "<STR_LIT>" ) <EOL> p = Gaffer . FileSystemPath ( "<STR_LIT>" ) <EOL> c = p . children ( ) <EOL> self . assertEqual ( len ( c ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( str ( c [ <NUM_LIT:0> ] ) , "<STR_LIT>" ) <EOL> self . assertTrue ( c [ <NUM_LIT:0> ] . isValid ( ) ) <EOL> def testChildrenOfFile ( self ) : <EOL> p = Gaffer . FileSystemPath ( __file__ ) <EOL> self . assertEqual ( p . children ( ) , [ ] ) <EOL> def testModificationTimes ( self ) : <EOL> p = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) ) <EOL> p . append ( "<STR_LIT:t>" ) <EOL> with open ( str ( p ) , "<STR_LIT:w>" ) as f : <EOL> f . write ( "<STR_LIT>" ) <EOL> mt = p . property ( "<STR_LIT>" ) <EOL> self . assertTrue ( isinstance ( mt , datetime . datetime ) ) <EOL> self . assertLess ( ( datetime . datetime . utcnow ( ) - mt ) . total_seconds ( ) , <NUM_LIT:2> ) <EOL> time . sleep ( <NUM_LIT:1> ) <EOL> with open ( str ( p ) , "<STR_LIT:w>" ) as f : <EOL> f . write ( "<STR_LIT>" ) <EOL> mt = p . property ( "<STR_LIT>" ) <EOL> self . assertTrue ( isinstance ( mt , datetime . datetime ) ) <EOL> self . assertLess ( ( datetime . datetime . utcnow ( ) - mt ) . total_seconds ( ) , <NUM_LIT:2> ) <EOL> def testOwner ( self ) : <EOL> p = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) ) <EOL> p . append ( "<STR_LIT:t>" ) <EOL> with open ( str ( p ) , "<STR_LIT:w>" ) as f : <EOL> f . write ( "<STR_LIT>" ) <EOL> o = p . property ( "<STR_LIT>" ) <EOL> self . assertTrue ( isinstance ( o , str ) ) <EOL> self . assertEqual ( o , pwd . getpwuid ( os . stat ( str ( p ) ) . st_uid ) . pw_name ) <EOL> def testGroup ( self ) : <EOL> p = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) ) <EOL> p . append ( "<STR_LIT:t>" ) <EOL> with open ( str ( p ) , "<STR_LIT:w>" ) as f : <EOL> f . write ( "<STR_LIT>" ) <EOL> g = p . property ( "<STR_LIT>" ) <EOL> self . assertTrue ( isinstance ( g , str ) ) <EOL> self . assertEqual ( g , grp . getgrgid ( os . stat ( str ( p ) ) . st_gid ) . gr_name ) <EOL> def testPropertyNames ( self ) : <EOL> p = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) ) <EOL> a = p . propertyNames ( ) <EOL> self . assertTrue ( isinstance ( a , list ) ) <EOL> self . assertTrue ( "<STR_LIT>" in a ) <EOL> self . assertTrue ( "<STR_LIT>" in a ) <EOL> self . assertTrue ( "<STR_LIT>" in a ) <EOL> self . assertTrue ( "<STR_LIT>" in a ) <EOL> self . assertTrue ( "<STR_LIT>" not in a ) <EOL> p = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) , includeSequences = True ) <EOL> self . assertTrue ( "<STR_LIT>" in p . propertyNames ( ) ) <EOL> def testSequences ( self ) : <EOL> os . mkdir ( self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> for n in [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] : <EOL> with open ( self . temporaryDirectory ( ) + "<STR_LIT:/>" + n , "<STR_LIT:w>" ) as f : <EOL> f . write ( "<STR_LIT>" ) <EOL> p = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) , includeSequences = True ) <EOL> self . assertTrue ( p . getIncludeSequences ( ) ) <EOL> c = p . children ( ) <EOL> self . assertEqual ( len ( c ) , <NUM_LIT:8> ) <EOL> s = sorted ( c , key = str ) <EOL> self . assertEqual ( str ( s [ <NUM_LIT:0> ] ) , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> self . assertEqual ( str ( s [ <NUM_LIT:1> ] ) , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> self . assertEqual ( str ( s [ <NUM_LIT:2> ] ) , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> self . assertEqual ( str ( s [ <NUM_LIT:3> ] ) , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> self . assertEqual ( str ( s [ <NUM_LIT:4> ] ) , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> self . assertEqual ( str ( s [ <NUM_LIT:5> ] ) , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> self . assertEqual ( str ( s [ <NUM_LIT:6> ] ) , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> self . assertEqual ( str ( s [ <NUM_LIT:7> ] ) , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> for x in s : <EOL> self . assertTrue ( x . isValid ( ) ) <EOL> if not os . path . isdir ( str ( x ) ) : <EOL> self . assertTrue ( x . isLeaf ( ) ) <EOL> self . assertEqual ( x . property ( "<STR_LIT>" ) , pwd . getpwuid ( os . stat ( str ( p ) ) . st_uid ) . pw_name ) <EOL> self . assertEqual ( x . property ( "<STR_LIT>" ) , grp . getgrgid ( os . stat ( str ( p ) ) . st_gid ) . gr_name ) <EOL> self . assertLess ( ( datetime . datetime . utcnow ( ) - x . property ( "<STR_LIT>" ) ) . total_seconds ( ) , <NUM_LIT:2> ) <EOL> if "<STR_LIT>" not in str ( x ) : <EOL> self . assertFalse ( x . isFileSequence ( ) ) <EOL> self . assertEqual ( x . fileSequence ( ) , None ) <EOL> self . assertEqual ( x . property ( "<STR_LIT>" ) , "<STR_LIT>" ) <EOL> if os . path . isdir ( str ( x ) ) : <EOL> self . assertEqual ( x . property ( "<STR_LIT>" ) , <NUM_LIT:0> ) <EOL> else : <EOL> self . assertEqual ( x . property ( "<STR_LIT>" ) , <NUM_LIT:4> ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . property ( "<STR_LIT>" ) , "<STR_LIT>" ) <EOL> self . assertTrue ( s [ <NUM_LIT:0> ] . isFileSequence ( ) ) <EOL> self . assertTrue ( isinstance ( s [ <NUM_LIT:0> ] . fileSequence ( ) , IECore . FileSequence ) ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . fileSequence ( ) , IECore . FileSequence ( str ( s [ <NUM_LIT:0> ] ) , IECore . frameListFromList ( [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:4> ] ) ) ) <EOL> self . assertEqual ( s [ <NUM_LIT:0> ] . property ( "<STR_LIT>" ) , <NUM_LIT:4> * <NUM_LIT:3> ) <EOL> self . assertEqual ( s [ <NUM_LIT:4> ] . property ( "<STR_LIT>" ) , "<STR_LIT:3>" ) <EOL> self . assertTrue ( s [ <NUM_LIT:4> ] . isFileSequence ( ) ) <EOL> self . assertTrue ( isinstance ( s [ <NUM_LIT:4> ] . fileSequence ( ) , IECore . FileSequence ) ) <EOL> self . assertEqual ( s [ <NUM_LIT:4> ] . fileSequence ( ) , IECore . FileSequence ( str ( s [ <NUM_LIT:4> ] ) , IECore . frameListFromList ( [ <NUM_LIT:3> ] ) ) ) <EOL> self . assertEqual ( s [ <NUM_LIT:4> ] . property ( "<STR_LIT>" ) , <NUM_LIT:4> ) <EOL> p2 = p . copy ( ) <EOL> self . assertTrue ( p2 . getIncludeSequences ( ) ) <EOL> self . assertEqual ( len ( p2 . children ( ) ) , <NUM_LIT:8> ) <EOL> p = Gaffer . FileSystemPath ( self . temporaryDirectory ( ) , includeSequences = False ) <EOL> self . assertFalse ( p . getIncludeSequences ( ) ) <EOL> c = p . children ( ) <EOL> self . assertEqual ( len ( c ) , <NUM_LIT:6> ) <EOL> s = sorted ( c , key = str ) <EOL> self . assertEqual ( str ( s [ <NUM_LIT:0> ] ) , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> self . assertEqual ( str ( s [ <NUM_LIT:1> ] ) , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> self . assertEqual ( str ( s [ <NUM_LIT:2> ] ) , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> self . assertEqual ( str ( s [ <NUM_LIT:3> ] ) , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> self . assertEqual ( str ( s [ <NUM_LIT:4> ] ) , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> self . assertEqual ( str ( s [ <NUM_LIT:5> ] ) , self . temporaryDirectory ( ) + "<STR_LIT>" ) <EOL> p . setIncludeSequences ( True ) <EOL> self . assertTrue ( p . getIncludeSequences ( ) ) <EOL> c = p . children ( ) <EOL> self . assertEqual ( len ( c ) , <NUM_LIT:8> ) <EOL> def setUp ( self ) : <EOL> GafferTest . TestCase . setUp ( self ) <EOL> self . __originalCWD = os . getcwd ( ) <EOL> def tearDown ( self ) : <EOL> GafferTest . TestCase . tearDown ( self ) <EOL> os . chdir ( self . __originalCWD ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> import unittest <EOL> import IECore <EOL> import Gaffer <EOL> import GafferTest <EOL> class SequencePathTest ( GafferTest . TestCase ) : <EOL> def __dictPath ( self ) : <EOL> dict = { } <EOL> dict [ "<STR_LIT>" ] = { } <EOL> for f in IECore . FileSequence ( "<STR_LIT>" ) . fileNames ( ) : <EOL> dict [ "<STR_LIT>" ] [ f ] = <NUM_LIT:1> <EOL> for f in IECore . FileSequence ( "<STR_LIT>" ) . fileNames ( ) : <EOL> dict [ "<STR_LIT>" ] [ f ] = <NUM_LIT:1> <EOL> return Gaffer . DictPath ( dict , "<STR_LIT:/>" ) <EOL> def test ( self ) : <EOL> path = Gaffer . SequencePath ( self . __dictPath ( ) ) <EOL> self . failUnless ( path . isValid ( ) ) <EOL> self . failUnless ( not path . isLeaf ( ) ) <EOL> path . append ( "<STR_LIT>" ) <EOL> self . failUnless ( path . isValid ( ) ) <EOL> self . failUnless ( not path . isLeaf ( ) ) <EOL> path [ <NUM_LIT:0> ] = "<STR_LIT>" <EOL> self . failIf ( path . isValid ( ) ) <EOL> self . failIf ( path . isLeaf ( ) ) <EOL> path [ : ] = [ "<STR_LIT>" ] <EOL> children = path . children ( ) <EOL> for child in children : <EOL> self . failUnless ( isinstance ( child , Gaffer . SequencePath ) ) <EOL> self . assertEqual ( len ( children ) , <NUM_LIT:2> ) <EOL> childrenStrings = [ str ( c ) for c in children ] <EOL> self . failUnless ( "<STR_LIT>" in childrenStrings ) <EOL> self . failUnless ( "<STR_LIT>" in childrenStrings ) <EOL> def testNonLeafChildren ( self ) : <EOL> path = Gaffer . SequencePath ( self . __dictPath ( ) ) <EOL> children = path . children ( ) <EOL> for child in children : <EOL> self . failUnless ( isinstance ( child , Gaffer . SequencePath ) ) <EOL> self . assertEqual ( len ( children ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( str ( children [ <NUM_LIT:0> ] ) , "<STR_LIT>" ) <EOL> def testCopy ( self ) : <EOL> path = Gaffer . SequencePath ( self . __dictPath ( ) ) <EOL> path . append ( "<STR_LIT>" ) <EOL> path2 = path . copy ( ) <EOL> self . failUnless ( isinstance ( path2 , Gaffer . SequencePath ) ) <EOL> self . assertEqual ( path [ : ] , path2 [ : ] ) <EOL> self . failUnless ( path . getFilter ( ) is path2 . getFilter ( ) ) <EOL> c = [ str ( p ) for p in path . children ( ) ] <EOL> c2 = [ str ( p ) for p in path2 . children ( ) ] <EOL> self . assertEqual ( c , c2 ) <EOL> def testInfo ( self ) : <EOL> dictPath = self . __dictPath ( ) <EOL> path = Gaffer . SequencePath ( dictPath ) <EOL> self . assertEqual ( dictPath . info ( ) , path . info ( ) ) <EOL> def testInfoOfInvalidPath ( self ) : <EOL> fp = Gaffer . FileSystemPath ( "<STR_LIT>" ) <EOL> self . assertEqual ( fp . isValid ( ) , False ) <EOL> self . assertEqual ( fp . info ( ) , None ) <EOL> sp = Gaffer . SequencePath ( fp ) <EOL> self . assertEqual ( sp . isValid ( ) , False ) <EOL> self . assertEqual ( sp . info ( ) , None ) <EOL> def testFilter ( self ) : <EOL> dictPath = self . __dictPath ( ) <EOL> path = Gaffer . SequencePath ( dictPath ) <EOL> def testIsEmpty ( self ) : <EOL> dictPath = self . __dictPath ( ) <EOL> path = Gaffer . SequencePath ( dictPath ) <EOL> path . setFromString ( "<STR_LIT>" ) <EOL> self . assertTrue ( path . isEmpty ( ) ) <EOL> path2 = path . copy ( ) <EOL> self . assertTrue ( path2 . isEmpty ( ) ) <EOL> def testProperties ( self ) : <EOL> dictPath = self . __dictPath ( ) <EOL> path = Gaffer . SequencePath ( dictPath ) <EOL> self . assertEqual ( dictPath . propertyNames ( ) , path . propertyNames ( ) ) <EOL> self . assertEqual ( dictPath . property ( "<STR_LIT>" ) , path . property ( "<STR_LIT>" ) ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> assert ( __name__ == "<STR_LIT:__main__>" ) </s>
<s> from __future__ import with_statement <EOL> import IECore <EOL> import Gaffer <EOL> import GafferUI <EOL> class CompoundDataPlugValueWidget ( GafferUI . PlugValueWidget ) : <EOL> def __init__ ( self , plug , parenting = None ) : <EOL> self . __column = GafferUI . ListContainer ( spacing = <NUM_LIT:6> ) <EOL> GafferUI . PlugValueWidget . __init__ ( self , self . __column , plug , parenting = parenting ) <EOL> with self . __column : <EOL> self . __layout = GafferUI . PlugLayout ( plug ) <EOL> with GafferUI . ListContainer ( GafferUI . ListContainer . Orientation . Horizontal ) as self . __editRow : <EOL> GafferUI . Spacer ( IECore . V2i ( GafferUI . PlugWidget . labelWidth ( ) , <NUM_LIT:1> ) ) <EOL> GafferUI . MenuButton ( <EOL> image = "<STR_LIT>" , <EOL> hasFrame = False , <EOL> menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __addMenuDefinition ) ) <EOL> ) <EOL> GafferUI . Spacer ( IECore . V2i ( <NUM_LIT:1> ) , IECore . V2i ( <NUM_LIT> , <NUM_LIT:1> ) , parenting = { "<STR_LIT>" : True } ) <EOL> self . _updateFromPlug ( ) <EOL> def hasLabel ( self ) : <EOL> return True <EOL> def setPlug ( self , plug ) : <EOL> GafferUI . PlugValueWidget . setPlug ( self , plug ) <EOL> self . __layout = GafferUI . PlugLayout ( plug ) <EOL> self . __column [ <NUM_LIT:0> ] = self . __layout <EOL> def setReadOnly ( self , readOnly ) : <EOL> if readOnly == self . getReadOnly ( ) : <EOL> return <EOL> GafferUI . PlugValueWidget . setReadOnly ( self , readOnly ) <EOL> self . __layout . setReadOnly ( readOnly ) <EOL> def childPlugValueWidget ( self , childPlug , lazy = True ) : <EOL> return self . __layout . plugValueWidget ( childPlug , lazy ) <EOL> def _updateFromPlug ( self ) : <EOL> editable = True <EOL> if self . getPlug ( ) is not None : <EOL> editable = Gaffer . Metadata . plugValue ( self . getPlug ( ) , "<STR_LIT>" ) <EOL> editable = editable if editable is not None else True <EOL> self . __editRow . setVisible ( editable ) <EOL> def __addMenuDefinition ( self ) : <EOL> result = IECore . MenuDefinition ( ) <EOL> result . append ( "<STR_LIT>" , { "<STR_LIT>" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , "<STR_LIT>" , IECore . BoolData ( False ) ) } ) <EOL> result . append ( "<STR_LIT>" , { "<STR_LIT>" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , "<STR_LIT>" , IECore . FloatData ( <NUM_LIT:0> ) ) } ) <EOL> result . append ( "<STR_LIT>" , { "<STR_LIT>" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , "<STR_LIT>" , IECore . IntData ( <NUM_LIT:0> ) ) } ) <EOL> result . append ( "<STR_LIT>" , { "<STR_LIT>" : True } ) <EOL> result . append ( "<STR_LIT>" , { "<STR_LIT>" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , "<STR_LIT>" , IECore . StringData ( "<STR_LIT>" ) ) } ) <EOL> result . append ( "<STR_LIT>" , { "<STR_LIT>" : True } ) <EOL> result . append ( "<STR_LIT>" , { "<STR_LIT>" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , "<STR_LIT>" , IECore . V2iData ( IECore . V2i ( <NUM_LIT:0> ) ) ) } ) <EOL> result . append ( "<STR_LIT>" , { "<STR_LIT>" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , "<STR_LIT>" , IECore . V3iData ( IECore . V3i ( <NUM_LIT:0> ) ) ) } ) <EOL> result . append ( "<STR_LIT>" , { "<STR_LIT>" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , "<STR_LIT>" , IECore . V2fData ( IECore . V2f ( <NUM_LIT:0> ) ) ) } ) <EOL> result . append ( "<STR_LIT>" , { "<STR_LIT>" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , "<STR_LIT>" , IECore . V3fData ( IECore . V3f ( <NUM_LIT:0> ) ) ) } ) <EOL> result . append ( "<STR_LIT>" , { "<STR_LIT>" : True } ) <EOL> result . append ( "<STR_LIT>" , { "<STR_LIT>" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , "<STR_LIT>" , IECore . Color3fData ( IECore . Color3f ( <NUM_LIT:0> ) ) ) } ) <EOL> result . append ( "<STR_LIT>" , { "<STR_LIT>" : IECore . curry ( Gaffer . WeakMethod ( self . __addItem ) , "<STR_LIT>" , IECore . Color4fData ( IECore . Color4f ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1> ) ) ) } ) <EOL> return result <EOL> def __addItem ( self , name , value ) : <EOL> with Gaffer . UndoContext ( self . getPlug ( ) . ancestor ( Gaffer . ScriptNode . staticTypeId ( ) ) ) : <EOL> self . getPlug ( ) . addOptionalMember ( name , value , enabled = True ) <EOL> class _MemberPlugValueWidget ( GafferUI . PlugValueWidget ) : <EOL> def __init__ ( self , childPlug ) : <EOL> self . __row = GafferUI . ListContainer ( GafferUI . ListContainer . Orientation . Horizontal , spacing = <NUM_LIT:4> ) <EOL> GafferUI . PlugValueWidget . __init__ ( self , self . __row , childPlug ) <EOL> if not childPlug . getFlags ( Gaffer . Plug . Flags . Dynamic ) : <EOL> nameWidget = GafferUI . LabelPlugValueWidget ( <EOL> childPlug , <EOL> horizontalAlignment = GafferUI . Label . HorizontalAlignment . Right , <EOL> verticalAlignment = GafferUI . Label . VerticalAlignment . Center , <EOL> ) <EOL> nameWidget . label ( ) . _qtWidget ( ) . setFixedWidth ( GafferUI . PlugWidget . labelWidth ( ) ) <EOL> nameWidget . label ( ) . _qtWidget ( ) . setFixedHeight ( <NUM_LIT:20> ) <EOL> else : <EOL> nameWidget = GafferUI . StringPlugValueWidget ( childPlug [ "<STR_LIT:name>" ] ) <EOL> nameWidget . textWidget ( ) . _qtWidget ( ) . setFixedWidth ( GafferUI . PlugWidget . labelWidth ( ) ) <EOL> self . __row . append ( nameWidget , <EOL> verticalAlignment = GafferUI . Label . VerticalAlignment . Top <EOL> ) <EOL> if "<STR_LIT>" in childPlug : <EOL> self . __row . append ( <EOL> GafferUI . BoolPlugValueWidget ( <EOL> childPlug [ "<STR_LIT>" ] , <EOL> displayMode = GafferUI . BoolWidget . DisplayMode . Switch <EOL> ) , <EOL> verticalAlignment = GafferUI . Label . VerticalAlignment . Top , <EOL> ) <EOL> self . __row . append ( GafferUI . PlugValueWidget . create ( childPlug [ "<STR_LIT:value>" ] ) , expand = True ) <EOL> self . _updateFromPlug ( ) <EOL> def setPlug ( self , plug ) : <EOL> GafferUI . PlugValueWidget . setPlug ( self , plug ) <EOL> if isinstance ( self . __row [ <NUM_LIT:0> ] , GafferUI . LabelPlugValueWidget ) : <EOL> self . __row [ <NUM_LIT:0> ] . setPlug ( plug ) <EOL> else : <EOL> self . __row [ <NUM_LIT:0> ] . setPlug ( plug [ "<STR_LIT:name>" ] ) <EOL> if "<STR_LIT>" in plug : <EOL> self . __row [ <NUM_LIT:1> ] . setPlug ( plug [ "<STR_LIT>" ] ) <EOL> self . __row [ - <NUM_LIT:1> ] . setPlug ( plug [ "<STR_LIT:value>" ] ) <EOL> def hasLabel ( self ) : <EOL> return True <EOL> def childPlugValueWidget ( self , childPlug , lazy = True ) : <EOL> for w in self . __row : <EOL> if w . getPlug ( ) . isSame ( childPlug ) : <EOL> return w <EOL> return None <EOL> def setReadOnly ( self , readOnly ) : <EOL> if readOnly == self . getReadOnly ( ) : <EOL> return <EOL> GafferUI . PlugValueWidget . setReadOnly ( self , readOnly ) <EOL> for w in self . __row : <EOL> w . setReadOnly ( readOnly ) <EOL> def _updateFromPlug ( self ) : <EOL> if "<STR_LIT>" in self . getPlug ( ) : <EOL> with self . getContext ( ) : <EOL> enabled = self . getPlug ( ) [ "<STR_LIT>" ] . getValue ( ) <EOL> if isinstance ( self . __row [ <NUM_LIT:0> ] , GafferUI . StringPlugValueWidget ) : <EOL> self . __row [ <NUM_LIT:0> ] . setEnabled ( enabled ) <EOL> self . __row [ - <NUM_LIT:1> ] . setEnabled ( enabled ) <EOL> GafferUI . PlugValueWidget . registerType ( Gaffer . CompoundDataPlug , CompoundDataPlugValueWidget ) <EOL> GafferUI . PlugValueWidget . registerType ( Gaffer . CompoundDataPlug . MemberPlug , _MemberPlugValueWidget ) <EOL> def __deletePlug ( plug ) : <EOL> with Gaffer . UndoContext ( plug . ancestor ( Gaffer . ScriptNode ) ) : <EOL> plug . parent ( ) . removeChild ( plug ) <EOL> def __plugPopupMenu ( menuDefinition , plugValueWidget ) : <EOL> plug = plugValueWidget . getPlug ( ) <EOL> memberPlug = plug if isinstance ( plug , Gaffer . CompoundDataPlug . MemberPlug ) else None <EOL> memberPlug = memberPlug if memberPlug is not None else plug . ancestor ( Gaffer . CompoundDataPlug . MemberPlug ) <EOL> if memberPlug is None : <EOL> return <EOL> if not memberPlug . getFlags ( Gaffer . Plug . Flags . Dynamic ) : <EOL> return <EOL> menuDefinition . append ( "<STR_LIT>" , { "<STR_LIT>" : True } ) <EOL> menuDefinition . append ( "<STR_LIT>" , { "<STR_LIT>" : IECore . curry ( __deletePlug , memberPlug ) , "<STR_LIT>" : not plugValueWidget . getReadOnly ( ) } ) <EOL> __plugPopupMenuConnection = GafferUI . PlugValueWidget . popupMenuSignal ( ) . connect ( __plugPopupMenu ) </s>
<s> import Gaffer <EOL> import GafferUI <EOL> class FileSystemPathPlugValueWidget ( GafferUI . PathPlugValueWidget ) : <EOL> def __init__ ( self , plug , path = None , parenting = None ) : <EOL> GafferUI . PathPlugValueWidget . __init__ ( <EOL> self , <EOL> plug , <EOL> path , <EOL> parenting = parenting <EOL> ) <EOL> self . _updateFromPlug ( ) <EOL> self . __plugMetadataChangedConnection = Gaffer . Metadata . plugValueChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __plugMetadataChanged ) ) <EOL> def getToolTip ( self ) : <EOL> result = GafferUI . PathPlugValueWidget . getToolTip ( self ) <EOL> extensions = self . __extensions ( ) <EOL> if extensions : <EOL> result += "<STR_LIT>" + "<STR_LIT:U+002CU+0020>" . join ( extensions ) <EOL> return result <EOL> def _pathChooserDialogue ( self ) : <EOL> dialogue = GafferUI . PathPlugValueWidget . _pathChooserDialogue ( self ) <EOL> if Gaffer . Metadata . plugValue ( self . getPlug ( ) , "<STR_LIT>" ) : <EOL> columns = dialogue . pathChooserWidget ( ) . pathListingWidget ( ) . getColumns ( ) <EOL> columns . append ( GafferUI . PathListingWidget . StandardColumn ( "<STR_LIT>" , "<STR_LIT>" ) ) <EOL> dialogue . pathChooserWidget ( ) . pathListingWidget ( ) . setColumns ( columns ) <EOL> return dialogue <EOL> def _updateFromPlug ( self ) : <EOL> GafferUI . PathPlugValueWidget . _updateFromPlug ( self ) <EOL> includeSequences = Gaffer . Metadata . plugValue ( self . getPlug ( ) , "<STR_LIT>" ) or False <EOL> self . path ( ) . setFilter ( <EOL> Gaffer . FileSystemPath . createStandardFilter ( <EOL> self . __extensions ( ) , <EOL> Gaffer . Metadata . plugValue ( self . getPlug ( ) , "<STR_LIT>" ) or "<STR_LIT>" , <EOL> includeSequenceFilter = includeSequences , <EOL> ) <EOL> ) <EOL> self . path ( ) . setIncludeSequences ( includeSequences ) <EOL> def _setPlugFromPath ( self , path ) : <EOL> if Gaffer . Metadata . plugValue ( self . getPlug ( ) , "<STR_LIT>" ) : <EOL> sequence = path . fileSequence ( ) <EOL> if sequence : <EOL> self . getPlug ( ) . setValue ( str ( sequence ) ) <EOL> return <EOL> GafferUI . PathPlugValueWidget . _setPlugFromPath ( self , path ) <EOL> def __plugMetadataChanged ( self , nodeTypeId , plugPath , key , plug ) : <EOL> if self . getPlug ( ) is None : <EOL> return <EOL> if plug is not None and not plug . isSame ( self . getPlug ( ) ) : <EOL> return <EOL> if not self . getPlug ( ) . node ( ) . isInstanceOf ( nodeTypeId ) : <EOL> return <EOL> if key . startswith ( "<STR_LIT>" ) : <EOL> self . _updateFromPlug ( ) <EOL> def __extensions ( self ) : <EOL> if self . getPlug ( ) is None : <EOL> return [ ] <EOL> extensions = Gaffer . Metadata . plugValue ( self . getPlug ( ) , "<STR_LIT>" ) or [ ] <EOL> if isinstance ( extensions , str ) : <EOL> extensions = extensions . split ( ) <EOL> else : <EOL> extensions = list ( extensions ) <EOL> return extensions </s>
<s> import IECore <EOL> import Gaffer <EOL> import GafferUI <EOL> class NameLabel ( GafferUI . Label ) : <EOL> def __init__ ( self , graphComponent , horizontalAlignment = GafferUI . Label . HorizontalAlignment . Left , verticalAlignment = GafferUI . Label . VerticalAlignment . Center , numComponents = <NUM_LIT:1> , formatter = None , parenting = None ) : <EOL> GafferUI . Label . __init__ ( self , "<STR_LIT>" , horizontalAlignment , verticalAlignment , parenting = parenting ) <EOL> self . __formatter = formatter if formatter is not None else self . defaultFormatter <EOL> self . __numComponents = numComponents <EOL> self . __connections = [ ] <EOL> self . __graphComponent = False <EOL> self . setGraphComponent ( graphComponent ) <EOL> self . __buttonPressConnection = self . buttonPressSignal ( ) . connect ( Gaffer . WeakMethod ( self . __buttonPress ) ) <EOL> self . __dragBeginConnection = self . dragBeginSignal ( ) . connect ( Gaffer . WeakMethod ( self . __dragBegin ) ) <EOL> self . __dragEndConnection = self . dragEndSignal ( ) . connect ( Gaffer . WeakMethod ( self . __dragEnd ) ) <EOL> def setText ( self , text ) : <EOL> GafferUI . Label . setText ( self , text ) <EOL> self . __connections = [ ] <EOL> def setGraphComponent ( self , graphComponent ) : <EOL> if graphComponent is not None and self . __graphComponent is not False : <EOL> if graphComponent . isSame ( self . __graphComponent ) : <EOL> return <EOL> elif self . __graphComponent is None : <EOL> return <EOL> self . __graphComponent = graphComponent <EOL> self . __setupConnections ( ) <EOL> self . __setText ( ) <EOL> def getGraphComponent ( self ) : <EOL> return self . __graphComponent <EOL> def setNumComponents ( self , numComponents ) : <EOL> assert ( numComponents > <NUM_LIT:0> ) <EOL> if numComponents == self . __numComponents : <EOL> return <EOL> self . __numComponents = numComponents <EOL> self . __setupConnections ( ) <EOL> self . __setText ( ) <EOL> def getNumComponents ( self ) : <EOL> return self . __numComponents <EOL> def setFormatter ( self , formatter ) : <EOL> self . __formatter = formatter <EOL> self . __setText ( ) <EOL> def getFormatter ( self ) : <EOL> return self . __formatter <EOL> @ staticmethod <EOL> def defaultFormatter ( graphComponents ) : <EOL> return "<STR_LIT:.>" . join ( IECore . CamelCase . toSpaced ( g . getName ( ) ) for g in graphComponents ) <EOL> def __setupConnections ( self , reuseUntil = None ) : <EOL> if self . __graphComponent is None : <EOL> self . __connections = [ ] <EOL> return <EOL> updatedConnections = [ ] <EOL> n = <NUM_LIT:0> <EOL> g = self . __graphComponent <EOL> reuse = reuseUntil is not None <EOL> while g is not None and n < self . __numComponents : <EOL> if reuse : <EOL> updatedConnections . extend ( self . __connections [ n * <NUM_LIT:2> : n * <NUM_LIT:2> + <NUM_LIT:2> ] ) <EOL> else : <EOL> updatedConnections . append ( g . nameChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __setText ) ) ) <EOL> if n < self . __numComponents - <NUM_LIT:1> : <EOL> updatedConnections . append ( g . parentChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __parentChanged ) ) ) <EOL> if g . isSame ( reuseUntil ) : <EOL> reuse = False <EOL> g = g . parent ( ) <EOL> n += <NUM_LIT:1> <EOL> self . __connections = updatedConnections <EOL> def __parentChanged ( self , child , oldParent ) : <EOL> self . __setText ( ) <EOL> self . __setupConnections ( reuseUntil = child ) <EOL> def __setText ( self , * unwantedArgs ) : <EOL> graphComponents = [ ] <EOL> n = <NUM_LIT:0> <EOL> g = self . __graphComponent <EOL> while g is not None and n < self . __numComponents : <EOL> graphComponents . append ( g ) <EOL> g = g . parent ( ) <EOL> n += <NUM_LIT:1> <EOL> graphComponents . reverse ( ) <EOL> GafferUI . Label . setText ( self , self . __formatter ( graphComponents ) ) <EOL> def __buttonPress ( self , widget , event ) : <EOL> return self . getGraphComponent ( ) is not None and event . buttons & ( event . Buttons . Left | event . Buttons . Middle ) <EOL> def __dragBegin ( self , widget , event ) : <EOL> if event . buttons & ( event . Buttons . Left | event . Buttons . Middle ) : <EOL> GafferUI . Pointer . setCurrent ( "<STR_LIT>" ) <EOL> return self . getGraphComponent ( ) <EOL> return None <EOL> def __dragEnd ( self , widget , event ) : <EOL> GafferUI . Pointer . setCurrent ( None ) </s>
<s> import functools <EOL> import IECore <EOL> import Gaffer <EOL> import GafferUI <EOL> class PresetsPlugValueWidget ( GafferUI . PlugValueWidget ) : <EOL> def __init__ ( self , plug , parenting = None ) : <EOL> self . __menuButton = GafferUI . MenuButton ( "<STR_LIT>" , menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __menuDefinition ) ) ) <EOL> GafferUI . PlugValueWidget . __init__ ( self , self . __menuButton , plug , parenting = parenting ) <EOL> self . __plugMetadataChangedConnection = Gaffer . Metadata . plugValueChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __plugMetadataChanged ) ) <EOL> self . _addPopupMenu ( self . __menuButton ) <EOL> self . _updateFromPlug ( ) <EOL> def _updateFromPlug ( self ) : <EOL> self . __menuButton . setEnabled ( self . _editable ( ) ) <EOL> text = "<STR_LIT>" <EOL> if self . getPlug ( ) is not None : <EOL> with self . getContext ( ) : <EOL> text = Gaffer . NodeAlgo . currentPreset ( self . getPlug ( ) ) or "<STR_LIT>" <EOL> self . __menuButton . setText ( text ) <EOL> def __menuDefinition ( self ) : <EOL> result = IECore . MenuDefinition ( ) <EOL> if self . getPlug ( ) is None : <EOL> return result <EOL> currentPreset = Gaffer . NodeAlgo . currentPreset ( self . getPlug ( ) ) <EOL> for n in Gaffer . NodeAlgo . presets ( self . getPlug ( ) ) : <EOL> result . append ( <EOL> "<STR_LIT:/>" + n , <EOL> { <EOL> "<STR_LIT>" : functools . partial ( Gaffer . WeakMethod ( self . __applyPreset ) , preset = n ) , <EOL> "<STR_LIT>" : n == currentPreset , <EOL> } <EOL> ) <EOL> return result <EOL> def __applyPreset ( self , unused , preset ) : <EOL> with Gaffer . UndoContext ( self . getPlug ( ) . ancestor ( Gaffer . ScriptNode ) ) : <EOL> Gaffer . NodeAlgo . applyPreset ( self . getPlug ( ) , preset ) <EOL> def __plugMetadataChanged ( self , nodeTypeId , plugPath , key , plug ) : <EOL> if self . getPlug ( ) is None : <EOL> return <EOL> if plug is not None and not plug . isSame ( self . getPlug ( ) ) : <EOL> return <EOL> if not self . getPlug ( ) . node ( ) . isInstanceOf ( nodeTypeId ) : <EOL> return <EOL> if key . startswith ( "<STR_LIT>" ) : <EOL> self . _updateFromPlug ( ) </s>
<s> import weakref <EOL> import functools <EOL> import types <EOL> import re <EOL> import collections <EOL> import IECore <EOL> import Gaffer <EOL> import GafferUI <EOL> class UIEditor ( GafferUI . NodeSetEditor ) : <EOL> def __init__ ( self , scriptNode , parenting = None ) : <EOL> self . __frame = GafferUI . Frame ( borderWidth = <NUM_LIT:4> , borderStyle = GafferUI . Frame . BorderStyle . None ) <EOL> GafferUI . NodeSetEditor . __init__ ( self , self . __frame , scriptNode , parenting = parenting ) <EOL> self . __nodeMetadataWidgets = [ ] <EOL> self . __plugMetadataWidgets = [ ] <EOL> with self . __frame : <EOL> self . __tabbedContainer = GafferUI . TabbedContainer ( ) <EOL> with self . __tabbedContainer : <EOL> with GafferUI . ListContainer ( spacing = <NUM_LIT:4> , borderWidth = <NUM_LIT:8> , parenting = { "<STR_LIT:label>" : "<STR_LIT>" } ) as self . __nodeTab : <EOL> with _Row ( ) : <EOL> _Label ( "<STR_LIT:Name>" ) <EOL> self . __nodeNameWidget = GafferUI . NameWidget ( None ) <EOL> with _Row ( ) : <EOL> _Label ( "<STR_LIT>" , parenting = { "<STR_LIT>" : GafferUI . ListContainer . VerticalAlignment . Top } ) <EOL> self . __nodeMetadataWidgets . append ( <EOL> _MultiLineStringMetadataWidget ( key = "<STR_LIT:description>" ) <EOL> ) <EOL> with _Row ( ) : <EOL> _Label ( "<STR_LIT>" ) <EOL> self . __nodeMetadataWidgets . append ( <EOL> _ColorSwatchMetadataWidget ( key = "<STR_LIT>" ) <EOL> ) <EOL> with GafferUI . SplitContainer ( orientation = GafferUI . SplitContainer . Orientation . Horizontal , borderWidth = <NUM_LIT:8> , parenting = { "<STR_LIT:label>" : "<STR_LIT>" } ) as self . __plugTab : <EOL> self . __plugListing = _PlugListing ( ) <EOL> self . __plugListingSelectionChangedConnection = self . __plugListing . selectionChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __plugListingSelectionChanged ) ) <EOL> with GafferUI . TabbedContainer ( ) as self . __plugAndSectionEditorsContainer : <EOL> self . __plugEditor = _PlugEditor ( ) <EOL> self . __sectionEditor = _SectionEditor ( ) <EOL> self . __sectionEditorNameChangedConnection = self . __sectionEditor . nameChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __sectionEditorNameChanged ) ) <EOL> self . __plugAndSectionEditorsContainer . setTabsVisible ( False ) <EOL> self . __plugTab . setSizes ( [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> self . __node = None <EOL> self . __selectedPlug = None <EOL> self . __updateFromSetInternal ( lazy = False ) <EOL> def setSelection ( self , selection ) : <EOL> self . __plugListing . setSelection ( selection ) <EOL> def getSelection ( self ) : <EOL> return self . __plugListing . getSelection ( ) <EOL> def nodeEditor ( self ) : <EOL> return self . __nodeTab <EOL> def plugEditor ( self ) : <EOL> return self . __plugTab <EOL> @ classmethod <EOL> def appendNodeContextMenuDefinitions ( cls , nodeGraph , node , menuDefinition ) : <EOL> menuDefinition . append ( "<STR_LIT>" , { "<STR_LIT>" : True } ) <EOL> menuDefinition . append ( "<STR_LIT>" , { "<STR_LIT>" : functools . partial ( cls . __setColor , node = node ) } ) <EOL> @ classmethod <EOL> def appendNodeEditorToolMenuDefinitions ( cls , nodeEditor , node , menuDefinition ) : <EOL> menuDefinition . append ( <EOL> "<STR_LIT>" , <EOL> { <EOL> "<STR_LIT>" : functools . partial ( GafferUI . UIEditor . acquire , node ) , <EOL> "<STR_LIT>" : isinstance ( node , Gaffer . Box ) or nodeEditor . nodeUI ( ) . plugValueWidget ( node [ "<STR_LIT:user>" ] ) is not None <EOL> } <EOL> ) <EOL> def _updateFromSet ( self ) : <EOL> GafferUI . NodeSetEditor . _updateFromSet ( self ) <EOL> self . __updateFromSetInternal ( ) <EOL> def __updateFromSetInternal ( self , lazy = True ) : <EOL> node = self . _lastAddedNode ( ) <EOL> if lazy and node == self . __node : <EOL> return <EOL> self . __node = node <EOL> self . __nodeNameWidget . setGraphComponent ( self . __node ) <EOL> self . __nodeTab . setEnabled ( self . __node is not None ) <EOL> if self . __node is None : <EOL> self . __plugListing . setPlugParent ( None ) <EOL> self . __sectionEditor . setPlugParent ( None ) <EOL> else : <EOL> plugParent = self . __node [ "<STR_LIT:user>" ] <EOL> if isinstance ( self . __node , Gaffer . Box ) : <EOL> plugParent = self . __node <EOL> self . __plugListing . setPlugParent ( plugParent ) <EOL> self . __sectionEditor . setPlugParent ( plugParent ) <EOL> for widget in self . __nodeMetadataWidgets : <EOL> widget . setTarget ( self . __node ) <EOL> self . setSelection ( None ) <EOL> def __plugListingSelectionChanged ( self , listing ) : <EOL> selection = listing . getSelection ( ) <EOL> if selection is None or isinstance ( selection , Gaffer . Plug ) : <EOL> self . __plugEditor . setPlug ( selection ) <EOL> self . __plugAndSectionEditorsContainer . setCurrent ( self . __plugEditor ) <EOL> elif isinstance ( selection , basestring ) : <EOL> self . __plugEditor . setPlug ( None ) <EOL> self . __sectionEditor . setSection ( selection ) <EOL> self . __plugAndSectionEditorsContainer . setCurrent ( self . __sectionEditor ) <EOL> def __sectionEditorNameChanged ( self , sectionEditor , oldName , newName ) : <EOL> self . __plugListing . setSelection ( newName ) <EOL> def __repr__ ( self ) : <EOL> return "<STR_LIT>" <EOL> @ classmethod <EOL> def __setColor ( cls , menu , node ) : <EOL> color = Gaffer . Metadata . nodeValue ( node , "<STR_LIT>" ) or IECore . Color3f ( <NUM_LIT:1> ) <EOL> dialogue = GafferUI . ColorChooserDialogue ( color = color , useDisplayTransform = False ) <EOL> color = dialogue . waitForColor ( parentWindow = menu . ancestor ( GafferUI . Window ) ) <EOL> if color is not None : <EOL> with Gaffer . UndoContext ( node . ancestor ( Gaffer . ScriptNode ) ) : <EOL> Gaffer . Metadata . registerNodeValue ( node , "<STR_LIT>" , color ) <EOL> GafferUI . EditorWidget . registerType ( "<STR_LIT>" , UIEditor ) <EOL> def __editPlugUI ( node , plug ) : <EOL> editor = GafferUI . UIEditor . acquire ( node ) <EOL> editor . setSelection ( plug ) <EOL> editor . plugEditor ( ) . reveal ( ) <EOL> def __plugPopupMenu ( menuDefinition , plugValueWidget ) : <EOL> plug = plugValueWidget . getPlug ( ) <EOL> node = plug . node ( ) <EOL> if node is None : <EOL> return <EOL> if isinstance ( node , Gaffer . Box ) : <EOL> if not plug . parent ( ) . isSame ( node ) : <EOL> return <EOL> else : <EOL> if not plug . parent ( ) . isSame ( node [ "<STR_LIT:user>" ] ) : <EOL> return <EOL> menuDefinition . append ( "<STR_LIT>" , { "<STR_LIT>" : True } ) <EOL> menuDefinition . append ( "<STR_LIT>" , { "<STR_LIT>" : IECore . curry ( __editPlugUI , node , plug ) , "<STR_LIT>" : not plugValueWidget . getReadOnly ( ) } ) <EOL> __plugPopupMenuConnection = GafferUI . PlugValueWidget . popupMenuSignal ( ) . connect ( __plugPopupMenu ) <EOL> class _Label ( GafferUI . Label ) : <EOL> def __init__ ( self , * args , ** kw ) : <EOL> GafferUI . Label . __init__ ( <EOL> self , <EOL> horizontalAlignment = GafferUI . Label . HorizontalAlignment . Right , <EOL> * args , ** kw <EOL> ) <EOL> self . _qtWidget ( ) . setFixedWidth ( <NUM_LIT> ) <EOL> class _Row ( GafferUI . ListContainer ) : <EOL> def __init__ ( self , * args , ** kw ) : <EOL> GafferUI . ListContainer . __init__ ( self , GafferUI . ListContainer . Orientation . Horizontal , spacing = <NUM_LIT:4> , * args , ** kw ) <EOL> class _MetadataWidget ( GafferUI . Widget ) : <EOL> def __init__ ( self , topLevelWidget , key , target = None , parenting = None ) : <EOL> GafferUI . Widget . __init__ ( self , topLevelWidget , parenting = parenting ) <EOL> self . __key = key <EOL> self . __target = None <EOL> self . setTarget ( target ) <EOL> def setTarget ( self , target ) : <EOL> assert ( isinstance ( target , ( Gaffer . Node , Gaffer . Plug , type ( None ) ) ) ) <EOL> self . __target = target <EOL> self . setEnabled ( self . __target is not None ) <EOL> if isinstance ( self . __target , Gaffer . Node ) : <EOL> self . __metadataChangedConnection = Gaffer . Metadata . nodeValueChangedSignal ( ) . connect ( <EOL> Gaffer . WeakMethod ( self . __nodeMetadataChanged ) <EOL> ) <EOL> elif isinstance ( self . __target , Gaffer . Plug ) : <EOL> self . __metadataChangedConnection = Gaffer . Metadata . plugValueChangedSignal ( ) . connect ( <EOL> Gaffer . WeakMethod ( self . __plugMetadataChanged ) <EOL> ) <EOL> else : <EOL> self . __metadataChangedConnection = None <EOL> self . __update ( ) <EOL> def getTarget ( self ) : <EOL> return self . __target <EOL> def setKey ( self , key ) : <EOL> if key == self . __key : <EOL> return <EOL> self . __key = key <EOL> self . __update ( ) <EOL> def getKey ( self , key ) : <EOL> return self . __key <EOL> def _updateFromValue ( self , value ) : <EOL> raise NotImplementedError <EOL> def _updateFromWidget ( self , value ) : <EOL> if self . __target is None : <EOL> return <EOL> with Gaffer . UndoContext ( self . __target . ancestor ( Gaffer . ScriptNode ) ) : <EOL> _registerMetadata ( self . __target , self . __key , value ) <EOL> def _deregisterValue ( self ) : <EOL> if self . __target is None : <EOL> return <EOL> with Gaffer . UndoContext ( self . __target . ancestor ( Gaffer . ScriptNode ) ) : <EOL> _deregisterMetadata ( self . __target , self . __key ) <EOL> def __update ( self ) : <EOL> if isinstance ( self . __target , Gaffer . Node ) : <EOL> self . _updateFromValue ( Gaffer . Metadata . nodeValue ( self . __target , self . __key ) ) <EOL> elif isinstance ( self . __target , Gaffer . Plug ) : <EOL> self . _updateFromValue ( Gaffer . Metadata . plugValue ( self . __target , self . __key ) ) <EOL> else : <EOL> self . _updateFromValue ( None ) <EOL> def __nodeMetadataChanged ( self , nodeTypeId , key , node ) : <EOL> if self . __key != key : <EOL> return <EOL> if node is not None and not node . isSame ( self . __target ) : <EOL> return <EOL> if not self . __target . isInstanceOf ( nodeTypeId ) : <EOL> return <EOL> self . __update ( ) <EOL> def __plugMetadataChanged ( self , nodeTypeId , plugPath , key , plug ) : <EOL> if self . __key != key : <EOL> return <EOL> if plug is not None and not plug . isSame ( self . __target ) : <EOL> return <EOL> if not self . __target . node ( ) . isInstanceOf ( nodeTypeId ) : <EOL> return <EOL> if not Gaffer . match ( self . __target . relativeName ( self . __target . node ( ) ) , plugPath ) : <EOL> return <EOL> self . __update ( ) <EOL> class _BoolMetadataWidget ( _MetadataWidget ) : <EOL> def __init__ ( self , key , target = None , parenting = None ) : <EOL> self . __boolWidget = GafferUI . BoolWidget ( ) <EOL> _MetadataWidget . __init__ ( self , self . __boolWidget , key , target , parenting = parenting ) <EOL> self . __stateChangedConnection = self . __boolWidget . stateChangedSignal ( ) . connect ( <EOL> Gaffer . WeakMethod ( self . __stateChanged ) <EOL> ) <EOL> def _updateFromValue ( self , value ) : <EOL> self . __boolWidget . setState ( value if value is not None else False ) <EOL> def __stateChanged ( self , * unused ) : <EOL> self . _updateFromWidget ( self . __boolWidget . getState ( ) ) <EOL> class _StringMetadataWidget ( _MetadataWidget ) : <EOL> def __init__ ( self , key , target = None , acceptEmptyString = True , parenting = None ) : <EOL> self . __textWidget = GafferUI . TextWidget ( ) <EOL> _MetadataWidget . __init__ ( self , self . __textWidget , key , target , parenting = None ) <EOL> self . __acceptEmptyString = acceptEmptyString <EOL> self . __editingFinishedConnection = self . __textWidget . editingFinishedSignal ( ) . connect ( <EOL> Gaffer . WeakMethod ( self . __editingFinished ) <EOL> ) <EOL> def textWidget ( self ) : <EOL> return self . __textWidget <EOL> def _updateFromValue ( self , value ) : <EOL> self . __textWidget . setText ( value if value is not None else "<STR_LIT>" ) <EOL> def __editingFinished ( self , * unused ) : <EOL> text = self . __textWidget . getText ( ) <EOL> if text or self . __acceptEmptyString : <EOL> self . _updateFromWidget ( text ) <EOL> else : <EOL> self . _deregisterValue ( ) <EOL> class _MultiLineStringMetadataWidget ( _MetadataWidget ) : <EOL> def __init__ ( self , key , target = None , parenting = None ) : <EOL> self . __textWidget = GafferUI . MultiLineTextWidget ( ) <EOL> _MetadataWidget . __init__ ( self , self . __textWidget , key , target , parenting = None ) <EOL> self . __editingFinishedConnection = self . __textWidget . editingFinishedSignal ( ) . connect ( <EOL> Gaffer . WeakMethod ( self . __editingFinished ) <EOL> ) <EOL> def textWidget ( self ) : <EOL> return self . __textWidget <EOL> def _updateFromValue ( self , value ) : <EOL> self . __textWidget . setText ( value if value is not None else "<STR_LIT>" ) <EOL> def __editingFinished ( self , * unused ) : <EOL> self . _updateFromWidget ( self . __textWidget . getText ( ) ) <EOL> class _ColorSwatchMetadataWidget ( _MetadataWidget ) : <EOL> def __init__ ( self , key , target = None , parenting = None ) : <EOL> self . __swatch = GafferUI . ColorSwatch ( useDisplayTransform = False ) <EOL> _MetadataWidget . __init__ ( self , self . __swatch , key , target , parenting = parenting ) <EOL> self . __swatch . _qtWidget ( ) . setFixedHeight ( <NUM_LIT> ) <EOL> self . __swatch . _qtWidget ( ) . setMaximumWidth ( <NUM_LIT> ) <EOL> self . __value = None <EOL> self . __buttonReleaseConnection = self . __swatch . buttonReleaseSignal ( ) . connect ( Gaffer . WeakMethod ( self . __buttonRelease ) ) <EOL> def _updateFromValue ( self , value ) : <EOL> if value is not None : <EOL> self . __swatch . setColor ( value ) <EOL> else : <EOL> self . __swatch . setColor ( IECore . Color4f ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> ) ) <EOL> self . __value = value <EOL> def __buttonRelease ( self , swatch , event ) : <EOL> if event . button != event . Buttons . Left : <EOL> return False <EOL> color = self . __value if self . __value is not None else IECore . Color3f ( <NUM_LIT:1> ) <EOL> dialogue = GafferUI . ColorChooserDialogue ( color = color , useDisplayTransform = False ) <EOL> color = dialogue . waitForColor ( parentWindow = self . ancestor ( GafferUI . Window ) ) <EOL> if color is not None : <EOL> self . _updateFromWidget ( color ) <EOL> class _MenuMetadataWidget ( _MetadataWidget ) : <EOL> def __init__ ( self , key , labelsAndValues , target = None , parenting = None ) : <EOL> self . __menuButton = GafferUI . MenuButton ( <EOL> menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __menuDefinition ) ) <EOL> ) <EOL> self . __labelsAndValues = labelsAndValues <EOL> self . __currentValue = None <EOL> _MetadataWidget . __init__ ( self , self . __menuButton , key , target , parenting = parenting ) <EOL> def _updateFromValue ( self , value ) : <EOL> self . __currentValue = value <EOL> buttonText = str ( value ) <EOL> for label , value in self . __labelsAndValues : <EOL> if value == self . __currentValue : <EOL> buttonText = label <EOL> break <EOL> self . __menuButton . setText ( buttonText ) <EOL> def __menuDefinition ( self ) : <EOL> result = IECore . MenuDefinition ( ) <EOL> for label , value in self . __labelsAndValues : <EOL> result . append ( <EOL> "<STR_LIT:/>" + label , <EOL> { <EOL> "<STR_LIT>" : functools . partial ( Gaffer . WeakMethod ( self . __setValue ) , value = value ) , <EOL> "<STR_LIT>" : value == self . __currentValue <EOL> } <EOL> ) <EOL> return result <EOL> def __setValue ( self , unused , value ) : <EOL> self . _updateFromWidget ( value ) <EOL> class _LayoutItem ( object ) : <EOL> def __init__ ( self ) : <EOL> self . __parent = None <EOL> self . __children = [ ] <EOL> def parent ( self ) : <EOL> if self . __parent is None : <EOL> return None <EOL> else : <EOL> return self . __parent ( ) <EOL> def child ( self , name ) : <EOL> for c in self . __children : <EOL> if c . name ( ) == name : <EOL> return c <EOL> return None <EOL> def isAncestorOf ( self , item ) : <EOL> while item is not None : <EOL> parent = item . parent ( ) <EOL> if parent is self : <EOL> return True <EOL> item = parent <EOL> return False <EOL> def append ( self , child ) : <EOL> self . insert ( len ( self ) , child ) <EOL> def insert ( self , index , child ) : <EOL> assert ( child . parent ( ) is None ) <EOL> self . __children . insert ( index , child ) <EOL> child . __parent = weakref . ref ( self ) <EOL> def remove ( self , child ) : <EOL> assert ( child . parent ( ) is self ) <EOL> self . __children . remove ( child ) <EOL> child . __parent = None <EOL> def index ( self , child ) : <EOL> return self . __children . index ( child ) <EOL> def name ( self ) : <EOL> raise NotImplementedError <EOL> def fullName ( self ) : <EOL> result = "<STR_LIT>" <EOL> item = self <EOL> while item . parent ( ) is not None : <EOL> if result : <EOL> result = item . name ( ) + "<STR_LIT:.>" + result <EOL> else : <EOL> result = item . name ( ) <EOL> item = item . parent ( ) <EOL> return result <EOL> def __len__ ( self ) : <EOL> return len ( self . __children ) <EOL> def __getitem__ ( self , index ) : <EOL> return self . __children [ index ] <EOL> class _SectionLayoutItem ( _LayoutItem ) : <EOL> def __init__ ( self , sectionName ) : <EOL> _LayoutItem . __init__ ( self ) <EOL> self . __sectionName = sectionName <EOL> def name ( self ) : <EOL> return self . __sectionName <EOL> class _PlugLayoutItem ( _LayoutItem ) : <EOL> def __init__ ( self , plug ) : <EOL> _LayoutItem . __init__ ( self ) <EOL> self . plug = plug <EOL> self . __name = plug . getName ( ) <EOL> def name ( self ) : <EOL> return self . __name <EOL> class _PlugListing ( GafferUI . Widget ) : <EOL> class __LayoutPath ( Gaffer . Path ) : <EOL> def __init__ ( self , rootItem , path , root = "<STR_LIT:/>" , filter = None ) : <EOL> Gaffer . Path . __init__ ( self , path , root , filter ) <EOL> self . __rootItem = rootItem <EOL> def rootItem ( self ) : <EOL> return self . __rootItem <EOL> def item ( self ) : <EOL> result = self . __rootItem <EOL> for name in self : <EOL> result = result . child ( name ) <EOL> if result is None : <EOL> return None <EOL> return result <EOL> def copy ( self ) : <EOL> return self . __class__ ( self . __rootItem , self [ : ] , self . root ( ) , self . getFilter ( ) ) <EOL> def isLeaf ( self ) : <EOL> return not isinstance ( self . item ( ) , _SectionLayoutItem ) <EOL> def isValid ( self ) : <EOL> return self . item ( ) is not None <EOL> def _children ( self ) : <EOL> item = self . item ( ) <EOL> if item is None : <EOL> return [ ] <EOL> result = [ <EOL> self . __class__ ( self . __rootItem , self [ : ] + [ c . name ( ) ] , self . root ( ) , self . getFilter ( ) ) <EOL> for c in item <EOL> ] <EOL> if len ( result ) == <NUM_LIT:0> and isinstance ( item , _SectionLayoutItem ) : <EOL> result . append ( self . __class__ ( self . __rootItem , self [ : ] + [ "<STR_LIT:U+0020>" ] , self . root ( ) , self . getFilter ( ) ) ) <EOL> return result <EOL> def __init__ ( self , parenting = None ) : <EOL> column = GafferUI . ListContainer ( spacing = <NUM_LIT:4> ) <EOL> GafferUI . Widget . __init__ ( self , column , parenting = parenting ) <EOL> with column : <EOL> self . __pathListing = GafferUI . PathListingWidget ( <EOL> self . __LayoutPath ( _SectionLayoutItem ( "<STR_LIT>" ) , "<STR_LIT:/>" ) , <EOL> columns = ( GafferUI . PathListingWidget . defaultNameColumn , ) , <EOL> displayMode = GafferUI . PathListingWidget . DisplayMode . Tree , <EOL> ) <EOL> self . __pathListing . setDragPointer ( "<STR_LIT>" ) <EOL> self . __pathListing . setSortable ( False ) <EOL> self . __pathListing . setHeaderVisible ( False ) <EOL> with GafferUI . ListContainer ( GafferUI . ListContainer . Orientation . Horizontal , spacing = <NUM_LIT:4> ) : <EOL> GafferUI . MenuButton ( <EOL> image = "<STR_LIT>" , <EOL> hasFrame = False , <EOL> menu = GafferUI . Menu ( <EOL> definition = Gaffer . WeakMethod ( self . __addMenuDefinition ) <EOL> ) <EOL> ) <EOL> self . __deleteButton = GafferUI . Button ( image = "<STR_LIT>" , hasFrame = False ) <EOL> self . __deleteButtonClickedConnection = self . __deleteButton . clickedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __deleteButtonClicked ) ) <EOL> self . __parent = None <EOL> self . __dragItem = None <EOL> self . __selectionChangedSignal = Gaffer . Signal1 ( ) <EOL> self . __dragEnterConnection = self . __pathListing . dragEnterSignal ( ) . connect ( Gaffer . WeakMethod ( self . __dragEnter ) ) <EOL> self . __dragMoveConnection = self . __pathListing . dragMoveSignal ( ) . connect ( Gaffer . WeakMethod ( self . __dragMove ) ) <EOL> self . __dragEndConnection = self . __pathListing . dragEndSignal ( ) . connect ( Gaffer . WeakMethod ( self . __dragEnd ) ) <EOL> self . __selectionChangedConnection = self . __pathListing . selectionChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __selectionChanged ) ) <EOL> self . __keyPressConnection = self . keyPressSignal ( ) . connect ( Gaffer . WeakMethod ( self . __keyPress ) ) <EOL> self . __nodeMetadataChangedConnection = Gaffer . Metadata . nodeValueChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __nodeMetadataChanged ) ) <EOL> self . __plugMetadataChangedConnection = Gaffer . Metadata . plugValueChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __plugMetadataChanged ) ) <EOL> def setPlugParent ( self , parent ) : <EOL> assert ( isinstance ( parent , ( Gaffer . Plug , Gaffer . Node , types . NoneType ) ) ) <EOL> self . __parent = parent <EOL> self . __childAddedConnection = None <EOL> self . __childRemovedConnection = None <EOL> self . __childNameChangedConnections = { } <EOL> if self . __parent is not None : <EOL> self . __childAddedConnection = self . __parent . childAddedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __childAddedOrRemoved ) ) <EOL> self . __childRemovedConnection = self . __parent . childRemovedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __childAddedOrRemoved ) ) <EOL> for child in self . __parent . children ( ) : <EOL> self . __updateChildNameChangedConnection ( child ) <EOL> self . __updatePath ( ) <EOL> def getPlugParent ( self ) : <EOL> return self . __parent <EOL> def setSelection ( self , selection ) : <EOL> self . __updatePathLazily . flush ( self ) <EOL> def findPlugPath ( path , plug ) : <EOL> item = path . item ( ) <EOL> if isinstance ( item , _PlugLayoutItem ) and item . plug . isSame ( plug ) : <EOL> return path <EOL> else : <EOL> for child in path . children ( ) : <EOL> r = findPlugPath ( child , plug ) <EOL> if r is not None : <EOL> return r <EOL> return None <EOL> if isinstance ( selection , Gaffer . Plug ) : <EOL> path = findPlugPath ( self . __pathListing . getPath ( ) , selection ) <EOL> if path is None : <EOL> self . __pathListing . setSelectedPaths ( [ ] ) <EOL> else : <EOL> self . __pathListing . setSelectedPaths ( [ path ] ) <EOL> elif isinstance ( selection , basestring ) : <EOL> path = self . __pathListing . getPath ( ) . copy ( ) <EOL> path [ : ] = selection . split ( "<STR_LIT:.>" ) <EOL> self . __pathListing . setSelectedPaths ( [ path ] ) <EOL> else : <EOL> assert ( selection is None ) <EOL> self . __pathListing . setSelectedPaths ( [ ] ) <EOL> def getSelection ( self ) : <EOL> item = self . __selectedItem ( ) <EOL> if item is None : <EOL> return None <EOL> elif isinstance ( item , _PlugLayoutItem ) : <EOL> return item . plug <EOL> elif isinstance ( item , _SectionLayoutItem ) : <EOL> return item . fullName ( ) <EOL> else : <EOL> return None <EOL> def selectionChangedSignal ( self ) : <EOL> return self . __selectionChangedSignal <EOL> def __updatePath ( self ) : <EOL> if self . __parent is None : <EOL> self . __pathListing . setPath ( self . __LayoutPath ( _SectionLayoutItem ( "<STR_LIT>" ) , "<STR_LIT:/>" ) ) <EOL> return <EOL> def section ( rootLayoutItem , sectionPath ) : <EOL> sectionItem = rootLayoutItem <EOL> if sectionPath != "<STR_LIT>" : <EOL> for sectionName in sectionPath . split ( "<STR_LIT:.>" ) : <EOL> childSectionItem = sectionItem . child ( sectionName ) <EOL> if childSectionItem is None : <EOL> childSectionItem = _SectionLayoutItem ( sectionName ) <EOL> sectionItem . append ( childSectionItem ) <EOL> sectionItem = childSectionItem <EOL> return sectionItem <EOL> layout = _SectionLayoutItem ( "<STR_LIT>" ) <EOL> for sectionPath in GafferUI . PlugLayout . layoutSections ( self . __parent ) : <EOL> if sectionPath == "<STR_LIT>" and isinstance ( self . __parent , Gaffer . Node ) : <EOL> continue <EOL> sectionItem = section ( layout , sectionPath ) <EOL> for plug in GafferUI . PlugLayout . layoutOrder ( self . __parent , section = sectionPath ) : <EOL> sectionItem . append ( _PlugLayoutItem ( plug ) ) <EOL> emptySections = _metadata ( self . getPlugParent ( ) , "<STR_LIT>" ) <EOL> emptySectionIndices = _metadata ( self . getPlugParent ( ) , "<STR_LIT>" ) <EOL> if emptySections and emptySectionIndices : <EOL> for sectionPath , sectionIndex in zip ( emptySections , emptySectionIndices ) : <EOL> parentPath , unused , sectionName = sectionPath . rpartition ( "<STR_LIT:.>" ) <EOL> parentSection = section ( layout , parentPath ) <EOL> if parentSection . child ( sectionName ) is None : <EOL> parentSection . insert ( sectionIndex , _SectionLayoutItem ( sectionName ) ) <EOL> if len ( layout ) == <NUM_LIT:0> and isinstance ( self . __parent , Gaffer . Node ) : <EOL> layout . append ( _SectionLayoutItem ( "<STR_LIT>" ) ) <EOL> expandedPaths = self . __pathListing . getExpandedPaths ( ) <EOL> self . __pathListing . setPath ( self . __LayoutPath ( layout , "<STR_LIT:/>" ) ) <EOL> self . __pathListing . setExpandedPaths ( expandedPaths ) <EOL> @ GafferUI . LazyMethod ( ) <EOL> def __updatePathLazily ( self ) : <EOL> self . __updatePath ( ) <EOL> def __updateMetadata ( self ) : <EOL> emptySections = IECore . StringVectorData ( ) <EOL> emptySectionIndices = IECore . IntVectorData ( ) <EOL> def walk ( layoutItem , path = "<STR_LIT>" , index = <NUM_LIT:0> ) : <EOL> for childItem in layoutItem : <EOL> if isinstance ( childItem , _PlugLayoutItem ) : <EOL> Gaffer . Metadata . registerPlugValue ( childItem . plug , "<STR_LIT>" , path ) <EOL> Gaffer . Metadata . registerPlugValue ( childItem . plug , "<STR_LIT>" , index ) <EOL> index += <NUM_LIT:1> <EOL> elif isinstance ( childItem , _SectionLayoutItem ) : <EOL> childPath = path + "<STR_LIT:.>" + childItem . name ( ) if path else childItem . name ( ) <EOL> if len ( childItem ) : <EOL> index = walk ( childItem , childPath , index ) <EOL> else : <EOL> emptySections . append ( childPath ) <EOL> emptySectionIndices . append ( layoutItem . index ( childItem ) ) <EOL> return index <EOL> with Gaffer . BlockedConnection ( self . __plugMetadataChangedConnection ) : <EOL> walk ( self . __pathListing . getPath ( ) . copy ( ) . setFromString ( "<STR_LIT:/>" ) . item ( ) ) <EOL> _registerMetadata ( self . getPlugParent ( ) , "<STR_LIT>" , emptySections ) <EOL> _registerMetadata ( self . getPlugParent ( ) , "<STR_LIT>" , emptySectionIndices ) <EOL> def __childAddedOrRemoved ( self , parent , child ) : <EOL> assert ( parent . isSame ( self . __parent ) ) <EOL> self . __updateChildNameChangedConnection ( child ) <EOL> self . __updatePathLazily ( ) <EOL> def __childNameChanged ( self , child ) : <EOL> selection = self . getSelection ( ) <EOL> self . __updatePath ( ) <EOL> if isinstance ( selection , Gaffer . Plug ) and child . isSame ( selection ) : <EOL> self . setSelection ( selection ) <EOL> def __updateChildNameChangedConnection ( self , child ) : <EOL> if self . __parent . isSame ( child . parent ( ) ) : <EOL> if child not in self . __childNameChangedConnections : <EOL> self . __childNameChangedConnections [ child ] = child . nameChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __childNameChanged ) ) <EOL> else : <EOL> if child in self . __childNameChangedConnections : <EOL> del self . __childNameChangedConnections [ child ] <EOL> def __dragEnter ( self , listing , event ) : <EOL> if event . sourceWidget is not self . __pathListing : <EOL> return False <EOL> if not isinstance ( event . data , IECore . StringVectorData ) : <EOL> return False <EOL> dragPath = self . __pathListing . getPath ( ) . copy ( ) . setFromString ( event . data [ <NUM_LIT:0> ] ) <EOL> self . __dragItem = dragPath . item ( ) <EOL> self . __pathListing . setPathExpanded ( dragPath , False ) <EOL> return True <EOL> def __dragMove ( self , listing , event ) : <EOL> if self . __dragItem is None : <EOL> return False <EOL> targetPath = self . __pathListing . pathAt ( event . line . p0 ) <EOL> if targetPath is not None : <EOL> targetItem = targetPath . item ( ) <EOL> if targetItem is not None : <EOL> if isinstance ( targetItem , _SectionLayoutItem ) and self . __pathListing . getPathExpanded ( targetPath ) and targetItem . parent ( ) is self . __dragItem . parent ( ) : <EOL> newParent = targetItem <EOL> newIndex = <NUM_LIT:0> <EOL> else : <EOL> newParent = targetItem . parent ( ) <EOL> newIndex = newParent . index ( targetItem ) <EOL> else : <EOL> newParent = targetPath . copy ( ) . truncateUntilValid ( ) . item ( ) <EOL> newIndex = <NUM_LIT:0> <EOL> else : <EOL> newParent = self . __pathListing . getPath ( ) . rootItem ( ) <EOL> newIndex = <NUM_LIT:0> if event . line . p0 . y < <NUM_LIT:1> else len ( newParent ) <EOL> if newParent is self . __dragItem or self . __dragItem . isAncestorOf ( newParent ) : <EOL> return True <EOL> firstNonPlugIndex = next ( <EOL> ( x [ <NUM_LIT:0> ] for x in enumerate ( newParent ) if not isinstance ( x [ <NUM_LIT:1> ] , _PlugLayoutItem ) ) , <EOL> len ( newParent ) <EOL> ) <EOL> if self . __dragItem . parent ( ) is newParent and newParent . index ( self . __dragItem ) < firstNonPlugIndex : <EOL> firstNonPlugIndex -= <NUM_LIT:1> <EOL> if isinstance ( self . __dragItem , _PlugLayoutItem ) : <EOL> if newIndex > firstNonPlugIndex : <EOL> return True <EOL> else : <EOL> if newIndex < firstNonPlugIndex : <EOL> newIndex = max ( newIndex , firstNonPlugIndex ) <EOL> self . __dragItem . parent ( ) . remove ( self . __dragItem ) <EOL> newParent . insert ( newIndex , self . __dragItem ) <EOL> self . __pathListing . getPath ( ) . pathChangedSignal ( ) ( self . __pathListing . getPath ( ) ) <EOL> selection = self . __pathListing . getPath ( ) . copy ( ) <EOL> selection [ : ] = self . __dragItem . fullName ( ) . split ( "<STR_LIT:.>" ) <EOL> self . __pathListing . setSelectedPaths ( [ selection ] , scrollToFirst = False , expandNonLeaf = False ) <EOL> return True <EOL> def __dragEnd ( self , listing , event ) : <EOL> if self . __dragItem is None : <EOL> return False <EOL> with Gaffer . UndoContext ( self . __parent . ancestor ( Gaffer . ScriptNode ) ) : <EOL> self . __updateMetadata ( ) <EOL> self . __dragItem = None <EOL> return True <EOL> def __selectionChanged ( self , pathListing ) : <EOL> self . __deleteButton . setEnabled ( bool ( pathListing . getSelectedPaths ( ) ) ) <EOL> self . __selectionChangedSignal ( self ) <EOL> def __deleteButtonClicked ( self , button ) : <EOL> self . __deleteSelected ( ) <EOL> def __nodeMetadataChanged ( self , nodeTypeId , key , node ) : <EOL> if self . __parent is None : <EOL> return <EOL> if node is not None and not self . __parent . isSame ( node ) : <EOL> return <EOL> if not self . __parent . isInstanceOf ( nodeTypeId ) : <EOL> return <EOL> if key in ( "<STR_LIT>" , "<STR_LIT>" ) : <EOL> self . __updatePathLazily ( ) <EOL> def __plugMetadataChanged ( self , nodeTypeId , plugPath , key , plug ) : <EOL> if self . __parent is None : <EOL> return <EOL> if plug is not None and not self . __parent . isSame ( plug ) and not self . __parent . isSame ( plug . parent ( ) ) : <EOL> return <EOL> node = self . __parent . node ( ) if isinstance ( self . __parent , Gaffer . Plug ) else self . __parent <EOL> if not node . isInstanceOf ( nodeTypeId ) : <EOL> return <EOL> if key in ( "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) : <EOL> self . __updatePathLazily ( ) <EOL> def __keyPress ( self , widget , event ) : <EOL> assert ( widget is self ) <EOL> if event . key == "<STR_LIT>" or event . key == "<STR_LIT>" : <EOL> self . __deleteSelected ( ) <EOL> return True <EOL> return False <EOL> def __addMenuDefinition ( self ) : <EOL> m = IECore . MenuDefinition ( ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . BoolPlug ) } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . FloatPlug ) } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . IntPlug ) } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : True } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . StringPlug ) } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : True } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . V2iPlug ) } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . V3iPlug ) } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . V2fPlug ) } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . V3fPlug ) } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : True } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . Color3fPlug ) } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : functools . partial ( Gaffer . WeakMethod ( self . __addPlug ) , Gaffer . Color4fPlug ) } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : True } ) <EOL> m . append ( "<STR_LIT>" , { "<STR_LIT>" : Gaffer . WeakMethod ( self . __addSection ) } ) <EOL> return m <EOL> def __addPlug ( self , plugType ) : <EOL> plug = plugType ( flags = Gaffer . Plug . Flags . Default | Gaffer . Plug . Flags . Dynamic ) <EOL> _registerMetadata ( plug , "<STR_LIT>" , "<STR_LIT>" ) <EOL> parentItem = self . __selectedItem ( ) <EOL> if parentItem is not None : <EOL> while not isinstance ( parentItem , _SectionLayoutItem ) : <EOL> parentItem = parentItem . parent ( ) <EOL> else : <EOL> parentItem = self . __pathListing . getPath ( ) . rootItem ( ) <EOL> parentItem = next ( <EOL> ( c for c in parentItem if isinstance ( c , _SectionLayoutItem ) ) , <EOL> parentItem <EOL> ) <EOL> _registerMetadata ( plug , "<STR_LIT>" , parentItem . fullName ( ) ) <EOL> with Gaffer . UndoContext ( self . __parent . ancestor ( Gaffer . ScriptNode ) ) : <EOL> self . getPlugParent ( ) . addChild ( plug ) <EOL> self . __updatePathLazily . flush ( self ) <EOL> self . setSelection ( plug ) <EOL> def __addSection ( self ) : <EOL> rootItem = self . __pathListing . getPath ( ) . rootItem ( ) <EOL> existingSectionNames = set ( c . name ( ) for c in rootItem if isinstance ( c , _SectionLayoutItem ) ) <EOL> name = "<STR_LIT>" <EOL> index = <NUM_LIT:1> <EOL> while name in existingSectionNames : <EOL> name = "<STR_LIT>" % index <EOL> index += <NUM_LIT:1> <EOL> rootItem . append ( _SectionLayoutItem ( name ) ) <EOL> self . __pathListing . getPath ( ) . pathChangedSignal ( ) ( self . __pathListing . getPath ( ) ) <EOL> with Gaffer . UndoContext ( self . __parent . ancestor ( Gaffer . ScriptNode ) ) : <EOL> self . __updateMetadata ( ) <EOL> self . __pathListing . setSelectedPaths ( <EOL> self . __pathListing . getPath ( ) . copy ( ) . setFromString ( "<STR_LIT:/>" + name ) <EOL> ) <EOL> def __selectedItem ( self ) : <EOL> selectedPaths = self . __pathListing . getSelectedPaths ( ) <EOL> if not len ( selectedPaths ) : <EOL> return None <EOL> assert ( len ( selectedPaths ) == <NUM_LIT:1> ) <EOL> return selectedPaths [ <NUM_LIT:0> ] . item ( ) <EOL> def __deleteSelected ( self ) : <EOL> selectedItem = self . __selectedItem ( ) <EOL> if selectedItem is None : <EOL> return <EOL> selectedItem . parent ( ) . remove ( selectedItem ) <EOL> def deletePlugsWalk ( item ) : <EOL> if isinstance ( item , _PlugLayoutItem ) : <EOL> item . plug . parent ( ) . removeChild ( item . plug ) <EOL> else : <EOL> for childItem in item : <EOL> deletePlugsWalk ( childItem ) <EOL> with Gaffer . UndoContext ( self . __parent . ancestor ( Gaffer . ScriptNode ) ) : <EOL> deletePlugsWalk ( selectedItem ) <EOL> self . __updateMetadata ( ) <EOL> class _PresetsEditor ( GafferUI . Widget ) : <EOL> def __init__ ( self , parenting = None ) : <EOL> row = GafferUI . ListContainer ( GafferUI . ListContainer . Orientation . Horizontal , spacing = <NUM_LIT:8> ) <EOL> GafferUI . Widget . __init__ ( self , row , parenting = parenting ) <EOL> with row : <EOL> with GafferUI . ListContainer ( spacing = <NUM_LIT:4> ) : <EOL> self . __pathListing = GafferUI . PathListingWidget ( <EOL> Gaffer . DictPath ( collections . OrderedDict ( ) , "<STR_LIT:/>" ) , <EOL> columns = ( GafferUI . PathListingWidget . defaultNameColumn , ) , <EOL> ) <EOL> self . __pathListing . setDragPointer ( "<STR_LIT>" ) <EOL> self . __pathListing . setSortable ( False ) <EOL> self . __pathListing . setHeaderVisible ( False ) <EOL> self . __pathListing . _qtWidget ( ) . setFixedWidth ( <NUM_LIT:200> ) <EOL> self . __pathListing . _qtWidget ( ) . setFixedHeight ( <NUM_LIT:200> ) <EOL> self . __pathListingSelectionChangedConnection = self . __pathListing . selectionChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __selectionChanged ) ) <EOL> self . __dragEnterConnection = self . __pathListing . dragEnterSignal ( ) . connect ( Gaffer . WeakMethod ( self . __dragEnter ) ) <EOL> self . __dragMoveConnection = self . __pathListing . dragMoveSignal ( ) . connect ( Gaffer . WeakMethod ( self . __dragMove ) ) <EOL> self . __dragEndConnection = self . __pathListing . dragEndSignal ( ) . connect ( Gaffer . WeakMethod ( self . __dragEnd ) ) <EOL> with GafferUI . ListContainer ( GafferUI . ListContainer . Orientation . Horizontal , spacing = <NUM_LIT:4> ) : <EOL> self . __addButton = GafferUI . Button ( image = "<STR_LIT>" , hasFrame = False ) <EOL> self . __addButtonClickedConnection = self . __addButton . clickedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __addButtonClicked ) ) <EOL> self . __deleteButton = GafferUI . Button ( image = "<STR_LIT>" , hasFrame = False ) <EOL> self . __deleteButtonClickedConnection = self . __deleteButton . clickedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __deleteButtonClicked ) ) <EOL> with GafferUI . ListContainer ( spacing = <NUM_LIT:4> ) as self . __editingColumn : <EOL> GafferUI . Label ( "<STR_LIT:Name>" ) <EOL> self . __nameWidget = GafferUI . TextWidget ( ) <EOL> self . __nameEditingFinishedConnection = self . __nameWidget . editingFinishedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __nameEditingFinished ) ) <EOL> GafferUI . Spacer ( IECore . V2i ( <NUM_LIT:4> ) , maximumSize = IECore . V2i ( <NUM_LIT:4> ) ) <EOL> GafferUI . Label ( "<STR_LIT>" ) <EOL> self . __valueNode = Gaffer . Node ( "<STR_LIT>" ) <EOL> self . __valuePlugSetConnection = self . __valueNode . plugSetSignal ( ) . connect ( Gaffer . WeakMethod ( self . __valuePlugSet ) ) <EOL> def setPlug ( self , plug ) : <EOL> self . __plug = plug <EOL> self . __plugMetadataChangedConnection = None <EOL> del self . __editingColumn [ <NUM_LIT:4> : ] <EOL> plugValueWidget = None <EOL> if self . __plug is not None : <EOL> self . __plugMetadataChangedConnection = Gaffer . Metadata . plugValueChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __plugMetadataChanged ) ) <EOL> self . __valueNode [ "<STR_LIT>" ] = plug . createCounterpart ( "<STR_LIT>" , plug . Direction . In ) <EOL> if hasattr ( self . __plug , "<STR_LIT>" ) : <EOL> plugValueWidget = GafferUI . PlugValueWidget . create ( self . __valueNode [ "<STR_LIT>" ] , useTypeOnly = True ) <EOL> self . __editingColumn . append ( plugValueWidget if plugValueWidget is not None else GafferUI . TextWidget ( ) ) <EOL> self . __editingColumn . append ( GafferUI . Spacer ( IECore . V2i ( <NUM_LIT:0> ) , parenting = { "<STR_LIT>" : True } ) ) <EOL> self . __updatePath ( ) <EOL> self . __addButton . setEnabled ( hasattr ( self . __plug , "<STR_LIT>" ) ) <EOL> def getPlug ( self ) : <EOL> return self . __plug <EOL> def __updatePath ( self ) : <EOL> d = self . __pathListing . getPath ( ) . dict ( ) <EOL> d . clear ( ) <EOL> if self . __plug is not None : <EOL> for name in _registeredMetadata ( self . __plug , instanceOnly = True , persistentOnly = True ) : <EOL> if name . startswith ( "<STR_LIT>" ) : <EOL> d [ name [ <NUM_LIT:7> : ] ] = _metadata ( self . __plug , name ) <EOL> self . __pathListing . getPath ( ) . pathChangedSignal ( ) ( self . __pathListing . getPath ( ) ) <EOL> def __plugMetadataChanged ( self , nodeTypeId , plugPath , key , plug ) : <EOL> if plug is None or not plug . isSame ( self . __plug ) : <EOL> return <EOL> if key . startswith ( "<STR_LIT>" ) : <EOL> self . __updatePath ( ) <EOL> def __selectionChanged ( self , listing ) : <EOL> selectedPaths = listing . getSelectedPaths ( ) <EOL> self . __nameWidget . setText ( selectedPaths [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] if selectedPaths else "<STR_LIT>" ) <EOL> if selectedPaths : <EOL> with Gaffer . BlockedConnection ( self . __valuePlugSetConnection ) : <EOL> self . __valueNode [ "<STR_LIT>" ] . setValue ( <EOL> Gaffer . Metadata . plugValue ( self . getPlug ( ) , "<STR_LIT>" + selectedPaths [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] ) <EOL> ) <EOL> self . __editingColumn . setEnabled ( bool ( selectedPaths ) ) <EOL> self . __deleteButton . setEnabled ( bool ( selectedPaths ) ) <EOL> def __dragEnter ( self , listing , event ) : <EOL> if event . sourceWidget is not self . __pathListing : <EOL> return False <EOL> if not isinstance ( event . data , IECore . StringVectorData ) : <EOL> return False <EOL> return True <EOL> def __dragMove ( self , listing , event ) : <EOL> d = self . __pathListing . getPath ( ) . dict ( ) <EOL> srcPath = self . __pathListing . getPath ( ) . copy ( ) . setFromString ( event . data [ <NUM_LIT:0> ] ) <EOL> srcIndex = d . keys ( ) . index ( srcPath [ <NUM_LIT:0> ] ) <EOL> targetPath = self . __pathListing . pathAt ( event . line . p0 ) <EOL> if targetPath is not None : <EOL> targetIndex = d . keys ( ) . index ( targetPath [ <NUM_LIT:0> ] ) <EOL> else : <EOL> targetIndex = <NUM_LIT:0> if event . line . p0 . y < <NUM_LIT:1> else len ( d ) <EOL> if srcIndex == targetIndex : <EOL> return True <EOL> items = d . items ( ) <EOL> item = items [ srcIndex ] <EOL> del items [ srcIndex ] <EOL> items . insert ( targetIndex , item ) <EOL> d . clear ( ) <EOL> d . update ( items ) <EOL> self . __pathListing . getPath ( ) . pathChangedSignal ( ) ( self . __pathListing . getPath ( ) ) <EOL> return True <EOL> def __dragEnd ( self , listing , event ) : <EOL> d = self . __pathListing . getPath ( ) . dict ( ) <EOL> with Gaffer . BlockedConnection ( self . __plugMetadataChangedConnection ) : <EOL> with Gaffer . UndoContext ( self . getPlug ( ) . ancestor ( Gaffer . ScriptNode ) ) : <EOL> for item in d . items ( ) : <EOL> Gaffer . Metadata . deregisterPlugValue ( self . getPlug ( ) , "<STR_LIT>" + item [ <NUM_LIT:0> ] ) <EOL> for item in d . items ( ) : <EOL> Gaffer . Metadata . registerPlugValue ( self . getPlug ( ) , "<STR_LIT>" + item [ <NUM_LIT:0> ] , item [ <NUM_LIT:1> ] ) <EOL> self . __updatePath ( ) <EOL> return True <EOL> def __addButtonClicked ( self , button ) : <EOL> existingNames = [ p [ <NUM_LIT:0> ] for p in self . __pathListing . getPath ( ) . children ( ) ] <EOL> name = "<STR_LIT>" <EOL> index = <NUM_LIT:1> <EOL> while name in existingNames : <EOL> name = "<STR_LIT>" % index <EOL> index += <NUM_LIT:1> <EOL> with Gaffer . UndoContext ( self . __plug . ancestor ( Gaffer . ScriptNode ) ) : <EOL> Gaffer . Metadata . registerPlugValue ( self . __plug , "<STR_LIT>" + name , self . __plug . getValue ( ) ) <EOL> self . __pathListing . setSelectedPaths ( <EOL> self . __pathListing . getPath ( ) . copy ( ) . setFromString ( "<STR_LIT:/>" + name ) <EOL> ) <EOL> self . __nameWidget . grabFocus ( ) <EOL> self . __nameWidget . setSelection ( <NUM_LIT:0> , len ( name ) ) <EOL> return True <EOL> def __deleteButtonClicked ( self , button ) : <EOL> paths = self . __pathListing . getPath ( ) . children ( ) <EOL> selectedPreset = self . __pathListing . getSelectedPaths ( ) [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] <EOL> selectedIndex = [ p [ <NUM_LIT:0> ] for p in paths ] . index ( selectedPreset ) <EOL> with Gaffer . UndoContext ( self . __plug . ancestor ( Gaffer . ScriptNode ) ) : <EOL> Gaffer . Metadata . deregisterPlugValue ( self . __plug , "<STR_LIT>" + selectedPreset ) <EOL> del paths [ selectedIndex ] <EOL> if len ( paths ) : <EOL> self . __pathListing . setSelectedPaths ( [ paths [ min ( selectedIndex , len ( paths ) - <NUM_LIT:1> ) ] ] ) <EOL> return True <EOL> def __nameEditingFinished ( self , nameWidget ) : <EOL> selectedPaths = self . __pathListing . getSelectedPaths ( ) <EOL> if not len ( selectedPaths ) : <EOL> return True <EOL> oldName = selectedPaths [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] <EOL> newName = nameWidget . getText ( ) <EOL> items = self . __pathListing . getPath ( ) . dict ( ) . items ( ) <EOL> with Gaffer . BlockedConnection ( self . __plugMetadataChangedConnection ) : <EOL> with Gaffer . UndoContext ( self . getPlug ( ) . ancestor ( Gaffer . ScriptNode ) ) : <EOL> for item in items : <EOL> Gaffer . Metadata . deregisterPlugValue ( self . getPlug ( ) , "<STR_LIT>" + item [ <NUM_LIT:0> ] ) <EOL> for item in items : <EOL> Gaffer . Metadata . registerPlugValue ( self . getPlug ( ) , "<STR_LIT>" + ( item [ <NUM_LIT:0> ] if item [ <NUM_LIT:0> ] != oldName else newName ) , item [ <NUM_LIT:1> ] ) <EOL> self . __updatePath ( ) <EOL> self . __pathListing . setSelectedPaths ( [ self . __pathListing . getPath ( ) . copy ( ) . setFromString ( "<STR_LIT:/>" + newName ) ] ) <EOL> return True <EOL> def __valuePlugSet ( self , plug ) : <EOL> if not plug . isSame ( self . __valueNode [ "<STR_LIT>" ] ) : <EOL> return <EOL> selectedPaths = self . __pathListing . getSelectedPaths ( ) <EOL> preset = selectedPaths [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] <EOL> with Gaffer . UndoContext ( self . getPlug ( ) . ancestor ( Gaffer . ScriptNode ) ) : <EOL> Gaffer . Metadata . registerPlugValue ( self . getPlug ( ) , "<STR_LIT>" + preset , plug . getValue ( ) ) <EOL> class _PlugEditor ( GafferUI . Widget ) : <EOL> def __init__ ( self , parenting = None ) : <EOL> scrolledContainer = GafferUI . ScrolledContainer ( horizontalMode = GafferUI . ScrolledContainer . ScrollMode . Never , borderWidth = <NUM_LIT:8> ) <EOL> GafferUI . Widget . __init__ ( self , scrolledContainer , parenting = parenting ) <EOL> self . __metadataWidgets = { } <EOL> scrolledContainer . setChild ( GafferUI . ListContainer ( spacing = <NUM_LIT:4> ) ) <EOL> with scrolledContainer . getChild ( ) : <EOL> with _Row ( ) : <EOL> _Label ( "<STR_LIT:Name>" ) <EOL> self . __nameWidget = GafferUI . NameWidget ( None ) <EOL> with _Row ( ) : <EOL> _Label ( "<STR_LIT>" ) <EOL> self . __metadataWidgets [ "<STR_LIT:label>" ] = _StringMetadataWidget ( key = "<STR_LIT:label>" , acceptEmptyString = False ) <EOL> with _Row ( ) : <EOL> _Label ( "<STR_LIT>" , parenting = { "<STR_LIT>" : GafferUI . ListContainer . VerticalAlignment . Top } ) <EOL> self . __metadataWidgets [ "<STR_LIT:description>" ] = _MultiLineStringMetadataWidget ( key = "<STR_LIT:description>" ) <EOL> self . __metadataWidgets [ "<STR_LIT:description>" ] . textWidget ( ) . setFixedLineHeight ( <NUM_LIT:10> ) <EOL> with _Row ( ) : <EOL> _Label ( "<STR_LIT>" ) <EOL> self . __widgetMenu = GafferUI . MenuButton ( <EOL> menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __widgetMenuDefinition ) ) <EOL> ) <EOL> with GafferUI . Collapsible ( "<STR_LIT>" , collapsed = True ) : <EOL> with _Row ( ) : <EOL> _Label ( "<STR_LIT>" ) <EOL> self . __presetsEditor = _PresetsEditor ( ) <EOL> with GafferUI . Collapsible ( "<STR_LIT>" , collapsed = True ) : <EOL> with GafferUI . ListContainer ( spacing = <NUM_LIT:4> ) : <EOL> with _Row ( ) : <EOL> _Label ( "<STR_LIT>" ) <EOL> self . __metadataWidgets [ "<STR_LIT>" ] = _BoolMetadataWidget ( key = "<STR_LIT>" ) <EOL> for m in self . __metadataDefinitions : <EOL> with _Row ( ) : <EOL> _Label ( m . label ) <EOL> self . __metadataWidgets [ m . key ] = m . metadataWidgetType ( key = m . key ) <EOL> with GafferUI . Collapsible ( "<STR_LIT>" , collapsed = True ) : <EOL> with GafferUI . ListContainer ( spacing = <NUM_LIT:4> ) as self . __nodeGraphSection : <EOL> with _Row ( ) : <EOL> _Label ( "<STR_LIT>" ) <EOL> self . __gadgetMenu = GafferUI . MenuButton ( <EOL> menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __gadgetMenuDefinition ) ) <EOL> ) <EOL> with _Row ( ) : <EOL> _Label ( "<STR_LIT>" ) <EOL> self . __metadataWidgets [ "<STR_LIT>" ] = _MenuMetadataWidget ( <EOL> key = "<STR_LIT>" , <EOL> labelsAndValues = [ <EOL> ( "<STR_LIT>" , None ) , <EOL> ( "<STR_LIT>" , "<STR_LIT>" ) , <EOL> ( "<STR_LIT>" , "<STR_LIT>" ) , <EOL> ( "<STR_LIT>" , "<STR_LIT:left>" ) , <EOL> ( "<STR_LIT>" , "<STR_LIT:right>" ) , <EOL> ] <EOL> ) <EOL> with _Row ( ) : <EOL> _Label ( "<STR_LIT>" ) <EOL> self . __metadataWidgets [ "<STR_LIT>" ] = _ColorSwatchMetadataWidget ( key = "<STR_LIT>" ) <EOL> with _Row ( ) : <EOL> _Label ( "<STR_LIT>" ) <EOL> self . __metadataWidgets [ "<STR_LIT>" ] = _ColorSwatchMetadataWidget ( key = "<STR_LIT>" ) <EOL> GafferUI . Spacer ( IECore . V2i ( <NUM_LIT:0> ) , parenting = { "<STR_LIT>" : True } ) <EOL> self . __plugMetadataChangedConnection = Gaffer . Metadata . plugValueChangedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __plugMetadataChanged ) ) <EOL> self . __plug = None <EOL> def setPlug ( self , plug ) : <EOL> self . __plug = plug <EOL> self . __nameWidget . setGraphComponent ( self . __plug ) <EOL> for widget in self . __metadataWidgets . values ( ) : <EOL> widget . setTarget ( self . __plug ) <EOL> self . __updateWidgetMenuText ( ) <EOL> self . __updateWidgetSettings ( ) <EOL> self . __updateGadgetMenuText ( ) <EOL> self . __presetsEditor . setPlug ( plug ) <EOL> self . __nodeGraphSection . setEnabled ( self . __plug is not None and self . __plug . parent ( ) . isSame ( self . __plug . node ( ) ) ) <EOL> self . setEnabled ( self . __plug is not None ) <EOL> def getPlug ( self ) : <EOL> return self . __plug <EOL> def __plugMetadataChanged ( self , nodeTypeId , plugPath , key , plug ) : <EOL> if self . getPlug ( ) is None : <EOL> return <EOL> if plug is not None and not plug . isSame ( self . getPlug ( ) ) : <EOL> return <EOL> if not self . getPlug ( ) . node ( ) . isInstanceOf ( nodeTypeId ) : <EOL> return <EOL> if key == "<STR_LIT>" : <EOL> self . __updateWidgetMenuText ( ) <EOL> self . __updateWidgetSettings ( ) <EOL> elif key == "<STR_LIT>" : <EOL> self . __updateGadgetMenuText ( ) <EOL> def __updateWidgetMenuText ( self ) : <EOL> if self . getPlug ( ) is None : <EOL> self . __widgetMenu . setText ( "<STR_LIT>" ) <EOL> return <EOL> metadata = Gaffer . Metadata . plugValue ( self . getPlug ( ) , "<STR_LIT>" ) <EOL> for w in self . __widgetDefinitions : <EOL> if w . metadata == metadata : <EOL> self . __widgetMenu . setText ( w . label ) <EOL> return <EOL> self . __widgetMenu . setText ( metadata ) <EOL> def __updateWidgetSettings ( self ) : <EOL> widgetType = None <EOL> if self . getPlug ( ) is not None : <EOL> widgetType = Gaffer . Metadata . plugValue ( self . getPlug ( ) , "<STR_LIT>" ) <EOL> for m in self . __metadataDefinitions : <EOL> widget = self . __metadataWidgets [ m . key ] <EOL> widget . parent ( ) . setEnabled ( m . plugValueWidgetType == widgetType ) <EOL> self . __metadataWidgets [ "<STR_LIT>" ] . parent ( ) . setEnabled ( <EOL> self . getPlug ( ) is not None and self . getPlug ( ) . direction ( ) == Gaffer . Plug . Direction . In <EOL> ) <EOL> def __widgetMenuDefinition ( self ) : <EOL> result = IECore . MenuDefinition ( ) <EOL> if self . getPlug ( ) is None : <EOL> return result <EOL> metadata = Gaffer . Metadata . plugValue ( self . getPlug ( ) , "<STR_LIT>" ) <EOL> for w in self . __widgetDefinitions : <EOL> if not isinstance ( self . getPlug ( ) , w . plugType ) : <EOL> continue <EOL> result . append ( <EOL> "<STR_LIT:/>" + w . label , <EOL> { <EOL> "<STR_LIT>" : functools . partial ( Gaffer . WeakMethod ( self . __registerOrDeregisterMetadata ) , key = "<STR_LIT>" , value = w . metadata ) , <EOL> "<STR_LIT>" : metadata == w . metadata , <EOL> } <EOL> ) <EOL> return result <EOL> def __updateGadgetMenuText ( self ) : <EOL> if self . getPlug ( ) is None : <EOL> self . __gadgetMenu . setText ( "<STR_LIT>" ) <EOL> return <EOL> metadata = Gaffer . Metadata . plugValue ( self . getPlug ( ) , "<STR_LIT>" ) <EOL> metadata = None if metadata == "<STR_LIT>" else metadata <EOL> for g in self . __gadgetDefinitions : <EOL> if g . metadata == metadata : <EOL> self . __gadgetMenu . setText ( g . label ) <EOL> return <EOL> self . __gadgetMenu . setText ( metadata ) <EOL> def __gadgetMenuDefinition ( self ) : <EOL> result = IECore . MenuDefinition ( ) <EOL> if self . getPlug ( ) is None : <EOL> return result <EOL> metadata = Gaffer . Metadata . plugValue ( self . getPlug ( ) , "<STR_LIT>" ) <EOL> for g in self . __gadgetDefinitions : <EOL> if not isinstance ( self . getPlug ( ) , g . plugType ) : <EOL> continue <EOL> result . append ( <EOL> "<STR_LIT:/>" + g . label , <EOL> { <EOL> "<STR_LIT>" : functools . partial ( Gaffer . WeakMethod ( self . __registerOrDeregisterMetadata ) , key = "<STR_LIT>" , value = g . metadata ) , <EOL> "<STR_LIT>" : metadata == g . metadata , <EOL> } <EOL> ) <EOL> return result <EOL> def __registerOrDeregisterMetadata ( self , unused , key , value ) : <EOL> with Gaffer . UndoContext ( self . getPlug ( ) . ancestor ( Gaffer . ScriptNode ) ) : <EOL> if value is not None : <EOL> Gaffer . Metadata . registerPlugValue ( self . getPlug ( ) , key , value ) <EOL> else : <EOL> Gaffer . Metadata . deregisterPlugValue ( self . getPlug ( ) , key ) <EOL> __WidgetDefinition = collections . namedtuple ( "<STR_LIT>" , ( "<STR_LIT:label>" , "<STR_LIT>" , "<STR_LIT>" ) ) <EOL> __widgetDefinitions = ( <EOL> __WidgetDefinition ( "<STR_LIT>" , Gaffer . Plug , None ) , <EOL> __WidgetDefinition ( "<STR_LIT>" , Gaffer . IntPlug , "<STR_LIT>" ) , <EOL> __WidgetDefinition ( "<STR_LIT>" , Gaffer . StringPlug , "<STR_LIT>" ) , <EOL> __WidgetDefinition ( "<STR_LIT>" , Gaffer . StringPlug , "<STR_LIT>" ) , <EOL> __WidgetDefinition ( "<STR_LIT>" , Gaffer . ValuePlug , "<STR_LIT>" ) , <EOL> __WidgetDefinition ( "<STR_LIT>" , Gaffer . Plug , "<STR_LIT>" ) , <EOL> __WidgetDefinition ( "<STR_LIT:None>" , Gaffer . Plug , "<STR_LIT>" ) , <EOL> ) <EOL> __MetadataDefinition = collections . namedtuple ( "<STR_LIT>" , ( "<STR_LIT:key>" , "<STR_LIT:label>" , "<STR_LIT>" , "<STR_LIT>" ) ) <EOL> __metadataDefinitions = ( <EOL> __MetadataDefinition ( "<STR_LIT>" , "<STR_LIT>" , _StringMetadataWidget , "<STR_LIT>" ) , <EOL> __MetadataDefinition ( "<STR_LIT>" , "<STR_LIT>" , _StringMetadataWidget , "<STR_LIT>" ) , <EOL> __MetadataDefinition ( "<STR_LIT>" , "<STR_LIT>" , _BoolMetadataWidget , "<STR_LIT>" ) , <EOL> __MetadataDefinition ( "<STR_LIT>" , "<STR_LIT>" , _BoolMetadataWidget , "<STR_LIT>" ) , <EOL> __MetadataDefinition ( "<STR_LIT>" , "<STR_LIT>" , _BoolMetadataWidget , "<STR_LIT>" ) , <EOL> __MetadataDefinition ( "<STR_LIT>" , "<STR_LIT>" , _BoolMetadataWidget , "<STR_LIT>" ) , <EOL> ) <EOL> __GadgetDefinition = collections . namedtuple ( "<STR_LIT>" , ( "<STR_LIT:label>" , "<STR_LIT>" , "<STR_LIT>" ) ) <EOL> __gadgetDefinitions = ( <EOL> __GadgetDefinition ( "<STR_LIT>" , Gaffer . Plug , None ) , <EOL> __GadgetDefinition ( "<STR_LIT>" , Gaffer . ArrayPlug , "<STR_LIT>" ) , <EOL> __GadgetDefinition ( "<STR_LIT:None>" , Gaffer . Plug , "<STR_LIT>" ) , <EOL> ) <EOL> class _SectionEditor ( GafferUI . Widget ) : <EOL> def __init__ ( self , parenting = None ) : <EOL> column = GafferUI . ListContainer ( spacing = <NUM_LIT:4> , borderWidth = <NUM_LIT:8> ) <EOL> GafferUI . Widget . __init__ ( self , column , parenting = parenting ) <EOL> with column : <EOL> with _Row ( ) : <EOL> _Label ( "<STR_LIT:Name>" ) <EOL> self . __nameWidget = GafferUI . TextWidget ( ) <EOL> self . __nameWidgetEditingFinishedConnection = self . __nameWidget . editingFinishedSignal ( ) . connect ( Gaffer . WeakMethod ( self . __nameWidgetEditingFinished ) ) <EOL> with _Row ( ) : <EOL> _Label ( "<STR_LIT>" , parenting = { "<STR_LIT>" : GafferUI . ListContainer . VerticalAlignment . Top } ) <EOL> self . __summaryMetadataWidget = _MultiLineStringMetadataWidget ( key = "<STR_LIT>" ) <EOL> self . __section = "<STR_LIT>" <EOL> self . __plugParent = None <EOL> self . __nameChangedSignal = Gaffer . Signal3 ( ) <EOL> def setPlugParent ( self , plugParent ) : <EOL> self . __plugParent = plugParent <EOL> self . __summaryMetadataWidget . setTarget ( self . __plugParent ) <EOL> def getPlugParent ( self ) : <EOL> return self . __plugParent <EOL> def setSection ( self , section ) : <EOL> assert ( isinstance ( section , basestring ) ) <EOL> self . __section = section <EOL> self . __nameWidget . setText ( section . rpartition ( "<STR_LIT:.>" ) [ - <NUM_LIT:1> ] ) <EOL> self . __summaryMetadataWidget . setKey ( "<STR_LIT>" + self . __section + "<STR_LIT>" ) <EOL> def getSection ( self ) : <EOL> return self . __section <EOL> def nameChangedSignal ( self ) : <EOL> return self . __nameChangedSignal <EOL> def __nameWidgetEditingFinished ( self , nameWidget ) : <EOL> if nameWidget . getText ( ) == "<STR_LIT>" : <EOL> self . setSection ( self . __section ) <EOL> return <EOL> oldSectionPath = self . __section . split ( "<STR_LIT:.>" ) <EOL> newSectionPath = oldSectionPath [ : ] <EOL> newSectionPath [ - <NUM_LIT:1> ] = nameWidget . getText ( ) . replace ( "<STR_LIT:.>" , "<STR_LIT>" ) <EOL> if oldSectionPath == newSectionPath : <EOL> return <EOL> def newSection ( oldSection ) : <EOL> s = oldSection . split ( "<STR_LIT:.>" ) <EOL> if s [ : len ( oldSectionPath ) ] == oldSectionPath : <EOL> s [ : len ( oldSectionPath ) ] = newSectionPath <EOL> return "<STR_LIT:.>" . join ( s ) <EOL> else : <EOL> return oldSection <EOL> with Gaffer . UndoContext ( self . __plugParent . ancestor ( Gaffer . ScriptNode ) ) : <EOL> for plug in self . __plugParent . children ( Gaffer . Plug ) : <EOL> s = _metadata ( plug , "<STR_LIT>" ) <EOL> if s is not None : <EOL> _registerMetadata ( plug , "<STR_LIT>" , newSection ( s ) ) <EOL> emptySections = _metadata ( self . getPlugParent ( ) , "<STR_LIT>" ) <EOL> if emptySections : <EOL> for i in range ( <NUM_LIT:0> , len ( emptySections ) ) : <EOL> emptySections [ i ] = newSection ( emptySections [ i ] ) <EOL> _registerMetadata ( self . getPlugParent ( ) , "<STR_LIT>" , emptySections ) <EOL> for name in _registeredMetadata ( self . getPlugParent ( ) , instanceOnly = True , persistentOnly = True ) : <EOL> m = re . match ( "<STR_LIT>" , name ) <EOL> if m : <EOL> if newSection ( m . group ( <NUM_LIT:2> ) ) != m . group ( <NUM_LIT:2> ) : <EOL> _registerMetadata ( <EOL> self . getPlugParent ( ) , <EOL> m . group ( <NUM_LIT:1> ) + newSection ( m . group ( <NUM_LIT:2> ) ) + m . group ( <NUM_LIT:3> ) , <EOL> _metadata ( self . getPlugParent ( ) , name ) <EOL> ) <EOL> _deregisterMetadata ( self . getPlugParent ( ) , name ) <EOL> self . setSection ( "<STR_LIT:.>" . join ( newSectionPath ) ) <EOL> self . nameChangedSignal ( ) ( self , "<STR_LIT:.>" . join ( oldSectionPath ) , "<STR_LIT:.>" . join ( newSectionPath ) ) <EOL> def _registerMetadata ( target , name , value ) : <EOL> if isinstance ( target , Gaffer . Node ) : <EOL> Gaffer . Metadata . registerNodeValue ( target , name , value ) <EOL> else : <EOL> Gaffer . Metadata . registerPlugValue ( target , name , value ) <EOL> def _registeredMetadata ( target , inherit = True , instanceOnly = False , persistentOnly = False ) : <EOL> if isinstance ( target , Gaffer . Node ) : <EOL> return Gaffer . Metadata . registeredNodeValues ( target , inherit , instanceOnly , persistentOnly ) <EOL> else : <EOL> return Gaffer . Metadata . registeredPlugValues ( target , inherit , instanceOnly , persistentOnly ) <EOL> def _metadata ( target , name ) : <EOL> if isinstance ( target , Gaffer . Node ) : <EOL> return Gaffer . Metadata . nodeValue ( target , name ) <EOL> else : <EOL> return Gaffer . Metadata . plugValue ( target , name ) <EOL> def _deregisterMetadata ( target , name ) : <EOL> if isinstance ( target , Gaffer . Node ) : <EOL> return Gaffer . Metadata . deregisterNodeValue ( target , name ) <EOL> else : <EOL> return Gaffer . Metadata . deregisterPlugValue ( target , name ) </s>
<s> import unittest <EOL> import GafferTest <EOL> import GafferUI <EOL> class NumericSliderTest ( unittest . TestCase ) : <EOL> def testConstruction ( self ) : <EOL> s = GafferUI . NumericSlider ( value = <NUM_LIT:0> , min = <NUM_LIT:0> , max = <NUM_LIT:1> ) <EOL> self . assertEqual ( s . getPosition ( ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( s . getRange ( ) , ( <NUM_LIT:0> , <NUM_LIT:1> , <NUM_LIT:0> , <NUM_LIT:1> ) ) <EOL> def testSetValue ( self ) : <EOL> s = GafferUI . NumericSlider ( value = <NUM_LIT:0> , min = <NUM_LIT:0> , max = <NUM_LIT:2> ) <EOL> self . assertEqual ( s . getPosition ( ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:0> ) <EOL> s . setValue ( <NUM_LIT:0.5> ) <EOL> self . assertEqual ( s . getPosition ( ) , <NUM_LIT> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:0.5> ) <EOL> def testSetRange ( self ) : <EOL> s = GafferUI . NumericSlider ( value = <NUM_LIT:1> , min = <NUM_LIT:0> , max = <NUM_LIT:2> ) <EOL> self . assertEqual ( s . getPosition ( ) , <NUM_LIT:0.5> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:1> ) <EOL> s . setRange ( <NUM_LIT:0> , <NUM_LIT:1> ) <EOL> self . assertEqual ( s . getPosition ( ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:1> ) <EOL> def testSetZeroRange ( self ) : <EOL> s = GafferUI . NumericSlider ( value = <NUM_LIT:1> , min = <NUM_LIT:1> , max = <NUM_LIT:2> ) <EOL> self . assertEqual ( s . getPosition ( ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:1> ) <EOL> s . setRange ( <NUM_LIT:1> , <NUM_LIT:1> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:1> ) <EOL> def testSetPosition ( self ) : <EOL> s = GafferUI . NumericSlider ( value = <NUM_LIT:0> , min = <NUM_LIT:0> , max = <NUM_LIT:2> ) <EOL> self . assertEqual ( s . getPosition ( ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:0> ) <EOL> s . setPosition ( <NUM_LIT:0.5> ) <EOL> self . assertEqual ( s . getPosition ( ) , <NUM_LIT:0.5> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:1> ) <EOL> def testValuesOutsideRangeAreClamped ( self ) : <EOL> s = GafferUI . NumericSlider ( value = <NUM_LIT:0.1> , min = <NUM_LIT:0> , max = <NUM_LIT:2> ) <EOL> cs = GafferTest . CapturingSlot ( s . valueChangedSignal ( ) , s . positionChangedSignal ( ) ) <EOL> s . setValue ( <NUM_LIT:3> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( s . getPosition ( ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( len ( cs ) , <NUM_LIT:2> ) <EOL> s . setValue ( <NUM_LIT:3> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( s . getPosition ( ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( len ( cs ) , <NUM_LIT:2> ) <EOL> def testPositionsOutsideRangeAreClamped ( self ) : <EOL> s = GafferUI . NumericSlider ( value = <NUM_LIT:0.1> , min = <NUM_LIT:0> , max = <NUM_LIT:2> ) <EOL> cs = GafferTest . CapturingSlot ( s . valueChangedSignal ( ) , s . positionChangedSignal ( ) ) <EOL> s . setPosition ( <NUM_LIT:2> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( s . getPosition ( ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( len ( cs ) , <NUM_LIT:2> ) <EOL> s . setPosition ( <NUM_LIT:2> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( s . getPosition ( ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( len ( cs ) , <NUM_LIT:2> ) <EOL> def testHardRange ( self ) : <EOL> s = GafferUI . NumericSlider ( value = <NUM_LIT:0.1> , min = <NUM_LIT:0> , max = <NUM_LIT:2> , hardMin = - <NUM_LIT:1> , hardMax = <NUM_LIT:3> ) <EOL> self . assertEqual ( s . getRange ( ) , ( <NUM_LIT:0> , <NUM_LIT:2> , - <NUM_LIT:1> , <NUM_LIT:3> ) ) <EOL> cs = GafferTest . CapturingSlot ( s . valueChangedSignal ( ) , s . positionChangedSignal ( ) ) <EOL> s . setValue ( <NUM_LIT:3> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:3> ) <EOL> self . assertEqual ( s . getPosition ( ) , <NUM_LIT> ) <EOL> self . assertEqual ( len ( cs ) , <NUM_LIT:2> ) <EOL> s . setValue ( <NUM_LIT> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:3> ) <EOL> self . assertEqual ( s . getPosition ( ) , <NUM_LIT> ) <EOL> self . assertEqual ( len ( cs ) , <NUM_LIT:2> ) <EOL> s . setValue ( - <NUM_LIT:1> ) <EOL> self . assertEqual ( s . getValue ( ) , - <NUM_LIT:1> ) <EOL> self . assertEqual ( s . getPosition ( ) , - <NUM_LIT:0.5> ) <EOL> self . assertEqual ( len ( cs ) , <NUM_LIT:4> ) <EOL> s . setValue ( - <NUM_LIT:2> ) <EOL> self . assertEqual ( s . getValue ( ) , - <NUM_LIT:1> ) <EOL> self . assertEqual ( s . getPosition ( ) , - <NUM_LIT:0.5> ) <EOL> self . assertEqual ( len ( cs ) , <NUM_LIT:4> ) <EOL> def testSetRangeClampsValue ( self ) : <EOL> s = GafferUI . NumericSlider ( value = <NUM_LIT:0.5> , min = <NUM_LIT:0> , max = <NUM_LIT:2> ) <EOL> self . assertEqual ( s . getPosition ( ) , <NUM_LIT> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:0.5> ) <EOL> s . setRange ( <NUM_LIT:1> , <NUM_LIT:2> ) <EOL> self . assertEqual ( s . getPosition ( ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( s . getValue ( ) , <NUM_LIT:1> ) <EOL> def testMultipleValues ( self ) : <EOL> self . assertRaises ( Exception , GafferUI . NumericSlider , value = <NUM_LIT:0> , values = [ <NUM_LIT:1> , <NUM_LIT:2> ] ) <EOL> s = GafferUI . NumericSlider ( values = [ <NUM_LIT:1> , <NUM_LIT> ] , min = <NUM_LIT:0> , max = <NUM_LIT:2> ) <EOL> self . assertEqual ( s . getValues ( ) , [ <NUM_LIT:1> , <NUM_LIT> ] ) <EOL> self . assertEqual ( s . getPositions ( ) , [ <NUM_LIT:0.5> , <NUM_LIT> ] ) <EOL> self . assertRaises ( ValueError , s . getValue ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> import unittest <EOL> import weakref <EOL> import sys <EOL> import IECore <EOL> import Gaffer <EOL> import GafferTest <EOL> import GafferUI <EOL> import GafferUITest <EOL> QtCore = GafferUI . _qtImport ( "<STR_LIT>" ) <EOL> QtGui = GafferUI . _qtImport ( "<STR_LIT>" ) <EOL> class TestWidget ( GafferUI . Widget ) : <EOL> def __init__ ( self , ** kw ) : <EOL> GafferUI . Widget . __init__ ( self , QtGui . QLabel ( "<STR_LIT:hello>" ) , ** kw ) <EOL> class TestWidget2 ( GafferUI . Widget ) : <EOL> def __init__ ( self ) : <EOL> self . topLevelGafferWidget = TestWidget ( ) <EOL> GafferUI . Widget . __init__ ( self , self . topLevelGafferWidget ) <EOL> class WidgetTest ( GafferUITest . TestCase ) : <EOL> def testOwner ( self ) : <EOL> w = TestWidget ( ) <EOL> self . assert_ ( GafferUI . Widget . _owner ( w . _qtWidget ( ) ) is w ) <EOL> def testParent ( self ) : <EOL> w = TestWidget ( ) <EOL> self . assert_ ( w . parent ( ) is None ) <EOL> def testCanDie ( self ) : <EOL> w = TestWidget ( ) <EOL> wr1 = weakref . ref ( w ) <EOL> wr2 = weakref . ref ( w . _qtWidget ( ) ) <EOL> del w <EOL> self . assert_ ( wr1 ( ) is None ) <EOL> self . assert_ ( wr2 ( ) is None ) <EOL> def testAncestor ( self ) : <EOL> w = GafferUI . Window ( "<STR_LIT:test>" ) <EOL> l = GafferUI . ListContainer ( GafferUI . ListContainer . Orientation . Vertical ) <EOL> p = GafferUI . SplitContainer ( ) <EOL> l . append ( p ) <EOL> w . setChild ( l ) <EOL> self . assert_ ( p . ancestor ( GafferUI . ListContainer ) is l ) <EOL> self . assert_ ( p . ancestor ( GafferUI . Window ) is w ) <EOL> self . assert_ ( p . ancestor ( GafferUI . Menu ) is None ) <EOL> def testIsAncestorOf ( self ) : <EOL> with GafferUI . Window ( "<STR_LIT:test>" ) as w : <EOL> with GafferUI . SplitContainer ( ) as p : <EOL> with GafferUI . ListContainer ( ) as l1 : <EOL> b1 = GafferUI . Button ( ) <EOL> with GafferUI . ListContainer ( ) as l2 : <EOL> b2 = GafferUI . Button ( ) <EOL> self . assertTrue ( l2 . isAncestorOf ( b2 ) ) <EOL> self . assertFalse ( l1 . isAncestorOf ( b2 ) ) <EOL> self . assertTrue ( p . isAncestorOf ( b2 ) ) <EOL> self . assertTrue ( w . isAncestorOf ( b2 ) ) <EOL> self . assertFalse ( b2 . isAncestorOf ( b1 ) ) <EOL> self . assertFalse ( b2 . isAncestorOf ( l1 ) ) <EOL> self . assertFalse ( b2 . isAncestorOf ( l2 ) ) <EOL> self . assertFalse ( b2 . isAncestorOf ( p ) ) <EOL> self . assertFalse ( b2 . isAncestorOf ( w ) ) <EOL> self . assertTrue ( l1 . isAncestorOf ( b1 ) ) <EOL> self . assertFalse ( l2 . isAncestorOf ( b1 ) ) <EOL> self . assertTrue ( p . isAncestorOf ( b1 ) ) <EOL> self . assertTrue ( w . isAncestorOf ( b1 ) ) <EOL> def testGafferWidgetAsTopLevel ( self ) : <EOL> w = TestWidget2 ( ) <EOL> self . assert_ ( GafferUI . Widget . _owner ( w . _qtWidget ( ) ) is w ) <EOL> self . assert_ ( w . topLevelGafferWidget . parent ( ) is w ) <EOL> self . assert_ ( GafferUI . Widget . _owner ( w . topLevelGafferWidget . _qtWidget ( ) ) is not w ) <EOL> def testToolTip ( self ) : <EOL> w = TestWidget ( ) <EOL> self . assertEqual ( w . getToolTip ( ) , "<STR_LIT>" ) <EOL> w = TestWidget ( toolTip = "<STR_LIT>" ) <EOL> self . assertEqual ( w . getToolTip ( ) , "<STR_LIT>" ) <EOL> w . setToolTip ( "<STR_LIT:a>" ) <EOL> self . assertEqual ( w . getToolTip ( ) , "<STR_LIT:a>" ) <EOL> def testEnabledState ( self ) : <EOL> w = TestWidget ( ) <EOL> self . assertEqual ( w . getEnabled ( ) , True ) <EOL> self . assertEqual ( w . enabled ( ) , True ) <EOL> w . setEnabled ( False ) <EOL> self . assertEqual ( w . getEnabled ( ) , False ) <EOL> self . assertEqual ( w . enabled ( ) , False ) <EOL> w . setEnabled ( True ) <EOL> self . assertEqual ( w . getEnabled ( ) , True ) <EOL> self . assertEqual ( w . enabled ( ) , True ) <EOL> def testDisabledWidgetsDontGetSignals ( self ) : <EOL> w = TestWidget ( ) <EOL> def f ( w , event ) : <EOL> WidgetTest . signalsEmitted += <NUM_LIT:1> <EOL> c = w . buttonPressSignal ( ) . connect ( f ) <EOL> WidgetTest . signalsEmitted = <NUM_LIT:0> <EOL> event = QtGui . QMouseEvent ( QtCore . QEvent . MouseButtonPress , QtCore . QPoint ( <NUM_LIT:0> , <NUM_LIT:0> ) , QtCore . Qt . LeftButton , QtCore . Qt . LeftButton , QtCore . Qt . NoModifier ) <EOL> QtGui . QApplication . instance ( ) . sendEvent ( w . _qtWidget ( ) , event ) <EOL> self . assertEqual ( WidgetTest . signalsEmitted , <NUM_LIT:1> ) <EOL> w . setEnabled ( False ) <EOL> QtGui . QApplication . instance ( ) . sendEvent ( w . _qtWidget ( ) , event ) <EOL> self . assertEqual ( WidgetTest . signalsEmitted , <NUM_LIT:1> ) <EOL> w . setEnabled ( True ) <EOL> QtGui . QApplication . instance ( ) . sendEvent ( w . _qtWidget ( ) , event ) <EOL> self . assertEqual ( WidgetTest . signalsEmitted , <NUM_LIT:2> ) <EOL> def testCanDieAfterUsingSignals ( self ) : <EOL> w = TestWidget ( ) <EOL> wr1 = weakref . ref ( w ) <EOL> wr2 = weakref . ref ( w . _qtWidget ( ) ) <EOL> w . buttonPressSignal ( ) <EOL> w . buttonReleaseSignal ( ) <EOL> w . mouseMoveSignal ( ) <EOL> w . wheelSignal ( ) <EOL> del w <EOL> self . assert_ ( wr1 ( ) is None ) <EOL> self . assert_ ( wr2 ( ) is None ) <EOL> def testVisibility ( self ) : <EOL> with GafferUI . Window ( ) as w : <EOL> with GafferUI . ListContainer ( ) as l : <EOL> t = TestWidget ( ) <EOL> self . assertEqual ( w . getVisible ( ) , False ) <EOL> self . assertEqual ( l . getVisible ( ) , True ) <EOL> self . assertEqual ( t . getVisible ( ) , True ) <EOL> self . assertEqual ( w . visible ( ) , False ) <EOL> self . assertEqual ( l . visible ( ) , False ) <EOL> self . assertEqual ( t . visible ( ) , False ) <EOL> w . setVisible ( True ) <EOL> self . assertEqual ( w . getVisible ( ) , True ) <EOL> self . assertEqual ( l . getVisible ( ) , True ) <EOL> self . assertEqual ( t . getVisible ( ) , True ) <EOL> self . assertEqual ( w . visible ( ) , True ) <EOL> self . assertEqual ( l . visible ( ) , True ) <EOL> self . assertEqual ( t . visible ( ) , True ) <EOL> w . setVisible ( False ) <EOL> self . assertEqual ( w . getVisible ( ) , False ) <EOL> self . assertEqual ( l . getVisible ( ) , True ) <EOL> self . assertEqual ( t . getVisible ( ) , True ) <EOL> self . assertEqual ( w . visible ( ) , False ) <EOL> self . assertEqual ( l . visible ( ) , False ) <EOL> self . assertEqual ( t . visible ( ) , False ) <EOL> self . assertEqual ( t . visible ( relativeTo = l ) , True ) <EOL> self . assertEqual ( t . visible ( relativeTo = w ) , True ) <EOL> w . setVisible ( True ) <EOL> t . setVisible ( False ) <EOL> self . assertEqual ( t . getVisible ( ) , False ) <EOL> self . assertEqual ( t . visible ( ) , False ) <EOL> self . assertEqual ( t . visible ( relativeTo = l ) , False ) <EOL> def testGetVisibleForNewWidgets ( self ) : <EOL> w = TestWidget ( ) <EOL> self . assertEqual ( w . getVisible ( ) , True ) <EOL> def testVisibilityOfParentlessWidgets ( self ) : <EOL> w = GafferUI . Window ( ) <EOL> t = TestWidget ( ) <EOL> self . assertEqual ( w . getVisible ( ) , False ) <EOL> self . assertEqual ( w . visible ( ) , False ) <EOL> self . assertEqual ( t . getVisible ( ) , True ) <EOL> self . assertEqual ( t . visible ( ) , False ) <EOL> w . setVisible ( True ) <EOL> self . assertEqual ( w . getVisible ( ) , True ) <EOL> self . assertEqual ( w . visible ( ) , True ) <EOL> w . setChild ( t ) <EOL> self . assertEqual ( t . getVisible ( ) , True ) <EOL> self . assertEqual ( t . visible ( ) , True ) <EOL> w . removeChild ( t ) <EOL> self . assertEqual ( t . parent ( ) , None ) <EOL> self . assertEqual ( t . getVisible ( ) , True ) <EOL> self . assertEqual ( t . visible ( ) , False ) <EOL> def testVisibilityWhenTransferringWidgets ( self ) : <EOL> w1 = GafferUI . Window ( ) <EOL> w1 . setVisible ( True ) <EOL> w2 = GafferUI . Window ( ) <EOL> w2 . setVisible ( True ) <EOL> v = TestWidget ( ) <EOL> self . assertEqual ( v . getVisible ( ) , True ) <EOL> self . assertEqual ( v . visible ( ) , False ) <EOL> h = TestWidget ( ) <EOL> self . assertEqual ( h . getVisible ( ) , True ) <EOL> h . setVisible ( False ) <EOL> self . assertEqual ( h . getVisible ( ) , False ) <EOL> self . assertEqual ( h . visible ( ) , False ) <EOL> w1 . setChild ( v ) <EOL> self . assertEqual ( v . getVisible ( ) , True ) <EOL> self . assertEqual ( v . visible ( ) , True ) <EOL> self . assertEqual ( h . getVisible ( ) , False ) <EOL> self . assertEqual ( h . visible ( ) , False ) <EOL> w2 . setChild ( v ) <EOL> self . assertEqual ( v . getVisible ( ) , True ) <EOL> self . assertEqual ( v . visible ( ) , True ) <EOL> self . assertEqual ( h . getVisible ( ) , False ) <EOL> self . assertEqual ( h . visible ( ) , False ) <EOL> w1 . setChild ( h ) <EOL> self . assertEqual ( v . getVisible ( ) , True ) <EOL> self . assertEqual ( v . visible ( ) , True ) <EOL> self . assertEqual ( h . getVisible ( ) , False ) <EOL> self . assertEqual ( h . visible ( ) , False ) <EOL> w2 . setChild ( h ) <EOL> self . assertEqual ( v . getVisible ( ) , True ) <EOL> self . assertEqual ( v . visible ( ) , False ) <EOL> self . assertEqual ( h . getVisible ( ) , False ) <EOL> self . assertEqual ( h . visible ( ) , False ) <EOL> def testSignals ( self ) : <EOL> w = TestWidget ( ) <EOL> for s in [ <EOL> ( "<STR_LIT>" , GafferUI . WidgetEventSignal ) , <EOL> ( "<STR_LIT>" , GafferUI . WidgetEventSignal ) , <EOL> ( "<STR_LIT>" , GafferUI . WidgetEventSignal ) , <EOL> ( "<STR_LIT>" , GafferUI . WidgetEventSignal ) , <EOL> ( "<STR_LIT>" , GafferUI . WidgetEventSignal ) , <EOL> ( "<STR_LIT>" , GafferUI . WidgetEventSignal ) , <EOL> ( "<STR_LIT>" , GafferUI . WidgetSignal ) , <EOL> ( "<STR_LIT>" , GafferUI . WidgetSignal ) , <EOL> ( "<STR_LIT>" , GafferUI . WidgetEventSignal ) , <EOL> ( "<STR_LIT>" , GafferUI . WidgetSignal ) , <EOL> ( "<STR_LIT>" , GafferUI . WidgetSignal ) , <EOL> ( "<STR_LIT>" , GafferUI . WidgetSignal ) , <EOL> ] : <EOL> self . failUnless ( isinstance ( getattr ( w , s [ <NUM_LIT:0> ] ) ( ) , s [ <NUM_LIT:1> ] ) ) <EOL> self . failUnless ( getattr ( w , s [ <NUM_LIT:0> ] ) ( ) is getattr ( w , s [ <NUM_LIT:0> ] ) ( ) ) <EOL> def testBound ( self ) : <EOL> w = GafferUI . Window ( borderWidth = <NUM_LIT:8> ) <EOL> b = GafferUI . Button ( ) <EOL> w . setChild ( b ) <EOL> w . setVisible ( True ) <EOL> w . setPosition ( IECore . V2i ( <NUM_LIT:100> ) ) <EOL> self . waitForIdle ( <NUM_LIT:1000> ) <EOL> wb = w . bound ( ) <EOL> bb = b . bound ( ) <EOL> bbw = b . bound ( relativeTo = w ) <EOL> self . failUnless ( isinstance ( wb , IECore . Box2i ) ) <EOL> self . failUnless ( isinstance ( bb , IECore . Box2i ) ) <EOL> self . failUnless ( isinstance ( bbw , IECore . Box2i ) ) <EOL> self . assertEqual ( bb . size ( ) , bbw . size ( ) ) <EOL> self . assertEqual ( bbw . min , bb . min - wb . min ) <EOL> self . assertEqual ( b . size ( ) , bb . size ( ) ) <EOL> def testParentChangedSignal ( self ) : <EOL> w = TestWidget ( ) <EOL> window = GafferUI . Window ( ) <EOL> cs = GafferTest . CapturingSlot ( w . parentChangedSignal ( ) ) <EOL> self . assertEqual ( len ( cs ) , <NUM_LIT:0> ) <EOL> window . setChild ( w ) <EOL> self . assertEqual ( len ( cs ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( cs [ <NUM_LIT:0> ] , ( w , ) ) <EOL> window . setChild ( None ) <EOL> self . assertEqual ( len ( cs ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( cs [ <NUM_LIT:1> ] , ( w , ) ) <EOL> def testHighlighting ( self ) : <EOL> w = TestWidget ( ) <EOL> self . assertEqual ( w . getHighlighted ( ) , False ) <EOL> w . setHighlighted ( True ) <EOL> self . assertEqual ( w . getHighlighted ( ) , True ) <EOL> w . setHighlighted ( False ) <EOL> self . assertEqual ( w . getHighlighted ( ) , False ) <EOL> def testWidgetAt ( self ) : <EOL> with GafferUI . Window ( ) as w1 : <EOL> t1 = GafferUI . TextWidget ( "<STR_LIT:hello>" ) <EOL> with GafferUI . Window ( ) as w2 : <EOL> t2 = GafferUI . TextWidget ( "<STR_LIT:hello>" ) <EOL> w1 . setVisible ( True ) <EOL> w2 . setVisible ( True ) <EOL> w1 . setPosition ( IECore . V2i ( <NUM_LIT:100> ) ) <EOL> w2 . setPosition ( IECore . V2i ( <NUM_LIT> ) ) <EOL> self . waitForIdle ( <NUM_LIT:1000> ) <EOL> self . assertTrue ( GafferUI . Widget . widgetAt ( w1 . bound ( ) . center ( ) ) is t1 ) <EOL> self . assertTrue ( GafferUI . Widget . widgetAt ( w2 . bound ( ) . center ( ) ) is t2 ) <EOL> self . assertTrue ( GafferUI . Widget . widgetAt ( w1 . bound ( ) . center ( ) , widgetType = GafferUI . Window ) is w1 ) <EOL> self . assertTrue ( GafferUI . Widget . widgetAt ( w2 . bound ( ) . center ( ) , widgetType = GafferUI . Window ) is w2 ) <EOL> def testMousePosition ( self ) : <EOL> w = GafferUI . Window ( borderWidth = <NUM_LIT:8> ) <EOL> b = GafferUI . Button ( ) <EOL> w . setChild ( b ) <EOL> w . setVisible ( True ) <EOL> w . setPosition ( IECore . V2i ( <NUM_LIT:100> ) ) <EOL> self . waitForIdle ( <NUM_LIT:1000> ) <EOL> mouseGlobal = GafferUI . Widget . mousePosition ( ) <EOL> mouseLocal = GafferUI . Widget . mousePosition ( relativeTo = b ) <EOL> self . assertEqual ( mouseGlobal , mouseLocal + b . bound ( ) . min ) <EOL> def testAddressAndObject ( self ) : <EOL> button = GafferUI . Button ( ) <EOL> address = GafferUI . _qtAddress ( button . _qtWidget ( ) ) <EOL> self . assertTrue ( isinstance ( address , int ) ) <EOL> widget = GafferUI . _qtObject ( address , QtGui . QPushButton ) <EOL> self . assertTrue ( isinstance ( widget , QtGui . QPushButton ) ) <EOL> def testSetVisibleWithNonBool ( self ) : <EOL> w = TestWidget ( ) <EOL> self . assertTrue ( w . getVisible ( ) is True ) <EOL> w . setVisible ( <NUM_LIT:0> ) <EOL> self . assertTrue ( w . getVisible ( ) is False ) <EOL> w . setVisible ( <NUM_LIT:1> ) <EOL> self . assertTrue ( w . getVisible ( ) is True ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> import GafferUI <EOL> import GafferSceneUI <EOL> def __toolMenu ( nodeEditor , node , menuDefinition ) : <EOL> GafferUI . UIEditor . appendNodeEditorToolMenuDefinitions ( nodeEditor , node , menuDefinition ) <EOL> GafferUI . BoxUI . appendNodeEditorToolMenuDefinitions ( nodeEditor , node , menuDefinition ) <EOL> GafferSceneUI . FilteredSceneProcessorUI . appendNodeEditorToolMenuDefinitions ( nodeEditor , node , menuDefinition ) <EOL> __nodeEditorToolMenuConnection = GafferUI . NodeEditor . toolMenuSignal ( ) . connect ( __toolMenu ) </s>
<s> VERSION = ( <NUM_LIT:0> , <NUM_LIT:1> , <NUM_LIT:0> , '<STR_LIT>' , <NUM_LIT:1> ) <EOL> __version__ = '<STR_LIT:.>' . join ( map ( str , VERSION ) ) <EOL> def get_version ( ) : <EOL> version = '<STR_LIT>' % ( VERSION [ <NUM_LIT:0> ] , VERSION [ <NUM_LIT:1> ] ) <EOL> if VERSION [ <NUM_LIT:2> ] : <EOL> version = '<STR_LIT>' % ( version , VERSION [ <NUM_LIT:2> ] ) <EOL> if VERSION [ <NUM_LIT:3> : ] == ( '<STR_LIT>' , <NUM_LIT:0> ) : <EOL> version = '<STR_LIT>' % version <EOL> else : <EOL> if VERSION [ <NUM_LIT:3> ] != '<STR_LIT>' : <EOL> version = '<STR_LIT>' % ( version , VERSION [ <NUM_LIT:3> ] , VERSION [ <NUM_LIT:4> ] ) <EOL> return version </s>
<s> import yappi <EOL> import os <EOL> from totalimpact import backend <EOL> rootdir = "<STR_LIT:.>" <EOL> logfile = '<STR_LIT>' <EOL> yappi . clear_stats ( ) <EOL> yappi . start ( ) <EOL> backend . main ( logfile ) <EOL> yappi . stop ( ) <EOL> yappi . print_stats ( sort_type = yappi . SORTTYPE_TTOT , limit = <NUM_LIT:30> , thread_stats_on = False ) </s>
<s> import os , collections , simplejson <EOL> from totalimpact import db , app <EOL> from totalimpact . providers import pmc <EOL> from test . unit_tests . providers import common <EOL> from test . unit_tests . providers . common import ProviderTestCase <EOL> from totalimpact . providers . provider import Provider , ProviderContentMalformedError , ProviderFactory <EOL> from totalimpact import provider_batch_data <EOL> from test . utils import http <EOL> from test . utils import setup_postgres_for_unittests , teardown_postgres_for_unittests <EOL> from nose . tools import assert_equals , raises , nottest , assert_items_equal <EOL> datadir = os . path . join ( os . path . split ( __file__ ) [ <NUM_LIT:0> ] , "<STR_LIT>" ) <EOL> SAMPLE_EXTRACT_METRICS_PAGE = os . path . join ( datadir , "<STR_LIT>" ) <EOL> SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH = os . path . join ( datadir , "<STR_LIT>" ) <EOL> TEST_PMID = "<STR_LIT>" <EOL> class TestPmc ( ProviderTestCase ) : <EOL> provider_name = "<STR_LIT>" <EOL> testitem_aliases = ( "<STR_LIT>" , TEST_PMID ) <EOL> testitem_metrics = ( "<STR_LIT>" , TEST_PMID ) <EOL> def setUp ( self ) : <EOL> ProviderTestCase . setUp ( self ) <EOL> self . db = setup_postgres_for_unittests ( db , app ) <EOL> sample_data_dump = open ( SAMPLE_EXTRACT_METRICS_PAGE , "<STR_LIT:r>" ) . read ( ) <EOL> sample_data_dump_different_month = open ( SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH , "<STR_LIT:r>" ) . read ( ) <EOL> test_monthly_data = [ <EOL> { "<STR_LIT>" : "<STR_LIT:abc>" , <EOL> "<STR_LIT:type>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : sample_data_dump , <EOL> "<STR_LIT>" : <NUM_LIT:1.0> , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : { "<STR_LIT>" : [ "<STR_LIT>" , "<STR_LIT>" ] } , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" <EOL> } , <EOL> { "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT:type>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : sample_data_dump_different_month , <EOL> "<STR_LIT>" : <NUM_LIT:1.0> , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : { "<STR_LIT>" : [ "<STR_LIT>" ] } , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" <EOL> } , <EOL> { <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" <EOL> ] <EOL> } , <EOL> "<STR_LIT>" : <NUM_LIT:1> , <EOL> "<STR_LIT:type>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" <EOL> } <EOL> ] <EOL> for doc in test_monthly_data : <EOL> new_object = provider_batch_data . create_objects_from_doc ( doc ) <EOL> print new_object <EOL> self . provider = pmc . Pmc ( ) <EOL> print "<STR_LIT>" <EOL> def tearDown ( self ) : <EOL> teardown_postgres_for_unittests ( self . db ) <EOL> def test_has_applicable_batch_data_true ( self ) : <EOL> response = self . provider . has_applicable_batch_data ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> assert_equals ( response , True ) <EOL> def test_has_applicable_batch_data_false ( self ) : <EOL> response = self . provider . has_applicable_batch_data ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> assert_equals ( response , False ) <EOL> def test_build_batch_data_dict ( self ) : <EOL> response = self . provider . build_batch_data_dict ( ) <EOL> print response . keys ( ) <EOL> expected = [ ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) ] <EOL> assert_items_equal ( response . keys ( ) , expected ) <EOL> def test_is_relevant_alias ( self ) : <EOL> assert_equals ( self . provider . is_relevant_alias ( self . testitem_aliases ) , True ) <EOL> def test_extract_metrics_success ( self ) : <EOL> f = open ( SAMPLE_EXTRACT_METRICS_PAGE , "<STR_LIT:r>" ) <EOL> good_page = f . read ( ) <EOL> metrics_dict = self . provider . _extract_metrics ( good_page , id = "<STR_LIT>" ) <EOL> print metrics_dict <EOL> expected = { '<STR_LIT>' : <NUM_LIT> , '<STR_LIT>' : <NUM_LIT> , '<STR_LIT>' : <NUM_LIT> , '<STR_LIT>' : <NUM_LIT:9> } <EOL> assert_equals ( metrics_dict , expected ) <EOL> def test_provider_metrics_500 ( self ) : <EOL> pass <EOL> def test_provider_metrics_400 ( self ) : <EOL> pass <EOL> def test_provider_metrics_nonsense_xml ( self ) : <EOL> pass <EOL> def test_provider_metrics_nonsense_txt ( self ) : <EOL> pass <EOL> def test_provider_metrics_empty ( self ) : <EOL> pass <EOL> @ http <EOL> def test_metrics ( self ) : <EOL> metrics_dict = self . provider . metrics ( [ ( "<STR_LIT>" , "<STR_LIT>" ) ] ) <EOL> expected = { '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT:9> , '<STR_LIT>' ) } <EOL> print metrics_dict <EOL> for key in expected : <EOL> assert metrics_dict [ key ] [ <NUM_LIT:0> ] >= expected [ key ] [ <NUM_LIT:0> ] , [ key , metrics_dict [ key ] , expected [ key ] ] <EOL> assert metrics_dict [ key ] [ <NUM_LIT:1> ] == expected [ key ] [ <NUM_LIT:1> ] , [ key , metrics_dict [ key ] , expected [ key ] ] <EOL> @ http <EOL> def test_metrics_multiple_months ( self ) : <EOL> metrics_dict = self . provider . metrics ( [ ( "<STR_LIT>" , "<STR_LIT>" ) ] ) <EOL> expected = { '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) } <EOL> print metrics_dict <EOL> for key in expected : <EOL> assert metrics_dict [ key ] [ <NUM_LIT:0> ] >= expected [ key ] [ <NUM_LIT:0> ] , [ key , metrics_dict [ key ] , expected [ key ] ] <EOL> assert metrics_dict [ key ] [ <NUM_LIT:1> ] == expected [ key ] [ <NUM_LIT:1> ] , [ key , metrics_dict [ key ] , expected [ key ] ] <EOL> @ http <EOL> def test_metrics_real ( self ) : <EOL> metrics_dict = self . provider . metrics ( [ ( "<STR_LIT>" , "<STR_LIT>" ) ] ) <EOL> expected = { '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) , '<STR_LIT>' : ( <NUM_LIT> , '<STR_LIT>' ) } <EOL> print metrics_dict <EOL> for key in expected : <EOL> assert metrics_dict [ key ] [ <NUM_LIT:0> ] >= expected [ key ] [ <NUM_LIT:0> ] , [ key , metrics_dict [ key ] , expected [ key ] ] <EOL> assert metrics_dict [ key ] [ <NUM_LIT:1> ] == expected [ key ] [ <NUM_LIT:1> ] , [ key , metrics_dict [ key ] , expected [ key ] ] </s>
<s> import os <EOL> import sys <EOL> import hashlib <EOL> import logging <EOL> import json <EOL> from cPickle import PicklingError <EOL> import redis <EOL> from totalimpact import REDIS_CACHE_DATABASE_NUMBER <EOL> logger = logging . getLogger ( "<STR_LIT>" ) <EOL> cache_client = redis . from_url ( os . getenv ( "<STR_LIT>" ) , REDIS_CACHE_DATABASE_NUMBER ) <EOL> MAX_PAYLOAD_SIZE_BYTES = <NUM_LIT:1000> * <NUM_LIT:1000> <EOL> MAX_CACHE_SIZE_BYTES = <NUM_LIT:100> * <NUM_LIT:1000> * <NUM_LIT:1000> <EOL> class CacheException ( Exception ) : <EOL> pass <EOL> class Cache ( object ) : <EOL> """<STR_LIT>""" <EOL> def _build_hash_key ( self , key ) : <EOL> json_key = json . dumps ( key ) <EOL> hash_key = hashlib . md5 ( json_key . encode ( "<STR_LIT:utf-8>" ) ) . hexdigest ( ) <EOL> return hash_key <EOL> def _get_client ( self ) : <EOL> return cache_client <EOL> def __init__ ( self , max_cache_age = <NUM_LIT> * <NUM_LIT> ) : <EOL> self . max_cache_age = max_cache_age <EOL> self . flush_cache ( ) <EOL> def flush_cache ( self ) : <EOL> mc = self . _get_client ( ) <EOL> def get_cache_entry ( self , key ) : <EOL> """<STR_LIT>""" <EOL> mc = self . _get_client ( ) <EOL> hash_key = self . _build_hash_key ( key ) <EOL> response = mc . get ( hash_key ) <EOL> if response : <EOL> response = json . loads ( response ) <EOL> return response <EOL> def set_cache_entry ( self , key , data ) : <EOL> """<STR_LIT>""" <EOL> if sys . getsizeof ( data [ "<STR_LIT:text>" ] ) > MAX_PAYLOAD_SIZE_BYTES : <EOL> logger . debug ( u"<STR_LIT>" ) <EOL> return None <EOL> mc = self . _get_client ( ) <EOL> if mc . info ( ) [ "<STR_LIT>" ] >= MAX_CACHE_SIZE_BYTES : <EOL> logger . debug ( u"<STR_LIT>" ) <EOL> return None <EOL> hash_key = self . _build_hash_key ( key ) <EOL> set_response = mc . set ( hash_key , json . dumps ( data ) ) <EOL> mc . expire ( hash_key , self . max_cache_age ) <EOL> if not set_response : <EOL> logger . warning ( "<STR_LIT>" ) <EOL> raise CacheException ( "<STR_LIT>" ) <EOL> return set_response </s>
<s> from totalimpact . providers import provider <EOL> from totalimpact . providers . provider import Provider , ProviderContentMalformedError <EOL> import simplejson , os , re , urllib <EOL> import logging <EOL> logger = logging . getLogger ( '<STR_LIT>' ) <EOL> class Plosalm ( Provider ) : <EOL> example_id = ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> url = "<STR_LIT>" <EOL> descr = "<STR_LIT>" <EOL> metrics_url_template = "<STR_LIT>" + os . environ [ "<STR_LIT>" ] <EOL> provenance_url_template = "<STR_LIT>" <EOL> PLOS_ICON = "<STR_LIT>" <EOL> static_meta_dict = { <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT:description>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : PLOS_ICON , <EOL> } , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT:description>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : PLOS_ICON , <EOL> } <EOL> } <EOL> def __init__ ( self ) : <EOL> super ( Plosalm , self ) . __init__ ( ) <EOL> def is_relevant_alias ( self , alias ) : <EOL> ( namespace , nid ) = alias <EOL> relevant = ( ( "<STR_LIT>" == namespace ) and ( "<STR_LIT>" in nid ) ) <EOL> return ( relevant ) <EOL> def _extract_metrics ( self , page , status_code = <NUM_LIT:200> , id = None ) : <EOL> if status_code != <NUM_LIT:200> : <EOL> if status_code == <NUM_LIT> : <EOL> return { } <EOL> else : <EOL> raise ( self . _get_error ( status_code ) ) <EOL> if not "<STR_LIT>" in page : <EOL> raise ProviderContentMalformedError <EOL> json_response = provider . _load_json ( page ) <EOL> this_article = json_response [ <NUM_LIT:0> ] [ "<STR_LIT>" ] [ <NUM_LIT:0> ] [ "<STR_LIT>" ] <EOL> dict_of_keylists = { <EOL> '<STR_LIT>' : [ '<STR_LIT:html>' ] , <EOL> '<STR_LIT>' : [ '<STR_LIT>' ] <EOL> } <EOL> metrics_dict = provider . _extract_from_data_dict ( this_article , dict_of_keylists ) <EOL> return metrics_dict </s>
<s> import os <EOL> import sys <EOL> import urlparse <EOL> from kombu import Exchange , Queue <EOL> sys . path . append ( '<STR_LIT:.>' ) <EOL> redis_url = os . environ . get ( '<STR_LIT>' , "<STR_LIT>" ) <EOL> if not redis_url . endswith ( "<STR_LIT:/>" ) : <EOL> redis_url += "<STR_LIT:/>" <EOL> BROKER_URL = redis_url + "<STR_LIT:1>" <EOL> CELERY_RESULT_BACKEND = redis_url + "<STR_LIT:2>" <EOL> REDIS_CONNECT_RETRY = True <EOL> BROKER_TRANSPORT_OPTIONS = { '<STR_LIT>' : True , <EOL> '<STR_LIT>' : True , <EOL> '<STR_LIT>' : <NUM_LIT> , <EOL> '<STR_LIT>' : <NUM_LIT:100> <EOL> } <EOL> CELERY_DEFAULT_QUEUE = '<STR_LIT>' <EOL> CELERY_QUEUES = [ <EOL> Queue ( '<STR_LIT>' , routing_key = '<STR_LIT>' ) , <EOL> Queue ( '<STR_LIT>' , routing_key = '<STR_LIT>' ) <EOL> ] <EOL> BROKER_POOL_LIMIT = None <EOL> CELERY_CREATE_MISSING_QUEUES = True <EOL> CELERY_ACCEPT_CONTENT = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> CELERY_ENABLE_UTC = True <EOL> CELERY_TASK_RESULT_EXPIRES = <NUM_LIT> * <NUM_LIT> * <NUM_LIT:1> <EOL> CELERY_ACKS_LATE = True <EOL> CELERYD_FORCE_EXECV = True <EOL> CELERY_TRACK_STARTED = True <EOL> CELERYD_PREFETCH_MULTIPLIER = <NUM_LIT:1> <EOL> CELERY_IMPORTS = ( "<STR_LIT>" , ) <EOL> CELERY_ANNOTATIONS = { <EOL> '<STR_LIT>' : { '<STR_LIT>' : <NUM_LIT> * <NUM_LIT:2> } <EOL> } </s>
<s> from totalimpact . providers import provider <EOL> from totalimpact . providers . provider import Provider , ProviderFactory <EOL> from totalimpactwebapp import app , db <EOL> from nose . tools import assert_equals , nottest <EOL> from xml . dom import minidom <EOL> from test . utils import setup_postgres_for_unittests , teardown_postgres_for_unittests <EOL> import simplejson , BeautifulSoup <EOL> import os <EOL> from sqlalchemy . sql import text <EOL> sampledir = os . path . join ( os . path . split ( __file__ ) [ <NUM_LIT:0> ] , "<STR_LIT>" ) <EOL> class Test_Provider ( ) : <EOL> TEST_PROVIDER_CONFIG = [ <EOL> ( "<STR_LIT>" , { "<STR_LIT>" : <NUM_LIT:1> } ) , <EOL> ( "<STR_LIT>" , { "<STR_LIT>" : <NUM_LIT:3> } ) , <EOL> ( "<STR_LIT>" , { "<STR_LIT>" : <NUM_LIT:3> } ) , <EOL> ] <EOL> TEST_JSON = """<STR_LIT>""" <EOL> TEST_XML = open ( os . path . join ( sampledir , "<STR_LIT>" , "<STR_LIT>" ) ) . read ( ) <EOL> def setUp ( self ) : <EOL> self . db = setup_postgres_for_unittests ( db , app ) <EOL> def tearDown ( self ) : <EOL> teardown_postgres_for_unittests ( self . db ) <EOL> def test_get_provider ( self ) : <EOL> provider = ProviderFactory . get_provider ( "<STR_LIT>" ) <EOL> assert_equals ( provider . __class__ . __name__ , "<STR_LIT>" ) <EOL> def test_get_providers ( self ) : <EOL> providers = ProviderFactory . get_providers ( self . TEST_PROVIDER_CONFIG ) <EOL> provider_names = [ provider . __class__ . __name__ for provider in providers ] <EOL> assert_equals ( set ( provider_names ) , set ( [ '<STR_LIT>' , '<STR_LIT>' , "<STR_LIT>" ] ) ) <EOL> def test_get_providers_filters_by_metrics ( self ) : <EOL> providers = ProviderFactory . get_providers ( self . TEST_PROVIDER_CONFIG , "<STR_LIT>" ) <EOL> provider_names = [ provider . __class__ . __name__ for provider in providers ] <EOL> assert_equals ( set ( provider_names ) , set ( [ '<STR_LIT>' , '<STR_LIT>' , "<STR_LIT>" ] ) ) <EOL> def test_get_providers_filters_by_biblio ( self ) : <EOL> providers = ProviderFactory . get_providers ( self . TEST_PROVIDER_CONFIG , "<STR_LIT>" ) <EOL> provider_names = [ provider . __class__ . __name__ for provider in providers ] <EOL> assert_equals ( set ( provider_names ) , set ( [ '<STR_LIT>' , '<STR_LIT>' ] ) ) <EOL> def test_get_providers_filters_by_aliases ( self ) : <EOL> providers = ProviderFactory . get_providers ( self . TEST_PROVIDER_CONFIG , "<STR_LIT>" ) <EOL> provider_names = [ provider . __class__ . __name__ for provider in providers ] <EOL> assert_equals ( set ( provider_names ) , set ( [ '<STR_LIT>' , '<STR_LIT>' ] ) ) <EOL> def test_lookup_json ( self ) : <EOL> page = self . TEST_JSON <EOL> data = simplejson . loads ( page ) <EOL> response = provider . _lookup_json ( data , [ '<STR_LIT>' , '<STR_LIT:name>' ] ) <EOL> assert_equals ( response , u'<STR_LIT>' ) <EOL> def test_extract_json ( self ) : <EOL> page = self . TEST_JSON <EOL> dict_of_keylists = { <EOL> '<STR_LIT:title>' : [ '<STR_LIT>' , '<STR_LIT:name>' ] , <EOL> '<STR_LIT:description>' : [ '<STR_LIT>' , '<STR_LIT:description>' ] } <EOL> response = provider . _extract_from_json ( page , dict_of_keylists ) <EOL> assert_equals ( response , { '<STR_LIT:description>' : u'<STR_LIT>' , '<STR_LIT:title>' : u'<STR_LIT>' } ) <EOL> def test_lookup_xml_from_dom ( self ) : <EOL> page = self . TEST_XML <EOL> doc = minidom . parseString ( page . strip ( ) ) <EOL> response = provider . _lookup_xml_from_dom ( doc , [ '<STR_LIT>' ] ) <EOL> assert_equals ( response , <NUM_LIT> ) <EOL> def test_lookup_xml_from_soup ( self ) : <EOL> page = self . TEST_XML <EOL> doc = BeautifulSoup . BeautifulStoneSoup ( page ) <EOL> response = provider . _lookup_xml_from_soup ( doc , [ '<STR_LIT>' ] ) <EOL> assert_equals ( response , <NUM_LIT> ) <EOL> def test_extract_xml ( self ) : <EOL> page = self . TEST_XML <EOL> dict_of_keylists = { <EOL> '<STR_LIT:count>' : [ '<STR_LIT>' ] } <EOL> response = provider . _extract_from_xml ( page , dict_of_keylists ) <EOL> assert_equals ( response , { '<STR_LIT:count>' : <NUM_LIT> } ) <EOL> def test_doi_from_url_string ( self ) : <EOL> test_url = "<STR_LIT>" <EOL> expected = "<STR_LIT>" <EOL> response = provider . doi_from_url_string ( test_url ) <EOL> assert_equals ( response , expected ) <EOL> def test_is_issn_in_doaj_false ( self ) : <EOL> response = provider . is_issn_in_doaj ( "<STR_LIT>" ) <EOL> assert_equals ( response , False ) <EOL> def test_is_issn_in_doaj_true ( self ) : <EOL> zookeys_issn = "<STR_LIT>" <EOL> response = provider . is_issn_in_doaj ( zookeys_issn ) <EOL> assert_equals ( response , True ) <EOL> def test_import_products ( self ) : <EOL> response = provider . import_products ( "<STR_LIT>" , <EOL> { "<STR_LIT>" : [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] } ) <EOL> expected = [ ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT:url>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) ] <EOL> assert_equals ( response , expected ) <EOL> def test_import_products_bad_providername ( self ) : <EOL> response = provider . import_products ( "<STR_LIT>" , { } ) <EOL> expected = [ ] <EOL> assert_equals ( response , expected ) <EOL> class TestProviderFactory ( ) : <EOL> TEST_PROVIDER_CONFIG = [ <EOL> ( "<STR_LIT>" , { "<STR_LIT>" : <NUM_LIT:1> } ) , <EOL> ( "<STR_LIT>" , { "<STR_LIT>" : <NUM_LIT:3> } ) , <EOL> ( "<STR_LIT>" , { "<STR_LIT>" : <NUM_LIT:3> } ) , <EOL> ] <EOL> def test_get_all_static_meta ( self ) : <EOL> sm = ProviderFactory . get_all_static_meta ( self . TEST_PROVIDER_CONFIG ) <EOL> expected = '<STR_LIT>' <EOL> assert_equals ( sm [ "<STR_LIT>" ] [ "<STR_LIT:description>" ] , expected ) <EOL> def test_get_all_metric_names ( self ) : <EOL> response = ProviderFactory . get_all_metric_names ( self . TEST_PROVIDER_CONFIG ) <EOL> expected = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> assert_equals ( response , expected ) <EOL> def test_get_all_metadata ( self ) : <EOL> md = ProviderFactory . get_all_metadata ( self . TEST_PROVIDER_CONFIG ) <EOL> print md [ "<STR_LIT>" ] <EOL> assert_equals ( md [ "<STR_LIT>" ] [ '<STR_LIT:url>' ] , '<STR_LIT>' ) </s>
<s> import datetime <EOL> import copy <EOL> import unicode_helpers <EOL> import json <EOL> import logging <EOL> from util import cached_property <EOL> from util import dict_from_dir <EOL> from totalimpactwebapp import db <EOL> logger = logging . getLogger ( "<STR_LIT>" ) <EOL> def clean_id ( nid ) : <EOL> try : <EOL> nid = nid . strip ( '<STR_LIT>' ) . strip ( ) <EOL> nid = unicode_helpers . remove_nonprinting_characters ( nid ) <EOL> except ( TypeError , AttributeError ) : <EOL> pass <EOL> return ( nid ) <EOL> def normalize_alias_tuple ( ns , nid ) : <EOL> ns = clean_id ( ns ) <EOL> ns = ns . lower ( ) <EOL> if ns == "<STR_LIT>" : <EOL> return ( ns , nid ) <EOL> nid = clean_id ( nid ) <EOL> from totalimpact . providers import crossref <EOL> from totalimpact . providers import pubmed <EOL> from totalimpact . providers import arxiv <EOL> from totalimpact . providers import webpage <EOL> from totalimpact import importer <EOL> clean_nid = None <EOL> if ns == "<STR_LIT>" or importer . is_doi ( nid ) : <EOL> ns = "<STR_LIT>" <EOL> clean_nid = crossref . clean_doi ( nid ) <EOL> elif ns == "<STR_LIT>" or importer . is_pmid ( nid ) : <EOL> ns = "<STR_LIT>" <EOL> clean_nid = pubmed . clean_pmid ( nid ) <EOL> elif ns == "<STR_LIT>" or importer . is_arxiv ( nid ) : <EOL> ns = "<STR_LIT>" <EOL> clean_nid = arxiv . clean_arxiv_id ( nid ) <EOL> elif ns == "<STR_LIT:url>" or importer . is_url ( nid ) : <EOL> ns = "<STR_LIT:url>" <EOL> clean_nid = webpage . clean_url ( nid ) <EOL> elif ns not in [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT:url>" ] : <EOL> clean_nid = nid <EOL> if not clean_nid : <EOL> return None <EOL> return ( ns , clean_nid ) <EOL> def clean_alias_tuple_for_comparing ( ns , nid ) : <EOL> alias_tuple = normalize_alias_tuple ( ns , nid ) <EOL> if not alias_tuple : <EOL> return None <EOL> try : <EOL> ( ns , nid ) = alias_tuple <EOL> cleaned_alias = ( ns . lower ( ) , nid . lower ( ) ) <EOL> except AttributeError : <EOL> logger . debug ( u"<STR_LIT>" . format ( <EOL> ns = ns , nid = nid ) ) <EOL> cleaned_alias = ( ns , nid ) <EOL> return cleaned_alias <EOL> def alias_tuples_from_dict ( aliases_dict ) : <EOL> """<STR_LIT>""" <EOL> alias_tuples = [ ] <EOL> for ns , ids in aliases_dict . iteritems ( ) : <EOL> if isinstance ( ids , basestring ) : <EOL> alias_tuples . append ( ( ns , ids ) ) <EOL> else : <EOL> for id in ids : <EOL> alias_tuples . append ( ( ns , id ) ) <EOL> return alias_tuples <EOL> def alias_dict_from_tuples ( aliases_tuples ) : <EOL> alias_dict = { } <EOL> for ( ns , ids ) in aliases_tuples : <EOL> if ns in alias_dict : <EOL> alias_dict [ ns ] += [ ids ] <EOL> else : <EOL> alias_dict [ ns ] = [ ids ] <EOL> return alias_dict <EOL> def canonical_aliases ( orig_aliases_dict ) : <EOL> lowercase_aliases_dict = { } <EOL> for orig_namespace in orig_aliases_dict : <EOL> lowercase_namespace = clean_id ( orig_namespace . lower ( ) ) <EOL> if lowercase_namespace == "<STR_LIT>" : <EOL> lowercase_aliases_dict [ lowercase_namespace ] = [ clean_id ( doi . lower ( ) ) for doi in orig_aliases_dict [ orig_namespace ] ] <EOL> else : <EOL> lowercase_aliases_dict [ lowercase_namespace ] = [ clean_id ( nid ) for nid in orig_aliases_dict [ orig_namespace ] ] <EOL> return lowercase_aliases_dict <EOL> def merge_alias_dicts ( aliases1 , aliases2 ) : <EOL> merged_aliases = copy . deepcopy ( aliases1 ) <EOL> for ns , nid_list in aliases2 . iteritems ( ) : <EOL> for nid in nid_list : <EOL> try : <EOL> if not nid in merged_aliases [ ns ] : <EOL> merged_aliases [ ns ] . append ( nid ) <EOL> except KeyError : <EOL> merged_aliases [ ns ] = [ nid ] <EOL> return merged_aliases <EOL> def matches_alias ( product1 , product2 , exclude = [ ] ) : <EOL> alias_tuple_list1 = [ alias_row . my_alias_tuple_for_comparing for alias_row in product1 . alias_rows ] <EOL> alias_tuple_list2 = [ alias_row . my_alias_tuple_for_comparing for alias_row in product2 . alias_rows ] <EOL> has_matches = False <EOL> for alias_tuple1 in alias_tuple_list1 : <EOL> if alias_tuple1 : <EOL> ( ns , nid ) = alias_tuple1 <EOL> if alias_tuple1 in alias_tuple_list2 and ns not in exclude : <EOL> has_matches = True <EOL> return has_matches <EOL> class AliasRow ( db . Model ) : <EOL> __tablename__ = '<STR_LIT>' <EOL> tiid = db . Column ( db . Text , db . ForeignKey ( '<STR_LIT>' ) , primary_key = True ) <EOL> namespace = db . Column ( db . Text , primary_key = True ) <EOL> nid = db . Column ( db . Text , primary_key = True ) <EOL> collected_date = db . Column ( db . DateTime ( ) ) <EOL> def __init__ ( self , ** kwargs ) : <EOL> if "<STR_LIT>" not in kwargs : <EOL> self . collected_date = datetime . datetime . utcnow ( ) <EOL> super ( AliasRow , self ) . __init__ ( ** kwargs ) <EOL> @ cached_property <EOL> def alias_tuple ( self ) : <EOL> return ( self . namespace , self . nid ) <EOL> @ cached_property <EOL> def my_alias_tuple_for_comparing ( self ) : <EOL> return clean_alias_tuple_for_comparing ( self . namespace , self . nid ) <EOL> def is_equivalent_alias ( self , given_namespace , given_nid ) : <EOL> if not given_nid : <EOL> return False <EOL> given_clean_alias = clean_alias_tuple_for_comparing ( given_namespace , given_nid ) <EOL> if not given_clean_alias : <EOL> return False <EOL> return given_clean_alias == self . my_alias_tuple_for_comparing <EOL> class Aliases ( object ) : <EOL> def __init__ ( self , alias_rows ) : <EOL> ignore_namepaces = [ "<STR_LIT>" ] <EOL> self . tiid = None <EOL> for alias_row in alias_rows : <EOL> if alias_row . namespace not in ignore_namepaces : <EOL> self . tiid = alias_row . tiid <EOL> try : <EOL> getattr ( self , alias_row . namespace ) . append ( alias_row . nid ) <EOL> except AttributeError : <EOL> setattr ( self , alias_row . namespace , [ alias_row . nid ] ) <EOL> @ cached_property <EOL> def best_url ( self ) : <EOL> if self . display_doi : <EOL> return u"<STR_LIT>" + self . display_doi <EOL> if self . display_pmid : <EOL> return u"<STR_LIT>" + self . display_pmid <EOL> if self . display_pmc : <EOL> return u"<STR_LIT>" + self . display_pmc <EOL> if self . resolved_url : <EOL> return self . resolved_url <EOL> try : <EOL> return self . url [ <NUM_LIT:0> ] <EOL> except AttributeError : <EOL> return None <EOL> @ cached_property <EOL> def display_best_url ( self ) : <EOL> return self . best_url <EOL> @ cached_property <EOL> def display_pmid ( self ) : <EOL> try : <EOL> return self . pmid [ <NUM_LIT:0> ] <EOL> except AttributeError : <EOL> return None <EOL> @ cached_property <EOL> def display_pmc ( self ) : <EOL> try : <EOL> return self . pmc [ <NUM_LIT:0> ] <EOL> except AttributeError : <EOL> return None <EOL> @ cached_property <EOL> def display_doi ( self ) : <EOL> try : <EOL> return self . doi [ <NUM_LIT:0> ] <EOL> except AttributeError : <EOL> return None <EOL> @ cached_property <EOL> def display_arxiv ( self ) : <EOL> try : <EOL> return self . arxiv [ <NUM_LIT:0> ] <EOL> except AttributeError : <EOL> return None <EOL> @ cached_property <EOL> def has_formal_alias ( self ) : <EOL> if self . display_arxiv or self . display_doi or self . display_pmid or self . display_pmc : <EOL> return True <EOL> else : <EOL> return False <EOL> @ cached_property <EOL> def resolved_url ( self ) : <EOL> try : <EOL> for url in self . url : <EOL> if "<STR_LIT>" in url : <EOL> continue <EOL> elif "<STR_LIT>" in url : <EOL> continue <EOL> elif "<STR_LIT>" in url : <EOL> continue <EOL> elif "<STR_LIT>" in url : <EOL> continue <EOL> elif "<STR_LIT>" in url : <EOL> continue <EOL> else : <EOL> return url <EOL> return self . url [ <NUM_LIT:0> ] <EOL> except AttributeError : <EOL> return None <EOL> def get_genre ( self ) : <EOL> return self . _guess_genre_and_host_from_aliases ( ) [ <NUM_LIT:0> ] <EOL> def get_host ( self ) : <EOL> return self . _guess_genre_and_host_from_aliases ( ) [ <NUM_LIT:1> ] <EOL> def _guess_genre_and_host_from_aliases ( self ) : <EOL> """<STR_LIT>""" <EOL> genre = "<STR_LIT>" <EOL> host = "<STR_LIT>" <EOL> if hasattr ( self , "<STR_LIT>" ) : <EOL> joined_doi_string = "<STR_LIT>" . join ( self . doi ) . lower ( ) <EOL> if "<STR_LIT>" in joined_doi_string : <EOL> genre = "<STR_LIT>" <EOL> host = "<STR_LIT>" <EOL> elif "<STR_LIT>" in joined_doi_string : <EOL> host = "<STR_LIT>" <EOL> genre = "<STR_LIT>" <EOL> else : <EOL> genre = "<STR_LIT>" <EOL> elif hasattr ( self , "<STR_LIT>" ) : <EOL> genre = "<STR_LIT>" <EOL> elif hasattr ( self , "<STR_LIT>" ) : <EOL> genre = "<STR_LIT>" <EOL> host = "<STR_LIT>" <EOL> elif hasattr ( self , "<STR_LIT>" ) : <EOL> genre = "<STR_LIT>" <EOL> host = "<STR_LIT>" <EOL> elif hasattr ( self , "<STR_LIT>" ) : <EOL> genre = "<STR_LIT>" <EOL> host = "<STR_LIT>" <EOL> elif hasattr ( self , "<STR_LIT:url>" ) : <EOL> joined_url_string = "<STR_LIT>" . join ( self . url ) . lower ( ) <EOL> if "<STR_LIT>" in joined_url_string : <EOL> genre = "<STR_LIT>" <EOL> host = "<STR_LIT>" <EOL> elif "<STR_LIT>" in joined_url_string : <EOL> genre = "<STR_LIT>" <EOL> host = "<STR_LIT>" <EOL> elif ( "<STR_LIT>" in joined_url_string ) or ( "<STR_LIT>" in joined_url_string ) : <EOL> genre = "<STR_LIT>" <EOL> host = "<STR_LIT>" <EOL> elif "<STR_LIT>" in joined_url_string : <EOL> genre = "<STR_LIT>" <EOL> host = "<STR_LIT>" <EOL> else : <EOL> genre = "<STR_LIT>" <EOL> return genre , host <EOL> def to_dict ( self ) : <EOL> ret = dict_from_dir ( self ) <EOL> return ret </s>
<s> from totalimpactwebapp import json_sqlalchemy <EOL> from util import commit <EOL> from util import cached_property <EOL> from util import dict_from_dir <EOL> from util import as_int_or_float_if_possible <EOL> from totalimpactwebapp import db <EOL> from totalimpactwebapp . tweeter import Tweeter <EOL> from birdy . twitter import AppClient , TwitterApiError , TwitterRateLimitError , TwitterClientError <EOL> from collections import defaultdict <EOL> from sqlalchemy import case <EOL> import os <EOL> import re <EOL> import datetime <EOL> import logging <EOL> logger = logging . getLogger ( '<STR_LIT>' ) <EOL> def tweets_from_tiids ( tiids ) : <EOL> if not tiids : <EOL> return [ ] <EOL> tweets = db . session . query ( Tweet ) . filter ( Tweet . tiid . in_ ( tiids ) ) . all ( ) <EOL> return tweets <EOL> def get_product_tweets_for_profile ( profile_id ) : <EOL> tweets = db . session . query ( Tweet ) . filter ( Tweet . profile_id == profile_id ) . all ( ) <EOL> response = defaultdict ( list ) <EOL> for tweet in tweets : <EOL> if tweet . tiid and tweet . tweet_text : <EOL> response [ tweet . tiid ] . append ( tweet ) <EOL> return response <EOL> def store_tweet_payload_and_tweeter_from_twitter ( payload_dicts_from_twitter , tweets ) : <EOL> tweets_by_tweet_id = defaultdict ( list ) <EOL> for tweet in tweets : <EOL> tweets_by_tweet_id [ tweet . tweet_id ] . append ( tweet ) <EOL> for payload_dict in payload_dicts_from_twitter : <EOL> tweet_id = payload_dict [ "<STR_LIT>" ] <EOL> logger . debug ( "<STR_LIT>" . format ( <EOL> tweet_id = tweet_id ) ) <EOL> for tweet in tweets_by_tweet_id [ tweet_id ] : <EOL> if not tweet . payload : <EOL> tweet . payload = payload_dict <EOL> logger . info ( u"<STR_LIT>" . format ( <EOL> tweet_id = tweet_id , tiid = tweet . tiid ) ) <EOL> if "<STR_LIT:user>" in payload_dict : <EOL> try : <EOL> tweet . tweeter . set_attributes_from_twitter_data ( payload_dict [ "<STR_LIT:user>" ] ) <EOL> except AttributeError : <EOL> tweeter = Tweeter . query . get ( tweet . screen_name ) <EOL> if not tweeter : <EOL> tweeter = Tweeter ( screen_name = tweet . screen_name ) <EOL> db . session . add ( tweeter ) <EOL> tweeter . set_attributes_from_twitter_data ( payload_dict [ "<STR_LIT:user>" ] ) <EOL> tweet . tweeter = tweeter <EOL> commit ( db ) <EOL> if tweet . tweeter : <EOL> logger . info ( u"<STR_LIT>" . format ( <EOL> screen_name = tweet . tweeter . screen_name ) ) <EOL> def flag_deleted_tweets ( tweet_ids ) : <EOL> if not tweet_ids : <EOL> return None <EOL> for tweet in Tweet . query . filter ( Tweet . tweet_id . in_ ( tweet_ids ) ) . all ( ) : <EOL> tweet . is_deleted = True <EOL> db . session . merge ( tweet ) <EOL> def handle_all_tweets ( data , tweets ) : <EOL> store_tweet_payload_and_tweeter_from_twitter ( data , tweets ) <EOL> tweet_ids = [ tweet . tweet_id for tweet in tweets ] <EOL> tweet_ids_with_response = [ tweet [ "<STR_LIT>" ] for tweet in data ] <EOL> tweet_ids_without_response = [ tweet for tweet in tweet_ids if tweet not in tweet_ids_with_response ] <EOL> flag_deleted_tweets ( tweet_ids_without_response ) <EOL> return True <EOL> class AppDictClient ( AppClient ) : <EOL> @ staticmethod <EOL> def get_json_object_hook ( data ) : <EOL> return data <EOL> def get_and_save_tweet_text_and_tweeter_followers ( tweets ) : <EOL> client = AppDictClient ( <EOL> os . getenv ( "<STR_LIT>" ) , <EOL> os . getenv ( "<STR_LIT>" ) , <EOL> access_token = os . getenv ( "<STR_LIT>" ) <EOL> ) <EOL> logger . info ( u"<STR_LIT>" . format ( <EOL> num = len ( tweets ) ) ) <EOL> group_size = <NUM_LIT:100> <EOL> list_of_groups = [ tweets [ i : i + group_size ] for i in range ( <NUM_LIT:0> , len ( tweets ) , group_size ) ] <EOL> for tweet_subset in list_of_groups : <EOL> tweet_id_string = "<STR_LIT:U+002C>" . join ( [ tweet . tweet_id for tweet in tweet_subset ] ) <EOL> try : <EOL> response = client . api . statuses . lookup . post ( id = tweet_id_string , trim_user = False ) <EOL> handle_all_tweets ( response . data , tweet_subset ) <EOL> except TwitterApiError , e : <EOL> logger . exception ( "<STR_LIT>" ) <EOL> except TwitterClientError , e : <EOL> logger . exception ( "<STR_LIT>" ) <EOL> except TwitterRateLimitError , e : <EOL> logger . exception ( "<STR_LIT>" ) <EOL> return <EOL> def hydrate_twitter_text_and_followers ( profile_id , altmetric_twitter_posts ) : <EOL> logger . info ( u"<STR_LIT>" . format ( <EOL> profile_id = profile_id ) ) <EOL> tweets_to_hydrate_from_twitter = [ ] <EOL> tweets = Tweet . query . filter ( Tweet . profile_id == profile_id ) <EOL> tweet_dict = dict ( [ ( ( tweet . tweet_id , tweet . tiid ) , tweet ) for tweet in tweets ] ) <EOL> for tiid , post_list in altmetric_twitter_posts . iteritems ( ) : <EOL> for post in post_list : <EOL> tweet_id = post [ "<STR_LIT>" ] <EOL> screen_name = post [ "<STR_LIT>" ] [ "<STR_LIT>" ] <EOL> if ( tweet_id , tiid ) in tweet_dict . keys ( ) : <EOL> tweet = tweet_dict [ ( tweet_id , tiid ) ] <EOL> if not tweet . tweet_text and not tweet . is_deleted : <EOL> tweets_to_hydrate_from_twitter . append ( tweet ) <EOL> else : <EOL> if not Tweet . query . get ( ( tweet_id , tiid ) ) : <EOL> tweet = Tweet ( tweet_id = tweet_id , tiid = tiid ) <EOL> tweet . set_attributes_from_altmetric_post ( post ) <EOL> tweet . profile_id = profile_id <EOL> tweets_to_hydrate_from_twitter . append ( tweet ) <EOL> db . session . add ( tweet ) <EOL> if not tweet . tweeter : <EOL> tweeter = Tweeter . query . get ( screen_name ) <EOL> if not tweeter : <EOL> tweeter = Tweeter ( screen_name = screen_name ) <EOL> db . session . add ( tweeter ) <EOL> tweeter . set_attributes_from_altmetric_post ( post ) <EOL> commit ( db ) <EOL> logger . info ( u"<STR_LIT>" . format ( <EOL> profile_id = profile_id ) ) <EOL> if tweets_to_hydrate_from_twitter : <EOL> commit ( db ) <EOL> tweet_ids = [ tweet . tweet_id for tweet in tweets_to_hydrate_from_twitter ] <EOL> logger . info ( u"<STR_LIT>" . format ( <EOL> profile_id = profile_id ) ) <EOL> get_and_save_tweet_text_and_tweeter_followers ( tweets_to_hydrate_from_twitter ) <EOL> commit ( db ) <EOL> else : <EOL> logger . info ( u"<STR_LIT>" . format ( <EOL> profile_id = profile_id ) ) <EOL> return <EOL> handle_workaround_join_string = "<STR_LIT>" <EOL> class Tweet ( db . Model ) : <EOL> tweet_id = db . Column ( db . Text , primary_key = True ) <EOL> tiid = db . Column ( db . Text , primary_key = True ) <EOL> profile_id = db . Column ( db . Integer , db . ForeignKey ( '<STR_LIT>' ) ) <EOL> screen_name = db . Column ( db . Text , db . ForeignKey ( '<STR_LIT>' ) ) <EOL> tweet_timestamp = db . Column ( db . DateTime ( ) ) <EOL> payload = db . Column ( json_sqlalchemy . JSONAlchemy ( db . Text ) ) <EOL> is_deleted = db . Column ( db . Boolean ) <EOL> tweet_url = db . Column ( db . Text ) <EOL> country = db . Column ( db . Text ) <EOL> followers_at_time_of_tweet = db . Column ( db . Integer ) <EOL> tweeter = db . relationship ( <EOL> '<STR_LIT>' , <EOL> lazy = '<STR_LIT>' , <EOL> cascade = '<STR_LIT:all>' , <EOL> backref = db . backref ( "<STR_LIT>" ) , <EOL> uselist = False , <EOL> primaryjoin = handle_workaround_join_string <EOL> ) <EOL> def __init__ ( self , ** kwargs ) : <EOL> if "<STR_LIT>" in kwargs : <EOL> payload_dict = kwargs [ "<STR_LIT>" ] <EOL> kwargs [ "<STR_LIT>" ] = payload_dict [ "<STR_LIT>" ] <EOL> kwargs [ "<STR_LIT>" ] = payload_dict [ "<STR_LIT:user>" ] [ "<STR_LIT>" ] <EOL> kwargs [ "<STR_LIT>" ] = payload_dict <EOL> kwargs [ "<STR_LIT>" ] = datetime . datetime . strptime ( payload_dict [ "<STR_LIT>" ] , r"<STR_LIT>" ) <EOL> if not "<STR_LIT>" in kwargs : <EOL> try : <EOL> kwargs [ "<STR_LIT>" ] = payload_dict [ "<STR_LIT>" ] [ "<STR_LIT>" ] <EOL> except ( AttributeError , TypeError ) : <EOL> pass <EOL> super ( Tweet , self ) . __init__ ( ** kwargs ) <EOL> @ classmethod <EOL> def most_recent_tweet_id ( cls , screen_name ) : <EOL> screen_name = screen_name . replace ( "<STR_LIT:@>" , "<STR_LIT>" ) <EOL> q = db . session . query ( Tweet ) . filter ( Tweet . screen_name == screen_name ) . order_by ( Tweet . tweet_timestamp . desc ( ) ) <EOL> tweet = q . first ( ) <EOL> try : <EOL> tweet_id = tweet . tweet_id <EOL> except AttributeError : <EOL> tweet_id = None <EOL> return tweet_id <EOL> @ cached_property <EOL> def tweet_text ( self ) : <EOL> try : <EOL> return self . payload [ "<STR_LIT:text>" ] <EOL> except TypeError : <EOL> return None <EOL> @ cached_property <EOL> def tweet_text_with_links ( self ) : <EOL> if self . tweet_text is None : <EOL> return None <EOL> ret = self . tweet_text <EOL> ret = re . sub ( r"<STR_LIT>" , r"<STR_LIT>" , ret ) <EOL> for url_info in self . urls : <EOL> my_link = u"<STR_LIT>" . format ( <EOL> url = url_info [ "<STR_LIT>" ] , <EOL> display_url = url_info [ "<STR_LIT>" ] <EOL> ) <EOL> ret = re . sub ( r"<STR_LIT>" , my_link , ret , <NUM_LIT:1> ) <EOL> ret = re . sub ( r"<STR_LIT>" , r"<STR_LIT>" , ret ) <EOL> ret = re . sub ( r"<STR_LIT>" , r"<STR_LIT>" , ret ) <EOL> return ret <EOL> @ cached_property <EOL> def urls ( self ) : <EOL> try : <EOL> return self . payload [ "<STR_LIT>" ] [ "<STR_LIT>" ] <EOL> except TypeError : <EOL> return None <EOL> except KeyError : <EOL> return [ ] <EOL> @ cached_property <EOL> def has_country ( self ) : <EOL> return self . country != None <EOL> def set_attributes_from_altmetric_post ( self , post ) : <EOL> self . tweet_id = post [ "<STR_LIT>" ] <EOL> self . screen_name = post [ "<STR_LIT>" ] [ "<STR_LIT>" ] <EOL> self . tweet_timestamp = post [ "<STR_LIT>" ] <EOL> if "<STR_LIT>" in post [ "<STR_LIT>" ] : <EOL> self . country = post [ "<STR_LIT>" ] [ "<STR_LIT>" ] . get ( "<STR_LIT>" , None ) <EOL> return self <EOL> def __repr__ ( self ) : <EOL> return u'<STR_LIT>' . format ( <EOL> tweet_id = self . tweet_id , <EOL> profile_id = self . profile_id , <EOL> screen_name = self . screen_name , <EOL> timestamp = self . tweet_timestamp ) <EOL> def to_dict ( self ) : <EOL> attributes_to_ignore = [ <EOL> "<STR_LIT>" <EOL> ] <EOL> ret = dict_from_dir ( self , attributes_to_ignore ) <EOL> return ret <EOL> twitter_example_contents = """<STR_LIT>""" </s>
<s> import os <EOL> import numpy as np <EOL> def load_gender_data ( ntrain = <NUM_LIT> , ntest = <NUM_LIT> ) : <EOL> import pandas as pd <EOL> file_loc = os . path . dirname ( os . path . realpath ( __file__ ) ) <EOL> relative_path = "<STR_LIT>" <EOL> fullpath = os . path . join ( file_loc , relative_path ) <EOL> data = pd . read_csv ( fullpath , nrows = ntrain + ntest ) <EOL> X = data [ '<STR_LIT:text>' ] . values <EOL> X = [ str ( x ) for x in X ] <EOL> Y = data [ '<STR_LIT>' ] . values <EOL> trX = X [ : - ntest ] <EOL> teX = X [ - ntest : ] <EOL> trY = Y [ : - ntest ] <EOL> teY = Y [ - ntest : ] <EOL> return trX , teX , trY , teY <EOL> def load_mnist ( data_dir = None ) : <EOL> if data_dir is None : <EOL> import urllib <EOL> import gzip <EOL> url = '<STR_LIT>' <EOL> fnames = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' <EOL> ] <EOL> for fname in fnames : <EOL> if not os . path . isfile ( fname ) : <EOL> print '<STR_LIT>' , fname <EOL> urllib . urlretrieve ( url + fname , fname ) <EOL> data_dir = '<STR_LIT>' <EOL> fd = gzip . open ( os . path . join ( data_dir , '<STR_LIT>' ) ) <EOL> loaded = np . fromstring ( fd . read ( ) , dtype = np . uint8 ) <EOL> trX = loaded [ <NUM_LIT:16> : ] . reshape ( ( <NUM_LIT> , - <NUM_LIT:1> ) ) <EOL> fd = gzip . open ( os . path . join ( data_dir , '<STR_LIT>' ) ) <EOL> loaded = np . fromstring ( fd . read ( ) , dtype = np . uint8 ) <EOL> trY = loaded [ <NUM_LIT:8> : ] . reshape ( ( <NUM_LIT> ) ) <EOL> fd = gzip . open ( os . path . join ( data_dir , '<STR_LIT>' ) ) <EOL> loaded = np . fromstring ( fd . read ( ) , dtype = np . uint8 ) <EOL> teX = loaded [ <NUM_LIT:16> : ] . reshape ( ( <NUM_LIT> , - <NUM_LIT:1> ) ) <EOL> fd = gzip . open ( os . path . join ( data_dir , '<STR_LIT>' ) ) <EOL> loaded = np . fromstring ( fd . read ( ) , dtype = np . uint8 ) <EOL> teY = loaded [ <NUM_LIT:8> : ] . reshape ( ( <NUM_LIT> ) ) <EOL> trX = trX / <NUM_LIT> <EOL> teX = teX / <NUM_LIT> <EOL> trX = trX . reshape ( - <NUM_LIT:1> , <NUM_LIT> , <NUM_LIT> ) <EOL> teX = teX . reshape ( - <NUM_LIT:1> , <NUM_LIT> , <NUM_LIT> ) <EOL> return trX , teX , trY , teY </s>
<s> import unittest <EOL> import os <EOL> import commands <EOL> from utils import get_temporary_location <EOL> from utils import delete_repository <EOL> from gitpy import LocalRepository <EOL> from gitpy import find_repository <EOL> from gitpy . exceptions import GitException <EOL> class EmptyRepositoryTest ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . dirname = get_temporary_location ( ) <EOL> self . repo = LocalRepository ( self . dirname ) <EOL> self . assertFalse ( os . path . exists ( self . dirname ) ) <EOL> self . assertFalse ( self . repo . isValid ( ) ) <EOL> def tearDown ( self ) : <EOL> if os . path . exists ( self . dirname ) : <EOL> delete_repository ( self . repo ) <EOL> class BasicRepositories ( EmptyRepositoryTest ) : <EOL> def testRepositoryInit ( self ) : <EOL> self . repo . init ( ) <EOL> self . assertTrue ( self . repo . isValid ( ) ) <EOL> self . failUnless ( os . path . isdir ( self . dirname ) ) <EOL> self . failUnless ( os . path . isdir ( os . path . join ( self . dirname , "<STR_LIT>" ) ) ) <EOL> def testConfiguration ( self ) : <EOL> self . repo . init ( ) <EOL> self . repo . config . setParameter ( '<STR_LIT>' , <NUM_LIT:2> ) <EOL> self . assertEquals ( self . repo . config . getParameter ( '<STR_LIT>' ) , '<STR_LIT:2>' ) <EOL> def testRepositoryInitWhenExists ( self ) : <EOL> os . mkdir ( self . dirname ) <EOL> self . repo . init ( ) <EOL> self . failUnless ( os . path . isdir ( self . dirname ) ) <EOL> self . failUnless ( os . path . isdir ( os . path . join ( self . dirname , "<STR_LIT>" ) ) ) <EOL> class ModifiedRepositoryTest ( EmptyRepositoryTest ) : <EOL> FILENAME = "<STR_LIT>" <EOL> def setUp ( self ) : <EOL> super ( ModifiedRepositoryTest , self ) . setUp ( ) <EOL> self . repo . init ( ) <EOL> with open ( os . path . join ( self . repo . path , self . FILENAME ) , "<STR_LIT:wb>" ) as f : <EOL> print >> f , "<STR_LIT>" <EOL> self . assertFalse ( self . repo . isWorkingDirectoryClean ( ) ) <EOL> class ModifiedRepositories ( ModifiedRepositoryTest ) : <EOL> def testStatus ( self ) : <EOL> untracked = self . repo . getUntrackedFiles ( ) <EOL> self . assertEquals ( untracked , [ self . FILENAME ] ) <EOL> def testAdding ( self ) : <EOL> untracked_files = self . repo . getUntrackedFiles ( ) <EOL> for u in untracked_files : <EOL> self . repo . add ( u ) <EOL> self . assertEquals ( self . repo . getStagedFiles ( ) , untracked_files ) <EOL> self . assertFalse ( self . repo . isWorkingDirectoryClean ( ) ) <EOL> def testCommitting ( self ) : <EOL> self . repo . addAll ( ) <EOL> self . assertNotEquals ( self . repo . getStagedFiles ( ) , [ ] ) <EOL> c = self . repo . commit ( message = "<STR_LIT>" ) <EOL> self . assertTrue ( self . repo . isWorkingDirectoryClean ( ) ) <EOL> self . assertEquals ( self . repo . getStagedFiles ( ) , [ ] ) <EOL> class CleaningUntrackedFiles ( ModifiedRepositoryTest ) : <EOL> def _clean ( self ) : <EOL> self . repo . cleanUntrackedFiles ( ) <EOL> self . failIf ( self . repo . getUntrackedFiles ( ) ) <EOL> def testCleaningUpUntrackedFiles ( self ) : <EOL> with open ( os . path . join ( self . repo . path , "<STR_LIT>" ) , "<STR_LIT:wb>" ) as f : <EOL> print >> f , "<STR_LIT:data>" <EOL> self . failUnless ( self . repo . getUntrackedFiles ( ) ) <EOL> self . _clean ( ) <EOL> dirpath = os . path . join ( self . repo . path , "<STR_LIT>" ) <EOL> os . mkdir ( dirpath ) <EOL> self . _clean ( ) <EOL> self . failIf ( os . path . exists ( dirpath ) ) <EOL> class TestAPI ( ModifiedRepositoryTest ) : <EOL> def test_find_repository ( self ) : <EOL> prev_path = os . path . realpath ( "<STR_LIT:.>" ) <EOL> subpath = os . path . join ( self . repo . path , "<STR_LIT:a>" , "<STR_LIT:b>" , "<STR_LIT:c>" ) <EOL> os . makedirs ( subpath ) <EOL> os . chdir ( subpath ) <EOL> try : <EOL> repo = find_repository ( ) <EOL> finally : <EOL> os . chdir ( prev_path ) <EOL> self . failUnless ( repo . path == self . repo . path ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> unittest . main ( ) </s>
<s> import logging <EOL> from okcupyd . db import model , txn , with_txn <EOL> log = logging . getLogger ( __name__ ) <EOL> class UserAdapter ( object ) : <EOL> def __init__ ( self , profile ) : <EOL> self . profile = profile <EOL> def build ( self , session ) : <EOL> found = model . User . query_no_txn ( session , model . User . handle == <EOL> self . profile . username ) <EOL> if found : <EOL> return found [ <NUM_LIT:0> ] <EOL> else : <EOL> return model . User ( okc_id = self . profile . id , <EOL> handle = self . profile . username , <EOL> age = self . profile . age , <EOL> location = self . profile . location ) <EOL> def get_no_txn ( self , session ) : <EOL> return model . User . upsert_one_no_txn ( session , self . build ( session ) , <EOL> id_key = '<STR_LIT>' ) <EOL> get = with_txn ( get_no_txn ) <EOL> class ThreadAdapter ( object ) : <EOL> def __init__ ( self , thread ) : <EOL> self . thread = thread <EOL> def _get_thread ( self , session ) : <EOL> initiator = UserAdapter ( self . thread . initiator ) . get_no_txn ( session ) <EOL> respondent = UserAdapter ( self . thread . respondent ) . get_no_txn ( session ) <EOL> message_thread = model . MessageThread ( okc_id = self . thread . id , <EOL> initiator = initiator , <EOL> respondent = respondent ) <EOL> return model . MessageThread . upsert_one_no_txn ( session , message_thread , <EOL> id_key = '<STR_LIT>' ) <EOL> def _add_messages ( self , thread_model ) : <EOL> existing_message_ids = set ( [ m . okc_id for m in thread_model . messages ] ) <EOL> new_messages = [ message for message in self . thread . messages <EOL> if message . id not in existing_message_ids ] <EOL> new_message_models = [ ] <EOL> for new_message in new_messages : <EOL> from_initiator = thread_model . initiator . handle . lower ( ) == new_message . sender . username . lower ( ) <EOL> sender , recipient = ( thread_model . initiator , <EOL> thread_model . respondent ) if from_initiator else ( thread_model . respondent , <EOL> thread_model . initiator ) <EOL> new_message_model = model . Message ( okc_id = new_message . id , <EOL> text = new_message . content , <EOL> sender = sender , <EOL> recipient = recipient , <EOL> time_sent = new_message . time_sent ) <EOL> new_message_models . append ( new_message_model ) <EOL> thread_model . messages . append ( new_message_model ) <EOL> return new_message_models <EOL> def add_messages ( self ) : <EOL> with txn ( ) as session : <EOL> thread_model = model . MessageThread . find_no_txn ( session , <EOL> self . thread . id , <EOL> id_key = '<STR_LIT>' ) <EOL> return self . _add_messages ( thread_model ) <EOL> def get_thread ( self ) : <EOL> with txn ( ) as session : <EOL> thread_model = self . _get_thread ( session ) <EOL> return thread_model , self . _add_messages ( thread_model ) </s>
<s> import logging <EOL> from invoke import task <EOL> import IPython <EOL> from okcupyd import db <EOL> from okcupyd import util <EOL> from okcupyd . db import mailbox , model <EOL> from okcupyd . user import User <EOL> log = logging . getLogger ( __name__ ) <EOL> @ task ( default = True ) <EOL> def session ( ) : <EOL> with db . txn ( ) as session : <EOL> IPython . embed ( ) <EOL> @ task <EOL> def reset ( ) : <EOL> util . enable_logger ( __name__ ) <EOL> log . info ( db . Base . metadata . bind ) <EOL> db . Base . metadata . drop_all ( ) <EOL> db . Base . metadata . create_all ( ) <EOL> @ task <EOL> def sync ( ) : <EOL> user = User ( ) <EOL> mailbox . Sync ( user ) . all ( ) <EOL> log . info ( model . Message . query ( model . User . okc_id == user . profile . id ) ) <EOL> @ task <EOL> def make ( ) : <EOL> user = User ( ) <EOL> user_model = model . User . from_profile ( user . profile ) <EOL> user_model . upsert_model ( id_key = '<STR_LIT>' ) <EOL> okcupyd_user = model . OKCupydUser ( user_id = user_model . id ) <EOL> okcupyd_user . upsert_model ( id_key = '<STR_LIT>' ) <EOL> return okcupyd_user </s>
<s> from . import util <EOL> from okcupyd import User , photo <EOL> @ util . use_cassette ( path = '<STR_LIT>' , <EOL> match_on = util . match_on_no_body ) <EOL> def test_photo_upload ( ) : <EOL> uploader = photo . PhotoUploader ( ) <EOL> upload_response_dict = uploader . upload_and_confirm ( '<STR_LIT>' ) <EOL> assert int ( upload_response_dict [ '<STR_LIT:id>' ] ) > <NUM_LIT:0> <EOL> @ util . use_cassette ( path = '<STR_LIT>' , match_on = util . match_on_no_body ) <EOL> def test_photo_delete ( ) : <EOL> user = User ( ) <EOL> response_dict = user . photo . upload_and_confirm ( user . quickmatch ( ) . photo_infos [ <NUM_LIT:0> ] ) <EOL> before_delete_photos = user . profile . photo_infos <EOL> user . photo . delete ( response_dict [ '<STR_LIT:id>' ] ) <EOL> user . profile . refresh ( ) <EOL> assert len ( before_delete_photos ) - <NUM_LIT:1> == len ( user . profile . photo_infos ) <EOL> def test_make_photo_uri_from_https_link ( ) : <EOL> photo_info = photo . Info . from_cdn_uri ( <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> ) <EOL> assert photo_info . id == <NUM_LIT> <EOL> assert photo_info . thumb_nail_top == <NUM_LIT> <EOL> @ util . use_cassette <EOL> def test_photo_info_upload ( vcr_live_sleep ) : <EOL> user = User ( ) <EOL> response = user . photo . upload_and_confirm ( user . quickmatch ( ) . photo_infos [ <NUM_LIT:0> ] ) <EOL> vcr_live_sleep ( <NUM_LIT:2> ) <EOL> assert int ( response [ '<STR_LIT:id>' ] ) in [ pi . id for pi in user . profile . photo_infos ] </s>
<s> import theano <EOL> import theano . tensor as T <EOL> from theano . sandbox . rng_mrg import MRG_RandomStreams <EOL> from theano . tensor . nnet . conv import conv2d <EOL> from theano . tensor . signal . downsample import max_pool_2d <EOL> from theano . tensor . shared_randomstreams import RandomStreams <EOL> import numpy as np <EOL> from toolbox import * <EOL> from modelbase import * <EOL> class LM_gru ( ModelLMBase ) : <EOL> def __init__ ( self , data , hp ) : <EOL> super ( LM_gru , self ) . __init__ ( self . __class__ . __name__ , data , hp ) <EOL> self . n_h = <NUM_LIT> <EOL> self . dropout = <NUM_LIT:0.5> <EOL> self . params = Parameters ( ) <EOL> self . hiddenstates = Parameters ( ) <EOL> n_tokens = self . data [ '<STR_LIT>' ] <EOL> n_h = self . n_h <EOL> scale = hp . init_scale <EOL> gates = <NUM_LIT:3> <EOL> with self . hiddenstates : <EOL> b1_h = shared_zeros ( ( self . hp . batch_size , n_h ) ) <EOL> b2_h = shared_zeros ( ( self . hp . batch_size , n_h ) ) <EOL> if hp . load_model and os . path . isfile ( self . filename ) : <EOL> self . params . load ( self . filename ) <EOL> else : <EOL> with self . params : <EOL> W_emb = shared_normal ( ( n_tokens , n_h ) , scale = scale ) <EOL> W1 = shared_normal ( ( n_h , n_h * gates ) , scale = scale * <NUM_LIT> ) <EOL> V1 = shared_normal ( ( n_h , n_h * gates ) , scale = scale * <NUM_LIT> ) <EOL> b1 = shared_zeros ( ( n_h * gates ) ) <EOL> W2 = shared_normal ( ( n_h , n_h * gates ) , scale = scale * <NUM_LIT> ) <EOL> V2 = shared_normal ( ( n_h , n_h * gates ) , scale = scale * <NUM_LIT> ) <EOL> b2 = shared_zeros ( ( n_h * gates , ) ) <EOL> def lstm ( X , h , c , W , U , b ) : <EOL> g_on = T . dot ( X , W ) + T . dot ( h , U ) + b <EOL> i_on = T . nnet . sigmoid ( g_on [ : , : n_h ] ) <EOL> f_on = T . nnet . sigmoid ( g_on [ : , n_h : <NUM_LIT:2> * n_h ] ) <EOL> o_on = T . nnet . sigmoid ( g_on [ : , <NUM_LIT:2> * n_h : <NUM_LIT:3> * n_h ] ) <EOL> c = f_on * c + i_on * T . tanh ( g_on [ : , <NUM_LIT:3> * n_h : ] ) <EOL> h = o_on * T . tanh ( c ) <EOL> return h , c <EOL> def gru ( X , h , W , U , b ) : <EOL> z_t = T . nnet . sigmoid ( T . dot ( X , W [ : , : n_h ] ) + T . dot ( h , U [ : , : n_h ] ) + b [ : n_h ] ) <EOL> r_t = T . nnet . sigmoid ( T . dot ( X , W [ : , n_h : <NUM_LIT:2> * n_h ] ) + T . dot ( h , U [ : , n_h : <NUM_LIT:2> * n_h ] ) + b [ n_h : <NUM_LIT:2> * n_h ] ) <EOL> h_t = T . tanh ( T . dot ( X , W [ : , <NUM_LIT:2> * n_h : <NUM_LIT:3> * n_h ] ) + r_t * T . dot ( h , U [ : , <NUM_LIT:2> * n_h : <NUM_LIT:3> * n_h ] ) + b [ <NUM_LIT:2> * n_h : <NUM_LIT:3> * n_h ] ) <EOL> return ( <NUM_LIT:1> - z_t ) * h + z_t * h_t <EOL> def sgru ( X , h , W , U , b ) : <EOL> z_t = T . tanh ( T . dot ( X , W [ : , : n_h ] ) + T . dot ( h , U [ : , : n_h ] ) + b [ : n_h ] ) <EOL> h_t = T . tanh ( T . dot ( X , W [ : , <NUM_LIT:1> * n_h : <NUM_LIT:2> * n_h ] ) + T . dot ( h , U [ : , <NUM_LIT:1> * n_h : <NUM_LIT:2> * n_h ] ) + b [ <NUM_LIT:1> * n_h : <NUM_LIT:2> * n_h ] ) <EOL> return z_t * h_t <EOL> def model ( x , p , p_dropout ) : <EOL> input_size = x . shape [ <NUM_LIT:1> ] <EOL> h0 = p . W_emb [ x ] <EOL> h0 = dropout ( h0 , p_dropout ) <EOL> cost , h1 , h2 = [ <NUM_LIT:0.> , b1_h , b2_h ] <EOL> for t in xrange ( <NUM_LIT:0> , self . hp . seq_size ) : <EOL> if t >= self . hp . warmup_size : <EOL> pyx = softmax ( T . dot ( dropout ( h2 , p_dropout ) , T . transpose ( p . W_emb ) ) ) <EOL> cost += T . sum ( T . nnet . categorical_crossentropy ( pyx , theano_one_hot ( x [ t ] , n_tokens ) ) ) <EOL> h1 = gru ( h0 [ t ] , h1 , p . W1 , p . V1 , p . b1 ) <EOL> h2 = gru ( dropout ( h1 , p_dropout ) , h2 , p . W2 , p . V2 , p . b2 ) <EOL> h_updates = [ ( b1_h , h1 ) , ( b2_h , h2 ) ] <EOL> return cost , h_updates <EOL> cost , h_updates = model ( self . X , self . params , self . dropout ) <EOL> te_cost , te_h_updates = model ( self . X , self . params , <NUM_LIT:0.> ) <EOL> self . compile ( cost , te_cost , h_updates , te_h_updates ) </s>
<s> """<STR_LIT>""" <EOL> import csv <EOL> import sys <EOL> def csvOutput ( queryResult , separator = '<STR_LIT:U+002C>' , quote = '<STR_LIT:">' ) : <EOL> """<STR_LIT>""" <EOL> csvWriter = csv . writer ( sys . stdout , delimiter = separator , quotechar = quote , <EOL> quoting = csv . QUOTE_MINIMAL ) <EOL> for line in queryResult : <EOL> csvWriter . writerow ( line ) </s>
<s> import sys , os , stat <EOL> import pythoncom <EOL> from win32com . shell import shell , shellcon <EOL> import commctrl <EOL> import winerror <EOL> from win32com . server . util import wrap <EOL> from pywintypes import IID <EOL> IPersist_Methods = [ "<STR_LIT>" ] <EOL> IColumnProvider_Methods = IPersist_Methods + [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] <EOL> class ColumnProvider : <EOL> _reg_progid_ = "<STR_LIT>" <EOL> _reg_desc_ = "<STR_LIT>" <EOL> _reg_clsid_ = IID ( "<STR_LIT>" ) <EOL> _com_interfaces_ = [ pythoncom . IID_IPersist , <EOL> shell . IID_IColumnProvider , <EOL> ] <EOL> _public_methods_ = IColumnProvider_Methods <EOL> def GetClassID ( self ) : <EOL> return self . _reg_clsid_ <EOL> def Initialize ( self , colInit ) : <EOL> flags , reserved , name = colInit <EOL> print "<STR_LIT>" , name <EOL> def GetColumnInfo ( self , index ) : <EOL> if index in [ <NUM_LIT:0> , <NUM_LIT:1> ] : <EOL> if index == <NUM_LIT:0> : <EOL> ext = "<STR_LIT>" <EOL> else : <EOL> ext = "<STR_LIT>" <EOL> title = ext + "<STR_LIT>" <EOL> description = "<STR_LIT>" % ext <EOL> col_id = ( self . _reg_clsid_ , <EOL> index ) <EOL> col_info = ( <EOL> col_id , <EOL> pythoncom . VT_I4 , <EOL> commctrl . LVCFMT_RIGHT , <EOL> <NUM_LIT:20> , <EOL> shellcon . SHCOLSTATE_TYPE_INT | shellcon . SHCOLSTATE_SECONDARYUI , <EOL> title , <EOL> description ) <EOL> return col_info <EOL> return None <EOL> def GetItemData ( self , colid , colData ) : <EOL> fmt_id , pid = colid <EOL> fmt_id == self . _reg_clsid_ <EOL> flags , attr , reserved , ext , name = colData <EOL> if ext . lower ( ) not in [ "<STR_LIT>" , "<STR_LIT>" ] : <EOL> return None <EOL> if pid == <NUM_LIT:0> : <EOL> ext = "<STR_LIT>" <EOL> else : <EOL> ext = "<STR_LIT>" <EOL> check_file = os . path . splitext ( name ) [ <NUM_LIT:0> ] + ext <EOL> try : <EOL> st = os . stat ( check_file ) <EOL> return st [ stat . ST_SIZE ] <EOL> except OSError : <EOL> return None <EOL> def DllRegisterServer ( ) : <EOL> import _winreg <EOL> key = _winreg . CreateKey ( _winreg . HKEY_CLASSES_ROOT , <EOL> "<STR_LIT>" + str ( ColumnProvider . _reg_clsid_ ) ) <EOL> _winreg . SetValueEx ( key , None , <NUM_LIT:0> , _winreg . REG_SZ , ColumnProvider . _reg_desc_ ) <EOL> print ColumnProvider . _reg_desc_ , "<STR_LIT>" <EOL> def DllUnregisterServer ( ) : <EOL> import _winreg <EOL> try : <EOL> key = _winreg . DeleteKey ( _winreg . HKEY_CLASSES_ROOT , <EOL> "<STR_LIT>" + str ( ColumnProvider . _reg_clsid_ ) ) <EOL> except WindowsError , details : <EOL> import errno <EOL> if details . errno != errno . ENOENT : <EOL> raise <EOL> print ColumnProvider . _reg_desc_ , "<STR_LIT>" <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> from win32com . server import register <EOL> register . UseCommandLine ( ColumnProvider , <EOL> finalize_register = DllRegisterServer , <EOL> finalize_unregister = DllUnregisterServer ) </s>
<s> def __load ( ) : <EOL> import imp , os , sys <EOL> try : <EOL> dirname = os . path . dirname ( __loader__ . archive ) <EOL> except NameError : <EOL> dirname = sys . prefix <EOL> path = os . path . join ( dirname , '<STR_LIT>' ) <EOL> mod = imp . load_dynamic ( __name__ , path ) <EOL> __load ( ) <EOL> del __load </s>
<s> import logging <EOL> class LoggerFactory ( object ) : <EOL> _isSetup = False <EOL> def __init__ ( self , level = logging . DEBUG ) : <EOL> if LoggerFactory . _isSetup is False : <EOL> logger = logging . getLogger ( "<STR_LIT>" ) <EOL> logger . setLevel ( level ) <EOL> formatter = logging . Formatter ( '<STR_LIT>' ) <EOL> ch = logging . StreamHandler ( ) <EOL> ch . setLevel ( level ) <EOL> ch . setFormatter ( formatter ) <EOL> logger . addHandler ( ch ) <EOL> LoggerFactory . _isSetup = True <EOL> def getLogger ( self , name , level = logging . DEBUG ) : <EOL> logger = logging . getLogger ( "<STR_LIT>" % name ) <EOL> logger . setLevel ( level ) <EOL> return logger </s>
<s> from . functions import * </s>
<s> from __future__ import division <EOL> import numpy as np <EOL> from pysd import functions <EOL> def time ( ) : <EOL> return _t <EOL> def flowa ( ) : <EOL> """<STR_LIT>""" <EOL> return <NUM_LIT:0.1> <EOL> def stocka ( ) : <EOL> return _state [ '<STR_LIT>' ] <EOL> def _stocka_init ( ) : <EOL> return - <NUM_LIT:5> <EOL> def _dstocka_dt ( ) : <EOL> return flowa ( ) <EOL> def test_exp ( ) : <EOL> """<STR_LIT>""" <EOL> return np . exp ( stocka ( ) ) <EOL> def final_time ( ) : <EOL> """<STR_LIT>""" <EOL> return <NUM_LIT:100> <EOL> def initial_time ( ) : <EOL> """<STR_LIT>""" <EOL> return <NUM_LIT:0> <EOL> def saveper ( ) : <EOL> """<STR_LIT>""" <EOL> return time_step ( ) <EOL> def time_step ( ) : <EOL> """<STR_LIT>""" <EOL> return <NUM_LIT:1> </s>
<s> """<STR_LIT>""" <EOL> __all__ = [ <EOL> '<STR_LIT>' <EOL> ] <EOL> __version__ = '<STR_LIT>' </s>
<s> from myapp import utils <EOL> module_name = utils . getFinalName ( __name__ ) <EOL> module = utils . getModule ( __name__ , subdomain = module_name ) <EOL> import views <EOL> import views . morepages </s>
<s> """<STR_LIT>""" <EOL> import sys <EOL> import os <EOL> import subprocess <EOL> def perform_testing ( config ) : <EOL> requirements = { <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" <EOL> } <EOL> print "<STR_LIT>" <EOL> print canwrite ( config [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) , "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> for req in requirements : <EOL> print checkcommand ( requirements [ req ] ) , req <EOL> sys . exit ( <NUM_LIT:0> ) <EOL> def canwrite ( path ) : <EOL> try : <EOL> ret = booltostatus ( os . access ( path , os . W_OK | os . X_OK ) ) <EOL> except : <EOL> ret = False <EOL> finally : <EOL> return ret <EOL> def booltostatus ( inbool ) : <EOL> if inbool : <EOL> return "<STR_LIT>" <EOL> else : <EOL> return "<STR_LIT>" <EOL> def checkcommand ( com ) : <EOL> proc = subprocess . Popen ( <EOL> [ <EOL> '<STR_LIT>' , <EOL> str ( com ) <EOL> ] , <EOL> stderr = subprocess . PIPE , <EOL> stdout = subprocess . PIPE <EOL> ) <EOL> return booltostatus ( len ( proc . stdout . read ( ) ) > <NUM_LIT:0> ) </s>
<s> """<STR_LIT>""" <EOL> from collections import namedtuple <EOL> from uuid import uuid4 <EOL> from django . http import HttpResponse <EOL> from django . contrib . gis . db . models . query import GeoQuerySet <EOL> from django . contrib . gis . db . models import GeometryField <EOL> from django import forms as f <EOL> import json <EOL> from django . shortcuts import render_to_response <EOL> from ga_ows . views import common <EOL> from ga_ows . utils import MultipleValueField , BBoxField , CaseInsensitiveDict <EOL> from lxml import etree <EOL> from ga_ows . views . common import RequestForm , CommonParameters , GetCapabilitiesMixin <EOL> from osgeo import ogr <EOL> from django . conf import settings <EOL> from tempfile import gettempdir <EOL> from django . db import connections <EOL> import re <EOL> from lxml import etree <EOL> import os <EOL> class InputParameters ( RequestForm ) : <EOL> """<STR_LIT:U+0020>""" <EOL> srs_name = f . CharField ( ) <EOL> input_format = f . CharField ( ) <EOL> srs_format = f . CharField ( required = False ) <EOL> @ classmethod <EOL> def from_request ( cls , request ) : <EOL> request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' , "<STR_LIT>" ) <EOL> class PresentationParameters ( RequestForm ) : <EOL> count = f . IntegerField ( ) <EOL> start_index = f . IntegerField ( ) <EOL> max_features = f . IntegerField ( ) <EOL> output_format = f . CharField ( ) <EOL> @ classmethod <EOL> def from_request ( cls , request ) : <EOL> request [ '<STR_LIT:count>' ] = int ( request . get ( '<STR_LIT:count>' , '<STR_LIT:1>' ) ) <EOL> request [ '<STR_LIT>' ] = int ( request . get ( '<STR_LIT>' , '<STR_LIT:1>' ) ) <EOL> request [ '<STR_LIT>' ] = int ( request . get ( '<STR_LIT>' , '<STR_LIT:1>' ) ) <EOL> request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' , "<STR_LIT>" ) <EOL> class AdHocQueryParameters ( RequestForm ) : <EOL> type_names = MultipleValueField ( ) <EOL> aliases = MultipleValueField ( required = False ) <EOL> filter = f . CharField ( required = False ) <EOL> filter_language = f . CharField ( required = False ) <EOL> resource_id = f . CharField ( required = False ) <EOL> bbox = BBoxField ( ) <EOL> sort_by = f . CharField ( required = False ) <EOL> @ classmethod <EOL> def from_request ( cls , request ) : <EOL> request [ '<STR_LIT>' ] = request . getlist ( '<STR_LIT>' ) <EOL> request [ '<STR_LIT>' ] = request . getlist ( '<STR_LIT>' ) <EOL> request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' ) <EOL> request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' ) <EOL> request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' ) <EOL> request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' ) <EOL> request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' ) <EOL> class StoredQueryParameters ( RequestForm ) : <EOL> stored_query_id = f . CharField ( required = False ) <EOL> @ classmethod <EOL> def from_request ( cls , request ) : <EOL> request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' ) <EOL> class GetFeatureByIdParameters ( RequestForm ) : <EOL> feature_id = f . CharField ( ) <EOL> @ classmethod <EOL> def from_request ( cls , request ) : <EOL> request [ '<STR_LIT>' ] = request . get ( '<STR_LIT:id>' ) <EOL> class ResolveParameters ( RequestForm ) : <EOL> resolve = f . CharField ( required = False ) <EOL> resolve_depth = f . IntegerField ( ) <EOL> resolve_timeout = f . FloatField ( ) <EOL> @ classmethod <EOL> def from_request ( cls , request ) : <EOL> request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' ) <EOL> request [ '<STR_LIT>' ] = int ( request . get ( '<STR_LIT>' , '<STR_LIT:0>' ) ) <EOL> request [ '<STR_LIT>' ] = float ( request . get ( '<STR_LIT>' , '<STR_LIT:0>' ) ) <EOL> class CannotLockAllFeatures ( common . OWSException ) : <EOL> """<STR_LIT>""" <EOL> class DuplicateStoredQueryIdValue ( common . OWSException ) : <EOL> """<STR_LIT>""" <EOL> class DuplicateStoredQueryParameterName ( common . OWSException ) : <EOL> """<STR_LIT>""" <EOL> class FeaturesNotLocked ( common . OWSException ) : <EOL> """<STR_LIT>""" <EOL> class InvalidLockId ( common . OWSException ) : <EOL> """<STR_LIT>""" <EOL> class InvalidValue ( common . OWSException ) : <EOL> """<STR_LIT>""" <EOL> class LockHasExpired ( common . OWSException ) : <EOL> """<STR_LIT>""" <EOL> class OperationParsingFailed ( common . OWSException ) : <EOL> """<STR_LIT>""" <EOL> class OperationProcessingFailed ( common . OWSException ) : <EOL> """<STR_LIT>""" <EOL> class ResponseCacheExpired ( common . OWSException ) : <EOL> """<STR_LIT>""" <EOL> class OperationNotSupported ( common . OWSException ) : <EOL> """<STR_LIT>""" <EOL> FeatureDescription = namedtuple ( '<STR_LIT>' , ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT:name>' , '<STR_LIT:title>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) ) <EOL> StoredQueryParameter = namedtuple ( "<STR_LIT>" , ( '<STR_LIT:type>' , '<STR_LIT:name>' , '<STR_LIT:title>' , '<STR_LIT>' , '<STR_LIT>' ) ) <EOL> StoredQueryExpression = namedtuple ( "<STR_LIT>" , ( '<STR_LIT:text>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) ) <EOL> StoredQueryDescription = namedtuple ( "<STR_LIT>" , ( '<STR_LIT:name>' , '<STR_LIT>' , '<STR_LIT:title>' , '<STR_LIT>' ) ) <EOL> class WFSAdapter ( object ) : <EOL> """<STR_LIT>""" <EOL> def get_feature_descriptions ( self , request , * types ) : <EOL> raise OperationNotSupported . at ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> def list_stored_queries ( self , request ) : <EOL> """<STR_LIT>""" <EOL> queries = dict ( [ ( q [ <NUM_LIT:3> : ] , [ ] ) for q in filter ( lambda x : x . startswith ( "<STR_LIT>" ) , <EOL> reduce ( <EOL> list . __add__ , <EOL> [ c . __dict__ . keys ( ) for c in self . __class__ . mro ( ) ] <EOL> ) <EOL> ) ] ) <EOL> return queries <EOL> def get_features ( self , request , parms ) : <EOL> raise OperationNotSupported . at ( '<STR_LIT>' , "<STR_LIT>" ) <EOL> def supports_feature_versioning ( self ) : <EOL> return False <EOL> class GeoDjangoWFSAdapter ( WFSAdapter ) : <EOL> def __init__ ( self , models ) : <EOL> self . models = { } <EOL> self . srids = { } <EOL> self . geometries = { } <EOL> for model in models : <EOL> self . models [ model . _meta . app_label + "<STR_LIT::>" + model . _meta . object_name ] = model <EOL> for field in model . _meta . fields : <EOL> if isinstance ( field , GeometryField ) : <EOL> self . geometries [ model . _meta . app_label + "<STR_LIT::>" + model . _meta . object_name ] = field <EOL> self . srids [ model . _meta . app_label + "<STR_LIT::>" + model . _meta . object_name ] = field . srid <EOL> def list_stored_queries ( self , request ) : <EOL> sq = super ( GeoDjangoWFSAdapter , self ) . list_stored_queries ( request ) <EOL> fts = list ( self . models . keys ( ) ) <EOL> for k in sq . keys ( ) : <EOL> sq [ k ] = StoredQueryDescription ( name = k , feature_types = fts , title = k , parameters = [ ] ) <EOL> return sq <EOL> def get_feature_descriptions ( self , request , * types ) : <EOL> namespace = request . build_absolute_uri ( ) . split ( '<STR_LIT:?>' ) [ <NUM_LIT:0> ] + "<STR_LIT>" <EOL> for model in self . models . values ( ) : <EOL> if model . objects . count ( ) > <NUM_LIT:0> : <EOL> extent = model . objects . extent ( ) <EOL> else : <EOL> extent = ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> ) <EOL> yield FeatureDescription ( <EOL> ns = namespace , <EOL> ns_name = model . _meta . app_label , <EOL> name = model . _meta . object_name , <EOL> abstract = model . __doc__ , <EOL> title = model . _meta . verbose_name , <EOL> keywords = [ ] , <EOL> srs = self . srids [ model . _meta . app_label + "<STR_LIT::>" + model . _meta . object_name ] , <EOL> bbox = extent , <EOL> schema = namespace <EOL> ) <EOL> def get_features ( self , request , parms ) : <EOL> if parms . cleaned_data [ '<STR_LIT>' ] : <EOL> squid = "<STR_LIT>" + parms . cleaned_data [ '<STR_LIT>' ] <EOL> try : <EOL> return self . __getattribute__ ( squid ) ( request , parms ) <EOL> except AttributeError : <EOL> raise OperationNotSupported . at ( '<STR_LIT>' , '<STR_LIT>' . format ( squid = squid ) ) <EOL> else : <EOL> return self . AdHocQuery ( request , parms ) <EOL> def AdHocQuery ( self , request , parms ) : <EOL> type_names = parms . cleaned_data [ '<STR_LIT>' ] <EOL> flt = parms . cleaned_data [ '<STR_LIT>' ] <EOL> flt_lang = parms . cleaned_data [ '<STR_LIT>' ] <EOL> bbox = parms . cleaned_data [ '<STR_LIT>' ] <EOL> sort_by = parms . cleaned_data [ '<STR_LIT>' ] <EOL> count = parms . cleaned_data [ '<STR_LIT:count>' ] <EOL> if not count : <EOL> count = parms . cleaned_data [ '<STR_LIT>' ] <EOL> start_index = parms . cleaned_data [ '<STR_LIT>' ] <EOL> srs_name = parms . cleaned_data [ '<STR_LIT>' ] <EOL> srs_format = parms . cleaned_data [ '<STR_LIT>' ] <EOL> model = self . models [ type_names [ <NUM_LIT:0> ] ] <EOL> geometry_field = self . geometries [ type_names [ <NUM_LIT:0> ] ] <EOL> query_set = model . objects . all ( ) <EOL> if bbox : <EOL> mnx , mny , mxx , mxy = bbox <EOL> query_set . filter ( ** { geometry_field . name + "<STR_LIT>" : <EOL> "<STR_LIT>" . format ( <EOL> mnx = mnx , <EOL> mny = mny , <EOL> mxx = mxx , <EOL> mxy = mxy ) <EOL> } ) <EOL> if flt : <EOL> flt = json . loads ( flt ) <EOL> query_set = query_set . filter ( ** flt ) <EOL> if sort_by and '<STR_LIT:U+002C>' in sort_by : <EOL> sort_by = sort_by . split ( '<STR_LIT:U+002C>' ) <EOL> query_set = query_set . order_by ( * sort_by ) <EOL> elif sort_by : <EOL> query_set = query_set . order_by ( sort_by ) <EOL> if start_index and count : <EOL> query_set = query_set [ start_index : start_index + count ] <EOL> elif start_index : <EOL> query_set = query_set [ start_index : ] <EOL> elif count : <EOL> query_set = query_set [ : count ] <EOL> if srs_name : <EOL> if ( not srs_format or srs_format == '<STR_LIT>' ) and srs_name != geometry_field . srid : <EOL> if srs_name . lower ( ) . startswith ( '<STR_LIT>' ) : <EOL> srs_name = srs_name [ <NUM_LIT:5> : ] <EOL> query_set . transform ( int ( srs_name ) ) <EOL> return query_set <EOL> def SQ_GetFeatureById ( self , request , parms ) : <EOL> my_parms = GetFeatureByIdParameters . create ( request . REQUEST ) <EOL> typename , pk = my_parms . cleaned_data [ '<STR_LIT>' ] . split ( '<STR_LIT:.>' ) <EOL> return self . models [ typename ] . objects . filter ( pk = int ( pk ) ) <EOL> class WFSBase ( object ) : <EOL> """<STR_LIT>""" <EOL> adapter = None <EOL> class DescribeFeatureTypeMixin ( WFSBase ) : <EOL> """<STR_LIT>""" <EOL> class Parameters ( <EOL> CommonParameters <EOL> ) : <EOL> type_names = MultipleValueField ( ) <EOL> output_format = f . CharField ( ) <EOL> @ classmethod <EOL> def from_request ( cls , request ) : <EOL> request [ '<STR_LIT>' ] = request . getlist ( '<STR_LIT>' ) + request . getlist ( '<STR_LIT>' ) <EOL> request [ '<STR_LIT>' ] = request . get ( '<STR_LIT>' , "<STR_LIT>" ) <EOL> def _parse_xml_DescribeFeatureType ( self , request ) : <EOL> """<STR_LIT>""" <EOL> def add_ns ( it , ns ) : <EOL> x = it . split ( '<STR_LIT::>' ) <EOL> if len ( x ) > <NUM_LIT:1> : <EOL> return ns [ x [ <NUM_LIT:0> ] ] , x [ <NUM_LIT:1> ] <EOL> else : <EOL> return '<STR_LIT>' , x <EOL> root = etree . fromstring ( request ) <EOL> xmlns = root . get ( '<STR_LIT>' ) <EOL> output_format = root . get ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> if xmlns is not None : <EOL> xmlns = "<STR_LIT:{>" + xmlns + "<STR_LIT:}>" <EOL> else : <EOL> xmlns = "<STR_LIT>" <EOL> namespaces = { } <EOL> for name , value in root . attrib . items ( ) : <EOL> if name . startswith ( xmlns ) : <EOL> namespaces [ value ] = name [ len ( xmlns ) : ] <EOL> type_names = root . get ( '<STR_LIT>' ) <EOL> if type_names is not None : <EOL> type_names = [ add_ns ( n , namespaces ) for n in type_names . split ( '<STR_LIT:U+002C>' ) ] <EOL> else : <EOL> type_names = [ ] <EOL> for elt in root : <EOL> if elt . tag . endswith ( "<STR_LIT>" ) : <EOL> namespace , name = elt . text . split ( "<STR_LIT::>" ) <EOL> namespace = namespaces [ namespace ] <EOL> type_names . append ( ( namespace , name ) ) <EOL> if not len ( type_names ) : <EOL> type_names = '<STR_LIT:all>' <EOL> return DescribeFeatureTypeMixin . Parameters . create ( CaseInsensitiveDict ( { "<STR_LIT>" : type_names , "<STR_LIT>" : output_format } ) ) <EOL> def _response_xml_DescribeFeatureType ( self , response ) : <EOL> return render_to_response ( "<STR_LIT>" , { "<STR_LIT>" : list ( response ) } ) <EOL> def _response_json_DescribeFeatureType ( self , response , callback = None ) : <EOL> rsp = [ ] <EOL> for feature_type in response : <EOL> rsp . append ( { <EOL> "<STR_LIT>" : feature_type . schema , <EOL> "<STR_LIT:name>" : feature_type . name , <EOL> "<STR_LIT>" : feature_type . abstract , <EOL> "<STR_LIT:title>" : feature_type . title , <EOL> "<STR_LIT>" : feature_type . ns_name <EOL> } ) <EOL> if callback is not None : <EOL> return HttpResponse ( callback + "<STR_LIT:(>" + json . dumps ( rsp ) + "<STR_LIT:)>" , mimetype = '<STR_LIT>' ) <EOL> else : <EOL> return HttpResponse ( json . dumps ( rsp ) , mimetype = '<STR_LIT:application/json>' ) <EOL> def DescribeFeatureType ( self , request , kwargs ) : <EOL> """<STR_LIT>""" <EOL> if '<STR_LIT>' in kwargs : <EOL> parms = self . _parse_xml_DescribeFeatureType ( kwargs [ '<STR_LIT>' ] ) <EOL> else : <EOL> parms = DescribeFeatureTypeMixin . Parameters . create ( kwargs ) <EOL> response = self . adapter . get_feature_descriptions ( request , * parms . cleaned_data [ '<STR_LIT>' ] ) <EOL> if parms . cleaned_data [ '<STR_LIT>' ] . endswith ( '<STR_LIT>' ) : <EOL> if '<STR_LIT>' in kwargs : <EOL> return self . _response_json_DescribeFeatureType ( response , callback = kwargs [ '<STR_LIT>' ] ) <EOL> elif '<STR_LIT>' in kwargs : <EOL> return self . _response_json_DescribeFeatureType ( response , callback = kwargs [ '<STR_LIT>' ] ) <EOL> else : <EOL> return self . _response_json_DescribeFeatureType ( response ) <EOL> else : <EOL> return self . _response_xml_DescribeFeatureType ( response ) <EOL> class GetFeatureMixin ( WFSBase ) : <EOL> """<STR_LIT>""" <EOL> class Parameters ( <EOL> CommonParameters , <EOL> InputParameters , <EOL> PresentationParameters , <EOL> AdHocQueryParameters , <EOL> StoredQueryParameters <EOL> ) : <EOL> pass <EOL> def _parse_xml_GetFeature ( self , request ) : <EOL> """<STR_LIT:U+0020>""" <EOL> raise OperationNotSupported . at ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> def GetFeature ( self , request , kwargs ) : <EOL> """<STR_LIT:U+0020>""" <EOL> mimetypes = { <EOL> '<STR_LIT>' : '<STR_LIT:application/json>' <EOL> } <EOL> if '<STR_LIT>' in kwargs : <EOL> parms = self . _parse_xml_GetFeature ( kwargs [ '<STR_LIT>' ] ) <EOL> else : <EOL> parms = GetFeatureMixin . Parameters . create ( kwargs ) <EOL> response = self . adapter . get_features ( request , parms ) <EOL> if isinstance ( response , GeoQuerySet ) : <EOL> layer = None <EOL> db_params = settings . DATABASES [ response . db ] <EOL> if db_params [ '<STR_LIT>' ] . endswith ( '<STR_LIT>' ) : <EOL> from psycopg2 . extensions import adapt <EOL> query , parameters = response . query . get_compiler ( response . db ) . as_sql ( ) <EOL> parameters = tuple ( [ adapt ( p ) for p in parameters ] ) <EOL> query = query % parameters <EOL> drv = ogr . GetDriverByName ( "<STR_LIT>" ) <EOL> connection_string = "<STR_LIT>" . format ( db = db_params [ '<STR_LIT>' ] ) <EOL> if '<STR_LIT>' in db_params and db_params [ '<STR_LIT>' ] : <EOL> connection_string += "<STR_LIT>" . format ( host = db_params [ '<STR_LIT>' ] ) <EOL> if '<STR_LIT>' in db_params and db_params [ '<STR_LIT>' ] : <EOL> connection_string += "<STR_LIT>" . format ( port = db_params [ '<STR_LIT>' ] ) <EOL> if '<STR_LIT>' in db_params and db_params [ '<STR_LIT>' ] : <EOL> connection_string += "<STR_LIT>" . format ( user = db_params [ '<STR_LIT>' ] ) <EOL> if '<STR_LIT>' in db_params and db_params [ '<STR_LIT>' ] : <EOL> connection_string += "<STR_LIT>" . format ( password = db_params [ '<STR_LIT>' ] ) <EOL> conn = drv . Open ( connection_string ) <EOL> layer = conn . ExecuteSQL ( query . encode ( '<STR_LIT:ascii>' ) ) <EOL> elif db_params [ '<STR_LIT>' ] . endswith ( '<STR_LIT>' ) : <EOL> from psycopg2 . extensions import adapt <EOL> query , parameters = response . query . get_compiler ( response . db ) . as_sql ( ) <EOL> parameters = tuple ( [ adapt ( p ) for p in parameters ] ) <EOL> query = query % parameters <EOL> drv = ogr . GetDriverByName ( "<STR_LIT>" ) <EOL> conn = drv . Open ( db_params [ '<STR_LIT>' ] ) <EOL> layer = conn . ExecuteSQL ( query ) <EOL> else : <EOL> layer = response . GetLayerByIndex ( <NUM_LIT:0> ) <EOL> drivers = dict ( [ ( ogr . GetDriver ( drv ) . GetName ( ) , ogr . GetDriver ( drv ) ) for drv in range ( ogr . GetDriverCount ( ) ) if ogr . GetDriver ( drv ) . TestCapability ( ogr . ODrCCreateDataSource ) ] ) <EOL> output_format = parms . cleaned_data [ '<STR_LIT>' ] . decode ( '<STR_LIT:ascii>' ) <EOL> if '<STR_LIT>' in output_format or '<STR_LIT>' in output_format : <EOL> tmpname = "<STR_LIT>" . format ( tmpdir = gettempdir ( ) , uuid = uuid4 ( ) , output_format = '<STR_LIT>' , sep = os . path . sep ) <EOL> drv = ogr . GetDriverByName ( "<STR_LIT>" ) <EOL> ds = drv . CreateDataSource ( tmpname ) <EOL> l2 = ds . CopyLayer ( layer , '<STR_LIT>' ) <EOL> l2 . SyncToDisk ( ) <EOL> del ds <EOL> responsef = open ( tmpname ) <EOL> rdata = responsef . read ( ) <EOL> responsef . close ( ) <EOL> os . unlink ( tmpname ) <EOL> return HttpResponse ( rdata , mimetype = output_format ) <EOL> elif output_format in drivers : <EOL> tmpname = "<STR_LIT>" . format ( tmpdir = gettempdir ( ) , uuid = uuid4 ( ) , output_format = output_format , sep = os . path . sep ) <EOL> drv = drivers [ output_format ] <EOL> ds = drv . CreateDataSource ( tmpname ) <EOL> l2 = ds . CopyLayer ( layer , '<STR_LIT>' ) <EOL> l2 . SyncToDisk ( ) <EOL> del ds <EOL> responsef = open ( tmpname ) <EOL> rdata = responsef . read ( ) <EOL> responsef . close ( ) <EOL> os . unlink ( tmpname ) <EOL> return HttpResponse ( rdata , mimetype = mimetypes . get ( output_format , '<STR_LIT>' ) ) <EOL> else : <EOL> raise OperationProcessingFailed . at ( '<STR_LIT>' , '<STR_LIT>' . format ( of = output_format , formats = drivers . keys ( ) ) ) <EOL> class ListStoredQueriesMixin ( WFSBase ) : <EOL> """<STR_LIT>""" <EOL> def ListStoredQueries ( self , request , kwargs ) : <EOL> """<STR_LIT:U+0020>""" <EOL> queries = self . adapter . list_stored_queries ( request ) <EOL> response = etree . Element ( "<STR_LIT>" ) <EOL> for query , description in queries . items ( ) : <EOL> sub = etree . SubElement ( response , "<STR_LIT>" ) <EOL> etree . SubElement ( sub , "<STR_LIT>" ) . text = query <EOL> for feature_type in description . feature_types : <EOL> etree . SubElement ( sub , '<STR_LIT>' ) . text = feature_type <EOL> return HttpResponse ( etree . tostring ( response , pretty_print = True ) , mimetype = '<STR_LIT>' ) <EOL> class DescribeStoredQueriesMixin ( WFSBase ) : <EOL> class Parameters ( CommonParameters ) : <EOL> stored_query_id = MultipleValueField ( ) <EOL> @ classmethod <EOL> def from_request ( cls , request ) : <EOL> request [ '<STR_LIT>' ] = request . getlist ( '<STR_LIT>' ) <EOL> def DescribeStoredQueries ( self , request , kwargs ) : <EOL> parms = DescribeStoredQueriesMixin . Parameters . create ( kwargs ) <EOL> inspected_queries = parms . cleaned_data [ '<STR_LIT>' ] <EOL> response = etree . Element ( '<STR_LIT>' ) <EOL> for query , description in filter ( lambda ( x , y ) : x in inspected_queries , self . adapter . list_stored_queries ( request ) . items ( ) ) : <EOL> desc = etree . SubElement ( response , "<STR_LIT>" ) <EOL> etree . SubElement ( desc , '<STR_LIT>' ) . text = query <EOL> for parameter in description . parameters : <EOL> p = etree . SubElement ( desc , "<STR_LIT>" , attrib = { "<STR_LIT:name>" : parameter . name , "<STR_LIT:type>" : parameter . type } ) <EOL> etree . SubElement ( p , '<STR_LIT>' ) . text = parameter . title <EOL> etree . SubElement ( p , '<STR_LIT>' ) . text = parameter . abstractS <EOL> if parameter . query_expression : <EOL> etree . SubElement ( p , "<STR_LIT>" , attrib = { <EOL> "<STR_LIT>" : parameter . query_expression . private == True , <EOL> "<STR_LIT>" : parameter . query_expression . language , <EOL> "<STR_LIT>" : '<STR_LIT:U+0020>' . join ( parameter . query_expression . return_feature_types ) <EOL> } ) . text = parameter . query_expression . text <EOL> return HttpResponse ( etree . tostring ( response , pretty_print = True ) , mimetype = '<STR_LIT>' ) <EOL> class CreateStoredQuery ( WFSBase ) : <EOL> def CreateStoredQuery ( self , request , kwargs ) : <EOL> raise OperationNotSupported . at ( "<STR_LIT>" ) <EOL> class DropStoredQuery ( WFSBase ) : <EOL> def DropStoredQuery ( self , request , kwargs ) : <EOL> raise OperationNotSupported . at ( "<STR_LIT>" ) <EOL> class TransactionMixin ( WFSBase ) : <EOL> def Transaction ( self , request , kwargs ) : <EOL> """<STR_LIT:U+0020>""" <EOL> raise OperationNotSupported . at ( '<STR_LIT>' ) <EOL> class GetFeatureWithLockMixin ( WFSBase ) : <EOL> def GetFeatureWithLock ( self , request , kwargs ) : <EOL> raise OperationNotSupported . at ( "<STR_LIT>" ) <EOL> class LockFeatureMixin ( WFSBase ) : <EOL> def LockFeature ( self , request , kwargs ) : <EOL> raise OperationNotSupported . at ( '<STR_LIT>' ) <EOL> class GetPropertyValueMixin ( WFSBase ) : <EOL> class Parameters ( StoredQueryParameters , AdHocQueryParameters ) : <EOL> value_reference = f . CharField ( ) <EOL> resolve_path = f . CharField ( required = False ) <EOL> def from_request ( cls , request ) : <EOL> request [ '<STR_LIT>' ] = request [ '<STR_LIT>' ] <EOL> request [ '<STR_LIT>' ] = request [ '<STR_LIT>' ] <EOL> def GetPropertyValue ( self , request , kwargs ) : <EOL> raise OperationNotSupported . at ( '<STR_LIT>' ) <EOL> class WFS ( <EOL> common . OWSView , <EOL> GetCapabilitiesMixin , <EOL> DescribeFeatureTypeMixin , <EOL> DescribeStoredQueriesMixin , <EOL> GetFeatureMixin , <EOL> ListStoredQueriesMixin , <EOL> GetPropertyValueMixin <EOL> ) : <EOL> """<STR_LIT>""" <EOL> adapter = None <EOL> models = None <EOL> title = None <EOL> keywords = [ ] <EOL> fees = None <EOL> access_constraints = None <EOL> provider_name = None <EOL> addr_street = None <EOL> addr_city = None <EOL> addr_admin_area = None <EOL> addr_postcode = None <EOL> addr_country = None <EOL> addr_email = None <EOL> def __init__ ( self , ** kwargs ) : <EOL> common . OWSView . __init__ ( self , ** kwargs ) <EOL> if self . models : <EOL> self . adapter = GeoDjangoWFSAdapter ( self . models ) <EOL> def get_capabilities_response ( self , request , params ) : <EOL> return render_to_response ( '<STR_LIT>' , { <EOL> "<STR_LIT:title>" : self . title , <EOL> "<STR_LIT>" : self . keywords , <EOL> "<STR_LIT>" : self . fees , <EOL> "<STR_LIT>" : self . access_constraints , <EOL> "<STR_LIT>" : request . build_absolute_uri ( ) . split ( '<STR_LIT:?>' ) [ <NUM_LIT:0> ] , <EOL> "<STR_LIT>" : [ ogr . GetDriver ( drv ) . GetName ( ) for drv in range ( ogr . GetDriverCount ( ) ) if ogr . GetDriver ( drv ) . TestCapability ( ogr . ODrCCreateDataSource ) ] , <EOL> "<STR_LIT>" : self . addr_street , <EOL> "<STR_LIT>" : self . addr_city , <EOL> "<STR_LIT>" : self . addr_admin_area , <EOL> "<STR_LIT>" : self . addr_postcode , <EOL> "<STR_LIT>" : self . addr_country , <EOL> "<STR_LIT>" : False , <EOL> "<STR_LIT>" : False , <EOL> '<STR_LIT>' : self . adapter . get_feature_descriptions ( request ) <EOL> } ) <EOL> class WFST ( WFS , TransactionMixin , GetFeatureWithLockMixin , LockFeatureMixin ) : <EOL> """<STR_LIT>""" <EOL> def get_capabilities_response ( self , request , params ) : <EOL> return render_to_response ( '<STR_LIT>' , { <EOL> "<STR_LIT:title>" : self . title , <EOL> "<STR_LIT>" : self . keywords , <EOL> "<STR_LIT>" : self . fees , <EOL> "<STR_LIT>" : self . access_constraints , <EOL> "<STR_LIT>" : request . build_absolute_uri ( ) . split ( '<STR_LIT:?>' ) [ <NUM_LIT:0> ] , <EOL> "<STR_LIT>" : [ ogr . GetDriver ( drv ) . GetName ( ) for drv in range ( ogr . GetDriverCount ( ) ) if ogr . GetDriver ( drv ) . TestCapability ( ogr . ODrCCreateDataSource ) ] , <EOL> "<STR_LIT>" : self . addr_street , <EOL> "<STR_LIT>" : self . addr_city , <EOL> "<STR_LIT>" : self . addr_admin_area , <EOL> "<STR_LIT>" : self . addr_postcode , <EOL> "<STR_LIT>" : self . addr_country , <EOL> "<STR_LIT>" : self . adapter . supports_feature_versioning ( ) , <EOL> "<STR_LIT>" : True , <EOL> '<STR_LIT>' : self . adapter . get_feature_descriptions ( request ) <EOL> } ) </s>
<s> from sondra . document . valuehandlers import DateTime , Geometry , Now <EOL> from shapely . geometry import Point <EOL> from datetime import datetime <EOL> import rethinkdb as r <EOL> import pytest <EOL> from sondra . tests . api import * <EOL> from sondra . auth import Auth <EOL> s = ConcreteSuite ( ) <EOL> api = SimpleApp ( s ) <EOL> auth = Auth ( s ) <EOL> AuthenticatedApp ( s ) <EOL> AuthorizedApp ( s ) <EOL> s . ensure_database_objects ( ) <EOL> @ pytest . fixture ( scope = '<STR_LIT>' ) <EOL> def simple_doc ( request ) : <EOL> simple_doc = s [ '<STR_LIT>' ] [ '<STR_LIT>' ] . create ( { <EOL> '<STR_LIT:name>' : "<STR_LIT>" , <EOL> "<STR_LIT:date>" : datetime . now ( ) , <EOL> "<STR_LIT:value>" : <NUM_LIT:0> <EOL> } ) <EOL> def teardown ( ) : <EOL> simple_doc . delete ( ) <EOL> request . addfinalizer ( teardown ) <EOL> return simple_doc <EOL> @ pytest . fixture ( scope = '<STR_LIT>' ) <EOL> def fk_doc ( request , simple_doc ) : <EOL> fk_doc = s [ '<STR_LIT>' ] [ '<STR_LIT>' ] . create ( { <EOL> '<STR_LIT:name>' : "<STR_LIT>" , <EOL> '<STR_LIT>' : simple_doc , <EOL> '<STR_LIT>' : [ simple_doc ] <EOL> } ) <EOL> def teardown ( ) : <EOL> fk_doc . delete ( ) <EOL> request . addfinalizer ( teardown ) <EOL> return fk_doc <EOL> def test_foreignkey ( fk_doc , simple_doc ) : <EOL> retr_doc = s [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> assert isinstance ( fk_doc . obj [ '<STR_LIT>' ] , str ) <EOL> assert fk_doc . obj [ '<STR_LIT>' ] == simple_doc . url <EOL> assert isinstance ( retr_doc . obj [ '<STR_LIT>' ] , str ) <EOL> assert retr_doc . obj [ '<STR_LIT>' ] == simple_doc . url <EOL> storage_repr = fk_doc . rql_repr ( ) <EOL> assert storage_repr [ '<STR_LIT>' ] == simple_doc . id <EOL> assert isinstance ( fk_doc [ '<STR_LIT>' ] , SimpleDocument ) </s>
<s> import os <EOL> from PySide . QtGui import * <EOL> from PySide . QtCore import * <EOL> from ui_Event import Ui_Event <EOL> '''<STR_LIT>''' <EOL> class EventWindow ( QDialog , Ui_Event ) : <EOL> def __init__ ( self , parent , eventId ) : <EOL> super ( EventWindow , self ) . __init__ ( parent ) <EOL> self . rent = parent <EOL> self . data = parent . eventData [ eventId ] <EOL> self . deckAssignment = [ ] <EOL> self . setupUi ( self ) <EOL> self . assignWidgets ( ) <EOL> self . setWindowTitle ( unicode ( "<STR_LIT>" % eventId ) ) <EOL> def savePressed ( self ) : <EOL> self . data [ "<STR_LIT>" ] = self . notesText . toPlainText ( ) <EOL> self . data [ "<STR_LIT>" ] = self . deckText . text ( ) <EOL> self . data [ "<STR_LIT>" ] = self . placeText . text ( ) <EOL> self . data [ "<STR_LIT>" ] = self . eventTypeText . text ( ) <EOL> self . data [ "<STR_LIT>" ] = self . playersText . text ( ) <EOL> self . data [ "<STR_LIT>" ] = self . formatText . text ( ) <EOL> self . data [ "<STR_LIT>" ] = self . locationText . text ( ) <EOL> self . data [ "<STR_LIT>" ] = self . dateText . text ( ) <EOL> ourCounter = <NUM_LIT:0> <EOL> for ourRound in self . deckAssignment : <EOL> self . data [ "<STR_LIT>" ] [ self . deckAssignment [ ourCounter ] [ <NUM_LIT:0> ] ] [ <NUM_LIT:2> ] = self . deckAssignment [ ourCounter ] [ <NUM_LIT:1> ] <EOL> ourCounter += <NUM_LIT:1> <EOL> self . rent . updateGUI ( ) <EOL> self . rent . messageBox ( "<STR_LIT>" ) <EOL> def closePressed ( self ) : <EOL> self . hide ( ) <EOL> def roundSelected ( self , ourRound , ourColumn ) : <EOL> ourIndex = int ( ourRound . text ( <NUM_LIT:0> ) ) - <NUM_LIT:1> <EOL> deckName , ok = QInputDialog . getText ( self , "<STR_LIT>" , <EOL> "<STR_LIT>" ) <EOL> if ok and deckName : <EOL> self . data [ "<STR_LIT>" ] [ ourIndex ] [ <NUM_LIT:3> ] . setData ( <NUM_LIT:3> , <NUM_LIT:0> , deckName ) <EOL> self . deckAssignment . append ( [ ourIndex , deckName ] ) <EOL> def assignWidgets ( self ) : <EOL> self . saveChangesButton . clicked . connect ( self . savePressed ) <EOL> self . closeButton . clicked . connect ( self . closePressed ) <EOL> self . roundTree . itemDoubleClicked . connect ( self . roundSelected ) <EOL> self . notesText . setPlainText ( self . data [ "<STR_LIT>" ] ) <EOL> self . deckText . setText ( self . data [ "<STR_LIT>" ] ) <EOL> self . placeText . setText ( self . data [ "<STR_LIT>" ] ) <EOL> self . eventTypeText . setText ( self . data [ "<STR_LIT>" ] ) <EOL> self . playersText . setText ( self . data [ "<STR_LIT>" ] ) <EOL> self . formatText . setText ( self . data [ "<STR_LIT>" ] ) <EOL> self . locationText . setText ( self . data [ "<STR_LIT>" ] ) <EOL> self . dateText . setText ( self . data [ "<STR_LIT>" ] ) <EOL> matchItem = TreeWidgetItem ( self . resultsTree ) <EOL> matchItem . setText ( <NUM_LIT:0> , unicode ( self . data [ "<STR_LIT>" ] ) ) <EOL> matchItem . setText ( <NUM_LIT:1> , unicode ( self . data [ "<STR_LIT>" ] ) ) <EOL> matchItem . setText ( <NUM_LIT:2> , unicode ( self . data [ "<STR_LIT>" ] ) ) <EOL> matchItem . setText ( <NUM_LIT:3> , unicode ( self . data [ "<STR_LIT>" ] ) ) <EOL> self . resultsTree . addTopLevelItem ( matchItem ) <EOL> for i in range ( <NUM_LIT:4> ) : <EOL> self . resultsTree . resizeColumnToContents ( i ) <EOL> roundCounter = <NUM_LIT:1> <EOL> for opponent in self . data [ "<STR_LIT>" ] : <EOL> roundItem = TreeWidgetItem ( self . roundTree ) <EOL> roundItem . setText ( <NUM_LIT:0> , unicode ( roundCounter ) ) <EOL> roundItem . setText ( <NUM_LIT:1> , unicode ( opponent [ <NUM_LIT:0> ] ) ) <EOL> roundItem . setText ( <NUM_LIT:2> , unicode ( opponent [ <NUM_LIT:1> ] ) ) <EOL> roundItem . setText ( <NUM_LIT:3> , unicode ( opponent [ <NUM_LIT:2> ] ) ) <EOL> opponent [ <NUM_LIT:3> ] = roundItem <EOL> self . roundTree . addTopLevelItem ( roundItem ) <EOL> roundCounter += <NUM_LIT:1> <EOL> for i in range ( <NUM_LIT:4> ) : <EOL> self . roundTree . resizeColumnToContents ( i ) <EOL> class TreeWidgetItem ( QTreeWidgetItem ) : <EOL> def __init__ ( self , parent = None ) : <EOL> QTreeWidgetItem . __init__ ( self , parent ) <EOL> def __lt__ ( self , otherItem ) : <EOL> column = self . treeWidget ( ) . sortColumn ( ) <EOL> try : <EOL> return float ( self . text ( column ) ) > float ( otherItem . text ( column ) ) <EOL> except ValueError : <EOL> return self . text ( column ) > otherItem . text ( column ) </s>
<s> """<STR_LIT>""" <EOL> import numpy as np <EOL> from pylatex import Document , Section , Subsection , Math , Matrix , VectorName <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> a = np . array ( [ [ <NUM_LIT:100> , <NUM_LIT:10> , <NUM_LIT:20> ] ] ) . T <EOL> doc = Document ( ) <EOL> section = Section ( '<STR_LIT>' ) <EOL> subsection = Subsection ( '<STR_LIT>' ) <EOL> vec = Matrix ( a ) <EOL> vec_name = VectorName ( '<STR_LIT:a>' ) <EOL> math = Math ( data = [ vec_name , '<STR_LIT:=>' , vec ] ) <EOL> subsection . append ( math ) <EOL> section . append ( subsection ) <EOL> subsection = Subsection ( '<STR_LIT>' ) <EOL> M = np . matrix ( [ [ <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ] , <EOL> [ <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1> ] , <EOL> [ <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:2> ] ] ) <EOL> matrix = Matrix ( M , mtype = '<STR_LIT:b>' ) <EOL> math = Math ( data = [ '<STR_LIT>' , matrix ] ) <EOL> subsection . append ( math ) <EOL> section . append ( subsection ) <EOL> subsection = Subsection ( '<STR_LIT>' ) <EOL> math = Math ( data = [ '<STR_LIT:M>' , vec_name , '<STR_LIT:=>' , Matrix ( M * a ) ] ) <EOL> subsection . append ( math ) <EOL> section . append ( subsection ) <EOL> doc . append ( section ) <EOL> doc . generate_pdf ( '<STR_LIT>' ) </s>
<s> import quantities as pq <EOL> from pylatex . quantities import _dimensionality_to_siunitx , Quantity <EOL> def test_quantity ( ) : <EOL> v = <NUM_LIT:1> * pq . m / pq . s <EOL> q1 = Quantity ( v ) <EOL> assert q1 . dumps ( ) == r'<STR_LIT>' <EOL> q2 = Quantity ( v , format_cb = lambda x : str ( int ( x ) ) ) <EOL> assert q2 . dumps ( ) == r'<STR_LIT>' <EOL> q3 = Quantity ( v , options = { '<STR_LIT>' : '<STR_LIT:true>' } ) <EOL> ref = r'<STR_LIT>' <EOL> assert q3 . dumps ( ) == ref <EOL> def test_quantity_float ( ) : <EOL> q1 = Quantity ( <NUM_LIT> ) <EOL> assert q1 . dumps ( ) == r'<STR_LIT>' <EOL> def test_quantity_uncertain ( ) : <EOL> t = pq . UncertainQuantity ( <NUM_LIT> , pq . second , <NUM_LIT:1.> ) <EOL> q1 = Quantity ( t ) <EOL> assert q1 . dumps ( ) == r'<STR_LIT>' <EOL> def test_dimensionality_to_siunitx ( ) : <EOL> assert _dimensionality_to_siunitx ( ( pq . volt / pq . kelvin ) . dimensionality ) == r'<STR_LIT>' <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> test_quantity ( ) <EOL> test_dimensionality_to_siunitx ( ) </s>
<s> from supervisor . medusa import asyncore_25 as asyncore <EOL> from supervisor . medusa import default_handler <EOL> from supervisor . medusa import http_server <EOL> from supervisor . medusa import put_handler <EOL> from supervisor . medusa import auth_handler <EOL> from supervisor . medusa import filesys <EOL> users = { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } <EOL> fs = filesys . os_filesystem ( '<STR_LIT>' ) <EOL> dh = default_handler . default_handler ( fs ) <EOL> ph = put_handler . put_handler ( fs , '<STR_LIT>' ) <EOL> ah = auth_handler . auth_handler ( users , ph ) <EOL> hs = http_server . http_server ( ip = '<STR_LIT>' , port = <NUM_LIT> ) <EOL> hs . install_handler ( dh ) <EOL> hs . install_handler ( ah ) <EOL> asyncore . loop ( ) </s>
<s> import socket <EOL> import string <EOL> from supervisor . medusa import asyncore_25 as asyncore <EOL> from supervisor . medusa import asynchat_25 as asynchat <EOL> class test_client ( asynchat . async_chat ) : <EOL> ac_in_buffer_size = <NUM_LIT> <EOL> ac_out_buffer_size = <NUM_LIT> <EOL> total_in = <NUM_LIT:0> <EOL> concurrent = <NUM_LIT:0> <EOL> max_concurrent = <NUM_LIT:0> <EOL> def __init__ ( self , addr , chain ) : <EOL> asynchat . async_chat . __init__ ( self ) <EOL> self . create_socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> self . set_terminator ( '<STR_LIT>' ) <EOL> self . connect ( addr ) <EOL> self . push ( chain ) <EOL> def handle_connect ( self ) : <EOL> test_client . concurrent = test_client . concurrent + <NUM_LIT:1> <EOL> if ( test_client . concurrent > test_client . max_concurrent ) : <EOL> test_client . max_concurrent = test_client . concurrent <EOL> def handle_expt ( self ) : <EOL> print '<STR_LIT>' <EOL> self . close ( ) <EOL> def close ( self ) : <EOL> test_client . concurrent = test_client . concurrent - <NUM_LIT:1> <EOL> asynchat . async_chat . close ( self ) <EOL> def collect_incoming_data ( self , data ) : <EOL> test_client . total_in = test_client . total_in + len ( data ) <EOL> def found_terminator ( self ) : <EOL> pass <EOL> def log ( self , * args ) : <EOL> pass <EOL> import time <EOL> class timer : <EOL> def __init__ ( self ) : <EOL> self . start = time . time ( ) <EOL> def end ( self ) : <EOL> return time . time ( ) - self . start <EOL> def build_request_chain ( num , host , request_size ) : <EOL> s = '<STR_LIT>' % ( request_size , host ) <EOL> sl = [ s ] * ( num - <NUM_LIT:1> ) <EOL> sl . append ( <EOL> '<STR_LIT>' % ( <EOL> request_size , host <EOL> ) <EOL> ) <EOL> return string . join ( sl , '<STR_LIT>' ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> import string <EOL> import sys <EOL> if len ( sys . argv ) != <NUM_LIT:6> : <EOL> print '<STR_LIT>' % sys . argv [ <NUM_LIT:0> ] <EOL> else : <EOL> host = sys . argv [ <NUM_LIT:1> ] <EOL> ip = socket . gethostbyname ( host ) <EOL> [ port , request_size , num_requests , num_conns ] = map ( <EOL> string . atoi , sys . argv [ <NUM_LIT:2> : ] <EOL> ) <EOL> chain = build_request_chain ( num_requests , host , request_size ) <EOL> t = timer ( ) <EOL> for i in range ( num_conns ) : <EOL> test_client ( ( host , port ) , chain ) <EOL> asyncore . loop ( ) <EOL> total_time = t . end ( ) <EOL> total_bytes = test_client . total_in <EOL> num_trans = num_requests * num_conns <EOL> throughput = float ( total_bytes ) / total_time <EOL> trans_per_sec = num_trans / total_time <EOL> sys . stderr . write ( '<STR_LIT>' % total_time ) <EOL> sys . stderr . write ( '<STR_LIT>' % num_trans ) <EOL> sys . stderr . write ( '<STR_LIT>' % total_bytes ) <EOL> sys . stderr . write ( '<STR_LIT>' % throughput ) <EOL> sys . stderr . write ( '<STR_LIT>' % trans_per_sec ) <EOL> sys . stderr . write ( '<STR_LIT>' % test_client . max_concurrent ) <EOL> sys . stdout . write ( <EOL> string . join ( <EOL> map ( str , ( num_conns , num_requests , request_size , throughput , trans_per_sec ) ) , <EOL> '<STR_LIT:U+002C>' <EOL> ) + '<STR_LIT:\n>' <EOL> ) </s>
<s> from os import * <EOL> from os import _exit <EOL> import os <EOL> class FakeOS : <EOL> def __init__ ( self ) : <EOL> self . orig_uid = os . getuid ( ) <EOL> self . orig_gid = os . getgid ( ) <EOL> def setgroups ( * args ) : <EOL> return <EOL> def getuid ( ) : <EOL> return <NUM_LIT:0> <EOL> def setuid ( arg ) : <EOL> self . uid = arg <EOL> self . setuid_called = <NUM_LIT:1> <EOL> def setgid ( arg ) : <EOL> self . gid = arg <EOL> self . setgid_called = <NUM_LIT:1> <EOL> def clear ( ) : <EOL> self . uid = orig_uid <EOL> self . gid = orig_gid <EOL> self . setuid_called = <NUM_LIT:0> <EOL> self . setgid_called = <NUM_LIT:0> <EOL> fake = FakeOS ( ) <EOL> setgroups = fake . setgroups <EOL> getuid = fake . getuid <EOL> setuid = fake . setuid <EOL> setgid = fake . setgid <EOL> clear = fake . clear </s>
<s> import toto <EOL> from toto . invocation import * <EOL> from tornado . ioloop import IOLoop <EOL> @ asynchronous <EOL> def invoke ( handler , params ) : <EOL> def receive_message ( message ) : <EOL> handler . respond ( result = { '<STR_LIT:message>' : message } ) <EOL> handler . register_event_handler ( '<STR_LIT:message>' , receive_message , deregister_on_finish = True ) </s>
<s> import unittest <EOL> from uuid import uuid4 <EOL> from time import time , sleep <EOL> from toto . tasks import TaskQueue , AwaitableInstance , InstancePool <EOL> from tornado . ioloop import IOLoop <EOL> from tornado . gen import coroutine <EOL> class _Instance ( object ) : <EOL> def __init__ ( self ) : <EOL> self . counter = <NUM_LIT:0> <EOL> def increment ( self ) : <EOL> self . counter += <NUM_LIT:1> <EOL> return self . counter <EOL> def value ( self ) : <EOL> return self . counter <EOL> class TestTasks ( unittest . TestCase ) : <EOL> def test_add_task ( self ) : <EOL> queue = TaskQueue ( ) <EOL> self . assertEquals ( len ( queue ) , <NUM_LIT:0> ) <EOL> task_results = [ ] <EOL> task = lambda x : task_results . append ( x ) <EOL> queue . add_task ( task , <NUM_LIT:1> ) <EOL> queue . add_task ( task , <NUM_LIT:2> ) <EOL> queue . add_task ( task , <NUM_LIT:3> ) <EOL> start = time ( ) <EOL> while <NUM_LIT:1> : <EOL> if len ( task_results ) == <NUM_LIT:3> : <EOL> break <EOL> if time ( ) - start > <NUM_LIT:5> : <EOL> break <EOL> sleep ( <NUM_LIT> ) <EOL> self . assertEquals ( len ( task_results ) , <NUM_LIT:3> ) <EOL> self . assertEquals ( task_results , [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ) <EOL> def test_yield_task ( self ) : <EOL> queue = TaskQueue ( ) <EOL> task_results = [ ] <EOL> @ coroutine <EOL> def yield_tasks ( ) : <EOL> task = lambda x : x <EOL> futures = [ ] <EOL> futures . append ( queue . yield_task ( task , <NUM_LIT:1> ) ) <EOL> futures . append ( queue . yield_task ( task , <NUM_LIT:2> ) ) <EOL> futures . append ( queue . yield_task ( task , <NUM_LIT:3> ) ) <EOL> res = yield futures <EOL> task_results [ : ] = res <EOL> loop = IOLoop ( ) <EOL> loop . make_current ( ) <EOL> loop . run_sync ( yield_tasks ) <EOL> self . assertEquals ( len ( task_results ) , <NUM_LIT:3> ) <EOL> self . assertEquals ( task_results , [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ) <EOL> def test_add_task_exception ( self ) : <EOL> queue = TaskQueue ( ) <EOL> self . assertEquals ( len ( queue ) , <NUM_LIT:0> ) <EOL> task_results = [ ] <EOL> def task ( x ) : <EOL> task_results . append ( x ) <EOL> raise Exception ( '<STR_LIT>' ) <EOL> queue . add_task ( task , <NUM_LIT:1> ) <EOL> queue . add_task ( task , <NUM_LIT:2> ) <EOL> queue . add_task ( task , <NUM_LIT:3> ) <EOL> start = time ( ) <EOL> while <NUM_LIT:1> : <EOL> if len ( task_results ) == <NUM_LIT:3> : <EOL> break <EOL> if time ( ) - start > <NUM_LIT:5> : <EOL> break <EOL> sleep ( <NUM_LIT> ) <EOL> self . assertEquals ( len ( task_results ) , <NUM_LIT:3> ) <EOL> self . assertEquals ( task_results , [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ) <EOL> def test_yield_task_exception ( self ) : <EOL> queue = TaskQueue ( ) <EOL> task_results = [ ] <EOL> @ coroutine <EOL> def yield_tasks ( ) : <EOL> def task ( x ) : <EOL> raise Exception ( '<STR_LIT>' ) <EOL> futures = [ ] <EOL> futures . append ( queue . yield_task ( task , <NUM_LIT:1> ) ) <EOL> futures . append ( queue . yield_task ( task , <NUM_LIT:2> ) ) <EOL> futures . append ( queue . yield_task ( task , <NUM_LIT:3> ) ) <EOL> for f in futures : <EOL> try : <EOL> yield f <EOL> except Exception as e : <EOL> task_results . append ( e ) <EOL> loop = IOLoop ( ) <EOL> loop . make_current ( ) <EOL> loop . run_sync ( yield_tasks ) <EOL> self . assertEquals ( len ( task_results ) , <NUM_LIT:3> ) <EOL> for e in task_results : <EOL> self . assertEquals ( e . message , '<STR_LIT>' ) <EOL> def test_awaitable ( self ) : <EOL> instance = _Instance ( ) <EOL> instance . increment ( ) <EOL> self . assertEquals ( instance . value ( ) , <NUM_LIT:1> ) <EOL> awaitable = AwaitableInstance ( instance ) <EOL> @ coroutine <EOL> def yield_tasks ( ) : <EOL> self . assertEquals ( ( yield awaitable . increment ( ) ) , <NUM_LIT:2> ) <EOL> self . assertEquals ( ( yield awaitable . increment ( ) ) , <NUM_LIT:3> ) <EOL> self . assertEquals ( ( yield awaitable . increment ( ) ) , <NUM_LIT:4> ) <EOL> self . assertEquals ( ( yield awaitable . value ( ) ) , <NUM_LIT:4> ) <EOL> loop = IOLoop ( ) <EOL> loop . make_current ( ) <EOL> loop . run_sync ( yield_tasks ) <EOL> self . assertEquals ( instance . value ( ) , <NUM_LIT:4> ) <EOL> def test_instance_pool ( self ) : <EOL> instance1 = _Instance ( ) <EOL> instance2 = _Instance ( ) <EOL> pool = InstancePool ( [ instance1 , instance2 ] ) <EOL> pool . increment ( ) <EOL> pool . increment ( ) <EOL> self . assertEquals ( instance1 . value ( ) , <NUM_LIT:1> ) <EOL> self . assertEquals ( instance2 . value ( ) , <NUM_LIT:1> ) <EOL> pool . transaction ( lambda i : i . increment ( ) ) <EOL> pool . transaction ( lambda i : i . increment ( ) ) <EOL> self . assertEquals ( instance1 . value ( ) , <NUM_LIT:2> ) <EOL> self . assertEquals ( instance2 . value ( ) , <NUM_LIT:2> ) <EOL> @ coroutine <EOL> def yield_tasks ( ) : <EOL> self . assertEquals ( ( yield pool . await ( ) . increment ( ) ) , <NUM_LIT:3> ) <EOL> self . assertEquals ( ( yield pool . await ( ) . increment ( ) ) , <NUM_LIT:3> ) <EOL> self . assertEquals ( instance1 . value ( ) , <NUM_LIT:3> ) <EOL> self . assertEquals ( instance2 . value ( ) , <NUM_LIT:3> ) <EOL> self . assertEquals ( ( yield pool . await_transaction ( lambda i : i . increment ( ) ) ) , <NUM_LIT:4> ) <EOL> self . assertEquals ( ( yield pool . await_transaction ( lambda i : i . increment ( ) ) ) , <NUM_LIT:4> ) <EOL> loop = IOLoop ( ) <EOL> loop . make_current ( ) <EOL> loop . run_sync ( yield_tasks ) <EOL> self . assertEquals ( instance1 . value ( ) , <NUM_LIT:4> ) <EOL> self . assertEquals ( instance2 . value ( ) , <NUM_LIT:4> ) </s>
<s> '''<STR_LIT>''' <EOL> import cPickle as pickle <EOL> from threading import Thread <EOL> from collections import deque <EOL> from tornado . web import * <EOL> from tornado . ioloop import IOLoop <EOL> from traceback import format_exc <EOL> from tornado . options import options <EOL> import zmq <EOL> import logging <EOL> import zlib <EOL> from random import choice , shuffle <EOL> class EventManager ( ) : <EOL> '''<STR_LIT>''' <EOL> def __init__ ( self , address = None ) : <EOL> self . __handlers = { } <EOL> self . address = address <EOL> self . __zmq_context = zmq . Context ( ) <EOL> self . __remote_servers = { } <EOL> self . __thread = None <EOL> self . __queued_servers = deque ( ) <EOL> def register_server ( self , address ) : <EOL> '''<STR_LIT>''' <EOL> if address in self . __remote_servers : <EOL> raise Exception ( '<STR_LIT>' , address ) <EOL> socket = self . __zmq_context . socket ( zmq . PUSH ) <EOL> socket . connect ( address ) <EOL> self . __remote_servers [ address ] = socket <EOL> self . refresh_server_queue ( ) <EOL> def remove_server ( self , address ) : <EOL> '''<STR_LIT>''' <EOL> del self . __remote_servers [ address ] <EOL> self . refresh_server_queue ( ) <EOL> def remove_all_servers ( self ) : <EOL> '''<STR_LIT>''' <EOL> self . __remote_servers . clear ( ) <EOL> self . refresh_server_queue ( ) <EOL> def refresh_server_queue ( self ) : <EOL> '''<STR_LIT>''' <EOL> self . __queued_servers . clear ( ) <EOL> self . __queued_servers . extend ( self . __remote_servers . itervalues ( ) ) <EOL> shuffle ( self . __queued_servers ) <EOL> def register_handler ( self , event_name , event_handler , run_on_main_loop = False , request_handler = None , persist = False ) : <EOL> '''<STR_LIT>''' <EOL> if not event_name in self . __handlers : <EOL> self . __handlers [ event_name ] = set ( ) <EOL> handler_tuple = ( event_handler , run_on_main_loop , request_handler , persist ) <EOL> self . __handlers [ event_name ] . add ( handler_tuple ) <EOL> return ( event_name , handler_tuple ) <EOL> def remove_handler ( self , handler_sig ) : <EOL> '''<STR_LIT>''' <EOL> self . __handlers [ handler_sig [ <NUM_LIT:0> ] ] . discard ( handler_sig [ <NUM_LIT:1> ] ) <EOL> def start_listening ( self ) : <EOL> '''<STR_LIT>''' <EOL> if self . __thread : <EOL> return <EOL> def receive ( ) : <EOL> context = zmq . Context ( ) <EOL> socket = context . socket ( zmq . PULL ) <EOL> socket . bind ( self . address ) <EOL> while True : <EOL> event = pickle . loads ( zlib . decompress ( socket . recv ( ) ) ) <EOL> event_name = event [ '<STR_LIT:name>' ] <EOL> event_args = event [ '<STR_LIT:args>' ] <EOL> if event_name in self . __handlers : <EOL> handlers = self . __handlers [ event_name ] <EOL> for handler in list ( handlers ) : <EOL> if not handler [ <NUM_LIT:3> ] : <EOL> handlers . remove ( handler ) <EOL> try : <EOL> if handler [ <NUM_LIT:2> ] and handler [ <NUM_LIT:2> ] . _finished : <EOL> continue <EOL> if handler [ <NUM_LIT:1> ] : <EOL> ( lambda h : IOLoop . instance ( ) . add_callback ( lambda : h [ <NUM_LIT:0> ] ( event_args ) ) ) ( handler ) <EOL> else : <EOL> handler [ <NUM_LIT:0> ] ( event_args ) <EOL> except Exception as e : <EOL> logging . error ( format_exc ( ) ) <EOL> self . __thread = Thread ( target = receive ) <EOL> self . __thread . daemon = True <EOL> self . __thread . start ( ) <EOL> def send_to_server ( self , address , event_name , event_args ) : <EOL> '''<STR_LIT>''' <EOL> event = { '<STR_LIT:name>' : event_name , '<STR_LIT:args>' : event_args } <EOL> event_data = zlib . compress ( pickle . dumps ( event ) ) <EOL> self . __remote_servers [ address ] . send ( event_data ) <EOL> def send ( self , event_name , event_args , broadcast = True ) : <EOL> '''<STR_LIT>''' <EOL> if not self . __remote_servers : <EOL> return <EOL> event = { '<STR_LIT:name>' : event_name , '<STR_LIT:args>' : event_args } <EOL> event_data = zlib . compress ( pickle . dumps ( event ) ) <EOL> if not broadcast : <EOL> self . __queued_servers [ <NUM_LIT:0> ] . send ( event_data ) <EOL> self . __queued_servers . rotate ( - <NUM_LIT:1> ) <EOL> return <EOL> for socket in self . __queued_servers : <EOL> socket . send ( event_data ) <EOL> @ classmethod <EOL> def instance ( cls ) : <EOL> '''<STR_LIT>''' <EOL> if not hasattr ( cls , '<STR_LIT>' ) : <EOL> cls . _instance = cls ( ) <EOL> return cls . _instance </s>
<s> import toto <EOL> import cPickle as pickle <EOL> import zlib <EOL> import logging <EOL> from threading import Thread <EOL> from tornado . options import options <EOL> from tornado . gen import Task <EOL> from collections import deque <EOL> from time import time <EOL> from uuid import uuid4 <EOL> from traceback import format_exc <EOL> from toto . options import safe_define <EOL> safe_define ( "<STR_LIT>" , type = str , help = "<STR_LIT>" ) <EOL> safe_define ( "<STR_LIT>" , type = str , help = "<STR_LIT>" ) <EOL> safe_define ( "<STR_LIT>" , type = str , default = '<STR_LIT>' , help = "<STR_LIT>" ) <EOL> safe_define ( "<STR_LIT>" , default = <NUM_LIT> , help = "<STR_LIT>" ) <EOL> safe_define ( "<STR_LIT>" , default = False , help = "<STR_LIT>" ) <EOL> safe_define ( "<STR_LIT>" , default = <NUM_LIT:0> , help = "<STR_LIT>" ) <EOL> safe_define ( "<STR_LIT>" , default = '<STR_LIT>' , help = "<STR_LIT>" ) <EOL> safe_define ( "<STR_LIT>" , default = '<STR_LIT>' , help = "<STR_LIT>" ) <EOL> WORKER_SOCKET_CONNECT = '<STR_LIT>' <EOL> WORKER_SOCKET_DISCONNECT = '<STR_LIT>' <EOL> class WorkerConnection ( object ) : <EOL> '''<STR_LIT>''' <EOL> def __getattr__ ( self , path ) : <EOL> return WorkerInvocation ( path , self ) <EOL> def log_error ( self , error ) : <EOL> logging . error ( repr ( error ) ) <EOL> def enable_traceback_logging ( self ) : <EOL> from new import instancemethod <EOL> from traceback import format_exc <EOL> def log_error ( self , e ) : <EOL> logging . error ( format_exc ( ) ) <EOL> self . log_error = instancemethod ( log_error , self ) <EOL> @ classmethod <EOL> def instance ( cls ) : <EOL> '''<STR_LIT>''' <EOL> if not hasattr ( cls , '<STR_LIT>' ) : <EOL> if options . worker_transport == '<STR_LIT:http>' : <EOL> from toto . httpworkerconnection import HTTPWorkerConnection <EOL> cls . _instance = HTTPWorkerConnection . instance ( ) <EOL> else : <EOL> from toto . zmqworkerconnection import ZMQWorkerConnection <EOL> cls . _instance = ZMQWorkerConnection . instance ( ) <EOL> return cls . _instance <EOL> class WorkerInvocation ( object ) : <EOL> def __init__ ( self , path , connection ) : <EOL> self . _path = path <EOL> self . _connection = connection <EOL> def __call__ ( self , * args , ** kwargs ) : <EOL> return self . _connection . invoke ( self . _path , * args , ** kwargs ) <EOL> def __getattr__ ( self , path ) : <EOL> return getattr ( self . _connection , self . _path + '<STR_LIT:.>' + path ) </s>
<s> from . import multiarray <EOL> __all__ = [ ] </s>
<s> """<STR_LIT>""" <EOL> __author__ = '<STR_LIT>' <EOL> import urllib <EOL> from pyactiveresource import connection <EOL> from pyactiveresource import formats <EOL> class Error ( Exception ) : <EOL> """<STR_LIT>""" <EOL> class FakeConnection ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , format = formats . XMLFormat ) : <EOL> """<STR_LIT>""" <EOL> self . format = format <EOL> self . _request_map = { } <EOL> self . _debug_only = False <EOL> def _split_path ( self , path ) : <EOL> """<STR_LIT>""" <EOL> path_only , query_string = urllib . splitquery ( path ) <EOL> if query_string : <EOL> query_dict = dict ( [ i . split ( '<STR_LIT:=>' ) for i in query_string . split ( '<STR_LIT:&>' ) ] ) <EOL> else : <EOL> query_dict = { } <EOL> return path_only , query_dict <EOL> def debug_only ( self , debug = True ) : <EOL> self . _debug_only = debug <EOL> def respond_to ( self , method , path , headers , data , body , <EOL> response_headers = None ) : <EOL> """<STR_LIT>""" <EOL> path_only , query = self . _split_path ( path ) <EOL> if response_headers is None : <EOL> response_headers = { } <EOL> self . _request_map . setdefault ( method , [ ] ) . append ( <EOL> ( ( path_only , query , headers , data ) , ( body , response_headers ) ) ) <EOL> def _lookup_response ( self , method , path , headers , data ) : <EOL> path_only , query = self . _split_path ( path ) <EOL> for key , value in self . _request_map . get ( method , { } ) : <EOL> if key == ( path_only , query , headers , data ) : <EOL> response_body , response_headers = value <EOL> return connection . Response ( <NUM_LIT:200> , response_body , response_headers ) <EOL> raise Error ( '<STR_LIT>' % <EOL> ( path , headers , data ) ) <EOL> def get ( self , path , headers = None ) : <EOL> """<STR_LIT>""" <EOL> return self . format . decode ( <EOL> self . _lookup_response ( '<STR_LIT>' , path , headers , None ) . body ) <EOL> def post ( self , path , headers = None , data = None ) : <EOL> """<STR_LIT>""" <EOL> return self . _lookup_response ( '<STR_LIT>' , path , headers , data ) <EOL> def put ( self , path , headers = None , data = None ) : <EOL> """<STR_LIT>""" <EOL> return self . _lookup_response ( '<STR_LIT>' , path , headers , data ) <EOL> def delete ( self , path , headers = None ) : <EOL> """<STR_LIT>""" <EOL> return self . _lookup_response ( '<STR_LIT>' , path , headers , None ) </s>
<s> from trac . env import Environment <EOL> from trac . attachment import Attachment <EOL> from tracLib import * <EOL> from ConfigParser import ConfigParser <EOL> import tracLib <EOL> import tracLib . timetracking <EOL> class Client ( object ) : <EOL> def __init__ ( self , env_path ) : <EOL> self . env_path = env_path <EOL> self . env = Environment ( env_path ) <EOL> self . db_cnx = self . env . get_db_cnx ( ) <EOL> self . _registered_users_logins = [ ] <EOL> self . _timetracking_plugins = self . _get_timetracking_plugins ( ) <EOL> def _get_timetracking_plugins ( self ) : <EOL> plugins = { } <EOL> if tracLib . SUPPORT_TIME_TRACKING == '<STR_LIT>' : <EOL> for plugin in tracLib . timetracking . plugins : <EOL> plugin_name = plugin . get_name ( ) <EOL> for com_name , com_enabled in self . env . _component_rules . items ( ) : <EOL> if com_name . startswith ( plugin_name ) and com_enabled and plugin_name not in plugins : <EOL> plugins [ plugin_name ] = plugin ( self . env ) <EOL> else : <EOL> for plugin in tracLib . timetracking . plugins : <EOL> plugin_name = plugin . get_name ( ) <EOL> if plugin_name == tracLib . SUPPORT_TIME_TRACKING : <EOL> plugins [ plugin_name ] = plugin ( self . env ) <EOL> break ; <EOL> for plugin_name in plugins . keys ( ) : <EOL> print "<STR_LIT>" % plugin_name <EOL> return plugins . values ( ) <EOL> def get_project_description ( self ) : <EOL> return self . env . project_description <EOL> def get_users ( self ) : <EOL> result = self . env . get_known_users ( ) <EOL> trac_users = list ( [ ] ) <EOL> for user in result : <EOL> user_login = user [ <NUM_LIT:0> ] . lower ( ) <EOL> if user_login in self . _registered_users_logins : <EOL> continue <EOL> u = TracUser ( user_login ) <EOL> u . email = user [ <NUM_LIT:2> ] <EOL> trac_users . append ( u ) <EOL> self . _registered_users_logins . append ( user_login ) <EOL> if not tracLib . ACCEPT_NON_AUTHORISED_USERS : <EOL> return trac_users <EOL> user_fields = [ ( "<STR_LIT>" , "<STR_LIT>" ) , ( "<STR_LIT>" , "<STR_LIT>" ) , ( "<STR_LIT>" , "<STR_LIT>" ) , ( "<STR_LIT>" , "<STR_LIT>" ) ] <EOL> first = True <EOL> request = "<STR_LIT>" <EOL> for column_name , table_name in user_fields : <EOL> if first : <EOL> first = False <EOL> else : <EOL> request += "<STR_LIT>" <EOL> request += "<STR_LIT>" % ( column_name , table_name ) <EOL> cursor = self . db_cnx . cursor ( ) <EOL> cursor . execute ( request ) <EOL> for row in cursor : <EOL> if row [ <NUM_LIT:0> ] not in self . _registered_users_logins : <EOL> trac_user = self . _get_non_authorised_user ( row [ <NUM_LIT:0> ] ) <EOL> if trac_user is not None : <EOL> trac_users . append ( trac_user ) <EOL> self . _registered_users_logins . append ( trac_user . name ) <EOL> return trac_users <EOL> def _get_non_authorised_user ( self , user_name ) : <EOL> if user_name is None : <EOL> return None <EOL> start = user_name . find ( "<STR_LIT:<>" ) <EOL> end = user_name . rfind ( "<STR_LIT:>>" ) <EOL> if ( start > - <NUM_LIT:1> ) and ( end > start + <NUM_LIT:1> ) : <EOL> if user_name . find ( "<STR_LIT:@>" , start , end ) > <NUM_LIT:0> : <EOL> user = TracUser ( user_name [ start + <NUM_LIT:1> : end ] . replace ( "<STR_LIT:U+0020>" , "<STR_LIT:_>" ) ) <EOL> user . email = user_name [ start + <NUM_LIT:1> : end ] . replace ( "<STR_LIT:U+0020>" , "<STR_LIT:_>" ) <EOL> return user <EOL> return None <EOL> def _get_user_login ( self , user_name ) : <EOL> if user_name is None : <EOL> return None <EOL> if user_name in self . _registered_users_logins : <EOL> return user_name <EOL> if not tracLib . ACCEPT_NON_AUTHORISED_USERS : <EOL> return None <EOL> user = self . _get_non_authorised_user ( user_name ) <EOL> if ( user is None ) or ( user . name not in self . _registered_users_logins ) : <EOL> return None <EOL> return user . name <EOL> def get_severities ( self ) : <EOL> return self . _get_data_from_enum ( "<STR_LIT>" ) <EOL> def get_issue_types ( self ) : <EOL> return self . _get_data_from_enum ( "<STR_LIT>" ) <EOL> def get_issue_priorities ( self ) : <EOL> return self . _get_data_from_enum ( "<STR_LIT>" ) <EOL> def get_issue_resolutions ( self ) : <EOL> return [ TracResolution ( name ) for name in self . _get_data_from_enum ( "<STR_LIT>" ) ] <EOL> def get_components ( self ) : <EOL> cursor = self . db_cnx . cursor ( ) <EOL> cursor . execute ( "<STR_LIT>" ) <EOL> trac_components = list ( [ ] ) <EOL> for row in cursor : <EOL> component = TracComponent ( row [ <NUM_LIT:0> ] ) <EOL> component . owner = self . _get_user_login ( component . owner ) <EOL> if row [ <NUM_LIT:2> ] is not None : <EOL> component . description = row [ <NUM_LIT:2> ] <EOL> trac_components . append ( component ) <EOL> return trac_components <EOL> def get_versions ( self ) : <EOL> cursor = self . db_cnx . cursor ( ) <EOL> cursor . execute ( "<STR_LIT>" ) <EOL> trac_versions = list ( [ ] ) <EOL> for row in cursor : <EOL> version = TracVersion ( row [ <NUM_LIT:0> ] ) <EOL> if row [ <NUM_LIT:1> ] : <EOL> version . time = to_unix_time ( row [ <NUM_LIT:1> ] ) <EOL> if row [ <NUM_LIT:2> ] is not None : <EOL> version . description = row [ <NUM_LIT:2> ] <EOL> trac_versions . append ( version ) <EOL> return trac_versions <EOL> def get_issues ( self ) : <EOL> cursor = self . db_cnx . cursor ( ) <EOL> cursor . execute ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> trac_issues = list ( [ ] ) <EOL> for row in cursor : <EOL> issue = TracIssue ( row [ <NUM_LIT:0> ] ) <EOL> issue . time = to_unix_time ( row [ <NUM_LIT:2> ] ) <EOL> issue . changetime = to_unix_time ( row [ <NUM_LIT:3> ] ) <EOL> issue . reporter = self . _get_user_login ( row [ <NUM_LIT:8> ] ) <EOL> if row [ <NUM_LIT:9> ] is not None : <EOL> cc = row [ <NUM_LIT:9> ] . split ( "<STR_LIT:U+002C>" ) <EOL> for c in cc : <EOL> if len ( c ) > <NUM_LIT:0> : <EOL> cc_name = self . _get_user_login ( c . strip ( ) ) <EOL> if cc_name is not None : <EOL> issue . cc . add ( cc_name ) <EOL> issue . summary = row [ <NUM_LIT> ] <EOL> issue . description = row [ <NUM_LIT> ] <EOL> issue . custom_fields [ "<STR_LIT>" ] = row [ <NUM_LIT:1> ] <EOL> issue . custom_fields [ "<STR_LIT>" ] = row [ <NUM_LIT:4> ] <EOL> issue . custom_fields [ "<STR_LIT>" ] = row [ <NUM_LIT:5> ] <EOL> issue . custom_fields [ "<STR_LIT>" ] = row [ <NUM_LIT:6> ] <EOL> issue . custom_fields [ "<STR_LIT>" ] = self . _get_user_login ( row [ <NUM_LIT:7> ] ) <EOL> issue . custom_fields [ "<STR_LIT>" ] = row [ <NUM_LIT:10> ] <EOL> issue . custom_fields [ "<STR_LIT>" ] = row [ <NUM_LIT:11> ] <EOL> issue . custom_fields [ "<STR_LIT>" ] = row [ <NUM_LIT:12> ] <EOL> if row [ <NUM_LIT:15> ] is not None : <EOL> keywords = row [ <NUM_LIT:15> ] . rsplit ( "<STR_LIT:U+002C>" ) <EOL> for kw in keywords : <EOL> if len ( kw ) > <NUM_LIT:0> : <EOL> issue . keywords . add ( kw . strip ( ) ) <EOL> custom_field_cursor = self . db_cnx . cursor ( ) <EOL> custom_field_cursor . execute ( "<STR_LIT>" , ( str ( row [ <NUM_LIT:0> ] ) , ) ) <EOL> for cf in custom_field_cursor : <EOL> issue . custom_fields [ cf [ <NUM_LIT:0> ] . capitalize ( ) ] = cf [ <NUM_LIT:1> ] <EOL> attachment_cursor = self . db_cnx . cursor ( ) <EOL> attachment_cursor . execute ( "<STR_LIT>" <EOL> "<STR_LIT>" , ( "<STR_LIT>" , str ( issue . id ) ) ) <EOL> for elem in attachment_cursor : <EOL> at = TracAttachment ( Attachment . _get_path ( self . env . path , '<STR_LIT>' , str ( issue . id ) , elem [ <NUM_LIT:0> ] ) ) <EOL> at . name = elem [ <NUM_LIT:0> ] <EOL> at . size = elem [ <NUM_LIT:1> ] <EOL> at . time = to_unix_time ( elem [ <NUM_LIT:2> ] ) <EOL> at . description = elem [ <NUM_LIT:3> ] <EOL> at . author_name = elem [ <NUM_LIT:4> ] <EOL> issue . attachment . add ( at ) <EOL> trac_issues . append ( issue ) <EOL> change_cursor = self . db_cnx . cursor ( ) <EOL> change_cursor . execute ( "<STR_LIT>" , ( str ( row [ <NUM_LIT:0> ] ) , "<STR_LIT>" , ) ) <EOL> for elem in change_cursor : <EOL> if ( elem [ <NUM_LIT:2> ] is None ) or ( not len ( elem [ <NUM_LIT:2> ] . lstrip ( ) ) ) : <EOL> continue <EOL> comment = TracComment ( to_unix_time ( elem [ <NUM_LIT:0> ] ) ) <EOL> comment . author = str ( elem [ <NUM_LIT:1> ] ) <EOL> comment . content = unicode ( elem [ <NUM_LIT:2> ] ) <EOL> comment . id = elem [ <NUM_LIT:3> ] <EOL> issue . comments . add ( comment ) <EOL> for ttp in self . _timetracking_plugins : <EOL> issue . workitems . update ( set ( ttp [ row [ <NUM_LIT:0> ] ] ) ) <EOL> return trac_issues <EOL> def get_custom_fields_declared ( self ) : <EOL> ini_file_path = self . env_path + "<STR_LIT>" <EOL> parser = ConfigParser ( ) <EOL> parser . read ( ini_file_path ) <EOL> if not ( "<STR_LIT>" in parser . sections ( ) ) : <EOL> return set ( [ ] ) <EOL> result = parser . items ( "<STR_LIT>" ) <EOL> items = dict ( [ ] ) <EOL> for elem in result : <EOL> items [ elem [ <NUM_LIT:0> ] ] = elem [ <NUM_LIT:1> ] <EOL> keys = items . keys ( ) <EOL> custom_fields = list ( [ ] ) <EOL> for k in keys : <EOL> if not ( "<STR_LIT:.>" in k ) : <EOL> field = TracCustomFieldDeclaration ( k . capitalize ( ) ) <EOL> field . type = items [ k ] <EOL> options_key = k + "<STR_LIT>" <EOL> if options_key in items : <EOL> opts_str = items [ options_key ] <EOL> opts = opts_str . rsplit ( "<STR_LIT:|>" ) <EOL> for o in opts : <EOL> field . options . append ( o ) <EOL> value_key = k + "<STR_LIT>" <EOL> if value_key in items : <EOL> field . value = items [ value_key ] <EOL> label_key = k + "<STR_LIT>" <EOL> if label_key in items : <EOL> field . label = items [ label_key ] <EOL> custom_fields . append ( field ) <EOL> return custom_fields <EOL> def _get_data_from_enum ( self , type_name ) : <EOL> cursor = self . db_cnx . cursor ( ) <EOL> cursor . execute ( "<STR_LIT>" , ( type_name , ) ) <EOL> return [ row [ <NUM_LIT:0> ] for row in cursor ] </s>
<s> """<STR_LIT>""" </s>
<s> import os <EOL> os . system ( "<STR_LIT>" ) </s>
<s> """<STR_LIT>""" <EOL> import sys <EOL> from collections import defaultdict <EOL> from bacpypes . debugging import Logging , function_debugging , ModuleLogger <EOL> from bacpypes . consolelogging import ConsoleLogHandler <EOL> from bacpypes . pdu import Address <EOL> from bacpypes . analysis import trace , strftimestamp , Tracer <EOL> from bacpypes . npdu import WhoIsRouterToNetwork <EOL> _debug = <NUM_LIT:0> <EOL> _log = ModuleLogger ( globals ( ) ) <EOL> filterSource = None <EOL> filterDestination = None <EOL> filterHost = None <EOL> requests = defaultdict ( int ) <EOL> networks = defaultdict ( list ) <EOL> @ function_debugging <EOL> def Match ( addr1 , addr2 ) : <EOL> """<STR_LIT>""" <EOL> if _debug : Match . _debug ( "<STR_LIT>" , addr1 , addr2 ) <EOL> if ( addr2 . addrType == Address . localBroadcastAddr ) : <EOL> return ( addr1 . addrType == Address . localStationAddr ) or ( addr1 . addrType == Address . localBroadcastAddr ) <EOL> elif ( addr2 . addrType == Address . localStationAddr ) : <EOL> return ( addr1 . addrType == Address . localStationAddr ) and ( addr1 . addrAddr == addr2 . addrAddr ) <EOL> elif ( addr2 . addrType == Address . remoteBroadcastAddr ) : <EOL> return ( ( addr1 . addrType == Address . remoteStationAddr ) or ( addr1 . addrType == Address . remoteBroadcastAddr ) ) and ( addr1 . addrNet == addr2 . addrNet ) <EOL> elif ( addr2 . addrType == Address . remoteStationAddr ) : <EOL> return ( addr1 . addrType == Address . remoteStationAddr ) and ( addr1 . addrNet == addr2 . addrNet ) and ( addr1 . addrAddr == addr2 . addrAddr ) <EOL> elif ( addr2 . addrType == Address . globalBroadcastAddr ) : <EOL> return ( addr1 . addrType == Address . globalBroadcastAddr ) <EOL> else : <EOL> raise RuntimeError , "<STR_LIT>" <EOL> class WhoIsRouterToNetworkSummary ( Tracer , Logging ) : <EOL> def __init__ ( self ) : <EOL> if _debug : IAmRouterToNetworkSummary . _debug ( "<STR_LIT>" ) <EOL> Tracer . __init__ ( self , self . Filter ) <EOL> def Filter ( self , pkt ) : <EOL> if _debug : WhoIsRouterToNetworkSummary . _debug ( "<STR_LIT>" , pkt ) <EOL> global requests , networks <EOL> if not isinstance ( pkt , WhoIsRouterToNetwork ) : <EOL> return <EOL> if filterSource : <EOL> if not Match ( pkt . pduSource , filterSource ) : <EOL> if _debug : WhoIsRouterToNetworkSummary . _debug ( "<STR_LIT>" ) <EOL> return <EOL> if filterDestination : <EOL> if not Match ( pkt . pduDestination , filterDestination ) : <EOL> if _debug : WhoIsRouterToNetworkSummary . _debug ( "<STR_LIT>" ) <EOL> return <EOL> if filterHost : <EOL> if ( not Match ( pkt . pduSource , filterHost ) ) and ( not Match ( pkt . pduDestination , filterHost ) ) : <EOL> if _debug : WhoIsRouterToNetworkSummary . _debug ( "<STR_LIT>" ) <EOL> return <EOL> requests [ pkt . pduSource ] += <NUM_LIT:1> <EOL> networks [ pkt . pduSource ] . append ( pkt . wirtnNetwork ) <EOL> try : <EOL> if ( '<STR_LIT>' in sys . argv ) : <EOL> indx = sys . argv . index ( '<STR_LIT>' ) <EOL> for i in range ( indx + <NUM_LIT:1> , len ( sys . argv ) ) : <EOL> ConsoleLogHandler ( sys . argv [ i ] ) <EOL> del sys . argv [ indx : ] <EOL> if _debug : _log . debug ( "<STR_LIT>" ) <EOL> if ( '<STR_LIT>' in sys . argv ) : <EOL> i = sys . argv . index ( '<STR_LIT>' ) <EOL> filterSource = Address ( sys . argv [ i + <NUM_LIT:1> ] ) <EOL> if _debug : _log . debug ( "<STR_LIT>" , filterSource ) <EOL> del sys . argv [ i : i + <NUM_LIT:2> ] <EOL> if ( '<STR_LIT>' in sys . argv ) : <EOL> i = sys . argv . index ( '<STR_LIT>' ) <EOL> filterDestination = Address ( sys . argv [ i + <NUM_LIT:1> ] ) <EOL> if _debug : _log . debug ( "<STR_LIT>" , filterDestination ) <EOL> del sys . argv [ i : i + <NUM_LIT:2> ] <EOL> if ( '<STR_LIT>' in sys . argv ) : <EOL> i = sys . argv . index ( '<STR_LIT>' ) <EOL> filterHost = Address ( sys . argv [ i + <NUM_LIT:1> ] ) <EOL> if _debug : _log . debug ( "<STR_LIT>" , filterHost ) <EOL> del sys . argv [ i : i + <NUM_LIT:2> ] <EOL> for fname in sys . argv [ <NUM_LIT:1> : ] : <EOL> trace ( fname , [ WhoIsRouterToNetworkSummary ] ) <EOL> items = requests . items ( ) <EOL> items . sort ( lambda x , y : cmp ( y [ <NUM_LIT:1> ] , x [ <NUM_LIT:1> ] ) ) <EOL> print "<STR_LIT>" % ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> for key , count in items : <EOL> print "<STR_LIT>" % ( key , count ) <EOL> net_count = defaultdict ( int ) <EOL> for net in networks [ key ] : <EOL> net_count [ net ] += <NUM_LIT:1> <EOL> net_count = net_count . items ( ) <EOL> net_count . sort ( lambda x , y : cmp ( y [ <NUM_LIT:1> ] , x [ <NUM_LIT:1> ] ) ) <EOL> for net , count in net_count : <EOL> print "<STR_LIT>" % ( net , count ) <EOL> except KeyboardInterrupt : <EOL> pass <EOL> except Exception , e : <EOL> _log . exception ( "<STR_LIT>" , e ) <EOL> finally : <EOL> if _debug : _log . debug ( "<STR_LIT>" ) </s>
<s> """<STR_LIT>""" <EOL> import asyncore <EOL> import socket <EOL> import cPickle as pickle <EOL> from time import time as _time , sleep as _sleep <EOL> from StringIO import StringIO <EOL> from . debugging import ModuleLogger , DebugContents , bacpypes_debugging <EOL> from . core import deferred <EOL> from . task import FunctionTask , OneShotFunction <EOL> from . comm import PDU , Client , Server <EOL> from . comm import ServiceAccessPoint , ApplicationServiceElement <EOL> _debug = <NUM_LIT:0> <EOL> _log = ModuleLogger ( globals ( ) ) <EOL> REBIND_SLEEP_INTERVAL = <NUM_LIT> <EOL> class PickleActorMixIn : <EOL> def __init__ ( self , * args ) : <EOL> if _debug : PickleActorMixIn . _debug ( "<STR_LIT>" , args ) <EOL> super ( PickleActorMixIn , self ) . __init__ ( * args ) <EOL> self . pickleBuffer = '<STR_LIT>' <EOL> def indication ( self , pdu ) : <EOL> if _debug : PickleActorMixIn . _debug ( "<STR_LIT>" , pdu ) <EOL> pdu . pduData = pickle . dumps ( pdu . pduData ) <EOL> super ( PickleActorMixIn , self ) . indication ( pdu ) <EOL> def response ( self , pdu ) : <EOL> if _debug : PickleActorMixIn . _debug ( "<STR_LIT>" , pdu ) <EOL> self . pickleBuffer += pdu . pduData <EOL> strm = StringIO ( self . pickleBuffer ) <EOL> pos = <NUM_LIT:0> <EOL> while ( pos < strm . len ) : <EOL> try : <EOL> msg = pickle . load ( strm ) <EOL> except : <EOL> break <EOL> rpdu = PDU ( msg ) <EOL> rpdu . update ( pdu ) <EOL> super ( PickleActorMixIn , self ) . response ( rpdu ) <EOL> pos = strm . tell ( ) <EOL> if ( pos < strm . len ) : <EOL> self . pickleBuffer = self . pickleBuffer [ pos : ] <EOL> else : <EOL> self . pickleBuffer = '<STR_LIT>' <EOL> bacpypes_debugging ( PickleActorMixIn ) <EOL> class TCPClient ( asyncore . dispatcher ) : <EOL> def __init__ ( self , peer ) : <EOL> if _debug : TCPClient . _debug ( "<STR_LIT>" , peer ) <EOL> asyncore . dispatcher . __init__ ( self ) <EOL> self . create_socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> self . peer = peer <EOL> self . request = '<STR_LIT>' <EOL> self . socketError = None <EOL> if _debug : TCPClient . _debug ( "<STR_LIT>" ) <EOL> self . connect ( peer ) <EOL> if _debug : TCPClient . _debug ( "<STR_LIT>" ) <EOL> def handle_connect ( self ) : <EOL> if _debug : deferred ( TCPClient . _debug , "<STR_LIT>" ) <EOL> def handle_expt ( self ) : <EOL> pass <EOL> def readable ( self ) : <EOL> return <NUM_LIT:1> <EOL> def handle_read ( self ) : <EOL> if _debug : deferred ( TCPClient . _debug , "<STR_LIT>" ) <EOL> try : <EOL> msg = self . recv ( <NUM_LIT> ) <EOL> if _debug : deferred ( TCPClient . _debug , "<STR_LIT>" , len ( msg ) ) <EOL> self . socketError = None <EOL> if not self . socket : <EOL> if _debug : deferred ( TCPClient . _debug , "<STR_LIT>" ) <EOL> else : <EOL> deferred ( self . response , PDU ( msg ) ) <EOL> except socket . error , err : <EOL> if ( err . args [ <NUM_LIT:0> ] == <NUM_LIT> ) : <EOL> deferred ( TCPClient . _error , "<STR_LIT>" , self . peer ) <EOL> else : <EOL> deferred ( TCPClient . _error , "<STR_LIT>" , err ) <EOL> self . socketError = err <EOL> def writable ( self ) : <EOL> return ( len ( self . request ) != <NUM_LIT:0> ) <EOL> def handle_write ( self ) : <EOL> if _debug : deferred ( TCPClient . _debug , "<STR_LIT>" ) <EOL> try : <EOL> sent = self . send ( self . request ) <EOL> if _debug : deferred ( TCPClient . _debug , "<STR_LIT>" , sent , len ( self . request ) - sent ) <EOL> self . socketError = None <EOL> self . request = self . request [ sent : ] <EOL> except socket . error , err : <EOL> if ( err . args [ <NUM_LIT:0> ] == <NUM_LIT> ) : <EOL> deferred ( TCPClient . _error , "<STR_LIT>" , self . peer ) <EOL> else : <EOL> deferred ( TCPClient . _error , "<STR_LIT>" , err ) <EOL> self . socketError = err <EOL> def handle_close ( self ) : <EOL> if _debug : deferred ( TCPClient . _debug , "<STR_LIT>" ) <EOL> self . close ( ) <EOL> self . socket = None <EOL> def indication ( self , pdu ) : <EOL> """<STR_LIT>""" <EOL> if _debug : TCPClient . _debug ( "<STR_LIT>" , pdu ) <EOL> self . request += pdu . pduData <EOL> bacpypes_debugging ( TCPClient ) <EOL> class TCPClientActor ( TCPClient ) : <EOL> def __init__ ( self , director , peer ) : <EOL> if _debug : TCPClientActor . _debug ( "<STR_LIT>" , director , peer ) <EOL> TCPClient . __init__ ( self , peer ) <EOL> self . director = director <EOL> self . timeout = director . timeout <EOL> if self . timeout > <NUM_LIT:0> : <EOL> self . timer = FunctionTask ( self . idle_timeout ) <EOL> self . timer . install_task ( _time ( ) + self . timeout ) <EOL> else : <EOL> self . timer = None <EOL> self . flushTask = None <EOL> self . director . add_actor ( self ) <EOL> def handle_close ( self ) : <EOL> if _debug : TCPClientActor . _debug ( "<STR_LIT>" ) <EOL> if self . flushTask : <EOL> self . flushTask . suspend_task ( ) <EOL> if self . timer : <EOL> self . timer . suspend_task ( ) <EOL> self . director . remove_actor ( self ) <EOL> TCPClient . handle_close ( self ) <EOL> def idle_timeout ( self ) : <EOL> if _debug : TCPClientActor . _debug ( "<STR_LIT>" ) <EOL> self . handle_close ( ) <EOL> def indication ( self , pdu ) : <EOL> if _debug : TCPClientActor . _debug ( "<STR_LIT>" , pdu ) <EOL> if self . flushTask : <EOL> if _debug : TCPServerActor . _debug ( "<STR_LIT>" ) <EOL> return <EOL> if self . timer : <EOL> self . timer . install_task ( _time ( ) + self . timeout ) <EOL> TCPClient . indication ( self , pdu ) <EOL> def response ( self , pdu ) : <EOL> if _debug : TCPClientActor . _debug ( "<STR_LIT>" , pdu ) <EOL> pdu . pduSource = self . peer <EOL> if self . timer : <EOL> self . timer . install_task ( _time ( ) + self . timeout ) <EOL> self . director . response ( pdu ) <EOL> def flush ( self ) : <EOL> if _debug : TCPClientActor . _debug ( "<STR_LIT>" ) <EOL> self . flushTask = None <EOL> if self . request : <EOL> self . flushTask = OneShotFunction ( self . flush ) <EOL> return <EOL> self . handle_close ( ) <EOL> bacpypes_debugging ( TCPClientActor ) <EOL> class TCPPickleClientActor ( PickleActorMixIn , TCPClientActor ) : <EOL> pass <EOL> class TCPClientDirector ( Server , ServiceAccessPoint , DebugContents ) : <EOL> _debug_contents = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) <EOL> def __init__ ( self , timeout = <NUM_LIT:0> , actorClass = TCPClientActor , sid = None , sapID = None ) : <EOL> if _debug : TCPClientDirector . _debug ( "<STR_LIT>" , timeout , actorClass , sid , sapID ) <EOL> Server . __init__ ( self , sid ) <EOL> ServiceAccessPoint . __init__ ( self , sapID ) <EOL> if not issubclass ( actorClass , TCPClientActor ) : <EOL> raise TypeError ( "<STR_LIT>" ) <EOL> self . actorClass = actorClass <EOL> self . timeout = timeout <EOL> self . clients = { } <EOL> self . reconnect = { } <EOL> def add_actor ( self , actor ) : <EOL> """<STR_LIT>""" <EOL> if _debug : TCPClientDirector . _debug ( "<STR_LIT>" , actor ) <EOL> self . clients [ actor . peer ] = actor <EOL> if self . serviceElement : <EOL> self . sap_request ( addPeer = actor . peer ) <EOL> def remove_actor ( self , actor ) : <EOL> """<STR_LIT>""" <EOL> if _debug : TCPClientDirector . _debug ( "<STR_LIT>" , actor ) <EOL> del self . clients [ actor . peer ] <EOL> if self . serviceElement : <EOL> self . sap_request ( delPeer = actor . peer ) <EOL> if actor . peer in self . reconnect : <EOL> connect_task = FunctionTask ( self . connect , actor . peer ) <EOL> connect_task . install_task ( _time ( ) + self . reconnect [ actor . peer ] ) <EOL> def get_actor ( self , address ) : <EOL> """<STR_LIT>""" <EOL> return self . clients . get ( address , None ) <EOL> def connect ( self , address , reconnect = <NUM_LIT:0> ) : <EOL> if _debug : TCPClientDirector . _debug ( "<STR_LIT>" , address , reconnect ) <EOL> if address in self . clients : <EOL> return <EOL> client = self . actorClass ( self , address ) <EOL> if _debug : TCPClientDirector . _debug ( "<STR_LIT>" , client ) <EOL> if reconnect : <EOL> self . reconnect [ address ] = reconnect <EOL> def disconnect ( self , address ) : <EOL> if _debug : TCPClientDirector . _debug ( "<STR_LIT>" , address ) <EOL> if address not in self . clients : <EOL> return <EOL> if address in self . reconnect : <EOL> del self . reconnect [ address ] <EOL> self . clients [ address ] . handle_close ( ) <EOL> def indication ( self , pdu ) : <EOL> """<STR_LIT>""" <EOL> if _debug : TCPClientDirector . _debug ( "<STR_LIT>" , pdu ) <EOL> addr = pdu . pduDestination <EOL> client = self . clients . get ( addr , None ) <EOL> if not client : <EOL> client = self . actorClass ( self , addr ) <EOL> client . indication ( pdu ) <EOL> bacpypes_debugging ( TCPClientDirector ) <EOL> class TCPServer ( asyncore . dispatcher ) : <EOL> def __init__ ( self , sock , peer ) : <EOL> if _debug : TCPServer . _debug ( "<STR_LIT>" , sock , peer ) <EOL> asyncore . dispatcher . __init__ ( self , sock ) <EOL> self . peer = peer <EOL> self . request = '<STR_LIT>' <EOL> self . socketError = None <EOL> def handle_connect ( self ) : <EOL> if _debug : deferred ( TCPServer . _debug , "<STR_LIT>" ) <EOL> def readable ( self ) : <EOL> return <NUM_LIT:1> <EOL> def handle_read ( self ) : <EOL> if _debug : deferred ( TCPServer . _debug , "<STR_LIT>" ) <EOL> try : <EOL> msg = self . recv ( <NUM_LIT> ) <EOL> if _debug : deferred ( TCPServer . _debug , "<STR_LIT>" , len ( msg ) ) <EOL> self . socketError = None <EOL> if not self . socket : <EOL> if _debug : deferred ( TCPServer . _debug , "<STR_LIT>" ) <EOL> else : <EOL> deferred ( self . response , PDU ( msg ) ) <EOL> except socket . error , err : <EOL> if ( err . args [ <NUM_LIT:0> ] == <NUM_LIT> ) : <EOL> deferred ( TCPServer . _error , "<STR_LIT>" , self . peer ) <EOL> else : <EOL> deferred ( TCPServer . _error , "<STR_LIT>" , err ) <EOL> self . socketError = err <EOL> def writable ( self ) : <EOL> return ( len ( self . request ) != <NUM_LIT:0> ) <EOL> def handle_write ( self ) : <EOL> if _debug : deferred ( TCPServer . _debug , "<STR_LIT>" ) <EOL> try : <EOL> sent = self . send ( self . request ) <EOL> if _debug : deferred ( TCPServer . _debug , "<STR_LIT>" , sent , len ( self . request ) - sent ) <EOL> self . socketError = None <EOL> self . request = self . request [ sent : ] <EOL> except socket . error , why : <EOL> if ( why . args [ <NUM_LIT:0> ] == <NUM_LIT> ) : <EOL> deferred ( TCPServer . _error , "<STR_LIT>" , self . peer ) <EOL> else : <EOL> deferred ( TCPServer . _error , "<STR_LIT>" , why ) <EOL> self . socketError = why <EOL> def handle_close ( self ) : <EOL> if _debug : deferred ( TCPServer . _debug , "<STR_LIT>" ) <EOL> if not self : <EOL> deferred ( TCPServer . _warning , "<STR_LIT>" ) <EOL> return <EOL> if not self . socket : <EOL> deferred ( TCPServer . _warning , "<STR_LIT>" ) <EOL> return <EOL> self . close ( ) <EOL> self . socket = None <EOL> def indication ( self , pdu ) : <EOL> """<STR_LIT>""" <EOL> if _debug : TCPServer . _debug ( "<STR_LIT>" , pdu ) <EOL> self . request += pdu . pduData <EOL> bacpypes_debugging ( TCPServer ) <EOL> class TCPServerActor ( TCPServer ) : <EOL> def __init__ ( self , director , sock , peer ) : <EOL> if _debug : TCPServerActor . _debug ( "<STR_LIT>" , director , sock , peer ) <EOL> TCPServer . __init__ ( self , sock , peer ) <EOL> self . director = director <EOL> self . timeout = director . timeout <EOL> if self . timeout > <NUM_LIT:0> : <EOL> self . timer = FunctionTask ( self . idle_timeout ) <EOL> self . timer . install_task ( _time ( ) + self . timeout ) <EOL> else : <EOL> self . timer = None <EOL> self . flushTask = None <EOL> self . director . add_actor ( self ) <EOL> def handle_close ( self ) : <EOL> if _debug : TCPServerActor . _debug ( "<STR_LIT>" ) <EOL> if self . flushTask : <EOL> self . flushTask . suspend_task ( ) <EOL> self . director . remove_actor ( self ) <EOL> TCPServer . handle_close ( self ) <EOL> def idle_timeout ( self ) : <EOL> if _debug : TCPServerActor . _debug ( "<STR_LIT>" ) <EOL> self . handle_close ( ) <EOL> def indication ( self , pdu ) : <EOL> if _debug : TCPServerActor . _debug ( "<STR_LIT>" , pdu ) <EOL> if self . flushTask : <EOL> if _debug : TCPServerActor . _debug ( "<STR_LIT>" ) <EOL> return <EOL> if self . timer : <EOL> self . timer . install_task ( _time ( ) + self . timeout ) <EOL> TCPServer . indication ( self , pdu ) <EOL> def response ( self , pdu ) : <EOL> if _debug : TCPServerActor . _debug ( "<STR_LIT>" , pdu ) <EOL> if self . flushTask : <EOL> if _debug : TCPServerActor . _debug ( "<STR_LIT>" ) <EOL> return <EOL> pdu . pduSource = self . peer <EOL> if self . timer : <EOL> self . timer . install_task ( _time ( ) + self . timeout ) <EOL> self . director . response ( pdu ) <EOL> def flush ( self ) : <EOL> if _debug : TCPServerActor . _debug ( "<STR_LIT>" ) <EOL> self . flushTask = None <EOL> if self . request : <EOL> self . flushTask = OneShotFunction ( self . flush ) <EOL> return <EOL> self . handle_close ( ) <EOL> bacpypes_debugging ( TCPServerActor ) <EOL> class TCPPickleServerActor ( PickleActorMixIn , TCPServerActor ) : <EOL> pass <EOL> class TCPServerDirector ( asyncore . dispatcher , Server , ServiceAccessPoint , DebugContents ) : <EOL> _debug_contents = ( '<STR_LIT:port>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) <EOL> def __init__ ( self , address , listeners = <NUM_LIT:5> , timeout = <NUM_LIT:0> , reuse = False , actorClass = TCPServerActor , cid = None , sapID = None ) : <EOL> if _debug : <EOL> TCPServerDirector . _debug ( "<STR_LIT>" <EOL> , address , listeners , timeout , reuse , actorClass , cid , sapID <EOL> ) <EOL> Server . __init__ ( self , cid ) <EOL> ServiceAccessPoint . __init__ ( self , sapID ) <EOL> self . port = address <EOL> self . timeout = timeout <EOL> if not issubclass ( actorClass , TCPServerActor ) : <EOL> raise TypeError ( "<STR_LIT>" ) <EOL> self . actorClass = actorClass <EOL> self . servers = { } <EOL> asyncore . dispatcher . __init__ ( self ) <EOL> self . create_socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> if reuse : <EOL> self . set_reuse_addr ( ) <EOL> hadBindErrors = False <EOL> for i in range ( <NUM_LIT:30> ) : <EOL> try : <EOL> self . bind ( address ) <EOL> break <EOL> except socket . error , err : <EOL> hadBindErrors = True <EOL> TCPServerDirector . _warning ( '<STR_LIT>' , err ) <EOL> _sleep ( REBIND_SLEEP_INTERVAL ) <EOL> else : <EOL> TCPServerDirector . _error ( '<STR_LIT>' ) <EOL> raise RuntimeError ( "<STR_LIT>" ) <EOL> if hadBindErrors : <EOL> TCPServerDirector . _info ( '<STR_LIT>' ) <EOL> self . listen ( listeners ) <EOL> def handle_accept ( self ) : <EOL> if _debug : TCPServerDirector . _debug ( "<STR_LIT>" ) <EOL> try : <EOL> client , addr = self . accept ( ) <EOL> except socket . error : <EOL> TCPServerDirector . _warning ( '<STR_LIT>' ) <EOL> return <EOL> except TypeError : <EOL> TCPServerDirector . _warning ( '<STR_LIT>' ) <EOL> return <EOL> if _debug : TCPServerDirector . _debug ( "<STR_LIT>" , client , addr ) <EOL> server = self . actorClass ( self , client , addr ) <EOL> self . servers [ addr ] = server <EOL> return server <EOL> def handle_close ( self ) : <EOL> if _debug : TCPServerDirector . _debug ( "<STR_LIT>" ) <EOL> self . close ( ) <EOL> def add_actor ( self , actor ) : <EOL> if _debug : TCPServerDirector . _debug ( "<STR_LIT>" , actor ) <EOL> self . servers [ actor . peer ] = actor <EOL> if self . serviceElement : <EOL> self . sap_request ( addPeer = actor . peer ) <EOL> def remove_actor ( self , actor ) : <EOL> if _debug : TCPServerDirector . _debug ( "<STR_LIT>" , actor ) <EOL> try : <EOL> del self . servers [ actor . peer ] <EOL> except KeyError : <EOL> TCPServerDirector . _warning ( "<STR_LIT>" , actor ) <EOL> if self . serviceElement : <EOL> self . sap_request ( delPeer = actor . peer ) <EOL> def get_actor ( self , address ) : <EOL> """<STR_LIT>""" <EOL> return self . servers . get ( address , None ) <EOL> def indication ( self , pdu ) : <EOL> """<STR_LIT>""" <EOL> if _debug : TCPServerDirector . _debug ( "<STR_LIT>" , pdu ) <EOL> addr = pdu . pduDestination <EOL> server = self . servers . get ( addr , None ) <EOL> if not server : <EOL> raise RuntimeError ( "<STR_LIT>" ) <EOL> server . indication ( pdu ) <EOL> bacpypes_debugging ( TCPServerDirector ) <EOL> class StreamToPacket ( Client , Server ) : <EOL> def __init__ ( self , fn , cid = None , sid = None ) : <EOL> if _debug : StreamToPacket . _debug ( "<STR_LIT>" , fn , cid , sid ) <EOL> Client . __init__ ( self , cid ) <EOL> Server . __init__ ( self , sid ) <EOL> self . packetFn = fn <EOL> self . upstreamBuffer = { } <EOL> self . downstreamBuffer = { } <EOL> def packetize ( self , pdu , streamBuffer ) : <EOL> if _debug : StreamToPacket . _debug ( "<STR_LIT>" , pdu ) <EOL> def chop ( addr ) : <EOL> if _debug : StreamToPacket . _debug ( "<STR_LIT>" , addr ) <EOL> buff = streamBuffer . get ( addr , '<STR_LIT>' ) + pdu . pduData <EOL> if _debug : StreamToPacket . _debug ( "<STR_LIT>" , buff ) <EOL> while <NUM_LIT:1> : <EOL> packet = self . packetFn ( buff ) <EOL> if packet is None : <EOL> break <EOL> yield PDU ( packet [ <NUM_LIT:0> ] , <EOL> source = pdu . pduSource , <EOL> destination = pdu . pduDestination , <EOL> user_data = pdu . pduUserData , <EOL> ) <EOL> buff = packet [ <NUM_LIT:1> ] <EOL> streamBuffer [ addr ] = buff <EOL> if pdu . pduSource : <EOL> for pdu in chop ( pdu . pduSource ) : <EOL> yield pdu <EOL> if pdu . pduDestination : <EOL> for pdu in chop ( pdu . pduDestination ) : <EOL> yield pdu <EOL> def indication ( self , pdu ) : <EOL> """<STR_LIT>""" <EOL> if _debug : StreamToPacket . _debug ( "<STR_LIT>" , pdu ) <EOL> for packet in self . packetize ( pdu , self . downstreamBuffer ) : <EOL> self . request ( packet ) <EOL> def confirmation ( self , pdu ) : <EOL> """<STR_LIT>""" <EOL> if _debug : StreamToPacket . _debug ( "<STR_LIT>" , pdu ) <EOL> for packet in self . packetize ( pdu , self . upstreamBuffer ) : <EOL> self . response ( packet ) <EOL> bacpypes_debugging ( StreamToPacket ) <EOL> class StreamToPacketSAP ( ApplicationServiceElement , ServiceAccessPoint ) : <EOL> def __init__ ( self , stp , aseID = None , sapID = None ) : <EOL> if _debug : StreamToPacketSAP . _debug ( "<STR_LIT>" , stp , aseID , sapID ) <EOL> ApplicationServiceElement . __init__ ( self , aseID ) <EOL> ServiceAccessPoint . __init__ ( self , sapID ) <EOL> self . stp = stp <EOL> def indication ( self , addPeer = None , delPeer = None ) : <EOL> if _debug : StreamToPacketSAP . _debug ( "<STR_LIT>" , addPeer , delPeer ) <EOL> if addPeer : <EOL> self . stp . upstreamBuffer [ addPeer ] = '<STR_LIT>' <EOL> self . stp . downstreamBuffer [ addPeer ] = '<STR_LIT>' <EOL> if delPeer : <EOL> del self . stp . upstreamBuffer [ delPeer ] <EOL> del self . stp . downstreamBuffer [ delPeer ] <EOL> if self . serviceElement : <EOL> self . sap_request ( addPeer = addPeer , delPeer = delPeer ) <EOL> bacpypes_debugging ( StreamToPacketSAP ) </s>
<s> """<STR_LIT>""" <EOL> import random <EOL> from copy import deepcopy <EOL> from . errors import ConfigurationError <EOL> from . debugging import ModuleLogger , bacpypes_debugging <EOL> from . core import deferred <EOL> from . pdu import Address <EOL> from . comm import Server <EOL> _debug = <NUM_LIT:0> <EOL> _log = ModuleLogger ( globals ( ) ) <EOL> @ bacpypes_debugging <EOL> class Network : <EOL> def __init__ ( self , dropPercent = <NUM_LIT:0.0> ) : <EOL> if _debug : Network . _debug ( "<STR_LIT>" , dropPercent ) <EOL> self . nodes = [ ] <EOL> self . dropPercent = dropPercent <EOL> def add_node ( self , node ) : <EOL> """<STR_LIT>""" <EOL> if _debug : Network . _debug ( "<STR_LIT>" , node ) <EOL> self . nodes . append ( node ) <EOL> node . lan = self <EOL> def remove_node ( self , node ) : <EOL> """<STR_LIT>""" <EOL> if _debug : Network . _debug ( "<STR_LIT>" , node ) <EOL> self . nodes . remove ( node ) <EOL> node . lan = None <EOL> def process_pdu ( self , pdu ) : <EOL> """<STR_LIT>""" <EOL> if _debug : Network . _debug ( "<STR_LIT>" , pdu ) <EOL> if self . dropPercent != <NUM_LIT:0.0> : <EOL> if ( random . random ( ) * <NUM_LIT> ) < self . dropPercent : <EOL> if _debug : Network . _debug ( "<STR_LIT>" ) <EOL> return <EOL> if not pdu . pduDestination or not isinstance ( pdu . pduDestination , Address ) : <EOL> raise RuntimeError ( "<STR_LIT>" ) <EOL> elif pdu . pduDestination . addrType == Address . localBroadcastAddr : <EOL> for n in self . nodes : <EOL> if ( pdu . pduSource != n . address ) : <EOL> n . response ( deepcopy ( pdu ) ) <EOL> elif pdu . pduDestination . addrType == Address . localStationAddr : <EOL> for n in self . nodes : <EOL> if n . promiscuous or ( pdu . pduDestination == n . address ) : <EOL> n . response ( deepcopy ( pdu ) ) <EOL> else : <EOL> raise RuntimeError ( "<STR_LIT>" ) <EOL> def __len__ ( self ) : <EOL> """<STR_LIT>""" <EOL> if _debug : Network . _debug ( "<STR_LIT>" ) <EOL> return len ( self . nodes ) <EOL> @ bacpypes_debugging <EOL> class Node ( Server ) : <EOL> def __init__ ( self , addr , lan = None , promiscuous = False , spoofing = False , sid = None ) : <EOL> if _debug : <EOL> Node . _debug ( "<STR_LIT>" , <EOL> addr , lan , promiscuous , spoofing , sid <EOL> ) <EOL> Server . __init__ ( self , sid ) <EOL> if not isinstance ( addr , Address ) : <EOL> raise TypeError ( "<STR_LIT>" ) <EOL> self . lan = None <EOL> self . address = addr <EOL> if lan : <EOL> self . bind ( lan ) <EOL> self . promiscuous = promiscuous <EOL> self . spoofing = spoofing <EOL> def bind ( self , lan ) : <EOL> """<STR_LIT>""" <EOL> if _debug : Node . _debug ( "<STR_LIT>" , lan ) <EOL> lan . add_node ( self ) <EOL> def indication ( self , pdu ) : <EOL> """<STR_LIT>""" <EOL> if _debug : Node . _debug ( "<STR_LIT>" , pdu ) <EOL> if not self . lan : <EOL> raise ConfigurationError ( "<STR_LIT>" ) <EOL> if pdu . pduSource is None : <EOL> pdu . pduSource = self . address <EOL> elif ( not self . spoofing ) and ( pdu . pduSource != self . address ) : <EOL> raise RuntimeError ( "<STR_LIT>" ) <EOL> deferred ( self . lan . process_pdu , pdu ) </s>
<s> """<STR_LIT>""" <EOL> import sys <EOL> from bacpypes . debugging import bacpypes_debugging , ModuleLogger <EOL> from bacpypes . consolelogging import ConfigArgumentParser <EOL> from bacpypes . consolecmd import ConsoleCmd <EOL> from bacpypes . core import run <EOL> from bacpypes . pdu import Address <EOL> from bacpypes . app import LocalDeviceObject , BIPSimpleApplication <EOL> from bacpypes . apdu import Error , AbortPDU , AtomicReadFileRequest , AtomicReadFileRequestAccessMethodChoice , AtomicReadFileRequestAccessMethodChoiceRecordAccess , AtomicReadFileRequestAccessMethodChoiceStreamAccess , AtomicReadFileACK , AtomicWriteFileRequest , AtomicWriteFileRequestAccessMethodChoice , AtomicWriteFileRequestAccessMethodChoiceRecordAccess , AtomicWriteFileRequestAccessMethodChoiceStreamAccess , AtomicWriteFileACK <EOL> from bacpypes . basetypes import ServicesSupported <EOL> _debug = <NUM_LIT:0> <EOL> _log = ModuleLogger ( globals ( ) ) <EOL> this_application = None <EOL> @ bacpypes_debugging <EOL> class TestApplication ( BIPSimpleApplication ) : <EOL> def request ( self , apdu ) : <EOL> if _debug : TestApplication . _debug ( "<STR_LIT>" , apdu ) <EOL> self . _request = apdu <EOL> BIPSimpleApplication . request ( self , apdu ) <EOL> def confirmation ( self , apdu ) : <EOL> if _debug : TestApplication . _debug ( "<STR_LIT>" , apdu ) <EOL> if isinstance ( apdu , Error ) : <EOL> sys . stdout . write ( "<STR_LIT>" % ( apdu . errorCode , ) ) <EOL> sys . stdout . flush ( ) <EOL> elif isinstance ( apdu , AbortPDU ) : <EOL> apdu . debug_contents ( ) <EOL> elif ( isinstance ( self . _request , AtomicReadFileRequest ) ) and ( isinstance ( apdu , AtomicReadFileACK ) ) : <EOL> if apdu . accessMethod . recordAccess : <EOL> value = apdu . accessMethod . recordAccess . fileRecordData <EOL> elif apdu . accessMethod . streamAccess : <EOL> value = apdu . accessMethod . streamAccess . fileData <EOL> TestApplication . _debug ( "<STR_LIT>" , value ) <EOL> sys . stdout . write ( repr ( value ) + '<STR_LIT:\n>' ) <EOL> sys . stdout . flush ( ) <EOL> elif ( isinstance ( self . _request , AtomicWriteFileRequest ) ) and ( isinstance ( apdu , AtomicWriteFileACK ) ) : <EOL> if apdu . fileStartPosition is not None : <EOL> value = apdu . fileStartPosition <EOL> elif apdu . fileStartRecord is not None : <EOL> value = apdu . fileStartRecord <EOL> TestApplication . _debug ( "<STR_LIT>" , value ) <EOL> sys . stdout . write ( repr ( value ) + '<STR_LIT:\n>' ) <EOL> sys . stdout . flush ( ) <EOL> @ bacpypes_debugging <EOL> class TestConsoleCmd ( ConsoleCmd ) : <EOL> def do_readrecord ( self , args ) : <EOL> """<STR_LIT>""" <EOL> args = args . split ( ) <EOL> if _debug : TestConsoleCmd . _debug ( "<STR_LIT>" , args ) <EOL> try : <EOL> addr , obj_inst , start_record , record_count = args <EOL> obj_type = '<STR_LIT:file>' <EOL> obj_inst = int ( obj_inst ) <EOL> start_record = int ( start_record ) <EOL> record_count = int ( record_count ) <EOL> request = AtomicReadFileRequest ( <EOL> fileIdentifier = ( obj_type , obj_inst ) , <EOL> accessMethod = AtomicReadFileRequestAccessMethodChoice ( <EOL> recordAccess = AtomicReadFileRequestAccessMethodChoiceRecordAccess ( <EOL> fileStartRecord = start_record , <EOL> requestedRecordCount = record_count , <EOL> ) , <EOL> ) , <EOL> ) <EOL> request . pduDestination = Address ( addr ) <EOL> if _debug : TestConsoleCmd . _debug ( "<STR_LIT>" , request ) <EOL> this_application . request ( request ) <EOL> except Exception , e : <EOL> TestConsoleCmd . _exception ( "<STR_LIT>" , e ) <EOL> def do_readstream ( self , args ) : <EOL> """<STR_LIT>""" <EOL> args = args . split ( ) <EOL> if _debug : TestConsoleCmd . _debug ( "<STR_LIT>" , args ) <EOL> try : <EOL> addr , obj_inst , start_position , octet_count = args <EOL> obj_type = '<STR_LIT:file>' <EOL> obj_inst = int ( obj_inst ) <EOL> start_position = int ( start_position ) <EOL> octet_count = int ( octet_count ) <EOL> request = AtomicReadFileRequest ( <EOL> fileIdentifier = ( obj_type , obj_inst ) , <EOL> accessMethod = AtomicReadFileRequestAccessMethodChoice ( <EOL> streamAccess = AtomicReadFileRequestAccessMethodChoiceStreamAccess ( <EOL> fileStartPosition = start_position , <EOL> requestedOctetCount = octet_count , <EOL> ) , <EOL> ) , <EOL> ) <EOL> request . pduDestination = Address ( addr ) <EOL> if _debug : TestConsoleCmd . _debug ( "<STR_LIT>" , request ) <EOL> this_application . request ( request ) <EOL> except Exception , e : <EOL> TestConsoleCmd . _exception ( "<STR_LIT>" , e ) <EOL> def do_writerecord ( self , args ) : <EOL> """<STR_LIT>""" <EOL> args = args . split ( ) <EOL> if _debug : TestConsoleCmd . _debug ( "<STR_LIT>" , args ) <EOL> try : <EOL> addr , obj_inst , start_record , record_count = args [ <NUM_LIT:0> : <NUM_LIT:4> ] <EOL> obj_type = '<STR_LIT:file>' <EOL> obj_inst = int ( obj_inst ) <EOL> start_record = int ( start_record ) <EOL> record_count = int ( record_count ) <EOL> record_data = list ( args [ <NUM_LIT:4> : ] ) <EOL> request = AtomicWriteFileRequest ( <EOL> fileIdentifier = ( obj_type , obj_inst ) , <EOL> accessMethod = AtomicWriteFileRequestAccessMethodChoice ( <EOL> recordAccess = AtomicWriteFileRequestAccessMethodChoiceRecordAccess ( <EOL> fileStartRecord = start_record , <EOL> recordCount = record_count , <EOL> fileRecordData = record_data , <EOL> ) , <EOL> ) , <EOL> ) <EOL> request . pduDestination = Address ( addr ) <EOL> if _debug : TestConsoleCmd . _debug ( "<STR_LIT>" , request ) <EOL> this_application . request ( request ) <EOL> except Exception , e : <EOL> TestConsoleCmd . _exception ( "<STR_LIT>" , e ) <EOL> def do_writestream ( self , args ) : <EOL> """<STR_LIT>""" <EOL> args = args . split ( ) <EOL> if _debug : TestConsoleCmd . _debug ( "<STR_LIT>" , args ) <EOL> try : <EOL> addr , obj_inst , start_position , data = args <EOL> obj_type = '<STR_LIT:file>' <EOL> obj_inst = int ( obj_inst ) <EOL> start_position = int ( start_position ) <EOL> request = AtomicWriteFileRequest ( <EOL> fileIdentifier = ( obj_type , obj_inst ) , <EOL> accessMethod = AtomicWriteFileRequestAccessMethodChoice ( <EOL> streamAccess = AtomicWriteFileRequestAccessMethodChoiceStreamAccess ( <EOL> fileStartPosition = start_position , <EOL> fileData = data , <EOL> ) , <EOL> ) , <EOL> ) <EOL> request . pduDestination = Address ( addr ) <EOL> if _debug : TestConsoleCmd . _debug ( "<STR_LIT>" , request ) <EOL> this_application . request ( request ) <EOL> except Exception , e : <EOL> TestConsoleCmd . _exception ( "<STR_LIT>" , e ) <EOL> try : <EOL> args = ConfigArgumentParser ( description = __doc__ ) . parse_args ( ) <EOL> if _debug : _log . debug ( "<STR_LIT>" ) <EOL> if _debug : _log . debug ( "<STR_LIT>" , args ) <EOL> this_device = LocalDeviceObject ( <EOL> objectName = args . ini . objectname , <EOL> objectIdentifier = int ( args . ini . objectidentifier ) , <EOL> maxApduLengthAccepted = int ( args . ini . maxapdulengthaccepted ) , <EOL> segmentationSupported = args . ini . segmentationsupported , <EOL> vendorIdentifier = int ( args . ini . vendoridentifier ) , <EOL> ) <EOL> this_application = TestApplication ( this_device , args . ini . address ) <EOL> services_supported = this_application . get_services_supported ( ) <EOL> if _debug : _log . debug ( "<STR_LIT>" , services_supported ) <EOL> this_device . protocolServicesSupported = services_supported . value <EOL> this_console = TestConsoleCmd ( ) <EOL> _log . debug ( "<STR_LIT>" ) <EOL> run ( ) <EOL> except Exception , e : <EOL> _log . exception ( "<STR_LIT>" , e ) <EOL> finally : <EOL> _log . debug ( "<STR_LIT>" ) </s>
<s> """<STR_LIT>""" <EOL> from . import test_address </s>
<s> from __future__ import division , unicode_literals <EOL> import os <EOL> import hashlib <EOL> import logging <EOL> from collections import defaultdict <EOL> from . bencode import bencode , bdecode <EOL> from . humanize import humanize_bytes <EOL> from . utils import is_unsplitable , get_root_of_unsplitable , Pieces <EOL> logger = logging . getLogger ( '<STR_LIT>' ) <EOL> class Color : <EOL> BLACK = '<STR_LIT>' <EOL> RED = '<STR_LIT>' <EOL> GREEN = '<STR_LIT>' <EOL> YELLOW = '<STR_LIT>' <EOL> BLUE = '<STR_LIT>' <EOL> PINK = '<STR_LIT>' <EOL> CYAN = '<STR_LIT>' <EOL> WHITE = '<STR_LIT>' <EOL> ENDC = '<STR_LIT>' <EOL> COLOR_OK = Color . GREEN <EOL> COLOR_MISSING_FILES = Color . RED <EOL> COLOR_ALREADY_SEEDING = Color . BLUE <EOL> COLOR_FOLDER_EXIST_NOT_SEEDING = Color . YELLOW <EOL> COLOR_FAILED_TO_ADD_TO_CLIENT = Color . PINK <EOL> class Status : <EOL> OK = <NUM_LIT:0> <EOL> MISSING_FILES = <NUM_LIT:1> <EOL> ALREADY_SEEDING = <NUM_LIT:2> <EOL> FOLDER_EXIST_NOT_SEEDING = <NUM_LIT:3> <EOL> FAILED_TO_ADD_TO_CLIENT = <NUM_LIT:4> <EOL> status_messages = { <EOL> Status . OK : '<STR_LIT>' % ( COLOR_OK , Color . ENDC ) , <EOL> Status . MISSING_FILES : '<STR_LIT>' % ( COLOR_MISSING_FILES , Color . ENDC ) , <EOL> Status . ALREADY_SEEDING : '<STR_LIT>' % ( COLOR_ALREADY_SEEDING , Color . ENDC ) , <EOL> Status . FOLDER_EXIST_NOT_SEEDING : '<STR_LIT>' % ( COLOR_FOLDER_EXIST_NOT_SEEDING , Color . ENDC ) , <EOL> Status . FAILED_TO_ADD_TO_CLIENT : '<STR_LIT>' % ( COLOR_FAILED_TO_ADD_TO_CLIENT , Color . ENDC ) , <EOL> } <EOL> CHUNK_SIZE = <NUM_LIT> <EOL> class UnknownLinkTypeException ( Exception ) : <EOL> pass <EOL> class IllegalPathException ( Exception ) : <EOL> pass <EOL> class AutoTorrent ( object ) : <EOL> def __init__ ( self , db , client , store_path , add_limit_size , add_limit_percent , delete_torrents , link_type = '<STR_LIT>' ) : <EOL> self . db = db <EOL> self . client = client <EOL> self . store_path = store_path <EOL> self . add_limit_size = add_limit_size <EOL> self . add_limit_percent = add_limit_percent <EOL> self . delete_torrents = delete_torrents <EOL> self . link_type = link_type <EOL> self . torrents_seeded = set ( ) <EOL> def try_decode ( self , value ) : <EOL> try : <EOL> return value . decode ( '<STR_LIT:utf-8>' ) <EOL> except UnicodeDecodeError : <EOL> logger . debug ( '<STR_LIT>' % value ) <EOL> return value . decode ( '<STR_LIT>' ) <EOL> def is_legal_path ( self , path ) : <EOL> for p in path : <EOL> if p in [ '<STR_LIT:.>' , '<STR_LIT:..>' ] or '<STR_LIT:/>' in p : <EOL> return False <EOL> return True <EOL> def populate_torrents_seeded ( self ) : <EOL> """<STR_LIT>""" <EOL> self . torrents_seeded = set ( x . lower ( ) for x in self . client . get_torrents ( ) ) <EOL> def get_info_hash ( self , torrent ) : <EOL> """<STR_LIT>""" <EOL> return hashlib . sha1 ( bencode ( torrent [ b'<STR_LIT:info>' ] ) ) . hexdigest ( ) <EOL> def find_hash_checks ( self , torrent , result ) : <EOL> """<STR_LIT>""" <EOL> modified_result = False <EOL> pieces = Pieces ( torrent ) <EOL> if self . db . hash_slow_mode : <EOL> logger . info ( '<STR_LIT>' ) <EOL> self . db . build_hash_size_table ( ) <EOL> start_size = <NUM_LIT:0> <EOL> end_size = <NUM_LIT:0> <EOL> logger . info ( '<STR_LIT>' ) <EOL> for f in result : <EOL> start_size = end_size <EOL> end_size += f [ '<STR_LIT>' ] <EOL> if f [ '<STR_LIT>' ] : <EOL> continue <EOL> files_to_check = [ ] <EOL> logger . debug ( '<STR_LIT>' ) <EOL> if self . db . hash_size_mode : <EOL> logger . debug ( '<STR_LIT>' ) <EOL> files_to_check += self . db . find_hash_size ( f [ '<STR_LIT>' ] ) <EOL> if self . db . hash_name_mode : <EOL> logger . debug ( '<STR_LIT>' ) <EOL> name = f [ '<STR_LIT:path>' ] [ - <NUM_LIT:1> ] <EOL> files_to_check += self . db . find_hash_name ( name ) <EOL> if self . db . hash_slow_mode : <EOL> logger . debug ( '<STR_LIT>' ) <EOL> files_to_check += self . db . find_hash_varying_size ( f [ '<STR_LIT>' ] ) <EOL> logger . debug ( '<STR_LIT>' % len ( files_to_check ) ) <EOL> checked_files = set ( ) <EOL> for db_file in files_to_check : <EOL> if db_file in checked_files : <EOL> logger . debug ( '<STR_LIT>' % db_file ) <EOL> checked_files . add ( db_file ) <EOL> logger . info ( '<STR_LIT>' % db_file ) <EOL> match_start , match_end = pieces . match_file ( db_file , start_size , end_size ) <EOL> logger . info ( '<STR_LIT>' % ( db_file , match_start , match_end ) ) <EOL> if match_start or match_end : <EOL> size = os . path . getsize ( db_file ) <EOL> if size != f [ '<STR_LIT>' ] : <EOL> logger . debug ( '<STR_LIT>' ) <EOL> if match_start and match_end : <EOL> logger . debug ( '<STR_LIT>' ) <EOL> modification_point = pieces . find_piece_breakpoint ( db_file , start_size , end_size ) <EOL> elif match_start : <EOL> logger . debug ( '<STR_LIT>' ) <EOL> modification_point = min ( f [ '<STR_LIT>' ] , size ) <EOL> elif match_end : <EOL> logger . debug ( '<STR_LIT>' ) <EOL> modification_point = <NUM_LIT:0> <EOL> if size > f [ '<STR_LIT>' ] : <EOL> modification_action = '<STR_LIT>' <EOL> else : <EOL> modification_action = '<STR_LIT>' <EOL> f [ '<STR_LIT>' ] = False <EOL> f [ '<STR_LIT>' ] = ( '<STR_LIT>' , modification_action , modification_point ) <EOL> modified_result = True <EOL> else : <EOL> logger . debug ( '<STR_LIT>' ) <EOL> f [ '<STR_LIT>' ] = True <EOL> f [ '<STR_LIT>' ] = db_file <EOL> break <EOL> return modified_result , result <EOL> def index_torrent ( self , torrent ) : <EOL> """<STR_LIT>""" <EOL> torrent_name = torrent [ b'<STR_LIT:info>' ] [ b'<STR_LIT:name>' ] <EOL> logger . debug ( '<STR_LIT>' % ( torrent_name , ) ) <EOL> torrent_name = self . try_decode ( torrent_name ) <EOL> if not self . is_legal_path ( [ torrent_name ] ) : <EOL> raise IllegalPathException ( '<STR_LIT>' % torrent_name ) <EOL> logger . info ( '<STR_LIT>' % torrent_name ) <EOL> if self . db . exact_mode : <EOL> prefix = '<STR_LIT:d>' if b'<STR_LIT>' in torrent [ b'<STR_LIT:info>' ] else '<STR_LIT:f>' <EOL> paths = self . db . find_exact_file_path ( prefix , torrent_name ) <EOL> if paths : <EOL> for path in paths : <EOL> logger . debug ( '<STR_LIT>' % path ) <EOL> if prefix == '<STR_LIT:f>' : <EOL> logger . info ( '<STR_LIT>' ) <EOL> size = os . path . getsize ( path ) <EOL> if torrent [ b'<STR_LIT:info>' ] [ b'<STR_LIT>' ] != size : <EOL> continue <EOL> return { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : os . path . dirname ( path ) , <EOL> '<STR_LIT>' : [ { <EOL> '<STR_LIT>' : path , <EOL> '<STR_LIT>' : size , <EOL> '<STR_LIT:path>' : [ torrent_name ] , <EOL> '<STR_LIT>' : True , <EOL> } ] } <EOL> else : <EOL> result = [ ] <EOL> for f in torrent [ b'<STR_LIT:info>' ] [ b'<STR_LIT>' ] : <EOL> orig_path = [ self . try_decode ( x ) for x in f [ b'<STR_LIT:path>' ] ] <EOL> p = os . path . join ( path , * orig_path ) <EOL> if not os . path . isfile ( p ) : <EOL> logger . debug ( '<STR_LIT>' % p ) <EOL> break <EOL> size = os . path . getsize ( p ) <EOL> if size != f [ b'<STR_LIT>' ] : <EOL> logger . debug ( '<STR_LIT>' % ( p , size , f [ b'<STR_LIT>' ] ) ) <EOL> break <EOL> result . append ( { <EOL> '<STR_LIT>' : p , <EOL> '<STR_LIT>' : f [ b'<STR_LIT>' ] , <EOL> '<STR_LIT:path>' : orig_path , <EOL> '<STR_LIT>' : True , <EOL> } ) <EOL> else : <EOL> logger . info ( '<STR_LIT>' ) <EOL> return { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : path , <EOL> '<STR_LIT>' : result } <EOL> result = [ ] <EOL> if b'<STR_LIT>' in torrent [ b'<STR_LIT:info>' ] : <EOL> files_sorted = { } <EOL> files = { } <EOL> if b'<STR_LIT>' in torrent [ b'<STR_LIT:info>' ] : <EOL> i = <NUM_LIT:0> <EOL> path_files = defaultdict ( list ) <EOL> for f in torrent [ b'<STR_LIT:info>' ] [ b'<STR_LIT>' ] : <EOL> logger . debug ( '<STR_LIT>' % ( f , ) ) <EOL> orig_path = [ self . try_decode ( x ) for x in f [ b'<STR_LIT:path>' ] if x ] <EOL> if not self . is_legal_path ( orig_path ) : <EOL> raise IllegalPathException ( '<STR_LIT>' % orig_path ) <EOL> path = [ torrent_name ] + orig_path <EOL> name = path . pop ( ) <EOL> path_files [ os . path . join ( * path ) ] . append ( { <EOL> '<STR_LIT:path>' : orig_path , <EOL> '<STR_LIT>' : f [ b'<STR_LIT>' ] , <EOL> } ) <EOL> files_sorted [ '<STR_LIT:/>' . join ( orig_path ) ] = i <EOL> i += <NUM_LIT:1> <EOL> if self . db . unsplitable_mode : <EOL> unsplitable_paths = set ( ) <EOL> for path , files in path_files . items ( ) : <EOL> if is_unsplitable ( f [ '<STR_LIT:path>' ] [ - <NUM_LIT:1> ] for f in files ) : <EOL> path = path . split ( os . sep ) <EOL> name = get_root_of_unsplitable ( path ) <EOL> if not name : <EOL> continue <EOL> while path [ - <NUM_LIT:1> ] != name : <EOL> path . pop ( ) <EOL> unsplitable_paths . add ( os . path . join ( * path ) ) <EOL> for path , files in path_files . items ( ) : <EOL> if self . db . unsplitable_mode : <EOL> path = path . split ( os . sep ) <EOL> while path and os . path . join ( * path ) not in unsplitable_paths : <EOL> path . pop ( ) <EOL> else : <EOL> path = None <EOL> if path : <EOL> name = path [ - <NUM_LIT:1> ] <EOL> for f in files : <EOL> actual_path = self . db . find_unsplitable_file_path ( name , f [ '<STR_LIT:path>' ] , f [ '<STR_LIT>' ] ) <EOL> f [ '<STR_LIT>' ] = actual_path <EOL> f [ '<STR_LIT>' ] = actual_path is not None <EOL> result += files <EOL> else : <EOL> for f in files : <EOL> actual_path = self . db . find_file_path ( f [ '<STR_LIT:path>' ] [ - <NUM_LIT:1> ] , f [ '<STR_LIT>' ] ) <EOL> f [ '<STR_LIT>' ] = actual_path <EOL> f [ '<STR_LIT>' ] = actual_path is not None <EOL> result += files <EOL> result = sorted ( result , key = lambda x : files_sorted [ '<STR_LIT:/>' . join ( x [ '<STR_LIT:path>' ] ) ] ) <EOL> else : <EOL> length = torrent [ b'<STR_LIT:info>' ] [ b'<STR_LIT>' ] <EOL> actual_path = self . db . find_file_path ( torrent_name , length ) <EOL> result . append ( { <EOL> '<STR_LIT>' : actual_path , <EOL> '<STR_LIT>' : length , <EOL> '<STR_LIT:path>' : [ torrent_name ] , <EOL> '<STR_LIT>' : actual_path is not None , <EOL> } ) <EOL> mode = '<STR_LIT>' <EOL> if self . db . hash_mode : <EOL> modified_result , result = self . find_hash_checks ( torrent , result ) <EOL> if modified_result : <EOL> mode = '<STR_LIT>' <EOL> return { '<STR_LIT>' : mode , '<STR_LIT>' : result } <EOL> def parse_torrent ( self , torrent ) : <EOL> """<STR_LIT>""" <EOL> files = self . index_torrent ( torrent ) <EOL> found_size , missing_size = <NUM_LIT:0> , <NUM_LIT:0> <EOL> for f in files [ '<STR_LIT>' ] : <EOL> if f [ '<STR_LIT>' ] or f . get ( '<STR_LIT>' ) : <EOL> found_size += f [ '<STR_LIT>' ] <EOL> else : <EOL> missing_size += f [ '<STR_LIT>' ] <EOL> return found_size , missing_size , files <EOL> def link_files ( self , destination_path , files ) : <EOL> """<STR_LIT>""" <EOL> if not os . path . isdir ( destination_path ) : <EOL> os . makedirs ( destination_path ) <EOL> for f in files : <EOL> if f [ '<STR_LIT>' ] : <EOL> destination = os . path . join ( destination_path , * f [ '<STR_LIT:path>' ] ) <EOL> file_path = os . path . dirname ( destination ) <EOL> if not os . path . isdir ( file_path ) : <EOL> logger . debug ( '<STR_LIT>' % file_path ) <EOL> os . makedirs ( file_path ) <EOL> logger . debug ( '<STR_LIT>' % ( self . link_type , f [ '<STR_LIT>' ] , destination ) ) <EOL> if self . link_type == '<STR_LIT>' : <EOL> os . symlink ( f [ '<STR_LIT>' ] , destination ) <EOL> elif self . link_type == '<STR_LIT>' : <EOL> os . link ( f [ '<STR_LIT>' ] , destination ) <EOL> else : <EOL> raise UnknownLinkTypeException ( '<STR_LIT>' % self . link_type ) <EOL> def rewrite_hashed_files ( self , destination_path , files ) : <EOL> """<STR_LIT>""" <EOL> if not os . path . isdir ( destination_path ) : <EOL> os . makedirs ( destination_path ) <EOL> for f in files : <EOL> if not f [ '<STR_LIT>' ] and '<STR_LIT>' in f : <EOL> destination = os . path . join ( destination_path , * f [ '<STR_LIT:path>' ] ) <EOL> file_path = os . path . dirname ( destination ) <EOL> if not os . path . isdir ( file_path ) : <EOL> logger . debug ( '<STR_LIT>' % file_path ) <EOL> os . makedirs ( file_path ) <EOL> logger . debug ( '<STR_LIT>' % ( f [ '<STR_LIT>' ] , destination ) ) <EOL> _ , modification_action , modification_point = f [ '<STR_LIT>' ] <EOL> current_size = os . path . getsize ( f [ '<STR_LIT>' ] ) <EOL> expected_size = f [ '<STR_LIT>' ] <EOL> diff = abs ( current_size - expected_size ) <EOL> modified = False <EOL> bytes_written = <NUM_LIT:0> <EOL> with open ( destination , '<STR_LIT:wb>' ) as output_fp : <EOL> with open ( f [ '<STR_LIT>' ] , '<STR_LIT:rb>' ) as input_fp : <EOL> logger . debug ( '<STR_LIT>' % ( f [ '<STR_LIT>' ] , destination , modification_point ) ) <EOL> while True : <EOL> if not modified and bytes_written == modification_point : <EOL> logger . debug ( '<STR_LIT>' % ( modification_action , diff ) ) <EOL> modified = True <EOL> if modification_action == '<STR_LIT>' : <EOL> seek_point = bytes_written + diff <EOL> logger . debug ( '<STR_LIT>' % ( seek_point , ) ) <EOL> input_fp . seek ( seek_point ) <EOL> elif modification_action == '<STR_LIT>' : <EOL> logger . debug ( '<STR_LIT>' % diff ) <EOL> while diff > <NUM_LIT:0> : <EOL> write_bytes = min ( CHUNK_SIZE , diff ) <EOL> output_fp . write ( b'<STR_LIT:\x00>' * write_bytes ) <EOL> diff -= write_bytes <EOL> read_bytes = CHUNK_SIZE <EOL> if not modified : <EOL> read_bytes = min ( read_bytes , modification_point - bytes_written ) <EOL> logger . debug ( '<STR_LIT>' % ( read_bytes , ) ) <EOL> data = input_fp . read ( read_bytes ) <EOL> if not data : <EOL> break <EOL> output_fp . write ( data ) <EOL> bytes_written += read_bytes <EOL> logger . debug ( '<STR_LIT>' ) <EOL> def handle_torrentfile ( self , path , dry_run = False ) : <EOL> """<STR_LIT>""" <EOL> logger . info ( '<STR_LIT>' % path ) <EOL> torrent = self . open_torrentfile ( path ) <EOL> if self . check_torrent_in_client ( torrent ) : <EOL> self . print_status ( Status . ALREADY_SEEDING , path , '<STR_LIT>' ) <EOL> if self . delete_torrents : <EOL> logger . info ( '<STR_LIT>' % path ) <EOL> os . remove ( path ) <EOL> return Status . ALREADY_SEEDING <EOL> found_size , missing_size , files = self . parse_torrent ( torrent ) <EOL> missing_percent = ( missing_size / ( found_size + missing_size ) ) * <NUM_LIT:100> <EOL> found_percent = <NUM_LIT:100> - missing_percent <EOL> would_not_add = missing_size and missing_percent > self . add_limit_percent or missing_size > self . add_limit_size <EOL> if dry_run : <EOL> return found_size , missing_size , would_not_add , [ f [ '<STR_LIT>' ] for f in files [ '<STR_LIT>' ] if f . get ( '<STR_LIT>' ) ] <EOL> if would_not_add : <EOL> logger . info ( '<STR_LIT>' % ( path , found_percent , humanize_bytes ( missing_size ) ) ) <EOL> self . print_status ( Status . MISSING_FILES , path , '<STR_LIT>' % ( found_percent , humanize_bytes ( missing_size ) ) ) <EOL> return Status . MISSING_FILES <EOL> if files [ '<STR_LIT>' ] == '<STR_LIT>' or files [ '<STR_LIT>' ] == '<STR_LIT>' : <EOL> logger . info ( '<STR_LIT>' ) <EOL> destination_path = os . path . join ( self . store_path , os . path . splitext ( os . path . basename ( path ) ) [ <NUM_LIT:0> ] ) <EOL> if os . path . isdir ( destination_path ) : <EOL> logger . info ( '<STR_LIT>' % destination_path ) <EOL> self . print_status ( Status . FOLDER_EXIST_NOT_SEEDING , path , '<STR_LIT>' ) <EOL> return Status . FOLDER_EXIST_NOT_SEEDING <EOL> self . link_files ( destination_path , files [ '<STR_LIT>' ] ) <EOL> elif files [ '<STR_LIT>' ] == '<STR_LIT>' : <EOL> logger . info ( '<STR_LIT>' ) <EOL> destination_path = files [ '<STR_LIT>' ] <EOL> fast_resume = True <EOL> if files [ '<STR_LIT>' ] == '<STR_LIT>' : <EOL> fast_resume = False <EOL> logger . info ( '<STR_LIT>' ) <EOL> self . rewrite_hashed_files ( destination_path , files [ '<STR_LIT>' ] ) <EOL> if self . delete_torrents : <EOL> logger . info ( '<STR_LIT>' % path ) <EOL> os . remove ( path ) <EOL> if self . client . add_torrent ( torrent , destination_path , files [ '<STR_LIT>' ] , fast_resume ) : <EOL> self . print_status ( Status . OK , path , '<STR_LIT>' ) <EOL> return Status . OK <EOL> else : <EOL> self . print_status ( Status . FAILED_TO_ADD_TO_CLIENT , path , '<STR_LIT>' ) <EOL> return Status . FAILED_TO_ADD_TO_CLIENT <EOL> def check_torrent_in_client ( self , torrent ) : <EOL> """<STR_LIT>""" <EOL> info_hash = self . get_info_hash ( torrent ) <EOL> return info_hash in self . torrents_seeded <EOL> def open_torrentfile ( self , path ) : <EOL> """<STR_LIT>""" <EOL> with open ( path , '<STR_LIT:rb>' ) as f : <EOL> return bdecode ( f . read ( ) ) <EOL> def print_status ( self , status , torrentfile , message ) : <EOL> print ( '<STR_LIT>' % ( '<STR_LIT>' % status_messages [ status ] , os . path . splitext ( os . path . basename ( torrentfile ) ) [ <NUM_LIT:0> ] , message ) ) </s>
<s> import pytest <EOL> import exceptions <EOL> def test_exceptions ( ) : <EOL> with pytest . raises ( Exception ) : <EOL> raise exceptions . CardinalException <EOL> with pytest . raises ( exceptions . CardinalException ) : <EOL> raise exceptions . InternalError <EOL> with pytest . raises ( exceptions . CardinalException ) : <EOL> raise exceptions . PluginError <EOL> with pytest . raises ( exceptions . CardinalException ) : <EOL> raise exceptions . CommandNotFoundError <EOL> with pytest . raises ( exceptions . CardinalException ) : <EOL> raise exceptions . ConfigNotFoundError <EOL> with pytest . raises ( exceptions . CardinalException ) : <EOL> raise exceptions . AmbiguousConfigError <EOL> with pytest . raises ( exceptions . CardinalException ) : <EOL> raise exceptions . EventAlreadyExistsError <EOL> with pytest . raises ( exceptions . CardinalException ) : <EOL> raise exceptions . EventDoesNotExistError <EOL> with pytest . raises ( exceptions . CardinalException ) : <EOL> raise exceptions . EventCallbackError <EOL> with pytest . raises ( exceptions . CardinalException ) : <EOL> raise exceptions . EventRejectedMessage </s>
<s> import os <EOL> import legofy <EOL> import tkinter as tk <EOL> import tkinter . ttk as ttk <EOL> from tkinter import filedialog <EOL> import tkinter . messagebox as tkmsg <EOL> LEGO_PALETTE = ( '<STR_LIT:none>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT:all>' , ) <EOL> class LegofyGui ( tk . Tk ) : <EOL> def __init__ ( self , * args , ** kwargs ) : <EOL> super ( ) . __init__ ( * args , ** kwargs ) <EOL> self . wm_title ( "<STR_LIT>" ) <EOL> self . iconbitmap ( os . path . dirname ( os . path . realpath ( __file__ ) ) + '<STR_LIT>' ) <EOL> self . resizable ( False , False ) <EOL> self . body = LegofyGuiMainFrame ( self ) <EOL> self . body . grid ( row = <NUM_LIT:0> , column = <NUM_LIT:0> , padx = <NUM_LIT:10> , pady = <NUM_LIT:10> ) <EOL> class LegofyGuiMainFrame ( tk . Frame ) : <EOL> def __init__ ( self , * args , ** kwargs ) : <EOL> super ( ) . __init__ ( * args , ** kwargs ) <EOL> self . chosenFile = None <EOL> self . chosenFilePath = tk . StringVar ( ) <EOL> self . pathField = tk . Entry ( self , width = <NUM_LIT> , textvariable = self . chosenFilePath , state = tk . DISABLED ) <EOL> self . pathField . grid ( row = <NUM_LIT:0> , column = <NUM_LIT:0> , padx = <NUM_LIT:10> ) <EOL> self . selectFile = tk . Button ( self , text = "<STR_LIT>" , command = self . choose_a_file ) <EOL> self . selectFile . grid ( row = <NUM_LIT:0> , column = <NUM_LIT:1> ) <EOL> self . groupFrame = tk . LabelFrame ( self , text = "<STR_LIT>" , padx = <NUM_LIT:5> , pady = <NUM_LIT:5> ) <EOL> self . groupFrame . grid ( row = <NUM_LIT:1> , column = <NUM_LIT:0> , columnspan = <NUM_LIT:2> , ) <EOL> self . colorPaletteLabel = tk . Label ( self . groupFrame , text = '<STR_LIT>' ) <EOL> self . colorPaletteLabel . grid ( row = <NUM_LIT:0> , column = <NUM_LIT:0> ) <EOL> self . colorPalette = ttk . Combobox ( self . groupFrame ) <EOL> self . colorPalette [ '<STR_LIT>' ] = LEGO_PALETTE <EOL> self . colorPalette . current ( <NUM_LIT:0> ) <EOL> self . colorPalette . grid ( row = <NUM_LIT:0> , column = <NUM_LIT:1> ) <EOL> self . brickNumberScale = tk . Scale ( self . groupFrame , from_ = <NUM_LIT:1> , to = <NUM_LIT:200> , orient = tk . HORIZONTAL , label = "<STR_LIT>" , length = <NUM_LIT> ) <EOL> self . brickNumberScale . set ( <NUM_LIT:30> ) <EOL> self . brickNumberScale . grid ( row = <NUM_LIT:1> , column = <NUM_LIT:0> , columnspan = <NUM_LIT:2> , ) <EOL> self . convertFile = tk . Button ( text = "<STR_LIT>" , command = self . convert_file ) <EOL> self . convertFile . grid ( row = <NUM_LIT:2> , column = <NUM_LIT:0> , columnspan = <NUM_LIT:2> ) <EOL> def choose_a_file ( self ) : <EOL> options = { } <EOL> options [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> options [ '<STR_LIT>' ] = [ ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> ( '<STR_LIT>' , '<STR_LIT>' ) , ] <EOL> options [ '<STR_LIT>' ] = os . path . realpath ( "<STR_LIT:\\>" ) <EOL> options [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> options [ '<STR_LIT>' ] = self <EOL> options [ '<STR_LIT:title>' ] = '<STR_LIT>' <EOL> self . chosenFile = filedialog . askopenfile ( mode = '<STR_LIT:r>' , ** options ) <EOL> if self . chosenFile : <EOL> self . chosenFilePath . set ( self . chosenFile . name ) <EOL> def convert_file ( self ) : <EOL> try : <EOL> if self . chosenFile is not None : <EOL> palette = self . colorPalette . get ( ) <EOL> if palette in LEGO_PALETTE and palette != '<STR_LIT:none>' : <EOL> legofy . main ( self . chosenFile . name , size = self . brickNumberScale . get ( ) , palette_mode = palette ) <EOL> else : <EOL> legofy . main ( self . chosenFile . name , size = self . brickNumberScale . get ( ) ) <EOL> tkmsg . showinfo ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> else : <EOL> tkmsg . showerror ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> except Exception as e : <EOL> tkmsg . showerror ( "<STR_LIT>" , str ( e ) ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> app = LegofyGui ( ) <EOL> app . mainloop ( ) </s>
<s> from distutils . core import setup <EOL> from condent import __version__ <EOL> with open ( "<STR_LIT>" ) as readme : <EOL> long_description = readme . read ( ) <EOL> classifiers = [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ] <EOL> setup ( <EOL> name = "<STR_LIT>" , <EOL> version = __version__ , <EOL> py_modules = [ "<STR_LIT>" ] , <EOL> scripts = [ "<STR_LIT>" ] , <EOL> author = "<STR_LIT>" , <EOL> author_email = "<STR_LIT>" , <EOL> classifiers = classifiers , <EOL> description = "<STR_LIT>" , <EOL> license = "<STR_LIT>" , <EOL> long_description = long_description , <EOL> url = "<STR_LIT>" , <EOL> ) </s>
<s> from pyvi import window <EOL> from pyvi . modes import normal <EOL> class Editor ( object ) : <EOL> _command = None <EOL> active_tab = None <EOL> def __init__ ( self , tabs = None , config = None , normal = normal ) : <EOL> self . config = config <EOL> self . mode = self . normal = normal <EOL> self . count = None <EOL> if tabs is None : <EOL> tabs = self . tabs = [ window . Tab ( self ) ] <EOL> else : <EOL> tabs = self . tabs = list ( tabs ) <EOL> if tabs : <EOL> self . active_tab = tabs [ <NUM_LIT:0> ] <EOL> @ property <EOL> def active_window ( self ) : <EOL> return self . active_tab . active_window <EOL> def keypress ( self , keys ) : <EOL> return self . mode . keypress ( self , keys ) </s>
<s> from collections import deque <EOL> from contextlib import contextmanager <EOL> import json <EOL> from jsonschema import FormatChecker , ValidationError <EOL> from jsonschema . tests . compat import mock , unittest <EOL> from jsonschema . validators import ( <EOL> RefResolutionError , UnknownType , Draft3Validator , <EOL> Draft4Validator , RefResolver , create , extend , validator_for , validate , <EOL> ) <EOL> class TestCreateAndExtend ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . meta_schema = { u"<STR_LIT>" : { u"<STR_LIT>" : { } } } <EOL> self . smelly = mock . MagicMock ( ) <EOL> self . validators = { u"<STR_LIT>" : self . smelly } <EOL> self . types = { u"<STR_LIT>" : dict } <EOL> self . Validator = create ( <EOL> meta_schema = self . meta_schema , <EOL> validators = self . validators , <EOL> default_types = self . types , <EOL> ) <EOL> self . validator_value = <NUM_LIT:12> <EOL> self . schema = { u"<STR_LIT>" : self . validator_value } <EOL> self . validator = self . Validator ( self . schema ) <EOL> def test_attrs ( self ) : <EOL> self . assertEqual ( self . Validator . VALIDATORS , self . validators ) <EOL> self . assertEqual ( self . Validator . META_SCHEMA , self . meta_schema ) <EOL> self . assertEqual ( self . Validator . DEFAULT_TYPES , self . types ) <EOL> def test_init ( self ) : <EOL> self . assertEqual ( self . validator . schema , self . schema ) <EOL> def test_iter_errors ( self ) : <EOL> instance = "<STR_LIT:hello>" <EOL> self . smelly . return_value = [ ] <EOL> self . assertEqual ( list ( self . validator . iter_errors ( instance ) ) , [ ] ) <EOL> error = mock . Mock ( ) <EOL> self . smelly . return_value = [ error ] <EOL> self . assertEqual ( list ( self . validator . iter_errors ( instance ) ) , [ error ] ) <EOL> self . smelly . assert_called_with ( <EOL> self . validator , self . validator_value , instance , self . schema , <EOL> ) <EOL> def test_if_a_version_is_provided_it_is_registered ( self ) : <EOL> with mock . patch ( "<STR_LIT>" ) as validates : <EOL> validates . side_effect = lambda version : lambda cls : cls <EOL> Validator = create ( meta_schema = { u"<STR_LIT:id>" : "<STR_LIT>" } , version = "<STR_LIT>" ) <EOL> validates . assert_called_once_with ( "<STR_LIT>" ) <EOL> self . assertEqual ( Validator . __name__ , "<STR_LIT>" ) <EOL> def test_if_a_version_is_not_provided_it_is_not_registered ( self ) : <EOL> with mock . patch ( "<STR_LIT>" ) as validates : <EOL> create ( meta_schema = { u"<STR_LIT:id>" : "<STR_LIT:id>" } ) <EOL> self . assertFalse ( validates . called ) <EOL> def test_extend ( self ) : <EOL> validators = dict ( self . Validator . VALIDATORS ) <EOL> new = mock . Mock ( ) <EOL> Extended = extend ( self . Validator , validators = { u"<STR_LIT>" : new } ) <EOL> validators . update ( [ ( u"<STR_LIT>" , new ) ] ) <EOL> self . assertEqual ( Extended . VALIDATORS , validators ) <EOL> self . assertNotIn ( u"<STR_LIT>" , self . Validator . VALIDATORS ) <EOL> self . assertEqual ( Extended . META_SCHEMA , self . Validator . META_SCHEMA ) <EOL> self . assertEqual ( Extended . DEFAULT_TYPES , self . Validator . DEFAULT_TYPES ) <EOL> class TestIterErrors ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . validator = Draft3Validator ( { } ) <EOL> def test_iter_errors ( self ) : <EOL> instance = [ <NUM_LIT:1> , <NUM_LIT:2> ] <EOL> schema = { <EOL> u"<STR_LIT>" : u"<STR_LIT>" , <EOL> u"<STR_LIT>" : [ [ "<STR_LIT:a>" , "<STR_LIT:b>" , "<STR_LIT:c>" ] , [ "<STR_LIT:d>" , "<STR_LIT:e>" , "<STR_LIT:f>" ] ] , <EOL> u"<STR_LIT>" : <NUM_LIT:3> <EOL> } <EOL> got = ( e . message for e in self . validator . iter_errors ( instance , schema ) ) <EOL> expected = [ <EOL> "<STR_LIT>" % ( schema [ "<STR_LIT>" ] , ) , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" % ( schema [ "<STR_LIT>" ] , ) , <EOL> ] <EOL> self . assertEqual ( sorted ( got ) , sorted ( expected ) ) <EOL> def test_iter_errors_multiple_failures_one_validator ( self ) : <EOL> instance = { "<STR_LIT:foo>" : <NUM_LIT:2> , "<STR_LIT:bar>" : [ <NUM_LIT:1> ] , "<STR_LIT>" : <NUM_LIT:15> , "<STR_LIT>" : "<STR_LIT>" } <EOL> schema = { <EOL> u"<STR_LIT>" : { <EOL> "<STR_LIT:foo>" : { u"<STR_LIT:type>" : "<STR_LIT:string>" } , <EOL> "<STR_LIT:bar>" : { u"<STR_LIT>" : <NUM_LIT:2> } , <EOL> "<STR_LIT>" : { u"<STR_LIT>" : <NUM_LIT:10> , u"<STR_LIT>" : [ <NUM_LIT:2> , <NUM_LIT:4> , <NUM_LIT:6> , <NUM_LIT:8> ] } , <EOL> } <EOL> } <EOL> errors = list ( self . validator . iter_errors ( instance , schema ) ) <EOL> self . assertEqual ( len ( errors ) , <NUM_LIT:4> ) <EOL> class TestValidationErrorMessages ( unittest . TestCase ) : <EOL> def message_for ( self , instance , schema , * args , ** kwargs ) : <EOL> kwargs . setdefault ( "<STR_LIT>" , Draft3Validator ) <EOL> with self . assertRaises ( ValidationError ) as e : <EOL> validate ( instance , schema , * args , ** kwargs ) <EOL> return e . exception . message <EOL> def test_single_type_failure ( self ) : <EOL> message = self . message_for ( instance = <NUM_LIT:1> , schema = { u"<STR_LIT:type>" : u"<STR_LIT:string>" } ) <EOL> self . assertEqual ( message , "<STR_LIT>" % u"<STR_LIT:string>" ) <EOL> def test_single_type_list_failure ( self ) : <EOL> message = self . message_for ( instance = <NUM_LIT:1> , schema = { u"<STR_LIT:type>" : [ u"<STR_LIT:string>" ] } ) <EOL> self . assertEqual ( message , "<STR_LIT>" % u"<STR_LIT:string>" ) <EOL> def test_multiple_type_failure ( self ) : <EOL> types = u"<STR_LIT:string>" , u"<STR_LIT:object>" <EOL> message = self . message_for ( instance = <NUM_LIT:1> , schema = { u"<STR_LIT:type>" : list ( types ) } ) <EOL> self . assertEqual ( message , "<STR_LIT>" % types ) <EOL> def test_object_without_title_type_failure ( self ) : <EOL> type = { u"<STR_LIT:type>" : [ { u"<STR_LIT>" : <NUM_LIT:3> } ] } <EOL> message = self . message_for ( instance = <NUM_LIT:1> , schema = { u"<STR_LIT:type>" : [ type ] } ) <EOL> self . assertEqual ( message , "<STR_LIT>" % ( type , ) ) <EOL> def test_object_with_name_type_failure ( self ) : <EOL> name = "<STR_LIT>" <EOL> schema = { u"<STR_LIT:type>" : [ { u"<STR_LIT:name>" : name , u"<STR_LIT>" : <NUM_LIT:3> } ] } <EOL> message = self . message_for ( instance = <NUM_LIT:1> , schema = schema ) <EOL> self . assertEqual ( message , "<STR_LIT>" % ( name , ) ) <EOL> def test_minimum ( self ) : <EOL> message = self . message_for ( instance = <NUM_LIT:1> , schema = { "<STR_LIT>" : <NUM_LIT:2> } ) <EOL> self . assertEqual ( message , "<STR_LIT>" ) <EOL> def test_maximum ( self ) : <EOL> message = self . message_for ( instance = <NUM_LIT:1> , schema = { "<STR_LIT>" : <NUM_LIT:0> } ) <EOL> self . assertEqual ( message , "<STR_LIT>" ) <EOL> def test_dependencies_failure_has_single_element_not_list ( self ) : <EOL> depend , on = "<STR_LIT:bar>" , "<STR_LIT:foo>" <EOL> schema = { u"<STR_LIT>" : { depend : on } } <EOL> message = self . message_for ( { "<STR_LIT:bar>" : <NUM_LIT:2> } , schema ) <EOL> self . assertEqual ( message , "<STR_LIT>" % ( on , depend ) ) <EOL> def test_additionalItems_single_failure ( self ) : <EOL> message = self . message_for ( <EOL> [ <NUM_LIT:2> ] , { u"<STR_LIT>" : [ ] , u"<STR_LIT>" : False } , <EOL> ) <EOL> self . assertIn ( "<STR_LIT>" , message ) <EOL> def test_additionalItems_multiple_failures ( self ) : <EOL> message = self . message_for ( <EOL> [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] , { u"<STR_LIT>" : [ ] , u"<STR_LIT>" : False } <EOL> ) <EOL> self . assertIn ( "<STR_LIT>" , message ) <EOL> def test_additionalProperties_single_failure ( self ) : <EOL> additional = "<STR_LIT:foo>" <EOL> schema = { u"<STR_LIT>" : False } <EOL> message = self . message_for ( { additional : <NUM_LIT:2> } , schema ) <EOL> self . assertIn ( "<STR_LIT>" % ( additional , ) , message ) <EOL> def test_additionalProperties_multiple_failures ( self ) : <EOL> schema = { u"<STR_LIT>" : False } <EOL> message = self . message_for ( dict . fromkeys ( [ "<STR_LIT:foo>" , "<STR_LIT:bar>" ] ) , schema ) <EOL> self . assertIn ( repr ( "<STR_LIT:foo>" ) , message ) <EOL> self . assertIn ( repr ( "<STR_LIT:bar>" ) , message ) <EOL> self . assertIn ( "<STR_LIT>" , message ) <EOL> def test_invalid_format_default_message ( self ) : <EOL> checker = FormatChecker ( formats = ( ) ) <EOL> check_fn = mock . Mock ( return_value = False ) <EOL> checker . checks ( u"<STR_LIT>" ) ( check_fn ) <EOL> schema = { u"<STR_LIT>" : u"<STR_LIT>" } <EOL> message = self . message_for ( "<STR_LIT>" , schema , format_checker = checker ) <EOL> self . assertIn ( repr ( "<STR_LIT>" ) , message ) <EOL> self . assertIn ( repr ( "<STR_LIT>" ) , message ) <EOL> self . assertIn ( "<STR_LIT>" , message ) <EOL> class TestValidationErrorDetails ( unittest . TestCase ) : <EOL> def test_anyOf ( self ) : <EOL> instance = <NUM_LIT:5> <EOL> schema = { <EOL> "<STR_LIT>" : [ <EOL> { "<STR_LIT>" : <NUM_LIT:20> } , <EOL> { "<STR_LIT:type>" : "<STR_LIT:string>" } <EOL> ] <EOL> } <EOL> validator = Draft4Validator ( schema ) <EOL> errors = list ( validator . iter_errors ( instance ) ) <EOL> self . assertEqual ( len ( errors ) , <NUM_LIT:1> ) <EOL> e = errors [ <NUM_LIT:0> ] <EOL> self . assertEqual ( e . validator , "<STR_LIT>" ) <EOL> self . assertEqual ( e . validator_value , schema [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( e . instance , instance ) <EOL> self . assertEqual ( e . schema , schema ) <EOL> self . assertIsNone ( e . parent ) <EOL> self . assertEqual ( e . path , deque ( [ ] ) ) <EOL> self . assertEqual ( e . relative_path , deque ( [ ] ) ) <EOL> self . assertEqual ( e . absolute_path , deque ( [ ] ) ) <EOL> self . assertEqual ( e . schema_path , deque ( [ "<STR_LIT>" ] ) ) <EOL> self . assertEqual ( e . relative_schema_path , deque ( [ "<STR_LIT>" ] ) ) <EOL> self . assertEqual ( e . absolute_schema_path , deque ( [ "<STR_LIT>" ] ) ) <EOL> self . assertEqual ( len ( e . context ) , <NUM_LIT:2> ) <EOL> e1 , e2 = sorted_errors ( e . context ) <EOL> self . assertEqual ( e1 . validator , "<STR_LIT>" ) <EOL> self . assertEqual ( e1 . validator_value , schema [ "<STR_LIT>" ] [ <NUM_LIT:0> ] [ "<STR_LIT>" ] ) <EOL> self . assertEqual ( e1 . instance , instance ) <EOL> self . assertEqual ( e1 . schema , schema [ "<STR_LIT>" ] [ <NUM_LIT:0> ] ) <EOL> self . assertIs ( e1 . parent , e ) <EOL> self . assertEqual ( e1 . path , deque ( [ ] ) ) <EOL> self . assertEqual ( e1 . absolute_path , deque ( [ ] ) ) <EOL> self . assertEqual ( e1 . relative_path , deque ( [ ] ) ) <EOL> self . assertEqual ( e1 . schema_path , deque ( [ <NUM_LIT:0> , "<STR_LIT>" ] ) ) <EOL> self . assertEqual ( e1 . relative_schema_path , deque ( [ <NUM_LIT:0> , "<STR_LIT>" ] ) ) <EOL> self . assertEqual ( <EOL> e1 . absolute_schema_path , deque ( [ "<STR_LIT>" , <NUM_LIT:0> , "<STR_LIT>" ] ) , <EOL> ) <EOL> self . assertFalse ( e1 . context ) <EOL> self . assertEqual ( e2 . validator , "<STR_LIT:type>" ) <EOL> self . assertEqual ( e2 . validator_value , schema [ "<STR_LIT>" ] [ <NUM_LIT:1> ] [ "<STR_LIT:type>" ] ) <EOL> self . assertEqual ( e2 . instance , instance ) <EOL> self . assertEqual ( e2 . schema , schema [ "<STR_LIT>" ] [ <NUM_LIT:1> ] ) <EOL> self . assertIs ( e2 . parent , e ) <EOL> self . assertEqual ( e2 . path , deque ( [ ] ) ) <EOL> self . assertEqual ( e2 . relative_path , deque ( [ ] ) ) <EOL> self . assertEqual ( e2 . absolute_path , deque ( [ ] ) ) <EOL> self . assertEqual ( e2 . schema_path , deque ( [ <NUM_LIT:1> , "<STR_LIT:type>" ] ) ) <EOL> self . assertEqual ( e2 . relative_schema_path , deque ( [ <NUM_LIT:1> , "<STR_LIT:type>" ] ) ) <EOL> self . assertEqual ( e2 . absolute_schema_path , deque ( [ "<STR_LIT>" , <NUM_LIT:1> , "<STR_LIT:type>" ] ) ) <EOL> self . assertEqual ( len ( e2 . context ) , <NUM_LIT:0> ) <EOL> def test_type ( self ) : <EOL> instance = { "<STR_LIT:foo>" : <NUM_LIT:1> } <EOL> schema = { <EOL> "<STR_LIT:type>" : [ <EOL> { "<STR_LIT:type>" : "<STR_LIT>" } , <EOL> { <EOL> "<STR_LIT:type>" : "<STR_LIT:object>" , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT:foo>" : { "<STR_LIT>" : [ <NUM_LIT:2> ] } <EOL> } <EOL> } <EOL> ] <EOL> } <EOL> validator = Draft3Validator ( schema ) <EOL> errors = list ( validator . iter_errors ( instance ) ) <EOL> self . assertEqual ( len ( errors ) , <NUM_LIT:1> ) <EOL> e = errors [ <NUM_LIT:0> ] <EOL> self . assertEqual ( e . validator , "<STR_LIT:type>" ) <EOL> self . assertEqual ( e . validator_value , schema [ "<STR_LIT:type>" ] ) <EOL> self . assertEqual ( e . instance , instance ) <EOL> self . assertEqual ( e . schema , schema ) <EOL> self . assertIsNone ( e . parent ) <EOL> self . assertEqual ( e . path , deque ( [ ] ) ) <EOL> self . assertEqual ( e . relative_path , deque ( [ ] ) ) <EOL> self . assertEqual ( e . absolute_path , deque ( [ ] ) ) <EOL> self . assertEqual ( e . schema_path , deque ( [ "<STR_LIT:type>" ] ) ) <EOL> self . assertEqual ( e . relative_schema_path , deque ( [ "<STR_LIT:type>" ] ) ) <EOL> self . assertEqual ( e . absolute_schema_path , deque ( [ "<STR_LIT:type>" ] ) ) <EOL> self . assertEqual ( len ( e . context ) , <NUM_LIT:2> ) <EOL> e1 , e2 = sorted_errors ( e . context ) <EOL> self . assertEqual ( e1 . validator , "<STR_LIT:type>" ) <EOL> self . assertEqual ( e1 . validator_value , schema [ "<STR_LIT:type>" ] [ <NUM_LIT:0> ] [ "<STR_LIT:type>" ] ) <EOL> self . assertEqual ( e1 . instance , instance ) <EOL> self . assertEqual ( e1 . schema , schema [ "<STR_LIT:type>" ] [ <NUM_LIT:0> ] ) <EOL> self . assertIs ( e1 . parent , e ) <EOL> self . assertEqual ( e1 . path , deque ( [ ] ) ) <EOL> self . assertEqual ( e1 . relative_path , deque ( [ ] ) ) <EOL> self . assertEqual ( e1 . absolute_path , deque ( [ ] ) ) <EOL> self . assertEqual ( e1 . schema_path , deque ( [ <NUM_LIT:0> , "<STR_LIT:type>" ] ) ) <EOL> self . assertEqual ( e1 . relative_schema_path , deque ( [ <NUM_LIT:0> , "<STR_LIT:type>" ] ) ) <EOL> self . assertEqual ( e1 . absolute_schema_path , deque ( [ "<STR_LIT:type>" , <NUM_LIT:0> , "<STR_LIT:type>" ] ) ) <EOL> self . assertFalse ( e1 . context ) <EOL> self . assertEqual ( e2 . validator , "<STR_LIT>" ) <EOL> self . assertEqual ( e2 . validator_value , [ <NUM_LIT:2> ] ) <EOL> self . assertEqual ( e2 . instance , <NUM_LIT:1> ) <EOL> self . assertEqual ( e2 . schema , { u"<STR_LIT>" : [ <NUM_LIT:2> ] } ) <EOL> self . assertIs ( e2 . parent , e ) <EOL> self . assertEqual ( e2 . path , deque ( [ "<STR_LIT:foo>" ] ) ) <EOL> self . assertEqual ( e2 . relative_path , deque ( [ "<STR_LIT:foo>" ] ) ) <EOL> self . assertEqual ( e2 . absolute_path , deque ( [ "<STR_LIT:foo>" ] ) ) <EOL> self . assertEqual ( <EOL> e2 . schema_path , deque ( [ <NUM_LIT:1> , "<STR_LIT>" , "<STR_LIT:foo>" , "<STR_LIT>" ] ) , <EOL> ) <EOL> self . assertEqual ( <EOL> e2 . relative_schema_path , deque ( [ <NUM_LIT:1> , "<STR_LIT>" , "<STR_LIT:foo>" , "<STR_LIT>" ] ) , <EOL> ) <EOL> self . assertEqual ( <EOL> e2 . absolute_schema_path , <EOL> deque ( [ "<STR_LIT:type>" , <NUM_LIT:1> , "<STR_LIT>" , "<STR_LIT:foo>" , "<STR_LIT>" ] ) , <EOL> ) <EOL> self . assertFalse ( e2 . context ) <EOL> def test_single_nesting ( self ) : <EOL> instance = { "<STR_LIT:foo>" : <NUM_LIT:2> , "<STR_LIT:bar>" : [ <NUM_LIT:1> ] , "<STR_LIT>" : <NUM_LIT:15> , "<STR_LIT>" : "<STR_LIT>" } <EOL> schema = { <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT:foo>" : { "<STR_LIT:type>" : "<STR_LIT:string>" } , <EOL> "<STR_LIT:bar>" : { "<STR_LIT>" : <NUM_LIT:2> } , <EOL> "<STR_LIT>" : { "<STR_LIT>" : <NUM_LIT:10> , "<STR_LIT>" : [ <NUM_LIT:2> , <NUM_LIT:4> , <NUM_LIT:6> , <NUM_LIT:8> ] } , <EOL> } <EOL> } <EOL> validator = Draft3Validator ( schema ) <EOL> errors = validator . iter_errors ( instance ) <EOL> e1 , e2 , e3 , e4 = sorted_errors ( errors ) <EOL> self . assertEqual ( e1 . path , deque ( [ "<STR_LIT:bar>" ] ) ) <EOL> self . assertEqual ( e2 . path , deque ( [ "<STR_LIT>" ] ) ) <EOL> self . assertEqual ( e3 . path , deque ( [ "<STR_LIT>" ] ) ) <EOL> self . assertEqual ( e4 . path , deque ( [ "<STR_LIT:foo>" ] ) ) <EOL> self . assertEqual ( e1 . relative_path , deque ( [ "<STR_LIT:bar>" ] ) ) <EOL> self . assertEqual ( e2 . relative_path , deque ( [ "<STR_LIT>" ] ) ) <EOL> self . assertEqual ( e3 . relative_path , deque ( [ "<STR_LIT>" ] ) ) <EOL> self . assertEqual ( e4 . relative_path , deque ( [ "<STR_LIT:foo>" ] ) ) <EOL> self . assertEqual ( e1 . absolute_path , deque ( [ "<STR_LIT:bar>" ] ) ) <EOL> self . assertEqual ( e2 . absolute_path , deque ( [ "<STR_LIT>" ] ) ) <EOL> self . assertEqual ( e3 . absolute_path , deque ( [ "<STR_LIT>" ] ) ) <EOL> self . assertEqual ( e4 . absolute_path , deque ( [ "<STR_LIT:foo>" ] ) ) <EOL> self . assertEqual ( e1 . validator , "<STR_LIT>" ) <EOL> self . assertEqual ( e2 . validator , "<STR_LIT>" ) <EOL> self . assertEqual ( e3 . validator , "<STR_LIT>" ) <EOL> self . assertEqual ( e4 . validator , "<STR_LIT:type>" ) <EOL> def test_multiple_nesting ( self ) : <EOL> instance = [ <NUM_LIT:1> , { "<STR_LIT:foo>" : <NUM_LIT:2> , "<STR_LIT:bar>" : { "<STR_LIT>" : [ <NUM_LIT:1> ] } } , "<STR_LIT>" ] <EOL> schema = { <EOL> "<STR_LIT:type>" : "<STR_LIT:string>" , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT:type>" : [ "<STR_LIT:string>" , "<STR_LIT:object>" ] , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT:foo>" : { "<STR_LIT>" : [ <NUM_LIT:1> , <NUM_LIT:3> ] } , <EOL> "<STR_LIT:bar>" : { <EOL> "<STR_LIT:type>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT:bar>" : { "<STR_LIT>" : True } , <EOL> "<STR_LIT>" : { "<STR_LIT>" : <NUM_LIT:2> } , <EOL> } <EOL> } <EOL> } <EOL> } <EOL> } <EOL> validator = Draft3Validator ( schema ) <EOL> errors = validator . iter_errors ( instance ) <EOL> e1 , e2 , e3 , e4 , e5 , e6 = sorted_errors ( errors ) <EOL> self . assertEqual ( e1 . path , deque ( [ ] ) ) <EOL> self . assertEqual ( e2 . path , deque ( [ <NUM_LIT:0> ] ) ) <EOL> self . assertEqual ( e3 . path , deque ( [ <NUM_LIT:1> , "<STR_LIT:bar>" ] ) ) <EOL> self . assertEqual ( e4 . path , deque ( [ <NUM_LIT:1> , "<STR_LIT:bar>" , "<STR_LIT:bar>" ] ) ) <EOL> self . assertEqual ( e5 . path , deque ( [ <NUM_LIT:1> , "<STR_LIT:bar>" , "<STR_LIT>" ] ) ) <EOL> self . assertEqual ( e6 . path , deque ( [ <NUM_LIT:1> , "<STR_LIT:foo>" ] ) ) <EOL> self . assertEqual ( e1 . schema_path , deque ( [ "<STR_LIT:type>" ] ) ) <EOL> self . assertEqual ( e2 . schema_path , deque ( [ "<STR_LIT>" , "<STR_LIT:type>" ] ) ) <EOL> self . assertEqual ( <EOL> list ( e3 . schema_path ) , [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT:bar>" , "<STR_LIT:type>" ] , <EOL> ) <EOL> self . assertEqual ( <EOL> list ( e4 . schema_path ) , <EOL> [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT:bar>" , "<STR_LIT>" , "<STR_LIT:bar>" , "<STR_LIT>" ] , <EOL> ) <EOL> self . assertEqual ( <EOL> list ( e5 . schema_path ) , <EOL> [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT:bar>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] <EOL> ) <EOL> self . assertEqual ( <EOL> list ( e6 . schema_path ) , [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT:foo>" , "<STR_LIT>" ] , <EOL> ) <EOL> self . assertEqual ( e1 . validator , "<STR_LIT:type>" ) <EOL> self . assertEqual ( e2 . validator , "<STR_LIT:type>" ) <EOL> self . assertEqual ( e3 . validator , "<STR_LIT:type>" ) <EOL> self . assertEqual ( e4 . validator , "<STR_LIT>" ) <EOL> self . assertEqual ( e5 . validator , "<STR_LIT>" ) <EOL> self . assertEqual ( e6 . validator , "<STR_LIT>" ) <EOL> def test_recursive ( self ) : <EOL> schema = { <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : [ { <EOL> "<STR_LIT:type>" : "<STR_LIT:object>" , <EOL> "<STR_LIT>" : [ "<STR_LIT:name>" , "<STR_LIT>" ] , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT:name>" : { <EOL> "<STR_LIT:type>" : "<STR_LIT:string>" , <EOL> } , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT:type>" : "<STR_LIT:object>" , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> } , <EOL> } , <EOL> } , <EOL> } , <EOL> } ] , <EOL> } , <EOL> } , <EOL> "<STR_LIT:type>" : "<STR_LIT:object>" , <EOL> "<STR_LIT>" : [ "<STR_LIT:root>" ] , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT:root>" : { "<STR_LIT>" : "<STR_LIT>" } , <EOL> } <EOL> } <EOL> instance = { <EOL> "<STR_LIT:root>" : { <EOL> "<STR_LIT:name>" : "<STR_LIT:root>" , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT:a>" : { <EOL> "<STR_LIT:name>" : "<STR_LIT:a>" , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT:name>" : "<STR_LIT>" , <EOL> } <EOL> } <EOL> } , <EOL> } , <EOL> } , <EOL> } <EOL> validator = Draft4Validator ( schema ) <EOL> e , = validator . iter_errors ( instance ) <EOL> self . assertEqual ( e . absolute_path , deque ( [ "<STR_LIT:root>" ] ) ) <EOL> self . assertEqual ( <EOL> e . absolute_schema_path , deque ( [ "<STR_LIT>" , "<STR_LIT:root>" , "<STR_LIT>" ] ) , <EOL> ) <EOL> e1 , = e . context <EOL> self . assertEqual ( e1 . absolute_path , deque ( [ "<STR_LIT:root>" , "<STR_LIT>" , "<STR_LIT:a>" ] ) ) <EOL> self . assertEqual ( <EOL> e1 . absolute_schema_path , deque ( <EOL> [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT:root>" , <EOL> "<STR_LIT>" , <EOL> <NUM_LIT:0> , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ] , <EOL> ) , <EOL> ) <EOL> e2 , = e1 . context <EOL> self . assertEqual ( <EOL> e2 . absolute_path , deque ( <EOL> [ "<STR_LIT:root>" , "<STR_LIT>" , "<STR_LIT:a>" , "<STR_LIT>" , "<STR_LIT>" ] , <EOL> ) , <EOL> ) <EOL> self . assertEqual ( <EOL> e2 . absolute_schema_path , deque ( <EOL> [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT:root>" , <EOL> "<STR_LIT>" , <EOL> <NUM_LIT:0> , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> <NUM_LIT:0> , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" <EOL> ] , <EOL> ) , <EOL> ) <EOL> def test_additionalProperties ( self ) : <EOL> instance = { "<STR_LIT:bar>" : "<STR_LIT:bar>" , "<STR_LIT:foo>" : <NUM_LIT:2> } <EOL> schema = { <EOL> "<STR_LIT>" : { "<STR_LIT:type>" : "<STR_LIT>" , "<STR_LIT>" : <NUM_LIT:5> } <EOL> } <EOL> validator = Draft3Validator ( schema ) <EOL> errors = validator . iter_errors ( instance ) <EOL> e1 , e2 = sorted_errors ( errors ) <EOL> self . assertEqual ( e1 . path , deque ( [ "<STR_LIT:bar>" ] ) ) <EOL> self . assertEqual ( e2 . path , deque ( [ "<STR_LIT:foo>" ] ) ) <EOL> self . assertEqual ( e1 . validator , "<STR_LIT:type>" ) <EOL> self . assertEqual ( e2 . validator , "<STR_LIT>" ) <EOL> def test_patternProperties ( self ) : <EOL> instance = { "<STR_LIT:bar>" : <NUM_LIT:1> , "<STR_LIT:foo>" : <NUM_LIT:2> } <EOL> schema = { <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT:bar>" : { "<STR_LIT:type>" : "<STR_LIT:string>" } , <EOL> "<STR_LIT:foo>" : { "<STR_LIT>" : <NUM_LIT:5> } <EOL> } <EOL> } <EOL> validator = Draft3Validator ( schema ) <EOL> errors = validator . iter_errors ( instance ) <EOL> e1 , e2 = sorted_errors ( errors ) <EOL> self . assertEqual ( e1 . path , deque ( [ "<STR_LIT:bar>" ] ) ) <EOL> self . assertEqual ( e2 . path , deque ( [ "<STR_LIT:foo>" ] ) ) <EOL> self . assertEqual ( e1 . validator , "<STR_LIT:type>" ) <EOL> self . assertEqual ( e2 . validator , "<STR_LIT>" ) <EOL> def test_additionalItems ( self ) : <EOL> instance = [ "<STR_LIT:foo>" , <NUM_LIT:1> ] <EOL> schema = { <EOL> "<STR_LIT>" : [ ] , <EOL> "<STR_LIT>" : { "<STR_LIT:type>" : "<STR_LIT>" , "<STR_LIT>" : <NUM_LIT:5> } <EOL> } <EOL> validator = Draft3Validator ( schema ) <EOL> errors = validator . iter_errors ( instance ) <EOL> e1 , e2 = sorted_errors ( errors ) <EOL> self . assertEqual ( e1 . path , deque ( [ <NUM_LIT:0> ] ) ) <EOL> self . assertEqual ( e2 . path , deque ( [ <NUM_LIT:1> ] ) ) <EOL> self . assertEqual ( e1 . validator , "<STR_LIT:type>" ) <EOL> self . assertEqual ( e2 . validator , "<STR_LIT>" ) <EOL> def test_additionalItems_with_items ( self ) : <EOL> instance = [ "<STR_LIT:foo>" , "<STR_LIT:bar>" , <NUM_LIT:1> ] <EOL> schema = { <EOL> "<STR_LIT>" : [ { } ] , <EOL> "<STR_LIT>" : { "<STR_LIT:type>" : "<STR_LIT>" , "<STR_LIT>" : <NUM_LIT:5> } <EOL> } <EOL> validator = Draft3Validator ( schema ) <EOL> errors = validator . iter_errors ( instance ) <EOL> e1 , e2 = sorted_errors ( errors ) <EOL> self . assertEqual ( e1 . path , deque ( [ <NUM_LIT:1> ] ) ) <EOL> self . assertEqual ( e2 . path , deque ( [ <NUM_LIT:2> ] ) ) <EOL> self . assertEqual ( e1 . validator , "<STR_LIT:type>" ) <EOL> self . assertEqual ( e2 . validator , "<STR_LIT>" ) <EOL> class ValidatorTestMixin ( object ) : <EOL> def setUp ( self ) : <EOL> self . instance = mock . Mock ( ) <EOL> self . schema = { } <EOL> self . resolver = mock . Mock ( ) <EOL> self . validator = self . validator_class ( self . schema ) <EOL> def test_valid_instances_are_valid ( self ) : <EOL> errors = iter ( [ ] ) <EOL> with mock . patch . object ( <EOL> self . validator , "<STR_LIT>" , return_value = errors , <EOL> ) : <EOL> self . assertTrue ( <EOL> self . validator . is_valid ( self . instance , self . schema ) <EOL> ) <EOL> def test_invalid_instances_are_not_valid ( self ) : <EOL> errors = iter ( [ mock . Mock ( ) ] ) <EOL> with mock . patch . object ( <EOL> self . validator , "<STR_LIT>" , return_value = errors , <EOL> ) : <EOL> self . assertFalse ( <EOL> self . validator . is_valid ( self . instance , self . schema ) <EOL> ) <EOL> def test_non_existent_properties_are_ignored ( self ) : <EOL> instance , my_property , my_value = mock . Mock ( ) , mock . Mock ( ) , mock . Mock ( ) <EOL> validate ( instance = instance , schema = { my_property : my_value } ) <EOL> def test_it_creates_a_ref_resolver_if_not_provided ( self ) : <EOL> self . assertIsInstance ( self . validator . resolver , RefResolver ) <EOL> def test_it_delegates_to_a_ref_resolver ( self ) : <EOL> resolver = RefResolver ( "<STR_LIT>" , { } ) <EOL> schema = { "<STR_LIT>" : mock . Mock ( ) } <EOL> with mock . patch . object ( resolver , "<STR_LIT>" ) as resolve : <EOL> resolve . return_value = "<STR_LIT:url>" , { "<STR_LIT:type>" : "<STR_LIT>" } <EOL> with self . assertRaises ( ValidationError ) : <EOL> self . validator_class ( schema , resolver = resolver ) . validate ( None ) <EOL> resolve . assert_called_once_with ( schema [ "<STR_LIT>" ] ) <EOL> def test_it_delegates_to_a_legacy_ref_resolver ( self ) : <EOL> """<STR_LIT>""" <EOL> class LegacyRefResolver ( object ) : <EOL> @ contextmanager <EOL> def resolving ( this , ref ) : <EOL> self . assertEqual ( ref , "<STR_LIT>" ) <EOL> yield { "<STR_LIT:type>" : "<STR_LIT>" } <EOL> resolver = LegacyRefResolver ( ) <EOL> schema = { "<STR_LIT>" : "<STR_LIT>" } <EOL> with self . assertRaises ( ValidationError ) : <EOL> self . validator_class ( schema , resolver = resolver ) . validate ( None ) <EOL> def test_is_type_is_true_for_valid_type ( self ) : <EOL> self . assertTrue ( self . validator . is_type ( "<STR_LIT:foo>" , "<STR_LIT:string>" ) ) <EOL> def test_is_type_is_false_for_invalid_type ( self ) : <EOL> self . assertFalse ( self . validator . is_type ( "<STR_LIT:foo>" , "<STR_LIT>" ) ) <EOL> def test_is_type_evades_bool_inheriting_from_int ( self ) : <EOL> self . assertFalse ( self . validator . is_type ( True , "<STR_LIT>" ) ) <EOL> self . assertFalse ( self . validator . is_type ( True , "<STR_LIT>" ) ) <EOL> def test_is_type_raises_exception_for_unknown_type ( self ) : <EOL> with self . assertRaises ( UnknownType ) : <EOL> self . validator . is_type ( "<STR_LIT:foo>" , object ( ) ) <EOL> class TestDraft3Validator ( ValidatorTestMixin , unittest . TestCase ) : <EOL> validator_class = Draft3Validator <EOL> def test_is_type_is_true_for_any_type ( self ) : <EOL> self . assertTrue ( self . validator . is_valid ( mock . Mock ( ) , { "<STR_LIT:type>" : "<STR_LIT>" } ) ) <EOL> def test_is_type_does_not_evade_bool_if_it_is_being_tested ( self ) : <EOL> self . assertTrue ( self . validator . is_type ( True , "<STR_LIT>" ) ) <EOL> self . assertTrue ( self . validator . is_valid ( True , { "<STR_LIT:type>" : "<STR_LIT>" } ) ) <EOL> def test_non_string_custom_types ( self ) : <EOL> schema = { '<STR_LIT:type>' : [ None ] } <EOL> cls = self . validator_class ( schema , types = { None : type ( None ) } ) <EOL> cls . validate ( None , schema ) <EOL> class TestDraft4Validator ( ValidatorTestMixin , unittest . TestCase ) : <EOL> validator_class = Draft4Validator <EOL> class TestBuiltinFormats ( unittest . TestCase ) : <EOL> """<STR_LIT>""" <EOL> for format in FormatChecker . checkers : <EOL> def test ( self , format = format ) : <EOL> v = Draft4Validator ( { "<STR_LIT>" : format } , format_checker = FormatChecker ( ) ) <EOL> v . validate ( <NUM_LIT> ) <EOL> name = "<STR_LIT>" . format ( format ) <EOL> test . __name__ = name <EOL> setattr ( TestBuiltinFormats , name , test ) <EOL> del test <EOL> class TestValidatorFor ( unittest . TestCase ) : <EOL> def test_draft_3 ( self ) : <EOL> schema = { "<STR_LIT>" : "<STR_LIT>" } <EOL> self . assertIs ( validator_for ( schema ) , Draft3Validator ) <EOL> schema = { "<STR_LIT>" : "<STR_LIT>" } <EOL> self . assertIs ( validator_for ( schema ) , Draft3Validator ) <EOL> def test_draft_4 ( self ) : <EOL> schema = { "<STR_LIT>" : "<STR_LIT>" } <EOL> self . assertIs ( validator_for ( schema ) , Draft4Validator ) <EOL> schema = { "<STR_LIT>" : "<STR_LIT>" } <EOL> self . assertIs ( validator_for ( schema ) , Draft4Validator ) <EOL> def test_custom_validator ( self ) : <EOL> Validator = create ( meta_schema = { "<STR_LIT:id>" : "<STR_LIT>" } , version = "<STR_LIT>" ) <EOL> schema = { "<STR_LIT>" : "<STR_LIT>" } <EOL> self . assertIs ( validator_for ( schema ) , Validator ) <EOL> def test_validator_for_jsonschema_default ( self ) : <EOL> self . assertIs ( validator_for ( { } ) , Draft4Validator ) <EOL> def test_validator_for_custom_default ( self ) : <EOL> self . assertIs ( validator_for ( { } , default = None ) , None ) <EOL> class TestValidate ( unittest . TestCase ) : <EOL> def test_draft3_validator_is_chosen ( self ) : <EOL> schema = { "<STR_LIT>" : "<STR_LIT>" } <EOL> with mock . patch . object ( Draft3Validator , "<STR_LIT>" ) as chk_schema : <EOL> validate ( { } , schema ) <EOL> chk_schema . assert_called_once_with ( schema ) <EOL> schema = { "<STR_LIT>" : "<STR_LIT>" } <EOL> with mock . patch . object ( Draft3Validator , "<STR_LIT>" ) as chk_schema : <EOL> validate ( { } , schema ) <EOL> chk_schema . assert_called_once_with ( schema ) <EOL> def test_draft4_validator_is_chosen ( self ) : <EOL> schema = { "<STR_LIT>" : "<STR_LIT>" } <EOL> with mock . patch . object ( Draft4Validator , "<STR_LIT>" ) as chk_schema : <EOL> validate ( { } , schema ) <EOL> chk_schema . assert_called_once_with ( schema ) <EOL> def test_draft4_validator_is_the_default ( self ) : <EOL> with mock . patch . object ( Draft4Validator , "<STR_LIT>" ) as chk_schema : <EOL> validate ( { } , { } ) <EOL> chk_schema . assert_called_once_with ( { } ) <EOL> class TestRefResolver ( unittest . TestCase ) : <EOL> base_uri = "<STR_LIT>" <EOL> stored_uri = "<STR_LIT>" <EOL> stored_schema = { "<STR_LIT>" : "<STR_LIT>" } <EOL> def setUp ( self ) : <EOL> self . referrer = { } <EOL> self . store = { self . stored_uri : self . stored_schema } <EOL> self . resolver = RefResolver ( self . base_uri , self . referrer , self . store ) <EOL> def test_it_does_not_retrieve_schema_urls_from_the_network ( self ) : <EOL> ref = Draft3Validator . META_SCHEMA [ "<STR_LIT:id>" ] <EOL> with mock . patch . object ( self . resolver , "<STR_LIT>" ) as remote : <EOL> with self . resolver . resolving ( ref ) as resolved : <EOL> self . assertEqual ( resolved , Draft3Validator . META_SCHEMA ) <EOL> self . assertFalse ( remote . called ) <EOL> def test_it_resolves_local_refs ( self ) : <EOL> ref = "<STR_LIT>" <EOL> self . referrer [ "<STR_LIT>" ] = { "<STR_LIT:foo>" : object ( ) } <EOL> with self . resolver . resolving ( ref ) as resolved : <EOL> self . assertEqual ( resolved , self . referrer [ "<STR_LIT>" ] [ "<STR_LIT:foo>" ] ) <EOL> def test_it_resolves_local_refs_with_id ( self ) : <EOL> schema = { "<STR_LIT:id>" : "<STR_LIT>" , "<STR_LIT:a>" : { "<STR_LIT:foo>" : "<STR_LIT:bar>" } } <EOL> resolver = RefResolver . from_schema ( schema ) <EOL> with resolver . resolving ( "<STR_LIT>" ) as resolved : <EOL> self . assertEqual ( resolved , schema [ "<STR_LIT:a>" ] ) <EOL> with resolver . resolving ( "<STR_LIT>" ) as resolved : <EOL> self . assertEqual ( resolved , schema [ "<STR_LIT:a>" ] ) <EOL> def test_it_retrieves_stored_refs ( self ) : <EOL> with self . resolver . resolving ( self . stored_uri ) as resolved : <EOL> self . assertIs ( resolved , self . stored_schema ) <EOL> self . resolver . store [ "<STR_LIT>" ] = { "<STR_LIT:foo>" : <NUM_LIT:12> } <EOL> with self . resolver . resolving ( "<STR_LIT>" ) as resolved : <EOL> self . assertEqual ( resolved , <NUM_LIT:12> ) <EOL> def test_it_retrieves_unstored_refs_via_requests ( self ) : <EOL> ref = "<STR_LIT>" <EOL> schema = { "<STR_LIT>" : <NUM_LIT:12> } <EOL> with mock . patch ( "<STR_LIT>" ) as requests : <EOL> requests . get . return_value . json . return_value = schema <EOL> with self . resolver . resolving ( ref ) as resolved : <EOL> self . assertEqual ( resolved , <NUM_LIT:12> ) <EOL> requests . get . assert_called_once_with ( "<STR_LIT>" ) <EOL> def test_it_retrieves_unstored_refs_via_urlopen ( self ) : <EOL> ref = "<STR_LIT>" <EOL> schema = { "<STR_LIT>" : <NUM_LIT:12> } <EOL> with mock . patch ( "<STR_LIT>" , None ) : <EOL> with mock . patch ( "<STR_LIT>" ) as urlopen : <EOL> urlopen . return_value . read . return_value = ( <EOL> json . dumps ( schema ) . encode ( "<STR_LIT:utf8>" ) ) <EOL> with self . resolver . resolving ( ref ) as resolved : <EOL> self . assertEqual ( resolved , <NUM_LIT:12> ) <EOL> urlopen . assert_called_once_with ( "<STR_LIT>" ) <EOL> def test_it_can_construct_a_base_uri_from_a_schema ( self ) : <EOL> schema = { "<STR_LIT:id>" : "<STR_LIT:foo>" } <EOL> resolver = RefResolver . from_schema ( schema ) <EOL> self . assertEqual ( resolver . base_uri , "<STR_LIT:foo>" ) <EOL> self . assertEqual ( resolver . resolution_scope , "<STR_LIT:foo>" ) <EOL> with resolver . resolving ( "<STR_LIT>" ) as resolved : <EOL> self . assertEqual ( resolved , schema ) <EOL> with resolver . resolving ( "<STR_LIT:#>" ) as resolved : <EOL> self . assertEqual ( resolved , schema ) <EOL> with resolver . resolving ( "<STR_LIT:foo>" ) as resolved : <EOL> self . assertEqual ( resolved , schema ) <EOL> with resolver . resolving ( "<STR_LIT>" ) as resolved : <EOL> self . assertEqual ( resolved , schema ) <EOL> def test_it_can_construct_a_base_uri_from_a_schema_without_id ( self ) : <EOL> schema = { } <EOL> resolver = RefResolver . from_schema ( schema ) <EOL> self . assertEqual ( resolver . base_uri , "<STR_LIT>" ) <EOL> self . assertEqual ( resolver . resolution_scope , "<STR_LIT>" ) <EOL> with resolver . resolving ( "<STR_LIT>" ) as resolved : <EOL> self . assertEqual ( resolved , schema ) <EOL> with resolver . resolving ( "<STR_LIT:#>" ) as resolved : <EOL> self . assertEqual ( resolved , schema ) <EOL> def test_custom_uri_scheme_handlers ( self ) : <EOL> schema = { "<STR_LIT:foo>" : "<STR_LIT:bar>" } <EOL> ref = "<STR_LIT>" <EOL> foo_handler = mock . Mock ( return_value = schema ) <EOL> resolver = RefResolver ( "<STR_LIT>" , { } , handlers = { "<STR_LIT:foo>" : foo_handler } ) <EOL> with resolver . resolving ( ref ) as resolved : <EOL> self . assertEqual ( resolved , schema ) <EOL> foo_handler . assert_called_once_with ( ref ) <EOL> def test_cache_remote_on ( self ) : <EOL> ref = "<STR_LIT>" <EOL> foo_handler = mock . Mock ( ) <EOL> resolver = RefResolver ( <EOL> "<STR_LIT>" , { } , cache_remote = True , handlers = { "<STR_LIT:foo>" : foo_handler } , <EOL> ) <EOL> with resolver . resolving ( ref ) : <EOL> pass <EOL> with resolver . resolving ( ref ) : <EOL> pass <EOL> foo_handler . assert_called_once_with ( ref ) <EOL> def test_cache_remote_off ( self ) : <EOL> ref = "<STR_LIT>" <EOL> foo_handler = mock . Mock ( ) <EOL> resolver = RefResolver ( <EOL> "<STR_LIT>" , { } , cache_remote = False , handlers = { "<STR_LIT:foo>" : foo_handler } , <EOL> ) <EOL> with resolver . resolving ( ref ) : <EOL> pass <EOL> self . assertEqual ( foo_handler . call_count , <NUM_LIT:1> ) <EOL> def test_if_you_give_it_junk_you_get_a_resolution_error ( self ) : <EOL> ref = "<STR_LIT>" <EOL> foo_handler = mock . Mock ( side_effect = ValueError ( "<STR_LIT>" ) ) <EOL> resolver = RefResolver ( "<STR_LIT>" , { } , handlers = { "<STR_LIT:foo>" : foo_handler } ) <EOL> with self . assertRaises ( RefResolutionError ) as err : <EOL> with resolver . resolving ( ref ) : <EOL> pass <EOL> self . assertEqual ( str ( err . exception ) , "<STR_LIT>" ) <EOL> def test_helpful_error_message_on_failed_pop_scope ( self ) : <EOL> resolver = RefResolver ( "<STR_LIT>" , { } ) <EOL> resolver . pop_scope ( ) <EOL> with self . assertRaises ( RefResolutionError ) as exc : <EOL> resolver . pop_scope ( ) <EOL> self . assertIn ( "<STR_LIT>" , str ( exc . exception ) ) <EOL> class UniqueTupleItemsMixin ( object ) : <EOL> """<STR_LIT>""" <EOL> def test_it_properly_formats_an_error_message ( self ) : <EOL> validator = self . validator_class ( <EOL> schema = { "<STR_LIT>" : True } , <EOL> types = { "<STR_LIT>" : ( tuple , ) } , <EOL> ) <EOL> with self . assertRaises ( ValidationError ) as e : <EOL> validator . validate ( ( <NUM_LIT:1> , <NUM_LIT:1> ) ) <EOL> self . assertIn ( "<STR_LIT>" , str ( e . exception ) ) <EOL> class TestDraft4UniqueTupleItems ( UniqueTupleItemsMixin , unittest . TestCase ) : <EOL> validator_class = Draft4Validator <EOL> class TestDraft3UniqueTupleItems ( UniqueTupleItemsMixin , unittest . TestCase ) : <EOL> validator_class = Draft3Validator <EOL> def sorted_errors ( errors ) : <EOL> def key ( error ) : <EOL> return ( <EOL> [ str ( e ) for e in error . path ] , <EOL> [ str ( e ) for e in error . schema_path ] <EOL> ) <EOL> return sorted ( errors , key = key ) </s>
<s> '''<STR_LIT>''' <EOL> import unittest <EOL> import os <EOL> from jnpr . openclos . report import ResourceAllocationReport , L2Report , L3Report <EOL> from test_dao import InMemoryDao <EOL> class Test ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> '''<STR_LIT>''' <EOL> self . __conf = { } <EOL> self . __conf [ '<STR_LIT>' ] = os . path . join ( os . path . dirname ( os . path . abspath ( __file__ ) ) , '<STR_LIT>' ) <EOL> self . __conf [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> self . __conf [ '<STR_LIT>' ] = '<STR_LIT:false>' <EOL> self . __conf [ '<STR_LIT>' ] = { <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' <EOL> } <EOL> self . __conf [ '<STR_LIT>' ] = { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] } <EOL> self . __conf [ '<STR_LIT>' ] = { <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : '<STR_LIT>' <EOL> } , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : '<STR_LIT>' , <EOL> "<STR_LIT>" : '<STR_LIT>' <EOL> } <EOL> } <EOL> self . _dao = InMemoryDao . getInstance ( ) <EOL> def tearDown ( self ) : <EOL> self . _dao = None <EOL> InMemoryDao . _destroy ( ) <EOL> '''<STR_LIT>''' <EOL> def testGenerateL2Report ( self ) : <EOL> l2Report = L2Report ( self . __conf , self . _dao ) <EOL> from test_model import createPod <EOL> with self . _dao . getReadSession ( ) as session : <EOL> pod = createPod ( "<STR_LIT:test>" , session ) <EOL> l2Report . generateReport ( pod . id , True , False ) <EOL> def testGenerateL3Report ( self ) : <EOL> l3Report = L3Report ( self . __conf , self . _dao ) <EOL> from test_model import createPod <EOL> with self . _dao . getReadSession ( ) as session : <EOL> pod = createPod ( "<STR_LIT:test>" , session ) <EOL> l3Report . generateReport ( pod . id , True , False ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> import yaml <EOL> import os . path <EOL> from jnpr . junos . factory . factory_loader import FactoryLoader <EOL> __all__ = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> def loadyaml ( path ) : <EOL> """<STR_LIT>""" <EOL> if os . path . splitext ( path ) [ <NUM_LIT:1> ] == '<STR_LIT>' : <EOL> path += '<STR_LIT>' <EOL> return FactoryLoader ( ) . load ( yaml . load ( open ( path , '<STR_LIT:r>' ) ) ) </s>
<s> """<STR_LIT>""" <EOL> from jnpr . junos . factory import loadyaml <EOL> from os . path import splitext <EOL> _YAML_ = splitext ( __file__ ) [ <NUM_LIT:0> ] + '<STR_LIT>' <EOL> globals ( ) . update ( loadyaml ( _YAML_ ) ) </s>
<s> '''<STR_LIT>''' <EOL> import unittest <EOL> from nose . plugins . attrib import attr <EOL> from jnpr . junos import Device <EOL> @ attr ( '<STR_LIT>' ) <EOL> class TestDeviceSsh ( unittest . TestCase ) : <EOL> def tearDown ( self ) : <EOL> self . dev . close ( ) <EOL> def test_device_open_default_key ( self ) : <EOL> self . dev = Device ( '<STR_LIT>' ) <EOL> self . dev . open ( ) <EOL> self . assertEqual ( self . dev . connected , True ) <EOL> def test_device_open_key_pass ( self ) : <EOL> self . dev = Device ( host = '<STR_LIT>' , ssh_private_key_file = '<STR_LIT>' , passwd = '<STR_LIT:password>' ) <EOL> self . dev . open ( ) <EOL> self . assertEqual ( self . dev . connected , True ) </s>
<s> __author__ = "<STR_LIT>" <EOL> __credits__ = "<STR_LIT>" <EOL> import unittest <EOL> from nose . plugins . attrib import attr <EOL> from jnpr . junos import Device <EOL> from jnpr . junos . utils . util import Util <EOL> from mock import patch <EOL> @ attr ( '<STR_LIT>' ) <EOL> class TestUtil ( unittest . TestCase ) : <EOL> @ patch ( '<STR_LIT>' ) <EOL> def setUp ( self , mock_connect ) : <EOL> self . dev = Device ( host = '<STR_LIT>' , user = '<STR_LIT>' , password = '<STR_LIT>' , <EOL> gather_facts = False ) <EOL> self . dev . open ( ) <EOL> self . util = Util ( self . dev ) <EOL> def test_repr ( self ) : <EOL> self . assertEqual ( repr ( self . util ) , '<STR_LIT>' ) <EOL> def test_dev_setter_exception ( self ) : <EOL> def mod_dev ( ) : <EOL> self . util . dev = '<STR_LIT:abc>' <EOL> self . assertRaises ( RuntimeError , mod_dev ) <EOL> def test_rpc_setter_exception ( self ) : <EOL> def mod_rpc ( ) : <EOL> self . util . rpc = '<STR_LIT:abc>' <EOL> self . assertRaises ( RuntimeError , mod_rpc ) </s>
<s> import unittest <EOL> from openmdao . main . api import set_as_top , Assembly <EOL> from openmdao . util . testutil import assert_rel_error <EOL> from openmdao . lib . drivers . api import BroydenSolver <EOL> from hyperloop . tube_wall_temp import TubeWallTemp <EOL> class TubeHeatBalance ( Assembly ) : <EOL> def configure ( self ) : <EOL> tm = self . add ( '<STR_LIT>' , TubeWallTemp ( ) ) <EOL> driver = self . add ( '<STR_LIT>' , BroydenSolver ( ) ) <EOL> driver . add_parameter ( '<STR_LIT>' , low = <NUM_LIT:0.> , high = <NUM_LIT> ) <EOL> driver . add_constraint ( '<STR_LIT>' ) <EOL> driver . workflow . add ( [ '<STR_LIT>' ] ) <EOL> class TubeWallTestCase ( unittest . TestCase ) : <EOL> def test_tube_temp ( self ) : <EOL> test = set_as_top ( TubeHeatBalance ( ) ) <EOL> test . tm . nozzle_air . setTotalTP ( <NUM_LIT> , <NUM_LIT> ) <EOL> test . tm . nozzle_air . W = <NUM_LIT> <EOL> test . tm . bearing_air . W = <NUM_LIT:0.> <EOL> test . tm . diameter_outer_tube = <NUM_LIT> <EOL> test . tm . length_tube = <NUM_LIT> <EOL> test . tm . num_pods = <NUM_LIT> <EOL> test . tm . temp_boundary = <NUM_LIT> <EOL> test . tm . temp_outside_ambient = <NUM_LIT> <EOL> test . run ( ) <EOL> assert_rel_error ( self , test . tm . heat_rate_pod , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . total_heat_rate_pods , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . GrDelTL3 , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . Pr , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . Gr , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . Ra , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . Nu , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . k , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . h , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . area_convection , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . q_per_area_nat_conv , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . total_q_nat_conv , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . area_viewing , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . q_per_area_solar , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . q_total_solar , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . area_rad , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . q_rad_per_area , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . q_rad_tot , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , test . tm . q_total_out , <NUM_LIT> , <NUM_LIT> ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> import os <EOL> from setuptools import setup , find_packages <EOL> with open ( os . path . join ( os . path . dirname ( __file__ ) , '<STR_LIT>' ) ) as f : <EOL> required = f . read ( ) . splitlines ( ) <EOL> setup ( <EOL> name = '<STR_LIT>' , <EOL> version = '<STR_LIT>' , <EOL> description = '<STR_LIT>' , <EOL> author = '<STR_LIT>' , <EOL> author_email = '<STR_LIT>' , <EOL> packages = find_packages ( exclude = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) , <EOL> include_package_data = True , <EOL> setup_requires = [ <EOL> '<STR_LIT>' , <EOL> ] , <EOL> install_requires = required , <EOL> entry_points = { <EOL> '<STR_LIT>' : [ <EOL> '<STR_LIT>' , <EOL> ] , <EOL> } , <EOL> ) <EOL> del required </s>
<s> import re <EOL> import os <EOL> import sys <EOL> import time <EOL> import hmac <EOL> import base64 <EOL> import hashlib <EOL> import threading <EOL> import logging <EOL> import requests <EOL> from yubico_client . otp import OTP <EOL> from yubico_client . yubico_exceptions import ( StatusCodeError , <EOL> InvalidClientIdError , <EOL> InvalidValidationResponse , <EOL> SignatureVerificationError ) <EOL> from yubico_client . py3 import b <EOL> from yubico_client . py3 import urlencode <EOL> from yubico_client . py3 import unquote <EOL> logger = logging . getLogger ( '<STR_LIT>' ) <EOL> COMMON_CA_LOCATIONS = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' <EOL> ] <EOL> DEFAULT_API_URLS = ( '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' ) <EOL> DEFAULT_TIMEOUT = <NUM_LIT:10> <EOL> DEFAULT_MAX_TIME_WINDOW = <NUM_LIT:5> <EOL> BAD_STATUS_CODES = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' ] <EOL> class Yubico ( object ) : <EOL> def __init__ ( self , client_id , key = None , verify_cert = True , <EOL> translate_otp = True , api_urls = DEFAULT_API_URLS , <EOL> ca_certs_bundle_path = None ) : <EOL> if ca_certs_bundle_path and not self . _is_valid_ca_bundle_file ( ca_certs_bundle_path ) : <EOL> raise ValueError ( ( '<STR_LIT>' <EOL> '<STR_LIT>' ) ) <EOL> self . client_id = client_id <EOL> if key is not None : <EOL> key = base64 . b64decode ( key . encode ( '<STR_LIT:ascii>' ) ) <EOL> self . key = key <EOL> self . verify_cert = verify_cert <EOL> self . translate_otp = translate_otp <EOL> self . api_urls = self . _init_request_urls ( api_urls = api_urls ) <EOL> self . ca_certs_bundle_path = ca_certs_bundle_path <EOL> def verify ( self , otp , timestamp = False , sl = None , timeout = None , <EOL> return_response = False ) : <EOL> """<STR_LIT>""" <EOL> ca_bundle_path = self . _get_ca_bundle_path ( ) <EOL> otp = OTP ( otp , self . translate_otp ) <EOL> rand_str = b ( os . urandom ( <NUM_LIT:30> ) ) <EOL> nonce = base64 . b64encode ( rand_str , b ( '<STR_LIT>' ) ) [ : <NUM_LIT> ] . decode ( '<STR_LIT:utf-8>' ) <EOL> query_string = self . generate_query_string ( otp . otp , nonce , timestamp , <EOL> sl , timeout ) <EOL> threads = [ ] <EOL> timeout = timeout or DEFAULT_TIMEOUT <EOL> for url in self . api_urls : <EOL> thread = URLThread ( '<STR_LIT>' % ( url , query_string ) , timeout , <EOL> self . verify_cert , ca_bundle_path ) <EOL> thread . start ( ) <EOL> threads . append ( thread ) <EOL> start_time = time . time ( ) <EOL> while threads and ( start_time + timeout ) > time . time ( ) : <EOL> for thread in threads : <EOL> if not thread . is_alive ( ) : <EOL> if thread . exception : <EOL> raise thread . exception <EOL> elif thread . response : <EOL> status = self . verify_response ( thread . response , <EOL> otp . otp , nonce , <EOL> return_response ) <EOL> if status : <EOL> if return_response : <EOL> return status <EOL> else : <EOL> return True <EOL> threads . remove ( thread ) <EOL> time . sleep ( <NUM_LIT:0.1> ) <EOL> raise Exception ( '<STR_LIT>' ) <EOL> def verify_multi ( self , otp_list , max_time_window = DEFAULT_MAX_TIME_WINDOW , <EOL> sl = None , timeout = None ) : <EOL> """<STR_LIT>""" <EOL> otps = [ ] <EOL> for otp in otp_list : <EOL> otps . append ( OTP ( otp , self . translate_otp ) ) <EOL> if len ( otp_list ) < <NUM_LIT:2> : <EOL> raise ValueError ( '<STR_LIT>' ) <EOL> device_ids = set ( ) <EOL> for otp in otps : <EOL> device_ids . add ( otp . device_id ) <EOL> if len ( device_ids ) != <NUM_LIT:1> : <EOL> raise Exception ( '<STR_LIT>' ) <EOL> for otp in otps : <EOL> response = self . verify ( otp . otp , True , sl , timeout , <EOL> return_response = True ) <EOL> if not response : <EOL> return False <EOL> otp . timestamp = int ( response [ '<STR_LIT>' ] ) <EOL> count = len ( otps ) <EOL> delta = otps [ count - <NUM_LIT:1> ] . timestamp - otps [ <NUM_LIT:0> ] . timestamp <EOL> delta = delta / <NUM_LIT:8> <EOL> if delta < <NUM_LIT:0> : <EOL> raise Exception ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> if delta > max_time_window : <EOL> raise Exception ( ( '<STR_LIT>' <EOL> '<STR_LIT>' ) % <EOL> ( max_time_window ) ) <EOL> return True <EOL> def verify_response ( self , response , otp , nonce , return_response = False ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> status = re . search ( r'<STR_LIT>' , response ) . groups ( ) <EOL> if len ( status ) > <NUM_LIT:1> : <EOL> message = '<STR_LIT>' <EOL> raise InvalidValidationResponse ( message , response ) <EOL> status = status [ <NUM_LIT:0> ] <EOL> except ( AttributeError , IndexError ) : <EOL> return False <EOL> signature , parameters = self . parse_parameters_from_response ( response ) <EOL> if self . key : <EOL> generated_signature = self . generate_message_signature ( parameters ) <EOL> if signature != generated_signature : <EOL> logger . warn ( "<STR_LIT>" , parameters ) <EOL> raise SignatureVerificationError ( generated_signature , <EOL> signature ) <EOL> param_dict = self . get_parameters_as_dictionary ( parameters ) <EOL> if '<STR_LIT>' in param_dict and param_dict [ '<STR_LIT>' ] != otp : <EOL> message = '<STR_LIT>' <EOL> raise InvalidValidationResponse ( message , response , param_dict ) <EOL> if '<STR_LIT>' in param_dict and param_dict [ '<STR_LIT>' ] != nonce : <EOL> message = '<STR_LIT>' <EOL> raise InvalidValidationResponse ( message , response , param_dict ) <EOL> if status == '<STR_LIT:OK>' : <EOL> if return_response : <EOL> return param_dict <EOL> else : <EOL> return True <EOL> elif status == '<STR_LIT>' : <EOL> raise InvalidClientIdError ( self . client_id ) <EOL> elif status == '<STR_LIT>' : <EOL> raise StatusCodeError ( status ) <EOL> return False <EOL> def generate_query_string ( self , otp , nonce , timestamp = False , sl = None , <EOL> timeout = None ) : <EOL> """<STR_LIT>""" <EOL> data = [ ( '<STR_LIT:id>' , self . client_id ) , <EOL> ( '<STR_LIT>' , otp ) , <EOL> ( '<STR_LIT>' , nonce ) ] <EOL> if timestamp : <EOL> data . append ( ( '<STR_LIT>' , '<STR_LIT:1>' ) ) <EOL> if sl is not None : <EOL> if sl not in range ( <NUM_LIT:0> , <NUM_LIT> ) and sl not in [ '<STR_LIT>' , '<STR_LIT>' ] : <EOL> raise Exception ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> data . append ( ( '<STR_LIT>' , sl ) ) <EOL> if timeout : <EOL> data . append ( ( '<STR_LIT>' , timeout ) ) <EOL> query_string = urlencode ( data ) <EOL> if self . key : <EOL> hmac_signature = self . generate_message_signature ( query_string ) <EOL> hmac_signature = hmac_signature <EOL> query_string += '<STR_LIT>' % ( hmac_signature . replace ( '<STR_LIT:+>' , '<STR_LIT>' ) ) <EOL> return query_string <EOL> def generate_message_signature ( self , query_string ) : <EOL> """<STR_LIT>""" <EOL> pairs = query_string . split ( '<STR_LIT:&>' ) <EOL> pairs = [ pair . split ( '<STR_LIT:=>' , <NUM_LIT:1> ) for pair in pairs ] <EOL> pairs_sorted = sorted ( pairs ) <EOL> pairs_string = '<STR_LIT:&>' . join ( [ '<STR_LIT:=>' . join ( pair ) for pair in pairs_sorted ] ) <EOL> digest = hmac . new ( self . key , b ( pairs_string ) , hashlib . sha1 ) . digest ( ) <EOL> signature = base64 . b64encode ( digest ) . decode ( '<STR_LIT:utf-8>' ) <EOL> return signature <EOL> def parse_parameters_from_response ( self , response ) : <EOL> """<STR_LIT>""" <EOL> lines = response . splitlines ( ) <EOL> pairs = [ line . strip ( ) . split ( '<STR_LIT:=>' , <NUM_LIT:1> ) for line in lines if '<STR_LIT:=>' in line ] <EOL> pairs = sorted ( pairs ) <EOL> signature = ( [ unquote ( v ) for k , v in pairs if k == '<STR_LIT:h>' ] or [ None ] ) [ <NUM_LIT:0> ] <EOL> query_string = '<STR_LIT:&>' . join ( [ k + '<STR_LIT:=>' + v for k , v in pairs if k != '<STR_LIT:h>' ] ) <EOL> return ( signature , query_string ) <EOL> def get_parameters_as_dictionary ( self , query_string ) : <EOL> """<STR_LIT>""" <EOL> pairs = ( x . split ( '<STR_LIT:=>' , <NUM_LIT:1> ) for x in query_string . split ( '<STR_LIT:&>' ) ) <EOL> return dict ( ( k , unquote ( v ) ) for k , v in pairs ) <EOL> def _init_request_urls ( self , api_urls ) : <EOL> """<STR_LIT>""" <EOL> if not isinstance ( api_urls , ( str , list , tuple ) ) : <EOL> raise TypeError ( '<STR_LIT>' ) <EOL> if isinstance ( api_urls , str ) : <EOL> api_urls = ( api_urls , ) <EOL> api_urls = list ( api_urls ) <EOL> for url in api_urls : <EOL> if not url . startswith ( '<STR_LIT>' ) and not url . startswith ( '<STR_LIT>' ) : <EOL> raise ValueError ( ( '<STR_LIT>' <EOL> '<STR_LIT>' % ( url ) ) ) <EOL> return list ( api_urls ) <EOL> def _get_ca_bundle_path ( self ) : <EOL> """<STR_LIT>""" <EOL> if self . ca_certs_bundle_path : <EOL> return self . ca_certs_bundle_path <EOL> for file_path in COMMON_CA_LOCATIONS : <EOL> if self . _is_valid_ca_bundle_file ( file_path = file_path ) : <EOL> return file_path <EOL> return None <EOL> def _is_valid_ca_bundle_file ( self , file_path ) : <EOL> return os . path . exists ( file_path ) and os . path . isfile ( file_path ) <EOL> class URLThread ( threading . Thread ) : <EOL> def __init__ ( self , url , timeout , verify_cert , ca_bundle_path = None ) : <EOL> super ( URLThread , self ) . __init__ ( ) <EOL> self . url = url <EOL> self . timeout = timeout <EOL> self . verify_cert = verify_cert <EOL> self . ca_bundle_path = ca_bundle_path <EOL> self . exception = None <EOL> self . request = None <EOL> self . response = None <EOL> def run ( self ) : <EOL> logger . debug ( '<STR_LIT>' % ( self . url , <EOL> self . name ) ) <EOL> verify = self . verify_cert <EOL> if self . ca_bundle_path is not None : <EOL> verify = self . ca_bundle_path <EOL> logger . debug ( '<STR_LIT>' % ( self . ca_bundle_path ) ) <EOL> try : <EOL> self . request = requests . get ( url = self . url , timeout = self . timeout , <EOL> verify = verify ) <EOL> self . response = self . request . content . decode ( '<STR_LIT:utf-8>' ) <EOL> except requests . exceptions . SSLError : <EOL> e = sys . exc_info ( ) [ <NUM_LIT:1> ] <EOL> self . exception = e <EOL> self . response = None <EOL> except Exception : <EOL> e = sys . exc_info ( ) [ <NUM_LIT:1> ] <EOL> logger . error ( '<STR_LIT>' + str ( e ) ) <EOL> self . response = None <EOL> args = ( self . url , self . name , self . response ) <EOL> logger . debug ( '<STR_LIT>' % args ) </s>
<s> import logging <EOL> from app import app , logger <EOL> root = logging . getLogger ( ) <EOL> root . setLevel ( logging . DEBUG ) <EOL> logging . getLogger ( "<STR_LIT>" ) . setLevel ( logging . INFO ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> logger . warn ( "<STR_LIT>" ) <EOL> app . run ( host = '<STR_LIT>' , debug = True ) </s>
<s> from setuptools import setup <EOL> setup ( <EOL> name = '<STR_LIT>' , <EOL> version = '<STR_LIT>' , <EOL> py_modules = [ '<STR_LIT>' ] , <EOL> install_requires = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> ] , <EOL> entry_points = '''<STR_LIT>''' , <EOL> ) </s>
<s> from nose . tools import ok_ , raises <EOL> from linot import config <EOL> from linot . interfaces . line_interface import LineClientP , LineInterface <EOL> class TestLineClientP : <EOL> def setUp ( self ) : <EOL> self . line_cfg = config [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> self . lineclient = LineClientP ( self . line_cfg [ '<STR_LIT>' ] , <EOL> self . line_cfg [ '<STR_LIT:password>' ] ) <EOL> def test_find_contact_by_id ( self ) : <EOL> contact = self . lineclient . find_contact_by_id ( self . line_cfg [ '<STR_LIT>' ] ) <EOL> ok_ ( contact . id == self . line_cfg [ '<STR_LIT>' ] ) <EOL> @ raises ( ValueError ) <EOL> def test_find_contact_by_id_exception ( self ) : <EOL> self . lineclient . find_contact_by_id ( self . line_cfg [ '<STR_LIT>' ] [ : - <NUM_LIT:2> ] ) <EOL> class TestLineInterface : <EOL> def setUp ( self ) : <EOL> self . line_interface = LineInterface ( ) <EOL> def test_polling_command ( self ) : <EOL> test_str = '<STR_LIT>' <EOL> me = self . line_interface . _client . getProfile ( ) <EOL> me . sendMessage ( test_str ) <EOL> result = self . line_interface . polling_command ( ) <EOL> ok_ ( len ( result ) == <NUM_LIT:1> , result ) <EOL> submitter , msg = result [ <NUM_LIT:0> ] <EOL> ok_ ( submitter . code == me . id , submitter ) <EOL> ok_ ( msg == test_str , <EOL> '<STR_LIT>' . format ( msg , test_str ) ) <EOL> def test_get_contact_by_id ( self ) : <EOL> me = self . line_interface . _client . getProfile ( ) <EOL> contact = self . line_interface . _get_contact_by_id ( me . id ) <EOL> ok_ ( me . id == contact . id , '<STR_LIT>' . format ( me . id , contact . id ) ) <EOL> def test_send_message ( self ) : <EOL> test_str = '<STR_LIT>' <EOL> me = self . line_interface . _client . getProfile ( ) <EOL> me . sendMessage ( test_str ) <EOL> result = self . line_interface . polling_command ( ) <EOL> me , msg = result [ <NUM_LIT:0> ] <EOL> self . line_interface . send_message ( me , test_str ) <EOL> result = self . line_interface . polling_command ( ) <EOL> me , msg = result [ <NUM_LIT:0> ] <EOL> ok_ ( msg == test_str , '<STR_LIT>' . format ( msg , test_str ) ) <EOL> def test_send_message_to_id ( self ) : <EOL> test_str = '<STR_LIT>' <EOL> me = self . line_interface . _client . getProfile ( ) <EOL> me . sendMessage ( test_str ) <EOL> result = self . line_interface . polling_command ( ) <EOL> me , msg = result [ <NUM_LIT:0> ] <EOL> self . line_interface . _send_message_to_id ( me . code , test_str ) <EOL> result = self . line_interface . polling_command ( ) <EOL> me , msg = result [ <NUM_LIT:0> ] <EOL> ok_ ( msg == test_str , '<STR_LIT>' . format ( msg , test_str ) ) <EOL> def test_get_display_name ( self ) : <EOL> test_str = '<STR_LIT>' <EOL> me = self . line_interface . _client . getProfile ( ) <EOL> me . sendMessage ( test_str ) <EOL> result = self . line_interface . polling_command ( ) <EOL> me_submitter , msg = result [ <NUM_LIT:0> ] <EOL> me_display_name = self . line_interface . get_display_name ( me_submitter ) <EOL> ok_ ( me_display_name == me . name ) </s>
<s> import pytest <EOL> import socket <EOL> from aiohttp . parsers import StreamWriter , CORK <EOL> from unittest import mock <EOL> def test_nodelay_default ( loop ) : <EOL> transport = mock . Mock ( ) <EOL> s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> transport . get_extra_info . return_value = s <EOL> proto = mock . Mock ( ) <EOL> reader = mock . Mock ( ) <EOL> writer = StreamWriter ( transport , proto , reader , loop ) <EOL> assert not writer . tcp_nodelay <EOL> assert not s . getsockopt ( socket . IPPROTO_TCP , socket . TCP_NODELAY ) <EOL> def test_set_nodelay_no_change ( loop ) : <EOL> transport = mock . Mock ( ) <EOL> s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> transport . get_extra_info . return_value = s <EOL> proto = mock . Mock ( ) <EOL> reader = mock . Mock ( ) <EOL> writer = StreamWriter ( transport , proto , reader , loop ) <EOL> writer . set_tcp_nodelay ( False ) <EOL> assert not writer . tcp_nodelay <EOL> assert not s . getsockopt ( socket . IPPROTO_TCP , socket . TCP_NODELAY ) <EOL> def test_set_nodelay_enable ( loop ) : <EOL> transport = mock . Mock ( ) <EOL> s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> transport . get_extra_info . return_value = s <EOL> proto = mock . Mock ( ) <EOL> reader = mock . Mock ( ) <EOL> writer = StreamWriter ( transport , proto , reader , loop ) <EOL> writer . set_tcp_nodelay ( True ) <EOL> assert writer . tcp_nodelay <EOL> assert s . getsockopt ( socket . IPPROTO_TCP , socket . TCP_NODELAY ) <EOL> def test_set_nodelay_enable_and_disable ( loop ) : <EOL> transport = mock . Mock ( ) <EOL> s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> transport . get_extra_info . return_value = s <EOL> proto = mock . Mock ( ) <EOL> reader = mock . Mock ( ) <EOL> writer = StreamWriter ( transport , proto , reader , loop ) <EOL> writer . set_tcp_nodelay ( True ) <EOL> writer . set_tcp_nodelay ( False ) <EOL> assert not writer . tcp_nodelay <EOL> assert not s . getsockopt ( socket . IPPROTO_TCP , socket . TCP_NODELAY ) <EOL> def test_set_nodelay_enable_ipv6 ( loop ) : <EOL> transport = mock . Mock ( ) <EOL> s = socket . socket ( socket . AF_INET6 , socket . SOCK_STREAM ) <EOL> transport . get_extra_info . return_value = s <EOL> proto = mock . Mock ( ) <EOL> reader = mock . Mock ( ) <EOL> writer = StreamWriter ( transport , proto , reader , loop ) <EOL> writer . set_tcp_nodelay ( True ) <EOL> assert writer . tcp_nodelay <EOL> assert s . getsockopt ( socket . IPPROTO_TCP , socket . TCP_NODELAY ) <EOL> @ pytest . mark . skipif ( not hasattr ( socket , '<STR_LIT>' ) , <EOL> reason = "<STR_LIT>" ) <EOL> def test_set_nodelay_enable_unix ( loop ) : <EOL> transport = mock . Mock ( ) <EOL> s = socket . socket ( socket . AF_UNIX , socket . SOCK_STREAM ) <EOL> transport . get_extra_info . return_value = s <EOL> proto = mock . Mock ( ) <EOL> reader = mock . Mock ( ) <EOL> writer = StreamWriter ( transport , proto , reader , loop ) <EOL> writer . set_tcp_nodelay ( True ) <EOL> assert writer . tcp_nodelay <EOL> def test_set_nodelay_enable_no_socket ( loop ) : <EOL> transport = mock . Mock ( ) <EOL> transport . get_extra_info . return_value = None <EOL> proto = mock . Mock ( ) <EOL> reader = mock . Mock ( ) <EOL> writer = StreamWriter ( transport , proto , reader , loop ) <EOL> writer . set_tcp_nodelay ( True ) <EOL> assert writer . tcp_nodelay <EOL> assert writer . _socket is None <EOL> @ pytest . mark . skipif ( CORK is None , reason = "<STR_LIT>" ) <EOL> def test_cork_default ( loop ) : <EOL> transport = mock . Mock ( ) <EOL> s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> transport . get_extra_info . return_value = s <EOL> proto = mock . Mock ( ) <EOL> reader = mock . Mock ( ) <EOL> writer = StreamWriter ( transport , proto , reader , loop ) <EOL> assert not writer . tcp_cork <EOL> assert not s . getsockopt ( socket . IPPROTO_TCP , CORK ) <EOL> @ pytest . mark . skipif ( CORK is None , reason = "<STR_LIT>" ) <EOL> def test_set_cork_no_change ( loop ) : <EOL> transport = mock . Mock ( ) <EOL> s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> transport . get_extra_info . return_value = s <EOL> proto = mock . Mock ( ) <EOL> reader = mock . Mock ( ) <EOL> writer = StreamWriter ( transport , proto , reader , loop ) <EOL> writer . set_tcp_cork ( False ) <EOL> assert not writer . tcp_cork <EOL> assert not s . getsockopt ( socket . IPPROTO_TCP , CORK ) <EOL> @ pytest . mark . skipif ( CORK is None , reason = "<STR_LIT>" ) <EOL> def test_set_cork_enable ( loop ) : <EOL> transport = mock . Mock ( ) <EOL> s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> transport . get_extra_info . return_value = s <EOL> proto = mock . Mock ( ) <EOL> reader = mock . Mock ( ) <EOL> writer = StreamWriter ( transport , proto , reader , loop ) <EOL> writer . set_tcp_cork ( True ) <EOL> assert writer . tcp_cork <EOL> assert s . getsockopt ( socket . IPPROTO_TCP , CORK ) <EOL> @ pytest . mark . skipif ( CORK is None , reason = "<STR_LIT>" ) <EOL> def test_set_cork_enable_and_disable ( loop ) : <EOL> transport = mock . Mock ( ) <EOL> s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> transport . get_extra_info . return_value = s <EOL> proto = mock . Mock ( ) <EOL> reader = mock . Mock ( ) <EOL> writer = StreamWriter ( transport , proto , reader , loop ) <EOL> writer . set_tcp_cork ( True ) <EOL> writer . set_tcp_cork ( False ) <EOL> assert not writer . tcp_cork <EOL> assert not s . getsockopt ( socket . IPPROTO_TCP , CORK ) <EOL> @ pytest . mark . skipif ( CORK is None , reason = "<STR_LIT>" ) <EOL> def test_set_cork_enable_ipv6 ( loop ) : <EOL> transport = mock . Mock ( ) <EOL> s = socket . socket ( socket . AF_INET6 , socket . SOCK_STREAM ) <EOL> transport . get_extra_info . return_value = s <EOL> proto = mock . Mock ( ) <EOL> reader = mock . Mock ( ) <EOL> writer = StreamWriter ( transport , proto , reader , loop ) <EOL> writer . set_tcp_cork ( True ) <EOL> assert writer . tcp_cork <EOL> assert s . getsockopt ( socket . IPPROTO_TCP , CORK ) <EOL> @ pytest . mark . skipif ( not hasattr ( socket , '<STR_LIT>' ) , <EOL> reason = "<STR_LIT>" ) <EOL> @ pytest . mark . skipif ( CORK is None , reason = "<STR_LIT>" ) <EOL> def test_set_cork_enable_unix ( loop ) : <EOL> transport = mock . Mock ( ) <EOL> s = socket . socket ( socket . AF_UNIX , socket . SOCK_STREAM ) <EOL> transport . get_extra_info . return_value = s <EOL> proto = mock . Mock ( ) <EOL> reader = mock . Mock ( ) <EOL> writer = StreamWriter ( transport , proto , reader , loop ) <EOL> writer . set_tcp_cork ( True ) <EOL> assert writer . tcp_cork <EOL> @ pytest . mark . skipif ( CORK is None , reason = "<STR_LIT>" ) <EOL> def test_set_cork_enable_no_socket ( loop ) : <EOL> transport = mock . Mock ( ) <EOL> transport . get_extra_info . return_value = None <EOL> proto = mock . Mock ( ) <EOL> reader = mock . Mock ( ) <EOL> writer = StreamWriter ( transport , proto , reader , loop ) <EOL> writer . set_tcp_cork ( True ) <EOL> assert writer . tcp_cork <EOL> assert writer . _socket is None <EOL> @ pytest . mark . skipif ( CORK is None , reason = "<STR_LIT>" ) <EOL> def test_set_enabling_cork_disables_nodelay ( loop ) : <EOL> transport = mock . Mock ( ) <EOL> s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> transport . get_extra_info . return_value = s <EOL> proto = mock . Mock ( ) <EOL> reader = mock . Mock ( ) <EOL> writer = StreamWriter ( transport , proto , reader , loop ) <EOL> writer . set_tcp_nodelay ( True ) <EOL> writer . set_tcp_cork ( True ) <EOL> assert not writer . tcp_nodelay <EOL> assert not s . getsockopt ( socket . IPPROTO_TCP , socket . TCP_NODELAY ) <EOL> assert writer . tcp_cork <EOL> assert s . getsockopt ( socket . IPPROTO_TCP , CORK ) <EOL> @ pytest . mark . skipif ( CORK is None , reason = "<STR_LIT>" ) <EOL> def test_set_enabling_nodelay_disables_cork ( loop ) : <EOL> transport = mock . Mock ( ) <EOL> s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> transport . get_extra_info . return_value = s <EOL> proto = mock . Mock ( ) <EOL> reader = mock . Mock ( ) <EOL> writer = StreamWriter ( transport , proto , reader , loop ) <EOL> writer . set_tcp_cork ( True ) <EOL> writer . set_tcp_nodelay ( True ) <EOL> assert writer . tcp_nodelay <EOL> assert s . getsockopt ( socket . IPPROTO_TCP , socket . TCP_NODELAY ) <EOL> assert not writer . tcp_cork <EOL> assert not s . getsockopt ( socket . IPPROTO_TCP , CORK ) </s>
<s> """<STR_LIT>""" <EOL> import argparse <EOL> import logging <EOL> from collections import namedtuple <EOL> from . import placeholder <EOL> logger = logging . getLogger ( ) <EOL> ShortenerSettings = namedtuple ( '<STR_LIT>' , [ <EOL> '<STR_LIT:name>' , <EOL> '<STR_LIT>' <EOL> ] ) <EOL> Settings = namedtuple ( '<STR_LIT>' , [ <EOL> '<STR_LIT:source>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT:strict>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' <EOL> ] ) <EOL> def default_settings ( ) : <EOL> return Settings ( <EOL> verbose = False , <EOL> strict = True , <EOL> force = False , <EOL> source = '<STR_LIT:src>' , <EOL> destination = '<STR_LIT:target>' , <EOL> templates = '<STR_LIT>' , <EOL> images = '<STR_LIT>' , <EOL> right_to_left = [ '<STR_LIT>' , '<STR_LIT>' ] , <EOL> pattern = '<STR_LIT>' , <EOL> shortener = { } , <EOL> exclusive = None , <EOL> default_locale = '<STR_LIT>' , <EOL> workers_pool = <NUM_LIT:10> , <EOL> local_images = '<STR_LIT>' , <EOL> save = None , <EOL> cms_service_host = "<STR_LIT>" <EOL> ) <EOL> def read_args ( argsargs = argparse . ArgumentParser ) : <EOL> settings = default_settings ( ) <EOL> logger . debug ( '<STR_LIT>' ) <EOL> args = argsargs ( epilog = '<STR_LIT>' ) <EOL> args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = '<STR_LIT>' % settings . source ) <EOL> args . add_argument ( <EOL> '<STR_LIT>' , '<STR_LIT>' , help = '<STR_LIT>' % settings . exclusive ) <EOL> args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , <EOL> help = '<STR_LIT>' % settings . destination ) <EOL> args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = '<STR_LIT>' % settings . templates ) <EOL> args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , <EOL> help = '<STR_LIT>' % settings . right_to_left ) <EOL> args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = '<STR_LIT>' % settings . images ) <EOL> args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = '<STR_LIT>' % settings . pattern ) <EOL> args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , <EOL> help = '<STR_LIT>' , <EOL> action = '<STR_LIT>' ) <EOL> args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = '<STR_LIT>' , action = '<STR_LIT:store_true>' ) <EOL> args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , <EOL> help = '<STR_LIT>' % settings . workers_pool , type = int ) <EOL> args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = '<STR_LIT>' , action = '<STR_LIT:store_true>' ) <EOL> args . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = '<STR_LIT>' , action = '<STR_LIT:store_true>' ) <EOL> subparsers = args . add_subparsers ( help = '<STR_LIT>' , dest = '<STR_LIT>' ) <EOL> template_parser = subparsers . add_parser ( '<STR_LIT>' ) <EOL> template_parser . add_argument ( '<STR_LIT>' , help = '<STR_LIT>' ) <EOL> template_parser . add_argument ( '<STR_LIT>' , <EOL> help = '<STR_LIT>' ) <EOL> config_parser = subparsers . add_parser ( '<STR_LIT>' ) <EOL> config_parser . add_argument ( '<STR_LIT>' , help = '<STR_LIT>' ) <EOL> gui_parser = subparsers . add_parser ( '<STR_LIT>' ) <EOL> gui_parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , type = int , help = '<STR_LIT>' , default = <NUM_LIT> ) <EOL> gui_parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , type = str , help = '<STR_LIT>' , <EOL> default = '<STR_LIT>' ) <EOL> gui_parser . add_argument ( '<STR_LIT>' , type = str , help = '<STR_LIT>' ) <EOL> gui_parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , type = str , help = '<STR_LIT>' ) <EOL> return args . parse_args ( ) <EOL> def read_settings ( args ) : <EOL> args = vars ( args ) <EOL> settings = default_settings ( ) . _asdict ( ) <EOL> for k in settings : <EOL> if k in args and args [ k ] is not None : <EOL> settings [ k ] = args [ k ] <EOL> return Settings ( ** settings ) <EOL> def print_version ( ) : <EOL> import pkg_resources <EOL> version = pkg_resources . require ( '<STR_LIT>' ) [ <NUM_LIT:0> ] . version <EOL> print ( version ) <EOL> return True <EOL> def generate_config ( args ) : <EOL> if args . config_name == '<STR_LIT>' : <EOL> logger . info ( '<STR_LIT>' ) <EOL> settings = read_settings ( args ) <EOL> placeholder . generate_config ( settings ) <EOL> return True <EOL> return False <EOL> def execute_command ( args ) : <EOL> if args . command == '<STR_LIT>' : <EOL> return generate_config ( args ) <EOL> elif args . command == '<STR_LIT>' : <EOL> from . gui . gui import serve <EOL> serve ( args ) <EOL> return True <EOL> return False </s>
<s> from ldap3 import Server , Connection , ALL <EOL> """<STR_LIT>""" <EOL> def rotate ( record , newpassword ) : <EOL> result = False <EOL> host = record . get ( '<STR_LIT>' ) <EOL> user_dn = record . get ( '<STR_LIT>' ) <EOL> try : <EOL> server = Server ( <EOL> host = host , <EOL> use_ssl = True , <EOL> get_info = ALL ) <EOL> conn = Connection ( <EOL> server = server , <EOL> user = user_dn , <EOL> password = record . password , <EOL> auto_bind = True ) <EOL> changePwdResult = conn . extend . microsoft . modify_password ( user_dn , newpassword ) <EOL> if ( changePwdResult == True ) : <EOL> print ( '<STR_LIT>' ) <EOL> record . password = newpassword <EOL> result = True <EOL> else : <EOL> print ( "<STR_LIT>" % ( changePwdResult ) ) <EOL> conn . unbind ( ) <EOL> except : <EOL> print ( "<STR_LIT>" ) <EOL> return result </s>
<s> from keepercommander . record import Record <EOL> def sample_record ( ) : <EOL> record = Record ( ) <EOL> record . folder = '<STR_LIT>' <EOL> record . title = '<STR_LIT:title>' <EOL> record . login = '<STR_LIT>' <EOL> record . password = '<STR_LIT:password>' <EOL> record . login_url = '<STR_LIT>' <EOL> record . notes = '<STR_LIT>' <EOL> record . custom_fields = [ <EOL> { '<STR_LIT:name>' : '<STR_LIT>' , '<STR_LIT:value>' : '<STR_LIT>' , '<STR_LIT:type>' : '<STR_LIT:text>' } , <EOL> { '<STR_LIT:name>' : '<STR_LIT>' , '<STR_LIT:value>' : '<STR_LIT>' , '<STR_LIT:type>' : '<STR_LIT:text>' } ] <EOL> return record <EOL> class TestRecord : <EOL> def test_to_tab_delimited ( self ) : <EOL> assert sample_record ( ) . to_tab_delimited ( ) == '<STR_LIT>' <EOL> def test_to_tab_dictionary ( self ) : <EOL> assert sample_record ( ) . to_dictionary ( ) == { <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:title>' : '<STR_LIT:title>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:password>' : '<STR_LIT:password>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : [ <EOL> { '<STR_LIT:name>' : '<STR_LIT>' , '<STR_LIT:value>' : '<STR_LIT>' , '<STR_LIT:type>' : '<STR_LIT:text>' } , <EOL> { '<STR_LIT:name>' : '<STR_LIT>' , '<STR_LIT:value>' : '<STR_LIT>' , '<STR_LIT:type>' : '<STR_LIT:text>' } ] , <EOL> } </s>
<s> from filesize import size <EOL> from filesize import traditional , alternative , verbose , iec , si </s>
<s> import os <EOL> import logbook <EOL> import pytest <EOL> import pyshark <EOL> @ pytest . fixture <EOL> def caps_directory ( ) : <EOL> return os . path . join ( os . path . dirname ( __file__ ) , '<STR_LIT>' ) <EOL> @ pytest . fixture <EOL> def lazy_simple_capture ( request , caps_directory ) : <EOL> """<STR_LIT>""" <EOL> cap_path = os . path . join ( caps_directory , '<STR_LIT>' ) <EOL> cap = pyshark . FileCapture ( cap_path ) <EOL> cap . log . level = logbook . DEBUG <EOL> def finalizer ( ) : <EOL> cap . close ( ) <EOL> cap . eventloop . stop ( ) <EOL> request . addfinalizer ( finalizer ) <EOL> return cap <EOL> @ pytest . fixture <EOL> def simple_capture ( lazy_simple_capture ) : <EOL> """<STR_LIT>""" <EOL> lazy_simple_capture . load_packets ( ) <EOL> return lazy_simple_capture </s>
<s> from cornice import Service <EOL> from pyramid import httpexceptions <EOL> from pyramid . security import NO_PERMISSION_REQUIRED <EOL> from kinto . events import ServerFlushed <EOL> flush = Service ( name = '<STR_LIT>' , <EOL> description = '<STR_LIT>' , <EOL> path = '<STR_LIT>' ) <EOL> @ flush . post ( permission = NO_PERMISSION_REQUIRED ) <EOL> def flush_post ( request ) : <EOL> request . registry . storage . flush ( ) <EOL> request . registry . permission . flush ( ) <EOL> request . registry . cache . flush ( ) <EOL> event = ServerFlushed ( request ) <EOL> request . registry . notify ( event ) <EOL> return httpexceptions . HTTPAccepted ( ) </s>
<s> import os <EOL> os . environ [ '<STR_LIT>' ] = os . environ . get ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> from tests import base <EOL> def setUpModule ( ) : <EOL> """<STR_LIT>""" <EOL> base . enabledPlugins . append ( '<STR_LIT>' ) <EOL> base . enabledPlugins . append ( '<STR_LIT>' ) <EOL> base . enabledPlugins . append ( '<STR_LIT>' ) <EOL> base . enabledPlugins . append ( '<STR_LIT>' ) <EOL> base . startServer ( False ) <EOL> def tearDownModule ( ) : <EOL> """<STR_LIT>""" <EOL> base . stopServer ( ) <EOL> class SourceTestCase ( base . TestCase ) : <EOL> """<STR_LIT>""" <EOL> def setUp ( self ) : <EOL> """<STR_LIT>""" <EOL> super ( SourceTestCase , self ) . setUp ( ) <EOL> self . _user = self . model ( '<STR_LIT:user>' ) . createUser ( <EOL> '<STR_LIT>' , '<STR_LIT:password>' , '<STR_LIT>' , '<STR_LIT:user>' , <EOL> '<STR_LIT>' ) <EOL> def testSource ( self ) : <EOL> """<STR_LIT>""" <EOL> path = '<STR_LIT>' <EOL> params = { <EOL> '<STR_LIT>' : self . _user [ '<STR_LIT>' ] , <EOL> } <EOL> response = self . request ( path = path , method = '<STR_LIT:GET>' , params = params ) <EOL> self . assertStatusOk ( response ) <EOL> folder = response . json [ '<STR_LIT>' ] <EOL> self . assertEquals ( folder , None ) <EOL> response = self . request ( path = path , method = '<STR_LIT:POST>' , params = params ) <EOL> self . assertStatus ( response , <NUM_LIT> ) <EOL> response = self . request ( path = path , method = '<STR_LIT:POST>' , params = params , user = self . _user ) <EOL> self . assertStatusOk ( response ) <EOL> folder = response . json [ '<STR_LIT>' ] <EOL> self . assertNotEquals ( folder , None ) <EOL> self . assertEquals ( folder [ '<STR_LIT>' ] , '<STR_LIT:user>' ) <EOL> self . assertEquals ( folder [ '<STR_LIT>' ] , str ( self . _user [ '<STR_LIT>' ] ) ) <EOL> response = self . request ( path = path , method = '<STR_LIT:GET>' , params = params ) <EOL> self . assertStatusOk ( response ) <EOL> folder = response . json [ '<STR_LIT>' ] <EOL> self . assertEquals ( folder , None ) <EOL> response = self . request ( path = path , method = '<STR_LIT:GET>' , params = params , user = self . _user ) <EOL> self . assertStatusOk ( response ) <EOL> folder = response . json [ '<STR_LIT>' ] <EOL> self . assertNotEquals ( folder , None ) <EOL> self . assertEquals ( folder [ '<STR_LIT>' ] , '<STR_LIT:user>' ) <EOL> self . assertEquals ( folder [ '<STR_LIT>' ] , str ( self . _user [ '<STR_LIT>' ] ) ) <EOL> params = { <EOL> '<STR_LIT:name>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : folder [ '<STR_LIT>' ] <EOL> } <EOL> response = self . request ( path = '<STR_LIT>' , method = '<STR_LIT:POST>' , params = params , <EOL> user = self . _user ) <EOL> item1Id = response . json [ '<STR_LIT>' ] <EOL> params = { <EOL> '<STR_LIT:name>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : folder [ '<STR_LIT>' ] <EOL> } <EOL> response = self . request ( path = '<STR_LIT>' , method = '<STR_LIT:POST>' , params = params , <EOL> user = self . _user ) <EOL> item2Id = response . json [ '<STR_LIT>' ] <EOL> path = '<STR_LIT>' <EOL> params = { <EOL> '<STR_LIT>' : self . _user [ '<STR_LIT>' ] , <EOL> } <EOL> response = self . request ( path = path , method = '<STR_LIT:GET>' , params = params ) <EOL> self . assertStatusOk ( response ) <EOL> self . assertEquals ( len ( response . json ) , <NUM_LIT:0> ) <EOL> response = self . request ( path = path , method = '<STR_LIT:GET>' , params = params , user = self . _user ) <EOL> self . assertStatusOk ( response ) <EOL> self . assertEquals ( len ( response . json ) , <NUM_LIT:2> ) <EOL> sourceIds = [ d [ '<STR_LIT>' ] for d in response . json ] <EOL> self . assertTrue ( item1Id in sourceIds , "<STR_LIT>" ) <EOL> self . assertTrue ( item2Id in sourceIds , "<STR_LIT>" ) </s>
<s> from girder . api import access <EOL> from girder . api . describe import Description <EOL> from girder . api . rest import loadmodel , RestException <EOL> from girder . constants import AccessType <EOL> from girder . plugins . minerva . rest . dataset import Dataset <EOL> from girder . plugins . minerva . utility . minerva_utility import findDatasetFolder , updateMinervaMetadata <EOL> class GeojsonDataset ( Dataset ) : <EOL> def __init__ ( self ) : <EOL> self . resourceName = '<STR_LIT>' <EOL> self . route ( '<STR_LIT:POST>' , ( ) , self . createGeojsonDataset ) <EOL> @ access . user <EOL> @ loadmodel ( map = { '<STR_LIT>' : '<STR_LIT>' } , model = '<STR_LIT>' , <EOL> level = AccessType . WRITE ) <EOL> def createGeojsonDataset ( self , item , params ) : <EOL> user = self . getCurrentUser ( ) <EOL> folder = findDatasetFolder ( user , user , create = True ) <EOL> if folder is None : <EOL> raise RestException ( '<STR_LIT>' ) <EOL> if folder [ '<STR_LIT>' ] != item [ '<STR_LIT>' ] : <EOL> raise RestException ( "<STR_LIT>" + <EOL> "<STR_LIT>" ) <EOL> minerva_metadata = { <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> } <EOL> for file in self . model ( '<STR_LIT>' ) . childFiles ( item = item , limit = <NUM_LIT:0> ) : <EOL> if '<STR_LIT>' in file [ '<STR_LIT>' ] or '<STR_LIT>' in file [ '<STR_LIT>' ] : <EOL> minerva_metadata [ '<STR_LIT>' ] = [ { <EOL> '<STR_LIT:name>' : file [ '<STR_LIT:name>' ] , '<STR_LIT>' : file [ '<STR_LIT>' ] } ] <EOL> minerva_metadata [ '<STR_LIT>' ] = { <EOL> '<STR_LIT:name>' : file [ '<STR_LIT:name>' ] , '<STR_LIT>' : file [ '<STR_LIT>' ] } <EOL> break <EOL> if '<STR_LIT>' not in minerva_metadata : <EOL> raise RestException ( '<STR_LIT>' ) <EOL> updateMinervaMetadata ( item , minerva_metadata ) <EOL> return item <EOL> createGeojsonDataset . description = ( <EOL> Description ( '<STR_LIT>' ) <EOL> . responseClass ( '<STR_LIT>' ) <EOL> . param ( '<STR_LIT>' , '<STR_LIT>' , required = True ) <EOL> . errorResponse ( '<STR_LIT>' ) <EOL> . errorResponse ( '<STR_LIT>' , <NUM_LIT> ) ) </s>
<s> from setuptools import setup , find_packages <EOL> import re <EOL> import os <EOL> from os . path import join as opj <EOL> curdir = os . path . dirname ( os . path . realpath ( __file__ ) ) <EOL> def read ( fname ) : <EOL> contents = '<STR_LIT>' <EOL> with open ( fname ) as f : <EOL> contents = f . read ( ) <EOL> return contents <EOL> package_name = '<STR_LIT>' <EOL> def version ( ) : <EOL> text = read ( opj ( curdir , package_name , '<STR_LIT>' ) ) <EOL> matches = re . findall ( "<STR_LIT>" , text ) <EOL> return matches [ <NUM_LIT:0> ] [ <NUM_LIT:1> ] <EOL> install_requires = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> ] <EOL> test_requires = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> ] <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> setup ( <EOL> name = package_name , <EOL> packages = [ package_name ] , <EOL> include_package_data = True , <EOL> author = '<STR_LIT>' , <EOL> author_email = '<STR_LIT>' , <EOL> version = version ( ) , <EOL> description = "<STR_LIT>" , <EOL> long_description = read ( opj ( curdir , '<STR_LIT>' ) ) , <EOL> url = '<STR_LIT>' , <EOL> install_requires = install_requires , <EOL> license = '<STR_LIT>' , <EOL> classifiers = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ] , <EOL> package_data = { '<STR_LIT>' : [ '<STR_LIT>' ] } , <EOL> zip_safe = False , <EOL> tests_require = test_requires , <EOL> ) </s>
<s> import unittest <EOL> import utils <EOL> import sdk <EOL> change_file_permissions = [ '<STR_LIT>' ] <EOL> change_folder_permissions = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> list_permissions = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> readonly_permissions = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> class Permissions ( unittest . TestCase ) : <EOL> new_roles = { } <EOL> @ utils . allow ( services = list_permissions ) <EOL> def setUp ( self ) : <EOL> acc = self . account <EOL> if acc . service in list_permissions : <EOL> self . test_folder = utils . create_or_get_test_folder ( acc ) <EOL> self . test_file = utils . create_test_file ( acc ) <EOL> new_roles = { <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" <EOL> } <EOL> if acc . service in change_folder_permissions : <EOL> self . new_roles = new_roles <EOL> self . test_folder . permissions . create ( data = self . new_roles ) <EOL> if acc . service in change_file_permissions : <EOL> self . new_roles = new_roles <EOL> self . test_file . permissions . create ( data = self . new_roles ) <EOL> def list_helper ( self , data ) : <EOL> result = data . permissions . all ( ) <EOL> self . assertIsInstance ( result , sdk . resources . AnnotatedList ) <EOL> owner_exists = False <EOL> for perm in result : <EOL> self . assertIsInstance ( perm , sdk . resources . Permission ) <EOL> if self . account . service not in readonly_permissions : <EOL> if perm . role == "<STR_LIT>" : <EOL> owner_exists = True <EOL> else : <EOL> self . assertIn ( perm . email , self . new_roles ) <EOL> self . assertEqual ( perm . role , self . new_roles . get ( perm . email ) ) <EOL> self . assertTrue ( owner_exists ) <EOL> def test_folder_permissions_list ( self ) : <EOL> if self . account . service in list_permissions : <EOL> self . list_helper ( self . test_folder ) <EOL> def test_folder_permissions_set ( self ) : <EOL> if self . account . service in change_folder_permissions : <EOL> self . new_roles = { <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" <EOL> } <EOL> result = self . test_folder . permissions . create ( data = self . new_roles ) <EOL> self . assertIsInstance ( result . permissions , list ) <EOL> self . list_helper ( self . test_folder ) <EOL> def test_folder_permissions_update ( self ) : <EOL> if self . account . service in change_folder_permissions : <EOL> self . new_roles . update ( { <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" <EOL> } ) <EOL> result = self . test_folder . permissions . update ( data = self . new_roles ) <EOL> self . assertIsInstance ( result . permissions , list ) <EOL> self . list_helper ( self . test_folder ) <EOL> def test_file_permissions_list ( self ) : <EOL> if self . account . service in list_permissions : <EOL> self . list_helper ( self . test_file ) <EOL> def test_file_permissions_set ( self ) : <EOL> if self . account . service in change_file_permissions : <EOL> self . new_roles = { <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" <EOL> } <EOL> result = self . test_file . permissions . create ( data = self . new_roles ) <EOL> self . assertIsInstance ( result . permissions , list ) <EOL> self . list_helper ( self . test_file ) <EOL> def test_file_permissions_update ( self ) : <EOL> if self . account . service in change_file_permissions : <EOL> self . new_roles . update ( { <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" <EOL> } ) <EOL> result = self . test_file . permissions . update ( data = self . new_roles ) <EOL> self . assertIsInstance ( result . permissions , list ) <EOL> self . list_helper ( self . test_file ) <EOL> def test_cases ( ) : <EOL> return [ utils . create_test_case ( acc , Permissions ) for acc in utils . accounts ] <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> suite = utils . create_suite ( test_cases ( ) ) <EOL> unittest . TextTestRunner ( verbosity = <NUM_LIT:2> ) . run ( suite ) </s>
<s> try : <EOL> basestring = basestring <EOL> except NameError : <EOL> basestring = str <EOL> from . nmea import NMEASentence <EOL> class NMEAFile ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , f , * args , ** kwargs ) : <EOL> super ( NMEAFile , self ) . __init__ ( ) <EOL> if isinstance ( f , basestring ) or args or kwargs : <EOL> self . _file = self . open ( f , * args , ** kwargs ) <EOL> else : <EOL> self . _file = f <EOL> self . _context = None <EOL> def open ( self , fp , mode = '<STR_LIT:r>' ) : <EOL> """<STR_LIT>""" <EOL> self . _file = open ( fp , mode = mode ) <EOL> return self . _file <EOL> def close ( self ) : <EOL> """<STR_LIT>""" <EOL> self . _file . close ( ) <EOL> def __iter__ ( self ) : <EOL> """<STR_LIT>""" <EOL> for line in self . _file : <EOL> yield self . parse ( line ) <EOL> def __enter__ ( self ) : <EOL> if hasattr ( self . _file , '<STR_LIT>' ) : <EOL> self . _context = self . _file . __enter__ ( ) <EOL> return self <EOL> def __exit__ ( self , exc_type , exc_val , exc_tb ) : <EOL> if self . _context : <EOL> ctx = self . _context <EOL> self . _context = None <EOL> ctx . __exit__ ( exc_type , exc_val , exc_tb ) <EOL> def next ( self ) : <EOL> """<STR_LIT>""" <EOL> data = self . _file . readline ( ) <EOL> return self . parse ( data ) <EOL> def parse ( self , s ) : <EOL> return NMEASentence . parse ( s ) <EOL> def readline ( self ) : <EOL> """<STR_LIT>""" <EOL> data = self . _file . readline ( ) <EOL> s = self . parse ( data ) <EOL> return s <EOL> def read ( self ) : <EOL> """<STR_LIT>""" <EOL> return [ s for s in self ] </s>
<s> from optparse import make_option <EOL> from django . core . management . base import BaseCommand <EOL> from django . utils . translation import ugettext as _ <EOL> from django_q . cluster import Cluster <EOL> class Command ( BaseCommand ) : <EOL> help = _ ( "<STR_LIT>" ) <EOL> option_list = BaseCommand . option_list + ( <EOL> make_option ( '<STR_LIT>' , <EOL> action = '<STR_LIT:store_true>' , <EOL> dest = '<STR_LIT>' , <EOL> default = False , <EOL> help = '<STR_LIT>' ) , <EOL> ) <EOL> def handle ( self , * args , ** options ) : <EOL> q = Cluster ( ) <EOL> q . start ( ) <EOL> if options . get ( '<STR_LIT>' , False ) : <EOL> q . stop ( ) </s>
<s> sources = """<STR_LIT>""" <EOL> import sys <EOL> import base64 <EOL> import zlib <EOL> class DictImporter ( object ) : <EOL> def __init__ ( self , sources ) : <EOL> self . sources = sources <EOL> def find_module ( self , fullname , path = None ) : <EOL> if fullname == "<STR_LIT>" and sys . version_info >= ( <NUM_LIT:2> , <NUM_LIT:7> ) : <EOL> return None <EOL> if fullname in self . sources : <EOL> return self <EOL> if fullname + '<STR_LIT>' in self . sources : <EOL> return self <EOL> return None <EOL> def load_module ( self , fullname ) : <EOL> from types import ModuleType <EOL> try : <EOL> s = self . sources [ fullname ] <EOL> is_pkg = False <EOL> except KeyError : <EOL> s = self . sources [ fullname + '<STR_LIT>' ] <EOL> is_pkg = True <EOL> co = compile ( s , fullname , '<STR_LIT>' ) <EOL> module = sys . modules . setdefault ( fullname , ModuleType ( fullname ) ) <EOL> module . __file__ = "<STR_LIT>" % ( __file__ , fullname ) <EOL> module . __loader__ = self <EOL> if is_pkg : <EOL> module . __path__ = [ fullname ] <EOL> do_exec ( co , module . __dict__ ) <EOL> return sys . modules [ fullname ] <EOL> def get_source ( self , name ) : <EOL> res = self . sources . get ( name ) <EOL> if res is None : <EOL> res = self . sources . get ( name + '<STR_LIT>' ) <EOL> return res <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> try : <EOL> import pkg_resources <EOL> except ImportError : <EOL> sys . stderr . write ( "<STR_LIT>" ) <EOL> sys . exit ( <NUM_LIT:2> ) <EOL> if sys . version_info >= ( <NUM_LIT:3> , <NUM_LIT:0> ) : <EOL> exec ( "<STR_LIT>" ) <EOL> import pickle <EOL> sources = sources . encode ( "<STR_LIT:ascii>" ) <EOL> sources = pickle . loads ( zlib . decompress ( base64 . decodebytes ( sources ) ) ) <EOL> else : <EOL> import cPickle as pickle <EOL> exec ( "<STR_LIT>" ) <EOL> sources = pickle . loads ( zlib . decompress ( base64 . decodestring ( sources ) ) ) <EOL> importer = DictImporter ( sources ) <EOL> sys . meta_path . insert ( <NUM_LIT:0> , importer ) <EOL> entry = "<STR_LIT>" <EOL> do_exec ( entry , locals ( ) ) </s>
<s> from __future__ import with_statement <EOL> from contextlib import contextmanager <EOL> from datetime import datetime <EOL> from UserDict import DictMixin <EOL> import bcrypt <EOL> from pyramid . location import lineage <EOL> from pyramid . security import view_execution_permitted <EOL> from six import string_types <EOL> from sqlalchemy import Boolean , bindparam <EOL> from sqlalchemy import Column <EOL> from sqlalchemy import DateTime <EOL> from sqlalchemy import func <EOL> from sqlalchemy import Integer <EOL> from sqlalchemy import Unicode <EOL> from sqlalchemy . orm . exc import NoResultFound <EOL> from sqlalchemy . sql . expression import and_ <EOL> from sqlalchemy . sql . expression import or_ <EOL> from zope . deprecation . deprecation import deprecated <EOL> from kotti import Base <EOL> from kotti import DBSession <EOL> from kotti import get_settings <EOL> from kotti . sqla import bakery <EOL> from kotti . sqla import JsonType <EOL> from kotti . sqla import MutationList <EOL> from kotti . util import _ <EOL> from kotti . util import request_cache <EOL> from kotti . util import DontCache <EOL> def get_principals ( ) : <EOL> return get_settings ( ) [ '<STR_LIT>' ] [ <NUM_LIT:0> ] ( ) <EOL> @ request_cache ( lambda request : None ) <EOL> def get_user ( request ) : <EOL> userid = request . unauthenticated_userid <EOL> return get_principals ( ) . get ( userid ) <EOL> def has_permission ( permission , context , request ) : <EOL> """<STR_LIT>""" <EOL> return request . has_permission ( permission , context ) <EOL> deprecated ( u'<STR_LIT>' , <EOL> u"<STR_LIT>" <EOL> u"<STR_LIT>" <EOL> u"<STR_LIT>" ) <EOL> class Principal ( Base ) : <EOL> """<STR_LIT>""" <EOL> id = Column ( Integer , primary_key = True ) <EOL> name = Column ( Unicode ( <NUM_LIT:100> ) , unique = True ) <EOL> password = Column ( Unicode ( <NUM_LIT:100> ) ) <EOL> active = Column ( Boolean ) <EOL> confirm_token = Column ( Unicode ( <NUM_LIT:100> ) ) <EOL> title = Column ( Unicode ( <NUM_LIT:100> ) , nullable = False ) <EOL> email = Column ( Unicode ( <NUM_LIT:100> ) , unique = True ) <EOL> groups = Column ( MutationList . as_mutable ( JsonType ) , nullable = False ) <EOL> creation_date = Column ( DateTime ( ) , nullable = False ) <EOL> last_login_date = Column ( DateTime ( ) ) <EOL> __tablename__ = '<STR_LIT>' <EOL> __mapper_args__ = dict ( <EOL> order_by = name , <EOL> ) <EOL> def __init__ ( self , name , password = None , active = True , confirm_token = None , <EOL> title = u"<STR_LIT>" , email = None , groups = None ) : <EOL> self . name = name <EOL> if password is not None : <EOL> password = get_principals ( ) . hash_password ( password ) <EOL> self . password = password <EOL> self . active = active <EOL> self . confirm_token = confirm_token <EOL> self . title = title <EOL> self . email = email <EOL> if groups is None : <EOL> groups = [ ] <EOL> self . groups = groups <EOL> self . creation_date = datetime . now ( ) <EOL> self . last_login_date = None <EOL> def __repr__ ( self ) : <EOL> return u'<STR_LIT>' . format ( self . name ) <EOL> class AbstractPrincipals ( object ) : <EOL> """<STR_LIT>""" <EOL> def __getitem__ ( self , name ) : <EOL> """<STR_LIT>""" <EOL> def __setitem__ ( self , name , principal ) : <EOL> """<STR_LIT>""" <EOL> def __delitem__ ( self , name ) : <EOL> """<STR_LIT>""" <EOL> def keys ( self ) : <EOL> """<STR_LIT>""" <EOL> def search ( self , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> def hash_password ( self , password ) : <EOL> """<STR_LIT>""" <EOL> def validate_password ( self , clear , hashed ) : <EOL> """<STR_LIT>""" <EOL> ROLES = { <EOL> u'<STR_LIT>' : Principal ( u'<STR_LIT>' , title = _ ( u'<STR_LIT>' ) ) , <EOL> u'<STR_LIT>' : Principal ( u'<STR_LIT>' , title = _ ( u'<STR_LIT>' ) ) , <EOL> u'<STR_LIT>' : Principal ( u'<STR_LIT>' , title = _ ( u'<STR_LIT>' ) ) , <EOL> u'<STR_LIT>' : Principal ( u'<STR_LIT>' , title = _ ( u'<STR_LIT>' ) ) , <EOL> } <EOL> _DEFAULT_ROLES = ROLES . copy ( ) <EOL> SHARING_ROLES = [ u'<STR_LIT>' , u'<STR_LIT>' , u'<STR_LIT>' ] <EOL> USER_MANAGEMENT_ROLES = SHARING_ROLES + [ '<STR_LIT>' ] <EOL> _DEFAULT_SHARING_ROLES = SHARING_ROLES [ : ] <EOL> _DEFAULT_USER_MANAGEMENT_ROLES = USER_MANAGEMENT_ROLES [ : ] <EOL> SITE_ACL = [ <EOL> [ '<STR_LIT>' , '<STR_LIT>' , [ '<STR_LIT>' ] ] , <EOL> [ '<STR_LIT>' , '<STR_LIT>' , [ '<STR_LIT>' ] ] , <EOL> [ '<STR_LIT>' , '<STR_LIT>' , [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ] , <EOL> [ '<STR_LIT>' , '<STR_LIT>' , [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ] , <EOL> ] <EOL> def set_roles ( roles_dict ) : <EOL> ROLES . clear ( ) <EOL> ROLES . update ( roles_dict ) <EOL> def set_sharing_roles ( role_names ) : <EOL> SHARING_ROLES [ : ] = role_names <EOL> def set_user_management_roles ( role_names ) : <EOL> USER_MANAGEMENT_ROLES [ : ] = role_names <EOL> def reset_roles ( ) : <EOL> ROLES . clear ( ) <EOL> ROLES . update ( _DEFAULT_ROLES ) <EOL> def reset_sharing_roles ( ) : <EOL> SHARING_ROLES [ : ] = _DEFAULT_SHARING_ROLES <EOL> def reset_user_management_roles ( ) : <EOL> USER_MANAGEMENT_ROLES [ : ] = _DEFAULT_USER_MANAGEMENT_ROLES <EOL> def reset ( ) : <EOL> reset_roles ( ) <EOL> reset_sharing_roles ( ) <EOL> reset_user_management_roles ( ) <EOL> class PersistentACLMixin ( object ) : <EOL> def _get_acl ( self ) : <EOL> if self . _acl is None : <EOL> raise AttributeError ( '<STR_LIT>' ) <EOL> return self . _acl <EOL> def _set_acl ( self , value ) : <EOL> self . _acl = value <EOL> def _del_acl ( self ) : <EOL> self . _acl = None <EOL> __acl__ = property ( _get_acl , _set_acl , _del_acl ) <EOL> def _cachekey_list_groups_raw ( name , context ) : <EOL> context_id = context is not None and getattr ( context , '<STR_LIT:id>' , id ( context ) ) <EOL> return name , context_id <EOL> @ request_cache ( _cachekey_list_groups_raw ) <EOL> def list_groups_raw ( name , context ) : <EOL> """<STR_LIT>""" <EOL> from kotti . resources import Node <EOL> if isinstance ( context , Node ) : <EOL> return set ( <EOL> r . group_name for r in context . local_groups <EOL> if r . principal_name == name <EOL> ) <EOL> return set ( ) <EOL> def list_groups ( name , context = None ) : <EOL> """<STR_LIT>""" <EOL> return list_groups_ext ( name , context ) [ <NUM_LIT:0> ] <EOL> def _cachekey_list_groups_ext ( name , context = None , _seen = None , _inherited = None ) : <EOL> if _seen is not None or _inherited is not None : <EOL> raise DontCache <EOL> else : <EOL> context_id = getattr ( context , '<STR_LIT:id>' , id ( context ) ) <EOL> return unicode ( name ) , context_id <EOL> @ request_cache ( _cachekey_list_groups_ext ) <EOL> def list_groups_ext ( name , context = None , _seen = None , _inherited = None ) : <EOL> name = unicode ( name ) <EOL> groups = set ( ) <EOL> recursing = _inherited is not None <EOL> _inherited = _inherited or set ( ) <EOL> principal = get_principals ( ) . get ( name ) <EOL> if principal is not None : <EOL> groups . update ( principal . groups ) <EOL> if context is not None or ( context is None and _seen is not None ) : <EOL> _inherited . update ( principal . groups ) <EOL> if _seen is None : <EOL> _seen = { name } <EOL> if context is not None : <EOL> items = lineage ( context ) <EOL> for idx , item in enumerate ( items ) : <EOL> group_names = [ i for i in list_groups_raw ( name , item ) <EOL> if i not in _seen ] <EOL> groups . update ( group_names ) <EOL> if recursing or idx != <NUM_LIT:0> : <EOL> _inherited . update ( group_names ) <EOL> new_groups = groups - _seen <EOL> _seen . update ( new_groups ) <EOL> for group_name in new_groups : <EOL> g , i = list_groups_ext ( <EOL> group_name , context , _seen = _seen , _inherited = _inherited ) <EOL> groups . update ( g ) <EOL> _inherited . update ( i ) <EOL> return list ( groups ) , list ( _inherited ) <EOL> def set_groups ( name , context , groups_to_set = ( ) ) : <EOL> """<STR_LIT>""" <EOL> from kotti . resources import LocalGroup <EOL> name = unicode ( name ) <EOL> context . local_groups = [ <EOL> lg for lg in context . local_groups <EOL> if lg . principal_name != name <EOL> ] + [ <EOL> LocalGroup ( context , name , unicode ( group_name ) ) <EOL> for group_name in groups_to_set <EOL> ] <EOL> def list_groups_callback ( name , request ) : <EOL> """<STR_LIT>""" <EOL> if not is_user ( name ) : <EOL> return None <EOL> if name in get_principals ( ) : <EOL> context = request . environ . get ( <EOL> '<STR_LIT>' , getattr ( request , '<STR_LIT>' , None ) ) <EOL> if context is None : <EOL> from kotti . resources import get_root <EOL> context = get_root ( request ) <EOL> return list_groups ( name , context ) <EOL> @ contextmanager <EOL> def authz_context ( context , request ) : <EOL> before = request . environ . pop ( '<STR_LIT>' , None ) <EOL> request . environ [ '<STR_LIT>' ] = context <EOL> try : <EOL> yield <EOL> finally : <EOL> del request . environ [ '<STR_LIT>' ] <EOL> if before is not None : <EOL> request . environ [ '<STR_LIT>' ] = before <EOL> @ contextmanager <EOL> def request_method ( request , method ) : <EOL> before = request . method <EOL> request . method = method <EOL> try : <EOL> yield <EOL> finally : <EOL> request . method = before <EOL> def view_permitted ( context , request , name = '<STR_LIT>' , method = '<STR_LIT:GET>' ) : <EOL> with authz_context ( context , request ) : <EOL> with request_method ( request , method ) : <EOL> return view_execution_permitted ( context , request , name ) <EOL> def principals_with_local_roles ( context , inherit = True ) : <EOL> """<STR_LIT>""" <EOL> principals = set ( ) <EOL> items = [ context ] <EOL> if inherit : <EOL> items = lineage ( context ) <EOL> for item in items : <EOL> principals . update ( <EOL> r . principal_name for r in item . local_groups <EOL> if not r . principal_name . startswith ( '<STR_LIT>' ) <EOL> ) <EOL> return list ( principals ) <EOL> def map_principals_with_local_roles ( context ) : <EOL> principals = get_principals ( ) <EOL> value = [ ] <EOL> for principal_name in principals_with_local_roles ( context ) : <EOL> try : <EOL> principal = principals [ principal_name ] <EOL> except KeyError : <EOL> continue <EOL> else : <EOL> all , inherited = list_groups_ext ( principal_name , context ) <EOL> value . append ( ( principal , ( all , inherited ) ) ) <EOL> return sorted ( value , key = lambda t : t [ <NUM_LIT:0> ] . name ) <EOL> def is_user ( principal ) : <EOL> if not isinstance ( principal , string_types ) : <EOL> principal = principal . name <EOL> return '<STR_LIT::>' not in principal <EOL> class Principals ( DictMixin ) : <EOL> """<STR_LIT>""" <EOL> factory = Principal <EOL> @ classmethod <EOL> def _principal_by_name ( cls , name ) : <EOL> query = bakery ( lambda session : session . query ( cls . factory ) . filter ( <EOL> cls . factory . name == bindparam ( '<STR_LIT:name>' ) ) ) <EOL> return query ( DBSession ( ) ) . params ( name = name ) . one ( ) <EOL> @ request_cache ( lambda self , name : unicode ( name ) ) <EOL> def __getitem__ ( self , name ) : <EOL> name = unicode ( name ) <EOL> if name . startswith ( '<STR_LIT>' ) : <EOL> raise KeyError ( name ) <EOL> try : <EOL> return self . _principal_by_name ( name ) <EOL> except NoResultFound : <EOL> raise KeyError ( name ) <EOL> def __setitem__ ( self , name , principal ) : <EOL> name = unicode ( name ) <EOL> if isinstance ( principal , dict ) : <EOL> principal = self . factory ( ** principal ) <EOL> DBSession . add ( principal ) <EOL> def __delitem__ ( self , name ) : <EOL> name = unicode ( name ) <EOL> try : <EOL> principal = self . _principal_by_name ( name ) <EOL> DBSession . delete ( principal ) <EOL> except NoResultFound : <EOL> raise KeyError ( name ) <EOL> def iterkeys ( self ) : <EOL> for ( principal_name , ) in DBSession . query ( self . factory . name ) : <EOL> yield principal_name <EOL> def keys ( self ) : <EOL> return list ( self . iterkeys ( ) ) <EOL> def search ( self , match = '<STR_LIT>' , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> if not kwargs : <EOL> return [ ] <EOL> filters = [ ] <EOL> for key , value in kwargs . items ( ) : <EOL> col = getattr ( self . factory , key ) <EOL> if isinstance ( value , string_types ) and '<STR_LIT:*>' in value : <EOL> value = value . replace ( '<STR_LIT:*>' , '<STR_LIT:%>' ) . lower ( ) <EOL> filters . append ( func . lower ( col ) . like ( value ) ) <EOL> else : <EOL> filters . append ( col == value ) <EOL> query = DBSession . query ( self . factory ) <EOL> if match == '<STR_LIT>' : <EOL> query = query . filter ( or_ ( * filters ) ) <EOL> elif match == '<STR_LIT:all>' : <EOL> query = query . filter ( and_ ( * filters ) ) <EOL> else : <EOL> raise ValueError ( '<STR_LIT>' ) <EOL> return query <EOL> log_rounds = <NUM_LIT:10> <EOL> def hash_password ( self , password , hashed = None ) : <EOL> if hashed is None : <EOL> hashed = bcrypt . gensalt ( self . log_rounds ) <EOL> return unicode ( <EOL> bcrypt . hashpw ( password . encode ( '<STR_LIT:utf-8>' ) , hashed . encode ( '<STR_LIT:utf-8>' ) ) ) <EOL> def validate_password ( self , clear , hashed ) : <EOL> try : <EOL> return self . hash_password ( clear , hashed ) == hashed <EOL> except ValueError : <EOL> return False <EOL> def principals_factory ( ) : <EOL> return Principals ( ) </s>
<s> import json <EOL> from mechanize . _mechanize import LinkNotFoundError <EOL> from pytest import raises <EOL> from kotti . testing import BASE_URL <EOL> from kotti . testing import user <EOL> from kotti . views . edit . upload import UploadView <EOL> def test_upload_anonymous ( root , dummy_request , browser ) : <EOL> view = UploadView ( root , dummy_request ) <EOL> assert view . factories == [ ] <EOL> link = browser . getLink <EOL> browser . open ( u'<STR_LIT>' . format ( BASE_URL ) ) <EOL> with raises ( LinkNotFoundError ) : <EOL> link ( '<STR_LIT>' ) . click ( ) <EOL> browser . open ( u'<STR_LIT>' . format ( BASE_URL ) ) <EOL> assert browser . url . startswith ( u'<STR_LIT>' . format ( BASE_URL ) ) <EOL> browser . open ( u'<STR_LIT>' . format ( BASE_URL ) ) <EOL> assert browser . url . startswith ( u'<STR_LIT>' . format ( BASE_URL ) ) <EOL> @ user ( '<STR_LIT>' ) <EOL> def test_upload_authenticated_wo_mimetype ( root , dummy_request , browser ) : <EOL> with raises ( KeyError ) : <EOL> browser . open ( u'<STR_LIT>' . format ( BASE_URL ) ) <EOL> @ user ( '<STR_LIT>' ) <EOL> def test_upload_authenticated_text ( root , dummy_request , browser ) : <EOL> browser . open ( u'<STR_LIT>' . format ( BASE_URL ) ) <EOL> j = json . loads ( browser . contents ) <EOL> assert '<STR_LIT>' in j <EOL> types = j [ '<STR_LIT>' ] <EOL> assert len ( types ) == <NUM_LIT:1> <EOL> assert types [ <NUM_LIT:0> ] [ '<STR_LIT:name>' ] == u'<STR_LIT>' </s>
<s> import os <EOL> import sys <EOL> from setuptools import setup <EOL> from setuptools import find_packages <EOL> here = os . path . abspath ( os . path . dirname ( __file__ ) ) <EOL> try : <EOL> README = open ( os . path . join ( here , '<STR_LIT>' ) ) . read ( ) <EOL> AUTHORS = open ( os . path . join ( here , '<STR_LIT>' ) ) . read ( ) <EOL> CHANGES = open ( os . path . join ( here , '<STR_LIT>' ) ) . read ( ) <EOL> except IOError : <EOL> README = AUTHORS = CHANGES = '<STR_LIT>' <EOL> install_requires = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> ] <EOL> tests_require = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> ] <EOL> development_requires = [ ] <EOL> docs_require = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> ] <EOL> if sys . version_info [ : <NUM_LIT:3> ] < ( <NUM_LIT:2> , <NUM_LIT:7> , <NUM_LIT:0> ) : <EOL> install_requires . append ( '<STR_LIT>' ) <EOL> setup ( name = '<STR_LIT>' , <EOL> version = '<STR_LIT>' , <EOL> description = "<STR_LIT>" , <EOL> long_description = '<STR_LIT>' . join ( [ README , AUTHORS , CHANGES ] ) , <EOL> classifiers = [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ] , <EOL> author = '<STR_LIT>' , <EOL> author_email = '<STR_LIT>' , <EOL> url = '<STR_LIT>' , <EOL> keywords = '<STR_LIT>' , <EOL> license = "<STR_LIT>" , <EOL> packages = find_packages ( ) , <EOL> include_package_data = True , <EOL> zip_safe = False , <EOL> install_requires = install_requires , <EOL> tests_require = tests_require , <EOL> dependency_links = [ ] , <EOL> entry_points = """<STR_LIT>""" , <EOL> extras_require = { <EOL> '<STR_LIT>' : tests_require , <EOL> '<STR_LIT>' : development_requires , <EOL> '<STR_LIT>' : docs_require , <EOL> } , <EOL> ) </s>
<s> """<STR_LIT>""" <EOL> from __future__ import division , unicode_literals <EOL> from . markers import list_marker_layout <EOL> from . min_max import handle_min_max_width <EOL> from . percentages import resolve_percentages , resolve_position_percentages <EOL> from . preferred import shrink_to_fit <EOL> from . tables import table_wrapper_width <EOL> from . . formatting_structure import boxes <EOL> @ handle_min_max_width <EOL> def float_width ( box , context , containing_block ) : <EOL> if box . width == '<STR_LIT>' : <EOL> box . width = shrink_to_fit ( context , box , containing_block . width ) <EOL> def float_layout ( context , box , containing_block , device_size , absolute_boxes , <EOL> fixed_boxes ) : <EOL> """<STR_LIT>""" <EOL> from . blocks import block_container_layout <EOL> from . inlines import inline_replaced_box_width_height <EOL> resolve_percentages ( box , ( containing_block . width , containing_block . height ) ) <EOL> resolve_position_percentages ( <EOL> box , ( containing_block . width , containing_block . height ) ) <EOL> if box . margin_left == '<STR_LIT>' : <EOL> box . margin_left = <NUM_LIT:0> <EOL> if box . margin_right == '<STR_LIT>' : <EOL> box . margin_right = <NUM_LIT:0> <EOL> if box . margin_top == '<STR_LIT>' : <EOL> box . margin_top = <NUM_LIT:0> <EOL> if box . margin_bottom == '<STR_LIT>' : <EOL> box . margin_bottom = <NUM_LIT:0> <EOL> clearance = get_clearance ( context , box ) <EOL> if clearance is not None : <EOL> box . position_y += clearance <EOL> if isinstance ( box , boxes . BlockReplacedBox ) : <EOL> inline_replaced_box_width_height ( box , device_size = None ) <EOL> elif box . width == '<STR_LIT>' : <EOL> float_width ( box , context , containing_block ) <EOL> if box . is_table_wrapper : <EOL> table_wrapper_width ( <EOL> context , box , ( containing_block . width , containing_block . height ) ) <EOL> if isinstance ( box , boxes . BlockBox ) : <EOL> context . create_block_formatting_context ( ) <EOL> box , _ , _ , _ , _ = block_container_layout ( <EOL> context , box , max_position_y = float ( '<STR_LIT>' ) , <EOL> skip_stack = None , device_size = device_size , page_is_empty = False , <EOL> absolute_boxes = absolute_boxes , fixed_boxes = fixed_boxes , <EOL> adjoining_margins = None ) <EOL> list_marker_layout ( context , box ) <EOL> context . finish_block_formatting_context ( box ) <EOL> else : <EOL> assert isinstance ( box , boxes . BlockReplacedBox ) <EOL> box = find_float_position ( context , box , containing_block ) <EOL> context . excluded_shapes . append ( box ) <EOL> return box <EOL> def find_float_position ( context , box , containing_block ) : <EOL> """<STR_LIT>""" <EOL> if context . excluded_shapes : <EOL> highest_y = context . excluded_shapes [ - <NUM_LIT:1> ] . position_y <EOL> if box . position_y < highest_y : <EOL> box . translate ( <NUM_LIT:0> , highest_y - box . position_y ) <EOL> position_x , position_y , available_width = avoid_collisions ( <EOL> context , box , containing_block ) <EOL> if box . style . float == '<STR_LIT:right>' : <EOL> position_x += available_width - box . margin_width ( ) <EOL> box . translate ( position_x - box . position_x , position_y - box . position_y ) <EOL> return box <EOL> def get_clearance ( context , box , collapsed_margin = <NUM_LIT:0> ) : <EOL> """<STR_LIT>""" <EOL> clearance = None <EOL> hypothetical_position = box . position_y + collapsed_margin <EOL> for excluded_shape in context . excluded_shapes : <EOL> if box . style . clear in ( excluded_shape . style . float , '<STR_LIT>' ) : <EOL> y , h = excluded_shape . position_y , excluded_shape . margin_height ( ) <EOL> if hypothetical_position < y + h : <EOL> clearance = max ( <EOL> ( clearance or <NUM_LIT:0> ) , y + h - hypothetical_position ) <EOL> return clearance <EOL> def avoid_collisions ( context , box , containing_block , outer = True ) : <EOL> excluded_shapes = context . excluded_shapes <EOL> position_y = box . position_y if outer else box . border_box_y ( ) <EOL> box_width = box . margin_width ( ) if outer else box . border_width ( ) <EOL> box_height = box . margin_height ( ) if outer else box . border_height ( ) <EOL> if box . border_height ( ) == <NUM_LIT:0> and box . is_floated ( ) : <EOL> return <NUM_LIT:0> , <NUM_LIT:0> , containing_block . width <EOL> while True : <EOL> colliding_shapes = [ <EOL> shape for shape in excluded_shapes <EOL> if ( shape . position_y < position_y < <EOL> shape . position_y + shape . margin_height ( ) ) or <EOL> ( shape . position_y < position_y + box_height < <EOL> shape . position_y + shape . margin_height ( ) ) or <EOL> ( shape . position_y >= position_y and <EOL> shape . position_y + shape . margin_height ( ) <= <EOL> position_y + box_height ) <EOL> ] <EOL> left_bounds = [ <EOL> shape . position_x + shape . margin_width ( ) <EOL> for shape in colliding_shapes <EOL> if shape . style . float == '<STR_LIT:left>' ] <EOL> right_bounds = [ <EOL> shape . position_x <EOL> for shape in colliding_shapes <EOL> if shape . style . float == '<STR_LIT:right>' ] <EOL> max_left_bound = containing_block . content_box_x ( ) <EOL> max_right_bound = containing_block . content_box_x ( ) + containing_block . width <EOL> if not outer : <EOL> max_left_bound += box . margin_left <EOL> max_right_bound -= box . margin_right <EOL> if left_bounds or right_bounds : <EOL> if left_bounds : <EOL> max_left_bound = max ( max ( left_bounds ) , max_left_bound ) <EOL> if right_bounds : <EOL> max_right_bound = min ( min ( right_bounds ) , max_right_bound ) <EOL> if box_width > max_right_bound - max_left_bound : <EOL> new_positon_y = min ( <EOL> shape . position_y + shape . margin_height ( ) <EOL> for shape in colliding_shapes ) <EOL> if new_positon_y > position_y : <EOL> position_y = new_positon_y <EOL> continue <EOL> break <EOL> position_x = max_left_bound <EOL> available_width = max_right_bound - max_left_bound <EOL> if not outer : <EOL> position_x -= box . margin_left <EOL> position_y -= box . margin_top <EOL> return position_x , position_y , available_width </s>
<s> """<STR_LIT>""" <EOL> from setuptools import setup , find_packages <EOL> VERSION = '<STR_LIT>' <EOL> options = dict ( <EOL> name = "<STR_LIT>" , <EOL> version = VERSION , <EOL> description = "<STR_LIT>" , <EOL> long_description = __doc__ , <EOL> author = "<STR_LIT>" , <EOL> author_email = "<STR_LIT>" , <EOL> license = "<STR_LIT>" , <EOL> platforms = "<STR_LIT>" , <EOL> install_requires = [ '<STR_LIT>' ] , <EOL> provides = [ '<STR_LIT>' ] , <EOL> packages = find_packages ( ) , <EOL> use_2to3 = True , <EOL> classifiers = [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" ] ) <EOL> setup ( ** options ) </s>
<s> from django . conf . urls import patterns , include , url <EOL> import health_check <EOL> health_check . autodiscover ( ) <EOL> urlpatterns = patterns ( '<STR_LIT>' , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = '<STR_LIT>' ) , <EOL> ) </s>
<s> import django <EOL> from django . db import connection <EOL> from django . db . models import Count <EOL> from django . db . models . query_utils import Q <EOL> from django . utils import translation <EOL> from hvad . test_utils . data import NORMAL , STANDARD <EOL> from hvad . test_utils . testcase import HvadTestCase , minimumDjangoVersion <EOL> from hvad . test_utils . project . app . models import Normal , AggregateModel , Standard , SimpleRelated <EOL> from hvad . test_utils . fixtures import NormalFixture , StandardFixture <EOL> class FilterTests ( HvadTestCase , NormalFixture ) : <EOL> normal_count = <NUM_LIT:2> <EOL> def test_simple_filter ( self ) : <EOL> qs = Normal . objects . language ( '<STR_LIT>' ) . filter ( shared_field__contains = '<STR_LIT:2>' ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) <EOL> obj = qs [ <NUM_LIT:0> ] <EOL> self . assertEqual ( obj . shared_field , NORMAL [ <NUM_LIT:2> ] . shared_field ) <EOL> self . assertEqual ( obj . translated_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) <EOL> qs = Normal . objects . language ( '<STR_LIT>' ) . filter ( shared_field__contains = '<STR_LIT:1>' ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) <EOL> obj = qs [ <NUM_LIT:0> ] <EOL> self . assertEqual ( obj . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> self . assertEqual ( obj . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> def test_translated_filter ( self ) : <EOL> qs = Normal . objects . language ( '<STR_LIT>' ) . filter ( translated_field__contains = '<STR_LIT>' ) <EOL> self . assertEqual ( qs . count ( ) , self . normal_count ) <EOL> obj1 , obj2 = qs <EOL> self . assertEqual ( obj1 . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> self . assertEqual ( obj1 . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> self . assertEqual ( obj2 . shared_field , NORMAL [ <NUM_LIT:2> ] . shared_field ) <EOL> self . assertEqual ( obj2 . translated_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) <EOL> def test_fallbacks_filter ( self ) : <EOL> ( Normal . objects . language ( '<STR_LIT>' ) <EOL> . filter ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> . delete_translations ( ) ) <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> qs = Normal . objects . language ( ) . fallbacks ( ) <EOL> with self . assertNumQueries ( <NUM_LIT:2> ) : <EOL> self . assertEqual ( qs . count ( ) , self . normal_count ) <EOL> self . assertEqual ( len ( qs ) , self . normal_count ) <EOL> with self . assertNumQueries ( <NUM_LIT:0> ) : <EOL> self . assertCountEqual ( ( obj . pk for obj in qs ) , tuple ( self . normal_id . values ( ) ) ) <EOL> self . assertCountEqual ( ( obj . language_code for obj in qs ) , self . translations ) <EOL> def test_all_languages_filter ( self ) : <EOL> with self . assertNumQueries ( <NUM_LIT:2> ) : <EOL> qs = Normal . objects . language ( '<STR_LIT:all>' ) . filter ( shared_field__contains = '<STR_LIT>' ) <EOL> self . assertEqual ( qs . count ( ) , self . normal_count * len ( self . translations ) ) <EOL> self . assertCountEqual ( ( obj . shared_field for obj in qs ) , <EOL> ( NORMAL [ <NUM_LIT:1> ] . shared_field , <EOL> NORMAL [ <NUM_LIT:2> ] . shared_field ) * <NUM_LIT:2> ) <EOL> self . assertCountEqual ( ( obj . translated_field for obj in qs ) , <EOL> ( NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] , <EOL> NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] , <EOL> NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] , <EOL> NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) ) <EOL> with self . assertNumQueries ( <NUM_LIT:2> ) : <EOL> qs = Normal . objects . language ( '<STR_LIT:all>' ) . filter ( translated_field__contains = '<STR_LIT>' ) <EOL> self . assertEqual ( qs . count ( ) , self . normal_count ) <EOL> self . assertCountEqual ( ( obj . shared_field for obj in qs ) , <EOL> ( NORMAL [ <NUM_LIT:1> ] . shared_field , <EOL> NORMAL [ <NUM_LIT:2> ] . shared_field ) ) <EOL> self . assertCountEqual ( ( obj . translated_field for obj in qs ) , <EOL> ( NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] , <EOL> NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) ) <EOL> with self . assertNumQueries ( <NUM_LIT:2> ) : <EOL> qs = Normal . objects . language ( '<STR_LIT:all>' ) . filter ( translated_field__contains = '<STR_LIT:1>' ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) <EOL> obj = qs [ <NUM_LIT:0> ] <EOL> self . assertEqual ( obj . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> self . assertEqual ( obj . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> def test_deferred_language_filter ( self ) : <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> qs = Normal . objects . language ( ) . filter ( translated_field__contains = '<STR_LIT>' ) <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> self . assertEqual ( qs . count ( ) , self . normal_count ) <EOL> obj1 , obj2 = qs <EOL> self . assertEqual ( obj1 . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> self . assertEqual ( obj1 . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> self . assertEqual ( obj2 . shared_field , NORMAL [ <NUM_LIT:2> ] . shared_field ) <EOL> self . assertEqual ( obj2 . translated_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) <EOL> class ExtraTests ( HvadTestCase , NormalFixture ) : <EOL> normal_count = <NUM_LIT:2> <EOL> def test_simple_extra ( self ) : <EOL> qs = Normal . objects . language ( '<STR_LIT>' ) . extra ( select = { '<STR_LIT>' : '<STR_LIT>' } ) <EOL> self . assertEqual ( qs . count ( ) , self . normal_count ) <EOL> self . assertEqual ( int ( qs [ <NUM_LIT:0> ] . test_extra ) , <NUM_LIT:4> ) <EOL> class QueryCachingTests ( HvadTestCase , NormalFixture ) : <EOL> normal_count = <NUM_LIT:2> <EOL> def _try_all_cache_using_methods ( self , qs , length ) : <EOL> with self . assertNumQueries ( <NUM_LIT:0> ) : <EOL> x = <NUM_LIT:0> <EOL> for obj in qs : x += <NUM_LIT:1> <EOL> self . assertEqual ( x , length ) <EOL> with self . assertNumQueries ( <NUM_LIT:0> ) : <EOL> qs [ <NUM_LIT:0> ] <EOL> with self . assertNumQueries ( <NUM_LIT:0> ) : <EOL> self . assertEqual ( qs . exists ( ) , length != <NUM_LIT:0> ) <EOL> with self . assertNumQueries ( <NUM_LIT:0> ) : <EOL> self . assertEqual ( qs . count ( ) , length ) <EOL> with self . assertNumQueries ( <NUM_LIT:0> ) : <EOL> self . assertEqual ( len ( qs ) , length ) <EOL> with self . assertNumQueries ( <NUM_LIT:0> ) : <EOL> self . assertEqual ( bool ( qs ) , length != <NUM_LIT:0> ) <EOL> def test_iter_caches ( self ) : <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> index = <NUM_LIT:0> <EOL> qs = Normal . objects . language ( ) . filter ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> for obj in qs : <EOL> index += <NUM_LIT:1> <EOL> self . assertEqual ( index , <NUM_LIT:1> ) <EOL> self . _try_all_cache_using_methods ( qs , <NUM_LIT:1> ) <EOL> def test_pickling_caches ( self ) : <EOL> import pickle <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> qs = Normal . objects . language ( ) . filter ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> pickle . dumps ( qs ) <EOL> self . _try_all_cache_using_methods ( qs , <NUM_LIT:1> ) <EOL> def test_len_caches ( self ) : <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> qs = Normal . objects . language ( ) . filter ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> self . assertEqual ( len ( qs ) , <NUM_LIT:1> ) <EOL> self . _try_all_cache_using_methods ( qs , <NUM_LIT:1> ) <EOL> def test_bool_caches ( self ) : <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> qs = Normal . objects . language ( ) . filter ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> self . assertTrue ( qs ) <EOL> self . _try_all_cache_using_methods ( qs , <NUM_LIT:1> ) <EOL> class IterTests ( HvadTestCase , NormalFixture ) : <EOL> normal_count = <NUM_LIT:2> <EOL> def test_simple_iter ( self ) : <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> with self . assertNumQueries ( <NUM_LIT:1> ) : <EOL> for index , obj in enumerate ( Normal . objects . language ( ) , <NUM_LIT:1> ) : <EOL> self . assertEqual ( obj . shared_field , NORMAL [ index ] . shared_field ) <EOL> self . assertEqual ( obj . translated_field , NORMAL [ index ] . translated_field [ '<STR_LIT>' ] ) <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> with self . assertNumQueries ( <NUM_LIT:1> ) : <EOL> for index , obj in enumerate ( Normal . objects . language ( ) , <NUM_LIT:1> ) : <EOL> self . assertEqual ( obj . shared_field , NORMAL [ index ] . shared_field ) <EOL> self . assertEqual ( obj . translated_field , NORMAL [ index ] . translated_field [ '<STR_LIT>' ] ) <EOL> def test_iter_unique_reply ( self ) : <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> self . assertEqual ( len ( Normal . objects . all ( ) ) , len ( Normal . objects . untranslated ( ) ) ) <EOL> def test_iter_deferred_language ( self ) : <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> qs = Normal . objects . language ( ) <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> for index , obj in enumerate ( qs , <NUM_LIT:1> ) : <EOL> self . assertEqual ( obj . shared_field , NORMAL [ index ] . shared_field ) <EOL> self . assertEqual ( obj . translated_field , NORMAL [ index ] . translated_field [ '<STR_LIT>' ] ) <EOL> class UpdateTests ( HvadTestCase , NormalFixture ) : <EOL> normal_count = <NUM_LIT:2> <EOL> def test_update_shared ( self ) : <EOL> NEW_SHARED = '<STR_LIT>' <EOL> n1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> n2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) <EOL> ja1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> ja2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) <EOL> with self . assertNumQueries ( <NUM_LIT:1> if connection . features . update_can_self_select else <NUM_LIT:2> ) : <EOL> Normal . objects . language ( '<STR_LIT>' ) . update ( shared_field = NEW_SHARED ) <EOL> new1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> new2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) <EOL> self . assertEqual ( new1 . shared_field , NEW_SHARED ) <EOL> self . assertEqual ( new1 . translated_field , n1 . translated_field ) <EOL> self . assertEqual ( new2 . shared_field , NEW_SHARED ) <EOL> self . assertEqual ( new2 . translated_field , n2 . translated_field ) <EOL> newja1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> newja2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) <EOL> self . assertEqual ( newja1 . shared_field , NEW_SHARED ) <EOL> self . assertEqual ( newja2 . shared_field , NEW_SHARED ) <EOL> self . assertEqual ( newja1 . translated_field , ja1 . translated_field ) <EOL> self . assertEqual ( newja2 . translated_field , ja2 . translated_field ) <EOL> def test_update_translated ( self ) : <EOL> NEW_TRANSLATED = '<STR_LIT>' <EOL> n1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> n2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) <EOL> ja1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> ja2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) <EOL> with self . assertNumQueries ( <NUM_LIT:1> ) : <EOL> Normal . objects . language ( '<STR_LIT>' ) . update ( translated_field = NEW_TRANSLATED ) <EOL> new1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> new2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) <EOL> self . assertEqual ( new1 . shared_field , n1 . shared_field ) <EOL> self . assertEqual ( new2 . shared_field , n2 . shared_field ) <EOL> self . assertEqual ( new1 . translated_field , NEW_TRANSLATED ) <EOL> self . assertEqual ( new2 . translated_field , NEW_TRANSLATED ) <EOL> newja1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> newja2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) <EOL> self . assertEqual ( newja1 . shared_field , ja1 . shared_field ) <EOL> self . assertEqual ( newja2 . shared_field , ja2 . shared_field ) <EOL> self . assertEqual ( newja1 . translated_field , ja1 . translated_field ) <EOL> self . assertEqual ( newja2 . translated_field , ja2 . translated_field ) <EOL> def test_update_mixed ( self ) : <EOL> NEW_SHARED = '<STR_LIT>' <EOL> NEW_TRANSLATED = '<STR_LIT>' <EOL> ja1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> ja2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) <EOL> with self . assertNumQueries ( <NUM_LIT:2> if connection . features . update_can_self_select else <NUM_LIT:3> ) : <EOL> Normal . objects . language ( '<STR_LIT>' ) . update ( <EOL> shared_field = NEW_SHARED , translated_field = NEW_TRANSLATED <EOL> ) <EOL> new1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> new2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) <EOL> self . assertEqual ( new1 . shared_field , NEW_SHARED ) <EOL> self . assertEqual ( new1 . translated_field , NEW_TRANSLATED ) <EOL> self . assertEqual ( new2 . shared_field , NEW_SHARED ) <EOL> self . assertEqual ( new2 . translated_field , NEW_TRANSLATED ) <EOL> newja1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> newja2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) <EOL> self . assertEqual ( newja1 . shared_field , NEW_SHARED ) <EOL> self . assertEqual ( newja2 . shared_field , NEW_SHARED ) <EOL> self . assertEqual ( newja1 . translated_field , ja1 . translated_field ) <EOL> self . assertEqual ( newja2 . translated_field , ja2 . translated_field ) <EOL> def test_update_deferred_language ( self ) : <EOL> NEW_TRANSLATED = '<STR_LIT>' <EOL> n1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> n2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) <EOL> ja1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> ja2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> qs = Normal . objects . language ( ) <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> with self . assertNumQueries ( <NUM_LIT:1> ) : <EOL> qs . update ( translated_field = NEW_TRANSLATED ) <EOL> new1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> new2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) <EOL> self . assertEqual ( new1 . shared_field , n1 . shared_field ) <EOL> self . assertEqual ( new2 . shared_field , n2 . shared_field ) <EOL> self . assertEqual ( new1 . translated_field , NEW_TRANSLATED ) <EOL> self . assertEqual ( new2 . translated_field , NEW_TRANSLATED ) <EOL> newja1 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:1> ] ) <EOL> newja2 = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = self . normal_id [ <NUM_LIT:2> ] ) <EOL> self . assertEqual ( newja1 . shared_field , ja1 . shared_field ) <EOL> self . assertEqual ( newja2 . shared_field , ja2 . shared_field ) <EOL> self . assertEqual ( newja1 . translated_field , ja1 . translated_field ) <EOL> self . assertEqual ( newja2 . translated_field , ja2 . translated_field ) <EOL> def test_update_fallbacks ( self ) : <EOL> qs = Normal . objects . language ( ) . fallbacks ( ) <EOL> with self . assertNumQueries ( <NUM_LIT:1> if connection . features . update_can_self_select else <NUM_LIT:2> ) : <EOL> qs . filter ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) . update ( shared_field = '<STR_LIT>' ) <EOL> self . assertEqual ( Normal . objects . language ( '<STR_LIT>' ) . get ( shared_field = '<STR_LIT>' ) . pk , self . normal_id [ <NUM_LIT:1> ] ) <EOL> self . assertEqual ( Normal . objects . language ( '<STR_LIT>' ) . get ( shared_field = '<STR_LIT>' ) . pk , self . normal_id [ <NUM_LIT:1> ] ) <EOL> class ValuesListTests ( HvadTestCase , NormalFixture ) : <EOL> normal_count = <NUM_LIT:2> <EOL> def test_values_list_translated ( self ) : <EOL> values = Normal . objects . language ( '<STR_LIT>' ) . values_list ( '<STR_LIT>' , flat = True ) <EOL> values_list = list ( values ) <EOL> self . assertCountEqual ( values_list , [ NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] , <EOL> NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ] ) <EOL> def test_values_list_shared ( self ) : <EOL> values = Normal . objects . language ( '<STR_LIT>' ) . values_list ( '<STR_LIT>' , flat = True ) <EOL> values_list = list ( values ) <EOL> self . assertCountEqual ( values_list , [ NORMAL [ <NUM_LIT:1> ] . shared_field , <EOL> NORMAL [ <NUM_LIT:2> ] . shared_field ] ) <EOL> def test_values_list_mixed ( self ) : <EOL> values = Normal . objects . language ( '<STR_LIT>' ) . values_list ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> values_list = list ( values ) <EOL> check = [ <EOL> ( NORMAL [ <NUM_LIT:1> ] . shared_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) , <EOL> ( NORMAL [ <NUM_LIT:2> ] . shared_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) , <EOL> ] <EOL> self . assertCountEqual ( values_list , check ) <EOL> def test_values_list_deferred_language ( self ) : <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> qs = Normal . objects . language ( ) <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> values = qs . values_list ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> values_list = list ( values ) <EOL> check = [ <EOL> ( NORMAL [ <NUM_LIT:1> ] . shared_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) , <EOL> ( NORMAL [ <NUM_LIT:2> ] . shared_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) , <EOL> ] <EOL> self . assertCountEqual ( values_list , check ) <EOL> def test_values_list_language_all ( self ) : <EOL> values = ( Normal . objects . language ( '<STR_LIT:all>' ) . filter ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> . values_list ( '<STR_LIT>' , '<STR_LIT>' ) ) <EOL> values_list = list ( values ) <EOL> check = [ <EOL> ( NORMAL [ <NUM_LIT:1> ] . shared_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) , <EOL> ( NORMAL [ <NUM_LIT:1> ] . shared_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) , <EOL> ] <EOL> self . assertCountEqual ( values_list , check ) <EOL> class ValuesTests ( HvadTestCase , NormalFixture ) : <EOL> normal_count = <NUM_LIT:2> <EOL> def test_values_shared ( self ) : <EOL> values = Normal . objects . language ( '<STR_LIT>' ) . values ( '<STR_LIT>' ) <EOL> values_list = list ( values ) <EOL> check = [ <EOL> { '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . shared_field } , <EOL> { '<STR_LIT>' : NORMAL [ <NUM_LIT:2> ] . shared_field } , <EOL> ] <EOL> self . assertCountEqual ( values_list , check ) <EOL> def test_values_translated ( self ) : <EOL> values = Normal . objects . language ( '<STR_LIT>' ) . values ( '<STR_LIT>' ) <EOL> values_list = list ( values ) <EOL> check = [ <EOL> { '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] } , <EOL> { '<STR_LIT>' : NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] } , <EOL> ] <EOL> self . assertCountEqual ( values_list , check ) <EOL> def test_values_mixed ( self ) : <EOL> values = Normal . objects . language ( '<STR_LIT>' ) . values ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> values_list = list ( values ) <EOL> check = [ <EOL> { '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . shared_field } , <EOL> { '<STR_LIT>' : NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : NORMAL [ <NUM_LIT:2> ] . shared_field } , <EOL> ] <EOL> self . assertCountEqual ( values_list , check ) <EOL> def test_values_post_language ( self ) : <EOL> values = Normal . objects . language ( ) . values ( '<STR_LIT>' ) . language ( '<STR_LIT>' ) <EOL> values_list = list ( values ) <EOL> check = [ <EOL> { '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . shared_field } , <EOL> { '<STR_LIT>' : NORMAL [ <NUM_LIT:2> ] . shared_field } , <EOL> ] <EOL> self . assertCountEqual ( values_list , check ) <EOL> def test_values_post_filter ( self ) : <EOL> qs = Normal . objects . language ( '<STR_LIT>' ) . values ( '<STR_LIT>' ) <EOL> values = qs . filter ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> values_list = list ( values ) <EOL> check = [ <EOL> { '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . shared_field } , <EOL> ] <EOL> self . assertCountEqual ( values_list , check ) <EOL> def test_values_deferred_language ( self ) : <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> qs = Normal . objects . language ( ) <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> values = qs . values ( '<STR_LIT>' ) <EOL> values_list = list ( values ) <EOL> check = [ <EOL> { '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] } , <EOL> { '<STR_LIT>' : NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] } , <EOL> ] <EOL> self . assertCountEqual ( values_list , check ) <EOL> def test_values_language_all ( self ) : <EOL> values = ( Normal . objects . language ( '<STR_LIT:all>' ) . filter ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> . values ( '<STR_LIT>' , '<STR_LIT>' ) ) <EOL> values_list = list ( values ) <EOL> check = [ <EOL> { '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . shared_field , <EOL> '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] } , <EOL> { '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . shared_field , <EOL> '<STR_LIT>' : NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] } , <EOL> ] <EOL> self . assertCountEqual ( values_list , check ) <EOL> class InBulkTests ( HvadTestCase , NormalFixture ) : <EOL> normal_count = <NUM_LIT:2> <EOL> def test_empty_in_bulk ( self ) : <EOL> with self . assertNumQueries ( <NUM_LIT:0> ) : <EOL> result = Normal . objects . language ( '<STR_LIT>' ) . in_bulk ( [ ] ) <EOL> self . assertEqual ( len ( result ) , <NUM_LIT:0> ) <EOL> def test_in_bulk ( self ) : <EOL> pk1 , pk2 = self . normal_id [ <NUM_LIT:1> ] , self . normal_id [ <NUM_LIT:2> ] <EOL> with self . assertNumQueries ( <NUM_LIT:1> ) : <EOL> result = Normal . objects . language ( '<STR_LIT>' ) . in_bulk ( [ pk1 , pk2 ] ) <EOL> self . assertCountEqual ( ( pk1 , pk2 ) , result ) <EOL> self . assertEqual ( result [ pk1 ] . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> self . assertEqual ( result [ pk1 ] . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> self . assertEqual ( result [ pk1 ] . language_code , '<STR_LIT>' ) <EOL> self . assertEqual ( result [ pk2 ] . shared_field , NORMAL [ <NUM_LIT:2> ] . shared_field ) <EOL> self . assertEqual ( result [ pk2 ] . translated_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) <EOL> self . assertEqual ( result [ pk2 ] . language_code , '<STR_LIT>' ) <EOL> def test_untranslated_in_bulk ( self ) : <EOL> pk1 = self . normal_id [ <NUM_LIT:1> ] <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> with self . assertNumQueries ( <NUM_LIT:2> ) : <EOL> result = Normal . objects . untranslated ( ) . in_bulk ( [ pk1 ] ) <EOL> self . assertCountEqual ( ( pk1 , ) , result ) <EOL> self . assertEqual ( result [ pk1 ] . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> self . assertEqual ( result [ pk1 ] . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> self . assertEqual ( result [ pk1 ] . language_code , '<STR_LIT>' ) <EOL> def test_fallbacks_in_bulk ( self ) : <EOL> ( Normal . objects . language ( '<STR_LIT>' ) <EOL> . filter ( shared_field = NORMAL [ <NUM_LIT:2> ] . shared_field ) <EOL> . delete_translations ( ) ) <EOL> with self . assertNumQueries ( <NUM_LIT:1> ) : <EOL> pk1 , pk2 = self . normal_id [ <NUM_LIT:1> ] , self . normal_id [ <NUM_LIT:2> ] <EOL> result = Normal . objects . language ( '<STR_LIT>' ) . fallbacks ( '<STR_LIT>' , '<STR_LIT>' ) . in_bulk ( [ pk1 , pk2 ] ) <EOL> self . assertCountEqual ( ( pk1 , pk2 ) , result ) <EOL> self . assertEqual ( result [ pk1 ] . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> self . assertEqual ( result [ pk1 ] . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> self . assertEqual ( result [ pk1 ] . language_code , '<STR_LIT>' ) <EOL> self . assertEqual ( result [ pk2 ] . shared_field , NORMAL [ <NUM_LIT:2> ] . shared_field ) <EOL> self . assertEqual ( result [ pk2 ] . translated_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) <EOL> self . assertEqual ( result [ pk2 ] . language_code , '<STR_LIT>' ) <EOL> def test_all_languages_in_bulk ( self ) : <EOL> with self . assertRaises ( ValueError ) : <EOL> Normal . objects . language ( '<STR_LIT:all>' ) . in_bulk ( [ self . normal_id [ <NUM_LIT:1> ] ] ) <EOL> def test_in_bulk_deferred_language ( self ) : <EOL> pk1 = self . normal_id [ <NUM_LIT:1> ] <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> qs = Normal . objects . language ( ) <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> result = qs . in_bulk ( [ pk1 ] ) <EOL> self . assertCountEqual ( ( pk1 , ) , result ) <EOL> self . assertEqual ( result [ pk1 ] . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> self . assertEqual ( result [ pk1 ] . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> self . assertEqual ( result [ pk1 ] . language_code , '<STR_LIT>' ) <EOL> class DeleteTests ( HvadTestCase , NormalFixture ) : <EOL> normal_count = <NUM_LIT:2> <EOL> def test_delete_all ( self ) : <EOL> Normal . objects . all ( ) . delete ( ) <EOL> self . assertEqual ( Normal . objects . count ( ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( Normal . _meta . translations_model . objects . count ( ) , <NUM_LIT:0> ) <EOL> def test_delete_translation ( self ) : <EOL> self . assertEqual ( Normal . _meta . translations_model . objects . count ( ) , <NUM_LIT:4> ) <EOL> Normal . objects . language ( '<STR_LIT>' ) . delete_translations ( ) <EOL> self . assertEqual ( Normal . objects . untranslated ( ) . count ( ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( Normal . _meta . translations_model . objects . count ( ) , <NUM_LIT:2> ) <EOL> Normal . objects . language ( '<STR_LIT>' ) . delete_translations ( ) <EOL> self . assertEqual ( Normal . objects . untranslated ( ) . count ( ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( Normal . _meta . translations_model . objects . count ( ) , <NUM_LIT:0> ) <EOL> def test_filtered_delete_translation ( self ) : <EOL> self . assertEqual ( Normal . _meta . translations_model . objects . count ( ) , <NUM_LIT:4> ) <EOL> ( Normal . objects . language ( '<STR_LIT>' ) <EOL> . filter ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> . delete_translations ( ) ) <EOL> self . assertEqual ( Normal . objects . untranslated ( ) . count ( ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( Normal . _meta . translations_model . objects . count ( ) , <NUM_LIT:3> ) <EOL> ( Normal . objects . language ( '<STR_LIT>' ) <EOL> . filter ( translated_field = NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) <EOL> . delete_translations ( ) ) <EOL> self . assertEqual ( Normal . objects . untranslated ( ) . count ( ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( Normal . _meta . translations_model . objects . count ( ) , <NUM_LIT:2> ) <EOL> def test_delete_translation_deferred_language ( self ) : <EOL> self . assertEqual ( Normal . _meta . translations_model . objects . count ( ) , <NUM_LIT:4> ) <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> qs = Normal . objects . language ( ) <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> qs . delete_translations ( ) <EOL> self . assertEqual ( Normal . objects . language ( '<STR_LIT>' ) . count ( ) , <NUM_LIT:2> ) <EOL> self . assertEqual ( Normal . objects . language ( '<STR_LIT>' ) . count ( ) , <NUM_LIT:0> ) <EOL> def test_delete_fallbacks ( self ) : <EOL> qs = Normal . objects . language ( ) . fallbacks ( ) <EOL> qs . filter ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) . delete ( ) <EOL> self . assertEqual ( Normal . objects . language ( '<STR_LIT>' ) . count ( ) , self . normal_count - <NUM_LIT:1> ) <EOL> self . assertEqual ( Normal . objects . language ( '<STR_LIT>' ) . count ( ) , self . normal_count - <NUM_LIT:1> ) <EOL> class GetTranslationFromInstanceTests ( HvadTestCase , NormalFixture ) : <EOL> normal_count = <NUM_LIT:1> <EOL> def test_simple ( self ) : <EOL> en = Normal . objects . language ( '<STR_LIT>' ) . get ( ) <EOL> ja_trans = en . translations . get_language ( '<STR_LIT>' ) <EOL> ja = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = en . pk ) <EOL> self . assertEqual ( en . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> self . assertEqual ( en . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> self . assertRaises ( AttributeError , getattr , ja_trans , '<STR_LIT>' ) <EOL> self . assertEqual ( ja_trans . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> self . assertEqual ( ja . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> self . assertEqual ( ja . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> def test_cached ( self ) : <EOL> en = Normal . objects . untranslated ( ) . prefetch_related ( '<STR_LIT>' ) . get ( ) <EOL> with self . assertNumQueries ( <NUM_LIT:0> ) : <EOL> ja_trans = en . translations . get_language ( '<STR_LIT>' ) <EOL> ja = Normal . objects . language ( '<STR_LIT>' ) . get ( pk = en . pk ) <EOL> self . assertEqual ( en . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> self . assertEqual ( en . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> self . assertRaises ( AttributeError , getattr , ja_trans , '<STR_LIT>' ) <EOL> self . assertEqual ( ja_trans . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> self . assertEqual ( ja . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> self . assertEqual ( ja . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> def test_not_exist ( self ) : <EOL> en = Normal . objects . untranslated ( ) . get ( ) <EOL> with self . assertRaises ( Normal . DoesNotExist ) : <EOL> en . translations . get_language ( '<STR_LIT>' ) <EOL> en = Normal . objects . untranslated ( ) . prefetch_related ( '<STR_LIT>' ) . get ( ) <EOL> with self . assertRaises ( Normal . DoesNotExist ) : <EOL> en . translations . get_language ( '<STR_LIT>' ) <EOL> class AggregateTests ( HvadTestCase ) : <EOL> def test_aggregate ( self ) : <EOL> from django . db . models import Avg <EOL> AggregateModel . objects . language ( "<STR_LIT>" ) . create ( number = <NUM_LIT:10> , translated_number = <NUM_LIT:20> ) <EOL> AggregateModel . objects . language ( "<STR_LIT>" ) . create ( number = <NUM_LIT:0> , translated_number = <NUM_LIT:0> ) <EOL> self . assertEqual ( AggregateModel . objects . language ( "<STR_LIT>" ) . aggregate ( Avg ( "<STR_LIT>" ) ) , { '<STR_LIT>' : <NUM_LIT:5> } ) <EOL> self . assertEqual ( AggregateModel . objects . language ( "<STR_LIT>" ) . aggregate ( Avg ( "<STR_LIT>" ) ) , { '<STR_LIT>' : <NUM_LIT:10> } ) <EOL> self . assertEqual ( AggregateModel . objects . language ( "<STR_LIT>" ) . aggregate ( num = Avg ( "<STR_LIT>" ) ) , { '<STR_LIT>' : <NUM_LIT:5> } ) <EOL> self . assertEqual ( AggregateModel . objects . language ( "<STR_LIT>" ) . aggregate ( tnum = Avg ( "<STR_LIT>" ) ) , { '<STR_LIT>' : <NUM_LIT:10> } ) <EOL> class AnnotateTests ( HvadTestCase , StandardFixture , NormalFixture ) : <EOL> normal_count = <NUM_LIT:2> <EOL> standard_count = <NUM_LIT:4> <EOL> def test_annotate ( self ) : <EOL> qs = Normal . objects . language ( '<STR_LIT>' ) . annotate ( Count ( '<STR_LIT>' ) ) <EOL> self . assertEqual ( len ( qs ) , self . normal_count ) <EOL> self . assertEqual ( qs [ <NUM_LIT:0> ] . standards__count , <NUM_LIT:2> ) <EOL> self . assertEqual ( qs [ <NUM_LIT:1> ] . standards__count , <NUM_LIT:2> ) <EOL> qs = Normal . objects . language ( '<STR_LIT>' ) . annotate ( foo = Count ( '<STR_LIT>' ) ) <EOL> self . assertEqual ( len ( qs ) , self . normal_count ) <EOL> self . assertEqual ( qs [ <NUM_LIT:0> ] . foo , <NUM_LIT:2> ) <EOL> self . assertEqual ( qs [ <NUM_LIT:1> ] . foo , <NUM_LIT:2> ) <EOL> with self . assertRaises ( ValueError ) : <EOL> qs = Normal . objects . language ( '<STR_LIT>' ) . annotate ( Count ( '<STR_LIT>' ) , standards__count = Count ( '<STR_LIT>' ) ) <EOL> class NotImplementedTests ( HvadTestCase ) : <EOL> def test_notimplemented ( self ) : <EOL> baseqs = SimpleRelated . objects . language ( '<STR_LIT>' ) <EOL> self . assertRaises ( NotImplementedError , baseqs . defer , '<STR_LIT>' ) <EOL> self . assertRaises ( NotImplementedError , baseqs . only ) <EOL> self . assertRaises ( NotImplementedError , baseqs . bulk_create , [ ] ) <EOL> self . assertRaises ( NotImplementedError , baseqs . select_related ) <EOL> if django . VERSION >= ( <NUM_LIT:1> , <NUM_LIT:7> ) : <EOL> self . assertRaises ( NotImplementedError , baseqs . update_or_create ) <EOL> class MinimumVersionTests ( HvadTestCase ) : <EOL> def test_versions ( self ) : <EOL> qs = SimpleRelated . objects . language ( '<STR_LIT>' ) <EOL> if django . VERSION < ( <NUM_LIT:1> , <NUM_LIT:7> ) : <EOL> self . assertRaises ( AttributeError , getattr , qs , '<STR_LIT>' ) <EOL> class ExcludeTests ( HvadTestCase , NormalFixture ) : <EOL> normal_count = <NUM_LIT:1> <EOL> def test_defer ( self ) : <EOL> qs = Normal . objects . language ( '<STR_LIT>' ) . exclude ( translated_field = NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:0> ) <EOL> def test_fallbacks_exclude ( self ) : <EOL> ( Normal . objects . language ( '<STR_LIT>' ) <EOL> . filter ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> . delete_translations ( ) ) <EOL> qs = ( Normal . objects . language ( '<STR_LIT>' ) <EOL> . fallbacks ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> . exclude ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:0> ) <EOL> def test_all_languages_exclude ( self ) : <EOL> qs = Normal . objects . language ( '<STR_LIT:all>' ) . exclude ( translated_field = NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( qs [ <NUM_LIT:0> ] . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> def test_invalid_all_languages_exclude ( self ) : <EOL> with self . assertRaises ( ValueError ) : <EOL> Normal . objects . language ( ) . exclude ( language_code = '<STR_LIT:all>' ) <EOL> class ComplexFilterTests ( HvadTestCase , StandardFixture , NormalFixture ) : <EOL> normal_count = <NUM_LIT:2> <EOL> standard_count = <NUM_LIT:2> <EOL> def test_qobject_filter ( self ) : <EOL> shared_contains_one = Q ( shared_field__contains = '<STR_LIT:1>' ) <EOL> shared_contains_two = Q ( shared_field__contains = '<STR_LIT:2>' ) <EOL> qs = Normal . objects . language ( '<STR_LIT>' ) . filter ( shared_contains_two ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) <EOL> obj = qs [ <NUM_LIT:0> ] <EOL> self . assertEqual ( obj . shared_field , NORMAL [ <NUM_LIT:2> ] . shared_field ) <EOL> self . assertEqual ( obj . translated_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) <EOL> qs = ( Normal . objects . language ( '<STR_LIT>' ) . filter ( Q ( shared_contains_one | shared_contains_two ) ) <EOL> . order_by ( '<STR_LIT>' ) ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:2> ) <EOL> obj = qs [ <NUM_LIT:0> ] <EOL> self . assertEqual ( obj . shared_field , NORMAL [ <NUM_LIT:1> ] . shared_field ) <EOL> self . assertEqual ( obj . translated_field , NORMAL [ <NUM_LIT:1> ] . translated_field [ '<STR_LIT>' ] ) <EOL> obj = qs [ <NUM_LIT:1> ] <EOL> self . assertEqual ( obj . shared_field , NORMAL [ <NUM_LIT:2> ] . shared_field ) <EOL> self . assertEqual ( obj . translated_field , NORMAL [ <NUM_LIT:2> ] . translated_field [ '<STR_LIT>' ] ) <EOL> def test_aware_qobject_filter ( self ) : <EOL> from hvad . utils import get_translation_aware_manager <EOL> manager = get_translation_aware_manager ( Standard ) <EOL> normal_one = Q ( normal_field = STANDARD [ <NUM_LIT:1> ] . normal_field ) <EOL> normal_two = Q ( normal_field = STANDARD [ <NUM_LIT:2> ] . normal_field ) <EOL> shared_one = Q ( normal__shared_field = NORMAL [ STANDARD [ <NUM_LIT:1> ] . normal ] . shared_field ) <EOL> translated_one_en = Q ( normal__translated_field = NORMAL [ STANDARD [ <NUM_LIT:1> ] . normal ] . translated_field [ '<STR_LIT>' ] ) <EOL> translated_two_en = Q ( normal__translated_field = NORMAL [ STANDARD [ <NUM_LIT:2> ] . normal ] . translated_field [ '<STR_LIT>' ] ) <EOL> with translation . override ( '<STR_LIT>' ) : <EOL> qs = manager . filter ( shared_one ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) <EOL> obj = qs [ <NUM_LIT:0> ] <EOL> self . assertEqual ( obj . normal_field , STANDARD [ <NUM_LIT:1> ] . normal_field ) <EOL> qs = manager . filter ( translated_one_en ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) <EOL> obj = qs [ <NUM_LIT:0> ] <EOL> self . assertEqual ( obj . normal_field , STANDARD [ <NUM_LIT:1> ] . normal_field ) <EOL> qs = manager . filter ( Q ( normal_one & shared_one & translated_one_en ) ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) <EOL> obj = qs [ <NUM_LIT:0> ] <EOL> self . assertEqual ( obj . normal_field , STANDARD [ <NUM_LIT:1> ] . normal_field ) <EOL> qs = manager . filter ( Q ( normal_one & translated_two_en ) ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:0> ) <EOL> qs = manager . filter ( Q ( shared_one & translated_two_en ) ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:0> ) <EOL> qs = manager . filter ( Q ( translated_one_en & translated_two_en ) ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:0> ) <EOL> qs = manager . filter ( Q ( normal_one | translated_one_en ) ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) <EOL> qs = manager . filter ( Q ( shared_one | translated_one_en ) ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) <EOL> qs = manager . filter ( Q ( normal_one | translated_two_en ) ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:2> ) <EOL> qs = manager . filter ( Q ( shared_one | translated_two_en ) ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:2> ) <EOL> qs = manager . filter ( Q ( translated_one_en | translated_two_en ) ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:2> ) <EOL> qs = manager . filter ( Q ( normal_one & ( translated_one_en | translated_two_en ) ) ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) <EOL> qs = manager . filter ( Q ( normal_two & ( translated_one_en | translated_two_en ) ) ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) <EOL> qs = manager . filter ( shared_one & ~ translated_one_en ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:0> ) <EOL> qs = manager . filter ( shared_one & ~ translated_two_en ) <EOL> self . assertEqual ( qs . count ( ) , <NUM_LIT:1> ) <EOL> def test_defer ( self ) : <EOL> qs = Normal . objects . language ( '<STR_LIT>' ) . complex_filter ( { } ) <EOL> self . assertEqual ( qs . count ( ) , self . normal_count ) <EOL> self . assertRaises ( NotImplementedError , <EOL> Normal . objects . language ( '<STR_LIT>' ) . complex_filter , <EOL> Q ( shared_field = NORMAL [ <NUM_LIT:1> ] . shared_field ) ) </s>
<s> import json <EOL> import threading <EOL> import sublime <EOL> import sublime_plugin <EOL> import analytics <EOL> import uuid <EOL> from elasticsearch import Elasticsearch <EOL> from elasticsearch_connections import CustomHeadersConnection <EOL> from abc import ABCMeta , abstractmethod <EOL> from . . panel import IndexListPanel <EOL> from . . panel import DocTypeListPanel <EOL> from . . panel import SwitchServerListPanel <EOL> from . . panel import AnalyzerListPanel <EOL> from . . panel import ScriptListPanel <EOL> from . . panel import SearchTemplateListPanel <EOL> from . . panel import AliasListPanel <EOL> from . . panel import IndexTemplateListPanel <EOL> from . . panel import WarmerListPanel <EOL> from . . panel import FieldListPanel <EOL> from . . panel import RepositoryListPanel <EOL> from . . panel import SnapshotListPanel <EOL> ANALYTICS_WRITE_KEY = "<STR_LIT>" <EOL> def track_command ( user_id , command_name ) : <EOL> analytics . write_key = ANALYTICS_WRITE_KEY <EOL> analytics . identify ( user_id ) <EOL> analytics . track ( user_id , "<STR_LIT>" , { <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT:label>" : command_name , <EOL> } ) <EOL> def track_activate ( user_id ) : <EOL> analytics . write_key = ANALYTICS_WRITE_KEY <EOL> analytics . identify ( user_id ) <EOL> analytics . track ( user_id , "<STR_LIT>" , { <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT:label>" : sublime . platform ( ) , <EOL> } ) <EOL> class Settings ( object ) : <EOL> SETTINGS_FILE = '<STR_LIT>' <EOL> def __init__ ( self ) : <EOL> self . settings = sublime . load_settings ( self . SETTINGS_FILE ) <EOL> @ property <EOL> def base_url ( self ) : <EOL> base_url = self . settings . get ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> if base_url . endswith ( "<STR_LIT:/>" ) : <EOL> return base_url [ : - <NUM_LIT:1> ] <EOL> return base_url <EOL> @ property <EOL> def index ( self ) : <EOL> return self . settings . get ( "<STR_LIT:index>" , "<STR_LIT>" ) <EOL> @ property <EOL> def doc_type ( self ) : <EOL> return self . settings . get ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> @ property <EOL> def scroll_size ( self ) : <EOL> return self . settings . get ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> @ property <EOL> def headers ( self ) : <EOL> return self . settings . get ( "<STR_LIT>" , { } ) <EOL> @ property <EOL> def servers ( self ) : <EOL> def _normalize_servers ( servers ) : <EOL> items = [ ] <EOL> for name , server in servers . items ( ) : <EOL> server [ "<STR_LIT:name>" ] = name <EOL> items . append ( server ) <EOL> servers = sorted ( items , key = lambda k : k [ "<STR_LIT:name>" ] ) <EOL> return servers <EOL> servers = self . settings . get ( "<STR_LIT>" , [ ] ) <EOL> if isinstance ( servers , dict ) : <EOL> servers = _normalize_servers ( servers ) <EOL> return servers <EOL> @ property <EOL> def active_server ( self ) : <EOL> return dict ( <EOL> base_url = self . base_url , <EOL> index = self . index , <EOL> doc_type = self . doc_type , <EOL> scroll_size = self . scroll_size , <EOL> ) <EOL> @ property <EOL> def ab_command ( self ) : <EOL> return self . settings . get ( "<STR_LIT>" ) <EOL> @ property <EOL> def ab_requests ( self ) : <EOL> return str ( self . settings . get ( "<STR_LIT>" ) ) <EOL> @ property <EOL> def ab_concurrency ( self ) : <EOL> return str ( self . settings . get ( "<STR_LIT>" ) ) <EOL> @ property <EOL> def analytics ( self ) : <EOL> return self . settings . get ( "<STR_LIT>" , True ) <EOL> @ property <EOL> def user_id ( self ) : <EOL> return self . settings . get ( "<STR_LIT>" , None ) <EOL> @ property <EOL> def dump_file ( self ) : <EOL> return self . settings . get ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> @ property <EOL> def chunk_size ( self ) : <EOL> return self . settings . get ( "<STR_LIT>" , <NUM_LIT> ) <EOL> def set ( self , key , value ) : <EOL> self . settings . set ( key , value ) <EOL> def save ( self ) : <EOL> sublime . save_settings ( self . SETTINGS_FILE ) <EOL> class BaseCommand ( sublime_plugin . WindowCommand ) : <EOL> __metaclass__ = ABCMeta <EOL> command_name = None <EOL> def __init__ ( self , * args , ** kwargs ) : <EOL> self . settings = Settings ( ) <EOL> sublime_plugin . WindowCommand . __init__ ( self , * args , ** kwargs ) <EOL> @ property <EOL> def view ( self ) : <EOL> return self . window . active_view ( ) <EOL> def is_valid_json ( self ) : <EOL> try : <EOL> json . loads ( self . get_text ( ) ) <EOL> except ValueError : <EOL> return False <EOL> return True <EOL> def is_enabled ( self ) : <EOL> return self . is_valid_json ( ) <EOL> def get_text ( self ) : <EOL> return self . view . substr ( sublime . Region ( <NUM_LIT:0> , self . view . size ( ) ) ) <EOL> def init_client ( self ) : <EOL> self . _client = Elasticsearch ( <EOL> self . settings . base_url , <EOL> send_get_body_as = '<STR_LIT:POST>' , <EOL> connection_class = CustomHeadersConnection , <EOL> headers = self . settings . headers <EOL> ) <EOL> return self . _client <EOL> def save_settings ( self ) : <EOL> self . settings . save ( ) <EOL> self . init_client ( ) <EOL> @ property <EOL> def client ( self ) : <EOL> return self . init_client ( ) <EOL> def track_command ( self ) : <EOL> if self . settings . analytics : <EOL> user_id = self . settings . user_id <EOL> if not user_id : <EOL> user_id = str ( uuid . uuid4 ( ) ) <EOL> self . settings . set ( "<STR_LIT>" , user_id ) <EOL> self . settings . save ( ) <EOL> track_activate ( user_id ) <EOL> track_command ( user_id , self . command_name ) <EOL> def show_input_panel ( self , label , default , callback ) : <EOL> self . window . show_input_panel ( label , default , callback , None , None ) <EOL> def show_response ( self , response , title = "<STR_LIT>" ) : <EOL> title = title or self . command_name <EOL> text = json . dumps ( response , indent = <NUM_LIT:2> , ensure_ascii = False ) <EOL> self . window . run_command ( <EOL> "<STR_LIT>" , { "<STR_LIT:title>" : title , "<STR_LIT:text>" : text } ) <EOL> def show_index_list_panel ( self , callback ) : <EOL> list_panel = IndexListPanel ( <EOL> self . window , self . client , self . settings . index ) <EOL> list_panel . show ( callback ) <EOL> def show_doc_type_list_panel ( self , callback ) : <EOL> list_panel = DocTypeListPanel ( <EOL> self . window , self . client , self . settings . index ) <EOL> list_panel . show ( callback ) <EOL> def show_analyzer_list_panel ( self , callback ) : <EOL> list_panel = AnalyzerListPanel ( <EOL> self . window , self . client , self . settings . index ) <EOL> list_panel . show ( callback ) <EOL> def show_switch_server_list_panel ( self , callback ) : <EOL> list_panel = SwitchServerListPanel ( self . window , self . settings . servers ) <EOL> list_panel . show ( callback ) <EOL> def show_script_list_panel ( self , callback ) : <EOL> list_panel = ScriptListPanel ( self . window , self . client ) <EOL> list_panel . show ( callback ) <EOL> def show_search_template_list_panel ( self , callback ) : <EOL> list_panel = SearchTemplateListPanel ( self . window , self . client ) <EOL> list_panel . show ( callback ) <EOL> def show_alias_list_panel ( self , callback ) : <EOL> list_panel = AliasListPanel ( <EOL> self . window , self . client , self . settings . index ) <EOL> list_panel . show ( callback ) <EOL> def show_index_template_list_panel ( self , callback ) : <EOL> list_panel = IndexTemplateListPanel ( self . window , self . client ) <EOL> list_panel . show ( callback ) <EOL> def show_warmer_list_panel ( self , callback ) : <EOL> list_panel = WarmerListPanel ( <EOL> self . window , self . client , self . settings . index ) <EOL> list_panel . show ( callback ) <EOL> def show_field_list_panel ( self , callback ) : <EOL> list_panel = FieldListPanel ( <EOL> self . window , self . client , <EOL> self . settings . index , self . settings . doc_type ) <EOL> list_panel . show ( callback ) <EOL> def show_repository_list_panel ( self , callback ) : <EOL> list_panel = RepositoryListPanel ( self . window , self . client ) <EOL> list_panel . show ( callback ) <EOL> def show_snapshot_list_panel ( self , repository , callback ) : <EOL> list_panel = SnapshotListPanel ( self . window , self . client , repository ) <EOL> list_panel . show ( callback ) <EOL> def show_output_panel ( self , text , syntax = None ) : <EOL> self . window . run_command ( <EOL> "<STR_LIT>" , { "<STR_LIT:text>" : text , "<STR_LIT>" : syntax } ) <EOL> def show_object_output_panel ( self , obj ) : <EOL> options = dict ( <EOL> indent = <NUM_LIT:4> , <EOL> ensure_ascii = False <EOL> ) <EOL> self . show_output_panel ( <EOL> json . dumps ( obj , ** options ) , <EOL> syntax = "<STR_LIT>" ) <EOL> def show_active_server ( self ) : <EOL> self . window . run_command ( "<STR_LIT>" ) <EOL> @ abstractmethod <EOL> def run_request ( self , * args , ** kwargs ) : <EOL> raise NotImplementedError ( ) <EOL> def run_request_wrapper ( self , * args , ** kwargs ) : <EOL> try : <EOL> response = self . run_request ( * args , ** kwargs ) <EOL> except Exception as e : <EOL> sublime . error_message ( "<STR_LIT>" . format ( e ) ) <EOL> return <EOL> if response is not None : <EOL> self . show_response ( response ) <EOL> self . track_command ( ) <EOL> def request_thread ( self , * args , ** kwargs ) : <EOL> thread = threading . Thread ( <EOL> target = self . run_request_wrapper , args = args , kwargs = kwargs ) <EOL> thread . start ( ) <EOL> def run ( self , * args , ** kwargs ) : <EOL> self . request_thread ( * args , ** kwargs ) <EOL> class CreateBaseCommand ( BaseCommand ) : <EOL> def run_request_wrapper ( self , * args , ** kwargs ) : <EOL> try : <EOL> response = self . run_request ( * args , ** kwargs ) <EOL> except Exception as e : <EOL> sublime . error_message ( "<STR_LIT>" . format ( e ) ) <EOL> return <EOL> if response is not None : <EOL> self . show_object_output_panel ( response ) <EOL> self . track_command ( ) <EOL> class DeleteBaseCommand ( CreateBaseCommand ) : <EOL> pass <EOL> class CatBaseCommand ( CreateBaseCommand ) : <EOL> def is_enabled ( self ) : <EOL> return True <EOL> def run_request_wrapper ( self , * args , ** kwargs ) : <EOL> try : <EOL> response = self . run_request ( * args , ** kwargs ) <EOL> except Exception as e : <EOL> sublime . error_message ( "<STR_LIT>" . format ( e ) ) <EOL> return <EOL> if response is not None : <EOL> self . show_output_panel ( response ) <EOL> self . track_command ( ) <EOL> class SearchBaseCommand ( BaseCommand ) : <EOL> def extend_options ( self , options , search_type = None ) : <EOL> if search_type : <EOL> self . command_name = "<STR_LIT>" . format ( <EOL> base = self . command_name , <EOL> search_type = search_type . lower ( ) <EOL> ) <EOL> if search_type == "<STR_LIT>" : <EOL> options [ "<STR_LIT>" ] = dict ( <EOL> search_type = search_type , <EOL> scroll = self . settings . scroll_size <EOL> ) <EOL> elif search_type is not None : <EOL> options [ "<STR_LIT>" ] = dict ( <EOL> search_type = search_type <EOL> ) <EOL> return options <EOL> class SettingsBaseCommand ( BaseCommand ) : <EOL> def is_enabled ( self ) : <EOL> return True </s>
<s> import sublime <EOL> from . base import DeleteBaseCommand <EOL> class DeleteDocumentCommand ( DeleteBaseCommand ) : <EOL> command_name = "<STR_LIT>" <EOL> def is_enabled ( self ) : <EOL> return True <EOL> def run_request ( self , id = None ) : <EOL> if not id : <EOL> self . show_input_panel ( '<STR_LIT>' , '<STR_LIT>' , self . run ) <EOL> return <EOL> options = dict ( <EOL> index = self . settings . index , <EOL> doc_type = self . settings . doc_type , <EOL> id = id <EOL> ) <EOL> if sublime . ok_cancel_dialog ( "<STR_LIT>" , ok_title = '<STR_LIT>' ) : <EOL> return self . client . delete ( ** options ) </s>
<s> import sublime <EOL> from . base import DeleteBaseCommand <EOL> class IndicesDeleteAliasCommand ( DeleteBaseCommand ) : <EOL> command_name = "<STR_LIT>" <EOL> def is_enabled ( self ) : <EOL> return True <EOL> def run_request ( self , index = None , name = None ) : <EOL> if not index or not name : <EOL> self . show_alias_list_panel ( self . run ) <EOL> return <EOL> options = dict ( <EOL> index = index , <EOL> name = name <EOL> ) <EOL> if sublime . ok_cancel_dialog ( "<STR_LIT>" , ok_title = '<STR_LIT>' ) : <EOL> return self . client . indices . delete_alias ( ** options ) </s>
<s> from . base import BaseCommand <EOL> class IndicesStatsCommand ( BaseCommand ) : <EOL> command_name = "<STR_LIT>" <EOL> def is_enabled ( self ) : <EOL> return True <EOL> def run_request ( self , index = None ) : <EOL> if index is None : <EOL> self . show_index_list_panel ( self . run ) <EOL> return <EOL> options = dict ( <EOL> index = index , <EOL> params = dict ( human = True ) <EOL> ) <EOL> return self . client . indices . stats ( ** options ) </s>
<s> import sublime_plugin <EOL> class ShowOutputPanelCommand ( sublime_plugin . WindowCommand ) : <EOL> default_syntax = "<STR_LIT>" <EOL> def run ( self , text , syntax = None ) : <EOL> if syntax is None : <EOL> syntax = self . default_syntax <EOL> panel = self . window . create_output_panel ( "<STR_LIT>" ) <EOL> self . window . run_command ( <EOL> "<STR_LIT>" , { "<STR_LIT>" : "<STR_LIT>" } ) <EOL> panel . set_syntax_file ( syntax ) <EOL> panel . settings ( ) . set ( '<STR_LIT>' , True ) <EOL> panel . settings ( ) . set ( '<STR_LIT>' , False ) <EOL> panel . set_read_only ( False ) <EOL> panel . run_command ( '<STR_LIT>' , { '<STR_LIT>' : text } ) <EOL> panel . set_read_only ( True ) </s>
<s> """<STR_LIT>""" <EOL> import datetime <EOL> __all__ = [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] <EOL> EASTER_JULIAN = <NUM_LIT:1> <EOL> EASTER_ORTHODOX = <NUM_LIT:2> <EOL> EASTER_WESTERN = <NUM_LIT:3> <EOL> def easter ( year , method = EASTER_WESTERN ) : <EOL> """<STR_LIT>""" <EOL> if not ( <NUM_LIT:1> <= method <= <NUM_LIT:3> ) : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> y = year <EOL> g = y % <NUM_LIT> <EOL> e = <NUM_LIT:0> <EOL> if method < <NUM_LIT:3> : <EOL> i = ( <NUM_LIT> * g + <NUM_LIT:15> ) % <NUM_LIT:30> <EOL> j = ( y + y // <NUM_LIT:4> + i ) % <NUM_LIT:7> <EOL> if method == <NUM_LIT:2> : <EOL> e = <NUM_LIT:10> <EOL> if y > <NUM_LIT> : <EOL> e = e + y // <NUM_LIT:100> - <NUM_LIT:16> - ( y // <NUM_LIT:100> - <NUM_LIT:16> ) // <NUM_LIT:4> <EOL> else : <EOL> c = y // <NUM_LIT:100> <EOL> h = ( c - c // <NUM_LIT:4> - ( <NUM_LIT:8> * c + <NUM_LIT> ) // <NUM_LIT> + <NUM_LIT> * g + <NUM_LIT:15> ) % <NUM_LIT:30> <EOL> i = h - ( h // <NUM_LIT> ) * ( <NUM_LIT:1> - ( h // <NUM_LIT> ) * ( <NUM_LIT> // ( h + <NUM_LIT:1> ) ) * ( ( <NUM_LIT> - g ) // <NUM_LIT:11> ) ) <EOL> j = ( y + y // <NUM_LIT:4> + i + <NUM_LIT:2> - c + c // <NUM_LIT:4> ) % <NUM_LIT:7> <EOL> p = i - j + e <EOL> d = <NUM_LIT:1> + ( p + <NUM_LIT> + ( p + <NUM_LIT:6> ) // <NUM_LIT> ) % <NUM_LIT> <EOL> m = <NUM_LIT:3> + ( p + <NUM_LIT> ) // <NUM_LIT:30> <EOL> return datetime . date ( int ( y ) , int ( m ) , int ( d ) ) </s>
<s> __all__ = [ <EOL> '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' <EOL> ] <EOL> class ImproperlyConfigured ( Exception ) : <EOL> """<STR_LIT>""" <EOL> class ElasticsearchException ( Exception ) : <EOL> """<STR_LIT>""" <EOL> class SerializationError ( ElasticsearchException ) : <EOL> """<STR_LIT>""" <EOL> class TransportError ( ElasticsearchException ) : <EOL> """<STR_LIT>""" <EOL> @ property <EOL> def status_code ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . args [ <NUM_LIT:0> ] <EOL> @ property <EOL> def error ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . args [ <NUM_LIT:1> ] <EOL> @ property <EOL> def info ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . args [ <NUM_LIT:2> ] <EOL> def __str__ ( self ) : <EOL> return '<STR_LIT>' % ( self . status_code , self . error ) <EOL> class ConnectionError ( TransportError ) : <EOL> """<STR_LIT>""" <EOL> def __str__ ( self ) : <EOL> return '<STR_LIT>' % ( <EOL> self . error , self . info . __class__ . __name__ , self . info ) <EOL> class SSLError ( ConnectionError ) : <EOL> """<STR_LIT>""" <EOL> class ConnectionTimeout ( ConnectionError ) : <EOL> """<STR_LIT>""" <EOL> def __str__ ( self ) : <EOL> return '<STR_LIT>' % ( <EOL> self . info . __class__ . __name__ , self . info ) <EOL> class NotFoundError ( TransportError ) : <EOL> """<STR_LIT>""" <EOL> class ConflictError ( TransportError ) : <EOL> """<STR_LIT>""" <EOL> class RequestError ( TransportError ) : <EOL> """<STR_LIT>""" <EOL> class AuthenticationException ( TransportError ) : <EOL> """<STR_LIT>""" <EOL> class AuthorizationException ( TransportError ) : <EOL> """<STR_LIT>""" <EOL> HTTP_EXCEPTIONS = { <EOL> <NUM_LIT> : RequestError , <EOL> <NUM_LIT> : AuthenticationException , <EOL> <NUM_LIT> : AuthorizationException , <EOL> <NUM_LIT> : NotFoundError , <EOL> <NUM_LIT> : ConflictError , <EOL> } </s>
<s> from . alias_list_panel import AliasListPanel <EOL> from . analyzer_list_panel import AnalyzerListPanel <EOL> from . doc_type_list_panel import DocTypeListPanel <EOL> from . field_list_panel import FieldListPanel <EOL> from . index_list_panel import IndexListPanel <EOL> from . index_template_list_panel import IndexTemplateListPanel <EOL> from . repository_list_panel import RepositoryListPanel <EOL> from . script_list_panel import ScriptListPanel <EOL> from . search_template_list_panel import SearchTemplateListPanel <EOL> from . snapshot_list_panel import SnapshotListPanel <EOL> from . switch_server_list_panel import SwitchServerListPanel <EOL> from . warmer_list_panel import WarmerListPanel <EOL> __all__ = [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ] </s>
<s> import unittest <EOL> from test . asserting . policy import PolicyAssertion , get_fixture_path <EOL> from vint . linting . level import Level <EOL> from vint . linting . policy . prohibit_command_with_unintended_side_effect import ProhibitCommandWithUnintendedSideEffect <EOL> PATH_VALID_VIM_SCRIPT = get_fixture_path ( '<STR_LIT>' ) <EOL> PATH_INVALID_VIM_SCRIPT = get_fixture_path ( '<STR_LIT>' ) <EOL> class TestProhibitCommandWithUnintendedSideEffect ( PolicyAssertion , unittest . TestCase ) : <EOL> def _create_violation_by_line_number ( self , line_number ) : <EOL> return { <EOL> '<STR_LIT:name>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : Level . WARNING , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : line_number , <EOL> '<STR_LIT>' : <NUM_LIT:1> , <EOL> '<STR_LIT:path>' : PATH_INVALID_VIM_SCRIPT <EOL> } <EOL> } <EOL> def test_get_violation_if_found_with_valid_file ( self ) : <EOL> self . assertFoundNoViolations ( PATH_VALID_VIM_SCRIPT , <EOL> ProhibitCommandWithUnintendedSideEffect ) <EOL> def test_get_violation_if_found_with_invalid_file ( self ) : <EOL> expected_violations = [ self . _create_violation_by_line_number ( line_number ) <EOL> for line_number in range ( <NUM_LIT:1> , <NUM_LIT> ) ] <EOL> expected_violations [ <NUM_LIT:3> ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] = <NUM_LIT:2> <EOL> expected_violations [ <NUM_LIT:4> ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] = <NUM_LIT:6> <EOL> self . assertFoundViolationsEqual ( PATH_INVALID_VIM_SCRIPT , <EOL> ProhibitCommandWithUnintendedSideEffect , <EOL> expected_violations ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> unittest . main ( ) </s>
<s> import unittest <EOL> from test . asserting . config_source import ConfigSourceAssertion <EOL> from test . asserting . config_source import get_fixture_path <EOL> from vint . linting . config . config_file_source import ConfigFileSource <EOL> from vint . linting . level import Level <EOL> FIXTURE_CONFIG_FILE = get_fixture_path ( '<STR_LIT>' ) <EOL> class TestConfigFileSource ( ConfigSourceAssertion , unittest . TestCase ) : <EOL> class ConcreteConfigFileSource ( ConfigFileSource ) : <EOL> def get_file_path ( self , env ) : <EOL> return FIXTURE_CONFIG_FILE <EOL> def test_get_config_dict ( self ) : <EOL> expected_config_dict = { <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : True , <EOL> '<STR_LIT>' : Level . WARNING , <EOL> '<STR_LIT>' : <NUM_LIT:10> , <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : False , <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : True , <EOL> } , <EOL> } <EOL> } <EOL> config_source = self . initialize_config_source_with_env ( <EOL> TestConfigFileSource . ConcreteConfigFileSource ) <EOL> self . assertConfigDict ( config_source , expected_config_dict ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> unittest . main ( ) </s>
<s> from vint . ast . plugin . scope_plugin . scope_detector import ( <EOL> detect_scope_visibility , <EOL> normalize_variable_name , <EOL> is_builtin_variable , <EOL> ) <EOL> from vint . ast . plugin . scope_plugin . scope_linker import ScopeLinker <EOL> from vint . ast . plugin . scope_plugin . identifier_classifier import ( <EOL> IdentifierClassifier , <EOL> is_function_identifier , <EOL> ) <EOL> REACHABILITY_FLAG = '<STR_LIT>' <EOL> REFERECED_FLAG = '<STR_LIT>' <EOL> class ReferenceReachabilityTester ( object ) : <EOL> """<STR_LIT>""" <EOL> class TwoWayScopeReferenceAttacher ( object ) : <EOL> """<STR_LIT>""" <EOL> @ classmethod <EOL> def attach ( cls , root_scope_tree ) : <EOL> root_scope_tree [ '<STR_LIT>' ] = None <EOL> return cls . _attach_recursively ( root_scope_tree ) <EOL> @ classmethod <EOL> def _attach_recursively ( cls , scope_tree ) : <EOL> for child_scope in scope_tree [ '<STR_LIT>' ] : <EOL> child_scope [ '<STR_LIT>' ] = scope_tree <EOL> cls . _attach_recursively ( child_scope ) <EOL> return scope_tree <EOL> def process ( self , ast ) : <EOL> scope_linker = ScopeLinker ( ) <EOL> scope_linker . process ( ast ) <EOL> id_collector = IdentifierClassifier . IdentifierCollector ( ) <EOL> classified_id_group = id_collector . collect_identifiers ( ast ) <EOL> dec_id_nodes = classified_id_group [ '<STR_LIT>' ] <EOL> ref_id_nodes = classified_id_group [ '<STR_LIT>' ] <EOL> self . _scope_tree = scope_linker . scope_tree <EOL> self . _link_registry = scope_linker . link_registry <EOL> ReferenceReachabilityTester . TwoWayScopeReferenceAttacher . attach ( self . _scope_tree ) <EOL> for dec_id_node in dec_id_nodes : <EOL> dec_id_node [ REFERECED_FLAG ] = False <EOL> for ref_id_node in ref_id_nodes : <EOL> is_reachable = self . check_reachability ( ref_id_node ) <EOL> ref_id_node [ REACHABILITY_FLAG ] = is_reachable <EOL> def get_objective_scope_visibility ( self , node ) : <EOL> """<STR_LIT>""" <EOL> context_scope = self . _link_registry . get_scope_by_referencing_identifier ( node ) <EOL> return detect_scope_visibility ( node , context_scope ) [ '<STR_LIT>' ] <EOL> def _reset_referenced_flag ( self , scope_tree ) : <EOL> for child_scope in scope_tree [ '<STR_LIT>' ] : <EOL> for functions in child_scope [ '<STR_LIT>' ] . values ( ) : <EOL> for function in functions : <EOL> function [ REFERECED_FLAG ] = False <EOL> for variables in child_scope [ '<STR_LIT>' ] . values ( ) : <EOL> for variable in variables : <EOL> variable [ REFERECED_FLAG ] = False <EOL> self . _reset_referenced_flag ( child_scope ) <EOL> def check_reachability ( self , ref_id_node ) : <EOL> scope = self . _link_registry . get_context_scope_by_identifier ( ref_id_node ) <EOL> var_name = normalize_variable_name ( ref_id_node , scope ) <EOL> is_func_id = is_function_identifier ( ref_id_node ) <EOL> while scope is not None : <EOL> if is_func_id : <EOL> functions_list = scope [ '<STR_LIT>' ] <EOL> if var_name in functions_list : <EOL> for variable in functions_list [ var_name ] : <EOL> declaring_id_node = self . _link_registry . get_declarative_identifier_by_variable ( variable ) <EOL> declaring_id_node [ REFERECED_FLAG ] = True <EOL> return True <EOL> else : <EOL> pass <EOL> variables_list = scope [ '<STR_LIT>' ] <EOL> if var_name in variables_list : <EOL> for variable in variables_list [ var_name ] : <EOL> declaring_id_node = self . _link_registry . get_declarative_identifier_by_variable ( variable ) <EOL> declaring_id_node [ REFERECED_FLAG ] = True <EOL> return True <EOL> scope = scope [ '<STR_LIT>' ] <EOL> return is_builtin_variable ( ref_id_node ) <EOL> def is_reference_identifier ( node ) : <EOL> return REACHABILITY_FLAG in node <EOL> def is_reachable_reference_identifier ( node ) : <EOL> return node . get ( REACHABILITY_FLAG , False ) <EOL> def is_declarative_identifier ( node ) : <EOL> return REFERECED_FLAG in node <EOL> def is_referenced_declarative_identifier ( node ) : <EOL> return node . get ( REFERECED_FLAG , False ) </s>
<s> import re <EOL> from vint . ast . node_type import NodeType <EOL> from vint . linting . level import Level <EOL> from vint . linting . policy . abstract_policy import AbstractPolicy <EOL> from vint . linting . policy_registry import register_policy <EOL> from vint . ast . dictionary . abbreviations import ( <EOL> Abbreviations , <EOL> AbbreviationsIncludingInvertPrefix , <EOL> ) <EOL> SetCommandFamily = { <EOL> '<STR_LIT>' : True , <EOL> '<STR_LIT>' : True , <EOL> '<STR_LIT>' : True , <EOL> } <EOL> @ register_policy <EOL> class ProhibitAbbreviationOption ( AbstractPolicy ) : <EOL> def __init__ ( self ) : <EOL> super ( ProhibitAbbreviationOption , self ) . __init__ ( ) <EOL> self . description = '<STR_LIT>' <EOL> self . reference = '<STR_LIT>' <EOL> self . level = Level . STYLE_PROBLEM <EOL> self . was_scriptencoding_found = False <EOL> self . has_encoding_opt_after_scriptencoding = False <EOL> def listen_node_types ( self ) : <EOL> return [ NodeType . EXCMD , NodeType . OPTION ] <EOL> def is_valid ( self , node , lint_context ) : <EOL> """<STR_LIT>""" <EOL> node_type = NodeType ( node [ '<STR_LIT:type>' ] ) <EOL> if node_type is NodeType . OPTION : <EOL> option_name = node [ '<STR_LIT:value>' ] [ <NUM_LIT:1> : ] <EOL> is_valid = option_name not in Abbreviations <EOL> if not is_valid : <EOL> self . _make_description_by_option_name ( option_name ) <EOL> return is_valid <EOL> excmd_node = node <EOL> is_set_cmd = excmd_node [ '<STR_LIT>' ] [ '<STR_LIT>' ] . get ( '<STR_LIT:name>' ) in SetCommandFamily <EOL> if not is_set_cmd : <EOL> return True <EOL> option_expr = excmd_node [ '<STR_LIT:str>' ] . split ( ) [ <NUM_LIT:1> ] <EOL> option_name = re . match ( r'<STR_LIT>' , option_expr ) . group ( <NUM_LIT:0> ) <EOL> is_valid = option_name not in AbbreviationsIncludingInvertPrefix <EOL> if not is_valid : <EOL> self . _make_description_by_option_name ( option_name ) <EOL> return is_valid <EOL> def _make_description_by_option_name ( self , option_name ) : <EOL> param = { <EOL> '<STR_LIT>' : AbbreviationsIncludingInvertPrefix [ option_name ] , <EOL> '<STR_LIT>' : option_name , <EOL> } <EOL> self . description = ( '<STR_LIT>' <EOL> '<STR_LIT>' . format ( ** param ) ) </s>
<s> from serfclient import result <EOL> class TestSerfResult ( object ) : <EOL> def test_initialises_to_none ( self ) : <EOL> r = result . SerfResult ( ) <EOL> assert r . head is None <EOL> assert r . body is None <EOL> def test_provides_a_pretty_printed_form_for_repl_use ( self ) : <EOL> r = result . SerfResult ( head = { "<STR_LIT:a>" : <NUM_LIT:1> } , body = ( '<STR_LIT:foo>' , '<STR_LIT:bar>' ) ) <EOL> assert str ( r ) == "<STR_LIT>" <EOL> def test_can_convert_to_list ( self ) : <EOL> r = result . SerfResult ( head = <NUM_LIT:1> , body = <NUM_LIT:2> ) <EOL> assert sorted ( list ( r ) ) == [ <NUM_LIT:1> , <NUM_LIT:2> ] <EOL> def test_can_convert_to_tuple ( self ) : <EOL> r = result . SerfResult ( head = <NUM_LIT:1> , body = <NUM_LIT:2> ) <EOL> assert sorted ( tuple ( r ) ) == [ <NUM_LIT:1> , <NUM_LIT:2> ] </s>
<s> import os <EOL> import logging <EOL> class AttrDict ( dict ) : <EOL> """<STR_LIT>""" <EOL> def __getattr__ ( self , name ) : <EOL> if name in self : <EOL> return self [ name ] <EOL> raise AttributeError ( '<STR_LIT>' % name ) <EOL> def __setattr__ ( self , name , val ) : <EOL> self [ name ] = val <EOL> def get_logger ( name , level = None ) : <EOL> """<STR_LIT>""" <EOL> logger = logging . getLogger ( name ) <EOL> if not logger . handlers : <EOL> stderr = logging . StreamHandler ( ) <EOL> stderr . setFormatter ( logging . Formatter ( <EOL> '<STR_LIT>' ) ) <EOL> logger . addHandler ( stderr ) <EOL> level = level if level else os . environ . get ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> logger . setLevel ( getattr ( logging , level ) ) <EOL> return logger </s>
<s> from hacksport . problem import Challenge <EOL> class Problem ( Challenge ) : <EOL> def setup ( self ) : <EOL> self . flag = '<STR_LIT>' </s>
<s> """<STR_LIT>""" <EOL> from math import * <EOL> def AirDensity ( RH , Tc , P = <NUM_LIT> ) : <EOL> Rd = <NUM_LIT> <EOL> q = <NUM_LIT> * ( RH * SatVapor ( Tc ) ) / P <EOL> Tv = ( Tc + <NUM_LIT> ) * ( <NUM_LIT:1.0> + <NUM_LIT> * q ) <EOL> P *= <NUM_LIT> <EOL> rho_a = P / ( Rd * Tv ) <EOL> return rho_a <EOL> def PsychConst ( P , cP = <NUM_LIT> , lambda_v = <NUM_LIT> ) : <EOL> gamma = ( cP * P / ( <NUM_LIT> * lambda_v ) ) <EOL> return gamma <EOL> def SatVaporPress ( Tc ) : <EOL> eSat = <NUM_LIT> * exp ( <NUM_LIT> * Tc / ( <NUM_LIT> + Tc ) ) <EOL> return eSat <EOL> def SlopeSatVaporPress ( Tc ) : <EOL> delta = <NUM_LIT> * SatVaporPress ( Tc ) / ( <NUM_LIT> + Tc ) ** <NUM_LIT:2> <EOL> return delta <EOL> def AeroReist ( um , zm , z0 , d , zmp = zm ) : <EOL> k = <NUM_LIT> <EOL> r_a = <NUM_LIT:1.0> / ( k ** <NUM_LIT:2> * um ) * log ( ( zm - d ) / z0 ) * log ( ( zmp - d ) / ( z0 / <NUM_LIT> ) ) <EOL> return r_a <EOL> def SurfResist ( g0 , S , D , Tc , SM , SM0 ) : <EOL> g_c = Gee_C ( ) <EOL> g_R = Gee_R ( S ) <EOL> g_D = Gee_D ( D ) <EOL> g_T = Gee_T ( Tc + <NUM_LIT> ) <EOL> g_M = Gee_M ( SM , SM0 ) <EOL> g_s = g0 * g_c * g_R * g_D * g_T * g_M <EOL> r_s = <NUM_LIT:1.0> / g_s <EOL> return r_s <EOL> def Gee_c ( ) : <EOL> g_c = <NUM_LIT:1.0> <EOL> return g_c <EOL> def Gee_R ( S , K_R = <NUM_LIT> ) : <EOL> g_R = ( S * ( <NUM_LIT> + K_R ) ) / ( <NUM_LIT> * ( S + K_R ) ) <EOL> return g_R <EOL> def Gee_D ( D , K_D1 = - <NUM_LIT> , K_D2 = <NUM_LIT> ) : <EOL> g_D = <NUM_LIT:1.0> + K_D1 * D + K_D2 * D ** <NUM_LIT:2> <EOL> return g_D <EOL> def Gee_T ( TK , TL = <NUM_LIT> , TH = <NUM_LIT> , T0 = <NUM_LIT> ) : <EOL> alpha_T = ( TH - T0 ) / ( T0 - TL ) <EOL> g_T = ( ( TK - TL ) * ( TH - TK ) ** alpha_T ) / ( ( T0 - TL ) * ( TH - T0 ) ** alpha_T ) <EOL> return g_T <EOL> def Gee_M ( SM , SM0 , K_M1 , K_M2 ) : <EOL> g_SM = <NUM_LIT:1.0> - K_M1 * exp ( K_M2 * ( SM - SM0 ) ) <EOL> return g_SM <EOL> def PenmanMonteithPET ( Tc , RH , Rn , S , SM , um , z0 , d , g0 , SM0 , P = <NUM_LIT> , zm = <NUM_LIT> ) : <EOL> cP = <NUM_LIT> <EOL> rho_a = AirDensity ( RH , Tc , P ) <EOL> D = ( <NUM_LIT:1.0> - RH ) * SatVaporPress ( Tc ) <EOL> delta = SlopeSatVaporPress ( Tc ) <EOL> gamma = PsychConst ( P ) <EOL> r_a = AeroReist ( um , zm , z0 , d ) <EOL> r_s = SurfResist ( g0 , S , D , Tc , SM , SM0 ) <EOL> LE = ( delta * Rn + ( rho_a * cP * D ) / r_a ) / ( delta + gamma * ( <NUM_LIT:1.0> + r_s / r_a ) ) <EOL> return LE </s>
<s> """<STR_LIT>""" <EOL> from contextlib import contextmanager <EOL> from OpenGL . GL import * <EOL> @ contextmanager <EOL> def glSection ( type ) : <EOL> glBegin ( type ) <EOL> yield <EOL> glEnd ( ) <EOL> @ contextmanager <EOL> def glMatrix ( ) : <EOL> glPushMatrix ( ) <EOL> yield <EOL> glPopMatrix ( ) <EOL> @ contextmanager <EOL> def glModeMatrix ( type ) : <EOL> glMatrixMode ( type ) <EOL> glPushMatrix ( ) <EOL> yield <EOL> glMatrixMode ( type ) <EOL> glPopMatrix ( ) <EOL> @ contextmanager <EOL> def attributes ( * glBits ) : <EOL> for bit in glBits : <EOL> glPushAttrib ( bit ) <EOL> yield <EOL> for bit in glBits : <EOL> glPopAttrib ( ) <EOL> @ contextmanager <EOL> def enabled ( * glBits ) : <EOL> for bit in glBits : <EOL> glEnable ( bit ) <EOL> yield <EOL> for bit in glBits : <EOL> glDisable ( bit ) <EOL> @ contextmanager <EOL> def disabled ( * glBits ) : <EOL> for bit in glBits : <EOL> glDisable ( bit ) <EOL> yield <EOL> for bit in glBits : <EOL> glEnable ( bit ) <EOL> @ contextmanager <EOL> def overlays2D ( width , height , background_color ) : <EOL> """<STR_LIT>""" <EOL> glDisable ( GL_LIGHTING ) <EOL> glDisable ( GL_LIGHT0 ) <EOL> glDisable ( GL_BLEND ) <EOL> glEnable ( GL_SCISSOR_TEST ) <EOL> with glModeMatrix ( GL_PROJECTION ) : <EOL> yield <EOL> glViewport ( <NUM_LIT:0> , <NUM_LIT:0> , width , height ) <EOL> glDisable ( GL_SCISSOR_TEST ) <EOL> glMatrixMode ( GL_MODELVIEW ) <EOL> glLoadIdentity ( ) <EOL> glEnable ( GL_LIGHTING ) <EOL> glEnable ( GL_LIGHT0 ) <EOL> glEnable ( GL_BLEND ) <EOL> glClearColor ( * background_color ) <EOL> def setup_overlay2D ( x , y , width , height ) : <EOL> """<STR_LIT>""" <EOL> glMatrixMode ( GL_PROJECTION ) <EOL> glLoadIdentity ( ) <EOL> glScissor ( x , y , width , height ) <EOL> glViewport ( x , y , width , height ) <EOL> glOrtho ( x , x + width , y , y + height , - <NUM_LIT:1> , <NUM_LIT:1> ) <EOL> glMatrixMode ( GL_MODELVIEW ) <EOL> cyltrigs = [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] ; <EOL> def notGlePolyCylinder ( points , color , radius ) : <EOL> trigs = [ radius * x for x in cyltrigs ] ; <EOL> if abs ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] - points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] ) > <NUM_LIT> : <EOL> with glSection ( GL_QUAD_STRIP ) : <EOL> glNormal3f ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1.> ) <EOL> glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , <NUM_LIT:0> , radius ) <EOL> glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , <NUM_LIT:0> , radius ) <EOL> glNormal3f ( <NUM_LIT:0> , cyltrigs [ <NUM_LIT:0> ] , cyltrigs [ <NUM_LIT:1> ] ) <EOL> glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:1> ] ) <EOL> glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:1> ] ) <EOL> glNormal3f ( <NUM_LIT:0> , cyltrigs [ <NUM_LIT:2> ] , cyltrigs [ <NUM_LIT:3> ] ) <EOL> glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:2> ] , trigs [ <NUM_LIT:3> ] ) <EOL> glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:2> ] , trigs [ <NUM_LIT:3> ] ) <EOL> glNormal3f ( <NUM_LIT:0> , cyltrigs [ <NUM_LIT:2> ] , - cyltrigs [ <NUM_LIT:3> ] ) <EOL> glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:2> ] , - trigs [ <NUM_LIT:3> ] ) <EOL> glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:2> ] , - trigs [ <NUM_LIT:3> ] ) <EOL> glNormal3f ( <NUM_LIT:0> , cyltrigs [ <NUM_LIT:0> ] , - cyltrigs [ <NUM_LIT:1> ] ) <EOL> glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:1> ] ) <EOL> glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:1> ] ) <EOL> glNormal3f ( <NUM_LIT:0> , <NUM_LIT:0> , - <NUM_LIT:1.> ) <EOL> glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , <NUM_LIT:0> , - radius ) <EOL> glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , <NUM_LIT:0> , - radius ) <EOL> glNormal3f ( <NUM_LIT:0> , - cyltrigs [ <NUM_LIT:0> ] , - cyltrigs [ <NUM_LIT:1> ] ) <EOL> glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:1> ] ) <EOL> glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:1> ] ) <EOL> glNormal3f ( <NUM_LIT:0> , - cyltrigs [ <NUM_LIT:2> ] , - cyltrigs [ <NUM_LIT:3> ] ) <EOL> glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:2> ] , - trigs [ <NUM_LIT:3> ] ) <EOL> glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:2> ] , - trigs [ <NUM_LIT:3> ] ) <EOL> glNormal3f ( <NUM_LIT:0> , - cyltrigs [ <NUM_LIT:2> ] , cyltrigs [ <NUM_LIT:3> ] ) <EOL> glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:2> ] , trigs [ <NUM_LIT:3> ] ) <EOL> glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:2> ] , trigs [ <NUM_LIT:3> ] ) <EOL> glNormal3f ( <NUM_LIT:0> , - cyltrigs [ <NUM_LIT:0> ] , cyltrigs [ <NUM_LIT:1> ] ) <EOL> glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:1> ] ) <EOL> glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:1> ] ) <EOL> glNormal3f ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1.> ) <EOL> glVertex ( points [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , <NUM_LIT:0> , radius ) <EOL> glVertex ( points [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , <NUM_LIT:0> , radius ) <EOL> elif abs ( points [ <NUM_LIT:1> ] [ <NUM_LIT:1> ] - points [ <NUM_LIT:2> ] [ <NUM_LIT:1> ] ) > <NUM_LIT> : <EOL> p1 = points [ <NUM_LIT:1> ] [ <NUM_LIT:1> ] <EOL> p2 = points [ <NUM_LIT:2> ] [ <NUM_LIT:1> ] <EOL> with glSection ( GL_QUAD_STRIP ) : <EOL> glNormal3f ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1.> ) <EOL> glVertex ( <NUM_LIT:0> , p1 , radius ) <EOL> glVertex ( <NUM_LIT:0> , p2 , radius ) <EOL> glNormal3f ( cyltrigs [ <NUM_LIT:0> ] , <NUM_LIT:0> , cyltrigs [ <NUM_LIT:1> ] ) <EOL> glVertex ( trigs [ <NUM_LIT:0> ] , p1 , trigs [ <NUM_LIT:1> ] ) <EOL> glVertex ( trigs [ <NUM_LIT:0> ] , p2 , trigs [ <NUM_LIT:1> ] ) <EOL> glNormal3f ( cyltrigs [ <NUM_LIT:2> ] , <NUM_LIT:0> , cyltrigs [ <NUM_LIT:3> ] ) <EOL> glVertex ( trigs [ <NUM_LIT:2> ] , p1 , trigs [ <NUM_LIT:3> ] ) <EOL> glVertex ( trigs [ <NUM_LIT:2> ] , p2 , trigs [ <NUM_LIT:3> ] ) <EOL> glNormal3f ( cyltrigs [ <NUM_LIT:2> ] , <NUM_LIT:0> , - cyltrigs [ <NUM_LIT:3> ] ) <EOL> glVertex ( trigs [ <NUM_LIT:2> ] , p1 , - trigs [ <NUM_LIT:3> ] ) <EOL> glVertex ( trigs [ <NUM_LIT:2> ] , p2 , - trigs [ <NUM_LIT:3> ] ) <EOL> glNormal3f ( cyltrigs [ <NUM_LIT:0> ] , <NUM_LIT:0> , - cyltrigs [ <NUM_LIT:1> ] ) <EOL> glVertex ( trigs [ <NUM_LIT:0> ] , p1 , - trigs [ <NUM_LIT:1> ] ) <EOL> glVertex ( trigs [ <NUM_LIT:0> ] , p2 , - trigs [ <NUM_LIT:1> ] ) <EOL> glNormal3f ( <NUM_LIT:0> , <NUM_LIT:0> , - <NUM_LIT:1.> ) <EOL> glVertex ( <NUM_LIT:0> , p1 , - radius ) <EOL> glVertex ( <NUM_LIT:0> , p2 , - radius ) <EOL> glNormal3f ( - cyltrigs [ <NUM_LIT:0> ] , <NUM_LIT:0> , - cyltrigs [ <NUM_LIT:1> ] ) <EOL> glVertex ( - trigs [ <NUM_LIT:0> ] , p1 , - trigs [ <NUM_LIT:1> ] ) <EOL> glVertex ( - trigs [ <NUM_LIT:0> ] , p2 , - trigs [ <NUM_LIT:1> ] ) <EOL> glNormal3f ( - cyltrigs [ <NUM_LIT:2> ] , <NUM_LIT:0> , - cyltrigs [ <NUM_LIT:3> ] ) <EOL> glVertex ( - trigs [ <NUM_LIT:2> ] , p1 , - trigs [ <NUM_LIT:3> ] ) <EOL> glVertex ( - trigs [ <NUM_LIT:2> ] , p2 , - trigs [ <NUM_LIT:3> ] ) <EOL> glNormal3f ( - cyltrigs [ <NUM_LIT:2> ] , <NUM_LIT:0> , cyltrigs [ <NUM_LIT:3> ] ) <EOL> glVertex ( - trigs [ <NUM_LIT:2> ] , p1 , trigs [ <NUM_LIT:3> ] ) <EOL> glVertex ( - trigs [ <NUM_LIT:2> ] , p2 , trigs [ <NUM_LIT:3> ] ) <EOL> glNormal3f ( - cyltrigs [ <NUM_LIT:0> ] , <NUM_LIT:0> , cyltrigs [ <NUM_LIT:1> ] ) <EOL> glVertex ( - trigs [ <NUM_LIT:0> ] , p1 , trigs [ <NUM_LIT:1> ] ) <EOL> glVertex ( - trigs [ <NUM_LIT:0> ] , p2 , trigs [ <NUM_LIT:1> ] ) <EOL> glNormal3f ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1.> ) <EOL> glVertex ( <NUM_LIT:0> , p1 , radius ) <EOL> glVertex ( <NUM_LIT:0> , p2 , radius ) <EOL> else : <EOL> p1 = points [ <NUM_LIT:1> ] [ <NUM_LIT:2> ] <EOL> p2 = points [ <NUM_LIT:2> ] [ <NUM_LIT:2> ] <EOL> with glSection ( GL_QUAD_STRIP ) : <EOL> glNormal3f ( <NUM_LIT:0> , <NUM_LIT:1.> , <NUM_LIT:0> ) <EOL> glVertex ( <NUM_LIT:0> , radius , p1 ) <EOL> glVertex ( <NUM_LIT:0> , radius , p2 ) <EOL> glNormal3f ( cyltrigs [ <NUM_LIT:0> ] , cyltrigs [ <NUM_LIT:1> ] , <NUM_LIT:0> ) <EOL> glVertex ( trigs [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:1> ] , p1 ) <EOL> glVertex ( trigs [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:1> ] , p2 ) <EOL> glNormal3f ( cyltrigs [ <NUM_LIT:2> ] , cyltrigs [ <NUM_LIT:3> ] , <NUM_LIT:0> ) <EOL> glVertex ( trigs [ <NUM_LIT:2> ] , trigs [ <NUM_LIT:3> ] , p1 ) <EOL> glVertex ( trigs [ <NUM_LIT:2> ] , trigs [ <NUM_LIT:3> ] , p2 ) <EOL> glNormal3f ( cyltrigs [ <NUM_LIT:2> ] , - cyltrigs [ <NUM_LIT:3> ] , <NUM_LIT:0> ) <EOL> glVertex ( trigs [ <NUM_LIT:2> ] , - trigs [ <NUM_LIT:3> ] , p1 ) <EOL> glVertex ( trigs [ <NUM_LIT:2> ] , - trigs [ <NUM_LIT:3> ] , p2 ) <EOL> glNormal3f ( cyltrigs [ <NUM_LIT:0> ] , - cyltrigs [ <NUM_LIT:1> ] , <NUM_LIT:0> ) <EOL> glVertex ( trigs [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:1> ] , p1 ) <EOL> glVertex ( trigs [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:1> ] , p2 ) <EOL> glNormal3f ( <NUM_LIT:0> , - <NUM_LIT:1.> , <NUM_LIT:0> ) <EOL> glVertex ( <NUM_LIT:0> , - radius , p1 ) <EOL> glVertex ( <NUM_LIT:0> , - radius , p2 ) <EOL> glNormal3f ( - cyltrigs [ <NUM_LIT:0> ] , - cyltrigs [ <NUM_LIT:1> ] , <NUM_LIT:0> ) <EOL> glVertex ( - trigs [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:1> ] , p1 ) <EOL> glVertex ( - trigs [ <NUM_LIT:0> ] , - trigs [ <NUM_LIT:1> ] , p2 ) <EOL> glNormal3f ( - cyltrigs [ <NUM_LIT:2> ] , - cyltrigs [ <NUM_LIT:3> ] , <NUM_LIT:0> ) <EOL> glVertex ( - trigs [ <NUM_LIT:2> ] , - trigs [ <NUM_LIT:3> ] , p1 ) <EOL> glVertex ( - trigs [ <NUM_LIT:2> ] , - trigs [ <NUM_LIT:3> ] , p2 ) <EOL> glNormal3f ( - cyltrigs [ <NUM_LIT:2> ] , cyltrigs [ <NUM_LIT:3> ] , <NUM_LIT:0> ) <EOL> glVertex ( - trigs [ <NUM_LIT:2> ] , trigs [ <NUM_LIT:3> ] , p1 ) <EOL> glVertex ( - trigs [ <NUM_LIT:2> ] , trigs [ <NUM_LIT:3> ] , p2 ) <EOL> glNormal3f ( - cyltrigs [ <NUM_LIT:0> ] , cyltrigs [ <NUM_LIT:1> ] , <NUM_LIT:0> ) <EOL> glVertex ( - trigs [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:1> ] , p1 ) <EOL> glVertex ( - trigs [ <NUM_LIT:0> ] , trigs [ <NUM_LIT:1> ] , p2 ) <EOL> glNormal3f ( <NUM_LIT:0> , <NUM_LIT:1.> , <NUM_LIT:0> ) <EOL> glVertex ( <NUM_LIT:0> , radius , p1 ) <EOL> glVertex ( <NUM_LIT:0> , radius , p2 ) <EOL> def notGlutSolidCube ( size ) : <EOL> p = size / <NUM_LIT:2> <EOL> n = - <NUM_LIT:1> * p <EOL> with glSection ( GL_QUADS ) : <EOL> glNormal3f ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1.> ) <EOL> glVertex ( n , p , n ) <EOL> glVertex ( n , n , n ) <EOL> glVertex ( p , n , n ) <EOL> glVertex ( p , p , n ) <EOL> with glSection ( GL_QUADS ) : <EOL> glNormal3f ( <NUM_LIT:0> , <NUM_LIT:1.> , <NUM_LIT:0> ) <EOL> glVertex ( n , p , p ) <EOL> glVertex ( n , p , n ) <EOL> glVertex ( p , p , n ) <EOL> glVertex ( p , p , p ) <EOL> with glSection ( GL_QUADS ) : <EOL> glNormal3f ( <NUM_LIT:1.> , <NUM_LIT:0> , <NUM_LIT:0> ) <EOL> glVertex ( p , p , n ) <EOL> glVertex ( p , n , n ) <EOL> glVertex ( p , n , p ) <EOL> glVertex ( p , p , p ) <EOL> with glSection ( GL_QUADS ) : <EOL> glNormal3f ( <NUM_LIT:0> , <NUM_LIT:0> , - <NUM_LIT:1.> ) <EOL> glVertex ( p , p , p ) <EOL> glVertex ( p , n , p ) <EOL> glVertex ( n , n , p ) <EOL> glVertex ( n , p , p ) <EOL> with glSection ( GL_QUADS ) : <EOL> glNormal3f ( <NUM_LIT:0> , - <NUM_LIT:1.> , <NUM_LIT:0> ) <EOL> glVertex ( p , n , p ) <EOL> glVertex ( p , n , n ) <EOL> glVertex ( n , n , n ) <EOL> glVertex ( n , n , p ) <EOL> with glSection ( GL_QUADS ) : <EOL> glNormal3f ( - <NUM_LIT:1.> , <NUM_LIT:0> , <NUM_LIT:0> ) <EOL> glVertex ( n , p , p ) <EOL> glVertex ( n , n , p ) <EOL> glVertex ( n , n , n ) <EOL> glVertex ( n , p , n ) <EOL> class DisplayList ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , renderFunction ) : <EOL> self . renderFunction = renderFunction <EOL> self . needsUpdate = True <EOL> self . listId = None <EOL> def update ( self ) : <EOL> self . needsUpdate = True <EOL> def __call__ ( self , * args ) : <EOL> if self . needsUpdate : <EOL> if self . listId : <EOL> glDeleteLists ( self . listId , <NUM_LIT:1> ) <EOL> self . listId = glGenLists ( <NUM_LIT:1> ) <EOL> glNewList ( self . listId , GL_COMPILE_AND_EXECUTE ) <EOL> self . renderFunction ( * args ) <EOL> glEndList ( ) <EOL> self . needsUpdate = False <EOL> else : <EOL> glCallList ( self . listId ) </s>
<s> """<STR_LIT>""" <EOL> from lantz import Q_ <EOL> from lantz . drivers . examples . dummydrivers import DummyOsci , DummyFunGen , DummyShutter <EOL> from myapps import AmplitudeScannerShutter <EOL> fungen = DummyFunGen ( '<STR_LIT>' ) <EOL> osci = DummyOsci ( '<STR_LIT>' ) <EOL> shutter = DummyShutter ( '<STR_LIT>' ) <EOL> with AmplitudeScannerShutter ( fungen = fungen , osci = osci , shutter = shutter ) as app : <EOL> print ( '<STR_LIT>' ) <EOL> data = list ( app . scan_amplitude ( Q_ ( range ( <NUM_LIT:1> , <NUM_LIT:10> ) , '<STR_LIT>' ) ) ) <EOL> print ( data ) </s>
<s> """<STR_LIT>""" <EOL> from . cobolt0601 import Cobolt0601 <EOL> __all__ = [ '<STR_LIT>' ] </s>
<s> """<STR_LIT>""" <EOL> import warnings <EOL> from . import Q_ <EOL> from . log import LOGGER as _LOG <EOL> from stringparser import Parser <EOL> class DimensionalityWarning ( Warning ) : <EOL> pass <EOL> def _do_nothing ( value ) : <EOL> return value <EOL> def _getitem ( a , b ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> return a [ b ] <EOL> except KeyError : <EOL> return a [ type ( b ) ] <EOL> getitem = _getitem <EOL> def convert_to ( units , on_dimensionless = '<STR_LIT>' , on_incompatible = '<STR_LIT>' , <EOL> return_float = False ) : <EOL> """<STR_LIT>""" <EOL> if on_dimensionless not in ( '<STR_LIT:ignore>' , '<STR_LIT>' , '<STR_LIT>' ) : <EOL> raise ValueError ( "<STR_LIT>" <EOL> "<STR_LIT>" . format ( on_dimensionless ) ) <EOL> if on_incompatible not in ( '<STR_LIT:ignore>' , '<STR_LIT>' , '<STR_LIT>' ) : <EOL> raise ValueError ( "<STR_LIT>" <EOL> "<STR_LIT>" . format ( on_dimensionless ) ) <EOL> if isinstance ( units , str ) : <EOL> units = Q_ ( <NUM_LIT:1> , units ) <EOL> elif not isinstance ( units , Q_ ) : <EOL> raise ValueError ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> if return_float : <EOL> def _inner ( value ) : <EOL> if isinstance ( value , Q_ ) : <EOL> try : <EOL> return value . to ( units ) . magnitude <EOL> except ValueError as e : <EOL> if on_incompatible == '<STR_LIT>' : <EOL> raise ValueError ( e ) <EOL> elif on_incompatible == '<STR_LIT>' : <EOL> msg = '<STR_LIT>' . format ( value , units ) <EOL> warnings . warn ( msg , DimensionalityWarning ) <EOL> _LOG . warn ( msg ) <EOL> return value . magnitude <EOL> else : <EOL> if not units . dimensionless : <EOL> if on_dimensionless == '<STR_LIT>' : <EOL> raise ValueError ( '<STR_LIT>' . format ( value , units ) ) <EOL> elif on_dimensionless == '<STR_LIT>' : <EOL> msg = '<STR_LIT>' . format ( value , units ) <EOL> warnings . warn ( msg , DimensionalityWarning ) <EOL> _LOG . warn ( msg ) <EOL> return float ( value ) <EOL> return _inner <EOL> else : <EOL> def _inner ( value ) : <EOL> if isinstance ( value , Q_ ) : <EOL> try : <EOL> return value . to ( units ) <EOL> except ValueError as e : <EOL> if on_incompatible == '<STR_LIT>' : <EOL> raise ValueError ( e ) <EOL> elif on_incompatible == '<STR_LIT>' : <EOL> msg = '<STR_LIT>' . format ( value , units ) <EOL> warnings . warn ( msg , DimensionalityWarning ) <EOL> _LOG . warn ( msg ) <EOL> return float ( value . magnitude ) * units <EOL> else : <EOL> if not units . dimensionless : <EOL> if on_dimensionless == '<STR_LIT>' : <EOL> raise ValueError ( '<STR_LIT>' . format ( value , units ) ) <EOL> elif on_dimensionless == '<STR_LIT>' : <EOL> msg = '<STR_LIT>' . format ( value , units ) <EOL> warnings . warn ( msg , DimensionalityWarning ) <EOL> _LOG . warn ( msg ) <EOL> return float ( value ) * units <EOL> return _inner <EOL> class Processor ( object ) : <EOL> """<STR_LIT>""" <EOL> def __new__ ( cls , processors ) : <EOL> if isinstance ( processors , ( tuple , list ) ) : <EOL> if len ( processors ) > <NUM_LIT:1> : <EOL> inst = super ( ) . __new__ ( cls ) <EOL> inst . processors = tuple ( cls . _to_callable ( processor ) <EOL> for processor in processors ) <EOL> return inst <EOL> else : <EOL> return cls . _to_callable ( processors [ <NUM_LIT:0> ] ) <EOL> else : <EOL> return cls . _to_callable ( processors ) <EOL> def __call__ ( self , values ) : <EOL> return tuple ( processor ( value ) <EOL> for processor , value in zip ( self . processors , values ) ) <EOL> @ classmethod <EOL> def _to_callable ( cls , obj ) : <EOL> if callable ( obj ) : <EOL> return obj <EOL> if obj is None : <EOL> return _do_nothing <EOL> return cls . to_callable ( obj ) <EOL> @ classmethod <EOL> def to_callable ( cls , obj ) : <EOL> raise TypeError ( '<STR_LIT>' . format ( obj ) ) <EOL> def __len__ ( self ) : <EOL> if isinstance ( self . processors , tuple ) : <EOL> return len ( self . processors ) <EOL> return <NUM_LIT:1> <EOL> class FromQuantityProcessor ( Processor ) : <EOL> """<STR_LIT>""" <EOL> @ classmethod <EOL> def to_callable ( cls , obj ) : <EOL> if isinstance ( obj , ( str , Q_ ) ) : <EOL> return convert_to ( obj , return_float = True ) <EOL> raise TypeError ( '<STR_LIT>' <EOL> '<STR_LIT>' . format ( obj ) ) <EOL> class ToQuantityProcessor ( Processor ) : <EOL> """<STR_LIT>""" <EOL> @ classmethod <EOL> def to_callable ( cls , obj ) : <EOL> if isinstance ( obj , ( str , Q_ ) ) : <EOL> return convert_to ( obj , on_dimensionless = '<STR_LIT:ignore>' ) <EOL> raise TypeError ( '<STR_LIT>' <EOL> '<STR_LIT>' . format ( obj ) ) <EOL> class ParseProcessor ( Processor ) : <EOL> """<STR_LIT>""" <EOL> @ classmethod <EOL> def to_callable ( cls , obj ) : <EOL> if isinstance ( obj , str ) : <EOL> return Parser ( obj ) <EOL> raise TypeError ( '<STR_LIT>' <EOL> '<STR_LIT>' . format ( obj ) ) <EOL> class MapProcessor ( Processor ) : <EOL> """<STR_LIT>""" <EOL> @ classmethod <EOL> def to_callable ( cls , obj ) : <EOL> if isinstance ( obj , dict ) : <EOL> return get_mapping ( obj ) <EOL> if isinstance ( obj , set ) : <EOL> return check_membership ( obj ) <EOL> raise TypeError ( '<STR_LIT>' <EOL> '<STR_LIT>' . format ( obj ) ) <EOL> class ReverseMapProcessor ( Processor ) : <EOL> """<STR_LIT>""" <EOL> __reversed_cache = { } <EOL> @ classmethod <EOL> def to_callable ( cls , obj ) : <EOL> if isinstance ( obj , dict ) : <EOL> obj = cls . __reversed_cache . setdefault ( id ( obj ) , <EOL> { value : key for key , value <EOL> in obj . items ( ) } ) <EOL> return get_mapping ( obj ) <EOL> if isinstance ( obj , set ) : <EOL> return check_membership ( obj ) <EOL> raise TypeError ( '<STR_LIT>' <EOL> '<STR_LIT>' . format ( obj ) ) <EOL> class RangeProcessor ( Processor ) : <EOL> """<STR_LIT>""" <EOL> @ classmethod <EOL> def to_callable ( cls , obj ) : <EOL> if not isinstance ( obj , ( list , tuple ) ) : <EOL> raise TypeError ( '<STR_LIT>' <EOL> '<STR_LIT>' . format ( obj ) ) <EOL> if not len ( obj ) in ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) : <EOL> raise TypeError ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' . format ( len ( obj ) ) ) <EOL> if len ( obj ) == <NUM_LIT:1> : <EOL> return check_range_and_coerce_step ( <NUM_LIT:0> , * obj ) <EOL> return check_range_and_coerce_step ( * obj ) <EOL> def check_range_and_coerce_step ( low , high , step = None ) : <EOL> """<STR_LIT>""" <EOL> def _inner ( value ) : <EOL> if not ( low <= value <= high ) : <EOL> raise ValueError ( '<STR_LIT>' . format ( value , low , high ) ) <EOL> if step : <EOL> value = round ( ( value - low ) / step ) * step + low <EOL> return value <EOL> return _inner <EOL> def check_membership ( container ) : <EOL> """<STR_LIT>""" <EOL> def _inner ( value ) : <EOL> if value not in container : <EOL> raise ValueError ( '<STR_LIT>' . format ( value , container ) ) <EOL> return value <EOL> return _inner <EOL> def get_mapping ( container ) : <EOL> """<STR_LIT>""" <EOL> def _inner ( key ) : <EOL> if key not in container : <EOL> raise ValueError ( "<STR_LIT>" . format ( key , tuple ( container . keys ( ) ) ) ) <EOL> return container [ key ] <EOL> return _inner </s>
<s> try : <EOL> from setuptools import setup <EOL> except ImportError : <EOL> print ( '<STR_LIT>' ) <EOL> sys . exit ( <NUM_LIT:1> ) <EOL> import os <EOL> import sys <EOL> import codecs <EOL> def read ( filename ) : <EOL> return codecs . open ( filename , encoding = '<STR_LIT:utf-8>' ) . read ( ) <EOL> long_description = '<STR_LIT>' . join ( [ read ( '<STR_LIT>' ) , <EOL> read ( '<STR_LIT>' ) , <EOL> read ( '<STR_LIT>' ) ] ) <EOL> __doc__ = long_description <EOL> requirements = [ ] <EOL> if sys . version_info < ( <NUM_LIT:3> , <NUM_LIT:4> ) : <EOL> requirements . append ( '<STR_LIT>' ) <EOL> root_folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . join ( root_folder , '<STR_LIT>' , '<STR_LIT>' ) <EOL> paths = os . listdir ( folder ) <EOL> companies = [ path for path in paths <EOL> if os . path . isdir ( os . path . join ( folder , path ) ) <EOL> and os . path . exists ( os . path . join ( folder , path , '<STR_LIT>' ) ) ] <EOL> folder = os . path . join ( root_folder , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) <EOL> paths = os . listdir ( folder ) <EOL> legacy_companies = [ path for path in paths <EOL> if os . path . isdir ( os . path . join ( folder , path ) ) <EOL> and os . path . exists ( os . path . join ( folder , path , '<STR_LIT>' ) ) ] <EOL> setup ( name = '<STR_LIT>' , <EOL> version = '<STR_LIT>' , <EOL> license = '<STR_LIT>' , <EOL> description = '<STR_LIT>' , <EOL> long_description = long_description , <EOL> keywords = '<STR_LIT>' , <EOL> author = '<STR_LIT>' , <EOL> author_email = '<STR_LIT>' , <EOL> url = '<STR_LIT>' , <EOL> packages = [ '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' ] + <EOL> [ '<STR_LIT>' + company for company in companies ] + <EOL> [ '<STR_LIT>' + company for company in legacy_companies ] , <EOL> test_suite = '<STR_LIT>' , <EOL> install_requires = [ '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> ] + requirements , <EOL> zip_safe = False , <EOL> platforms = '<STR_LIT>' , <EOL> entry_points = { <EOL> '<STR_LIT>' : [ <EOL> '<STR_LIT>' , <EOL> ] , <EOL> '<STR_LIT>' : [ <EOL> '<STR_LIT>' , <EOL> ] <EOL> } , <EOL> classifiers = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' <EOL> ] , <EOL> scripts = [ '<STR_LIT>' , <EOL> ] , <EOL> ) </s>
<s> __author__ = '<STR_LIT>' <EOL> from learnpy . Problem import Problem <EOL> pro = Problem ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> pro . set_label ( '<STR_LIT:Name>' ) <EOL> pro . set_model ( "<STR_LIT>" ) <EOL> pro . model . fit ( None ) <EOL> pro . set_testing ( "<STR_LIT>" ) <EOL> pro . predict ( ) <EOL> pro2 = Problem ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> pro2 . set_label ( '<STR_LIT:Name>' ) <EOL> pro2 . set_model ( "<STR_LIT>" ) <EOL> pro2 . model . fit ( None ) <EOL> pro2 . set_testing ( "<STR_LIT>" ) <EOL> pro2 . predict ( ) </s>
<s> from collections import OrderedDict <EOL> import theano . tensor as T <EOL> from . . import utils <EOL> __all__ = [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ] <EOL> class Layer ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , incoming , name = None ) : <EOL> if isinstance ( incoming , tuple ) : <EOL> self . input_shape = incoming <EOL> self . input_layer = None <EOL> else : <EOL> self . input_shape = incoming . output_shape <EOL> self . input_layer = incoming <EOL> self . name = name <EOL> self . params = OrderedDict ( ) <EOL> self . get_output_kwargs = [ ] <EOL> if any ( d is not None and d <= <NUM_LIT:0> for d in self . input_shape ) : <EOL> raise ValueError ( ( <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" ) % ( <EOL> self . input_shape , self . name ) ) <EOL> @ property <EOL> def output_shape ( self ) : <EOL> shape = self . get_output_shape_for ( self . input_shape ) <EOL> if any ( isinstance ( s , T . Variable ) for s in shape ) : <EOL> raise ValueError ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" % ( self . __class__ . __name__ , shape ) ) <EOL> return shape <EOL> def get_params ( self , ** tags ) : <EOL> """<STR_LIT>""" <EOL> result = list ( self . params . keys ( ) ) <EOL> only = set ( tag for tag , value in tags . items ( ) if value ) <EOL> if only : <EOL> result = [ param for param in result <EOL> if not ( only - self . params [ param ] ) ] <EOL> exclude = set ( tag for tag , value in tags . items ( ) if not value ) <EOL> if exclude : <EOL> result = [ param for param in result <EOL> if not ( self . params [ param ] & exclude ) ] <EOL> return utils . collect_shared_vars ( result ) <EOL> def get_output_shape_for ( self , input_shape ) : <EOL> """<STR_LIT>""" <EOL> return input_shape <EOL> def get_output_for ( self , input , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> raise NotImplementedError <EOL> def add_param ( self , spec , shape , name = None , ** tags ) : <EOL> """<STR_LIT>""" <EOL> if name is not None : <EOL> if self . name is not None : <EOL> name = "<STR_LIT>" % ( self . name , name ) <EOL> param = utils . create_param ( spec , shape , name ) <EOL> tags [ '<STR_LIT>' ] = tags . get ( '<STR_LIT>' , True ) <EOL> tags [ '<STR_LIT>' ] = tags . get ( '<STR_LIT>' , True ) <EOL> self . params [ param ] = set ( tag for tag , value in tags . items ( ) if value ) <EOL> return param <EOL> class MergeLayer ( Layer ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , incomings , name = None ) : <EOL> self . input_shapes = [ incoming if isinstance ( incoming , tuple ) <EOL> else incoming . output_shape <EOL> for incoming in incomings ] <EOL> self . input_layers = [ None if isinstance ( incoming , tuple ) <EOL> else incoming <EOL> for incoming in incomings ] <EOL> self . name = name <EOL> self . params = OrderedDict ( ) <EOL> self . get_output_kwargs = [ ] <EOL> @ Layer . output_shape . getter <EOL> def output_shape ( self ) : <EOL> shape = self . get_output_shape_for ( self . input_shapes ) <EOL> if any ( isinstance ( s , T . Variable ) for s in shape ) : <EOL> raise ValueError ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" % ( self . __class__ . __name__ , shape ) ) <EOL> return shape <EOL> def get_output_shape_for ( self , input_shapes ) : <EOL> """<STR_LIT>""" <EOL> raise NotImplementedError <EOL> def get_output_for ( self , inputs , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> raise NotImplementedError </s>
<s> from mock import Mock <EOL> import numpy <EOL> import pytest <EOL> import theano <EOL> class TestAutocrop : <EOL> def test_autocrop_array_shapes ( self ) : <EOL> from lasagne . layers . merge import autocrop_array_shapes <EOL> crop0 = None <EOL> crop1 = [ None , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> crop2 = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> crop_bad = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> assert autocrop_array_shapes ( <EOL> [ ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ) , ( <NUM_LIT:5> , <NUM_LIT:6> , <NUM_LIT:7> , <NUM_LIT:8> ) , ( <NUM_LIT:5> , <NUM_LIT:4> , <NUM_LIT:3> , <NUM_LIT:2> ) ] , crop0 ) == [ ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ) , ( <NUM_LIT:5> , <NUM_LIT:6> , <NUM_LIT:7> , <NUM_LIT:8> ) , ( <NUM_LIT:5> , <NUM_LIT:4> , <NUM_LIT:3> , <NUM_LIT:2> ) ] <EOL> assert autocrop_array_shapes ( <EOL> [ ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ) , ( <NUM_LIT:5> , <NUM_LIT:6> , <NUM_LIT:7> , <NUM_LIT:8> ) , ( <NUM_LIT:5> , <NUM_LIT:4> , <NUM_LIT:3> , <NUM_LIT:2> ) ] , crop1 ) == [ ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:5> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:5> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:2> ) ] <EOL> assert autocrop_array_shapes ( <EOL> [ ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ) , ( <NUM_LIT:5> , <NUM_LIT:6> , <NUM_LIT:7> , <NUM_LIT:8> ) , ( <NUM_LIT:5> , <NUM_LIT:4> , <NUM_LIT:3> , <NUM_LIT:2> ) ] , crop2 ) == [ ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ) , ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:7> , <NUM_LIT:8> ) , ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:2> ) ] <EOL> with pytest . raises ( ValueError ) : <EOL> autocrop_array_shapes ( <EOL> [ ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ) , ( <NUM_LIT:5> , <NUM_LIT:6> , <NUM_LIT:7> , <NUM_LIT:8> ) , ( <NUM_LIT:5> , <NUM_LIT:4> , <NUM_LIT:3> , <NUM_LIT:2> ) ] , crop_bad ) <EOL> with pytest . raises ( ValueError ) : <EOL> autocrop_array_shapes ( <EOL> [ ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ) , ( <NUM_LIT:5> , <NUM_LIT:6> , <NUM_LIT:7> ) , ( <NUM_LIT:5> , <NUM_LIT:4> , <NUM_LIT:3> , <NUM_LIT:2> , <NUM_LIT:10> ) ] , crop1 ) <EOL> def test_crop_inputs ( self ) : <EOL> from lasagne . layers . merge import autocrop <EOL> from numpy . testing import assert_array_equal <EOL> crop_0 = None <EOL> crop_1 = [ None , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> crop_l = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> crop_c = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> crop_u = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> crop_x = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> crop_bad = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> x0 = numpy . random . random ( ( <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:5> , <NUM_LIT:7> ) ) <EOL> x1 = numpy . random . random ( ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> ) ) <EOL> x2 = numpy . random . random ( ( <NUM_LIT:6> , <NUM_LIT:3> , <NUM_LIT:4> , <NUM_LIT:2> ) ) <EOL> def crop_test ( cropping , inputs , expected ) : <EOL> inputs = [ theano . shared ( x ) for x in inputs ] <EOL> outs = autocrop ( inputs , cropping ) <EOL> outs = [ o . eval ( ) for o in outs ] <EOL> assert len ( outs ) == len ( expected ) <EOL> for o , e in zip ( outs , expected ) : <EOL> assert_array_equal ( o , e ) <EOL> crop_test ( crop_0 , [ x0 , x1 ] , <EOL> [ x0 , x1 ] ) <EOL> crop_test ( crop_1 , [ x0 , x1 ] , <EOL> [ x0 [ : , : <NUM_LIT:2> , <NUM_LIT:1> : <NUM_LIT:4> , <NUM_LIT:3> : ] , x1 [ : , : , : , : ] ] ) <EOL> crop_test ( crop_l , [ x0 , x1 ] , <EOL> [ x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : <NUM_LIT:3> , : <NUM_LIT:4> ] , x1 [ : , : , : , : ] ] ) <EOL> crop_test ( crop_c , [ x0 , x1 ] , <EOL> [ x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , <NUM_LIT:1> : <NUM_LIT:4> , <NUM_LIT:1> : <NUM_LIT:5> ] , x1 [ : , : , : , : ] ] ) <EOL> crop_test ( crop_u , [ x0 , x1 ] , <EOL> [ x0 [ <NUM_LIT:1> : , <NUM_LIT:1> : , <NUM_LIT:2> : , <NUM_LIT:3> : ] , x1 [ : , : , : , : ] ] ) <EOL> crop_test ( crop_0 , [ x0 , x2 ] , <EOL> [ x0 , x2 ] ) <EOL> crop_test ( crop_1 , [ x0 , x2 ] , <EOL> [ x0 [ : , : , : <NUM_LIT:4> , <NUM_LIT:5> : ] , x2 [ : , : , : , : ] ] ) <EOL> crop_test ( crop_l , [ x0 , x2 ] , <EOL> [ x0 [ : , : , : <NUM_LIT:4> , : <NUM_LIT:2> ] , x2 [ : <NUM_LIT:2> , : , : , : ] ] ) <EOL> crop_test ( crop_c , [ x0 , x2 ] , <EOL> [ x0 [ : , : , : <NUM_LIT:4> , <NUM_LIT:2> : <NUM_LIT:4> ] , x2 [ <NUM_LIT:2> : <NUM_LIT:4> , : , : , : ] ] ) <EOL> crop_test ( crop_u , [ x0 , x2 ] , <EOL> [ x0 [ : , : , <NUM_LIT:1> : , <NUM_LIT:5> : ] , x2 [ <NUM_LIT:4> : , : , : , : ] ] ) <EOL> crop_test ( crop_0 , [ x0 , x1 , x2 ] , <EOL> [ x0 , x1 , x2 ] ) <EOL> crop_test ( crop_1 , [ x0 , x1 , x2 ] , <EOL> [ x0 [ : , : <NUM_LIT:2> , <NUM_LIT:1> : <NUM_LIT:4> , <NUM_LIT:5> : ] , x1 [ : , : , : , <NUM_LIT:2> : ] , x2 [ : , : <NUM_LIT:2> , : <NUM_LIT:3> , : ] ] ) <EOL> crop_test ( crop_l , [ x0 , x1 , x2 ] , <EOL> [ x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : <NUM_LIT:3> , : <NUM_LIT:2> ] , x1 [ : , : , : , : <NUM_LIT:2> ] , x2 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : <NUM_LIT:3> , : ] ] ) <EOL> crop_test ( crop_c , [ x0 , x1 , x2 ] , <EOL> [ x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , <NUM_LIT:1> : <NUM_LIT:4> , <NUM_LIT:2> : <NUM_LIT:4> ] , x1 [ : , : , : , <NUM_LIT:1> : <NUM_LIT:3> ] , x2 [ <NUM_LIT:2> : <NUM_LIT:3> , : <NUM_LIT:2> , : <NUM_LIT:3> , : ] ] ) <EOL> crop_test ( crop_u , [ x0 , x1 , x2 ] , <EOL> [ x0 [ <NUM_LIT:1> : , <NUM_LIT:1> : , <NUM_LIT:2> : , <NUM_LIT:5> : ] , x1 [ : , : , : , <NUM_LIT:2> : ] , x2 [ <NUM_LIT:5> : , <NUM_LIT:1> : , <NUM_LIT:1> : , : ] ] ) <EOL> crop_test ( crop_x , [ x0 , x1 , x2 ] , <EOL> [ x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x1 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x2 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] ] ) <EOL> crop_test ( crop_x , [ x0 , x1 , x2 , x0 , x1 , x2 ] , <EOL> [ x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x1 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x2 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , <EOL> x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x1 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x2 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] ] ) <EOL> with pytest . raises ( ValueError ) : <EOL> crop_test ( crop_bad , [ x0 , x1 , x2 ] , <EOL> [ x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x1 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x2 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] ] ) <EOL> with pytest . raises ( ValueError ) : <EOL> crop_test ( crop_bad , [ x0 [ : , : , : , <NUM_LIT:0> ] , x1 , x2 [ : , : , : , : , None ] ] , <EOL> [ x0 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x1 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] , x2 [ : <NUM_LIT:1> , : <NUM_LIT:2> , : , : ] ] ) <EOL> class TestConcatLayer : <EOL> @ pytest . fixture <EOL> def layer ( self ) : <EOL> from lasagne . layers . merge import ConcatLayer <EOL> return ConcatLayer ( [ Mock ( ) , Mock ( ) ] , axis = <NUM_LIT:1> ) <EOL> @ pytest . fixture <EOL> def crop_layer_0 ( self ) : <EOL> from lasagne . layers . merge import ConcatLayer <EOL> return ConcatLayer ( [ Mock ( ) , Mock ( ) ] , axis = <NUM_LIT:0> , <EOL> cropping = [ '<STR_LIT>' ] * <NUM_LIT:2> ) <EOL> @ pytest . fixture <EOL> def crop_layer_1 ( self ) : <EOL> from lasagne . layers . merge import ConcatLayer <EOL> return ConcatLayer ( [ Mock ( ) , Mock ( ) ] , axis = <NUM_LIT:1> , <EOL> cropping = [ '<STR_LIT>' ] * <NUM_LIT:2> ) <EOL> def test_get_output_shape_for ( self , layer ) : <EOL> assert layer . get_output_shape_for ( [ ( <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:3> , <NUM_LIT:5> ) ] ) == ( <NUM_LIT:3> , <NUM_LIT:7> ) <EOL> assert layer . get_output_shape_for ( [ ( <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:3> , None ) ] ) == ( <NUM_LIT:3> , None ) <EOL> assert layer . get_output_shape_for ( [ ( None , <NUM_LIT:2> ) , ( <NUM_LIT:3> , <NUM_LIT:5> ) ] ) == ( <NUM_LIT:3> , <NUM_LIT:7> ) <EOL> assert layer . get_output_shape_for ( [ ( None , <NUM_LIT:2> ) , ( None , <NUM_LIT:5> ) ] ) == ( None , <NUM_LIT:7> ) <EOL> with pytest . raises ( ValueError ) : <EOL> layer . get_output_shape_for ( [ ( <NUM_LIT:4> , None ) , ( <NUM_LIT:3> , <NUM_LIT:5> ) ] ) <EOL> with pytest . raises ( ValueError ) : <EOL> layer . get_output_shape_for ( [ ( <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:4> , None ) ] ) <EOL> with pytest . raises ( ValueError ) : <EOL> layer . get_output_shape_for ( [ ( None , <NUM_LIT:2> ) , ( <NUM_LIT:3> , <NUM_LIT:5> ) , ( <NUM_LIT:4> , <NUM_LIT:5> ) ] ) <EOL> def test_get_output_shape_for_cropped ( self , crop_layer_0 , crop_layer_1 ) : <EOL> input_shapes = [ ( <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:4> , <NUM_LIT:5> ) ] <EOL> result_0 = crop_layer_0 . get_output_shape_for ( input_shapes ) <EOL> result_1 = crop_layer_1 . get_output_shape_for ( input_shapes ) <EOL> assert result_0 == ( <NUM_LIT:7> , <NUM_LIT:2> ) <EOL> assert result_1 == ( <NUM_LIT:3> , <NUM_LIT:7> ) <EOL> def test_get_output_for ( self , layer ) : <EOL> inputs = [ theano . shared ( numpy . ones ( ( <NUM_LIT:3> , <NUM_LIT:3> ) ) ) , <EOL> theano . shared ( numpy . ones ( ( <NUM_LIT:3> , <NUM_LIT:2> ) ) ) ] <EOL> result = layer . get_output_for ( inputs ) <EOL> result_eval = result . eval ( ) <EOL> desired_result = numpy . hstack ( [ input . get_value ( ) for input in inputs ] ) <EOL> assert ( result_eval == desired_result ) . all ( ) <EOL> def test_get_output_for_cropped ( self , crop_layer_0 , crop_layer_1 ) : <EOL> x0 = numpy . random . random ( ( <NUM_LIT:5> , <NUM_LIT:3> ) ) <EOL> x1 = numpy . random . random ( ( <NUM_LIT:4> , <NUM_LIT:2> ) ) <EOL> inputs = [ theano . shared ( x0 ) , <EOL> theano . shared ( x1 ) ] <EOL> result_0 = crop_layer_0 . get_output_for ( inputs ) . eval ( ) <EOL> result_1 = crop_layer_1 . get_output_for ( inputs ) . eval ( ) <EOL> desired_result_0 = numpy . concatenate ( [ x0 [ : , : <NUM_LIT:2> ] , x1 [ : , : <NUM_LIT:2> ] ] , axis = <NUM_LIT:0> ) <EOL> desired_result_1 = numpy . concatenate ( [ x0 [ : <NUM_LIT:4> , : ] , x1 [ : <NUM_LIT:4> , : ] ] , axis = <NUM_LIT:1> ) <EOL> assert ( result_0 == desired_result_0 ) . all ( ) <EOL> assert ( result_1 == desired_result_1 ) . all ( ) <EOL> class TestElemwiseSumLayer : <EOL> @ pytest . fixture <EOL> def layer ( self ) : <EOL> from lasagne . layers . merge import ElemwiseSumLayer <EOL> return ElemwiseSumLayer ( [ Mock ( ) , Mock ( ) ] , coeffs = [ <NUM_LIT:2> , - <NUM_LIT:1> ] ) <EOL> @ pytest . fixture <EOL> def crop_layer ( self ) : <EOL> from lasagne . layers . merge import ElemwiseSumLayer <EOL> return ElemwiseSumLayer ( [ Mock ( ) , Mock ( ) ] , coeffs = [ <NUM_LIT:2> , - <NUM_LIT:1> ] , <EOL> cropping = [ '<STR_LIT>' ] * <NUM_LIT:2> ) <EOL> def test_get_output_shape_for ( self , layer ) : <EOL> assert layer . get_output_shape_for ( [ ( <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:3> , <NUM_LIT:2> ) ] ) == ( <NUM_LIT:3> , <NUM_LIT:2> ) <EOL> assert layer . get_output_shape_for ( [ ( <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:3> , None ) ] ) == ( <NUM_LIT:3> , <NUM_LIT:2> ) <EOL> assert layer . get_output_shape_for ( [ ( None , <NUM_LIT:2> ) , ( <NUM_LIT:3> , <NUM_LIT:2> ) ] ) == ( <NUM_LIT:3> , <NUM_LIT:2> ) <EOL> assert layer . get_output_shape_for ( [ ( None , <NUM_LIT:2> ) , ( None , <NUM_LIT:2> ) ] ) == ( None , <NUM_LIT:2> ) <EOL> with pytest . raises ( ValueError ) : <EOL> layer . get_output_shape_for ( [ ( <NUM_LIT:3> , None ) , ( <NUM_LIT:4> , <NUM_LIT:2> ) ] ) <EOL> with pytest . raises ( ValueError ) : <EOL> layer . get_output_shape_for ( [ ( <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:4> , None ) ] ) <EOL> with pytest . raises ( ValueError ) : <EOL> layer . get_output_shape_for ( [ ( None , <NUM_LIT:2> ) , ( <NUM_LIT:3> , <NUM_LIT:2> ) , ( <NUM_LIT:4> , <NUM_LIT:2> ) ] ) <EOL> def test_get_output_for ( self , layer ) : <EOL> a = numpy . array ( [ [ <NUM_LIT:0> , <NUM_LIT:1> ] , [ <NUM_LIT:2> , <NUM_LIT:3> ] ] ) <EOL> b = numpy . array ( [ [ <NUM_LIT:1> , <NUM_LIT:2> ] , [ <NUM_LIT:4> , <NUM_LIT:5> ] ] ) <EOL> inputs = [ theano . shared ( a ) , <EOL> theano . shared ( b ) ] <EOL> result = layer . get_output_for ( inputs ) <EOL> result_eval = result . eval ( ) <EOL> desired_result = <NUM_LIT:2> * a - b <EOL> assert ( result_eval == desired_result ) . all ( ) <EOL> def test_get_output_for_cropped ( self , crop_layer ) : <EOL> from numpy . testing import assert_array_almost_equal as aeq <EOL> x0 = numpy . random . random ( ( <NUM_LIT:5> , <NUM_LIT:3> ) ) <EOL> x1 = numpy . random . random ( ( <NUM_LIT:4> , <NUM_LIT:2> ) ) <EOL> inputs = [ theano . shared ( x0 ) , <EOL> theano . shared ( x1 ) ] <EOL> result = crop_layer . get_output_for ( inputs ) . eval ( ) <EOL> desired_result = <NUM_LIT:2> * x0 [ : <NUM_LIT:4> , : <NUM_LIT:2> ] - x1 [ : <NUM_LIT:4> , : <NUM_LIT:2> ] <EOL> aeq ( result , desired_result ) <EOL> def test_bad_coeffs_fails ( self , layer ) : <EOL> from lasagne . layers . merge import ElemwiseSumLayer <EOL> with pytest . raises ( ValueError ) : <EOL> ElemwiseSumLayer ( [ Mock ( ) , Mock ( ) ] , coeffs = [ <NUM_LIT:2> , <NUM_LIT:3> , - <NUM_LIT:1> ] ) <EOL> class TestElemwiseMergeLayerMul : <EOL> @ pytest . fixture <EOL> def layer ( self ) : <EOL> import theano . tensor as T <EOL> from lasagne . layers . merge import ElemwiseMergeLayer <EOL> return ElemwiseMergeLayer ( [ Mock ( ) , Mock ( ) ] , merge_function = T . mul ) <EOL> def test_get_output_for ( self , layer ) : <EOL> a = numpy . array ( [ [ <NUM_LIT:0> , <NUM_LIT:1> ] , [ <NUM_LIT:2> , <NUM_LIT:3> ] ] ) <EOL> b = numpy . array ( [ [ <NUM_LIT:1> , <NUM_LIT:2> ] , [ <NUM_LIT:4> , <NUM_LIT:5> ] ] ) <EOL> inputs = [ theano . shared ( a ) , <EOL> theano . shared ( b ) ] <EOL> result = layer . get_output_for ( inputs ) <EOL> result_eval = result . eval ( ) <EOL> desired_result = a * b <EOL> assert ( result_eval == desired_result ) . all ( ) <EOL> class TestElemwiseMergeLayerMaximum : <EOL> @ pytest . fixture <EOL> def layer ( self ) : <EOL> import theano . tensor as T <EOL> from lasagne . layers . merge import ElemwiseMergeLayer <EOL> return ElemwiseMergeLayer ( [ Mock ( ) , Mock ( ) ] , merge_function = T . maximum ) <EOL> def test_get_output_for ( self , layer ) : <EOL> a = numpy . array ( [ [ <NUM_LIT:0> , <NUM_LIT:1> ] , [ <NUM_LIT:2> , <NUM_LIT:3> ] ] ) <EOL> b = numpy . array ( [ [ <NUM_LIT:1> , <NUM_LIT:2> ] , [ <NUM_LIT:4> , <NUM_LIT:5> ] ] ) <EOL> inputs = [ theano . shared ( a ) , <EOL> theano . shared ( b ) ] <EOL> result = layer . get_output_for ( inputs ) <EOL> result_eval = result . eval ( ) <EOL> desired_result = numpy . maximum ( a , b ) <EOL> assert ( result_eval == desired_result ) . all ( ) </s>
<s> from gevent import monkey ; monkey . patch_all ( ) <EOL> import gevent <EOL> from ws4py . client . geventclient import WebSocketClient <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> ws = WebSocketClient ( '<STR_LIT>' , protocols = [ '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> ws . connect ( ) <EOL> ws . send ( "<STR_LIT>" ) <EOL> print ( ( ws . receive ( ) , ) ) <EOL> ws . send ( "<STR_LIT>" ) <EOL> print ( ( ws . receive ( ) , ) ) <EOL> def incoming ( ) : <EOL> while True : <EOL> m = ws . receive ( ) <EOL> if m is not None : <EOL> m = str ( m ) <EOL> print ( ( m , len ( m ) ) ) <EOL> if len ( m ) == <NUM_LIT> : <EOL> ws . close ( ) <EOL> break <EOL> else : <EOL> break <EOL> print ( ( "<STR_LIT>" , ) ) <EOL> def outgoing ( ) : <EOL> for i in range ( <NUM_LIT:0> , <NUM_LIT> , <NUM_LIT:5> ) : <EOL> ws . send ( "<STR_LIT:*>" * i ) <EOL> ws . send ( "<STR_LIT>" ) <EOL> greenlets = [ <EOL> gevent . spawn ( incoming ) , <EOL> gevent . spawn ( outgoing ) , <EOL> ] <EOL> gevent . joinall ( greenlets ) </s>
<s> import os <EOL> import struct <EOL> from ws4py . framing import Frame , OPCODE_CONTINUATION , OPCODE_TEXT , OPCODE_BINARY , OPCODE_CLOSE , OPCODE_PING , OPCODE_PONG <EOL> from ws4py . compat import unicode , py3k <EOL> __all__ = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' ] <EOL> class Message ( object ) : <EOL> def __init__ ( self , opcode , data = b'<STR_LIT>' , encoding = '<STR_LIT:utf-8>' ) : <EOL> """<STR_LIT>""" <EOL> self . opcode = opcode <EOL> self . _completed = False <EOL> self . encoding = encoding <EOL> if isinstance ( data , unicode ) : <EOL> if not encoding : <EOL> raise TypeError ( "<STR_LIT>" ) <EOL> data = data . encode ( encoding ) <EOL> elif isinstance ( data , bytearray ) : <EOL> data = bytes ( data ) <EOL> elif not isinstance ( data , bytes ) : <EOL> raise TypeError ( "<STR_LIT>" % type ( data ) ) <EOL> self . data = data <EOL> def single ( self , mask = False ) : <EOL> """<STR_LIT>""" <EOL> mask = os . urandom ( <NUM_LIT:4> ) if mask else None <EOL> return Frame ( body = self . data , opcode = self . opcode , <EOL> masking_key = mask , fin = <NUM_LIT:1> ) . build ( ) <EOL> def fragment ( self , first = False , last = False , mask = False ) : <EOL> """<STR_LIT>""" <EOL> fin = <NUM_LIT:1> if last is True else <NUM_LIT:0> <EOL> opcode = self . opcode if first is True else OPCODE_CONTINUATION <EOL> mask = os . urandom ( <NUM_LIT:4> ) if mask else None <EOL> return Frame ( body = self . data , <EOL> opcode = opcode , masking_key = mask , <EOL> fin = fin ) . build ( ) <EOL> @ property <EOL> def completed ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . _completed <EOL> @ completed . setter <EOL> def completed ( self , state ) : <EOL> """<STR_LIT>""" <EOL> self . _completed = state <EOL> def extend ( self , data ) : <EOL> """<STR_LIT>""" <EOL> if isinstance ( data , bytes ) : <EOL> self . data += data <EOL> elif isinstance ( data , bytearray ) : <EOL> self . data += bytes ( data ) <EOL> elif isinstance ( data , unicode ) : <EOL> self . data += data . encode ( self . encoding ) <EOL> else : <EOL> raise TypeError ( "<STR_LIT>" % type ( data ) ) <EOL> def __len__ ( self ) : <EOL> return len ( self . __unicode__ ( ) ) <EOL> def __str__ ( self ) : <EOL> if py3k : <EOL> return self . data . decode ( self . encoding ) <EOL> return self . data <EOL> def __unicode__ ( self ) : <EOL> return self . data . decode ( self . encoding ) <EOL> class TextMessage ( Message ) : <EOL> def __init__ ( self , text = None ) : <EOL> Message . __init__ ( self , OPCODE_TEXT , text ) <EOL> @ property <EOL> def is_binary ( self ) : <EOL> return False <EOL> @ property <EOL> def is_text ( self ) : <EOL> return True <EOL> class BinaryMessage ( Message ) : <EOL> def __init__ ( self , bytes = None ) : <EOL> Message . __init__ ( self , OPCODE_BINARY , bytes , encoding = None ) <EOL> @ property <EOL> def is_binary ( self ) : <EOL> return True <EOL> @ property <EOL> def is_text ( self ) : <EOL> return False <EOL> def __len__ ( self ) : <EOL> return len ( self . data ) <EOL> class CloseControlMessage ( Message ) : <EOL> def __init__ ( self , code = <NUM_LIT:1000> , reason = '<STR_LIT>' ) : <EOL> data = b"<STR_LIT>" <EOL> if code : <EOL> data += struct . pack ( "<STR_LIT>" , code ) <EOL> if reason is not None : <EOL> if isinstance ( reason , unicode ) : <EOL> reason = reason . encode ( '<STR_LIT:utf-8>' ) <EOL> data += reason <EOL> Message . __init__ ( self , OPCODE_CLOSE , data , '<STR_LIT:utf-8>' ) <EOL> self . code = code <EOL> self . reason = reason <EOL> def __str__ ( self ) : <EOL> if py3k : <EOL> return self . reason . decode ( '<STR_LIT:utf-8>' ) <EOL> return self . reason <EOL> def __unicode__ ( self ) : <EOL> return self . reason . decode ( self . encoding ) <EOL> class PingControlMessage ( Message ) : <EOL> def __init__ ( self , data = None ) : <EOL> Message . __init__ ( self , OPCODE_PING , data ) <EOL> class PongControlMessage ( Message ) : <EOL> def __init__ ( self , data ) : <EOL> Message . __init__ ( self , OPCODE_PONG , data ) </s>
<s> import sys <EOL> import base64 <EOL> import time <EOL> import urllib <EOL> from struct import unpack <EOL> from threading import Lock <EOL> from binascii import hexlify <EOL> from urlparse import urlparse <EOL> from mod_python import apache <EOL> from PyAuthenNTLM2 . ntlm_dc_proxy import NTLM_DC_Proxy <EOL> from PyAuthenNTLM2 . ntlm_ad_proxy import NTLM_AD_Proxy <EOL> use_basic_auth = True <EOL> try : <EOL> from PyAuthenNTLM2 . ntlm_client import NTLM_Client <EOL> except ImportError : <EOL> use_basic_auth = False <EOL> class CacheConnections : <EOL> def __init__ ( self ) : <EOL> self . _mutex = Lock ( ) <EOL> self . _cache = { } <EOL> def __len__ ( self ) : <EOL> return len ( self . _cache ) <EOL> def remove ( self , id ) : <EOL> self . _mutex . acquire ( ) <EOL> ( proxy , ts ) = self . _cache . get ( id , ( None , None ) ) <EOL> if proxy : <EOL> proxy . close ( ) <EOL> del self . _cache [ id ] <EOL> self . _mutex . release ( ) <EOL> def add ( self , id , proxy ) : <EOL> self . _mutex . acquire ( ) <EOL> self . _cache [ id ] = ( proxy , int ( time . time ( ) ) ) <EOL> self . _mutex . release ( ) <EOL> def clean ( self ) : <EOL> now = int ( time . time ( ) ) <EOL> self . _mutex . acquire ( ) <EOL> for id , conn in self . _cache . items ( ) : <EOL> if conn [ <NUM_LIT:1> ] + <NUM_LIT> < now : <EOL> conn [ <NUM_LIT:0> ] . close ( ) <EOL> del self . _cache [ id ] <EOL> self . _mutex . release ( ) <EOL> def has_key ( self , id ) : <EOL> return self . _cache . has_key ( id ) <EOL> def get_proxy ( self , id ) : <EOL> self . _mutex . acquire ( ) <EOL> proxy = self . _cache [ id ] [ <NUM_LIT:0> ] <EOL> self . _mutex . release ( ) <EOL> return proxy <EOL> class CacheGroups : <EOL> def __init__ ( self ) : <EOL> self . _mutex = Lock ( ) <EOL> self . _cache = { } <EOL> def __len__ ( self ) : <EOL> return len ( self . _cache ) <EOL> def add ( self , group , user ) : <EOL> self . _mutex . acquire ( ) <EOL> if not self . _cache . has_key ( group ) : <EOL> self . _cache [ group ] = { } <EOL> self . _cache [ group ] [ user ] = int ( time . time ( ) ) <EOL> self . _mutex . release ( ) <EOL> def clean ( self ) : <EOL> now = int ( time . time ( ) ) <EOL> self . _mutex . acquire ( ) <EOL> old = [ ] <EOL> for group , members in self . _cache . items ( ) : <EOL> for user in members : <EOL> if members [ user ] + <NUM_LIT:3> * <NUM_LIT> * <NUM_LIT> < now : <EOL> old . append ( ( group , user ) ) <EOL> for group , user in old : <EOL> del self . _cache [ group ] [ user ] <EOL> self . _mutex . release ( ) <EOL> def has ( self , group , user ) : <EOL> if not self . _cache . has_key ( group ) : <EOL> return False <EOL> return self . _cache [ group ] . has_key ( user ) <EOL> cache = CacheConnections ( ) <EOL> cacheGroups = CacheGroups ( ) <EOL> def ntlm_message_type ( msg ) : <EOL> if not msg . startswith ( '<STR_LIT>' ) or len ( msg ) < <NUM_LIT:12> : <EOL> raise RuntimeError ( "<STR_LIT>" % hexlify ( msg ) ) <EOL> msg_type = unpack ( '<STR_LIT>' , msg [ <NUM_LIT:8> : <NUM_LIT:8> + <NUM_LIT:4> ] ) [ <NUM_LIT:0> ] <EOL> if msg_type not in ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) : <EOL> raise RuntimeError ( "<STR_LIT>" % msg_type ) <EOL> return msg_type <EOL> def parse_ntlm_authenticate ( msg ) : <EOL> '''<STR_LIT>''' <EOL> NTLMSSP_NEGOTIATE_UNICODE = <NUM_LIT> <EOL> idx = <NUM_LIT> <EOL> length , offset = unpack ( '<STR_LIT>' , msg [ idx : idx + <NUM_LIT:8> ] ) <EOL> domain = msg [ offset : offset + length ] <EOL> idx += <NUM_LIT:8> <EOL> length , offset = unpack ( '<STR_LIT>' , msg [ idx : idx + <NUM_LIT:8> ] ) <EOL> username = msg [ offset : offset + length ] <EOL> idx += <NUM_LIT> <EOL> flags = unpack ( '<STR_LIT>' , msg [ idx : idx + <NUM_LIT:4> ] ) [ <NUM_LIT:0> ] <EOL> if flags & NTLMSSP_NEGOTIATE_UNICODE : <EOL> domain = str ( domain . decode ( '<STR_LIT>' ) ) <EOL> username = str ( username . decode ( '<STR_LIT>' ) ) <EOL> return username , domain <EOL> def set_remote_user ( req , username , domain ) : <EOL> format = req . get_options ( ) . get ( '<STR_LIT>' , '<STR_LIT>' ) . lower ( ) <EOL> if format == '<STR_LIT>' : <EOL> req . user = domain + '<STR_LIT:\\>' + username <EOL> else : <EOL> req . user = username <EOL> def decode_http_authorization_header ( auth ) : <EOL> '''<STR_LIT>''' <EOL> ah = auth . split ( '<STR_LIT:U+0020>' ) <EOL> if len ( ah ) == <NUM_LIT:2> : <EOL> b64 = base64 . b64decode ( ah [ <NUM_LIT:1> ] ) <EOL> if ah [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> return ( '<STR_LIT>' , b64 ) <EOL> elif ah [ <NUM_LIT:0> ] == '<STR_LIT>' and use_basic_auth : <EOL> ( user , password ) = b64 . split ( '<STR_LIT::>' ) <EOL> return ( '<STR_LIT>' , user , password ) <EOL> return False <EOL> def handle_unauthorized ( req ) : <EOL> '''<STR_LIT>''' <EOL> req . err_headers_out . add ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> if use_basic_auth : <EOL> req . err_headers_out . add ( '<STR_LIT>' , '<STR_LIT>' % req . auth_name ( ) ) <EOL> req . err_headers_out . add ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> return apache . HTTP_UNAUTHORIZED <EOL> def connect_to_proxy ( req , type1 ) : <EOL> '''<STR_LIT>''' <EOL> try : <EOL> domain = req . get_options ( ) [ '<STR_LIT>' ] <EOL> pdc = req . get_options ( ) [ '<STR_LIT>' ] <EOL> bdc = req . get_options ( ) . get ( '<STR_LIT>' , False ) <EOL> except KeyError , e : <EOL> req . log_error ( '<STR_LIT>' % str ( e ) , apache . APLOG_CRIT ) <EOL> raise <EOL> ntlm_challenge = None <EOL> for server in ( pdc , bdc ) : <EOL> if not server : continue <EOL> try : <EOL> if server . startswith ( '<STR_LIT>' ) : <EOL> url = urlparse ( server ) <EOL> decoded_path = urllib . unquote ( url . path ) [ <NUM_LIT:1> : ] <EOL> req . log_error ( '<STR_LIT>' % <EOL> ( url . netloc , domain , decoded_path ) , apache . APLOG_INFO ) <EOL> proxy = NTLM_AD_Proxy ( url . netloc , domain , base = decoded_path ) <EOL> else : <EOL> req . log_error ( '<STR_LIT>' % <EOL> ( server , domain ) , apache . APLOG_INFO ) <EOL> proxy = NTLM_DC_Proxy ( server , domain ) <EOL> ntlm_challenge = proxy . negotiate ( type1 ) <EOL> except Exception , e : <EOL> req . log_error ( '<STR_LIT>' % ( server , str ( e ) ) , apache . APLOG_CRIT ) <EOL> if ntlm_challenge : break <EOL> proxy . close ( ) <EOL> else : <EOL> raise RuntimeError ( "<STR_LIT>" ) <EOL> return ( proxy , ntlm_challenge ) <EOL> def handle_type1 ( req , ntlm_message ) : <EOL> '''<STR_LIT>''' <EOL> cache . remove ( req . connection . id ) <EOL> cache . clean ( ) <EOL> try : <EOL> ( proxy , ntlm_challenge ) = connect_to_proxy ( req , ntlm_message ) <EOL> except Exception , e : <EOL> return apache . HTTP_INTERNAL_SERVER_ERROR <EOL> cache . add ( req . connection . id , proxy ) <EOL> req . err_headers_out . add ( '<STR_LIT>' , "<STR_LIT>" + base64 . b64encode ( ntlm_challenge ) ) <EOL> return apache . HTTP_UNAUTHORIZED <EOL> def check_authorization ( req , username , proxy ) : <EOL> '''<STR_LIT>''' <EOL> rules = '<STR_LIT>' . join ( req . requires ( ) ) . strip ( ) <EOL> if rules == '<STR_LIT>' or cacheGroups . has ( rules , username ) : <EOL> return True <EOL> groups = [ ] <EOL> for r in req . requires ( ) : <EOL> if r . lower ( ) . startswith ( "<STR_LIT>" ) : <EOL> users = [ u . strip ( ) for u in r [ <NUM_LIT:5> : ] . split ( "<STR_LIT:U+002C>" ) ] <EOL> if username in users : <EOL> req . log_error ( '<STR_LIT>' % <EOL> ( username , req . unparsed_uri ) , apache . APLOG_INFO ) <EOL> return True <EOL> if r . lower ( ) . startswith ( "<STR_LIT>" ) : <EOL> groups += [ g . strip ( ) for g in r [ <NUM_LIT:6> : ] . split ( "<STR_LIT:U+002C>" ) ] <EOL> if groups : <EOL> try : <EOL> res = proxy . check_membership ( username , groups ) <EOL> except Exception , e : <EOL> req . log_error ( '<STR_LIT>' % ( username , str ( groups ) , req . unparsed_uri , str ( e ) ) ) <EOL> if res : <EOL> cacheGroups . add ( rules , username ) <EOL> req . log_error ( '<STR_LIT>' % <EOL> ( username , str ( groups ) , req . unparsed_uri ) , apache . APLOG_INFO ) <EOL> return True <EOL> req . log_error ( '<STR_LIT>' % <EOL> ( username , str ( groups ) , req . unparsed_uri ) ) <EOL> else : <EOL> req . log_error ( '<STR_LIT>' % <EOL> ( username , req . unparsed_uri ) ) <EOL> return False <EOL> def handle_type3 ( req , ntlm_message ) : <EOL> '''<STR_LIT>''' <EOL> proxy = cache . get_proxy ( req . connection . id ) <EOL> try : <EOL> user , domain = parse_ntlm_authenticate ( ntlm_message ) <EOL> if not domain : <EOL> domain = req . get_options ( ) . get ( '<STR_LIT>' , req . auth_name ( ) ) <EOL> result = proxy . authenticate ( ntlm_message ) <EOL> except Exception , e : <EOL> req . log_error ( '<STR_LIT>' % str ( e ) , apache . APLOG_CRIT ) <EOL> user , domain = '<STR_LIT>' , '<STR_LIT>' <EOL> result = False <EOL> if not result : <EOL> cache . remove ( req . connection . id ) <EOL> req . log_error ( '<STR_LIT>' % ( <EOL> domain , user , req . unparsed_uri ) ) <EOL> return handle_unauthorized ( req ) <EOL> req . log_error ( '<STR_LIT>' % ( user , domain , req . unparsed_uri ) , apache . APLOG_NOTICE ) <EOL> set_remote_user ( req , user , domain ) <EOL> result = check_authorization ( req , user , proxy ) <EOL> cache . remove ( req . connection . id ) <EOL> if not result : <EOL> return apache . HTTP_FORBIDDEN <EOL> req . connection . notes . add ( '<STR_LIT>' , req . user ) <EOL> return apache . OK <EOL> def handle_basic ( req , user , password ) : <EOL> '''<STR_LIT>''' <EOL> req . log_error ( '<STR_LIT>' % ( req . unparsed_uri ) ) <EOL> domain = req . get_options ( ) . get ( '<STR_LIT>' , req . auth_name ( ) ) <EOL> client = NTLM_Client ( user , domain , password ) <EOL> type1 = client . make_ntlm_negotiate ( ) <EOL> try : <EOL> ( proxy , type2 ) = connect_to_proxy ( req , type1 ) <EOL> except Exception , e : <EOL> return apache . HTTP_INTERNAL_SERVER_ERROR <EOL> client . parse_ntlm_challenge ( type2 ) <EOL> type3 = client . make_ntlm_authenticate ( ) <EOL> if not proxy . authenticate ( type3 ) : <EOL> proxy . close ( ) <EOL> req . log_error ( '<STR_LIT>' % ( <EOL> user , domain , req . unparsed_uri ) ) <EOL> return handle_unauthorized ( req ) <EOL> req . log_error ( '<STR_LIT>' % ( user , domain , req . unparsed_uri ) , apache . APLOG_NOTICE ) <EOL> set_remote_user ( req , user , domain ) <EOL> result = check_authorization ( req , user , proxy ) <EOL> proxy . close ( ) <EOL> if not result : <EOL> return apache . HTTP_FORBIDDEN <EOL> req . connection . notes . add ( '<STR_LIT>' , user + password ) <EOL> return apache . OK <EOL> def authenhandler ( req ) : <EOL> '''<STR_LIT>''' <EOL> req . log_error ( "<STR_LIT>" % ( <EOL> req . connection . id , req . method , req . unparsed_uri , len ( cache ) ) , apache . APLOG_INFO ) <EOL> auth_headers = req . headers_in . get ( '<STR_LIT>' , [ ] ) <EOL> if not isinstance ( auth_headers , list ) : <EOL> auth_headers = [ auth_headers ] <EOL> user = req . connection . notes . get ( '<STR_LIT>' , None ) <EOL> if user : <EOL> req . user = user <EOL> if auth_headers : <EOL> req . log_error ( '<STR_LIT>' % ( <EOL> req . connection . id , req . method , req . clength , auth_headers ) , apache . APLOG_INFO ) <EOL> if req . method != '<STR_LIT:POST>' or req . clength > <NUM_LIT:0> : <EOL> return apache . OK <EOL> else : <EOL> return apache . OK <EOL> if not auth_headers : <EOL> return handle_unauthorized ( req ) <EOL> try : <EOL> for ah in auth_headers : <EOL> ah_data = decode_http_authorization_header ( ah ) <EOL> if ah_data : <EOL> break <EOL> except : <EOL> ah_data = False <EOL> if not ah_data : <EOL> req . log_error ( '<STR_LIT>' % req . unparsed_uri , apache . APLOG_ERR ) <EOL> return apache . HTTP_BAD_REQUEST <EOL> if ah_data [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> userpwd = req . connection . notes . get ( '<STR_LIT>' , None ) <EOL> if userpwd : <EOL> if userpwd != ah_data [ <NUM_LIT:1> ] + ah_data [ <NUM_LIT:2> ] : <EOL> return handle_unauthorized ( req ) <EOL> domain = req . get_options ( ) . get ( '<STR_LIT>' , req . auth_name ( ) ) <EOL> set_remote_user ( req , ah_data [ <NUM_LIT:1> ] , domain ) <EOL> return apache . OK <EOL> return handle_basic ( req , ah_data [ <NUM_LIT:1> ] , ah_data [ <NUM_LIT:2> ] ) <EOL> try : <EOL> ntlm_version = ntlm_message_type ( ah_data [ <NUM_LIT:1> ] ) <EOL> if ntlm_version == <NUM_LIT:1> : <EOL> return handle_type1 ( req , ah_data [ <NUM_LIT:1> ] ) <EOL> if ntlm_version == <NUM_LIT:3> : <EOL> if cache . has_key ( req . connection . id ) : <EOL> return handle_type3 ( req , ah_data [ <NUM_LIT:1> ] ) <EOL> req . log_error ( '<STR_LIT>' % <EOL> ( req . unparsed_uri ) , apache . APLOG_INFO ) <EOL> return handle_unauthorized ( req ) <EOL> error = '<STR_LIT>' <EOL> except Exception , e : <EOL> error = str ( e ) <EOL> req . log_error ( '<STR_LIT>' % <EOL> ( req . unparsed_uri , error ) , apache . APLOG_ERR ) <EOL> return apache . HTTP_BAD_REQUEST </s>
<s> from celery import Celery <EOL> def create_celery_app ( app ) : <EOL> if app . config . get ( '<STR_LIT>' ) : <EOL> app . celery = Celery ( __name__ , broker = app . config [ '<STR_LIT>' ] ) <EOL> app . celery . conf . update ( app . config ) <EOL> taskbase = app . celery . Task <EOL> class ContextTask ( taskbase ) : <EOL> abstract = True <EOL> def __call__ ( self , * args , ** kwargs ) : <EOL> with app . app_context ( ) : <EOL> return taskbase . __call__ ( self , * args , ** kwargs ) <EOL> app . celery . Task = ContextTask </s>
<s> import unittest <EOL> import os <EOL> import sys <EOL> import json <EOL> sys . path . append ( os . path . dirname ( os . path . realpath ( __file__ ) . rsplit ( '<STR_LIT:/>' , <NUM_LIT:2> ) [ <NUM_LIT:0> ] ) ) <EOL> from app import create_app <EOL> app = create_app ( '<STR_LIT>' ) <EOL> add_data = """<STR_LIT>""" <EOL> update_data = """<STR_LIT>""" <EOL> class TestUsers ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . app = app . test_client ( ) <EOL> def test_01_add ( self ) : <EOL> rv = self . app . post ( '<STR_LIT>' , data = add_data , <EOL> content_type = "<STR_LIT:application/json>" ) <EOL> assert rv . status_code == <NUM_LIT> <EOL> def test_02_read_update ( self ) : <EOL> request = self . app . get ( '<STR_LIT>' ) <EOL> dict = json . loads ( request . data . decode ( '<STR_LIT:utf-8>' ) ) <EOL> id = dict [ '<STR_LIT:data>' ] [ <NUM_LIT:0> ] [ '<STR_LIT:id>' ] <EOL> rv = self . app . patch ( '<STR_LIT>' . format ( id ) , <EOL> data = update_data , content_type = "<STR_LIT:application/json>" ) <EOL> assert rv . status_code == <NUM_LIT:200> <EOL> def test_03_delete ( self ) : <EOL> request = self . app . get ( '<STR_LIT>' ) <EOL> dict = json . loads ( request . data . decode ( '<STR_LIT:utf-8>' ) ) <EOL> id = dict [ '<STR_LIT:data>' ] [ <NUM_LIT:0> ] [ '<STR_LIT:id>' ] <EOL> rv = self . app . delete ( '<STR_LIT>' . format ( id ) ) <EOL> assert rv . status_code == <NUM_LIT> <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> unittest . main ( ) </s>
<s> """<STR_LIT>""" <EOL> def tokenProgressFunc ( state = "<STR_LIT>" , action = None , text = None , tick = <NUM_LIT:0> ) : <EOL> """<STR_LIT>""" <EOL> print ( "<STR_LIT>" % ( state , str ( title ) , str ( text ) , str ( tick ) ) ) <EOL> def build ( <EOL> documentPath , <EOL> outputUFOFormatVersion = <NUM_LIT:2> , <EOL> roundGeometry = True , <EOL> verbose = True , <EOL> logPath = None , <EOL> progressFunc = None , <EOL> ) : <EOL> """<STR_LIT>""" <EOL> from mutatorMath . ufo . document import DesignSpaceDocumentReader <EOL> import os , glob <EOL> if os . path . isdir ( documentPath ) : <EOL> todo = glob . glob ( os . path . join ( documentPath , "<STR_LIT>" ) ) <EOL> else : <EOL> todo = [ documentPath ] <EOL> results = [ ] <EOL> for path in todo : <EOL> reader = DesignSpaceDocumentReader ( <EOL> path , <EOL> ufoVersion = outputUFOFormatVersion , <EOL> roundGeometry = roundGeometry , <EOL> verbose = verbose , <EOL> logPath = logPath , <EOL> progressFunc = progressFunc <EOL> ) <EOL> reader . process ( ) <EOL> results . append ( reader . results ) <EOL> reader = None <EOL> return results </s>
<s> from django . core . management . base import BaseCommand <EOL> from chronam . core . management . commands import configure_logging <EOL> from chronam . core . index import index_pages <EOL> configure_logging ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> class Command ( BaseCommand ) : <EOL> def handle ( self , ** options ) : <EOL> index_pages ( ) </s>
<s> import os <EOL> from django . conf import settings <EOL> from django . http import HttpResponse <EOL> class HttpResponseServiceUnavailable ( HttpResponse ) : <EOL> status_code = <NUM_LIT> <EOL> class TooBusyMiddleware ( object ) : <EOL> def process_request ( self , request ) : <EOL> one , five , fifteen = os . getloadavg ( ) <EOL> if one > settings . TOO_BUSY_LOAD_AVERAGE : <EOL> return HttpResponseServiceUnavailable ( """<STR_LIT>""" ) <EOL> return None </s>
<s> from os . path import dirname , join <EOL> from django . test import TestCase <EOL> from chronam . core . ocr_extractor import ocr_extractor <EOL> class OcrExtractorTests ( TestCase ) : <EOL> def test_extractor ( self ) : <EOL> dir = join ( dirname ( dirname ( __file__ ) ) , '<STR_LIT>' ) <EOL> ocr_file = join ( dir , '<STR_LIT>' ) <EOL> text , coord_info = ocr_extractor ( ocr_file ) <EOL> coords = coord_info [ "<STR_LIT>" ] <EOL> expected_text = { "<STR_LIT>" : file ( join ( dir , '<STR_LIT>' ) ) . read ( ) . decode ( '<STR_LIT:utf-8>' ) } <EOL> self . assertEqual ( text , expected_text ) <EOL> self . assertEqual ( len ( coords . keys ( ) ) , <NUM_LIT> ) <EOL> self . assertEqual ( len ( coords [ '<STR_LIT>' ] ) , <NUM_LIT:3> ) <EOL> self . assertTrue ( coords . has_key ( '<STR_LIT>' ) ) <EOL> self . assertTrue ( not coords . has_key ( '<STR_LIT>' ) ) </s>
<s> """<STR_LIT>""" <EOL> import logging <EOL> from . tests import * <EOL> logger = logging . getLogger ( "<STR_LIT>" ) <EOL> logger . setLevel ( logging . DEBUG ) <EOL> handler = logging . StreamHandler ( ) <EOL> formatter = logging . Formatter ( "<STR_LIT>" ) <EOL> handler . setFormatter ( formatter ) <EOL> logger . addHandler ( handler ) </s>
<s> """<STR_LIT>""" <EOL> from __future__ import print_function <EOL> import argparse <EOL> import datetime <EOL> import json <EOL> import multiprocessing <EOL> import os <EOL> import random <EOL> import sys <EOL> import threading <EOL> import time <EOL> import numpy as np <EOL> from PIL import Image <EOL> import six <EOL> import six . moves . cPickle as pickle <EOL> from six . moves import queue <EOL> import chainer <EOL> from chainer import computational_graph <EOL> from chainer import cuda <EOL> from chainer import optimizers <EOL> from chainer import serializers <EOL> parser = argparse . ArgumentParser ( <EOL> description = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT:train>' , help = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT>' , help = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , default = '<STR_LIT>' , <EOL> help = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , default = '<STR_LIT>' , <EOL> help = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , type = int , default = <NUM_LIT:32> , <EOL> help = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , type = int , default = <NUM_LIT> , <EOL> help = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , default = <NUM_LIT:10> , type = int , <EOL> help = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , default = - <NUM_LIT:1> , type = int , <EOL> help = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , default = <NUM_LIT:20> , type = int , <EOL> help = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , default = '<STR_LIT:.>' , <EOL> help = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , default = '<STR_LIT>' , <EOL> help = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , default = '<STR_LIT:state>' , <EOL> help = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT>' , default = '<STR_LIT>' , <EOL> help = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT>' , default = '<STR_LIT>' , <EOL> help = '<STR_LIT>' ) <EOL> args = parser . parse_args ( ) <EOL> if args . gpu >= <NUM_LIT:0> : <EOL> cuda . check_cuda_available ( ) <EOL> xp = cuda . cupy if args . gpu >= <NUM_LIT:0> else np <EOL> assert <NUM_LIT> % args . val_batchsize == <NUM_LIT:0> <EOL> def load_image_list ( path , root ) : <EOL> tuples = [ ] <EOL> for line in open ( path ) : <EOL> pair = line . strip ( ) . split ( ) <EOL> tuples . append ( ( os . path . join ( root , pair [ <NUM_LIT:0> ] ) , np . int32 ( pair [ <NUM_LIT:1> ] ) ) ) <EOL> return tuples <EOL> train_list = load_image_list ( args . train , args . root ) <EOL> val_list = load_image_list ( args . val , args . root ) <EOL> mean_image = pickle . load ( open ( args . mean , '<STR_LIT:rb>' ) ) <EOL> if args . arch == '<STR_LIT>' : <EOL> import nin <EOL> model = nin . NIN ( ) <EOL> elif args . arch == '<STR_LIT>' : <EOL> import alex <EOL> model = alex . Alex ( ) <EOL> elif args . arch == '<STR_LIT>' : <EOL> import alexbn <EOL> model = alexbn . AlexBN ( ) <EOL> elif args . arch == '<STR_LIT>' : <EOL> import googlenet <EOL> model = googlenet . GoogLeNet ( ) <EOL> elif args . arch == '<STR_LIT>' : <EOL> import googlenetbn <EOL> model = googlenetbn . GoogLeNetBN ( ) <EOL> else : <EOL> raise ValueError ( '<STR_LIT>' ) <EOL> if args . gpu >= <NUM_LIT:0> : <EOL> cuda . get_device ( args . gpu ) . use ( ) <EOL> model . to_gpu ( ) <EOL> optimizer = optimizers . MomentumSGD ( lr = <NUM_LIT> , momentum = <NUM_LIT> ) <EOL> optimizer . setup ( model ) <EOL> if args . initmodel : <EOL> print ( '<STR_LIT>' , args . initmodel ) <EOL> serializers . load_hdf5 ( args . initmodel , model ) <EOL> if args . resume : <EOL> print ( '<STR_LIT>' , args . resume ) <EOL> serializers . load_hdf5 ( args . resume , optimizer ) <EOL> data_q = queue . Queue ( maxsize = <NUM_LIT:1> ) <EOL> res_q = queue . Queue ( ) <EOL> cropwidth = <NUM_LIT> - model . insize <EOL> def read_image ( path , center = False , flip = False ) : <EOL> image = np . asarray ( Image . open ( path ) ) . transpose ( <NUM_LIT:2> , <NUM_LIT:0> , <NUM_LIT:1> ) <EOL> if center : <EOL> top = left = cropwidth / <NUM_LIT:2> <EOL> else : <EOL> top = random . randint ( <NUM_LIT:0> , cropwidth - <NUM_LIT:1> ) <EOL> left = random . randint ( <NUM_LIT:0> , cropwidth - <NUM_LIT:1> ) <EOL> bottom = model . insize + top <EOL> right = model . insize + left <EOL> image = image [ : , top : bottom , left : right ] . astype ( np . float32 ) <EOL> image -= mean_image [ : , top : bottom , left : right ] <EOL> image /= <NUM_LIT:255> <EOL> if flip and random . randint ( <NUM_LIT:0> , <NUM_LIT:1> ) == <NUM_LIT:0> : <EOL> return image [ : , : , : : - <NUM_LIT:1> ] <EOL> else : <EOL> return image <EOL> def feed_data ( ) : <EOL> i = <NUM_LIT:0> <EOL> count = <NUM_LIT:0> <EOL> x_batch = np . ndarray ( <EOL> ( args . batchsize , <NUM_LIT:3> , model . insize , model . insize ) , dtype = np . float32 ) <EOL> y_batch = np . ndarray ( ( args . batchsize , ) , dtype = np . int32 ) <EOL> val_x_batch = np . ndarray ( <EOL> ( args . val_batchsize , <NUM_LIT:3> , model . insize , model . insize ) , dtype = np . float32 ) <EOL> val_y_batch = np . ndarray ( ( args . val_batchsize , ) , dtype = np . int32 ) <EOL> batch_pool = [ None ] * args . batchsize <EOL> val_batch_pool = [ None ] * args . val_batchsize <EOL> pool = multiprocessing . Pool ( args . loaderjob ) <EOL> data_q . put ( '<STR_LIT:train>' ) <EOL> for epoch in six . moves . range ( <NUM_LIT:1> , <NUM_LIT:1> + args . epoch ) : <EOL> print ( '<STR_LIT>' , epoch , file = sys . stderr ) <EOL> print ( '<STR_LIT>' , optimizer . lr , file = sys . stderr ) <EOL> perm = np . random . permutation ( len ( train_list ) ) <EOL> for idx in perm : <EOL> path , label = train_list [ idx ] <EOL> batch_pool [ i ] = pool . apply_async ( read_image , ( path , False , True ) ) <EOL> y_batch [ i ] = label <EOL> i += <NUM_LIT:1> <EOL> if i == args . batchsize : <EOL> for j , x in enumerate ( batch_pool ) : <EOL> x_batch [ j ] = x . get ( ) <EOL> data_q . put ( ( x_batch . copy ( ) , y_batch . copy ( ) ) ) <EOL> i = <NUM_LIT:0> <EOL> count += <NUM_LIT:1> <EOL> if count % <NUM_LIT:1000> == <NUM_LIT:0> : <EOL> data_q . put ( '<STR_LIT>' ) <EOL> j = <NUM_LIT:0> <EOL> for path , label in val_list : <EOL> val_batch_pool [ j ] = pool . apply_async ( <EOL> read_image , ( path , True , False ) ) <EOL> val_y_batch [ j ] = label <EOL> j += <NUM_LIT:1> <EOL> if j == args . val_batchsize : <EOL> for k , x in enumerate ( val_batch_pool ) : <EOL> val_x_batch [ k ] = x . get ( ) <EOL> data_q . put ( ( val_x_batch . copy ( ) , val_y_batch . copy ( ) ) ) <EOL> j = <NUM_LIT:0> <EOL> data_q . put ( '<STR_LIT:train>' ) <EOL> optimizer . lr *= <NUM_LIT> <EOL> pool . close ( ) <EOL> pool . join ( ) <EOL> data_q . put ( '<STR_LIT:end>' ) <EOL> def log_result ( ) : <EOL> train_count = <NUM_LIT:0> <EOL> train_cur_loss = <NUM_LIT:0> <EOL> train_cur_accuracy = <NUM_LIT:0> <EOL> begin_at = time . time ( ) <EOL> val_begin_at = None <EOL> while True : <EOL> result = res_q . get ( ) <EOL> if result == '<STR_LIT:end>' : <EOL> print ( file = sys . stderr ) <EOL> break <EOL> elif result == '<STR_LIT:train>' : <EOL> print ( file = sys . stderr ) <EOL> train = True <EOL> if val_begin_at is not None : <EOL> begin_at += time . time ( ) - val_begin_at <EOL> val_begin_at = None <EOL> continue <EOL> elif result == '<STR_LIT>' : <EOL> print ( file = sys . stderr ) <EOL> train = False <EOL> val_count = val_loss = val_accuracy = <NUM_LIT:0> <EOL> val_begin_at = time . time ( ) <EOL> continue <EOL> loss , accuracy = result <EOL> if train : <EOL> train_count += <NUM_LIT:1> <EOL> duration = time . time ( ) - begin_at <EOL> throughput = train_count * args . batchsize / duration <EOL> sys . stderr . write ( <EOL> '<STR_LIT>' <EOL> . format ( train_count , train_count * args . batchsize , <EOL> datetime . timedelta ( seconds = duration ) , throughput ) ) <EOL> train_cur_loss += loss <EOL> train_cur_accuracy += accuracy <EOL> if train_count % <NUM_LIT:1000> == <NUM_LIT:0> : <EOL> mean_loss = train_cur_loss / <NUM_LIT:1000> <EOL> mean_error = <NUM_LIT:1> - train_cur_accuracy / <NUM_LIT:1000> <EOL> print ( file = sys . stderr ) <EOL> print ( json . dumps ( { '<STR_LIT:type>' : '<STR_LIT:train>' , '<STR_LIT>' : train_count , <EOL> '<STR_LIT:error>' : mean_error , '<STR_LIT>' : mean_loss } ) ) <EOL> sys . stdout . flush ( ) <EOL> train_cur_loss = <NUM_LIT:0> <EOL> train_cur_accuracy = <NUM_LIT:0> <EOL> else : <EOL> val_count += args . val_batchsize <EOL> duration = time . time ( ) - val_begin_at <EOL> throughput = val_count / duration <EOL> sys . stderr . write ( <EOL> '<STR_LIT>' <EOL> . format ( val_count / args . val_batchsize , val_count , <EOL> datetime . timedelta ( seconds = duration ) , throughput ) ) <EOL> val_loss += loss <EOL> val_accuracy += accuracy <EOL> if val_count == <NUM_LIT> : <EOL> mean_loss = val_loss * args . val_batchsize / <NUM_LIT> <EOL> mean_error = <NUM_LIT:1> - val_accuracy * args . val_batchsize / <NUM_LIT> <EOL> print ( file = sys . stderr ) <EOL> print ( json . dumps ( { '<STR_LIT:type>' : '<STR_LIT>' , '<STR_LIT>' : train_count , <EOL> '<STR_LIT:error>' : mean_error , '<STR_LIT>' : mean_loss } ) ) <EOL> sys . stdout . flush ( ) <EOL> def train_loop ( ) : <EOL> graph_generated = False <EOL> while True : <EOL> while data_q . empty ( ) : <EOL> time . sleep ( <NUM_LIT:0.1> ) <EOL> inp = data_q . get ( ) <EOL> if inp == '<STR_LIT:end>' : <EOL> res_q . put ( '<STR_LIT:end>' ) <EOL> break <EOL> elif inp == '<STR_LIT:train>' : <EOL> res_q . put ( '<STR_LIT:train>' ) <EOL> model . train = True <EOL> continue <EOL> elif inp == '<STR_LIT>' : <EOL> res_q . put ( '<STR_LIT>' ) <EOL> serializers . save_hdf5 ( args . out , model ) <EOL> serializers . save_hdf5 ( args . outstate , optimizer ) <EOL> model . train = False <EOL> continue <EOL> volatile = '<STR_LIT>' if model . train else '<STR_LIT>' <EOL> x = chainer . Variable ( xp . asarray ( inp [ <NUM_LIT:0> ] ) , volatile = volatile ) <EOL> t = chainer . Variable ( xp . asarray ( inp [ <NUM_LIT:1> ] ) , volatile = volatile ) <EOL> if model . train : <EOL> optimizer . update ( model , x , t ) <EOL> if not graph_generated : <EOL> with open ( '<STR_LIT>' , '<STR_LIT:w>' ) as o : <EOL> o . write ( computational_graph . build_computational_graph ( <EOL> ( model . loss , ) ) . dump ( ) ) <EOL> print ( '<STR_LIT>' , file = sys . stderr ) <EOL> graph_generated = True <EOL> else : <EOL> model ( x , t ) <EOL> res_q . put ( ( float ( model . loss . data ) , float ( model . accuracy . data ) ) ) <EOL> del x , t <EOL> feeder = threading . Thread ( target = feed_data ) <EOL> feeder . daemon = True <EOL> feeder . start ( ) <EOL> logger = threading . Thread ( target = log_result ) <EOL> logger . daemon = True <EOL> logger . start ( ) <EOL> train_loop ( ) <EOL> feeder . join ( ) <EOL> logger . join ( ) <EOL> serializers . save_hdf5 ( args . out , model ) <EOL> serializers . save_hdf5 ( args . outstate , optimizer ) </s>
<s> import sys , os <EOL> sys . path . insert ( <NUM_LIT:0> , os . path . abspath ( '<STR_LIT:..>' ) ) <EOL> import local_settings <EOL> extensions = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> templates_path = [ '<STR_LIT>' ] <EOL> source_suffix = '<STR_LIT>' <EOL> master_doc = '<STR_LIT:index>' <EOL> project = u'<STR_LIT>' <EOL> copyright = u'<STR_LIT>' <EOL> html_show_copyright = False <EOL> import djoauth2 <EOL> version = djoauth2 . __version__ <EOL> release = djoauth2 . __version__ <EOL> exclude_patterns = [ '<STR_LIT>' ] <EOL> pygments_style = '<STR_LIT>' <EOL> html_theme = '<STR_LIT:default>' <EOL> html_static_path = [ '<STR_LIT>' ] <EOL> htmlhelp_basename = '<STR_LIT>' <EOL> latex_elements = { <EOL> } <EOL> latex_documents = [ <EOL> ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , <EOL> u'<STR_LIT>' , '<STR_LIT>' ) , <EOL> ] <EOL> man_pages = [ <EOL> ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , <EOL> [ u'<STR_LIT>' ] , <NUM_LIT:1> ) <EOL> ] <EOL> texinfo_documents = [ <EOL> ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , <EOL> u'<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' ) , <EOL> ] <EOL> epub_title = u'<STR_LIT>' <EOL> epub_author = u'<STR_LIT>' <EOL> epub_publisher = u'<STR_LIT>' <EOL> epub_copyright = u'<STR_LIT>' </s>
<s> import asyncio <EOL> from zeroservices import ZeroMQMedium , ResourceService <EOL> from zeroservices . services import get_http_interface <EOL> from zeroservices . discovery import UdpDiscoveryMedium <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> loop = asyncio . get_event_loop ( ) <EOL> medium = ZeroMQMedium ( loop , UdpDiscoveryMedium ) <EOL> service = ResourceService ( '<STR_LIT>' , medium ) <EOL> application = get_http_interface ( service , loop , port = <NUM_LIT> , allowed_origins = "<STR_LIT:*>" ) <EOL> application = loop . run_until_complete ( application ) <EOL> loop . run_until_complete ( service . start ( ) ) <EOL> loop . run_forever ( ) </s>
<s> """<STR_LIT>""" <EOL> import argparse <EOL> import sys <EOL> from trello import TrelloClient <EOL> from slugify import slugify <EOL> from matterllo . utils import config <EOL> from matterllo . utils import logger <EOL> SETTINGS = config ( ) <EOL> LOGGING = logger ( ) <EOL> def main ( ) : <EOL> try : <EOL> parser = argparse . ArgumentParser ( description = "<STR_LIT>" ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , action = '<STR_LIT:store_true>' , help = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , action = '<STR_LIT:store_true>' , help = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT>' , dest = '<STR_LIT>' , action = '<STR_LIT:store_true>' , help = '<STR_LIT>' ) <EOL> args = parser . parse_args ( ) <EOL> if not args . cleanup and not args . update and not args . init : <EOL> print parser . print_help ( ) <EOL> sys . exit ( <NUM_LIT:0> ) <EOL> client = TrelloClient ( api_key = SETTINGS [ '<STR_LIT>' ] , token = SETTINGS [ '<STR_LIT>' ] ) <EOL> trello_boards = client . list_boards ( ) <EOL> boards_name = [ slugify ( b [ '<STR_LIT:name>' ] ) for b in SETTINGS . get ( '<STR_LIT>' , { } ) . values ( ) ] <EOL> if args . cleanup or args . init : <EOL> result = [ h . delete ( ) for h in client . list_hooks ( ) ] <EOL> LOGGING . info ( '<STR_LIT>' . format ( len ( result ) ) ) <EOL> if args . update or args . init : <EOL> for board in trello_boards : <EOL> board_name = slugify ( board . name ) <EOL> if board_name not in boards_name : <EOL> continue <EOL> LOGGING . info ( '<STR_LIT>' . format ( board_name ) ) <EOL> url = SETTINGS [ '<STR_LIT>' ] + '<STR_LIT>' <EOL> result = client . create_hook ( url , board . id ) <EOL> LOGGING . info ( '<STR_LIT>' . format ( board_name , result ) ) <EOL> except Exception as e : <EOL> LOGGING . error ( '<STR_LIT>' . format ( e ) ) <EOL> sys . exit ( <NUM_LIT:1> ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> main ( ) </s>
<s> """<STR_LIT>""" <EOL> from contextlib import contextmanager <EOL> import sys <EOL> import zlib <EOL> try : <EOL> from . import ssl_compat <EOL> except ImportError : <EOL> ssl_compat = None <EOL> _ver = sys . version_info <EOL> is_py2 = _ver [ <NUM_LIT:0> ] == <NUM_LIT:2> <EOL> is_py2_7_9_or_later = _ver [ <NUM_LIT:0> ] >= <NUM_LIT:2> and _ver [ <NUM_LIT:1> ] >= <NUM_LIT:7> and _ver [ <NUM_LIT:2> ] >= <NUM_LIT:9> <EOL> is_py3 = _ver [ <NUM_LIT:0> ] == <NUM_LIT:3> <EOL> is_py3_3 = is_py3 and _ver [ <NUM_LIT:1> ] == <NUM_LIT:3> <EOL> @ contextmanager <EOL> def ignore_missing ( ) : <EOL> try : <EOL> yield <EOL> except ( AttributeError , NotImplementedError ) : <EOL> pass <EOL> if is_py2 : <EOL> if is_py2_7_9_or_later : <EOL> import ssl <EOL> else : <EOL> ssl = ssl_compat <EOL> from urllib import urlencode <EOL> from urlparse import urlparse , urlsplit <EOL> from itertools import imap <EOL> def to_byte ( char ) : <EOL> return ord ( char ) <EOL> def decode_hex ( b ) : <EOL> return b . decode ( '<STR_LIT>' ) <EOL> def write_to_stdout ( data ) : <EOL> sys . stdout . write ( data + '<STR_LIT:\n>' ) <EOL> sys . stdout . flush ( ) <EOL> def zlib_compressobj ( level = <NUM_LIT:6> , method = zlib . DEFLATED , wbits = <NUM_LIT:15> , memlevel = <NUM_LIT:8> , <EOL> strategy = zlib . Z_DEFAULT_STRATEGY ) : <EOL> return zlib . compressobj ( level , method , wbits , memlevel , strategy ) <EOL> unicode = unicode <EOL> bytes = str <EOL> elif is_py3 : <EOL> from urllib . parse import urlencode , urlparse , urlsplit <EOL> imap = map <EOL> def to_byte ( char ) : <EOL> return char <EOL> def decode_hex ( b ) : <EOL> return bytes . fromhex ( b ) <EOL> def write_to_stdout ( data ) : <EOL> sys . stdout . buffer . write ( data + b'<STR_LIT:\n>' ) <EOL> sys . stdout . buffer . flush ( ) <EOL> zlib_compressobj = zlib . compressobj <EOL> if is_py3_3 : <EOL> ssl = ssl_compat <EOL> else : <EOL> import ssl <EOL> unicode = str <EOL> bytes = bytes </s>
<s> """<STR_LIT>""" <EOL> import threading <EOL> import socket <EOL> import sys <EOL> from hyper import HTTP20Connection <EOL> from hyper . compat import ssl <EOL> from hyper . http11 . connection import HTTP11Connection <EOL> from hpack . hpack import Encoder <EOL> from hpack . huffman import HuffmanEncoder <EOL> from hpack . huffman_constants import ( <EOL> REQUEST_CODES , REQUEST_CODES_LENGTH <EOL> ) <EOL> from hyper . tls import NPN_PROTOCOL <EOL> class SocketServerThread ( threading . Thread ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , <EOL> socket_handler , <EOL> host = '<STR_LIT:localhost>' , <EOL> ready_event = None , <EOL> h2 = True , <EOL> secure = True ) : <EOL> threading . Thread . __init__ ( self ) <EOL> self . socket_handler = socket_handler <EOL> self . host = host <EOL> self . secure = secure <EOL> self . ready_event = ready_event <EOL> self . daemon = True <EOL> if self . secure : <EOL> self . cxt = ssl . SSLContext ( ssl . PROTOCOL_SSLv23 ) <EOL> if ssl . HAS_NPN and h2 : <EOL> self . cxt . set_npn_protocols ( [ NPN_PROTOCOL ] ) <EOL> self . cxt . load_cert_chain ( certfile = '<STR_LIT>' , <EOL> keyfile = '<STR_LIT>' ) <EOL> def _start_server ( self ) : <EOL> sock = socket . socket ( ) <EOL> if sys . platform != '<STR_LIT:win32>' : <EOL> sock . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEADDR , <NUM_LIT:1> ) <EOL> if self . secure : <EOL> sock = self . cxt . wrap_socket ( sock , server_side = True ) <EOL> sock . bind ( ( self . host , <NUM_LIT:0> ) ) <EOL> self . port = sock . getsockname ( ) [ <NUM_LIT:1> ] <EOL> sock . listen ( <NUM_LIT:1> ) <EOL> if self . ready_event : <EOL> self . ready_event . set ( ) <EOL> self . socket_handler ( sock ) <EOL> sock . close ( ) <EOL> def _wrap_socket ( self , sock ) : <EOL> raise NotImplementedError ( ) <EOL> def run ( self ) : <EOL> self . server = self . _start_server ( ) <EOL> class SocketLevelTest ( object ) : <EOL> """<STR_LIT>""" <EOL> def set_up ( self , secure = True , proxy = False ) : <EOL> self . host = None <EOL> self . port = None <EOL> self . secure = secure if not proxy else False <EOL> self . proxy = proxy <EOL> self . server_thread = None <EOL> def _start_server ( self , socket_handler ) : <EOL> """<STR_LIT>""" <EOL> ready_event = threading . Event ( ) <EOL> self . server_thread = SocketServerThread ( <EOL> socket_handler = socket_handler , <EOL> ready_event = ready_event , <EOL> h2 = self . h2 , <EOL> secure = self . secure <EOL> ) <EOL> self . server_thread . start ( ) <EOL> ready_event . wait ( ) <EOL> self . host = self . server_thread . host <EOL> self . port = self . server_thread . port <EOL> self . secure = self . server_thread . secure <EOL> def get_connection ( self ) : <EOL> if self . h2 : <EOL> if not self . proxy : <EOL> return HTTP20Connection ( self . host , self . port , self . secure ) <EOL> else : <EOL> return HTTP20Connection ( '<STR_LIT>' , secure = self . secure , <EOL> proxy_host = self . host , <EOL> proxy_port = self . port ) <EOL> else : <EOL> if not self . proxy : <EOL> return HTTP11Connection ( self . host , self . port , self . secure ) <EOL> else : <EOL> return HTTP11Connection ( '<STR_LIT>' , secure = self . secure , <EOL> proxy_host = self . host , <EOL> proxy_port = self . port ) <EOL> def get_encoder ( self ) : <EOL> """<STR_LIT>""" <EOL> e = Encoder ( ) <EOL> e . huffman_coder = HuffmanEncoder ( REQUEST_CODES , REQUEST_CODES_LENGTH ) <EOL> return e <EOL> def tear_down ( self ) : <EOL> """<STR_LIT>""" <EOL> self . server_thread . join ( <NUM_LIT:0.1> ) </s>
<s> import numpy as np <EOL> import lxmls . readers . pos_corpus as pcc <EOL> from os import path <EOL> import pickle <EOL> corpus = pcc . PostagCorpus ( ) <EOL> input_data = path . join ( <EOL> path . dirname ( __file__ ) , <EOL> "<STR_LIT>" ) <EOL> train_seq = corpus . read_sequence_list_conll ( input_data , max_sent_len = <NUM_LIT:15> , max_nr_sent = <NUM_LIT:1000> ) <EOL> pickle . dump ( ( corpus . word_dict , corpus . tag_dict ) , open ( '<STR_LIT>' , '<STR_LIT:w>' ) ) <EOL> with open ( '<STR_LIT>' , '<STR_LIT:w>' ) as output : <EOL> for seq in train_seq : <EOL> words = [ corpus . word_dict . get_label_name ( seq . x [ i ] ) for i in xrange ( len ( seq ) ) ] <EOL> tags = [ corpus . tag_dict . get_label_name ( seq . y [ i ] ) for i in xrange ( len ( seq ) ) ] <EOL> s = '<STR_LIT:U+0020>' . join ( [ '<STR_LIT:_>' . join ( [ word , tag ] ) for word , tag in zip ( words , tags ) ] ) <EOL> output . write ( s + '<STR_LIT:\n>' ) </s>
<s> import sys <EOL> import numpy as np <EOL> from lxmls . parsing . dependency_reader import * <EOL> from lxmls . parsing . dependency_writer import * <EOL> from lxmls . parsing . dependency_features import * <EOL> from lxmls . parsing . dependency_decoder import * <EOL> from lxmls . util . my_math_utils import * <EOL> class DependencyParser ( ) : <EOL> '''<STR_LIT>''' <EOL> def __init__ ( self ) : <EOL> self . trained = False <EOL> self . projective = False <EOL> self . language = "<STR_LIT>" <EOL> self . weights = [ ] <EOL> self . decoder = DependencyDecoder ( ) <EOL> self . reader = DependencyReader ( ) <EOL> self . writer = DependencyWriter ( ) <EOL> self . features = DependencyFeatures ( ) <EOL> def read_data ( self , language ) : <EOL> self . language = language <EOL> self . reader . load ( language ) <EOL> self . features . create_dictionary ( self . reader . train_instances ) <EOL> def train_perceptron ( self , n_epochs ) : <EOL> '''<STR_LIT>''' <EOL> self . weights = np . zeros ( self . features . n_feats ) <EOL> total = np . zeros ( self . features . n_feats ) <EOL> for epoch in range ( n_epochs ) : <EOL> print "<STR_LIT>" . format ( epoch + <NUM_LIT:1> ) <EOL> n_mistakes = <NUM_LIT:0> <EOL> n_tokens = <NUM_LIT:0> <EOL> n_instances = <NUM_LIT:0> <EOL> for instance in self . reader . train_instances : <EOL> feats = self . features . create_features ( instance ) <EOL> scores = self . features . compute_scores ( feats , self . weights ) <EOL> if self . projective : <EOL> heads_pred = self . decoder . parse_proj ( scores ) <EOL> else : <EOL> heads_pred = self . decoder . parse_nonproj ( scores ) <EOL> for m in range ( np . size ( heads_pred ) ) : <EOL> if heads_pred [ m ] != instance . heads [ m ] : <EOL> for f in feats [ instance . heads [ m ] ] [ m ] : <EOL> if f < <NUM_LIT:0> : <EOL> continue <EOL> self . weights [ f ] += <NUM_LIT:1.0> <EOL> for f in feats [ heads_pred [ m ] ] [ m ] : <EOL> if f < <NUM_LIT:0> : <EOL> continue <EOL> self . weights [ f ] -= <NUM_LIT:1.0> <EOL> n_mistakes += <NUM_LIT:1> <EOL> n_tokens += <NUM_LIT:1> <EOL> n_instances += <NUM_LIT:1> <EOL> print "<STR_LIT>" . format ( np . double ( n_tokens - n_mistakes ) / np . double ( n_tokens ) ) <EOL> total += self . weights <EOL> self . weights = total / np . double ( n_epochs ) <EOL> def train_crf_sgd ( self , n_epochs , sigma , eta0 = <NUM_LIT> ) : <EOL> '''<STR_LIT>''' <EOL> self . weights = np . zeros ( self . features . n_feats ) <EOL> t = <NUM_LIT:0> <EOL> t0 = <NUM_LIT:1.0> / ( sigma * eta0 ) <EOL> for epoch in range ( n_epochs ) : <EOL> print "<STR_LIT>" . format ( epoch + <NUM_LIT:1> ) <EOL> n_mistakes = <NUM_LIT:0> <EOL> n_tokens = <NUM_LIT:0> <EOL> n_instances = <NUM_LIT:0> <EOL> objective = <NUM_LIT:0.0> <EOL> for instance in self . reader . train_instances : <EOL> eta = <NUM_LIT:1.0> / ( sigma * ( t + t0 ) ) <EOL> feats = self . features . create_features ( instance ) <EOL> scores = self . features . compute_scores ( feats , self . weights ) <EOL> marginals , logZ = self . decoder . parse_marginals_nonproj ( scores ) <EOL> self . weights -= eta * sigma * self . weights <EOL> for h in range ( np . size ( marginals , <NUM_LIT:0> ) ) : <EOL> for m in range ( <NUM_LIT:1> , np . size ( marginals , <NUM_LIT:1> ) ) : <EOL> if feats [ h ] [ m ] == None : <EOL> continue <EOL> for f in feats [ h ] [ m ] : <EOL> if f < <NUM_LIT:0> : <EOL> continue <EOL> self . weights [ f ] -= eta * marginals [ h , m ] <EOL> score_corr = <NUM_LIT:0.0> <EOL> for m in range ( <NUM_LIT:1> , np . size ( instance . heads ) ) : <EOL> h = instance . heads [ m ] <EOL> score_corr += scores [ h , m ] <EOL> for f in feats [ h ] [ m ] : <EOL> if f < <NUM_LIT:0> : <EOL> continue <EOL> self . weights [ f ] += eta <EOL> objective += <NUM_LIT:0.5> * sigma * np . dot ( self . weights , self . weights ) - score_corr + logZ <EOL> n_instances += <NUM_LIT:1> <EOL> t += <NUM_LIT:1> <EOL> print "<STR_LIT>" . format ( objective / n_instances ) <EOL> def test ( self ) : <EOL> n_mistakes = <NUM_LIT:0> <EOL> n_tokens = <NUM_LIT:0> <EOL> n_instances = <NUM_LIT:0> <EOL> arr_heads_pred = [ ] ; <EOL> for instance in self . reader . test_instances : <EOL> feats = self . features . create_features ( instance ) <EOL> scores = self . features . compute_scores ( feats , self . weights ) <EOL> if self . projective : <EOL> heads_pred = self . decoder . parse_proj ( scores ) <EOL> else : <EOL> heads_pred = self . decoder . parse_nonproj ( scores ) <EOL> for m in range ( np . size ( heads_pred ) ) : <EOL> if heads_pred [ m ] != instance . heads [ m ] : <EOL> for f in feats [ instance . heads [ m ] ] [ m ] : <EOL> if f < <NUM_LIT:0> : <EOL> continue <EOL> for f in feats [ heads_pred [ m ] ] [ m ] : <EOL> if f < <NUM_LIT:0> : <EOL> continue <EOL> n_mistakes += <NUM_LIT:1> <EOL> n_tokens += <NUM_LIT:1> <EOL> n_instances += <NUM_LIT:1> <EOL> arr_heads_pred . append ( heads_pred ) <EOL> print "<STR_LIT>" . format ( n_instances , np . double ( n_tokens - n_mistakes ) / np . double ( n_tokens ) ) <EOL> self . writer . save ( self . language , arr_heads_pred ) </s>
<s> from lxmls . sequences . label_dictionary import * <EOL> import pdb <EOL> class IDFeatures : <EOL> '''<STR_LIT>''' <EOL> def __init__ ( self , dataset ) : <EOL> '''<STR_LIT>''' <EOL> self . feature_dict = LabelDictionary ( ) <EOL> self . feature_list = [ ] <EOL> self . add_features = False <EOL> self . dataset = dataset <EOL> self . node_feature_cache = { } <EOL> self . initial_state_feature_cache = { } <EOL> self . final_state_feature_cache = { } <EOL> self . edge_feature_cache = { } <EOL> def get_num_features ( self ) : <EOL> return len ( self . feature_dict ) <EOL> def build_features ( self ) : <EOL> '''<STR_LIT>''' <EOL> self . add_features = True <EOL> for sequence in self . dataset . seq_list : <EOL> initial_features , transition_features , final_features , emission_features = self . get_sequence_features ( sequence ) <EOL> self . feature_list . append ( [ initial_features , transition_features , final_features , emission_features ] ) <EOL> self . add_features = False <EOL> def get_sequence_features ( self , sequence ) : <EOL> '''<STR_LIT>''' <EOL> emission_features = [ ] <EOL> initial_features = [ ] <EOL> transition_features = [ ] <EOL> final_features = [ ] <EOL> features = [ ] <EOL> features = self . add_initial_features ( sequence , sequence . y [ <NUM_LIT:0> ] , features ) <EOL> initial_features . append ( features ) <EOL> for pos , tag in enumerate ( sequence . y ) : <EOL> features = [ ] <EOL> features = self . add_emission_features ( sequence , pos , sequence . y [ pos ] , features ) <EOL> emission_features . append ( features ) <EOL> if pos > <NUM_LIT:0> : <EOL> prev_tag = sequence . y [ pos - <NUM_LIT:1> ] <EOL> features = [ ] <EOL> features = self . add_transition_features ( sequence , pos - <NUM_LIT:1> , tag , prev_tag , features ) <EOL> transition_features . append ( features ) <EOL> features = [ ] <EOL> features = self . add_final_features ( sequence , sequence . y [ - <NUM_LIT:1> ] , features ) <EOL> final_features . append ( features ) <EOL> return initial_features , transition_features , final_features , emission_features <EOL> def get_emission_features ( self , sequence , pos , y ) : <EOL> all_feat = [ ] <EOL> x = sequence . x [ pos ] <EOL> if ( x not in self . node_feature_cache ) : <EOL> self . node_feature_cache [ x ] = { } <EOL> if ( y not in self . node_feature_cache [ x ] ) : <EOL> node_idx = [ ] <EOL> node_idx = self . add_emission_features ( sequence , pos , y , node_idx ) <EOL> self . node_feature_cache [ x ] [ y ] = node_idx <EOL> idx = self . node_feature_cache [ x ] [ y ] <EOL> all_feat = idx [ : ] <EOL> return all_feat <EOL> def get_transition_features ( self , sequence , pos , y , y_prev ) : <EOL> assert ( pos >= <NUM_LIT:0> and pos < len ( sequence . x ) ) , pdb . set_trace ( ) <EOL> if ( y not in self . edge_feature_cache ) : <EOL> self . edge_feature_cache [ y ] = { } <EOL> if ( y_prev not in self . edge_feature_cache [ y ] ) : <EOL> edge_idx = [ ] <EOL> edge_idx = self . add_transition_features ( sequence , pos , y , y_prev , edge_idx ) <EOL> self . edge_feature_cache [ y ] [ y_prev ] = edge_idx <EOL> return self . edge_feature_cache [ y ] [ y_prev ] <EOL> def get_initial_features ( self , sequence , y ) : <EOL> if ( y not in self . initial_state_feature_cache ) : <EOL> edge_idx = [ ] <EOL> edge_idx = self . add_initial_features ( sequence , y , edge_idx ) <EOL> self . initial_state_feature_cache [ y ] = edge_idx <EOL> return self . initial_state_feature_cache [ y ] <EOL> def get_final_features ( self , sequence , y_prev ) : <EOL> if ( y_prev not in self . final_state_feature_cache ) : <EOL> edge_idx = [ ] <EOL> edge_idx = self . add_final_features ( sequence , y_prev , edge_idx ) <EOL> self . final_state_feature_cache [ y_prev ] = edge_idx <EOL> return self . final_state_feature_cache [ y_prev ] <EOL> def add_initial_features ( self , sequence , y , features ) : <EOL> y_name = self . dataset . y_dict . get_label_name ( y ) <EOL> feat_name = "<STR_LIT>" % ( y_name ) <EOL> feat_id = self . add_feature ( feat_name ) <EOL> if ( feat_id != - <NUM_LIT:1> ) : <EOL> features . append ( feat_id ) <EOL> return features <EOL> def add_final_features ( self , sequence , y_prev , features ) : <EOL> y_name = self . dataset . y_dict . get_label_name ( y_prev ) <EOL> feat_name = "<STR_LIT>" % ( y_name ) <EOL> feat_id = self . add_feature ( feat_name ) <EOL> if ( feat_id != - <NUM_LIT:1> ) : <EOL> features . append ( feat_id ) <EOL> return features <EOL> def add_emission_features ( self , sequence , pos , y , features ) : <EOL> '''<STR_LIT>''' <EOL> x = sequence . x [ pos ] <EOL> y_name = self . dataset . y_dict . get_label_name ( y ) <EOL> x_name = self . dataset . x_dict . get_label_name ( x ) <EOL> feat_name = "<STR_LIT>" % ( x_name , y_name ) <EOL> feat_id = self . add_feature ( feat_name ) <EOL> if feat_id != - <NUM_LIT:1> : <EOL> features . append ( feat_id ) <EOL> return features <EOL> def add_transition_features ( self , sequence , pos , y , y_prev , features ) : <EOL> """<STR_LIT>""" <EOL> assert pos < len ( sequence . x ) - <NUM_LIT:1> , pdb . set_trace ( ) <EOL> y_name = self . dataset . y_dict . get_label_name ( y ) <EOL> y_prev_name = self . dataset . y_dict . get_label_name ( y_prev ) <EOL> feat_name = "<STR_LIT>" % ( y_prev_name , y_name ) <EOL> feat_id = self . add_feature ( feat_name ) <EOL> if ( feat_id != - <NUM_LIT:1> ) : <EOL> features . append ( feat_id ) <EOL> return features <EOL> def add_feature ( self , feat_name ) : <EOL> """<STR_LIT>""" <EOL> if ( feat_name in self . feature_dict ) : <EOL> return self . feature_dict [ feat_name ] <EOL> if not self . add_features : <EOL> return - <NUM_LIT:1> <EOL> return self . feature_dict . add ( feat_name ) </s>
<s> '''<STR_LIT>''' <EOL> import os <EOL> try : <EOL> import ogr <EOL> except ImportError : <EOL> from osgeo import ogr <EOL> line_shp_file = "<STR_LIT>" <EOL> line_datasource = ogr . Open ( line_shp_file ) <EOL> driver = ogr . GetDriverByName ( '<STR_LIT>' ) <EOL> point_shp_file = '<STR_LIT>' <EOL> layer_name = '<STR_LIT>' <EOL> if os . path . exists ( point_shp_file ) : <EOL> driver . DeleteDataSource ( point_shp_file ) <EOL> point_datasource = driver . CreateDataSource ( point_shp_file ) <EOL> layer_count = line_datasource . GetLayerCount ( ) <EOL> for each_layer in range ( layer_count ) : <EOL> layer = line_datasource . GetLayerByIndex ( each_layer ) <EOL> srs = layer . GetSpatialRef ( ) <EOL> point_shp_layer = point_datasource . CreateLayer ( layer_name , srs , ogr . wkbPoint ) <EOL> feature_count = layer . GetFeatureCount ( ) <EOL> for each_feature in range ( feature_count ) : <EOL> line_feature = layer . GetFeature ( each_feature ) <EOL> feature_geom = line_feature . GetGeometryRef ( ) <EOL> if feature_geom . GetGeometryName ( ) != '<STR_LIT>' : <EOL> points = feature_geom . GetPoints ( ) <EOL> for point in points : <EOL> point_geom = ogr . Geometry ( ogr . wkbPoint ) <EOL> point_geom . AddPoint ( point [ <NUM_LIT:0> ] , point [ <NUM_LIT:1> ] ) <EOL> point_feature = ogr . Feature ( point_shp_layer . GetLayerDefn ( ) ) <EOL> point_feature . SetGeometry ( point_geom ) <EOL> point_shp_layer . CreateFeature ( point_feature ) </s>
<s> '''<STR_LIT>''' <EOL> try : <EOL> import ogr <EOL> except ImportError : <EOL> from osgeo import ogr <EOL> latitudes = [ <NUM_LIT:50> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] <EOL> longitudes = [ <NUM_LIT:100> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] <EOL> elevation = <NUM_LIT:0> <EOL> points = ogr . Geometry ( ogr . wkbMultiPoint ) <EOL> point_1 = ogr . Geometry ( ogr . wkbPoint ) <EOL> point_1 . AddPoint ( longitudes [ <NUM_LIT:0> ] , latitudes [ <NUM_LIT:0> ] , elevation ) <EOL> points . AddGeometry ( point_1 ) <EOL> point_2 = ogr . Geometry ( ogr . wkbPoint ) <EOL> point_2 . AddPoint ( longitudes [ <NUM_LIT:1> ] , latitudes [ <NUM_LIT:1> ] , elevation ) <EOL> points . AddGeometry ( point_2 ) <EOL> point_3 = ogr . Geometry ( ogr . wkbPoint ) <EOL> point_3 . AddPoint ( longitudes [ <NUM_LIT:2> ] , latitudes [ <NUM_LIT:2> ] , elevation ) <EOL> points . AddGeometry ( point_3 ) <EOL> point_4 = ogr . Geometry ( ogr . wkbPoint ) <EOL> point_4 . AddPoint ( longitudes [ <NUM_LIT:3> ] , latitudes [ <NUM_LIT:3> ] , elevation ) <EOL> points . AddGeometry ( point_4 ) <EOL> point_5 = ogr . Geometry ( ogr . wkbPoint ) <EOL> point_5 . AddPoint ( longitudes [ <NUM_LIT:4> ] , latitudes [ <NUM_LIT:4> ] , elevation ) <EOL> points . AddGeometry ( point_5 ) <EOL> points . ExportToWkt ( ) <EOL> print points </s>
<s> from __future__ import division <EOL> import numpy as np <EOL> from collections import defaultdict <EOL> import json <EOL> import itertools <EOL> from sklearn import cluster , preprocessing , manifold <EOL> from datetime import datetime <EOL> import sys <EOL> class KeplerMapper ( object ) : <EOL> def __init__ ( self , verbose = <NUM_LIT:2> ) : <EOL> self . verbose = verbose <EOL> self . chunk_dist = [ ] <EOL> self . overlap_dist = [ ] <EOL> self . d = [ ] <EOL> self . nr_cubes = <NUM_LIT:0> <EOL> self . overlap_perc = <NUM_LIT:0> <EOL> self . clusterer = False <EOL> def fit_transform ( self , X , projection = "<STR_LIT>" , scaler = preprocessing . MinMaxScaler ( ) ) : <EOL> self . scaler = scaler <EOL> self . projection = str ( projection ) <EOL> if str ( type ( projection ) ) [ <NUM_LIT:1> : <NUM_LIT:6> ] == "<STR_LIT:class>" : <EOL> reducer = projection <EOL> if self . verbose > <NUM_LIT:0> : <EOL> try : <EOL> projection . set_params ( ** { "<STR_LIT>" : self . verbose } ) <EOL> except : <EOL> pass <EOL> print ( "<STR_LIT>" % str ( projection ) ) <EOL> X = reducer . fit_transform ( X ) <EOL> if isinstance ( projection , str ) : <EOL> if self . verbose > <NUM_LIT:0> : <EOL> print ( "<STR_LIT>" % ( projection ) ) <EOL> if projection == "<STR_LIT>" : <EOL> X = np . sum ( X , axis = <NUM_LIT:1> ) . reshape ( ( X . shape [ <NUM_LIT:0> ] , <NUM_LIT:1> ) ) <EOL> if projection == "<STR_LIT>" : <EOL> X = np . mean ( X , axis = <NUM_LIT:1> ) . reshape ( ( X . shape [ <NUM_LIT:0> ] , <NUM_LIT:1> ) ) <EOL> if projection == "<STR_LIT>" : <EOL> X = np . median ( X , axis = <NUM_LIT:1> ) . reshape ( ( X . shape [ <NUM_LIT:0> ] , <NUM_LIT:1> ) ) <EOL> if projection == "<STR_LIT>" : <EOL> X = np . max ( X , axis = <NUM_LIT:1> ) . reshape ( ( X . shape [ <NUM_LIT:0> ] , <NUM_LIT:1> ) ) <EOL> if projection == "<STR_LIT>" : <EOL> X = np . min ( X , axis = <NUM_LIT:1> ) . reshape ( ( X . shape [ <NUM_LIT:0> ] , <NUM_LIT:1> ) ) <EOL> if projection == "<STR_LIT>" : <EOL> X = np . std ( X , axis = <NUM_LIT:1> ) . reshape ( ( X . shape [ <NUM_LIT:0> ] , <NUM_LIT:1> ) ) <EOL> if projection == "<STR_LIT>" : <EOL> X_mean = np . mean ( X , axis = <NUM_LIT:0> ) <EOL> X = np . sum ( np . sqrt ( ( X - X_mean ) ** <NUM_LIT:2> ) , axis = <NUM_LIT:1> ) . reshape ( ( X . shape [ <NUM_LIT:0> ] , <NUM_LIT:1> ) ) <EOL> if isinstance ( projection , list ) : <EOL> if self . verbose > <NUM_LIT:0> : <EOL> print ( "<STR_LIT>" % ( str ( projection ) ) ) <EOL> X = X [ : , np . array ( projection ) ] <EOL> if scaler is not None : <EOL> if self . verbose > <NUM_LIT:0> : <EOL> print ( "<STR_LIT>" % str ( scaler ) ) <EOL> X = scaler . fit_transform ( X ) <EOL> return X <EOL> def map ( self , projected_X , inverse_X = None , clusterer = cluster . DBSCAN ( eps = <NUM_LIT:0.5> , min_samples = <NUM_LIT:3> ) , nr_cubes = <NUM_LIT:10> , overlap_perc = <NUM_LIT:0.1> ) : <EOL> start = datetime . now ( ) <EOL> def cube_coordinates_all ( nr_cubes , nr_dimensions ) : <EOL> l = [ ] <EOL> for x in range ( nr_cubes ) : <EOL> l += [ x ] * nr_dimensions <EOL> return [ np . array ( list ( f ) ) for f in sorted ( set ( itertools . permutations ( l , nr_dimensions ) ) ) ] <EOL> nodes = defaultdict ( list ) <EOL> links = defaultdict ( list ) <EOL> complex = { } <EOL> self . nr_cubes = nr_cubes <EOL> self . clusterer = clusterer <EOL> self . overlap_perc = overlap_perc <EOL> if self . verbose > <NUM_LIT:0> : <EOL> print ( "<STR_LIT>" % ( str ( projected_X . shape ) ) ) <EOL> if inverse_X is None : <EOL> inverse_X = projected_X <EOL> self . chunk_dist = ( np . max ( projected_X , axis = <NUM_LIT:0> ) - np . min ( projected_X , axis = <NUM_LIT:0> ) ) / nr_cubes <EOL> self . overlap_dist = self . overlap_perc * self . chunk_dist <EOL> self . d = np . min ( projected_X , axis = <NUM_LIT:0> ) <EOL> di = np . array ( [ x for x in range ( projected_X . shape [ <NUM_LIT:1> ] ) ] ) <EOL> ids = np . array ( [ x for x in range ( projected_X . shape [ <NUM_LIT:0> ] ) ] ) <EOL> projected_X = np . c_ [ ids , projected_X ] <EOL> inverse_X = np . c_ [ ids , inverse_X ] <EOL> if self . verbose > <NUM_LIT:0> : <EOL> total_cubes = len ( cube_coordinates_all ( nr_cubes , projected_X . shape [ <NUM_LIT:1> ] ) ) <EOL> print ( "<STR_LIT>" % total_cubes ) <EOL> for i , coor in enumerate ( cube_coordinates_all ( nr_cubes , di . shape [ <NUM_LIT:0> ] ) ) : <EOL> hypercube = projected_X [ np . invert ( np . any ( ( projected_X [ : , di + <NUM_LIT:1> ] >= self . d [ di ] + ( coor * self . chunk_dist [ di ] ) ) & <EOL> ( projected_X [ : , di + <NUM_LIT:1> ] < self . d [ di ] + ( coor * self . chunk_dist [ di ] ) + self . chunk_dist [ di ] + self . overlap_dist [ di ] ) == False , axis = <NUM_LIT:1> ) ) ] <EOL> if self . verbose > <NUM_LIT:1> : <EOL> print ( "<STR_LIT>" % <EOL> ( hypercube . shape [ <NUM_LIT:0> ] , i , total_cubes , self . d [ di ] + ( coor * self . chunk_dist [ di ] ) ) ) <EOL> if hypercube . shape [ <NUM_LIT:0> ] > <NUM_LIT:0> : <EOL> inverse_x = inverse_X [ [ int ( nn ) for nn in hypercube [ : , <NUM_LIT:0> ] ] ] <EOL> clusterer . fit ( inverse_x [ : , <NUM_LIT:1> : ] ) <EOL> if self . verbose > <NUM_LIT:1> : <EOL> print ( "<STR_LIT>" % ( np . unique ( clusterer . labels_ [ clusterer . labels_ > - <NUM_LIT:1> ] ) . shape [ <NUM_LIT:0> ] , i ) ) <EOL> for a in np . c_ [ hypercube [ : , <NUM_LIT:0> ] , clusterer . labels_ ] : <EOL> if a [ <NUM_LIT:1> ] != - <NUM_LIT:1> : <EOL> cluster_id = str ( coor [ <NUM_LIT:0> ] ) + "<STR_LIT:_>" + str ( i ) + "<STR_LIT:_>" + str ( a [ <NUM_LIT:1> ] ) + "<STR_LIT:_>" + str ( coor ) + "<STR_LIT:_>" + str ( self . d [ di ] + ( coor * self . chunk_dist [ di ] ) ) <EOL> nodes [ cluster_id ] . append ( int ( a [ <NUM_LIT:0> ] ) ) <EOL> else : <EOL> if self . verbose > <NUM_LIT:1> : <EOL> print ( "<STR_LIT>" % ( i ) ) <EOL> candidates = itertools . combinations ( nodes . keys ( ) , <NUM_LIT:2> ) <EOL> for candidate in candidates : <EOL> if len ( nodes [ candidate [ <NUM_LIT:0> ] ] + nodes [ candidate [ <NUM_LIT:1> ] ] ) != len ( set ( nodes [ candidate [ <NUM_LIT:0> ] ] + nodes [ candidate [ <NUM_LIT:1> ] ] ) ) : <EOL> links [ candidate [ <NUM_LIT:0> ] ] . append ( candidate [ <NUM_LIT:1> ] ) <EOL> if self . verbose > <NUM_LIT:0> : <EOL> nr_links = <NUM_LIT:0> <EOL> for k in links : <EOL> nr_links += len ( links [ k ] ) <EOL> print ( "<STR_LIT>" % ( nr_links , len ( nodes ) , str ( datetime . now ( ) - start ) ) ) <EOL> complex [ "<STR_LIT>" ] = nodes <EOL> complex [ "<STR_LIT>" ] = links <EOL> complex [ "<STR_LIT>" ] = self . projection <EOL> return complex <EOL> def visualize ( self , complex , color_function = "<STR_LIT>" , path_html = "<STR_LIT>" , title = "<STR_LIT>" , <EOL> graph_link_distance = <NUM_LIT:30> , graph_gravity = <NUM_LIT:0.1> , graph_charge = - <NUM_LIT> , custom_tooltips = None , width_html = <NUM_LIT:0> , <EOL> height_html = <NUM_LIT:0> , show_tooltips = True , show_title = True , show_meta = True ) : <EOL> json_s = { } <EOL> json_s [ "<STR_LIT>" ] = [ ] <EOL> json_s [ "<STR_LIT>" ] = [ ] <EOL> k2e = { } <EOL> for e , k in enumerate ( complex [ "<STR_LIT>" ] ) : <EOL> if custom_tooltips is not None : <EOL> tooltip_s = "<STR_LIT>" % k + "<STR_LIT:U+0020>" . join ( [ str ( f ) for f in custom_tooltips [ complex [ "<STR_LIT>" ] [ k ] ] ] ) <EOL> if color_function == "<STR_LIT>" : <EOL> tooltip_i = int ( ( ( sum ( [ f for f in custom_tooltips [ complex [ "<STR_LIT>" ] [ k ] ] ] ) / len ( custom_tooltips [ complex [ "<STR_LIT>" ] [ k ] ] ) ) * <NUM_LIT:30> ) ) <EOL> json_s [ "<STR_LIT>" ] . append ( { "<STR_LIT:name>" : str ( k ) , "<STR_LIT>" : tooltip_s , "<STR_LIT>" : <NUM_LIT:2> * int ( np . log ( len ( complex [ "<STR_LIT>" ] [ k ] ) ) ) , "<STR_LIT>" : str ( tooltip_i ) } ) <EOL> else : <EOL> json_s [ "<STR_LIT>" ] . append ( { "<STR_LIT:name>" : str ( k ) , "<STR_LIT>" : tooltip_s , "<STR_LIT>" : <NUM_LIT:2> * int ( np . log ( len ( complex [ "<STR_LIT>" ] [ k ] ) ) ) , "<STR_LIT>" : str ( k . split ( "<STR_LIT:_>" ) [ <NUM_LIT:0> ] ) } ) <EOL> else : <EOL> tooltip_s = "<STR_LIT>" % ( k , len ( complex [ "<STR_LIT>" ] [ k ] ) ) <EOL> json_s [ "<STR_LIT>" ] . append ( { "<STR_LIT:name>" : str ( k ) , "<STR_LIT>" : tooltip_s , "<STR_LIT>" : <NUM_LIT:2> * int ( np . log ( len ( complex [ "<STR_LIT>" ] [ k ] ) ) ) , "<STR_LIT>" : str ( k . split ( "<STR_LIT:_>" ) [ <NUM_LIT:0> ] ) } ) <EOL> k2e [ k ] = e <EOL> for k in complex [ "<STR_LIT>" ] : <EOL> for link in complex [ "<STR_LIT>" ] [ k ] : <EOL> json_s [ "<STR_LIT>" ] . append ( { "<STR_LIT:source>" : k2e [ k ] , "<STR_LIT:target>" : k2e [ link ] , "<STR_LIT:value>" : <NUM_LIT:1> } ) <EOL> if width_html == <NUM_LIT:0> : <EOL> width_css = "<STR_LIT>" <EOL> width_js = '<STR_LIT>' <EOL> else : <EOL> width_css = "<STR_LIT>" % width_html <EOL> width_js = "<STR_LIT:%s>" % width_html <EOL> if height_html == <NUM_LIT:0> : <EOL> height_css = "<STR_LIT>" <EOL> height_js = '<STR_LIT>' <EOL> else : <EOL> height_css = "<STR_LIT>" % height_html <EOL> height_js = "<STR_LIT:%s>" % height_html <EOL> if show_tooltips == False : <EOL> tooltips_display = "<STR_LIT>" <EOL> else : <EOL> tooltips_display = "<STR_LIT>" <EOL> if show_meta == False : <EOL> meta_display = "<STR_LIT>" <EOL> else : <EOL> meta_display = "<STR_LIT>" <EOL> if show_title == False : <EOL> title_display = "<STR_LIT>" <EOL> else : <EOL> title_display = "<STR_LIT>" <EOL> with open ( path_html , "<STR_LIT:wb>" ) as outfile : <EOL> html = """<STR_LIT>""" % ( title , width_css , height_css , title_display , meta_display , tooltips_display , title , complex [ "<STR_LIT>" ] , self . nr_cubes , self . overlap_perc * <NUM_LIT:100> , color_function , complex [ "<STR_LIT>" ] , str ( self . clusterer ) , str ( self . scaler ) , width_js , height_js , graph_charge , graph_link_distance , graph_gravity , json . dumps ( json_s ) ) <EOL> outfile . write ( html . encode ( "<STR_LIT:utf-8>" ) ) <EOL> if self . verbose > <NUM_LIT:0> : <EOL> print ( "<STR_LIT>" % path_html ) </s>
<s> """<STR_LIT>""" <EOL> import sys <EOL> import os <EOL> import unittest <EOL> from SystemConfiguration import * <EOL> class SCPreferences ( object ) : <EOL> """<STR_LIT>""" <EOL> proxy_protocols = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) <EOL> session = None <EOL> def __init__ ( self ) : <EOL> super ( SCPreferences , self ) . __init__ ( ) <EOL> self . session = SCPreferencesCreate ( None , "<STR_LIT>" , None ) <EOL> def save ( self ) : <EOL> if not self . session : <EOL> return <EOL> if not SCPreferencesCommitChanges ( self . session ) : <EOL> raise RuntimeError ( "<STR_LIT>" ) <EOL> if not SCPreferencesApplyChanges ( self . session ) : <EOL> raise RuntimeError ( "<STR_LIT>" ) <EOL> def set_proxy ( self , enable = True , protocol = "<STR_LIT>" , server = "<STR_LIT:localhost>" , port = <NUM_LIT> ) : <EOL> new_settings = SCPreferencesPathGetValue ( self . session , u'<STR_LIT>' ) <EOL> for interface in new_settings : <EOL> new_settings [ interface ] [ '<STR_LIT>' ] [ "<STR_LIT>" % protocol ] = <NUM_LIT:1> if enable else <NUM_LIT:0> <EOL> if enable : <EOL> new_settings [ interface ] [ '<STR_LIT>' ] [ '<STR_LIT>' % protocol ] = int ( port ) <EOL> new_settings [ interface ] [ '<STR_LIT>' ] [ '<STR_LIT>' % protocol ] = server <EOL> SCPreferencesPathSetValue ( self . session , u'<STR_LIT>' , new_settings ) <EOL> class SCPreferencesTests ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> raise RuntimeError ( "<STR_LIT>" ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> unittest . main ( ) </s>
<s> import sublime , sublime_plugin , os , re <EOL> class StyleSheetSetup : <EOL> def __init__ ( self , extensions , regex , partials = None , index = None ) : <EOL> if partials is None : <EOL> self . partials = False <EOL> else : <EOL> self . partials = partials <EOL> if index is None : <EOL> self . index = False <EOL> else : <EOL> self . index = index <EOL> self . extensions = extensions <EOL> self . regex = regex <EOL> class ListStylesheetVariables ( sublime_plugin . TextCommand ) : <EOL> def run ( self , edit ) : <EOL> settings = sublime . load_settings ( '<STR_LIT>' ) <EOL> handle_imports = settings . get ( "<STR_LIT>" ) <EOL> read_all_views = settings . get ( "<STR_LIT>" ) <EOL> less_setup = StyleSheetSetup ( ( b'<STR_LIT>' , b'<STR_LIT>' ) , "<STR_LIT>" ) <EOL> sass_setup = StyleSheetSetup ( ( b'<STR_LIT>' , b'<STR_LIT>' ) , "<STR_LIT>" , True ) <EOL> stylus_setup = StyleSheetSetup ( ( b'<STR_LIT>' , ) , "<STR_LIT>" , False , True ) <EOL> sass_erb_setup = StyleSheetSetup ( ( b'<STR_LIT>' , b'<STR_LIT>' ) , "<STR_LIT>" , True ) <EOL> setups = ( less_setup , sass_setup , stylus_setup , sass_erb_setup ) <EOL> chosen_setup = None <EOL> self . edit = edit <EOL> fn = self . view . file_name ( ) . encode ( "<STR_LIT>" ) <EOL> for setup in setups : <EOL> for ext in setup . extensions : <EOL> if fn . endswith ( ext ) : <EOL> chosen_setup = setup <EOL> if chosen_setup == None : <EOL> return <EOL> imports = [ ] <EOL> imported_vars = [ ] <EOL> compiled_regex = re . compile ( chosen_setup . regex , re . MULTILINE ) <EOL> if handle_imports : <EOL> self . view . find_all ( "<STR_LIT>" , <NUM_LIT:0> , "<STR_LIT>" , imports ) <EOL> file_dir = os . path . dirname ( fn ) . decode ( "<STR_LIT:utf-8>" ) <EOL> for i , filename in enumerate ( imports ) : <EOL> has_extension = False <EOL> for ext in chosen_setup . extensions : <EOL> if filename . endswith ( ext . decode ( "<STR_LIT:utf-8>" ) ) : <EOL> has_extension = True <EOL> if has_extension == False : <EOL> for ext in chosen_setup . extensions : <EOL> ext = ext . decode ( "<STR_LIT:utf-8>" ) <EOL> if os . path . isfile ( os . path . normpath ( file_dir + '<STR_LIT:/>' + filename + ext ) ) : <EOL> filename += ext <EOL> break <EOL> if chosen_setup . partials : <EOL> fn_split = os . path . split ( filename ) <EOL> partial_filename = fn_split [ <NUM_LIT:0> ] + "<STR_LIT>" + fn_split [ <NUM_LIT:1> ] <EOL> if os . path . isfile ( os . path . normpath ( file_dir + partial_filename + ext ) ) : <EOL> filename = "<STR_LIT:_>" + filename + ext <EOL> break <EOL> if chosen_setup . index and os . path . isfile ( os . path . normpath ( file_dir + "<STR_LIT:/>" + filename + "<STR_LIT>" + ext ) ) : <EOL> filename += "<STR_LIT>" + ext <EOL> try : <EOL> f = open ( os . path . normpath ( file_dir + '<STR_LIT:/>' + filename ) , '<STR_LIT:r>' ) <EOL> contents = f . read ( ) <EOL> f . close ( ) <EOL> m = re . findall ( compiled_regex , contents ) <EOL> imported_vars = imported_vars + m <EOL> except : <EOL> print ( '<STR_LIT>' + filename ) <EOL> imported_vars = [ list ( item ) for item in imported_vars ] <EOL> self . variables = [ ] <EOL> vars_from_views = [ ] <EOL> if read_all_views : <EOL> for view in self . view . window ( ) . views ( ) : <EOL> viewfn = self . view . file_name ( ) . encode ( "<STR_LIT:utf-8>" ) <EOL> compatible_view = False <EOL> for ext in chosen_setup . extensions : <EOL> if viewfn . endswith ( ext ) : <EOL> viewvars = [ ] <EOL> view . find_all ( chosen_setup . regex , <NUM_LIT:0> , "<STR_LIT>" , viewvars ) <EOL> vars_from_views += viewvars <EOL> break ; <EOL> else : <EOL> self . view . find_all ( chosen_setup . regex , <NUM_LIT:0> , "<STR_LIT>" , self . variables ) <EOL> self . variables += vars_from_views <EOL> self . variables = list ( set ( self . variables ) ) <EOL> for i , val in enumerate ( self . variables ) : <EOL> self . variables [ i ] = val . split ( "<STR_LIT:|>" ) <EOL> self . variables = imported_vars + self . variables <EOL> self . variables . sort ( ) <EOL> self . view . window ( ) . show_quick_panel ( self . variables , self . insert_variable , sublime . MONOSPACE_FONT ) <EOL> def insert_variable ( self , choice ) : <EOL> if choice == - <NUM_LIT:1> : <EOL> return <EOL> self . view . run_command ( '<STR_LIT>' , { '<STR_LIT:string>' : self . variables [ choice ] [ <NUM_LIT:0> ] } ) <EOL> class InsertText ( sublime_plugin . TextCommand ) : <EOL> def run ( self , edit , string = '<STR_LIT>' ) : <EOL> for selection in self . view . sel ( ) : <EOL> self . view . insert ( edit , selection . begin ( ) , string ) </s>
<s> from driver_base import DriverBase <EOL> import socket <EOL> import sys <EOL> import time <EOL> import os <EOL> os . sys . path . insert ( <NUM_LIT:0> , os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) ) <EOL> import log <EOL> class CMDTYPE : <EOL> SETUP_DATA = <NUM_LIT:1> <EOL> PIXEL_DATA = <NUM_LIT:2> <EOL> BRIGHTNESS = <NUM_LIT:3> <EOL> class RETURN_CODES : <EOL> SUCCESS = <NUM_LIT:255> <EOL> ERROR = <NUM_LIT:0> <EOL> ERROR_SIZE = <NUM_LIT:1> <EOL> ERROR_UNSUPPORTED = <NUM_LIT:2> <EOL> class DriverNetwork ( DriverBase ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , num = <NUM_LIT:0> , width = <NUM_LIT:0> , height = <NUM_LIT:0> , host = "<STR_LIT:localhost>" , port = <NUM_LIT> ) : <EOL> super ( DriverNetwork , self ) . __init__ ( num , width , height ) <EOL> self . _host = host <EOL> self . _port = port <EOL> def _generateHeader ( self , cmd , size ) : <EOL> packet = bytearray ( ) <EOL> packet . append ( cmd ) <EOL> packet . append ( size & <NUM_LIT> ) <EOL> packet . append ( size >> <NUM_LIT:8> ) <EOL> return packet <EOL> def _connect ( self ) : <EOL> try : <EOL> s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> s . connect ( ( self . _host , self . _port ) ) <EOL> return s <EOL> except socket . gaierror : <EOL> error = "<STR_LIT>" . format ( <EOL> self . _host ) <EOL> log . error ( error ) <EOL> raise IOError ( error ) <EOL> def update ( self , data ) : <EOL> try : <EOL> s = self . _connect ( ) <EOL> count = self . bufByteCount <EOL> packet = self . _generateHeader ( CMDTYPE . PIXEL_DATA , count ) <EOL> packet . extend ( data ) <EOL> s . sendall ( packet ) <EOL> resp = ord ( s . recv ( <NUM_LIT:1> ) ) <EOL> s . close ( ) <EOL> if resp != RETURN_CODES . SUCCESS : <EOL> log . warning ( "<STR_LIT>" , resp ) <EOL> except Exception as e : <EOL> log . exception ( e ) <EOL> error = "<STR_LIT>" <EOL> log . error ( error ) <EOL> raise IOError ( error ) <EOL> def setMasterBrightness ( self , brightness ) : <EOL> packet = self . _generateHeader ( CMDTYPE . BRIGHTNESS , <NUM_LIT:1> ) <EOL> packet . append ( brightness ) <EOL> s = self . _connect ( ) <EOL> s . sendall ( packet ) <EOL> resp = ord ( s . recv ( <NUM_LIT:1> ) ) <EOL> if resp != RETURN_CODES . SUCCESS : <EOL> return False <EOL> else : <EOL> return True <EOL> MANIFEST = [ <EOL> { <EOL> "<STR_LIT:id>" : "<STR_LIT>" , <EOL> "<STR_LIT:class>" : DriverNetwork , <EOL> "<STR_LIT:type>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : [ { <EOL> "<STR_LIT:id>" : "<STR_LIT>" , <EOL> "<STR_LIT:label>" : "<STR_LIT>" , <EOL> "<STR_LIT:type>" : "<STR_LIT:int>" , <EOL> "<STR_LIT:default>" : <NUM_LIT:0> , <EOL> "<STR_LIT>" : <NUM_LIT:0> , <EOL> "<STR_LIT>" : "<STR_LIT>" <EOL> } , { <EOL> "<STR_LIT:id>" : "<STR_LIT:width>" , <EOL> "<STR_LIT:label>" : "<STR_LIT>" , <EOL> "<STR_LIT:type>" : "<STR_LIT:int>" , <EOL> "<STR_LIT:default>" : <NUM_LIT:0> , <EOL> "<STR_LIT>" : <NUM_LIT:0> , <EOL> "<STR_LIT>" : "<STR_LIT>" <EOL> } , { <EOL> "<STR_LIT:id>" : "<STR_LIT>" , <EOL> "<STR_LIT:label>" : "<STR_LIT>" , <EOL> "<STR_LIT:type>" : "<STR_LIT:int>" , <EOL> "<STR_LIT:default>" : <NUM_LIT:0> , <EOL> "<STR_LIT>" : <NUM_LIT:0> , <EOL> "<STR_LIT>" : "<STR_LIT>" <EOL> } , { <EOL> "<STR_LIT:id>" : "<STR_LIT:host>" , <EOL> "<STR_LIT:label>" : "<STR_LIT>" , <EOL> "<STR_LIT:type>" : "<STR_LIT:str>" , <EOL> "<STR_LIT:default>" : "<STR_LIT:localhost>" , <EOL> "<STR_LIT>" : "<STR_LIT>" <EOL> } , { <EOL> "<STR_LIT:id>" : "<STR_LIT:port>" , <EOL> "<STR_LIT:label>" : "<STR_LIT>" , <EOL> "<STR_LIT:type>" : "<STR_LIT:int>" , <EOL> "<STR_LIT:default>" : <NUM_LIT> , <EOL> "<STR_LIT>" : "<STR_LIT>" <EOL> } ] <EOL> } <EOL> ] </s>
<s> _ID = '<STR_LIT>' <EOL> API = '<STR_LIT>' <EOL> API_CALL_TIMEOUT = '<STR_LIT>' <EOL> API_VERSION = '<STR_LIT>' <EOL> API_VERSION_MAXIMUM = '<STR_LIT>' <EOL> API_VERSION_MINIMUM = '<STR_LIT>' <EOL> AREA = '<STR_LIT>' <EOL> AREA_MAX = '<STR_LIT>' <EOL> BBOX = '<STR_LIT>' <EOL> BOUNDS = '<STR_LIT>' <EOL> CFGSLAB = '<STR_LIT>' <EOL> CFGVERSION = <NUM_LIT:1> <EOL> CHANGESET = '<STR_LIT>' <EOL> CHANGESETS = '<STR_LIT>' <EOL> CHANGESETS_INLINE_SIZE = '<STR_LIT>' <EOL> CHANGESETS_PER_SLAB = '<STR_LIT>' <EOL> CHANGESETS_MAX = '<STR_LIT>' <EOL> CONFIGURATION_SCHEMA_VERSION = '<STR_LIT>' <EOL> CONTENT_TYPE = '<STR_LIT:Content-Type>' <EOL> COUCHDB = '<STR_LIT>' <EOL> DATASTORE = '<STR_LIT>' <EOL> DATASTORE_BACKEND = '<STR_LIT>' <EOL> DATASTORE_CONFIG = '<STR_LIT>' <EOL> DATASTORE_ENCODING = '<STR_LIT>' <EOL> DBHOST = '<STR_LIT>' <EOL> DBJOB_ADDELEM = '<STR_LIT>' <EOL> DBJOB_QUIT = '<STR_LIT>' <EOL> DBNAME = '<STR_LIT>' <EOL> DBNAME_SUFFIXES = '<STR_LIT>' <EOL> DBPORT = '<STR_LIT>' <EOL> DBURL = '<STR_LIT>' <EOL> DEFAULT = '<STR_LIT>' <EOL> ELEMENT = '<STR_LIT>' <EOL> FRONT_END = '<STR_LIT>' <EOL> GENERATOR = '<STR_LIT>' <EOL> GEODOC = '<STR_LIT>' <EOL> GEODOC_LRU_SIZE = '<STR_LIT>' <EOL> GEODOC_LRU_THREADS = '<STR_LIT>' <EOL> GEOHASH_LENGTH = '<STR_LIT>' <EOL> ID = '<STR_LIT:id>' <EOL> JSON = '<STR_LIT>' <EOL> K = '<STR_LIT:k>' <EOL> LAT = '<STR_LIT>' <EOL> LAT_MAX = + <NUM_LIT> <EOL> LAT_MIN = - <NUM_LIT> <EOL> LON = '<STR_LIT>' <EOL> LON_MAX = + <NUM_LIT> <EOL> LON_MIN = - <NUM_LIT> <EOL> MAXIMUM = '<STR_LIT>' <EOL> MAXIMUM_ELEMENTS = '<STR_LIT>' <EOL> MAXGHLAT = <NUM_LIT> <EOL> MAXLAT = '<STR_LIT>' <EOL> MAXLON = '<STR_LIT>' <EOL> MEMBASE = '<STR_LIT>' <EOL> MEMBASE_MAX_VALUE_LENGTH = <NUM_LIT:20> * <NUM_LIT> * <NUM_LIT> <EOL> MEMBER = '<STR_LIT>' <EOL> MEMBERS = '<STR_LIT>' <EOL> MINIMUM = '<STR_LIT>' <EOL> MINLAT = '<STR_LIT>' <EOL> MINLON = '<STR_LIT>' <EOL> ND = '<STR_LIT>' <EOL> NODE = '<STR_LIT>' <EOL> NODES = '<STR_LIT>' <EOL> NODES_INLINE_SIZE = '<STR_LIT>' <EOL> NODES_PER_SLAB = '<STR_LIT>' <EOL> OSM = '<STR_LIT>' <EOL> PER_PAGE = '<STR_LIT>' <EOL> PORT = '<STR_LIT:port>' <EOL> PROJECT_DOC = '<STR_LIT>' <EOL> PROTOBUF = '<STR_LIT>' <EOL> REF = '<STR_LIT>' <EOL> REFERENCES = '<STR_LIT>' <EOL> RELATION = '<STR_LIT>' <EOL> RELATIONS = '<STR_LIT>' <EOL> RELATIONS_INLINE_SIZE = '<STR_LIT>' <EOL> RELATIONS_PER_SLAB = '<STR_LIT>' <EOL> ROLE = '<STR_LIT>' <EOL> SCALE_FACTOR = '<STR_LIT>' <EOL> SECONDS = '<STR_LIT>' <EOL> SERVER_NAME = '<STR_LIT>' <EOL> SERVER_VERSION = '<STR_LIT>' <EOL> SLAB_INDIRECT = <NUM_LIT:1> <EOL> SLAB_INLINE = <NUM_LIT:0> <EOL> SLAB_LRU_SIZE = '<STR_LIT>' <EOL> SLAB_LRU_THREADS = '<STR_LIT>' <EOL> SLAB_NOT_PRESENT = <NUM_LIT:2> <EOL> SOURCE_REPOSITORY = '<STR_LIT>' <EOL> STATUS = '<STR_LIT:status>' <EOL> TAG = '<STR_LIT>' <EOL> TAGS = '<STR_LIT>' <EOL> TEXT_XML = '<STR_LIT>' <EOL> TIMEOUT = '<STR_LIT>' <EOL> TRACEPOINTS = '<STR_LIT>' <EOL> TRACEPOINTS_PER_PAGE = '<STR_LIT>' <EOL> TYPE = '<STR_LIT:type>' <EOL> UTF8 = '<STR_LIT:utf-8>' <EOL> V = '<STR_LIT:v>' <EOL> VERSION = '<STR_LIT:version>' <EOL> WAY = '<STR_LIT>' <EOL> WAYS = '<STR_LIT>' <EOL> WAYS_INLINE_SIZE = '<STR_LIT>' <EOL> WAYS_PER_SLAB = '<STR_LIT>' <EOL> WAYNODES = '<STR_LIT>' <EOL> WAYNODES_MAX = '<STR_LIT>' </s>
<s> import webapp2 <EOL> from urllib import urlencode <EOL> import json , urllib2 <EOL> from secret import client_id , client_secret <EOL> import config <EOL> class AuthRedirector ( webapp2 . RequestHandler ) : <EOL> def get ( self ) : <EOL> args = self . request . GET <EOL> args [ "<STR_LIT>" ] = client_id <EOL> args [ "<STR_LIT>" ] = config . auth_redir_uri <EOL> url = "<STR_LIT>" + urlencode ( args ) <EOL> self . response . location = url <EOL> self . response . status_int = <NUM_LIT> <EOL> def query_json ( url , data ) : <EOL> """<STR_LIT>""" <EOL> if not ( data is str ) : <EOL> data = urlencode ( data ) <EOL> try : <EOL> return json . loads ( urllib2 . urlopen ( url , data ) . read ( ) ) <EOL> except urllib2 . HTTPError as e : <EOL> return json . loads ( e . read ( ) ) <EOL> def json_compactify ( data ) : <EOL> return json . dumps ( data , separators = ( '<STR_LIT:U+002C>' , '<STR_LIT::>' ) ) <EOL> class AuthCallback ( webapp2 . RequestHandler ) : <EOL> """<STR_LIT>""" <EOL> def get ( self ) : <EOL> state = self . request . get ( "<STR_LIT:state>" ) <EOL> code = self . request . get ( "<STR_LIT:code>" ) <EOL> error = self . request . get ( "<STR_LIT:error>" ) <EOL> q = { <EOL> "<STR_LIT:code>" : code , <EOL> "<STR_LIT>" : client_id , <EOL> "<STR_LIT>" : client_secret , <EOL> "<STR_LIT>" : config . auth_redir_uri , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> } <EOL> result = query_json ( "<STR_LIT>" , q ) <EOL> url = ( config . auth_success_page if "<STR_LIT>" in result <EOL> else config . auth_failure_page ) + "<STR_LIT:#>" + urlencode ( result ) <EOL> self . response . location = url <EOL> self . response . status_int = <NUM_LIT> <EOL> class AuthRefresh ( webapp2 . RequestHandler ) : <EOL> """<STR_LIT>""" <EOL> def get ( self ) : <EOL> refresh_token = self . request . get ( "<STR_LIT>" ) <EOL> if not refresh_token : <EOL> self . response . status_int = <NUM_LIT> <EOL> return <EOL> q = { <EOL> "<STR_LIT>" : refresh_token , <EOL> "<STR_LIT>" : client_id , <EOL> "<STR_LIT>" : client_secret , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> } <EOL> result = query_json ( "<STR_LIT>" , q ) <EOL> self . response . headers [ '<STR_LIT:Content-Type>' ] = "<STR_LIT>" <EOL> self . response . write ( json_compactify ( result ) ) <EOL> application = webapp2 . WSGIApplication ( [ <EOL> ( '<STR_LIT>' , AuthRedirector ) , <EOL> ( '<STR_LIT>' , AuthCallback ) , <EOL> ( '<STR_LIT>' , AuthRefresh ) , <EOL> ] , debug = True ) </s>
<s> from __future__ import unicode_literals <EOL> from django . db import migrations , models <EOL> class Migration ( migrations . Migration ) : <EOL> dependencies = [ <EOL> ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> ] <EOL> operations = [ <EOL> migrations . AddField ( <EOL> model_name = '<STR_LIT>' , <EOL> name = '<STR_LIT>' , <EOL> field = models . EmailField ( help_text = '<STR_LIT>' , max_length = <NUM_LIT> , null = True , verbose_name = '<STR_LIT>' , blank = True ) , <EOL> preserve_default = True , <EOL> ) , <EOL> ] </s>
<s> from __future__ import print_function <EOL> __author__ = "<STR_LIT>" <EOL> __email__ = "<STR_LIT>" <EOL> """<STR_LIT>""" <EOL> from debug import Debuggable <EOL> import sys <EOL> from difflib import SequenceMatcher <EOL> import locale <EOL> class Interactive ( Debuggable ) : <EOL> def __init__ ( self , debug ) : <EOL> self . debug = debug <EOL> Debuggable . __init__ ( self , '<STR_LIT>' ) <EOL> self . COLOR_ESCAPE = "<STR_LIT>" <EOL> self . DARK_COLORS = [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , <EOL> "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] <EOL> self . LIGHT_COLORS = [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , <EOL> "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] <EOL> self . RESET_COLOR = self . COLOR_ESCAPE + "<STR_LIT>" <EOL> def input_options ( self , options , require = False , prompt = None , fallback_prompt = None , <EOL> numrange = None , default = None , max_width = <NUM_LIT> ) : <EOL> """<STR_LIT>""" <EOL> letters = { } <EOL> display_letters = [ ] <EOL> capitalized = [ ] <EOL> first = True <EOL> for option in options : <EOL> for letter in option : <EOL> if letter . isalpha ( ) and letter . upper ( ) == letter : <EOL> found_letter = letter <EOL> break <EOL> else : <EOL> for letter in option : <EOL> if not letter . isalpha ( ) : <EOL> continue <EOL> if letter not in letters : <EOL> found_letter = letter <EOL> break <EOL> else : <EOL> raise ValueError ( '<STR_LIT>' ) <EOL> letters [ found_letter . lower ( ) ] = option <EOL> index = option . index ( found_letter ) <EOL> if not require and ( ( default is None and not numrange and first ) or <EOL> ( isinstance ( default , basestring ) and <EOL> found_letter . lower ( ) == default . lower ( ) ) ) : <EOL> show_letter = '<STR_LIT>' % found_letter . upper ( ) <EOL> is_default = True <EOL> else : <EOL> show_letter = found_letter . upper ( ) <EOL> is_default = False <EOL> show_letter = self . colorize ( '<STR_LIT>' if is_default else '<STR_LIT>' , <EOL> show_letter ) <EOL> capitalized . append ( <EOL> option [ : index ] + show_letter + option [ index + <NUM_LIT:1> : ] <EOL> ) <EOL> display_letters . append ( found_letter . upper ( ) ) <EOL> first = False <EOL> if require : <EOL> default = None <EOL> elif default is None : <EOL> if numrange : <EOL> default = numrange [ <NUM_LIT:0> ] <EOL> else : <EOL> default = display_letters [ <NUM_LIT:0> ] . lower ( ) <EOL> if not prompt : <EOL> prompt_parts = [ ] <EOL> prompt_part_lengths = [ ] <EOL> if numrange : <EOL> if isinstance ( default , int ) : <EOL> default_name = str ( default ) <EOL> default_name = self . colorize ( '<STR_LIT>' , default_name ) <EOL> tmpl = '<STR_LIT>' <EOL> prompt_parts . append ( tmpl % default_name ) <EOL> prompt_part_lengths . append ( len ( tmpl % str ( default ) ) ) <EOL> else : <EOL> prompt_parts . append ( '<STR_LIT>' ) <EOL> prompt_part_lengths . append ( len ( prompt_parts [ - <NUM_LIT:1> ] ) ) <EOL> prompt_parts += capitalized <EOL> prompt_part_lengths += [ len ( s ) for s in options ] <EOL> prompt = '<STR_LIT>' <EOL> line_length = <NUM_LIT:0> <EOL> for i , ( part , length ) in enumerate ( zip ( prompt_parts , <EOL> prompt_part_lengths ) ) : <EOL> if i == len ( prompt_parts ) - <NUM_LIT:1> : <EOL> part += '<STR_LIT:?>' <EOL> else : <EOL> part += '<STR_LIT:U+002C>' <EOL> length += <NUM_LIT:1> <EOL> if line_length + length + <NUM_LIT:1> > max_width : <EOL> prompt += '<STR_LIT:\n>' <EOL> line_length = <NUM_LIT:0> <EOL> if line_length != <NUM_LIT:0> : <EOL> part = '<STR_LIT:U+0020>' + part <EOL> length += <NUM_LIT:1> <EOL> prompt += part <EOL> line_length += length <EOL> if not fallback_prompt : <EOL> fallback_prompt = '<STR_LIT>' <EOL> if numrange : <EOL> fallback_prompt += '<STR_LIT>' % numrange <EOL> fallback_prompt += '<STR_LIT:U+002CU+0020>' . join ( display_letters ) + '<STR_LIT::>' <EOL> resp = self . input_ ( prompt ) <EOL> while True : <EOL> resp = resp . strip ( ) . lower ( ) <EOL> if default is not None and not resp : <EOL> resp = default <EOL> if numrange : <EOL> try : <EOL> resp = int ( resp ) <EOL> except ValueError : <EOL> pass <EOL> else : <EOL> low , high = numrange <EOL> if low <= resp <= high : <EOL> return resp <EOL> else : <EOL> resp = None <EOL> if resp : <EOL> resp = resp [ <NUM_LIT:0> ] <EOL> if resp in letters : <EOL> return resp <EOL> resp = self . input_ ( fallback_prompt ) <EOL> def input_ ( self , prompt = None ) : <EOL> """<STR_LIT>""" <EOL> if prompt : <EOL> if isinstance ( prompt , unicode ) : <EOL> prompt = prompt . encode ( self . _encoding ( ) , '<STR_LIT:replace>' ) <EOL> print ( prompt , end = '<STR_LIT:U+0020>' ) <EOL> try : <EOL> resp = raw_input ( ) <EOL> except EOFError : <EOL> self . debug . print_debug ( '<STR_LIT>' ) <EOL> return resp . decode ( sys . stdin . encoding or '<STR_LIT:utf8>' , '<STR_LIT:ignore>' ) <EOL> def _encoding ( self ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> return locale . getdefaultlocale ( ) [ <NUM_LIT:1> ] or '<STR_LIT:utf8>' <EOL> except ValueError : <EOL> return '<STR_LIT:utf8>' <EOL> def _colorize ( self , color , text ) : <EOL> """<STR_LIT>""" <EOL> if color in self . DARK_COLORS : <EOL> escape = self . COLOR_ESCAPE + "<STR_LIT>" % ( self . DARK_COLORS . index ( color ) + <NUM_LIT:30> ) <EOL> elif color in self . LIGHT_COLORS : <EOL> escape = self . COLOR_ESCAPE + "<STR_LIT>" % ( self . LIGHT_COLORS . index ( color ) + <NUM_LIT:30> ) <EOL> else : <EOL> raise ValueError ( '<STR_LIT>' , color ) <EOL> return escape + text + self . RESET_COLOR <EOL> def colorize ( self , color , text ) : <EOL> """<STR_LIT>""" <EOL> return self . _colorize ( color , text ) <EOL> def _colordiff ( self , a , b , highlight = '<STR_LIT>' , minor_highlight = '<STR_LIT>' ) : <EOL> """<STR_LIT>""" <EOL> if not isinstance ( a , basestring ) or not isinstance ( b , basestring ) : <EOL> a = unicode ( a ) <EOL> b = unicode ( b ) <EOL> if a == b : <EOL> return a , b <EOL> else : <EOL> return self . colorize ( highlight , a ) , self . colorize ( highlight , b ) <EOL> if isinstance ( a , bytes ) or isinstance ( b , bytes ) : <EOL> a = self . displayable_path ( a ) <EOL> b = self . displayable_path ( b ) <EOL> a_out = [ ] <EOL> b_out = [ ] <EOL> matcher = SequenceMatcher ( lambda x : False , a , b ) <EOL> for op , a_start , a_end , b_start , b_end in matcher . get_opcodes ( ) : <EOL> if op == '<STR_LIT>' : <EOL> a_out . append ( a [ a_start : a_end ] ) <EOL> b_out . append ( b [ b_start : b_end ] ) <EOL> elif op == '<STR_LIT>' : <EOL> b_out . append ( self . colorize ( highlight , b [ b_start : b_end ] ) ) <EOL> elif op == '<STR_LIT>' : <EOL> a_out . append ( self . colorize ( highlight , a [ a_start : a_end ] ) ) <EOL> elif op == '<STR_LIT:replace>' : <EOL> if a [ a_start : a_end ] . lower ( ) != b [ b_start : b_end ] . lower ( ) : <EOL> color = highlight <EOL> else : <EOL> color = minor_highlight <EOL> a_out . append ( self . colorize ( color , a [ a_start : a_end ] ) ) <EOL> b_out . append ( self . colorize ( color , b [ b_start : b_end ] ) ) <EOL> else : <EOL> assert ( False ) <EOL> return u'<STR_LIT>' . join ( a_out ) , u'<STR_LIT>' . join ( b_out ) <EOL> def displayable_path ( self , path , separator = u'<STR_LIT>' ) : <EOL> """<STR_LIT>""" <EOL> if isinstance ( path , ( list , tuple ) ) : <EOL> return separator . join ( self . displayable_path ( p ) for p in path ) <EOL> elif isinstance ( path , unicode ) : <EOL> return path <EOL> elif not isinstance ( path , str ) : <EOL> return unicode ( path ) <EOL> try : <EOL> return path . decode ( self . _fsencoding ( ) , '<STR_LIT:ignore>' ) <EOL> except ( UnicodeError , LookupError ) : <EOL> return path . decode ( '<STR_LIT:utf8>' , '<STR_LIT:ignore>' ) <EOL> def _fsencoding ( self ) : <EOL> """<STR_LIT>""" <EOL> encoding = sys . getfilesystemencoding ( ) or sys . getdefaultencoding ( ) <EOL> if encoding == '<STR_LIT>' : <EOL> encoding = '<STR_LIT:utf8>' <EOL> return encoding <EOL> def colordiff ( self , a , b , highlight = '<STR_LIT>' ) : <EOL> """<STR_LIT>""" <EOL> if self . gv . settings . get_setting ( '<STR_LIT>' , self ) == '<STR_LIT:True>' : <EOL> return self . _colordiff ( a , b , highlight ) <EOL> else : <EOL> return unicode ( a ) , unicode ( b ) <EOL> def print_ ( self , * strings ) : <EOL> """<STR_LIT>""" <EOL> if strings : <EOL> if isinstance ( strings [ <NUM_LIT:0> ] , unicode ) : <EOL> txt = u'<STR_LIT:U+0020>' . join ( strings ) <EOL> else : <EOL> txt = '<STR_LIT:U+0020>' . join ( strings ) <EOL> else : <EOL> txt = u'<STR_LIT>' <EOL> if isinstance ( txt , unicode ) : <EOL> txt = txt . encode ( self . _encoding ( ) , '<STR_LIT:replace>' ) <EOL> print ( txt ) <EOL> def color_diff_suffix ( self , a , b , highlight = '<STR_LIT>' ) : <EOL> """<STR_LIT>""" <EOL> a , b = unicode ( a ) , unicode ( b ) <EOL> if not self . gv . settings . get_setting ( '<STR_LIT>' , self ) == '<STR_LIT:True>' : <EOL> return a , b <EOL> if a == b : <EOL> return a , b <EOL> first_diff = None <EOL> for i in range ( min ( len ( a ) , len ( b ) ) ) : <EOL> if a [ i ] != b [ i ] : <EOL> first_diff = i <EOL> break <EOL> else : <EOL> first_diff = min ( len ( a ) , len ( b ) ) <EOL> return a [ : first_diff ] + self . colorize ( highlight , a [ first_diff : ] ) , b [ : first_diff ] + self . colorize ( highlight , b [ first_diff : ] ) <EOL> def choose_candidate ( self , candidates , manipulate , opts , item = None , itemcount = None ) : <EOL> self . print_ ( u'<STR_LIT>' ) <EOL> for i , match in enumerate ( candidates ) : <EOL> line = [ <EOL> u'<STR_LIT>' . format ( i + <NUM_LIT:1> ) , <EOL> u'<STR_LIT>' . format ( manipulate . get_stripped_text ( match . reference_to_link ) <EOL> ) <EOL> ] <EOL> self . print_ ( '<STR_LIT:U+0020>' . join ( line ) ) <EOL> sel = self . input_options ( opts , numrange = ( <NUM_LIT:1> , len ( candidates ) ) ) <EOL> return sel </s>
<s> """<STR_LIT>""" <EOL> import re <EOL> import string <EOL> from jsbeautifier . unpackers import UnpackingError <EOL> PRIORITY = <NUM_LIT:1> <EOL> def detect ( source ) : <EOL> """<STR_LIT>""" <EOL> return source . replace ( '<STR_LIT:U+0020>' , '<STR_LIT>' ) . startswith ( '<STR_LIT>' ) <EOL> def unpack ( source ) : <EOL> """<STR_LIT>""" <EOL> payload , symtab , radix , count = _filterargs ( source ) <EOL> if count != len ( symtab ) : <EOL> raise UnpackingError ( '<STR_LIT>' ) <EOL> try : <EOL> unbase = Unbaser ( radix ) <EOL> except TypeError : <EOL> raise UnpackingError ( '<STR_LIT>' ) <EOL> def lookup ( match ) : <EOL> """<STR_LIT>""" <EOL> word = match . group ( <NUM_LIT:0> ) <EOL> return symtab [ unbase ( word ) ] or word <EOL> source = re . sub ( r'<STR_LIT>' , lookup , payload ) <EOL> return _replacestrings ( source ) <EOL> def _filterargs ( source ) : <EOL> """<STR_LIT>""" <EOL> argsregex = ( r"<STR_LIT>" <EOL> r"<STR_LIT>" ) <EOL> args = re . search ( argsregex , source , re . DOTALL ) . groups ( ) <EOL> try : <EOL> return args [ <NUM_LIT:0> ] , args [ <NUM_LIT:3> ] . split ( '<STR_LIT:|>' ) , int ( args [ <NUM_LIT:1> ] ) , int ( args [ <NUM_LIT:2> ] ) <EOL> except ValueError : <EOL> raise UnpackingError ( '<STR_LIT>' ) <EOL> def _replacestrings ( source ) : <EOL> """<STR_LIT>""" <EOL> match = re . search ( r'<STR_LIT>' , source , re . DOTALL ) <EOL> if match : <EOL> varname , strings = match . groups ( ) <EOL> startpoint = len ( match . group ( <NUM_LIT:0> ) ) <EOL> lookup = strings . split ( '<STR_LIT>' ) <EOL> variable = '<STR_LIT>' % varname <EOL> for index , value in enumerate ( lookup ) : <EOL> source = source . replace ( variable % index , '<STR_LIT>' % value ) <EOL> return source [ startpoint : ] <EOL> return source <EOL> class Unbaser ( object ) : <EOL> """<STR_LIT>""" <EOL> ALPHABET = { <EOL> <NUM_LIT> : '<STR_LIT>' , <EOL> <NUM_LIT> : ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> } <EOL> def __init__ ( self , base ) : <EOL> self . base = base <EOL> if <NUM_LIT:2> <= base <= <NUM_LIT> : <EOL> self . unbase = lambda string : int ( string , base ) <EOL> else : <EOL> try : <EOL> self . dictionary = dict ( ( cipher , index ) for <EOL> index , cipher in enumerate ( self . ALPHABET [ base ] ) ) <EOL> except KeyError : <EOL> raise TypeError ( '<STR_LIT>' ) <EOL> self . unbase = self . _dictunbaser <EOL> def __call__ ( self , string ) : <EOL> return self . unbase ( string ) <EOL> def _dictunbaser ( self , string ) : <EOL> """<STR_LIT>""" <EOL> ret = <NUM_LIT:0> <EOL> for index , cipher in enumerate ( string [ : : - <NUM_LIT:1> ] ) : <EOL> ret += ( self . base ** index ) * self . dictionary [ cipher ] <EOL> return ret </s>
<s> import os , sys <EOL> parentdir = os . path . dirname ( __file__ ) <EOL> sys . path . insert ( <NUM_LIT:0> , parentdir ) <EOL> import executemechanize <EOL> class redirection : <EOL> def createarray ( self ) : <EOL> setattr ( self , "<STR_LIT>" , [ ] ) <EOL> def appendurl ( self , url ) : <EOL> url = str ( url ) <EOL> if not url . endswith ( "<STR_LIT>" ) or url . endswith ( "<STR_LIT>" ) : <EOL> self . redirection_list . append ( url ) ; <EOL> self . passarray ( ) <EOL> def passarray ( self ) : <EOL> executemechanize . set_redirection_list ( self . redirection_list ) </s>
<s> SQL_PORT = <NUM_LIT> <EOL> ZMQ_RPC_PORT = <NUM_LIT> <EOL> HTTP_PORT = <NUM_LIT> <EOL> HTTPS_PORT = <NUM_LIT> <EOL> ZMQ_PUBSUB_PORT = <NUM_LIT> </s>
<s> __author__ = '<STR_LIT>' <EOL> __copyright__ = '<STR_LIT>' <EOL> __license__ = '<STR_LIT>' <EOL> __version__ = '<STR_LIT>' <EOL> __maintainer__ = '<STR_LIT>' <EOL> __email__ = '<STR_LIT>' <EOL> __status__ = '<STR_LIT>' </s>
<s> """<STR_LIT>""" <EOL> from __future__ import absolute_import <EOL> from . . config import PATHS <EOL> from . . entity import Entity <EOL> class StrategyConcept ( Entity ) : <EOL> """<STR_LIT>""" <EOL> collection = '<STR_LIT>' <EOL> resource = '<STR_LIT>' <EOL> _relations = { <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> } <EOL> _pull = { <EOL> '<STR_LIT>' : int , <EOL> '<STR_LIT>' : Entity . _strpt , <EOL> '<STR_LIT:id>' : int , <EOL> '<STR_LIT:status>' : Entity . _int_to_bool , <EOL> '<STR_LIT>' : int , <EOL> '<STR_LIT>' : Entity . _strpt , <EOL> '<STR_LIT:version>' : int , <EOL> } <EOL> _push = _pull . copy ( ) <EOL> _push . update ( { <EOL> '<STR_LIT:status>' : int , <EOL> } ) <EOL> _readonly = Entity . _readonly | { '<STR_LIT:name>' , } <EOL> def __init__ ( self , session , properties = None , ** kwargs ) : <EOL> super ( StrategyConcept , self ) . __init__ ( session , properties , ** kwargs ) <EOL> def remove ( self ) : <EOL> """<STR_LIT>""" <EOL> url = '<STR_LIT:/>' . join ( [ self . collection , <EOL> str ( self . id ) , <EOL> '<STR_LIT>' ] ) <EOL> self . _post ( PATHS [ '<STR_LIT>' ] , rest = url , data = { '<STR_LIT:version>' : self . version } ) <EOL> for item in list ( self . properties . keys ( ) ) : <EOL> del self . properties [ item ] </s>
<s> from __future__ import print_function <EOL> from __future__ import absolute_import <EOL> import unittest <EOL> import responses <EOL> import requests <EOL> from . requests_patch import patched_extract_cookies_to_jar <EOL> from terminalone import T1 <EOL> mock_credentials = { <EOL> '<STR_LIT:username>' : '<STR_LIT>' , <EOL> '<STR_LIT:password>' : '<STR_LIT:password>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> } <EOL> API_BASE = '<STR_LIT>' <EOL> requests . sessions . extract_cookies_to_jar = patched_extract_cookies_to_jar <EOL> requests . adapters . extract_cookies_to_jar = patched_extract_cookies_to_jar <EOL> class TestPermissions ( unittest . TestCase ) : <EOL> def setup ( self ) : <EOL> """<STR_LIT>""" <EOL> with open ( '<STR_LIT>' ) as f : <EOL> fixture = f . read ( ) <EOL> responses . add ( responses . POST , '<STR_LIT>' , <EOL> body = fixture , <EOL> adding_headers = { <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> } , <EOL> content_type = '<STR_LIT>' ) <EOL> self . t1 = T1 ( auth_method = '<STR_LIT>' , <EOL> api_base = API_BASE , <EOL> ** mock_credentials ) <EOL> @ responses . activate <EOL> def test_get_permissions ( self ) : <EOL> self . setup ( ) <EOL> with open ( '<STR_LIT>' ) as f : <EOL> fixture = f . read ( ) <EOL> responses . add ( responses . GET , <EOL> '<STR_LIT>' , <EOL> body = fixture , <EOL> content_type = '<STR_LIT>' , <EOL> match_querystring = True ) <EOL> p = self . t1 . get ( '<STR_LIT>' , <NUM_LIT> , child = '<STR_LIT>' ) <EOL> assert p . _type == '<STR_LIT>' , '<STR_LIT>' . format ( p . _type ) <EOL> assert p . parent_id == <NUM_LIT> , '<STR_LIT>' . format ( p . parent_id ) <EOL> @ responses . activate <EOL> def test_remove_advertiser ( self ) : <EOL> self . setup ( ) <EOL> with open ( '<STR_LIT>' ) as f : <EOL> fixture = f . read ( ) <EOL> responses . add ( responses . GET , <EOL> '<STR_LIT>' , <EOL> body = fixture , <EOL> content_type = '<STR_LIT>' , <EOL> match_querystring = True ) <EOL> p = self . t1 . get ( '<STR_LIT>' , <NUM_LIT> , child = '<STR_LIT>' ) <EOL> remove_id = <NUM_LIT:6> <EOL> assert remove_id in p . advertiser . keys ( ) , '<STR_LIT>' . format ( remove_id ) <EOL> p . remove ( '<STR_LIT>' , <NUM_LIT:6> ) <EOL> assert remove_id not in p . advertiser . keys ( ) , '<STR_LIT>' . format ( remove_id ) <EOL> @ responses . activate <EOL> def test_it_should_remove_child_advertisers_when_removing_agency ( self ) : <EOL> self . setup ( ) <EOL> with open ( '<STR_LIT>' ) as f : <EOL> fixture = f . read ( ) <EOL> responses . add ( responses . GET , <EOL> '<STR_LIT>' , <EOL> body = fixture , <EOL> content_type = '<STR_LIT>' , <EOL> match_querystring = True ) <EOL> p = self . t1 . get ( '<STR_LIT>' , <NUM_LIT> , child = '<STR_LIT>' ) <EOL> remove_ids = [ <NUM_LIT:6> , <NUM_LIT:7> ] <EOL> for ad_id in remove_ids : <EOL> assert ad_id in p . advertiser . keys ( ) , '<STR_LIT>' . format ( ad_id ) <EOL> p . remove ( '<STR_LIT>' , <NUM_LIT:3> ) <EOL> for ad_id in remove_ids : <EOL> assert ad_id not in p . advertiser . keys ( ) , '<STR_LIT>' . format ( ad_id ) <EOL> @ responses . activate <EOL> def test_it_should_remove_child_agencies_and_advertisers_when_removing_organization ( self ) : <EOL> self . setup ( ) <EOL> with open ( '<STR_LIT>' ) as f : <EOL> fixture = f . read ( ) <EOL> responses . add ( responses . GET , <EOL> '<STR_LIT>' , <EOL> body = fixture , <EOL> content_type = '<STR_LIT>' , <EOL> match_querystring = True ) <EOL> p = self . t1 . get ( '<STR_LIT>' , <NUM_LIT> , child = '<STR_LIT>' ) <EOL> remove_advertiser_ids = [ <NUM_LIT:8> , <NUM_LIT:9> , <NUM_LIT:10> ] <EOL> remove_agency_ids = [ <NUM_LIT:4> , <NUM_LIT:5> ] <EOL> for advertiser_id in remove_advertiser_ids : <EOL> assert advertiser_id in p . advertiser . keys ( ) , '<STR_LIT>' . format ( advertiser_id ) <EOL> for agency_id in remove_agency_ids : <EOL> assert agency_id in p . agency . keys ( ) , '<STR_LIT>' . format ( agency_id ) <EOL> p . remove ( '<STR_LIT>' , <NUM_LIT:2> ) <EOL> for advertiser_id in remove_advertiser_ids : <EOL> assert advertiser_id not in p . advertiser . keys ( ) , '<STR_LIT>' . format ( advertiser_id ) <EOL> for agency_id in remove_agency_ids : <EOL> assert agency_id not in p . agency . keys ( ) , '<STR_LIT>' . format ( agency_id ) <EOL> @ responses . activate <EOL> def test_it_should_add_entity_ids_on_save ( self ) : <EOL> self . setup ( ) <EOL> with open ( '<STR_LIT>' ) as f : <EOL> fixture = f . read ( ) <EOL> responses . add ( responses . GET , <EOL> '<STR_LIT>' , <EOL> body = fixture , <EOL> content_type = '<STR_LIT>' , <EOL> match_querystring = True ) <EOL> p = self . t1 . get ( '<STR_LIT>' , <NUM_LIT> , child = '<STR_LIT>' ) <EOL> p . add ( '<STR_LIT>' , <NUM_LIT:10> ) <EOL> data = p . _generate_save_data ( ) <EOL> assert sorted ( data [ '<STR_LIT>' ] ) == [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:10> ] , data [ '<STR_LIT>' ] <EOL> @ responses . activate <EOL> def test_it_should_add_access_to_empty_permissions ( self ) : <EOL> self . setup ( ) <EOL> with open ( '<STR_LIT>' ) as f : <EOL> fixture = f . read ( ) <EOL> responses . add ( responses . GET , <EOL> '<STR_LIT>' , <EOL> body = fixture , <EOL> content_type = '<STR_LIT>' , <EOL> match_querystring = True ) <EOL> p = self . t1 . get ( '<STR_LIT>' , <NUM_LIT> , child = '<STR_LIT>' ) <EOL> p . add ( '<STR_LIT>' , <NUM_LIT:10> ) <EOL> data = p . _generate_save_data ( ) <EOL> assert sorted ( data [ '<STR_LIT>' ] ) == [ <NUM_LIT:10> ] , data [ '<STR_LIT>' ] </s>
<s> VERSION = ( <NUM_LIT:0> , <NUM_LIT:1> , <NUM_LIT:9> ) <EOL> __version__ = "<STR_LIT>" </s>
<s> import sys , os <EOL> sys . path . insert ( <NUM_LIT:0> , os . path . abspath ( '<STR_LIT:.>' ) ) <EOL> sys . path . insert ( <NUM_LIT:0> , os . path . abspath ( '<STR_LIT:..>' ) ) <EOL> needs_sphinx = '<STR_LIT:1.0>' <EOL> extensions = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> templates_path = [ '<STR_LIT>' ] <EOL> source_suffix = '<STR_LIT>' <EOL> master_doc = '<STR_LIT:index>' <EOL> project = u'<STR_LIT>' <EOL> copyright = u'<STR_LIT>' <EOL> import pkg_resources <EOL> try : <EOL> release = pkg_resources . get_distribution ( '<STR_LIT>' ) . version <EOL> except pkg_resources . DistributionNotFound : <EOL> print '<STR_LIT>' <EOL> print '<STR_LIT>' <EOL> print '<STR_LIT>' <EOL> print '<STR_LIT>' <EOL> sys . exit ( <NUM_LIT:1> ) <EOL> del pkg_resources <EOL> version = '<STR_LIT:.>' . join ( release . split ( '<STR_LIT:.>' ) [ : <NUM_LIT:2> ] ) <EOL> exclude_patterns = [ '<STR_LIT>' ] <EOL> pygments_style = '<STR_LIT>' <EOL> html_theme = '<STR_LIT>' <EOL> html_static_path = [ '<STR_LIT>' ] <EOL> html_use_smartypants = True <EOL> htmlhelp_basename = '<STR_LIT>' <EOL> latex_elements = { <EOL> } <EOL> latex_documents = [ <EOL> ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , <EOL> u'<STR_LIT>' , '<STR_LIT>' ) , <EOL> ] <EOL> man_pages = [ <EOL> ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , <EOL> [ u'<STR_LIT>' ] , <NUM_LIT:1> ) <EOL> ] <EOL> texinfo_documents = [ <EOL> ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , <EOL> u'<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' ) , <EOL> ] </s>
<s> import math <EOL> import glob <EOL> import re <EOL> import os <EOL> import subprocess <EOL> from shutil import rmtree <EOL> import logging <EOL> from mrec import load_sparse_matrix , save_recommender <EOL> class ItemSimilarityRunner ( object ) : <EOL> def run ( self , view , model , input_format , trainfile , num_engines , simsdir , overwrite , max_sims , simsfile , modelfile ) : <EOL> logging . info ( '<STR_LIT>' ) <EOL> dataset = load_sparse_matrix ( input_format , trainfile ) <EOL> num_users , num_items = dataset . shape <EOL> del dataset <EOL> logging . info ( '<STR_LIT>' , num_users , num_items ) <EOL> logging . info ( '<STR_LIT>' . format ( simsdir ) ) <EOL> subprocess . check_call ( [ '<STR_LIT>' , '<STR_LIT>' , simsdir ] ) <EOL> done = [ ] <EOL> if not overwrite : <EOL> logging . info ( '<STR_LIT>' ) <EOL> done . extend ( self . find_done ( simsdir ) ) <EOL> if done : <EOL> logging . info ( '<STR_LIT>' . format ( len ( done ) ) ) <EOL> logging . info ( '<STR_LIT>' ) <EOL> tasks = self . create_tasks ( model , input_format , trainfile , simsdir , num_items , num_engines , max_sims , done ) <EOL> if num_engines > <NUM_LIT:0> : <EOL> logging . info ( '<STR_LIT>' <EOL> '<STR_LIT>' , len ( tasks ) ) <EOL> async_job = view . map_async ( process , tasks , retries = <NUM_LIT:2> ) <EOL> results = async_job . get ( ) <EOL> else : <EOL> logging . info ( '<STR_LIT>' ) <EOL> results = [ process ( task ) for task in tasks ] <EOL> logging . info ( '<STR_LIT>' ) <EOL> done = self . find_done ( simsdir ) <EOL> remaining = len ( tasks ) - len ( done ) <EOL> if remaining == <NUM_LIT:0> : <EOL> logging . info ( '<STR_LIT>' ) <EOL> logging . info ( '<STR_LIT>' . format ( len ( done ) ) ) <EOL> paths = [ os . path . join ( simsdir , '<STR_LIT>' . format ( start , end ) ) for start , end in done ] <EOL> cmd = [ '<STR_LIT>' ] + paths <EOL> subprocess . check_call ( cmd , stdout = open ( simsfile , '<STR_LIT:w>' ) ) <EOL> logging . info ( '<STR_LIT>' ) <EOL> rmtree ( simsdir ) <EOL> logging . info ( '<STR_LIT>' , <EOL> num_items , type ( model ) . __name__ , simsfile ) <EOL> model . load_similarity_matrix ( simsfile , num_items ) <EOL> save_recommender ( model , modelfile ) <EOL> logging . info ( '<STR_LIT>' ) <EOL> else : <EOL> logging . error ( '<STR_LIT>' . format ( remaining , len ( tasks ) ) ) <EOL> logging . error ( '<STR_LIT>' ) <EOL> def find_done ( self , outdir ) : <EOL> success_files = glob . glob ( os . path . join ( outdir , '<STR_LIT>' ) ) <EOL> r = re . compile ( '<STR_LIT>' ) <EOL> done = [ ] <EOL> for path in success_files : <EOL> m = r . match ( path ) <EOL> start = int ( m . group ( <NUM_LIT:1> ) ) <EOL> end = int ( m . group ( <NUM_LIT:2> ) ) <EOL> done . append ( ( start , end ) ) <EOL> return done <EOL> def create_tasks ( self , model , input_format , trainfile , outdir , num_items , num_engines , max_similar_items , done ) : <EOL> if num_engines == <NUM_LIT:0> : <EOL> num_engines = <NUM_LIT:1> <EOL> items_per_engine = int ( math . ceil ( float ( num_items ) / num_engines ) ) <EOL> tasks = [ ] <EOL> for start in xrange ( <NUM_LIT:0> , num_items , items_per_engine ) : <EOL> end = min ( num_items , start + items_per_engine ) <EOL> if ( start , end ) not in done : <EOL> tasks . append ( ( model , input_format , trainfile , outdir , start , end , max_similar_items ) ) <EOL> return tasks <EOL> def process ( task ) : <EOL> """<STR_LIT>""" <EOL> import os <EOL> import subprocess <EOL> from mrec import load_fast_sparse_matrix <EOL> model , input_format , trainfile , outdir , start , end , max_similar_items = task <EOL> dataset = load_fast_sparse_matrix ( input_format , trainfile ) <EOL> if hasattr ( model , '<STR_LIT>' ) : <EOL> model . similarity_matrix = None <EOL> outfile = os . path . join ( outdir , '<STR_LIT>' . format ( start , end ) ) <EOL> out = open ( outfile , '<STR_LIT:w>' ) <EOL> for j in xrange ( start , end ) : <EOL> w = model . get_similar_items ( j , max_similar_items = max_similar_items , dataset = dataset ) <EOL> for k , v in w : <EOL> print >> out , '<STR_LIT>' . format ( j + <NUM_LIT:1> , k + <NUM_LIT:1> , v ) <EOL> out . close ( ) <EOL> cmd = [ '<STR_LIT>' , os . path . join ( outdir , '<STR_LIT>' . format ( start , end ) ) ] <EOL> subprocess . check_call ( cmd ) <EOL> return start , end </s>
<s> """<STR_LIT>""" <EOL> import inspect <EOL> NO_DEFAULT = object ( ) <EOL> def memoize_default ( default = NO_DEFAULT , evaluator_is_first_arg = False , second_arg_is_evaluator = False ) : <EOL> """<STR_LIT>""" <EOL> def func ( function ) : <EOL> def wrapper ( obj , * args , ** kwargs ) : <EOL> if evaluator_is_first_arg : <EOL> cache = obj . memoize_cache <EOL> elif second_arg_is_evaluator : <EOL> cache = args [ <NUM_LIT:0> ] . memoize_cache <EOL> else : <EOL> cache = obj . _evaluator . memoize_cache <EOL> try : <EOL> memo = cache [ function ] <EOL> except KeyError : <EOL> memo = { } <EOL> cache [ function ] = memo <EOL> key = ( obj , args , frozenset ( kwargs . items ( ) ) ) <EOL> if key in memo : <EOL> return memo [ key ] <EOL> else : <EOL> if default is not NO_DEFAULT : <EOL> memo [ key ] = default <EOL> rv = function ( obj , * args , ** kwargs ) <EOL> if inspect . isgenerator ( rv ) : <EOL> rv = list ( rv ) <EOL> memo [ key ] = rv <EOL> return rv <EOL> return wrapper <EOL> return func <EOL> class CachedMetaClass ( type ) : <EOL> """<STR_LIT>""" <EOL> @ memoize_default ( None , second_arg_is_evaluator = True ) <EOL> def __call__ ( self , * args , ** kwargs ) : <EOL> return super ( CachedMetaClass , self ) . __call__ ( * args , ** kwargs ) </s>
<s> """<STR_LIT>""" <EOL> from __future__ import absolute_import <EOL> import __main__ <EOL> from collections import namedtuple <EOL> import re <EOL> import os <EOL> import sys <EOL> from jedi import Interpreter <EOL> from jedi . api . helpers import completion_parts <EOL> from jedi . parser . user_context import UserContext <EOL> def setup_readline ( namespace_module = __main__ ) : <EOL> """<STR_LIT>""" <EOL> class JediRL ( object ) : <EOL> def complete ( self , text , state ) : <EOL> """<STR_LIT>""" <EOL> if state == <NUM_LIT:0> : <EOL> sys . path . insert ( <NUM_LIT:0> , os . getcwd ( ) ) <EOL> try : <EOL> interpreter = Interpreter ( text , [ namespace_module . __dict__ ] ) <EOL> path = UserContext ( text , ( <NUM_LIT:1> , len ( text ) ) ) . get_path_until_cursor ( ) <EOL> path , dot , like = completion_parts ( path ) <EOL> before = text [ : len ( text ) - len ( like ) ] <EOL> completions = interpreter . completions ( ) <EOL> finally : <EOL> sys . path . pop ( <NUM_LIT:0> ) <EOL> self . matches = [ before + c . name_with_symbols for c in completions ] <EOL> try : <EOL> return self . matches [ state ] <EOL> except IndexError : <EOL> return None <EOL> try : <EOL> import readline <EOL> except ImportError : <EOL> print ( "<STR_LIT>" ) <EOL> else : <EOL> readline . set_completer ( JediRL ( ) . complete ) <EOL> readline . parse_and_bind ( "<STR_LIT>" ) <EOL> readline . parse_and_bind ( "<STR_LIT>" ) <EOL> readline . parse_and_bind ( "<STR_LIT>" ) <EOL> readline . parse_and_bind ( "<STR_LIT>" ) <EOL> readline . parse_and_bind ( "<STR_LIT>" ) <EOL> readline . set_completer_delims ( '<STR_LIT>' ) <EOL> def version_info ( ) : <EOL> """<STR_LIT>""" <EOL> Version = namedtuple ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> from jedi import __version__ <EOL> tupl = re . findall ( '<STR_LIT>' , __version__ ) <EOL> return Version ( * [ x if i == <NUM_LIT:3> else int ( x ) for i , x in enumerate ( tupl ) ] ) </s>
<s> import collections <EOL> import copy <EOL> from . Utils import _write_complex_object <EOL> class ExceptionDetails ( object ) : <EOL> """<STR_LIT>""" <EOL> _defaults = collections . OrderedDict ( [ <EOL> ( '<STR_LIT:id>' , None ) , <EOL> ( '<STR_LIT>' , None ) , <EOL> ( '<STR_LIT>' , None ) , <EOL> ( '<STR_LIT:message>' , None ) , <EOL> ( '<STR_LIT>' , True ) , <EOL> ( '<STR_LIT>' , None ) , <EOL> ( '<STR_LIT>' , [ ] ) <EOL> ] ) <EOL> def __init__ ( self ) : <EOL> """<STR_LIT>""" <EOL> self . _values = { <EOL> '<STR_LIT>' : None , <EOL> '<STR_LIT:message>' : None , <EOL> '<STR_LIT>' : True , <EOL> } <EOL> self . _initialize ( ) <EOL> @ property <EOL> def id ( self ) : <EOL> """<STR_LIT>""" <EOL> if '<STR_LIT:id>' in self . _values : <EOL> return self . _values [ '<STR_LIT:id>' ] <EOL> return self . _defaults [ '<STR_LIT:id>' ] <EOL> @ id . setter <EOL> def id ( self , value ) : <EOL> """<STR_LIT>""" <EOL> if value == self . _defaults [ '<STR_LIT:id>' ] and '<STR_LIT:id>' in self . _values : <EOL> del self . _values [ '<STR_LIT:id>' ] <EOL> else : <EOL> self . _values [ '<STR_LIT:id>' ] = value <EOL> @ property <EOL> def outer_id ( self ) : <EOL> """<STR_LIT>""" <EOL> if '<STR_LIT>' in self . _values : <EOL> return self . _values [ '<STR_LIT>' ] <EOL> return self . _defaults [ '<STR_LIT>' ] <EOL> @ outer_id . setter <EOL> def outer_id ( self , value ) : <EOL> """<STR_LIT>""" <EOL> if value == self . _defaults [ '<STR_LIT>' ] and '<STR_LIT>' in self . _values : <EOL> del self . _values [ '<STR_LIT>' ] <EOL> else : <EOL> self . _values [ '<STR_LIT>' ] = value <EOL> @ property <EOL> def type_name ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . _values [ '<STR_LIT>' ] <EOL> @ type_name . setter <EOL> def type_name ( self , value ) : <EOL> """<STR_LIT>""" <EOL> self . _values [ '<STR_LIT>' ] = value <EOL> @ property <EOL> def message ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . _values [ '<STR_LIT:message>' ] <EOL> @ message . setter <EOL> def message ( self , value ) : <EOL> """<STR_LIT>""" <EOL> self . _values [ '<STR_LIT:message>' ] = value <EOL> @ property <EOL> def has_full_stack ( self ) : <EOL> """<STR_LIT>""" <EOL> if '<STR_LIT>' in self . _values : <EOL> return self . _values [ '<STR_LIT>' ] <EOL> return self . _defaults [ '<STR_LIT>' ] <EOL> @ has_full_stack . setter <EOL> def has_full_stack ( self , value ) : <EOL> """<STR_LIT>""" <EOL> if value == self . _defaults [ '<STR_LIT>' ] and '<STR_LIT>' in self . _values : <EOL> del self . _values [ '<STR_LIT>' ] <EOL> else : <EOL> self . _values [ '<STR_LIT>' ] = value <EOL> @ property <EOL> def stack ( self ) : <EOL> """<STR_LIT>""" <EOL> if '<STR_LIT>' in self . _values : <EOL> return self . _values [ '<STR_LIT>' ] <EOL> return self . _defaults [ '<STR_LIT>' ] <EOL> @ stack . setter <EOL> def stack ( self , value ) : <EOL> """<STR_LIT>""" <EOL> if value == self . _defaults [ '<STR_LIT>' ] and '<STR_LIT>' in self . _values : <EOL> del self . _values [ '<STR_LIT>' ] <EOL> else : <EOL> self . _values [ '<STR_LIT>' ] = value <EOL> @ property <EOL> def parsed_stack ( self ) : <EOL> """<STR_LIT>""" <EOL> if '<STR_LIT>' in self . _values : <EOL> return self . _values [ '<STR_LIT>' ] <EOL> self . _values [ '<STR_LIT>' ] = copy . deepcopy ( self . _defaults [ '<STR_LIT>' ] ) <EOL> return self . _values [ '<STR_LIT>' ] <EOL> @ parsed_stack . setter <EOL> def parsed_stack ( self , value ) : <EOL> """<STR_LIT>""" <EOL> if value == self . _defaults [ '<STR_LIT>' ] and '<STR_LIT>' in self . _values : <EOL> del self . _values [ '<STR_LIT>' ] <EOL> else : <EOL> self . _values [ '<STR_LIT>' ] = value <EOL> def _initialize ( self ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> def write ( self ) : <EOL> """<STR_LIT>""" <EOL> return _write_complex_object ( self . _defaults , self . _values ) </s>
<s> import random <EOL> import unittest <EOL> import time <EOL> import threading <EOL> try : <EOL> import BaseHTTPServer as HTTPServer <EOL> except ImportError : <EOL> import http . server as HTTPServer <EOL> import sys , os , os . path <EOL> rootDirectory = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ ) ) , '<STR_LIT:..>' , '<STR_LIT:..>' ) <EOL> if rootDirectory not in sys . path : <EOL> sys . path . append ( rootDirectory ) <EOL> from applicationinsights import channel <EOL> class TestSenderBase ( unittest . TestCase ) : <EOL> def test_construct ( self ) : <EOL> actual = channel . SenderBase ( '<STR_LIT>' ) <EOL> self . assertIsNotNone ( actual ) <EOL> self . assertEqual ( '<STR_LIT>' , actual . service_endpoint_uri ) <EOL> self . assertIsNone ( actual . queue ) <EOL> self . assertEqual ( <NUM_LIT:100> , actual . send_buffer_size ) <EOL> def test_service_endpoint_uri_works_as_expected ( self ) : <EOL> actual = channel . SenderBase ( '<STR_LIT>' ) <EOL> self . assertEqual ( '<STR_LIT>' , actual . service_endpoint_uri ) <EOL> actual . service_endpoint_uri = '<STR_LIT:foo>' <EOL> self . assertEqual ( '<STR_LIT:foo>' , actual . service_endpoint_uri ) <EOL> def test_queue_works_as_expected ( self ) : <EOL> actual = channel . SenderBase ( '<STR_LIT>' ) <EOL> self . assertIsNone ( actual . queue ) <EOL> expected = object ( ) <EOL> actual . queue = expected <EOL> self . assertEqual ( expected , actual . queue ) <EOL> def test_send_buffer_size_works_as_expected ( self ) : <EOL> actual = channel . SenderBase ( '<STR_LIT>' ) <EOL> self . assertEqual ( <NUM_LIT:100> , actual . send_buffer_size ) <EOL> actual . send_buffer_size = <NUM_LIT> <EOL> self . assertEqual ( <NUM_LIT> , actual . send_buffer_size ) <EOL> actual . send_buffer_size = - <NUM_LIT:1> <EOL> self . assertEqual ( <NUM_LIT:1> , actual . send_buffer_size ) <EOL> def test_send_works_as_expected ( self ) : <EOL> port = random . randint ( <NUM_LIT> , <NUM_LIT> ) <EOL> actual = channel . SenderBase ( "<STR_LIT>" + str ( port ) + "<STR_LIT>" ) <EOL> actual . queue = channel . QueueBase ( None ) <EOL> MockHTTPRequestHandler . ExpectedContent = "<STR_LIT>" <EOL> MockHTTPRequestHandler . TestCase = self <EOL> thread = WorkerThread ( actual ) <EOL> thread . start ( ) <EOL> runHttpHandlerOnce ( handler = MockHTTPRequestHandler , port = port ) <EOL> thread . join ( ) <EOL> if "<STR_LIT>" in dir ( self ) : <EOL> self . fail ( self . failed ) <EOL> self . assertEqual ( None , actual . queue . get ( ) ) <EOL> class WorkerThread ( threading . Thread ) : <EOL> def __init__ ( self , sender ) : <EOL> threading . Thread . __init__ ( self ) <EOL> self . sender = sender <EOL> def run ( self ) : <EOL> time . sleep ( <NUM_LIT:1> ) <EOL> self . sender . send ( [ MockSerializable ( <NUM_LIT> ) , MockSerializable ( <NUM_LIT> ) ] ) <EOL> class MockSerializable ( object ) : <EOL> def __init__ ( self , data ) : <EOL> self . _data = data <EOL> def write ( self ) : <EOL> return self . _data <EOL> class MockHTTPRequestHandler ( HTTPServer . BaseHTTPRequestHandler ) : <EOL> ExpectedContent = None <EOL> TestCase = None <EOL> def do_POST ( self ) : <EOL> contentLength = int ( self . headers [ '<STR_LIT>' ] ) <EOL> content = self . rfile . read ( contentLength ) <EOL> response = "<STR_LIT>" <EOL> if isinstance ( content , bytes ) : <EOL> content = content . decode ( "<STR_LIT:utf-8>" ) <EOL> response = b"<STR_LIT>" <EOL> if "<STR_LIT:POST>" != self . command : <EOL> MockHTTPRequestHandler . TestCase . failed = '<STR_LIT>' <EOL> if "<STR_LIT>" != self . headers [ "<STR_LIT:Content-Type>" ] : <EOL> MockHTTPRequestHandler . TestCase . failed = '<STR_LIT>' <EOL> if MockHTTPRequestHandler . ExpectedContent != content : <EOL> MockHTTPRequestHandler . TestCase . failed = '<STR_LIT:">' + MockHTTPRequestHandler . ExpectedContent + '<STR_LIT>' <EOL> self . send_response ( <NUM_LIT:200> ) <EOL> self . send_header ( "<STR_LIT:Content-Type>" , "<STR_LIT:application/json>" ) <EOL> self . send_header ( "<STR_LIT>" , "<STR_LIT:0>" ) <EOL> self . end_headers ( ) <EOL> self . wfile . write ( response ) <EOL> def runHttpHandlerOnce ( server = HTTPServer . HTTPServer , handler = HTTPServer . BaseHTTPRequestHandler , port = <NUM_LIT> ) : <EOL> serverAddress = ( '<STR_LIT>' , port ) <EOL> httpd = server ( serverAddress , handler ) <EOL> httpd . handle_request ( ) </s>
<s> from . import TestEnable </s>
<s> """<STR_LIT>""" <EOL> import sys as _sys <EOL> from operator import itemgetter as _itemgetter <EOL> from keyword import iskeyword as _iskeyword <EOL> from collections import OrderedDict <EOL> class tagtuple ( tuple ) : <EOL> """<STR_LIT>""" <EOL> __slots__ = ( ) <EOL> def __new__ ( cls , * args ) : <EOL> """<STR_LIT>""" <EOL> return super ( tagtuple , cls ) . __new__ ( cls , args ) <EOL> def __repr__ ( self ) : <EOL> """<STR_LIT>""" <EOL> return type ( self ) . __name__ + super ( tagtuple , self ) . __repr__ ( ) <EOL> def __getnewargs__ ( self ) : <EOL> """<STR_LIT>""" <EOL> return tuple ( self ) <EOL> def __eq__ ( self , other ) : <EOL> return type ( self ) is type ( other ) and super ( tagtuple , self ) . __eq__ ( other ) <EOL> def __ne__ ( self , other ) : <EOL> return not self . __eq__ ( other ) <EOL> def __getslice__ ( self , i , j ) : <EOL> return type ( self ) ( * super ( tagtuple , self ) . __getslice__ ( i , j ) ) <EOL> __add__ = property ( ) <EOL> __contains__ = property ( ) <EOL> __mul__ = property ( ) <EOL> __rmul__ = property ( ) <EOL> count = property ( ) <EOL> index = property ( ) <EOL> _class_template = '''<STR_LIT>''' <EOL> _repr_template = '<STR_LIT>' <EOL> _field_template = '''<STR_LIT>''' <EOL> def rectuple ( typename , field_names , verbose = False , rename = False ) : <EOL> """<STR_LIT>""" <EOL> if isinstance ( field_names , basestring ) : <EOL> field_names = field_names . replace ( '<STR_LIT:U+002C>' , '<STR_LIT:U+0020>' ) . split ( ) <EOL> field_names = map ( str , field_names ) <EOL> if rename : <EOL> seen = set ( ) <EOL> for index , name in enumerate ( field_names ) : <EOL> if ( not all ( c . isalnum ( ) or c == '<STR_LIT:_>' for c in name ) <EOL> or _iskeyword ( name ) <EOL> or not name <EOL> or name [ <NUM_LIT:0> ] . isdigit ( ) <EOL> or name . startswith ( '<STR_LIT:_>' ) <EOL> or name in seen ) : <EOL> field_names [ index ] = '<STR_LIT>' % index <EOL> seen . add ( name ) <EOL> for name in [ typename ] + field_names : <EOL> if not all ( c . isalnum ( ) or c == '<STR_LIT:_>' for c in name ) : <EOL> raise ValueError ( '<STR_LIT>' <EOL> '<STR_LIT>' % name ) <EOL> if _iskeyword ( name ) : <EOL> raise ValueError ( '<STR_LIT>' <EOL> '<STR_LIT>' % name ) <EOL> if name [ <NUM_LIT:0> ] . isdigit ( ) : <EOL> raise ValueError ( '<STR_LIT>' <EOL> '<STR_LIT>' % name ) <EOL> seen = set ( ) <EOL> for name in field_names : <EOL> if name . startswith ( '<STR_LIT:_>' ) and not rename : <EOL> raise ValueError ( '<STR_LIT>' <EOL> '<STR_LIT>' % name ) <EOL> if name in seen : <EOL> raise ValueError ( '<STR_LIT>' % name ) <EOL> seen . add ( name ) <EOL> class_definition = _class_template . format ( <EOL> typename = typename , <EOL> field_names = tuple ( field_names ) , <EOL> num_fields = len ( field_names ) , <EOL> arg_list = repr ( tuple ( field_names ) ) . replace ( "<STR_LIT:'>" , "<STR_LIT>" ) [ <NUM_LIT:1> : - <NUM_LIT:1> ] , <EOL> repr_fmt = '<STR_LIT:U+002CU+0020>' . join ( _repr_template . format ( name = name ) <EOL> for name in field_names ) , <EOL> field_defs = '<STR_LIT:\n>' . join ( _field_template . format ( index = index , name = name ) <EOL> for index , name in enumerate ( field_names ) ) <EOL> ) <EOL> if verbose : <EOL> print class_definition <EOL> namespace = dict ( _itemgetter = _itemgetter , __name__ = '<STR_LIT>' % typename , <EOL> OrderedDict = OrderedDict , _property = property , _tuple = tuple ) <EOL> try : <EOL> exec class_definition in namespace <EOL> except SyntaxError as e : <EOL> raise SyntaxError ( e . message + '<STR_LIT>' + class_definition ) <EOL> result = namespace [ typename ] <EOL> try : <EOL> result . __module__ = _sys . _getframe ( <NUM_LIT:1> ) . f_globals . get ( '<STR_LIT>' , '<STR_LIT:__main__>' ) <EOL> except ( AttributeError , ValueError ) : <EOL> pass <EOL> return result <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> import pickle <EOL> from itertools import chain , product <EOL> print "<STR_LIT>" <EOL> print <EOL> class A ( tagtuple ) : <EOL> __slots__ = ( ) <EOL> class B ( tagtuple ) : <EOL> __slots__ = ( ) <EOL> a = A ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) <EOL> b = B ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) <EOL> t = ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) <EOL> print "<STR_LIT>" , a <EOL> print "<STR_LIT>" , b <EOL> print "<STR_LIT>" , t <EOL> print <EOL> print "<STR_LIT>" , a == b <EOL> print "<STR_LIT>" , a != b <EOL> print "<STR_LIT>" , hash ( a ) == hash ( b ) <EOL> print "<STR_LIT>" , a <= b <EOL> print "<STR_LIT>" , b <= a <EOL> print <EOL> print "<STR_LIT>" , a == t <EOL> print "<STR_LIT>" , a != t <EOL> print "<STR_LIT>" , hash ( a ) == hash ( t ) <EOL> print "<STR_LIT>" , a <= t <EOL> print "<STR_LIT>" , t <= a <EOL> print <EOL> d = { } <EOL> d [ a ] = <NUM_LIT:1> <EOL> d [ b ] = <NUM_LIT:2> <EOL> d [ t ] = <NUM_LIT:3> <EOL> print "<STR_LIT>" , d <EOL> s = set ( ) <EOL> s . add ( a ) <EOL> s . add ( b ) <EOL> s . add ( t ) <EOL> print "<STR_LIT>" , s <EOL> print <EOL> print "<STR_LIT>" , tuple ( x for x in a ) <EOL> print "<STR_LIT>" , list ( a ) <EOL> print "<STR_LIT>" , tuple ( a ) <EOL> print <EOL> a0 = pickle . loads ( pickle . dumps ( a , <NUM_LIT:0> ) ) <EOL> a1 = pickle . loads ( pickle . dumps ( a , <NUM_LIT:1> ) ) <EOL> a2 = pickle . loads ( pickle . dumps ( a , <NUM_LIT:2> ) ) <EOL> print "<STR_LIT>" , a0 <EOL> print "<STR_LIT>" , a1 <EOL> print "<STR_LIT>" , a2 <EOL> print "<STR_LIT>" , a0 == a , hash ( a0 ) == hash ( a ) <EOL> print "<STR_LIT>" , a1 == a , hash ( a1 ) == hash ( a ) <EOL> print "<STR_LIT>" , a2 == a , hash ( a2 ) == hash ( a ) <EOL> print <EOL> print "<STR_LIT>" , a [ : ] <EOL> print "<STR_LIT>" , a [ <NUM_LIT:1> : - <NUM_LIT:1> ] <EOL> print "<STR_LIT>" , a + a <EOL> print "<STR_LIT>" , a + b <EOL> print "<STR_LIT>" , ( <NUM_LIT:0> , ) + a <EOL> print "<STR_LIT>" , a + ( <NUM_LIT:0> , ) <EOL> print "<STR_LIT>" , <NUM_LIT:2> * a <EOL> print "<STR_LIT>" , a * <NUM_LIT:2> <EOL> print <EOL> print "<STR_LIT>" , A ( * chain ( ( x ** <NUM_LIT:2> for x in range ( <NUM_LIT:10> ) ) , a ) ) <EOL> print "<STR_LIT>" , A ( * product ( range ( <NUM_LIT:3> ) , repeat = <NUM_LIT:2> ) ) <EOL> print <EOL> print "<STR_LIT>" <EOL> print <EOL> A = rectuple ( '<STR_LIT:A>' , '<STR_LIT>' , verbose = True ) <EOL> B = rectuple ( '<STR_LIT:B>' , '<STR_LIT>' , verbose = True ) <EOL> a = A ( <NUM_LIT:1> , <NUM_LIT:2> ) <EOL> b = B ( <NUM_LIT:1> , <NUM_LIT:2> ) <EOL> t = ( <NUM_LIT:1> , <NUM_LIT:2> ) <EOL> print "<STR_LIT>" , a <EOL> print "<STR_LIT>" , b <EOL> print "<STR_LIT>" , t <EOL> print <EOL> print "<STR_LIT>" , a == b <EOL> print "<STR_LIT>" , a != b <EOL> print "<STR_LIT>" , hash ( a ) == hash ( b ) <EOL> print "<STR_LIT>" , a <= b <EOL> print "<STR_LIT>" , b <= a <EOL> print <EOL> print "<STR_LIT>" , a == t <EOL> print "<STR_LIT>" , a != t <EOL> print "<STR_LIT>" , hash ( a ) == hash ( t ) <EOL> print "<STR_LIT>" , a <= t <EOL> print "<STR_LIT>" , t <= a <EOL> print <EOL> d = { } <EOL> d [ a ] = <NUM_LIT:1> <EOL> d [ b ] = <NUM_LIT:2> <EOL> d [ t ] = <NUM_LIT:3> <EOL> print "<STR_LIT>" , d <EOL> s = set ( ) <EOL> s . add ( a ) <EOL> s . add ( b ) <EOL> s . add ( t ) <EOL> print "<STR_LIT>" , s <EOL> print <EOL> print "<STR_LIT>" , tuple ( x for x in a ) <EOL> print "<STR_LIT>" , list ( a ) <EOL> print "<STR_LIT>" , tuple ( a ) <EOL> print <EOL> a0 = pickle . loads ( pickle . dumps ( a , <NUM_LIT:0> ) ) <EOL> a1 = pickle . loads ( pickle . dumps ( a , <NUM_LIT:1> ) ) <EOL> a2 = pickle . loads ( pickle . dumps ( a , <NUM_LIT:2> ) ) <EOL> print "<STR_LIT>" , a0 <EOL> print "<STR_LIT>" , a1 <EOL> print "<STR_LIT>" , a2 <EOL> print "<STR_LIT>" , a0 == a , hash ( a0 ) == hash ( a ) <EOL> print "<STR_LIT>" , a1 == a , hash ( a1 ) == hash ( a ) <EOL> print "<STR_LIT>" , a2 == a , hash ( a2 ) == hash ( a ) </s>
<s> import pandas <EOL> import util <EOL> import matplotlib . pyplot as plt <EOL> import scipy as sp <EOL> import scipy . stats <EOL> import numpy as np <EOL> import os <EOL> cur_dir = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> def from_custom_file ( data_file , learn_options ) : <EOL> print "<STR_LIT>" % data_file <EOL> data = pandas . read_csv ( data_file ) <EOL> mandatory_columns = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> for col in mandatory_columns : <EOL> assert col in data . columns , "<STR_LIT>" % mandatory_columns <EOL> Xdf = pandas . DataFrame ( data ) <EOL> Xdf [ '<STR_LIT>' ] = Xdf [ '<STR_LIT>' ] <EOL> Xdf = Xdf . set_index ( [ '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> Xdf [ '<STR_LIT>' ] = Xdf [ '<STR_LIT>' ] <EOL> Xdf . index . names = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> Xdf [ '<STR_LIT>' ] = [ '<STR_LIT>' % i for i in range ( Xdf . shape [ <NUM_LIT:0> ] ) ] <EOL> Xdf = Xdf . set_index ( '<STR_LIT>' , append = True ) <EOL> Y = None <EOL> gene_position = Xdf [ [ '<STR_LIT>' , '<STR_LIT>' ] ] <EOL> target_genes = np . unique ( Xdf . index . levels [ <NUM_LIT:1> ] ) <EOL> learn_options = set_V2_target_names ( learn_options ) <EOL> return Xdf , Y , gene_position , target_genes <EOL> def from_file ( data_file , learn_options , data_file2 = None , data_file3 = None ) : <EOL> if learn_options [ "<STR_LIT>" ] == <NUM_LIT:1> : <EOL> print "<STR_LIT>" % learn_options [ "<STR_LIT>" ] <EOL> assert not learn_options [ "<STR_LIT>" ] is not None , "<STR_LIT>" <EOL> annotations , gene_position , target_genes , Xdf , Y = read_V1_data ( data_file , learn_options ) <EOL> learn_options [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> learn_options [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> learn_options [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> elif learn_options [ "<STR_LIT>" ] == <NUM_LIT:2> : <EOL> Xdf , drugs_to_genes , target_genes , Y , gene_position = read_V2_data ( data_file , learn_options ) <EOL> xx = Xdf [ '<STR_LIT>' ] . values <EOL> yy = Y [ '<STR_LIT>' ] . values <EOL> rr , pp = sp . stats . pearsonr ( xx , yy ) <EOL> assert rr > <NUM_LIT:0> , "<STR_LIT>" <EOL> learn_options = set_V2_target_names ( learn_options ) <EOL> elif learn_options [ "<STR_LIT>" ] == <NUM_LIT:3> : <EOL> learn_options [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> learn_options [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> learn_options [ '<STR_LIT>' ] = None <EOL> Xdf , Y , gene_position , target_genes = mergeV1_V2 ( data_file , data_file2 , learn_options ) <EOL> elif learn_options [ "<STR_LIT>" ] == <NUM_LIT:4> : <EOL> learn_options [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> learn_options [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> learn_options [ '<STR_LIT>' ] = None <EOL> Xdf , Y , gene_position , target_genes = merge_all ( data_file , data_file2 , data_file3 , learn_options ) <EOL> elif learn_options [ '<STR_LIT>' ] == <NUM_LIT:5> : <EOL> learn_options [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> learn_options [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> learn_options [ '<STR_LIT>' ] = None <EOL> gene_position , target_genes , Xdf , Y = read_xu_et_al ( data_file3 ) <EOL> Xdf [ "<STR_LIT>" ] = Xdf [ "<STR_LIT>" ] . apply ( lambda x : x [ <NUM_LIT:0> : <NUM_LIT:30> ] ) <EOL> return Xdf , Y , gene_position , target_genes <EOL> def set_V2_target_names ( learn_options ) : <EOL> if '<STR_LIT>' not in learn_options . keys ( ) : <EOL> learn_options [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> if '<STR_LIT>' not in learn_options . keys ( ) : <EOL> learn_options [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> learn_options [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> return learn_options <EOL> def combine_organisms ( human_data , mouse_data ) : <EOL> cd13 = human_data . xs ( '<STR_LIT>' , level = '<STR_LIT>' , drop_level = False ) <EOL> X_CD13 , Y_CD13 = util . get_data ( cd13 , y_names = [ '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> cd33 = human_data . xs ( '<STR_LIT>' , level = '<STR_LIT>' , drop_level = False ) <EOL> X_CD33 , Y_CD33 = util . get_data ( cd33 , y_names = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> cd15 = human_data . xs ( '<STR_LIT>' , level = '<STR_LIT>' , drop_level = False ) <EOL> X_CD15 , Y_CD15 = util . get_data ( cd15 , y_names = [ '<STR_LIT>' ] ) <EOL> mouse_X = pandas . DataFrame ( ) <EOL> mouse_Y = pandas . DataFrame ( ) <EOL> for k in mouse_data . index . levels [ <NUM_LIT:1> ] : <EOL> X , Y = util . get_data ( mouse_data . xs ( k , level = '<STR_LIT>' , drop_level = False ) , [ "<STR_LIT>" ] , target_gene = k , organism = '<STR_LIT>' ) <EOL> mouse_X = pandas . concat ( [ mouse_X , X ] , axis = <NUM_LIT:0> ) <EOL> mouse_Y = pandas . concat ( [ mouse_Y , Y ] , axis = <NUM_LIT:0> ) <EOL> X = pandas . concat ( [ X_CD13 , X_CD15 , X_CD33 , mouse_X ] , axis = <NUM_LIT:0> ) <EOL> Y = pandas . concat ( [ Y_CD13 , Y_CD15 , Y_CD33 , mouse_Y ] , axis = <NUM_LIT:0> ) <EOL> return X , Y <EOL> def read_V1_data ( data_file , learn_options , AML_file = cur_dir + "<STR_LIT>" ) : <EOL> if data_file is None : <EOL> data_file = cur_dir + "<STR_LIT>" <EOL> human_data = pandas . read_excel ( data_file , sheetname = <NUM_LIT:0> , index_col = [ <NUM_LIT:0> , <NUM_LIT:1> ] ) <EOL> mouse_data = pandas . read_excel ( data_file , sheetname = <NUM_LIT:1> , index_col = [ <NUM_LIT:0> , <NUM_LIT:1> ] ) <EOL> Xdf , Y = combine_organisms ( human_data , mouse_data ) <EOL> annotations = pandas . read_csv ( AML_file , delimiter = '<STR_LIT:\t>' , index_col = [ <NUM_LIT:0> , <NUM_LIT:4> ] ) <EOL> annotations . index . names = Xdf . index . names <EOL> gene_position = pandas . merge ( Xdf , annotations , how = "<STR_LIT>" , left_index = True , right_index = True ) <EOL> gene_position = util . impute_gene_position ( gene_position ) <EOL> gene_position = gene_position [ [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ] <EOL> Y = Y . loc [ gene_position . index ] <EOL> Xdf = Xdf . loc [ gene_position . index ] <EOL> Y [ '<STR_LIT:test>' ] = <NUM_LIT:1> <EOL> target_genes = Y [ '<STR_LIT>' ] . unique ( ) <EOL> Y . index . names = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> assert Xdf . index . equals ( Y . index ) , "<STR_LIT>" <EOL> if learn_options is not None and learn_options [ "<STR_LIT>" ] : <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> Y [ '<STR_LIT>' ] = Y [ '<STR_LIT>' ] < <NUM_LIT> <EOL> print "<STR_LIT>" <EOL> import ipdb <EOL> ipdb . set_trace ( ) <EOL> return annotations , gene_position , target_genes , Xdf , Y <EOL> def rank_transform ( x ) : <EOL> return <NUM_LIT:1.0> - sp . stats . mstats . rankdata ( x ) / sp . stats . mstats . rankdata ( x ) . max ( ) <EOL> def read_xu_et_al ( data_file , learn_options = None , verbose = True , subsetting = '<STR_LIT>' ) : <EOL> if data_file is None : <EOL> data_file = '<STR_LIT>' <EOL> datasets = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> aggregated = None <EOL> for d in datasets : <EOL> data_efficient = pandas . read_excel ( data_file , sheetname = '<STR_LIT>' % d , skiprows = <NUM_LIT:2> ) <EOL> data_inefficient = pandas . read_excel ( data_file , sheetname = '<STR_LIT>' % d , skiprows = <NUM_LIT:2> ) <EOL> data_efficient [ '<STR_LIT>' ] = <NUM_LIT:1.> <EOL> data_inefficient [ '<STR_LIT>' ] = <NUM_LIT:0.> <EOL> exp_data = pandas . concat ( ( data_efficient , data_inefficient ) ) <EOL> exp_data [ '<STR_LIT>' ] = exp_data . groupby ( '<STR_LIT>' ) [ '<STR_LIT>' ] . transform ( rank_transform ) <EOL> exp_data [ '<STR_LIT>' ] = exp_data . groupby ( '<STR_LIT>' ) [ '<STR_LIT>' ] . transform ( rank_transform ) <EOL> if aggregated is None : <EOL> aggregated = exp_data <EOL> else : <EOL> aggregated = pandas . concat ( ( aggregated , exp_data ) ) <EOL> if subsetting == '<STR_LIT>' : <EOL> aggregated [ "<STR_LIT>" ] = aggregated [ "<STR_LIT>" ] . apply ( lambda x : x [ <NUM_LIT:6> : - <NUM_LIT:4> ] ) <EOL> else : <EOL> aggregated [ "<STR_LIT>" ] = aggregated [ "<STR_LIT>" ] . apply ( lambda x : x [ <NUM_LIT:10> : ] ) <EOL> aggregated [ "<STR_LIT>" ] = aggregated [ "<STR_LIT>" ] . apply ( lambda x : x . upper ( ) ) <EOL> aggregated . rename ( columns = { "<STR_LIT>" : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , inplace = True ) <EOL> aggregated [ '<STR_LIT>' ] . loc [ aggregated [ '<STR_LIT>' ] == '<STR_LIT:+>' ] = '<STR_LIT>' <EOL> aggregated [ '<STR_LIT>' ] . loc [ aggregated [ '<STR_LIT>' ] == '<STR_LIT:->' ] = '<STR_LIT>' <EOL> aggregated [ '<STR_LIT>' ] = aggregated [ [ '<STR_LIT>' , '<STR_LIT>' ] ] . mean ( axis = <NUM_LIT:1> ) <EOL> df = aggregated <EOL> df = df . rename ( columns = { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ) <EOL> df [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> df [ '<STR_LIT:test>' ] = <NUM_LIT:1> <EOL> df = df . set_index ( [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> df [ '<STR_LIT>' ] = df . index . get_level_values ( <NUM_LIT:0> ) <EOL> df [ '<STR_LIT>' ] = df . index . get_level_values ( <NUM_LIT:1> ) <EOL> df [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> df [ '<STR_LIT>' ] = df [ '<STR_LIT>' ] <EOL> df [ '<STR_LIT>' ] = df [ '<STR_LIT>' ] <EOL> df [ '<STR_LIT>' ] = df [ '<STR_LIT>' ] <EOL> df [ '<STR_LIT>' ] = <NUM_LIT:0> <EOL> df [ '<STR_LIT>' ] = <NUM_LIT:0> <EOL> target_genes = np . unique ( df [ '<STR_LIT>' ] . values ) <EOL> return df [ [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ] , target_genes , df [ [ '<STR_LIT>' , '<STR_LIT>' ] ] , df [ [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT:test>' , '<STR_LIT>' ] ] <EOL> def read_V2_data ( data_file , learn_options = None , verbose = True ) : <EOL> if data_file is None : <EOL> data_file = cur_dir + "<STR_LIT>" <EOL> data = pandas . read_excel ( data_file , sheetname = "<STR_LIT>" , skiprows = range ( <NUM_LIT:0> , <NUM_LIT:6> + <NUM_LIT:1> ) , index_col = [ <NUM_LIT:0> , <NUM_LIT:4> ] ) <EOL> Xdf = pandas . DataFrame ( ) <EOL> known_pairs = { '<STR_LIT>' : [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] , <EOL> '<STR_LIT>' : [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] } <EOL> drugs_to_genes = { '<STR_LIT>' : [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] , <EOL> '<STR_LIT>' : [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] } <EOL> if learn_options is not None : <EOL> assert not ( learn_options [ '<STR_LIT>' ] and learn_options [ '<STR_LIT>' ] ) , "<STR_LIT>" <EOL> if learn_options [ '<STR_LIT>' ] : <EOL> drugs_to_genes [ '<STR_LIT>' ] . extend ( [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> elif learn_options [ '<STR_LIT>' ] : <EOL> drugs_to_genes [ '<STR_LIT>' ] . extend ( [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> drugs_to_genes [ '<STR_LIT>' ] . extend ( [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> drugs_to_genes [ '<STR_LIT>' ] . extend ( [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> count = <NUM_LIT:0> <EOL> for drug in drugs_to_genes . keys ( ) : <EOL> genes = drugs_to_genes [ drug ] <EOL> for g in genes : <EOL> Xtmp = data . copy ( ) . xs ( g , level = '<STR_LIT>' , drop_level = False ) <EOL> Xtmp [ '<STR_LIT>' ] = drug <EOL> Xtmp [ '<STR_LIT>' ] = Xtmp [ drug ] . copy ( ) <EOL> if g in known_pairs [ drug ] : <EOL> Xtmp [ '<STR_LIT:test>' ] = <NUM_LIT:1.> <EOL> else : <EOL> Xtmp [ '<STR_LIT:test>' ] = <NUM_LIT:0.> <EOL> count = count + Xtmp . shape [ <NUM_LIT:0> ] <EOL> Xdf = pandas . concat ( [ Xdf , Xtmp ] , axis = <NUM_LIT:0> ) <EOL> if verbose : <EOL> print "<STR_LIT>" % ( Xtmp . shape [ <NUM_LIT:0> ] , g , count ) <EOL> Xdf = Xdf . set_index ( '<STR_LIT>' , append = True ) <EOL> Y = pandas . DataFrame ( Xdf . pop ( "<STR_LIT>" ) ) <EOL> Y . columns . names = [ "<STR_LIT>" ] <EOL> test_gene = pandas . DataFrame ( Xdf . pop ( '<STR_LIT:test>' ) ) <EOL> target = pandas . DataFrame ( Xdf . index . get_level_values ( '<STR_LIT>' ) . values , index = Y . index , columns = [ "<STR_LIT>" ] ) <EOL> Y = pandas . concat ( ( Y , target , test_gene ) , axis = <NUM_LIT:1> ) <EOL> target_genes = Y [ '<STR_LIT>' ] . unique ( ) <EOL> gene_position = Xdf [ [ "<STR_LIT>" , "<STR_LIT>" ] ] . copy ( ) <EOL> y_rank = pandas . DataFrame ( ) <EOL> y_threshold = pandas . DataFrame ( ) <EOL> y_quant = pandas . DataFrame ( ) <EOL> for drug in drugs_to_genes . keys ( ) : <EOL> gene_list = drugs_to_genes [ drug ] <EOL> for gene in gene_list : <EOL> ytmp = pandas . DataFrame ( Y . xs ( ( gene , drug ) , level = [ "<STR_LIT>" , "<STR_LIT>" ] , drop_level = False ) [ '<STR_LIT>' ] ) <EOL> y_ranktmp , y_rank_raw , y_thresholdtmp , y_quanttmp = util . get_ranks ( ytmp , thresh = <NUM_LIT> , prefix = "<STR_LIT>" , flip = False ) <EOL> y_rank = pandas . concat ( ( y_rank , y_ranktmp ) , axis = <NUM_LIT:0> ) <EOL> y_threshold = pandas . concat ( ( y_threshold , y_thresholdtmp ) , axis = <NUM_LIT:0> ) <EOL> y_quant = pandas . concat ( ( y_quant , y_quanttmp ) , axis = <NUM_LIT:0> ) <EOL> yall = pandas . concat ( ( y_rank , y_threshold , y_quant ) , axis = <NUM_LIT:1> ) <EOL> Y = pandas . merge ( Y , yall , how = '<STR_LIT>' , left_index = True , right_index = True ) <EOL> y_rank = pandas . DataFrame ( ) <EOL> y_threshold = pandas . DataFrame ( ) <EOL> y_quant = pandas . DataFrame ( ) <EOL> for drug in drugs_to_genes . keys ( ) : <EOL> ytmp = pandas . DataFrame ( Y . xs ( drug , level = "<STR_LIT>" , drop_level = False ) [ '<STR_LIT>' ] ) <EOL> y_ranktmp , y_rank_raw , y_thresholdtmp , y_quanttmp = util . get_ranks ( ytmp , thresh = <NUM_LIT> , prefix = "<STR_LIT>" , flip = False ) <EOL> y_rank = pandas . concat ( ( y_rank , y_ranktmp ) , axis = <NUM_LIT:0> ) <EOL> y_threshold = pandas . concat ( ( y_threshold , y_thresholdtmp ) , axis = <NUM_LIT:0> ) <EOL> y_quant = pandas . concat ( ( y_quant , y_quanttmp ) , axis = <NUM_LIT:0> ) <EOL> yall = pandas . concat ( ( y_rank , y_threshold , y_quant ) , axis = <NUM_LIT:1> ) <EOL> Y = pandas . merge ( Y , yall , how = '<STR_LIT>' , left_index = True , right_index = True ) <EOL> PLOT = False <EOL> if PLOT : <EOL> labels = [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] <EOL> for label in labels : <EOL> plt . figure ( ) <EOL> plt . plot ( Xdf [ '<STR_LIT>' ] . values , Y [ label ] . values , '<STR_LIT:.>' ) <EOL> r , pearp = sp . stats . pearsonr ( Xdf [ '<STR_LIT>' ] . values . flatten ( ) , Y [ label ] . values . flatten ( ) ) <EOL> plt . title ( label + '<STR_LIT>' % ( r , pearp ) ) <EOL> plt . xlabel ( "<STR_LIT>" ) <EOL> plt . ylabel ( label ) <EOL> gene_position = util . impute_gene_position ( gene_position ) <EOL> if learn_options is not None and learn_options [ "<STR_LIT>" ] == "<STR_LIT>" : <EOL> print "<STR_LIT>" <EOL> data = pandas . read_excel ( data_file , sheetname = "<STR_LIT>" , skiprows = range ( <NUM_LIT:0> , <NUM_LIT:6> + <NUM_LIT:1> ) , index_col = [ <NUM_LIT:0> , <NUM_LIT:4> ] ) <EOL> data . index . names = [ "<STR_LIT>" , "<STR_LIT>" ] <EOL> experiments = { } <EOL> experiments [ '<STR_LIT>' ] = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> experiments [ '<STR_LIT>' ] = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> experiments [ '<STR_LIT>' ] = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> variance = None <EOL> for drug in drugs_to_genes . keys ( ) : <EOL> data_tmp = data . iloc [ data . index . get_level_values ( '<STR_LIT>' ) . isin ( drugs_to_genes [ drug ] ) ] [ experiments [ drug ] ] <EOL> data_tmp [ "<STR_LIT>" ] = drug <EOL> data_tmp = data_tmp . set_index ( '<STR_LIT>' , append = True ) <EOL> data_tmp [ "<STR_LIT>" ] = np . var ( data_tmp . values , axis = <NUM_LIT:1> ) <EOL> if variance is None : <EOL> variance = data_tmp [ "<STR_LIT>" ] . copy ( ) <EOL> else : <EOL> variance = pandas . concat ( ( variance , data_tmp [ "<STR_LIT>" ] ) , axis = <NUM_LIT:0> ) <EOL> orig_index = Y . index . copy ( ) <EOL> Y = pandas . merge ( Y , pandas . DataFrame ( variance ) , how = "<STR_LIT>" , left_index = True , right_index = True ) <EOL> Y = Y . ix [ orig_index ] <EOL> print "<STR_LIT>" <EOL> assert Xdf . index . equals ( Y . index ) , "<STR_LIT>" <EOL> return Xdf , drugs_to_genes , target_genes , Y , gene_position <EOL> def merge_all ( data_file = None , data_file2 = None , data_file3 = None , learn_options = None ) : <EOL> Xdf , Y , gene_position , target_genes = mergeV1_V2 ( data_file , data_file2 , learn_options ) <EOL> gene_position_xu , target_genes_xu , Xdf_xu , Y_xu = read_xu_et_al ( data_file3 , learn_options ) <EOL> Xdf = pandas . concat ( ( Xdf , Xdf_xu ) ) <EOL> Y = pandas . concat ( ( Y , Y_xu ) ) <EOL> gene_position = pandas . concat ( ( gene_position , gene_position_xu ) ) <EOL> target_genes = np . concatenate ( ( target_genes , target_genes_xu ) ) <EOL> return Xdf , Y , gene_position , target_genes <EOL> def mergeV1_V2 ( data_file , data_file2 , learn_options ) : <EOL> '''<STR_LIT>''' <EOL> assert not learn_options [ '<STR_LIT>' ] , "<STR_LIT>" <EOL> annotations , gene_position1 , target_genes1 , Xdf1 , Y1 = read_V1_data ( data_file , learn_options ) <EOL> Xdf2 , drugs_to_genes , target_genes2 , Y2 , gene_position2 = read_V2_data ( data_file2 ) <EOL> Y1 . rename ( columns = { '<STR_LIT>' : learn_options [ "<STR_LIT>" ] } , inplace = True ) <EOL> Y1 . rename ( columns = { '<STR_LIT>' : learn_options [ "<STR_LIT>" ] } , inplace = True ) <EOL> Y1 [ "<STR_LIT>" ] = [ "<STR_LIT>" for x in range ( Y1 . shape [ <NUM_LIT:0> ] ) ] <EOL> Y1 = Y1 . set_index ( '<STR_LIT>' , append = True ) <EOL> Y1 . index . names = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> Y_cols_to_keep = np . unique ( [ '<STR_LIT>' , '<STR_LIT:test>' , '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> Y1 = Y1 [ Y_cols_to_keep ] <EOL> Y2 = Y2 [ Y_cols_to_keep ] <EOL> Xdf1 [ "<STR_LIT>" ] = [ "<STR_LIT>" for x in range ( Xdf1 . shape [ <NUM_LIT:0> ] ) ] <EOL> Xdf1 = Xdf1 . set_index ( '<STR_LIT>' , append = True ) <EOL> X_cols_to_keep = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> Xdf1 = Xdf1 [ X_cols_to_keep ] <EOL> Xdf2 = Xdf2 [ X_cols_to_keep ] <EOL> gene_position1 [ "<STR_LIT>" ] = [ "<STR_LIT>" for x in range ( gene_position1 . shape [ <NUM_LIT:0> ] ) ] <EOL> gene_position1 = gene_position1 . set_index ( '<STR_LIT>' , append = True ) <EOL> gene_position1 . index . names = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> cols_to_keep = [ u'<STR_LIT>' , u'<STR_LIT>' ] <EOL> gene_position1 = gene_position1 [ cols_to_keep ] <EOL> gene_position2 = gene_position2 [ cols_to_keep ] <EOL> Y = pandas . concat ( ( Y1 , Y2 ) , axis = <NUM_LIT:0> ) <EOL> Xdf = pandas . concat ( ( Xdf1 , Xdf2 ) , axis = <NUM_LIT:0> ) <EOL> gene_position = pandas . concat ( ( gene_position1 , gene_position2 ) ) <EOL> target_genes = np . concatenate ( ( target_genes1 , target_genes2 ) ) <EOL> save_to_file = False <EOL> if save_to_file : <EOL> Y . index . names = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> assert np . all ( Xdf . index . values == Y . index . values ) , "<STR_LIT>" <EOL> onedupind = np . where ( Y . index . duplicated ( ) ) [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] <EOL> alldupind = np . where ( Y . index . get_level_values ( <NUM_LIT:0> ) . values == Y . index [ onedupind ] [ <NUM_LIT:0> ] ) [ <NUM_LIT:0> ] <EOL> assert len ( alldupind ) == <NUM_LIT:2> , "<STR_LIT>" <EOL> newindex = Y . index . tolist ( ) <EOL> newindex [ onedupind ] = ( newindex [ onedupind ] [ <NUM_LIT:0> ] , newindex [ onedupind ] [ <NUM_LIT:1> ] , "<STR_LIT>" ) <EOL> Y . index = pandas . MultiIndex . from_tuples ( newindex , names = Y . index . names ) <EOL> Xdf . index = pandas . MultiIndex . from_tuples ( newindex , names = Y . index . names ) <EOL> XandY = pandas . merge ( Xdf , Y , how = "<STR_LIT>" , left_index = True , right_index = True ) <EOL> gene_position_tmp = gene_position . copy ( ) <EOL> gene_position_tmp . index . names = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> gene_position_tmp . index = pandas . MultiIndex . from_tuples ( newindex , names = Y . index . names ) <EOL> XandY = pandas . merge ( XandY , gene_position_tmp , how = "<STR_LIT>" , left_index = True , right_index = True ) <EOL> XandY [ "<STR_LIT>" ] = XandY [ "<STR_LIT>" ] . apply ( lambda x : x [ <NUM_LIT:0> : <NUM_LIT:30> ] ) <EOL> XandY . to_csv ( r'<STR_LIT>' ) <EOL> return Xdf , Y , gene_position , target_genes <EOL> def get_V1_genes ( data_file = None ) : <EOL> annotations , gene_position , target_genes , Xdf , Y = read_V1_data ( data_file , learn_options = None ) <EOL> return target_genes <EOL> def get_V2_genes ( data_file = None ) : <EOL> Xdf , drugs_to_genes , target_genes , Y , gene_position = read_V2_data ( data_file , verbose = False ) <EOL> return target_genes <EOL> def get_V3_genes ( data_fileV1 = None , data_fileV2 = None ) : <EOL> target_genes = np . concatenate ( ( get_V1_genes ( data_fileV1 ) , get_V2_genes ( data_fileV2 ) ) ) <EOL> return target_genes <EOL> def get_xu_genes ( data_file = None ) : <EOL> return read_xu_et_al ( data_file ) [ <NUM_LIT:1> ] <EOL> def get_mouse_genes ( data_file = None ) : <EOL> annotations , gene_position , target_genes , Xdf , Y = read_V1_data ( data_file , learn_options = None ) <EOL> return Xdf [ Xdf [ '<STR_LIT>' ] == '<STR_LIT>' ] [ '<STR_LIT>' ] . unique ( ) <EOL> def get_human_genes ( data_file = None ) : <EOL> annotations , gene_position , target_genes , Xdf , Y = read_V1_data ( data_file , learn_options = None ) <EOL> mouse_genes = Xdf [ Xdf [ '<STR_LIT>' ] == '<STR_LIT>' ] [ '<STR_LIT>' ] . unique ( ) <EOL> all_genes = get_V3_genes ( None , None ) <EOL> return np . setdiff1d ( all_genes , mouse_genes ) </s>
<s> import os <EOL> from os import path <EOL> import sys <EOL> try : <EOL> import simplejson as json <EOL> except ImportError : <EOL> import json <EOL> from . detector import Detector <EOL> from . lang_detect_exception import ErrorCode , LangDetectException <EOL> from . utils . lang_profile import LangProfile <EOL> class DetectorFactory ( object ) : <EOL> '''<STR_LIT>''' <EOL> seed = None <EOL> def __init__ ( self ) : <EOL> self . word_lang_prob_map = { } <EOL> self . langlist = [ ] <EOL> def load_profile ( self , profile_directory ) : <EOL> list_files = os . listdir ( profile_directory ) <EOL> if not list_files : <EOL> raise LangDetectException ( ErrorCode . NeedLoadProfileError , '<STR_LIT>' + profile_directory ) <EOL> langsize , index = len ( list_files ) , <NUM_LIT:0> <EOL> for filename in list_files : <EOL> if filename . startswith ( '<STR_LIT:.>' ) : <EOL> continue <EOL> filename = path . join ( profile_directory , filename ) <EOL> if not path . isfile ( filename ) : <EOL> continue <EOL> f = None <EOL> try : <EOL> if sys . version_info [ <NUM_LIT:0> ] < <NUM_LIT:3> : <EOL> f = open ( filename , '<STR_LIT:r>' ) <EOL> else : <EOL> f = open ( filename , '<STR_LIT:r>' , encoding = '<STR_LIT:utf-8>' ) <EOL> json_data = json . load ( f ) <EOL> profile = LangProfile ( ** json_data ) <EOL> self . add_profile ( profile , index , langsize ) <EOL> index += <NUM_LIT:1> <EOL> except IOError : <EOL> raise LangDetectException ( ErrorCode . FileLoadError , '<STR_LIT>' % filename ) <EOL> except : <EOL> raise LangDetectException ( ErrorCode . FormatError , '<STR_LIT>' % filename ) <EOL> finally : <EOL> if f : <EOL> f . close ( ) <EOL> def load_json_profile ( self , json_profiles ) : <EOL> langsize , index = len ( json_profiles ) , <NUM_LIT:0> <EOL> if langsize < <NUM_LIT:2> : <EOL> raise LangDetectException ( ErrorCode . NeedLoadProfileError , '<STR_LIT>' ) <EOL> for json_profile in json_profiles : <EOL> try : <EOL> json_data = json . loads ( json_profile ) <EOL> profile = LangProfile ( ** json_data ) <EOL> self . add_profile ( profile , index , langsize ) <EOL> index += <NUM_LIT:1> <EOL> except : <EOL> raise LangDetectException ( ErrorCode . FormatError , '<STR_LIT>' ) <EOL> def add_profile ( self , profile , index , langsize ) : <EOL> lang = profile . name <EOL> if lang in self . langlist : <EOL> raise LangDetectException ( ErrorCode . DuplicateLangError , '<STR_LIT>' ) <EOL> self . langlist . append ( lang ) <EOL> for word in profile . freq : <EOL> if word not in self . word_lang_prob_map : <EOL> self . word_lang_prob_map [ word ] = [ <NUM_LIT:0.0> ] * langsize <EOL> length = len ( word ) <EOL> if <NUM_LIT:1> <= length <= <NUM_LIT:3> : <EOL> prob = <NUM_LIT:1.0> * profile . freq . get ( word ) / profile . n_words [ length - <NUM_LIT:1> ] <EOL> self . word_lang_prob_map [ word ] [ index ] = prob <EOL> def clear ( self ) : <EOL> self . langlist = [ ] <EOL> self . word_lang_prob_map = { } <EOL> def create ( self , alpha = None ) : <EOL> '''<STR_LIT>''' <EOL> detector = self . _create_detector ( ) <EOL> if alpha is not None : <EOL> detector . set_alpha ( alpha ) <EOL> return detector <EOL> def _create_detector ( self ) : <EOL> if not self . langlist : <EOL> raise LangDetectException ( ErrorCode . NeedLoadProfileError , '<STR_LIT>' ) <EOL> return Detector ( self ) <EOL> def set_seed ( self , seed ) : <EOL> self . seed = seed <EOL> def get_lang_list ( self ) : <EOL> return list ( self . langlist ) <EOL> PROFILES_DIRECTORY = path . join ( path . dirname ( __file__ ) , '<STR_LIT>' ) <EOL> _factory = None <EOL> def init_factory ( ) : <EOL> global _factory <EOL> if _factory is None : <EOL> _factory = DetectorFactory ( ) <EOL> _factory . load_profile ( PROFILES_DIRECTORY ) <EOL> def detect ( text ) : <EOL> init_factory ( ) <EOL> detector = _factory . create ( ) <EOL> detector . append ( text ) <EOL> return detector . detect ( ) <EOL> def detect_langs ( text ) : <EOL> init_factory ( ) <EOL> detector = _factory . create ( ) <EOL> detector . append ( text ) <EOL> return detector . get_probabilities ( ) </s>
<s> import math <EOL> def distance ( pa , pb ) : <EOL> ax , ay = pa <EOL> bx , by = pb <EOL> return math . sqrt ( ( ax - bx ) ** <NUM_LIT:2> + ( ay - by ) ** <NUM_LIT:2> ) <EOL> def index_of_nearest ( p , hot_points , distance_f = distance ) : <EOL> """<STR_LIT>""" <EOL> min_dist = None <EOL> nearest_hp_i = None <EOL> for i , hp in enumerate ( hot_points ) : <EOL> dist = distance_f ( p , hp ) <EOL> if min_dist is None or dist < min_dist : <EOL> min_dist = dist <EOL> nearest_hp_i = i <EOL> return nearest_hp_i </s>
<s> from pig_util import outputSchema <EOL> @ outputSchema ( '<STR_LIT>' ) <EOL> def reverse ( word ) : <EOL> """<STR_LIT>""" <EOL> return word [ : : - <NUM_LIT:1> ] <EOL> @ outputSchema ( '<STR_LIT>' ) <EOL> def num_chars ( word ) : <EOL> """<STR_LIT>""" <EOL> return len ( word ) </s>
<s> from fabric import main as fab_main <EOL> from cloudferry import fabfile <EOL> def main ( ) : <EOL> fab = fabfile . __file__ <EOL> if fab . endswith ( '<STR_LIT>' ) : <EOL> fab = fab [ : - <NUM_LIT:1> ] <EOL> fab_main . main ( [ fab ] ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> main ( ) </s>
<s> from cloudferry . lib . base . action import action <EOL> DEFAULT = <NUM_LIT:0> <EOL> PATH_ONE = <NUM_LIT:1> <EOL> PATH_TWO = <NUM_LIT:2> <EOL> class IsOption ( action . Action ) : <EOL> def __init__ ( self , init , option_name ) : <EOL> self . option_name = option_name <EOL> super ( IsOption , self ) . __init__ ( init ) <EOL> def run ( self , ** kwargs ) : <EOL> self . set_next_path ( DEFAULT ) <EOL> option_value = self . cfg . migrate [ self . option_name ] <EOL> if option_value : <EOL> self . set_next_path ( PATH_ONE ) <EOL> else : <EOL> self . set_next_path ( PATH_TWO ) <EOL> return { } </s>
<s> from cloudferry . lib . base . action import action <EOL> from cloudferry . lib . utils import log <EOL> from cloudferry . lib . utils import utils as utl <EOL> LOG = log . getLogger ( __name__ ) <EOL> class CheckConfigQuotaNeutron ( action . Action ) : <EOL> """<STR_LIT>""" <EOL> def run ( self , ** kwargs ) : <EOL> src_cloud = self . src_cloud <EOL> dst_cloud = self . dst_cloud <EOL> network_src = src_cloud . resources [ utl . NETWORK_RESOURCE ] <EOL> identity_dst = dst_cloud . resources [ utl . IDENTITY_RESOURCE ] <EOL> network_dst = dst_cloud . resources [ utl . NETWORK_RESOURCE ] <EOL> search_opts_tenant = kwargs . get ( '<STR_LIT>' , { } ) <EOL> tenants_src = self . get_src_tenants ( search_opts_tenant ) <EOL> list_quotas = network_src . list_quotas ( ) <EOL> tenants_without_quotas = self . get_tenants_without_quotas ( tenants_src , <EOL> list_quotas ) <EOL> if not tenants_without_quotas : <EOL> LOG . info ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> LOG . info ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> LOG . info ( "<STR_LIT>" ) <EOL> return <EOL> LOG . info ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> quot = network_src . show_quota ( tenants_without_quotas [ <NUM_LIT:0> ] ) <EOL> dst_temp_tenant = identity_dst . create_tenant ( "<STR_LIT>" ) <EOL> quot_default_dst = network_dst . show_quota ( dst_temp_tenant . id ) <EOL> is_configs_different = False <EOL> identity_dst . delete_tenant ( dst_temp_tenant ) <EOL> for item_quot , val_quot in quot . iteritems ( ) : <EOL> if val_quot != quot_default_dst [ item_quot ] : <EOL> is_configs_different = True <EOL> LOG . info ( "<STR_LIT>" <EOL> "<STR_LIT>" , item_quot , val_quot , <EOL> quot_default_dst [ item_quot ] ) <EOL> if not is_configs_different : <EOL> LOG . info ( "<STR_LIT>" ) <EOL> @ staticmethod <EOL> def get_tenants_without_quotas ( tenants_src , list_quotas ) : <EOL> tenants_ids = tenants_src . keys ( ) <EOL> quotas_ids_tenants = [ quota [ "<STR_LIT>" ] for quota in list_quotas ] <EOL> return list ( set ( tenants_ids ) - set ( quotas_ids_tenants ) ) <EOL> def get_src_tenants ( self , search_opts ) : <EOL> identity_src = self . src_cloud . resources [ utl . IDENTITY_RESOURCE ] <EOL> if search_opts . get ( '<STR_LIT>' ) : <EOL> filter_tenants_ids_list = search_opts [ '<STR_LIT>' ] <EOL> tenants = [ identity_src . keystone_client . tenants . find ( id = tnt_id ) for <EOL> tnt_id in filter_tenants_ids_list ] <EOL> else : <EOL> tenants = identity_src . get_tenants_list ( ) <EOL> tenants_dict = { tenant . id : tenant . name for tenant in tenants } <EOL> return tenants_dict </s>
<s> import copy <EOL> import logging <EOL> from oslo_config import cfg <EOL> from cloudferry . lib . base . action import action <EOL> from cloudferry . lib . utils import utils <EOL> CONF = cfg . CONF <EOL> LOG = logging . getLogger ( __name__ ) <EOL> class DetachVolumesCompute ( action . Action ) : <EOL> def run ( self , info , ** kwargs ) : <EOL> info = copy . deepcopy ( info ) <EOL> compute_resource = self . cloud . resources [ utils . COMPUTE_RESOURCE ] <EOL> storage_resource = self . cloud . resources [ utils . STORAGE_RESOURCE ] <EOL> for instance in info [ utils . INSTANCES_TYPE ] . itervalues ( ) : <EOL> LOG . info ( "<STR_LIT>" , <EOL> instance [ '<STR_LIT>' ] [ '<STR_LIT:name>' ] , instance [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] ) <EOL> if not instance [ '<STR_LIT>' ] [ utils . VOLUMES_TYPE ] : <EOL> continue <EOL> for vol in instance [ '<STR_LIT>' ] [ utils . VOLUMES_TYPE ] : <EOL> volume_status = storage_resource . get_status ( vol [ '<STR_LIT:id>' ] ) <EOL> LOG . debug ( "<STR_LIT>" , <EOL> vol [ '<STR_LIT:id>' ] , volume_status ) <EOL> if volume_status == '<STR_LIT>' : <EOL> compute_resource . detach_volume ( instance [ '<STR_LIT>' ] [ '<STR_LIT:id>' ] , <EOL> vol [ '<STR_LIT:id>' ] ) <EOL> LOG . debug ( "<STR_LIT>" , vol [ '<STR_LIT:id>' ] ) <EOL> timeout = CONF . migrate . storage_backend_timeout <EOL> storage_resource . wait_for_status ( <EOL> vol [ '<STR_LIT:id>' ] , storage_resource . get_status , '<STR_LIT>' , <EOL> timeout = timeout ) <EOL> return { } </s>
<s> from cloudferry . lib . base . action import action <EOL> from cloudferry . lib . utils . ssh_util import SshUtil <EOL> class RemoteExecution ( action . Action ) : <EOL> def __init__ ( self , cloud , host = None , int_host = None , config_migrate = None ) : <EOL> self . cloud = cloud <EOL> self . host = host <EOL> self . int_host = int_host <EOL> self . config_migrate = config_migrate <EOL> self . remote_exec_obj = SshUtil ( self . cloud , <EOL> self . config_migrate , <EOL> self . host ) <EOL> super ( RemoteExecution , self ) . __init__ ( { } ) <EOL> def run ( self , command , ** kwargs ) : <EOL> self . remote_exec_obj . execute ( command , self . int_host ) <EOL> return { } </s>
<s> import json <EOL> import os <EOL> from xml . etree import ElementTree <EOL> from cloudferry . lib . utils import log <EOL> LOG = log . getLogger ( __name__ ) <EOL> nova_instances_path = "<STR_LIT>" <EOL> def instance_path ( instance_id ) : <EOL> return os . path . join ( nova_instances_path , instance_id ) <EOL> def instance_image_path ( instance_id ) : <EOL> return os . path . join ( instance_path ( instance_id ) , "<STR_LIT>" ) <EOL> def _qemu_img_rebase ( src , dst ) : <EOL> return "<STR_LIT>" . format ( src = src , dst = dst ) <EOL> class QemuBackingFileMover ( object ) : <EOL> def __init__ ( self , runner , src , instance_id ) : <EOL> self . runner = runner <EOL> self . src = src <EOL> self . dst = instance_image_path ( instance_id ) <EOL> def __enter__ ( self ) : <EOL> cmd = _qemu_img_rebase ( self . src , self . dst ) <EOL> self . runner . run ( cmd ) <EOL> return self <EOL> def __exit__ ( self , exc_type , exc_val , exc_tb ) : <EOL> cmd = _qemu_img_rebase ( self . dst , self . src ) <EOL> self . runner . run_ignoring_errors ( cmd ) <EOL> return self <EOL> class DestNovaInstanceDestroyer ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , dest_libvirt , dest_nova , libvirt_name , nova_vm_id ) : <EOL> self . dest_libvirt = dest_libvirt <EOL> self . dest_nova = dest_nova <EOL> self . libvirt_name = libvirt_name <EOL> self . nova_vm_id = nova_vm_id <EOL> def __enter__ ( self ) : <EOL> self . do ( ) <EOL> def __exit__ ( self , exc_type , exc_val , exc_tb ) : <EOL> self . undo ( ) <EOL> def do ( self ) : <EOL> self . dest_libvirt . destroy_vm ( self . libvirt_name ) <EOL> def undo ( self ) : <EOL> try : <EOL> LOG . debug ( "<STR_LIT>" , self . nova_vm_id ) <EOL> self . dest_nova . reset_state ( self . nova_vm_id ) <EOL> self . dest_nova . delete_vm_by_id ( self . nova_vm_id ) <EOL> except RuntimeError : <EOL> pass <EOL> class Libvirt ( object ) : <EOL> def __init__ ( self , remote_runner ) : <EOL> """<STR_LIT>""" <EOL> self . runner = remote_runner <EOL> def get_backing_file ( self , instance_id ) : <EOL> cmd = ( "<STR_LIT>" . format ( <EOL> image_path = instance_image_path ( instance_id ) ) ) <EOL> try : <EOL> image_info = json . loads ( self . runner . run ( cmd ) ) <EOL> return image_info [ '<STR_LIT>' ] <EOL> except ( ValueError , TypeError ) as e : <EOL> LOG . error ( "<STR_LIT>" , e ) <EOL> except KeyError : <EOL> LOG . warning ( "<STR_LIT>" , <EOL> instance_id ) <EOL> def get_xml ( self , libvirt_instance_name ) : <EOL> cmd = ( "<STR_LIT>" . format ( <EOL> inst_name = libvirt_instance_name ) ) <EOL> return LibvirtXml ( self . runner . run ( cmd ) ) <EOL> def destroy_vm ( self , libvirt_instance_name ) : <EOL> cmds = [ <EOL> "<STR_LIT>" . format ( instance = libvirt_instance_name ) , <EOL> "<STR_LIT>" . format ( instance = libvirt_instance_name ) <EOL> ] <EOL> for cmd in cmds : <EOL> self . runner . run ( cmd ) <EOL> def move_backing_file ( self , source_file , instance_id ) : <EOL> cmd = _qemu_img_rebase ( src = source_file , <EOL> dst = instance_image_path ( instance_id ) ) <EOL> self . runner . run ( cmd ) <EOL> def live_migrate ( self , libvirt_instance_name , dest_host , migration_xml ) : <EOL> cmd = ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" . format ( instance = libvirt_instance_name , <EOL> dst_host = dest_host , <EOL> migration_xml = migration_xml ) ) <EOL> self . runner . run ( cmd ) <EOL> class LibvirtDeviceInterfaceHwAddress ( object ) : <EOL> def __init__ ( self , element ) : <EOL> self . type = element . get ( '<STR_LIT:type>' ) <EOL> self . domain = element . get ( '<STR_LIT>' ) <EOL> self . bus = element . get ( '<STR_LIT>' ) <EOL> self . slot = element . get ( '<STR_LIT>' ) <EOL> self . function = element . get ( '<STR_LIT>' ) <EOL> def __repr__ ( self ) : <EOL> return "<STR_LIT>" % ( self . type , self . bus , self . slot ) <EOL> def __eq__ ( self , other ) : <EOL> return ( isinstance ( other , self . __class__ ) and <EOL> self . type == other . type and <EOL> self . domain == other . domain and <EOL> self . bus == other . bus and <EOL> self . slot == other . slot and <EOL> self . function == other . function ) <EOL> class LibvirtDeviceInterface ( object ) : <EOL> def __init__ ( self , interface ) : <EOL> """<STR_LIT>""" <EOL> self . _xml_element = interface <EOL> self . mac = interface . find ( '<STR_LIT>' ) . get ( '<STR_LIT:address>' ) <EOL> self . source_iface = interface . find ( '<STR_LIT:source>' ) . get ( '<STR_LIT>' ) <EOL> self . target_iface = interface . find ( '<STR_LIT:target>' ) . get ( '<STR_LIT>' ) <EOL> self . hw_address = LibvirtDeviceInterfaceHwAddress ( <EOL> interface . find ( '<STR_LIT:address>' ) ) <EOL> def __eq__ ( self , other ) : <EOL> return ( isinstance ( other , self . __class__ ) and <EOL> self . source_iface == other . source_iface and <EOL> self . target_iface == other . target_iface and <EOL> self . hw_address == other . hw_address ) <EOL> def __repr__ ( self ) : <EOL> return "<STR_LIT>" . format ( <EOL> mac = self . mac , src = self . source_iface , dst = self . target_iface ) <EOL> @ classmethod <EOL> def _replace_attr ( cls , element , attr , value ) : <EOL> if element . get ( attr ) != value : <EOL> element . clear ( ) <EOL> element . attrib = { attr : value } <EOL> def element ( self ) : <EOL> source = self . _xml_element . find ( '<STR_LIT:source>' ) <EOL> target = self . _xml_element . find ( '<STR_LIT:target>' ) <EOL> self . _replace_attr ( source , '<STR_LIT>' , self . source_iface ) <EOL> self . _replace_attr ( target , '<STR_LIT>' , self . target_iface ) <EOL> return self . _xml_element <EOL> class LibvirtXml ( object ) : <EOL> def __init__ ( self , contents ) : <EOL> """<STR_LIT>""" <EOL> self . _xml = ElementTree . fromstring ( contents ) <EOL> self . _interfaces = [ LibvirtDeviceInterface ( i ) <EOL> for i in self . _xml . findall ( '<STR_LIT>' ) ] <EOL> self . disk_file = self . _get ( '<STR_LIT>' , '<STR_LIT:file>' ) <EOL> self . serial_file = self . _get ( '<STR_LIT>' , '<STR_LIT:path>' ) <EOL> self . console_file = self . _get ( '<STR_LIT>' , '<STR_LIT:path>' ) <EOL> def _get ( self , element , attribute ) : <EOL> el = self . _xml . find ( element ) <EOL> if el is not None : <EOL> return el . get ( attribute ) <EOL> def _set ( self , element , attribute , value ) : <EOL> el = self . _xml . find ( element ) <EOL> if el is not None : <EOL> el . set ( attribute , value ) <EOL> @ property <EOL> def interfaces ( self ) : <EOL> return self . _interfaces <EOL> @ interfaces . setter <EOL> def interfaces ( self , other ) : <EOL> """<STR_LIT>""" <EOL> if len ( self . interfaces ) != len ( other ) : <EOL> raise RuntimeError ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> for other_iface in other : <EOL> for this_iface in self . interfaces : <EOL> identical = ( this_iface . mac == other_iface . mac ) <EOL> if identical : <EOL> this_iface . source_iface = other_iface . source_iface <EOL> this_iface . target_iface = other_iface . target_iface <EOL> break <EOL> def dump ( self ) : <EOL> self . _set ( '<STR_LIT>' , '<STR_LIT:file>' , self . disk_file ) <EOL> self . _set ( '<STR_LIT>' , '<STR_LIT:path>' , self . serial_file ) <EOL> self . _set ( '<STR_LIT>' , '<STR_LIT:path>' , self . console_file ) <EOL> xml_devices = self . _xml . find ( '<STR_LIT>' ) <EOL> xml_interfaces = self . _xml . findall ( '<STR_LIT>' ) <EOL> for iface in xml_interfaces : <EOL> xml_devices . remove ( iface ) <EOL> for iface in self . _interfaces : <EOL> xml_devices . append ( iface . element ( ) ) <EOL> return ElementTree . tostring ( self . _xml ) </s>
<s> import abc <EOL> from cloudferry . lib . utils import files <EOL> from cloudferry . lib . utils import remote_runner <EOL> from cloudferry . lib . copy_engines import base <EOL> class CopyFailed ( RuntimeError ) : <EOL> pass <EOL> class CopyMechanism ( object ) : <EOL> __metaclass__ = abc . ABCMeta <EOL> @ abc . abstractmethod <EOL> def copy ( self , context , source_object , destination_object ) : <EOL> raise NotImplementedError ( ) <EOL> class CopyObject ( object ) : <EOL> def __init__ ( self , host = None , path = None ) : <EOL> self . host = host <EOL> self . path = path <EOL> def __repr__ ( self ) : <EOL> return "<STR_LIT>" . format ( host = self . host , path = self . path ) <EOL> class RemoteFileCopy ( CopyMechanism ) : <EOL> """<STR_LIT>""" <EOL> def copy ( self , context , source_object , destination_object ) : <EOL> data = { <EOL> '<STR_LIT>' : source_object . host , <EOL> '<STR_LIT>' : source_object . path , <EOL> '<STR_LIT>' : destination_object . host , <EOL> '<STR_LIT>' : destination_object . path <EOL> } <EOL> try : <EOL> copier = base . get_copier ( context . src_cloud , <EOL> context . dst_cloud , <EOL> data ) <EOL> copier . transfer ( data ) <EOL> except ( base . FileCopyError , <EOL> base . CopierCannotBeUsed , <EOL> base . CopierNotFound ) as e : <EOL> msg = ( "<STR_LIT>" <EOL> "<STR_LIT>" ) . format ( <EOL> src_host = source_object . host , <EOL> src_file = source_object . path , <EOL> dst_host = destination_object . host , <EOL> dst_file = destination_object . path , <EOL> err = e . message ) <EOL> raise CopyFailed ( msg ) <EOL> class CopyRegularFileToBlockDevice ( CopyMechanism ) : <EOL> """<STR_LIT>""" <EOL> def copy ( self , context , source_object , destination_object ) : <EOL> src_user = context . cfg . src . ssh_user <EOL> dst_user = context . cfg . dst . ssh_user <EOL> src_host = source_object . host <EOL> dst_host = destination_object . host <EOL> rr = remote_runner . RemoteRunner ( src_host , src_user ) <EOL> ssh_opts = ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> try : <EOL> progress_view = "<STR_LIT>" <EOL> if files . is_installed ( rr , "<STR_LIT>" ) : <EOL> src_file_size = files . remote_file_size ( rr , source_object . path ) <EOL> progress_view = "<STR_LIT>" . format ( <EOL> size = src_file_size ) <EOL> copy = ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> rr . run ( copy . format ( src_file = source_object . path , <EOL> dst_user = dst_user , <EOL> dst_host = dst_host , <EOL> ssh_opts = ssh_opts , <EOL> dst_device = destination_object . path , <EOL> progress_view = progress_view ) ) <EOL> except remote_runner . RemoteExecutionError as e : <EOL> msg = "<STR_LIT>" <EOL> msg = msg . format ( src_object = source_object , <EOL> dst_object = destination_object , <EOL> error = e . message ) <EOL> raise CopyFailed ( msg ) </s>
<s> import datetime <EOL> import logging <EOL> from logging import config <EOL> from logging import handlers <EOL> import os <EOL> import sys <EOL> from fabric import api <EOL> from oslo_config import cfg <EOL> import yaml <EOL> from cloudferry . lib . utils import sizeof_format <EOL> getLogger = logging . getLogger <EOL> CONF = cfg . CONF <EOL> class StdoutLogger ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , name = None ) : <EOL> self . log = logging . getLogger ( name or '<STR_LIT>' ) <EOL> def write ( self , message ) : <EOL> message = message . strip ( ) <EOL> if message : <EOL> self . log . info ( message ) <EOL> def flush ( self ) : <EOL> pass <EOL> def configure_logging ( log_config = None , debug = None , forward_stdout = None ) : <EOL> """<STR_LIT>""" <EOL> if log_config is None : <EOL> log_config = CONF . migrate . log_config <EOL> if debug is None : <EOL> debug = CONF . migrate . debug <EOL> if forward_stdout is None : <EOL> forward_stdout = CONF . migrate . forward_stdout <EOL> with open ( log_config , '<STR_LIT:r>' ) as f : <EOL> config . dictConfig ( yaml . load ( f ) ) <EOL> if debug : <EOL> logger = logging . getLogger ( '<STR_LIT>' ) <EOL> for handler in logger . handlers : <EOL> if handler . name == '<STR_LIT>' : <EOL> handler . setLevel ( logging . DEBUG ) <EOL> if forward_stdout : <EOL> sys . stdout = StdoutLogger ( ) <EOL> class RunRotatingFileHandler ( handlers . RotatingFileHandler ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , <EOL> filename = '<STR_LIT>' , <EOL> date_format = '<STR_LIT>' , <EOL> ** kwargs ) : <EOL> self . date_format = date_format <EOL> max_bytes = sizeof_format . parse_size ( kwargs . pop ( '<STR_LIT>' , <NUM_LIT:0> ) ) <EOL> super ( RunRotatingFileHandler , self ) . __init__ ( <EOL> filename = self . get_filename ( filename ) , <EOL> maxBytes = max_bytes , <EOL> ** kwargs ) <EOL> def get_filename ( self , filename ) : <EOL> """<STR_LIT>""" <EOL> if hasattr ( CONF , '<STR_LIT>' ) and hasattr ( CONF . migrate , '<STR_LIT>' ) : <EOL> scenario_filename = os . path . basename ( CONF . migrate . scenario ) <EOL> scenario = os . path . splitext ( scenario_filename ) [ <NUM_LIT:0> ] <EOL> else : <EOL> scenario = '<STR_LIT:none>' <EOL> dt = datetime . datetime . now ( ) . strftime ( self . date_format ) <EOL> return filename % { <EOL> '<STR_LIT>' : scenario , <EOL> '<STR_LIT:date>' : dt <EOL> } <EOL> class CurrentTaskFilter ( logging . Filter ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , name_format = '<STR_LIT>' , ** kwargs ) : <EOL> super ( CurrentTaskFilter , self ) . __init__ ( ** kwargs ) <EOL> self . name_format = name_format <EOL> def filter ( self , record ) : <EOL> current_task = self . name_format % { <EOL> '<STR_LIT:name>' : api . env . current_task or '<STR_LIT>' , <EOL> } <EOL> record . current_task = current_task <EOL> return True </s>
<s> """<STR_LIT>""" <EOL> import os <EOL> import yaml <EOL> import cloudferry_devlab . tests . config as config <EOL> from cloudferry_devlab . tests . data_collector import DataCollector <EOL> from cloudferry_devlab . tests import functional_test <EOL> import cloudferry_devlab . tests . utils as utils <EOL> class RollbackVerification ( functional_test . FunctionalTest ) : <EOL> def setUp ( self ) : <EOL> data_collector = DataCollector ( config = config ) <EOL> self . data_after = utils . convert ( data_collector . data_collector ( ) ) <EOL> file_name = config . rollback_params [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> pre_file_path = os . path . join ( self . cloudferry_dir , file_name ) <EOL> with open ( pre_file_path , "<STR_LIT:r>" ) as f : <EOL> self . pre_data = yaml . load ( f ) <EOL> def test_verify_rollback ( self ) : <EOL> """<STR_LIT>""" <EOL> self . maxDiff = None <EOL> msg = '<STR_LIT>' <EOL> for cloud in self . data_after : <EOL> for service in self . data_after [ cloud ] : <EOL> for resource in self . data_after [ cloud ] [ service ] : <EOL> print ( msg . format ( service . lower ( ) , resource . lower ( ) ) ) <EOL> self . assertEqual ( self . data_after [ cloud ] [ service ] [ resource ] , <EOL> self . pre_data [ cloud ] [ service ] [ resource ] ) </s>
<s> import mock <EOL> from cloudferry . lib . os . actions import convert_volume_to_image <EOL> from cloudferry . lib . utils import utils <EOL> from tests import test <EOL> class ConverterVolumeToImageTest ( test . TestCase ) : <EOL> def setUp ( self ) : <EOL> super ( ConverterVolumeToImageTest , self ) . setUp ( ) <EOL> self . fake_src_cloud = mock . Mock ( ) <EOL> self . fake_storage = mock . Mock ( ) <EOL> self . fake_storage . deploy = mock . Mock ( ) <EOL> self . fake_storage . upload_volume_to_image . return_value = ( <EOL> '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . fake_storage . get_backend . return_value = '<STR_LIT>' <EOL> self . fake_image = mock . Mock ( ) <EOL> self . fake_image . wait_for_status = mock . Mock ( ) <EOL> self . fake_image . get_image_by_id_converted = mock . Mock ( ) <EOL> self . fake_image . get_image_by_id_converted . return_value = { <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : { '<STR_LIT:image>' : '<STR_LIT>' , '<STR_LIT>' : { } } } } <EOL> self . fake_image . patch_image = mock . Mock ( ) <EOL> self . fake_src_cloud . resources = { '<STR_LIT>' : self . fake_storage , <EOL> '<STR_LIT:image>' : self . fake_image } <EOL> self . fake_volumes_info = { <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:id>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:image>' : '<STR_LIT:image>' , <EOL> } , <EOL> } } , <EOL> } <EOL> self . fake_dst_cloud = mock . Mock ( ) <EOL> self . fake_config = utils . ext_dict ( migrate = utils . ext_dict ( <EOL> { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' } ) ) <EOL> self . fake_init = { <EOL> '<STR_LIT>' : self . fake_src_cloud , <EOL> '<STR_LIT>' : self . fake_dst_cloud , <EOL> '<STR_LIT>' : self . fake_config <EOL> } <EOL> def test_action ( self ) : <EOL> fake_action = convert_volume_to_image . ConvertVolumeToImage ( <EOL> self . fake_init , <EOL> cloud = '<STR_LIT>' ) <EOL> res = fake_action . run ( self . fake_volumes_info ) <EOL> self . assertEqual ( '<STR_LIT>' , <EOL> res [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT:image>' ] ) <EOL> self . assertEqual ( '<STR_LIT>' , <EOL> res [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ <EOL> '<STR_LIT>' ] [ '<STR_LIT>' ] ) </s>
<s> from cloudferry . lib . utils . cache import Memoized , Cached <EOL> from tests import test <EOL> class MemoizationTestCase ( test . TestCase ) : <EOL> def test_treats_self_as_separate_objects ( self ) : <EOL> class C ( object ) : <EOL> def __init__ ( self , i ) : <EOL> self . i = i <EOL> @ Memoized <EOL> def get_i ( self ) : <EOL> return self . i <EOL> o1 = C ( <NUM_LIT:1> ) <EOL> o2 = C ( <NUM_LIT:2> ) <EOL> self . assertNotEqual ( o1 . get_i ( ) , o2 . get_i ( ) ) <EOL> self . assertEqual ( o1 . get_i ( ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( o2 . get_i ( ) , <NUM_LIT:2> ) <EOL> def test_takes_value_from_cache ( self ) : <EOL> class C ( object ) : <EOL> def __init__ ( self , i ) : <EOL> self . i = i <EOL> @ Memoized <EOL> def get_i ( self ) : <EOL> return self . i <EOL> def set_i ( self , i ) : <EOL> self . i = i <EOL> original = <NUM_LIT:1> <EOL> o = C ( original ) <EOL> self . assertEqual ( o . get_i ( ) , original ) <EOL> o . set_i ( <NUM_LIT:10> ) <EOL> self . assertEqual ( o . get_i ( ) , original ) <EOL> class CacheTestCase ( test . TestCase ) : <EOL> def test_resets_cache_when_modifier_called ( self ) : <EOL> @ Cached ( getter = '<STR_LIT>' , modifier = '<STR_LIT>' ) <EOL> class C ( object ) : <EOL> def __init__ ( self , i ) : <EOL> self . i = i <EOL> def get_i ( self ) : <EOL> return self . i <EOL> def set_i ( self , i ) : <EOL> self . i = i <EOL> o = C ( <NUM_LIT:1> ) <EOL> self . assertEqual ( o . get_i ( ) , <NUM_LIT:1> ) <EOL> o . set_i ( <NUM_LIT:100> ) <EOL> self . assertEqual ( o . get_i ( ) , <NUM_LIT:100> ) </s>
<s> from django . http import HttpResponse , HttpResponseRedirect , HttpResponseNotFound <EOL> from django . template import Context , loader <EOL> from django . core . urlresolvers import reverse <EOL> from django . template import RequestContext <EOL> from django . shortcuts import get_object_or_404 , render_to_response <EOL> from django . core . exceptions import ObjectDoesNotExist <EOL> from datetime import datetime <EOL> from tagging . models import Tag , TaggedItem <EOL> from django . views . decorators . csrf import csrf_exempt <EOL> from django . contrib . auth . models import User <EOL> from django . contrib . auth . decorators import login_required <EOL> from django . contrib . auth import authenticate , login <EOL> from django . core . mail import send_mail <EOL> from django . conf import settings <EOL> from django . http import Http404 <EOL> from django . db . models import Q <EOL> import json <EOL> from openwatch . recordings . models import Recording <EOL> from openwatch import recording_tags <EOL> @ login_required <EOL> def moderate ( request ) : <EOL> '''<STR_LIT>''' <EOL> response_values = { } <EOL> org_tag = request . user . get_profile ( ) . org_tag <EOL> if not request . user . is_superuser and ( not request . user . get_profile ( ) . can_moderate or org_tag == '<STR_LIT>' ) : <EOL> raise Http404 <EOL> if recording_tags . ACLU_NJ in org_tag : <EOL> location = { } <EOL> location [ '<STR_LIT>' ] = <NUM_LIT> <EOL> location [ '<STR_LIT>' ] = - <NUM_LIT> <EOL> response_values [ '<STR_LIT:location>' ] = location <EOL> response_values [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> return render_to_response ( '<STR_LIT>' , response_values , context_instance = RequestContext ( request ) ) <EOL> def map ( request ) : <EOL> total = "<STR_LIT>" <EOL> return render_to_response ( '<STR_LIT>' , { '<STR_LIT>' : total } , context_instance = RequestContext ( request ) ) <EOL> def size ( request ) : <EOL> featureset = Recording . objects . filter ( ~ Q ( lat = None ) , ~ Q ( lon = None ) , ~ Q ( jtype = '<STR_LIT>' ) ) . exclude ( location__exact = '<STR_LIT>' ) . exclude ( location__exact = '<STR_LIT>' ) . order_by ( '<STR_LIT>' ) <EOL> total = len ( featureset ) <EOL> return render_to_response ( '<STR_LIT>' , { '<STR_LIT>' : total } , context_instance = RequestContext ( request ) ) <EOL> def redir ( self ) : <EOL> return HttpResponseRedirect ( '<STR_LIT:/>' ) <EOL> def map_json ( request ) : <EOL> featureset = Recording . objects . all ( ) . order_by ( '<STR_LIT>' ) . filter ( ~ Q ( location = '<STR_LIT>' ) ) . exclude ( location__isnull = True ) . exclude ( location__exact = '<STR_LIT>' ) [ : <NUM_LIT> ] <EOL> resp = encode_queryset ( featureset ) <EOL> return HttpResponse ( resp , mimetype = "<STR_LIT:application/json>" ) <EOL> @ login_required <EOL> def map_json_moderate ( request ) : <EOL> org_tag = request . user . get_profile ( ) . org_tag <EOL> if org_tag != '<STR_LIT>' : <EOL> featureset = Recording . objects . filter ( org_approved = False , org_flagged = False , tags__contains = org_tag ) <EOL> else : <EOL> featureset = Recording . objects . all ( ) <EOL> featureset = featureset . order_by ( '<STR_LIT>' ) . filter ( ~ Q ( location = '<STR_LIT>' ) ) . exclude ( location__isnull = True ) . exclude ( location__exact = '<STR_LIT>' ) <EOL> resp = encode_queryset ( featureset ) <EOL> return HttpResponse ( resp , mimetype = "<STR_LIT:application/json>" ) <EOL> def map_location_json ( request , ne_lat = <NUM_LIT:0> , ne_lon = <NUM_LIT:0> , sw_lat = <NUM_LIT:0> , sw_lon = <NUM_LIT:0> ) : <EOL> ne_lat = float ( ne_lat ) <EOL> ne_lon = float ( ne_lon ) <EOL> sw_lat = float ( sw_lat ) <EOL> sw_lon = float ( sw_lon ) <EOL> featureset = Recording . objects . filter ( lat__lt = ne_lat , lat__gt = sw_lat , lon__lt = ne_lon , lon__gt = sw_lon ) . order_by ( '<STR_LIT>' ) . exclude ( location__isnull = True ) . exclude ( location__exact = '<STR_LIT>' ) . exclude ( location__exact = '<STR_LIT>' ) . exclude ( location__exact = '<STR_LIT>' ) [ : <NUM_LIT> ] <EOL> if len ( featureset ) < <NUM_LIT:1> : <EOL> return HttpResponse ( "<STR_LIT>" , mimetype = "<STR_LIT:application/json>" ) <EOL> resp = encode_queryset ( featureset ) <EOL> return HttpResponse ( resp , mimetype = "<STR_LIT:application/json>" ) <EOL> def encode_queryset ( featureset ) : <EOL> resp = '<STR_LIT>' <EOL> for obj in featureset : <EOL> resp = resp + json . dumps ( obj . to_dict ( ) ) + '<STR_LIT:U+002C>' <EOL> resp = resp [ : - <NUM_LIT:1> ] + '<STR_LIT>' <EOL> return resp </s>
<s> """<STR_LIT>""" <EOL> from django . template import loader , RequestContext <EOL> from django . http import HttpResponse , Http404 <EOL> from django . http import HttpResponseRedirect , HttpResponsePermanentRedirect <EOL> from django . db . models . base import ModelBase <EOL> from django . db . models . manager import Manager <EOL> from django . db . models . query import QuerySet <EOL> from django . core import urlresolvers <EOL> from django . utils import six <EOL> import datetime <EOL> try : <EOL> import json <EOL> except Exception , e : <EOL> import simplejson as json <EOL> from . dumper import DataDumper <EOL> from dicttoxml import dicttoxml as dict2xml <EOL> from xml . dom . minidom import parseString <EOL> import yaml <EOL> def render_to_easy_api_response ( * args , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> httpresponse_kwargs = { '<STR_LIT>' : kwargs . pop ( '<STR_LIT>' , None ) } <EOL> context = kwargs . pop ( '<STR_LIT>' ) <EOL> processors = context . context_processors <EOL> request = processors [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> if request . GET . has_key ( '<STR_LIT>' ) : <EOL> api_type = request . GET [ '<STR_LIT>' ] <EOL> for arg in args : <EOL> passed = arg <EOL> dump_me = { } <EOL> for key in passed . keys ( ) : <EOL> value = passed [ key ] <EOL> dump_me [ key ] = dump_object ( value ) <EOL> if api_type == '<STR_LIT>' : <EOL> def replace_spaces ( dump_me ) : <EOL> new = { } <EOL> for k , v in dump_me . iteritems ( ) : <EOL> if isinstance ( v , dict ) : <EOL> v = replace_spaces ( v ) <EOL> new [ k . replace ( '<STR_LIT:U+0020>' , '<STR_LIT:_>' ) ] = v <EOL> return new <EOL> new = replace_spaces ( dump_me ) <EOL> dump_me = dict2xml ( new ) <EOL> dom = parseString ( dump_me ) <EOL> pretty = dom . toprettyxml ( ) <EOL> return HttpResponse ( pretty , content_type = '<STR_LIT>' ) <EOL> if api_type == '<STR_LIT>' : <EOL> yml = yaml . safe_dump ( dump_me ) <EOL> return HttpResponse ( yml , content_type = '<STR_LIT>' ) <EOL> else : <EOL> dump_me = json . dumps ( dump_me , indent = <NUM_LIT:2> ) <EOL> return HttpResponse ( dump_me , content_type = '<STR_LIT:application/json>' ) <EOL> return HttpResponse ( loader . render_to_string ( * args , ** kwargs ) , ** httpresponse_kwargs ) <EOL> def render_to_response ( * args , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> return render_to_easy_api_response ( * args , ** kwargs ) <EOL> def dump_object ( queryset ) : <EOL> if str ( type ( queryset ) ) != "<STR_LIT>" : <EOL> d = DataDumper ( ) <EOL> ret = d . dump ( queryset ) <EOL> return ret <EOL> try : <EOL> modelName = queryset [ <NUM_LIT:0> ] . __class__ . __name__ <EOL> modelNameData = [ ] <EOL> fields = get_fields ( queryset [ <NUM_LIT:0> ] ) <EOL> for obj in queryset : <EOL> temp_dict = dict ( ) <EOL> for field in fields : <EOL> try : <EOL> attribute = getattr ( obj , str ( field ) ) <EOL> temp_dict [ field ] = attribute <EOL> except Exception , e : <EOL> continue <EOL> modelNameData . append ( temp_dict ) <EOL> dthandler = lambda obj : obj . isoformat ( ) if isinstance ( obj , datetime . datetime ) or isinstance ( obj , datetime . date ) else None <EOL> return json . loads ( json . dumps ( modelNameData , default = dthandler ) ) <EOL> except Exception , e : <EOL> return '<STR_LIT>' <EOL> def get_fields ( model ) : <EOL> try : <EOL> if hasattr ( model , "<STR_LIT>" ) : <EOL> fields = model . easy_api_fields ( ) <EOL> else : <EOL> try : <EOL> fields = model . to_dict ( ) . keys ( ) <EOL> except Exception , e : <EOL> fields = model . _meta . get_all_field_names ( ) <EOL> return fields <EOL> except Exception , e : <EOL> return [ ] </s>
<s> class SimpleEngagementCalculator ( object ) : <EOL> def calculate_user_engagement_score ( self , user , start_date , end_date ) : <EOL> return <NUM_LIT:0> <EOL> ROOT_URLCONF = None <EOL> DATABASE_ENGINE = '<STR_LIT>' <EOL> DATABASE_NAME = '<STR_LIT>' <EOL> DATABASE_SUPPORTS_TRANSACTIONS = False <EOL> INSTALLED_APPS = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' ] <EOL> TEMPLATE_CONTEXT_PROCESSORS = ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" ) </s>
<s> import os <EOL> import sys <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> os . environ . setdefault ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> from django . core . management import execute_from_command_line <EOL> is_testing = '<STR_LIT:test>' in sys . argv <EOL> if is_testing : <EOL> import coverage <EOL> cov = coverage . coverage ( include = "<STR_LIT>" , omit = [ '<STR_LIT>' ] ) <EOL> cov . erase ( ) <EOL> cov . start ( ) <EOL> execute_from_command_line ( sys . argv ) <EOL> if is_testing : <EOL> cov . stop ( ) <EOL> cov . save ( ) <EOL> cov . report ( ) </s>
<s> import datetime <EOL> import time <EOL> class CountdownManager ( object ) : <EOL> def __init__ ( self , root_tk_app ) : <EOL> self . start_time = time . time ( ) <EOL> self . minutes = <NUM_LIT:0> <EOL> self . seconds = <NUM_LIT:0> <EOL> self . time_change_callbacks = [ ] <EOL> self . count_down_total = datetime . timedelta ( days = - <NUM_LIT:1> , minutes = <NUM_LIT:0> , seconds = <NUM_LIT:0> ) <EOL> self . root_tk_app = root_tk_app <EOL> self . refresh_timer ( ) <EOL> def set_countdown_duration ( self , minutes , seconds ) : <EOL> self . start_time = time . time ( ) <EOL> self . minutes = minutes <EOL> self . seconds = seconds <EOL> self . count_down_total = datetime . timedelta ( minutes = minutes , seconds = seconds ) <EOL> self . fire_time_change_callbacks ( ) <EOL> def subscribe_to_time_changes ( self , time_change_callback ) : <EOL> self . time_change_callbacks . append ( time_change_callback ) <EOL> def fire_time_change_callbacks ( self ) : <EOL> end_time = time . time ( ) <EOL> up_time = end_time - self . start_time <EOL> remaining_time = self . count_down_total - datetime . timedelta ( seconds = ( int ( up_time ) ) ) <EOL> for callback in self . time_change_callbacks : <EOL> if callback : <EOL> callback ( remaining_time . days , ( remaining_time . seconds // <NUM_LIT> ) % <NUM_LIT> , remaining_time . seconds % <NUM_LIT> ) <EOL> def refresh_timer ( self ) : <EOL> self . fire_time_change_callbacks ( ) <EOL> if self . root_tk_app : <EOL> self . root_tk_app . after ( <NUM_LIT> , self . refresh_timer ) </s>
<s> """<STR_LIT>""" <EOL> import simplexml , time , sys <EOL> from protocol import * <EOL> from client import PlugIn <EOL> DefaultTimeout = <NUM_LIT> <EOL> ID = <NUM_LIT:0> <EOL> class Dispatcher ( PlugIn ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self ) : <EOL> PlugIn . __init__ ( self ) <EOL> DBG_LINE = '<STR_LIT>' <EOL> self . handlers = { } <EOL> self . _expected = { } <EOL> self . _defaultHandler = None <EOL> self . _pendingExceptions = [ ] <EOL> self . _eventHandler = None <EOL> self . _cycleHandlers = [ ] <EOL> self . _exported_methods = [ self . Process , self . RegisterHandler , self . RegisterDefaultHandler , self . RegisterEventHandler , self . UnregisterCycleHandler , self . RegisterCycleHandler , self . RegisterHandlerOnce , self . UnregisterHandler , self . RegisterProtocol , self . WaitForResponse , self . SendAndWaitForResponse , self . send , self . disconnect , self . SendAndCallForResponse , ] <EOL> def dumpHandlers ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . handlers <EOL> def restoreHandlers ( self , handlers ) : <EOL> """<STR_LIT>""" <EOL> self . handlers = handlers <EOL> def _init ( self ) : <EOL> """<STR_LIT>""" <EOL> self . RegisterNamespace ( '<STR_LIT>' ) <EOL> self . RegisterNamespace ( NS_STREAMS ) <EOL> self . RegisterNamespace ( self . _owner . defaultNamespace ) <EOL> self . RegisterProtocol ( '<STR_LIT>' , Iq ) <EOL> self . RegisterProtocol ( '<STR_LIT>' , Presence ) <EOL> self . RegisterProtocol ( '<STR_LIT:message>' , Message ) <EOL> self . RegisterDefaultHandler ( self . returnStanzaHandler ) <EOL> self . RegisterHandler ( '<STR_LIT:error>' , self . streamErrorHandler , xmlns = NS_STREAMS ) <EOL> def plugin ( self , owner ) : <EOL> """<STR_LIT>""" <EOL> self . _init ( ) <EOL> for method in self . _old_owners_methods : <EOL> if method . __name__ == '<STR_LIT>' : self . _owner_send = method ; break <EOL> self . _owner . lastErrNode = None <EOL> self . _owner . lastErr = None <EOL> self . _owner . lastErrCode = None <EOL> self . StreamInit ( ) <EOL> def plugout ( self ) : <EOL> """<STR_LIT>""" <EOL> self . Stream . dispatch = None <EOL> self . Stream . DEBUG = None <EOL> self . Stream . features = None <EOL> self . Stream . destroy ( ) <EOL> def StreamInit ( self ) : <EOL> """<STR_LIT>""" <EOL> self . Stream = simplexml . NodeBuilder ( ) <EOL> self . Stream . _dispatch_depth = <NUM_LIT:2> <EOL> self . Stream . dispatch = self . dispatch <EOL> self . Stream . stream_header_received = self . _check_stream_start <EOL> self . _owner . debug_flags . append ( simplexml . DBG_NODEBUILDER ) <EOL> self . Stream . DEBUG = self . _owner . DEBUG <EOL> self . Stream . features = None <EOL> self . _metastream = Node ( '<STR_LIT>' ) <EOL> self . _metastream . setNamespace ( self . _owner . Namespace ) <EOL> self . _metastream . setAttr ( '<STR_LIT:version>' , '<STR_LIT:1.0>' ) <EOL> self . _metastream . setAttr ( '<STR_LIT>' , NS_STREAMS ) <EOL> self . _metastream . setAttr ( '<STR_LIT:to>' , self . _owner . Server ) <EOL> self . _owner . send ( "<STR_LIT>" % str ( self . _metastream ) [ : - <NUM_LIT:2> ] ) <EOL> def _check_stream_start ( self , ns , tag , attrs ) : <EOL> if ns < > NS_STREAMS or tag < > '<STR_LIT>' : <EOL> raise ValueError ( '<STR_LIT>' % ( tag , ns ) ) <EOL> def Process ( self , timeout = <NUM_LIT:0> ) : <EOL> """<STR_LIT>""" <EOL> for handler in self . _cycleHandlers : handler ( self ) <EOL> if len ( self . _pendingExceptions ) > <NUM_LIT:0> : <EOL> _pendingException = self . _pendingExceptions . pop ( ) <EOL> raise _pendingException [ <NUM_LIT:0> ] , _pendingException [ <NUM_LIT:1> ] , _pendingException [ <NUM_LIT:2> ] <EOL> if self . _owner . Connection . pending_data ( timeout ) : <EOL> try : data = self . _owner . Connection . receive ( ) <EOL> except IOError : return <EOL> self . Stream . Parse ( data ) <EOL> if len ( self . _pendingExceptions ) > <NUM_LIT:0> : <EOL> _pendingException = self . _pendingExceptions . pop ( ) <EOL> raise _pendingException [ <NUM_LIT:0> ] , _pendingException [ <NUM_LIT:1> ] , _pendingException [ <NUM_LIT:2> ] <EOL> if data : return len ( data ) <EOL> return '<STR_LIT:0>' <EOL> def RegisterNamespace ( self , xmlns , order = '<STR_LIT:info>' ) : <EOL> """<STR_LIT>""" <EOL> self . DEBUG ( '<STR_LIT>' % xmlns , order ) <EOL> self . handlers [ xmlns ] = { } <EOL> self . RegisterProtocol ( '<STR_LIT>' , Protocol , xmlns = xmlns ) <EOL> self . RegisterProtocol ( '<STR_LIT:default>' , Protocol , xmlns = xmlns ) <EOL> def RegisterProtocol ( self , tag_name , Proto , xmlns = None , order = '<STR_LIT:info>' ) : <EOL> """<STR_LIT>""" <EOL> if not xmlns : xmlns = self . _owner . defaultNamespace <EOL> self . DEBUG ( '<STR_LIT>' % ( tag_name , Proto , xmlns ) , order ) <EOL> self . handlers [ xmlns ] [ tag_name ] = { type : Proto , '<STR_LIT:default>' : [ ] } <EOL> def RegisterNamespaceHandler ( self , xmlns , handler , typ = '<STR_LIT>' , ns = '<STR_LIT>' , makefirst = <NUM_LIT:0> , system = <NUM_LIT:0> ) : <EOL> """<STR_LIT>""" <EOL> self . RegisterHandler ( '<STR_LIT:default>' , handler , typ , ns , xmlns , makefirst , system ) <EOL> def RegisterHandler ( self , name , handler , typ = '<STR_LIT>' , ns = '<STR_LIT>' , xmlns = None , makefirst = <NUM_LIT:0> , system = <NUM_LIT:0> ) : <EOL> """<STR_LIT>""" <EOL> if not xmlns : xmlns = self . _owner . defaultNamespace <EOL> self . DEBUG ( '<STR_LIT>' % ( handler , name , typ , ns , xmlns ) , '<STR_LIT:info>' ) <EOL> if not typ and not ns : typ = '<STR_LIT:default>' <EOL> if not self . handlers . has_key ( xmlns ) : self . RegisterNamespace ( xmlns , '<STR_LIT>' ) <EOL> if not self . handlers [ xmlns ] . has_key ( name ) : self . RegisterProtocol ( name , Protocol , xmlns , '<STR_LIT>' ) <EOL> if not self . handlers [ xmlns ] [ name ] . has_key ( typ + ns ) : self . handlers [ xmlns ] [ name ] [ typ + ns ] = [ ] <EOL> if makefirst : self . handlers [ xmlns ] [ name ] [ typ + ns ] . insert ( <NUM_LIT:0> , { '<STR_LIT>' : handler , '<STR_LIT>' : system } ) <EOL> else : self . handlers [ xmlns ] [ name ] [ typ + ns ] . append ( { '<STR_LIT>' : handler , '<STR_LIT>' : system } ) <EOL> def RegisterHandlerOnce ( self , name , handler , typ = '<STR_LIT>' , ns = '<STR_LIT>' , xmlns = None , makefirst = <NUM_LIT:0> , system = <NUM_LIT:0> ) : <EOL> """<STR_LIT>""" <EOL> if not xmlns : xmlns = self . _owner . defaultNamespace <EOL> self . RegisterHandler ( name , handler , typ , ns , xmlns , makefirst , system ) <EOL> def UnregisterHandler ( self , name , handler , typ = '<STR_LIT>' , ns = '<STR_LIT>' , xmlns = None ) : <EOL> """<STR_LIT>""" <EOL> if not xmlns : xmlns = self . _owner . defaultNamespace <EOL> if not self . handlers . has_key ( xmlns ) : return <EOL> if not typ and not ns : typ = '<STR_LIT:default>' <EOL> for pack in self . handlers [ xmlns ] [ name ] [ typ + ns ] : <EOL> if handler == pack [ '<STR_LIT>' ] : break <EOL> else : pack = None <EOL> try : self . handlers [ xmlns ] [ name ] [ typ + ns ] . remove ( pack ) <EOL> except ValueError : pass <EOL> def RegisterDefaultHandler ( self , handler ) : <EOL> """<STR_LIT>""" <EOL> self . _defaultHandler = handler <EOL> def RegisterEventHandler ( self , handler ) : <EOL> """<STR_LIT>""" <EOL> self . _eventHandler = handler <EOL> def returnStanzaHandler ( self , conn , stanza ) : <EOL> """<STR_LIT>""" <EOL> if stanza . getType ( ) in [ '<STR_LIT>' , '<STR_LIT>' ] : <EOL> conn . send ( Error ( stanza , ERR_FEATURE_NOT_IMPLEMENTED ) ) <EOL> def streamErrorHandler ( self , conn , error ) : <EOL> name , text = '<STR_LIT:error>' , error . getData ( ) <EOL> for tag in error . getChildren ( ) : <EOL> if tag . getNamespace ( ) == NS_XMPP_STREAMS : <EOL> if tag . getName ( ) == '<STR_LIT:text>' : text = tag . getData ( ) <EOL> else : name = tag . getName ( ) <EOL> if name in stream_exceptions . keys ( ) : exc = stream_exceptions [ name ] <EOL> else : exc = StreamError <EOL> raise exc ( ( name , text ) ) <EOL> def RegisterCycleHandler ( self , handler ) : <EOL> """<STR_LIT>""" <EOL> if handler not in self . _cycleHandlers : self . _cycleHandlers . append ( handler ) <EOL> def UnregisterCycleHandler ( self , handler ) : <EOL> """<STR_LIT>""" <EOL> if handler in self . _cycleHandlers : self . _cycleHandlers . remove ( handler ) <EOL> def Event ( self , realm , event , data ) : <EOL> """<STR_LIT>""" <EOL> if self . _eventHandler : self . _eventHandler ( realm , event , data ) <EOL> def dispatch ( self , stanza , session = None , direct = <NUM_LIT:0> ) : <EOL> """<STR_LIT>""" <EOL> if not session : session = self <EOL> session . Stream . _mini_dom = None <EOL> name = stanza . getName ( ) <EOL> if not direct and self . _owner . _route : <EOL> if name == '<STR_LIT>' : <EOL> if stanza . getAttr ( '<STR_LIT:error>' ) == None : <EOL> if len ( stanza . getChildren ( ) ) == <NUM_LIT:1> : <EOL> stanza = stanza . getChildren ( ) [ <NUM_LIT:0> ] <EOL> name = stanza . getName ( ) <EOL> else : <EOL> for each in stanza . getChildren ( ) : <EOL> self . dispatch ( each , session , direct = <NUM_LIT:1> ) <EOL> return <EOL> elif name == '<STR_LIT>' : <EOL> return <EOL> elif name in ( '<STR_LIT>' , '<STR_LIT>' ) : <EOL> pass <EOL> else : <EOL> raise UnsupportedStanzaType ( name ) <EOL> if name == '<STR_LIT>' : session . Stream . features = stanza <EOL> xmlns = stanza . getNamespace ( ) <EOL> if not self . handlers . has_key ( xmlns ) : <EOL> self . DEBUG ( "<STR_LIT>" + xmlns , '<STR_LIT>' ) <EOL> xmlns = '<STR_LIT>' <EOL> if not self . handlers [ xmlns ] . has_key ( name ) : <EOL> self . DEBUG ( "<STR_LIT>" + name , '<STR_LIT>' ) <EOL> name = '<STR_LIT>' <EOL> else : <EOL> self . DEBUG ( "<STR_LIT>" % ( xmlns , name ) , '<STR_LIT>' ) <EOL> if stanza . __class__ . __name__ == '<STR_LIT>' : stanza = self . handlers [ xmlns ] [ name ] [ type ] ( node = stanza ) <EOL> typ = stanza . getType ( ) <EOL> if not typ : typ = '<STR_LIT>' <EOL> stanza . props = stanza . getProperties ( ) <EOL> ID = stanza . getID ( ) <EOL> session . DEBUG ( "<STR_LIT>" % ( name , typ , stanza . props , ID ) , '<STR_LIT>' ) <EOL> list = [ '<STR_LIT:default>' ] <EOL> if self . handlers [ xmlns ] [ name ] . has_key ( typ ) : list . append ( typ ) <EOL> for prop in stanza . props : <EOL> if self . handlers [ xmlns ] [ name ] . has_key ( prop ) : list . append ( prop ) <EOL> if typ and self . handlers [ xmlns ] [ name ] . has_key ( typ + prop ) : list . append ( typ + prop ) <EOL> chain = self . handlers [ xmlns ] [ '<STR_LIT:default>' ] [ '<STR_LIT:default>' ] <EOL> for key in list : <EOL> if key : chain = chain + self . handlers [ xmlns ] [ name ] [ key ] <EOL> output = '<STR_LIT>' <EOL> if session . _expected . has_key ( ID ) : <EOL> user = <NUM_LIT:0> <EOL> if type ( session . _expected [ ID ] ) == type ( ( ) ) : <EOL> cb , args = session . _expected [ ID ] <EOL> session . DEBUG ( "<STR_LIT>" % ( cb , args ) , '<STR_LIT>' ) <EOL> try : cb ( session , stanza , ** args ) <EOL> except Exception , typ : <EOL> if typ . __class__ . __name__ < > '<STR_LIT>' : raise <EOL> else : <EOL> session . DEBUG ( "<STR_LIT>" , '<STR_LIT>' ) <EOL> session . _expected [ ID ] = stanza <EOL> else : user = <NUM_LIT:1> <EOL> for handler in chain : <EOL> if user or handler [ '<STR_LIT>' ] : <EOL> try : <EOL> handler [ '<STR_LIT>' ] ( session , stanza ) <EOL> except Exception , typ : <EOL> if typ . __class__ . __name__ < > '<STR_LIT>' : <EOL> self . _pendingExceptions . insert ( <NUM_LIT:0> , sys . exc_info ( ) ) <EOL> return <EOL> user = <NUM_LIT:0> <EOL> if user and self . _defaultHandler : self . _defaultHandler ( session , stanza ) <EOL> def WaitForResponse ( self , ID , timeout = DefaultTimeout ) : <EOL> """<STR_LIT>""" <EOL> self . _expected [ ID ] = None <EOL> has_timed_out = <NUM_LIT:0> <EOL> abort_time = time . time ( ) + timeout <EOL> self . DEBUG ( "<STR_LIT>" % ( ID , timeout ) , '<STR_LIT>' ) <EOL> while not self . _expected [ ID ] : <EOL> if not self . Process ( <NUM_LIT> ) : <EOL> self . _owner . lastErr = "<STR_LIT>" <EOL> return None <EOL> if time . time ( ) > abort_time : <EOL> self . _owner . lastErr = "<STR_LIT>" <EOL> return None <EOL> response = self . _expected [ ID ] <EOL> del self . _expected [ ID ] <EOL> if response . getErrorCode ( ) : <EOL> self . _owner . lastErrNode = response <EOL> self . _owner . lastErr = response . getError ( ) <EOL> self . _owner . lastErrCode = response . getErrorCode ( ) <EOL> return response <EOL> def SendAndWaitForResponse ( self , stanza , timeout = DefaultTimeout ) : <EOL> """<STR_LIT>""" <EOL> return self . WaitForResponse ( self . send ( stanza ) , timeout ) <EOL> def SendAndCallForResponse ( self , stanza , func , args = { } ) : <EOL> """<STR_LIT>""" <EOL> self . _expected [ self . send ( stanza ) ] = ( func , args ) <EOL> def send ( self , stanza ) : <EOL> """<STR_LIT>""" <EOL> if type ( stanza ) in [ type ( '<STR_LIT>' ) , type ( u'<STR_LIT>' ) ] : return self . _owner_send ( stanza ) <EOL> if not isinstance ( stanza , Protocol ) : _ID = None <EOL> elif not stanza . getID ( ) : <EOL> global ID <EOL> ID += <NUM_LIT:1> <EOL> _ID = ` ID ` <EOL> stanza . setID ( _ID ) <EOL> else : _ID = stanza . getID ( ) <EOL> if self . _owner . _registered_name and not stanza . getAttr ( '<STR_LIT>' ) : stanza . setAttr ( '<STR_LIT>' , self . _owner . _registered_name ) <EOL> if self . _owner . _route and stanza . getName ( ) != '<STR_LIT>' : <EOL> to = self . _owner . Server <EOL> if stanza . getTo ( ) and stanza . getTo ( ) . getDomain ( ) : <EOL> to = stanza . getTo ( ) . getDomain ( ) <EOL> frm = stanza . getFrom ( ) <EOL> if frm . getDomain ( ) : <EOL> frm = frm . getDomain ( ) <EOL> route = Protocol ( '<STR_LIT>' , to = to , frm = frm , payload = [ stanza ] ) <EOL> stanza = route <EOL> stanza . setNamespace ( self . _owner . Namespace ) <EOL> stanza . setParent ( self . _metastream ) <EOL> self . _owner_send ( stanza ) <EOL> return _ID <EOL> def disconnect ( self ) : <EOL> """<STR_LIT>""" <EOL> self . _owner_send ( '<STR_LIT>' ) <EOL> while self . Process ( <NUM_LIT:1> ) : pass </s>
<s> from . gl_utils import * <EOL> from . texture import VideoTexture <EOL> from . widget import Widget , BGUI_DEFAULT , WeakMethod <EOL> from . image import Image <EOL> class Video ( Image ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , parent , vid , name = None , play_audio = False , repeat = <NUM_LIT:0> , aspect = None , size = [ <NUM_LIT:1> , <NUM_LIT:1> ] , pos = [ <NUM_LIT:0> , <NUM_LIT:0> ] , <EOL> sub_theme = '<STR_LIT>' , options = BGUI_DEFAULT ) : <EOL> """<STR_LIT>""" <EOL> Image . __init__ ( self , parent , name , None , aspect , size , pos , sub_theme = sub_theme , options = options ) <EOL> self . _texture = VideoTexture ( vid , GL_LINEAR , repeat , play_audio ) <EOL> self . _on_finish = None <EOL> self . _on_finish_called = False <EOL> def play ( self , start , end , use_frames = True , fps = None ) : <EOL> self . _texture . play ( start , end , use_frames , fps ) <EOL> self . _on_finish_called = False <EOL> @ property <EOL> def on_finish ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . _on_finish <EOL> @ on_finish . setter <EOL> def on_finish ( self , value ) : <EOL> self . _on_finish = WeakMethod ( value ) <EOL> def _draw ( self ) : <EOL> """<STR_LIT>""" <EOL> self . _texture . update ( ) <EOL> Image . _draw ( self ) <EOL> if self . _texture . video . status == <NUM_LIT:3> : <EOL> if self . _on_finish and not self . _on_finish_called : <EOL> self . on_finish ( self ) <EOL> self . _on_finish_called = True </s>
<s> from django import template <EOL> from django . conf import settings <EOL> register = template . Library ( ) <EOL> class CheckGrappelli ( template . Node ) : <EOL> def __init__ ( self , var_name ) : <EOL> self . var_name = var_name <EOL> def render ( self , context ) : <EOL> context [ self . var_name ] = '<STR_LIT>' in settings . INSTALLED_APPS <EOL> return '<STR_LIT>' <EOL> def check_grappelli ( parser , token ) : <EOL> """<STR_LIT>""" <EOL> bits = token . contents . split ( ) <EOL> if len ( bits ) != <NUM_LIT:3> : <EOL> raise template . TemplateSyntaxError ( "<STR_LIT>" ) <EOL> if bits [ <NUM_LIT:1> ] != '<STR_LIT>' : <EOL> raise template . TemplateSyntaxError ( "<STR_LIT>" ) <EOL> varname = bits [ <NUM_LIT:2> ] <EOL> return CheckGrappelli ( varname ) <EOL> register . tag ( check_grappelli ) </s>
<s> """<STR_LIT>""" <EOL> from setuptools import setup , find_packages <EOL> import sys , os <EOL> __version__ = '<STR_LIT>' <EOL> __description__ = '<STR_LIT>' , <EOL> __license__ = '<STR_LIT>' <EOL> __author__ = '<STR_LIT>' , <EOL> __email__ = '<STR_LIT>' , <EOL> sys . path . insert ( <NUM_LIT:0> , os . path . dirname ( __file__ ) ) <EOL> REQUIRES = [ i . strip ( ) for i in open ( "<STR_LIT>" ) . readlines ( ) ] <EOL> setup ( <EOL> name = '<STR_LIT>' , <EOL> version = __version__ , <EOL> url = '<STR_LIT>' , <EOL> download_url = '<STR_LIT>' , <EOL> license = __license__ , <EOL> author = __author__ , <EOL> author_email = __email__ , <EOL> description = __description__ , <EOL> long_description = __doc__ , <EOL> test_suite = '<STR_LIT>' , <EOL> zip_safe = False , <EOL> platforms = '<STR_LIT>' , <EOL> install_requires = REQUIRES , <EOL> packages = find_packages ( exclude = ( '<STR_LIT>' , '<STR_LIT>' , ) ) , <EOL> include_package_data = True , <EOL> setup_requires = [ '<STR_LIT>' , '<STR_LIT>' ] , <EOL> classifiers = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' <EOL> ] <EOL> ) </s>
<s> from mongoengine . base import BaseField <EOL> __all__ = ( '<STR_LIT>' ) <EOL> class WtfBaseField ( BaseField ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , validators = None , filters = None , ** kwargs ) : <EOL> self . validators = self . _ensure_callable_or_list ( validators , '<STR_LIT>' ) <EOL> self . filters = self . _ensure_callable_or_list ( filters , '<STR_LIT>' ) <EOL> BaseField . __init__ ( self , ** kwargs ) <EOL> def _ensure_callable_or_list ( self , field , msg_flag ) : <EOL> """<STR_LIT>""" <EOL> if field is not None : <EOL> if callable ( field ) : <EOL> field = [ field ] <EOL> else : <EOL> msg = "<STR_LIT>" % msg_flag <EOL> if not isinstance ( field , list ) : <EOL> raise TypeError ( msg ) <EOL> return field </s>
<s> from bson import DBRef , SON <EOL> from mongoengine . python_support import txt_type <EOL> from base import ( <EOL> BaseDict , BaseList , EmbeddedDocumentList , <EOL> TopLevelDocumentMetaclass , get_document <EOL> ) <EOL> from fields import ( ReferenceField , ListField , DictField , MapField ) <EOL> from connection import get_db <EOL> from queryset import QuerySet <EOL> from document import Document , EmbeddedDocument <EOL> class DeReference ( object ) : <EOL> def __call__ ( self , items , max_depth = <NUM_LIT:1> , instance = None , name = None ) : <EOL> """<STR_LIT>""" <EOL> if items is None or isinstance ( items , basestring ) : <EOL> return items <EOL> if isinstance ( items , QuerySet ) : <EOL> items = [ i for i in items ] <EOL> self . max_depth = max_depth <EOL> doc_type = None <EOL> if instance and isinstance ( instance , ( Document , EmbeddedDocument , <EOL> TopLevelDocumentMetaclass ) ) : <EOL> doc_type = instance . _fields . get ( name ) <EOL> while hasattr ( doc_type , '<STR_LIT>' ) : <EOL> doc_type = doc_type . field <EOL> if isinstance ( doc_type , ReferenceField ) : <EOL> field = doc_type <EOL> doc_type = doc_type . document_type <EOL> is_list = not hasattr ( items , '<STR_LIT>' ) <EOL> if is_list and all ( [ i . __class__ == doc_type for i in items ] ) : <EOL> return items <EOL> elif not is_list and all ( <EOL> [ i . __class__ == doc_type for i in items . values ( ) ] ) : <EOL> return items <EOL> elif not field . dbref : <EOL> if not hasattr ( items , '<STR_LIT>' ) : <EOL> def _get_items ( items ) : <EOL> new_items = [ ] <EOL> for v in items : <EOL> if isinstance ( v , list ) : <EOL> new_items . append ( _get_items ( v ) ) <EOL> elif not isinstance ( v , ( DBRef , Document ) ) : <EOL> new_items . append ( field . to_python ( v ) ) <EOL> else : <EOL> new_items . append ( v ) <EOL> return new_items <EOL> items = _get_items ( items ) <EOL> else : <EOL> items = dict ( [ <EOL> ( k , field . to_python ( v ) ) <EOL> if not isinstance ( v , ( DBRef , Document ) ) else ( k , v ) <EOL> for k , v in items . iteritems ( ) ] <EOL> ) <EOL> self . reference_map = self . _find_references ( items ) <EOL> self . object_map = self . _fetch_objects ( doc_type = doc_type ) <EOL> return self . _attach_objects ( items , <NUM_LIT:0> , instance , name ) <EOL> def _find_references ( self , items , depth = <NUM_LIT:0> ) : <EOL> """<STR_LIT>""" <EOL> reference_map = { } <EOL> if not items or depth >= self . max_depth : <EOL> return reference_map <EOL> if not hasattr ( items , '<STR_LIT>' ) : <EOL> iterator = enumerate ( items ) <EOL> else : <EOL> iterator = items . iteritems ( ) <EOL> depth += <NUM_LIT:1> <EOL> for k , item in iterator : <EOL> if isinstance ( item , ( Document , EmbeddedDocument ) ) : <EOL> for field_name , field in item . _fields . iteritems ( ) : <EOL> v = item . _data . get ( field_name , None ) <EOL> if isinstance ( v , DBRef ) : <EOL> reference_map . setdefault ( field . document_type , set ( ) ) . add ( v . id ) <EOL> elif isinstance ( v , ( dict , SON ) ) and '<STR_LIT>' in v : <EOL> reference_map . setdefault ( get_document ( v [ '<STR_LIT>' ] ) , set ( ) ) . add ( v [ '<STR_LIT>' ] . id ) <EOL> elif isinstance ( v , ( dict , list , tuple ) ) and depth <= self . max_depth : <EOL> field_cls = getattr ( getattr ( field , '<STR_LIT>' , None ) , '<STR_LIT>' , None ) <EOL> references = self . _find_references ( v , depth ) <EOL> for key , refs in references . iteritems ( ) : <EOL> if isinstance ( field_cls , ( Document , TopLevelDocumentMetaclass ) ) : <EOL> key = field_cls <EOL> reference_map . setdefault ( key , set ( ) ) . update ( refs ) <EOL> elif isinstance ( item , DBRef ) : <EOL> reference_map . setdefault ( item . collection , set ( ) ) . add ( item . id ) <EOL> elif isinstance ( item , ( dict , SON ) ) and '<STR_LIT>' in item : <EOL> reference_map . setdefault ( get_document ( item [ '<STR_LIT>' ] ) , set ( ) ) . add ( item [ '<STR_LIT>' ] . id ) <EOL> elif isinstance ( item , ( dict , list , tuple ) ) and depth - <NUM_LIT:1> <= self . max_depth : <EOL> references = self . _find_references ( item , depth - <NUM_LIT:1> ) <EOL> for key , refs in references . iteritems ( ) : <EOL> reference_map . setdefault ( key , set ( ) ) . update ( refs ) <EOL> return reference_map <EOL> def _fetch_objects ( self , doc_type = None ) : <EOL> """<STR_LIT>""" <EOL> object_map = { } <EOL> for collection , dbrefs in self . reference_map . iteritems ( ) : <EOL> if hasattr ( collection , '<STR_LIT>' ) : <EOL> col_name = collection . _get_collection_name ( ) <EOL> refs = [ dbref for dbref in dbrefs <EOL> if ( col_name , dbref ) not in object_map ] <EOL> references = collection . objects . in_bulk ( refs ) <EOL> for key , doc in references . iteritems ( ) : <EOL> object_map [ ( col_name , key ) ] = doc <EOL> else : <EOL> if isinstance ( doc_type , ( ListField , DictField , MapField , ) ) : <EOL> continue <EOL> refs = [ dbref for dbref in dbrefs <EOL> if ( collection , dbref ) not in object_map ] <EOL> if doc_type : <EOL> references = doc_type . _get_db ( ) [ collection ] . find ( { '<STR_LIT>' : { '<STR_LIT>' : refs } } ) <EOL> for ref in references : <EOL> doc = doc_type . _from_son ( ref ) <EOL> object_map [ ( collection , doc . id ) ] = doc <EOL> else : <EOL> references = get_db ( ) [ collection ] . find ( { '<STR_LIT>' : { '<STR_LIT>' : refs } } ) <EOL> for ref in references : <EOL> if '<STR_LIT>' in ref : <EOL> doc = get_document ( ref [ "<STR_LIT>" ] ) . _from_son ( ref ) <EOL> elif doc_type is None : <EOL> doc = get_document ( <EOL> '<STR_LIT>' . join ( x . capitalize ( ) <EOL> for x in collection . split ( '<STR_LIT:_>' ) ) ) . _from_son ( ref ) <EOL> else : <EOL> doc = doc_type . _from_son ( ref ) <EOL> object_map [ ( collection , doc . id ) ] = doc <EOL> return object_map <EOL> def _attach_objects ( self , items , depth = <NUM_LIT:0> , instance = None , name = None ) : <EOL> """<STR_LIT>""" <EOL> if not items : <EOL> if isinstance ( items , ( BaseDict , BaseList ) ) : <EOL> return items <EOL> if instance : <EOL> if isinstance ( items , dict ) : <EOL> return BaseDict ( items , instance , name ) <EOL> else : <EOL> return BaseList ( items , instance , name ) <EOL> if isinstance ( items , ( dict , SON ) ) : <EOL> if '<STR_LIT>' in items : <EOL> return self . object_map . get ( <EOL> ( items [ '<STR_LIT>' ] . collection , items [ '<STR_LIT>' ] . id ) , items ) <EOL> elif '<STR_LIT>' in items : <EOL> doc = get_document ( items [ '<STR_LIT>' ] ) . _from_son ( items ) <EOL> _cls = doc . _data . pop ( '<STR_LIT>' , None ) <EOL> del items [ '<STR_LIT>' ] <EOL> doc . _data = self . _attach_objects ( doc . _data , depth , doc , None ) <EOL> if _cls is not None : <EOL> doc . _data [ '<STR_LIT>' ] = _cls <EOL> return doc <EOL> if not hasattr ( items , '<STR_LIT>' ) : <EOL> is_list = True <EOL> list_type = BaseList <EOL> if isinstance ( items , EmbeddedDocumentList ) : <EOL> list_type = EmbeddedDocumentList <EOL> as_tuple = isinstance ( items , tuple ) <EOL> iterator = enumerate ( items ) <EOL> data = [ ] <EOL> else : <EOL> is_list = False <EOL> iterator = items . iteritems ( ) <EOL> data = { } <EOL> depth += <NUM_LIT:1> <EOL> for k , v in iterator : <EOL> if is_list : <EOL> data . append ( v ) <EOL> else : <EOL> data [ k ] = v <EOL> if k in self . object_map and not is_list : <EOL> data [ k ] = self . object_map [ k ] <EOL> elif isinstance ( v , ( Document , EmbeddedDocument ) ) : <EOL> for field_name , field in v . _fields . iteritems ( ) : <EOL> v = data [ k ] . _data . get ( field_name , None ) <EOL> if isinstance ( v , DBRef ) : <EOL> data [ k ] . _data [ field_name ] = self . object_map . get ( <EOL> ( v . collection , v . id ) , v ) <EOL> elif isinstance ( v , ( dict , SON ) ) and '<STR_LIT>' in v : <EOL> data [ k ] . _data [ field_name ] = self . object_map . get ( <EOL> ( v [ '<STR_LIT>' ] . collection , v [ '<STR_LIT>' ] . id ) , v ) <EOL> elif isinstance ( v , ( dict , list , tuple ) ) and depth <= self . max_depth : <EOL> item_name = txt_type ( "<STR_LIT>" ) . format ( name , k , field_name ) <EOL> data [ k ] . _data [ field_name ] = self . _attach_objects ( v , depth , instance = instance , name = item_name ) <EOL> elif isinstance ( v , ( dict , list , tuple ) ) and depth <= self . max_depth : <EOL> item_name = '<STR_LIT>' % ( name , k ) if name else name <EOL> data [ k ] = self . _attach_objects ( v , depth - <NUM_LIT:1> , instance = instance , name = item_name ) <EOL> elif hasattr ( v , '<STR_LIT:id>' ) : <EOL> data [ k ] = self . object_map . get ( ( v . collection , v . id ) , v ) <EOL> if instance and name : <EOL> if is_list : <EOL> return tuple ( data ) if as_tuple else list_type ( data , instance , name ) <EOL> return BaseDict ( data , instance , name ) <EOL> depth += <NUM_LIT:1> <EOL> return data </s>
<s> import sys <EOL> sys . path [ <NUM_LIT:0> : <NUM_LIT:0> ] = [ "<STR_LIT>" ] <EOL> import unittest <EOL> from mongoengine import * <EOL> from mongoengine . connection import get_db <EOL> __all__ = ( "<STR_LIT>" , ) <EOL> class GeoFieldTest ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> connect ( db = '<STR_LIT>' ) <EOL> self . db = get_db ( ) <EOL> def _test_for_expected_error ( self , Cls , loc , expected ) : <EOL> try : <EOL> Cls ( loc = loc ) . validate ( ) <EOL> self . fail ( '<STR_LIT>' . format ( loc ) ) <EOL> except ValidationError as e : <EOL> self . assertEqual ( expected , e . to_dict ( ) [ '<STR_LIT>' ] ) <EOL> def test_geopoint_validation ( self ) : <EOL> class Location ( Document ) : <EOL> loc = GeoPointField ( ) <EOL> invalid_coords = [ { "<STR_LIT:x>" : <NUM_LIT:1> , "<STR_LIT:y>" : <NUM_LIT:2> } , <NUM_LIT:5> , "<STR_LIT:a>" ] <EOL> expected = '<STR_LIT>' <EOL> for coord in invalid_coords : <EOL> self . _test_for_expected_error ( Location , coord , expected ) <EOL> invalid_coords = [ [ ] , [ <NUM_LIT:1> ] , [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ] <EOL> for coord in invalid_coords : <EOL> expected = "<STR_LIT>" % repr ( coord ) <EOL> self . _test_for_expected_error ( Location , coord , expected ) <EOL> invalid_coords = [ [ { } , { } ] , ( "<STR_LIT:a>" , "<STR_LIT:b>" ) ] <EOL> for coord in invalid_coords : <EOL> expected = "<STR_LIT>" % repr ( coord ) <EOL> self . _test_for_expected_error ( Location , coord , expected ) <EOL> def test_point_validation ( self ) : <EOL> class Location ( Document ) : <EOL> loc = PointField ( ) <EOL> invalid_coords = { "<STR_LIT:x>" : <NUM_LIT:1> , "<STR_LIT:y>" : <NUM_LIT:2> } <EOL> expected = '<STR_LIT>' <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = { "<STR_LIT:type>" : "<STR_LIT>" , "<STR_LIT>" : [ ] } <EOL> expected = '<STR_LIT>' <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = { "<STR_LIT:type>" : "<STR_LIT>" , "<STR_LIT>" : [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] } <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ <NUM_LIT:5> , "<STR_LIT:a>" ] <EOL> expected = "<STR_LIT>" <EOL> for coord in invalid_coords : <EOL> self . _test_for_expected_error ( Location , coord , expected ) <EOL> invalid_coords = [ [ ] , [ <NUM_LIT:1> ] , [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ] <EOL> for coord in invalid_coords : <EOL> expected = "<STR_LIT>" % repr ( coord ) <EOL> self . _test_for_expected_error ( Location , coord , expected ) <EOL> invalid_coords = [ [ { } , { } ] , ( "<STR_LIT:a>" , "<STR_LIT:b>" ) ] <EOL> for coord in invalid_coords : <EOL> expected = "<STR_LIT>" % repr ( coord ) <EOL> self . _test_for_expected_error ( Location , coord , expected ) <EOL> Location ( loc = [ <NUM_LIT:1> , <NUM_LIT:2> ] ) . validate ( ) <EOL> Location ( loc = { <EOL> "<STR_LIT:type>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> <EOL> ] } ) . validate ( ) <EOL> def test_linestring_validation ( self ) : <EOL> class Location ( Document ) : <EOL> loc = LineStringField ( ) <EOL> invalid_coords = { "<STR_LIT:x>" : <NUM_LIT:1> , "<STR_LIT:y>" : <NUM_LIT:2> } <EOL> expected = '<STR_LIT>' <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = { "<STR_LIT:type>" : "<STR_LIT>" , "<STR_LIT>" : [ [ ] ] } <EOL> expected = '<STR_LIT>' <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = { "<STR_LIT:type>" : "<STR_LIT>" , "<STR_LIT>" : [ [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ] } <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ <NUM_LIT:5> , "<STR_LIT:a>" ] <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ <NUM_LIT:1> ] ] <EOL> expected = "<STR_LIT>" % repr ( invalid_coords [ <NUM_LIT:0> ] ) <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ] <EOL> expected = "<STR_LIT>" % repr ( invalid_coords [ <NUM_LIT:0> ] ) <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ [ { } , { } ] ] , [ ( "<STR_LIT:a>" , "<STR_LIT:b>" ) ] ] <EOL> for coord in invalid_coords : <EOL> expected = "<STR_LIT>" % repr ( coord [ <NUM_LIT:0> ] ) <EOL> self . _test_for_expected_error ( Location , coord , expected ) <EOL> Location ( loc = [ [ <NUM_LIT:1> , <NUM_LIT:2> ] , [ <NUM_LIT:3> , <NUM_LIT:4> ] , [ <NUM_LIT:5> , <NUM_LIT:6> ] , [ <NUM_LIT:1> , <NUM_LIT:2> ] ] ) . validate ( ) <EOL> def test_polygon_validation ( self ) : <EOL> class Location ( Document ) : <EOL> loc = PolygonField ( ) <EOL> invalid_coords = { "<STR_LIT:x>" : <NUM_LIT:1> , "<STR_LIT:y>" : <NUM_LIT:2> } <EOL> expected = '<STR_LIT>' <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = { "<STR_LIT:type>" : "<STR_LIT>" , "<STR_LIT>" : [ [ ] ] } <EOL> expected = '<STR_LIT>' <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = { "<STR_LIT:type>" : "<STR_LIT>" , "<STR_LIT>" : [ [ [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ] ] } <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ [ <NUM_LIT:5> , "<STR_LIT:a>" ] ] ] <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ [ ] ] ] <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ] ] <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ [ { } , { } ] ] , [ ( "<STR_LIT:a>" , "<STR_LIT:b>" ) ] ] <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ [ <NUM_LIT:1> , <NUM_LIT:2> ] , [ <NUM_LIT:3> , <NUM_LIT:4> ] ] ] <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> Location ( loc = [ [ [ <NUM_LIT:1> , <NUM_LIT:2> ] , [ <NUM_LIT:3> , <NUM_LIT:4> ] , [ <NUM_LIT:5> , <NUM_LIT:6> ] , [ <NUM_LIT:1> , <NUM_LIT:2> ] ] ] ) . validate ( ) <EOL> def test_multipoint_validation ( self ) : <EOL> class Location ( Document ) : <EOL> loc = MultiPointField ( ) <EOL> invalid_coords = { "<STR_LIT:x>" : <NUM_LIT:1> , "<STR_LIT:y>" : <NUM_LIT:2> } <EOL> expected = '<STR_LIT>' <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = { "<STR_LIT:type>" : "<STR_LIT>" , "<STR_LIT>" : [ [ ] ] } <EOL> expected = '<STR_LIT>' <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = { "<STR_LIT:type>" : "<STR_LIT>" , "<STR_LIT>" : [ [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ] } <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ ] ] <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ [ <NUM_LIT:1> ] ] , [ [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ] ] <EOL> for coord in invalid_coords : <EOL> expected = "<STR_LIT>" % repr ( coord [ <NUM_LIT:0> ] ) <EOL> self . _test_for_expected_error ( Location , coord , expected ) <EOL> invalid_coords = [ [ [ { } , { } ] ] , [ ( "<STR_LIT:a>" , "<STR_LIT:b>" ) ] ] <EOL> for coord in invalid_coords : <EOL> expected = "<STR_LIT>" % repr ( coord [ <NUM_LIT:0> ] ) <EOL> self . _test_for_expected_error ( Location , coord , expected ) <EOL> Location ( loc = [ [ <NUM_LIT:1> , <NUM_LIT:2> ] ] ) . validate ( ) <EOL> Location ( loc = { <EOL> "<STR_LIT:type>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : [ <EOL> [ <NUM_LIT:1> , <NUM_LIT:2> ] , <EOL> [ <NUM_LIT> , <NUM_LIT> ] <EOL> ] } ) . validate ( ) <EOL> def test_multilinestring_validation ( self ) : <EOL> class Location ( Document ) : <EOL> loc = MultiLineStringField ( ) <EOL> invalid_coords = { "<STR_LIT:x>" : <NUM_LIT:1> , "<STR_LIT:y>" : <NUM_LIT:2> } <EOL> expected = '<STR_LIT>' <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = { "<STR_LIT:type>" : "<STR_LIT>" , "<STR_LIT>" : [ [ ] ] } <EOL> expected = '<STR_LIT>' <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = { "<STR_LIT:type>" : "<STR_LIT>" , "<STR_LIT>" : [ [ [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ] ] } <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ <NUM_LIT:5> , "<STR_LIT:a>" ] <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ [ <NUM_LIT:1> ] ] ] <EOL> expected = "<STR_LIT>" % repr ( invalid_coords [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] ) <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ] ] <EOL> expected = "<STR_LIT>" % repr ( invalid_coords [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] ) <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ [ [ { } , { } ] ] ] , [ [ ( "<STR_LIT:a>" , "<STR_LIT:b>" ) ] ] ] <EOL> for coord in invalid_coords : <EOL> expected = "<STR_LIT>" % repr ( coord [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] ) <EOL> self . _test_for_expected_error ( Location , coord , expected ) <EOL> Location ( loc = [ [ [ <NUM_LIT:1> , <NUM_LIT:2> ] , [ <NUM_LIT:3> , <NUM_LIT:4> ] , [ <NUM_LIT:5> , <NUM_LIT:6> ] , [ <NUM_LIT:1> , <NUM_LIT:2> ] ] ] ) . validate ( ) <EOL> def test_multipolygon_validation ( self ) : <EOL> class Location ( Document ) : <EOL> loc = MultiPolygonField ( ) <EOL> invalid_coords = { "<STR_LIT:x>" : <NUM_LIT:1> , "<STR_LIT:y>" : <NUM_LIT:2> } <EOL> expected = '<STR_LIT>' <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = { "<STR_LIT:type>" : "<STR_LIT>" , "<STR_LIT>" : [ [ ] ] } <EOL> expected = '<STR_LIT>' <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = { "<STR_LIT:type>" : "<STR_LIT>" , "<STR_LIT>" : [ [ [ [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ] ] ] } <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ [ [ <NUM_LIT:5> , "<STR_LIT:a>" ] ] ] ] <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ [ [ ] ] ] ] <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ [ [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] ] ] ] <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ [ [ { } , { } ] ] ] , [ [ ( "<STR_LIT:a>" , "<STR_LIT:b>" ) ] ] ] <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> invalid_coords = [ [ [ [ <NUM_LIT:1> , <NUM_LIT:2> ] , [ <NUM_LIT:3> , <NUM_LIT:4> ] ] ] ] <EOL> expected = "<STR_LIT>" <EOL> self . _test_for_expected_error ( Location , invalid_coords , expected ) <EOL> Location ( loc = [ [ [ [ <NUM_LIT:1> , <NUM_LIT:2> ] , [ <NUM_LIT:3> , <NUM_LIT:4> ] , [ <NUM_LIT:5> , <NUM_LIT:6> ] , [ <NUM_LIT:1> , <NUM_LIT:2> ] ] ] ] ) . validate ( ) <EOL> def test_indexes_geopoint ( self ) : <EOL> """<STR_LIT>""" <EOL> class Event ( Document ) : <EOL> title = StringField ( ) <EOL> location = GeoPointField ( ) <EOL> geo_indicies = Event . _geo_indices ( ) <EOL> self . assertEqual ( geo_indicies , [ { '<STR_LIT>' : [ ( '<STR_LIT:location>' , '<STR_LIT>' ) ] } ] ) <EOL> def test_geopoint_embedded_indexes ( self ) : <EOL> """<STR_LIT>""" <EOL> class Venue ( EmbeddedDocument ) : <EOL> location = GeoPointField ( ) <EOL> name = StringField ( ) <EOL> class Event ( Document ) : <EOL> title = StringField ( ) <EOL> venue = EmbeddedDocumentField ( Venue ) <EOL> geo_indicies = Event . _geo_indices ( ) <EOL> self . assertEqual ( geo_indicies , [ { '<STR_LIT>' : [ ( '<STR_LIT>' , '<STR_LIT>' ) ] } ] ) <EOL> def test_indexes_2dsphere ( self ) : <EOL> """<STR_LIT>""" <EOL> class Event ( Document ) : <EOL> title = StringField ( ) <EOL> point = PointField ( ) <EOL> line = LineStringField ( ) <EOL> polygon = PolygonField ( ) <EOL> geo_indicies = Event . _geo_indices ( ) <EOL> self . assertTrue ( { '<STR_LIT>' : [ ( '<STR_LIT>' , '<STR_LIT>' ) ] } in geo_indicies ) <EOL> self . assertTrue ( { '<STR_LIT>' : [ ( '<STR_LIT>' , '<STR_LIT>' ) ] } in geo_indicies ) <EOL> self . assertTrue ( { '<STR_LIT>' : [ ( '<STR_LIT>' , '<STR_LIT>' ) ] } in geo_indicies ) <EOL> def test_indexes_2dsphere_embedded ( self ) : <EOL> """<STR_LIT>""" <EOL> class Venue ( EmbeddedDocument ) : <EOL> name = StringField ( ) <EOL> point = PointField ( ) <EOL> line = LineStringField ( ) <EOL> polygon = PolygonField ( ) <EOL> class Event ( Document ) : <EOL> title = StringField ( ) <EOL> venue = EmbeddedDocumentField ( Venue ) <EOL> geo_indicies = Event . _geo_indices ( ) <EOL> self . assertTrue ( { '<STR_LIT>' : [ ( '<STR_LIT>' , '<STR_LIT>' ) ] } in geo_indicies ) <EOL> self . assertTrue ( { '<STR_LIT>' : [ ( '<STR_LIT>' , '<STR_LIT>' ) ] } in geo_indicies ) <EOL> self . assertTrue ( { '<STR_LIT>' : [ ( '<STR_LIT>' , '<STR_LIT>' ) ] } in geo_indicies ) <EOL> def test_geo_indexes_recursion ( self ) : <EOL> class Location ( Document ) : <EOL> name = StringField ( ) <EOL> location = GeoPointField ( ) <EOL> class Parent ( Document ) : <EOL> name = StringField ( ) <EOL> location = ReferenceField ( Location ) <EOL> Location . drop_collection ( ) <EOL> Parent . drop_collection ( ) <EOL> Parent ( name = '<STR_LIT>' ) . save ( ) <EOL> info = Parent . _get_collection ( ) . index_information ( ) <EOL> self . assertFalse ( '<STR_LIT>' in info ) <EOL> info = Location . _get_collection ( ) . index_information ( ) <EOL> self . assertTrue ( '<STR_LIT>' in info ) <EOL> self . assertEqual ( len ( Parent . _geo_indices ( ) ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( len ( Location . _geo_indices ( ) ) , <NUM_LIT:1> ) <EOL> def test_geo_indexes_auto_index ( self ) : <EOL> class Log ( Document ) : <EOL> location = PointField ( auto_index = False ) <EOL> datetime = DateTimeField ( ) <EOL> meta = { <EOL> '<STR_LIT>' : [ [ ( "<STR_LIT:location>" , "<STR_LIT>" ) , ( "<STR_LIT>" , <NUM_LIT:1> ) ] ] <EOL> } <EOL> self . assertEqual ( [ ] , Log . _geo_indices ( ) ) <EOL> Log . drop_collection ( ) <EOL> Log . ensure_indexes ( ) <EOL> info = Log . _get_collection ( ) . index_information ( ) <EOL> self . assertEqual ( info [ "<STR_LIT>" ] [ "<STR_LIT:key>" ] , <EOL> [ ( '<STR_LIT:location>' , '<STR_LIT>' ) , ( '<STR_LIT>' , <NUM_LIT:1> ) ] ) <EOL> class Log ( Document ) : <EOL> location = PointField ( auto_index = False ) <EOL> datetime = DateTimeField ( ) <EOL> meta = { <EOL> '<STR_LIT>' : [ <EOL> { '<STR_LIT>' : [ ( "<STR_LIT:location>" , "<STR_LIT>" ) , ( "<STR_LIT>" , <NUM_LIT:1> ) ] } <EOL> ] <EOL> } <EOL> self . assertEqual ( [ ] , Log . _geo_indices ( ) ) <EOL> Log . drop_collection ( ) <EOL> Log . ensure_indexes ( ) <EOL> info = Log . _get_collection ( ) . index_information ( ) <EOL> self . assertEqual ( info [ "<STR_LIT>" ] [ "<STR_LIT:key>" ] , <EOL> [ ( '<STR_LIT:location>' , '<STR_LIT>' ) , ( '<STR_LIT>' , <NUM_LIT:1> ) ] ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> unittest . main ( ) </s>
<s> from south . db import db <EOL> from django . db import models <EOL> from django_lean . experiments . models import * <EOL> class Migration : <EOL> def forwards ( self , orm ) : <EOL> db . create_table ( '<STR_LIT>' , ( <EOL> ( '<STR_LIT:id>' , orm [ '<STR_LIT>' ] ) , <EOL> ( '<STR_LIT:name>' , orm [ '<STR_LIT>' ] ) , <EOL> ( '<STR_LIT:state>' , orm [ '<STR_LIT>' ] ) , <EOL> ( '<STR_LIT>' , orm [ '<STR_LIT>' ] ) , <EOL> ( '<STR_LIT>' , orm [ '<STR_LIT>' ] ) , <EOL> ) ) <EOL> db . send_create_signal ( '<STR_LIT>' , [ '<STR_LIT>' ] ) <EOL> db . create_table ( '<STR_LIT>' , ( <EOL> ( '<STR_LIT:id>' , orm [ '<STR_LIT>' ] ) , <EOL> ( '<STR_LIT:user>' , orm [ '<STR_LIT>' ] ) , <EOL> ( '<STR_LIT>' , orm [ '<STR_LIT>' ] ) , <EOL> ( '<STR_LIT>' , orm [ '<STR_LIT>' ] ) , <EOL> ( '<STR_LIT>' , orm [ '<STR_LIT>' ] ) , <EOL> ) ) <EOL> db . send_create_signal ( '<STR_LIT>' , [ '<STR_LIT>' ] ) <EOL> db . create_table ( '<STR_LIT>' , ( <EOL> ( '<STR_LIT:id>' , orm [ '<STR_LIT>' ] ) , <EOL> ( '<STR_LIT:date>' , orm [ '<STR_LIT>' ] ) , <EOL> ( '<STR_LIT>' , orm [ '<STR_LIT>' ] ) , <EOL> ( '<STR_LIT>' , orm [ '<STR_LIT>' ] ) , <EOL> ( '<STR_LIT>' , orm [ '<STR_LIT>' ] ) , <EOL> ) ) <EOL> db . send_create_signal ( '<STR_LIT>' , [ '<STR_LIT>' ] ) <EOL> db . create_unique ( '<STR_LIT>' , [ '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> def backwards ( self , orm ) : <EOL> db . delete_table ( '<STR_LIT>' ) <EOL> db . delete_table ( '<STR_LIT>' ) <EOL> db . delete_table ( '<STR_LIT>' ) <EOL> db . delete_unique ( '<STR_LIT>' , [ '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> models = { <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:name>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:Meta>' : { '<STR_LIT>' : "<STR_LIT>" } , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT:100>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" } ) , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:name>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' } ) <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT>' } ) , <EOL> '<STR_LIT:email>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT:False>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT:False>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:password>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:username>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT:True>' } ) <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:Meta>' : { '<STR_LIT>' : "<STR_LIT>" , '<STR_LIT>' : "<STR_LIT>" } , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT:100>' } ) , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT:100>' } ) , <EOL> '<STR_LIT:name>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT:100>' } ) <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { } ) , <EOL> '<STR_LIT:date>' : ( '<STR_LIT>' , [ ] , { } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" } ) , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { } ) <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:null>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:name>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:null>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:state>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT:0>' } ) <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:Meta>' : { '<STR_LIT>' : "<STR_LIT>" } , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { } ) , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:user>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" } ) <EOL> } <EOL> } <EOL> complete_apps = [ '<STR_LIT>' ] </s>
<s> class SimpleEngagementCalculator ( object ) : <EOL> def calculate_user_engagement_score ( self , user , start_date , end_date ) : <EOL> return <NUM_LIT:0> <EOL> ROOT_URLCONF = None <EOL> DATABASE_ENGINE = '<STR_LIT>' <EOL> DATABASE_NAME = '<STR_LIT>' <EOL> DATABASE_SUPPORTS_TRANSACTIONS = False <EOL> INSTALLED_APPS = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' ] <EOL> TEMPLATE_CONTEXT_PROCESSORS = ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" ) </s>
<s> from contextlib import contextmanager <EOL> from django . contrib . sites . models import Site <EOL> from django . core import mail <EOL> from django . db import transaction <EOL> from django . utils . functional import LazyObject <EOL> def get_current_site ( ) : <EOL> if Site . _meta . installed : <EOL> return Site . objects . get_current ( ) <EOL> return None <EOL> def in_transaction ( test_ignore = True ) : <EOL> result = transaction . is_managed ( ) <EOL> if test_ignore : <EOL> result = result and not hasattr ( mail , '<STR_LIT>' ) <EOL> return result <EOL> @ contextmanager <EOL> def patch ( namespace , name , function ) : <EOL> """<STR_LIT>""" <EOL> if isinstance ( namespace , LazyObject ) : <EOL> if namespace . _wrapped is None : <EOL> namespace . _setup ( ) <EOL> namespace = namespace . _wrapped <EOL> try : <EOL> original = getattr ( namespace , name ) <EOL> except AttributeError : <EOL> original = NotImplemented <EOL> try : <EOL> setattr ( namespace , name , function ) <EOL> yield <EOL> finally : <EOL> if original is NotImplemented : <EOL> delattr ( namespace , name ) <EOL> else : <EOL> setattr ( namespace , name , original ) </s>
<s> """<STR_LIT>""" </s>
<s> """<STR_LIT>""" <EOL> from construct import * <EOL> from ipv4 import IpAddress <EOL> echo_payload = Struct ( "<STR_LIT>" , <EOL> UBInt16 ( "<STR_LIT>" ) , <EOL> UBInt16 ( "<STR_LIT>" ) , <EOL> Bytes ( "<STR_LIT:data>" , <NUM_LIT:32> ) , <EOL> ) <EOL> dest_unreachable_payload = Struct ( "<STR_LIT>" , <EOL> Padding ( <NUM_LIT:2> ) , <EOL> UBInt16 ( "<STR_LIT>" ) , <EOL> IpAddress ( "<STR_LIT:host>" ) , <EOL> Bytes ( "<STR_LIT>" , <NUM_LIT:8> ) , <EOL> ) <EOL> dest_unreachable_code = Enum ( Byte ( "<STR_LIT:code>" ) , <EOL> Network_unreachable_error = <NUM_LIT:0> , <EOL> Host_unreachable_error = <NUM_LIT:1> , <EOL> Protocol_unreachable_error = <NUM_LIT:2> , <EOL> Port_unreachable_error = <NUM_LIT:3> , <EOL> The_datagram_is_too_big = <NUM_LIT:4> , <EOL> Source_route_failed_error = <NUM_LIT:5> , <EOL> Destination_network_unknown_error = <NUM_LIT:6> , <EOL> Destination_host_unknown_error = <NUM_LIT:7> , <EOL> Source_host_isolated_error = <NUM_LIT:8> , <EOL> Desination_administratively_prohibited = <NUM_LIT:9> , <EOL> Host_administratively_prohibited2 = <NUM_LIT:10> , <EOL> Network_TOS_unreachable = <NUM_LIT:11> , <EOL> Host_TOS_unreachable = <NUM_LIT:12> , <EOL> ) <EOL> icmp_header = Struct ( "<STR_LIT>" , <EOL> Enum ( Byte ( "<STR_LIT:type>" ) , <EOL> Echo_reply = <NUM_LIT:0> , <EOL> Destination_unreachable = <NUM_LIT:3> , <EOL> Source_quench = <NUM_LIT:4> , <EOL> Redirect = <NUM_LIT:5> , <EOL> Alternate_host_address = <NUM_LIT:6> , <EOL> Echo_request = <NUM_LIT:8> , <EOL> Router_advertisement = <NUM_LIT:9> , <EOL> Router_solicitation = <NUM_LIT:10> , <EOL> Time_exceeded = <NUM_LIT:11> , <EOL> Parameter_problem = <NUM_LIT:12> , <EOL> Timestamp_request = <NUM_LIT> , <EOL> Timestamp_reply = <NUM_LIT> , <EOL> Information_request = <NUM_LIT:15> , <EOL> Information_reply = <NUM_LIT:16> , <EOL> Address_mask_request = <NUM_LIT> , <EOL> Address_mask_reply = <NUM_LIT> , <EOL> _default_ = Pass , <EOL> ) , <EOL> Switch ( "<STR_LIT:code>" , lambda ctx : ctx . type , <EOL> { <EOL> "<STR_LIT>" : dest_unreachable_code , <EOL> } , <EOL> default = Byte ( "<STR_LIT:code>" ) , <EOL> ) , <EOL> UBInt16 ( "<STR_LIT>" ) , <EOL> Switch ( "<STR_LIT>" , lambda ctx : ctx . type , <EOL> { <EOL> "<STR_LIT>" : echo_payload , <EOL> "<STR_LIT>" : echo_payload , <EOL> "<STR_LIT>" : dest_unreachable_payload , <EOL> } , <EOL> default = Pass <EOL> ) <EOL> ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> cap1 = ( "<STR_LIT>" <EOL> "<STR_LIT>" ) . decode ( "<STR_LIT>" ) <EOL> cap2 = ( "<STR_LIT>" <EOL> "<STR_LIT>" ) . decode ( "<STR_LIT>" ) <EOL> cap3 = ( "<STR_LIT>" ) . decode ( "<STR_LIT>" ) <EOL> print icmp_header . parse ( cap1 ) <EOL> print icmp_header . parse ( cap2 ) <EOL> print icmp_header . parse ( cap3 ) </s>
<s> from construct . core import Container <EOL> from construct . adapters import Adapter <EOL> class AstNode ( Container ) : <EOL> def __init__ ( self , nodetype , ** kw ) : <EOL> Container . __init__ ( self ) <EOL> self . nodetype = nodetype <EOL> for k , v in sorted ( kw . iteritems ( ) ) : <EOL> setattr ( self , k , v ) <EOL> def accept ( self , visitor ) : <EOL> return getattr ( visitor , "<STR_LIT>" % ( self . nodetype , ) ) ( self ) <EOL> class AstTransformator ( Adapter ) : <EOL> def _decode ( self , obj , context ) : <EOL> return self . to_ast ( obj , context ) <EOL> def _encode ( self , obj , context ) : <EOL> return self . to_cst ( obj , context ) </s>
<s> def pytest_funcarg__setupopts ( request ) : <EOL> return OptsSetup ( request ) <EOL> def pytest_addoption ( parser ) : <EOL> parser . addoption ( "<STR_LIT>" , dest = "<STR_LIT>" , <EOL> type = str , default = None , <EOL> help = "<STR_LIT>" ) <EOL> parser . addoption ( "<STR_LIT>" , dest = "<STR_LIT>" , <EOL> action = "<STR_LIT:store_true>" , <EOL> help = "<STR_LIT>" ) <EOL> parser . addoption ( "<STR_LIT>" , dest = "<STR_LIT>" , <EOL> action = "<STR_LIT:store_true>" , <EOL> help = "<STR_LIT>" ) <EOL> parser . addoption ( "<STR_LIT>" , dest = "<STR_LIT>" , <EOL> type = int , default = <NUM_LIT:0> , <EOL> help = "<STR_LIT>" ) <EOL> parser . addoption ( "<STR_LIT>" , dest = "<STR_LIT:time>" , <EOL> type = str , default = "<STR_LIT>" , <EOL> help = "<STR_LIT>" ) <EOL> parser . addoption ( "<STR_LIT>" , dest = "<STR_LIT>" , <EOL> type = int , default = <NUM_LIT:8> , <EOL> help = "<STR_LIT>" ) <EOL> parser . addoption ( "<STR_LIT>" , dest = "<STR_LIT>" , <EOL> type = float , default = <NUM_LIT:16> , <EOL> help = "<STR_LIT>" ) <EOL> parser . addoption ( "<STR_LIT>" , dest = "<STR_LIT>" , <EOL> type = int , default = <NUM_LIT:8> , <EOL> help = "<STR_LIT>" ) <EOL> parser . addoption ( "<STR_LIT>" , dest = "<STR_LIT>" , <EOL> type = str , default = None , <EOL> help = "<STR_LIT>" ) <EOL> parser . addoption ( "<STR_LIT>" , dest = "<STR_LIT>" , <EOL> action = "<STR_LIT:store_true>" , <EOL> help = "<STR_LIT>" ) <EOL> parser . addoption ( "<STR_LIT>" , dest = "<STR_LIT>" , <EOL> type = str , default = "<STR_LIT>" , <EOL> help = "<STR_LIT>" ) <EOL> class OptsSetup ( ) : <EOL> def __init__ ( self , request ) : <EOL> self . config = request . config <EOL> def returnAllOptions ( self ) : <EOL> return self . config . option <EOL> def getNumExecutors ( self ) : <EOL> return self . config . option . num_exec <EOL> def getTime ( self ) : <EOL> return self . config . option . time <EOL> def getProc ( self ) : <EOL> return self . config . option . proc <EOL> def getMem ( self ) : <EOL> return self . config . option . mem <EOL> def getQueue ( self ) : <EOL> return self . config . option . queue <EOL> def getPpn ( self ) : <EOL> return self . config . option . ppn <EOL> def getRestart ( self ) : <EOL> return self . config . option . restart <EOL> def getBackupDir ( self ) : <EOL> return self . config . option . backup_directory <EOL> def returnSampleArgs ( self ) : <EOL> sampleArgArray = [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] <EOL> return sampleArgArray </s>
<s> """<STR_LIT>""" <EOL> import base64 <EOL> import random <EOL> from twisted . python import log <EOL> from twisted . web . error import Error as WebError <EOL> from opennsa import constants as cnt , config <EOL> from opennsa . backends . common import genericbackend <EOL> from opennsa . protocols . shared import httpclient <EOL> NCS_TIMEOUT = <NUM_LIT> <EOL> NO_OUT_OF_SYNC_CHECK = '<STR_LIT>' <EOL> ETHERNET_VPN_PAYLOAD_BASE = """<STR_LIT>""" <EOL> ETHERNET_VLAN_VPN_PAYLOAD_BASE = """<STR_LIT>""" <EOL> ETHERNET_VLAN_REWRITE_VPN_PAYLOAD_BASE = """<STR_LIT>""" <EOL> LOG_SYSTEM = '<STR_LIT>' <EOL> class NCSVPNTarget ( object ) : <EOL> def __init__ ( self , router , interface , vlan = None ) : <EOL> self . router = router <EOL> self . interface = interface <EOL> self . vlan = vlan <EOL> def __str__ ( self ) : <EOL> if self . vlan : <EOL> return '<STR_LIT>' % ( self . router , self . interface , self . vlan ) <EOL> else : <EOL> return '<STR_LIT>' % ( self . router , self . interface ) <EOL> def createVPNPayload ( service_name , source_target , dest_target ) : <EOL> intps = { <EOL> '<STR_LIT>' : service_name , <EOL> '<STR_LIT>' : service_name , <EOL> '<STR_LIT>' : source_target . router , <EOL> '<STR_LIT>' : source_target . interface , <EOL> '<STR_LIT>' : dest_target . router , <EOL> '<STR_LIT>' : dest_target . interface <EOL> } <EOL> if source_target . vlan and dest_target . vlan : <EOL> if source_target . vlan == dest_target . vlan : <EOL> intps [ '<STR_LIT>' ] = source_target . vlan <EOL> payload = ETHERNET_VLAN_VPN_PAYLOAD_BASE % intps <EOL> else : <EOL> intps [ '<STR_LIT>' ] = source_target . vlan <EOL> intps [ '<STR_LIT>' ] = dest_target . vlan <EOL> payload = ETHERNET_VLAN_REWRITE_VPN_PAYLOAD_BASE % intps <EOL> else : <EOL> payload = ETHERNET_VPN_PAYLOAD_BASE % intps <EOL> return payload <EOL> def _extractErrorMessage ( failure ) : <EOL> if isinstance ( failure . value , WebError ) : <EOL> return failure . value . response <EOL> else : <EOL> return failure . getErrorMessage ( ) <EOL> class NCSVPNConnectionManager : <EOL> def __init__ ( self , ncs_services_url , user , password , port_map , log_system ) : <EOL> self . ncs_services_url = ncs_services_url <EOL> self . user = user <EOL> self . password = password <EOL> self . port_map = port_map <EOL> self . log_system = log_system <EOL> def getResource ( self , port , label_type , label_value ) : <EOL> assert label_type in ( None , cnt . ETHERNET_VLAN ) , '<STR_LIT>' <EOL> return port + '<STR_LIT::>' + str ( label_value ) <EOL> def getTarget ( self , port , label_type , label_value ) : <EOL> assert label_type in ( None , cnt . ETHERNET_VLAN ) , '<STR_LIT>' <EOL> if label_type == cnt . ETHERNET_VLAN : <EOL> vlan = int ( label_value ) <EOL> assert <NUM_LIT:1> <= vlan <= <NUM_LIT> , '<STR_LIT>' % label_value <EOL> ri = self . port_map [ port ] <EOL> router , interface = ri . split ( '<STR_LIT::>' ) <EOL> return NCSVPNTarget ( router , interface , vlan ) <EOL> def createConnectionId ( self , source_target , dest_target ) : <EOL> return '<STR_LIT>' + str ( random . randint ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> def canSwapLabel ( self , label_type ) : <EOL> return label_type == cnt . ETHERNET_VLAN <EOL> def _createAuthzHeader ( self ) : <EOL> return '<STR_LIT>' + base64 . b64encode ( self . user + '<STR_LIT::>' + self . password ) <EOL> def _createHeaders ( self ) : <EOL> headers = { } <EOL> headers [ '<STR_LIT:Content-Type>' ] = '<STR_LIT>' <EOL> headers [ '<STR_LIT>' ] = self . _createAuthzHeader ( ) <EOL> return headers <EOL> def setupLink ( self , connection_id , source_target , dest_target , bandwidth ) : <EOL> service_url = self . ncs_services_url + '<STR_LIT:?>' + NO_OUT_OF_SYNC_CHECK <EOL> payload = createVPNPayload ( connection_id , source_target , dest_target ) <EOL> headers = self . _createHeaders ( ) <EOL> def linkUp ( _ ) : <EOL> log . msg ( '<STR_LIT>' % ( source_target , dest_target ) , system = self . log_system ) <EOL> def error ( failure ) : <EOL> log . msg ( '<STR_LIT>' % ( source_target , dest_target ) , system = self . log_system ) <EOL> log . msg ( '<STR_LIT>' % _extractErrorMessage ( failure ) , system = self . log_system ) <EOL> return failure <EOL> d = httpclient . httpRequest ( service_url , payload , headers , method = '<STR_LIT:POST>' , timeout = NCS_TIMEOUT ) <EOL> d . addCallbacks ( linkUp , error ) <EOL> return d <EOL> def teardownLink ( self , connection_id , source_target , dest_target , bandwidth ) : <EOL> service_url = self . ncs_services_url + '<STR_LIT>' + connection_id + '<STR_LIT:?>' + NO_OUT_OF_SYNC_CHECK <EOL> headers = self . _createHeaders ( ) <EOL> def linkDown ( _ ) : <EOL> log . msg ( '<STR_LIT>' % ( source_target , dest_target ) , system = self . log_system ) <EOL> def error ( failure ) : <EOL> log . msg ( '<STR_LIT>' % ( source_target , dest_target ) , system = self . log_system ) <EOL> log . msg ( '<STR_LIT>' % _extractErrorMessage ( failure ) , system = self . log_system ) <EOL> return failure <EOL> d = httpclient . httpRequest ( service_url , None , headers , method = '<STR_LIT>' , timeout = NCS_TIMEOUT ) <EOL> d . addCallbacks ( linkDown , error ) <EOL> return d <EOL> def NCSVPNBackend ( network_name , nrm_ports , parent_requester , cfg ) : <EOL> name = '<STR_LIT>' % network_name <EOL> nrm_map = dict ( [ ( p . name , p ) for p in nrm_ports ] ) <EOL> port_map = dict ( [ ( p . name , p . interface ) for p in nrm_ports ] ) <EOL> ncs_services_url = str ( cfg [ config . NCS_SERVICES_URL ] ) <EOL> user = cfg [ config . NCS_USER ] <EOL> password = cfg [ config . NCS_PASSWORD ] <EOL> cm = NCSVPNConnectionManager ( ncs_services_url , user , password , port_map , name ) <EOL> return genericbackend . GenericBackend ( network_name , nrm_map , cm , parent_requester , name ) </s>
<s> """<STR_LIT>""" <EOL> import time <EOL> from twisted . python import log , failure <EOL> from opennsa import nsa , error <EOL> from opennsa . shared import xmlhelper <EOL> from opennsa . protocols . shared import minisoap , soapresource <EOL> from opennsa . protocols . nsi2 import helper , queryhelper <EOL> from opennsa . protocols . nsi2 . bindings import actions , nsiconnection , p2pservices <EOL> LOG_SYSTEM = '<STR_LIT>' <EOL> class ProviderService : <EOL> def __init__ ( self , soap_resource , provider ) : <EOL> self . provider = provider <EOL> soap_resource . registerDecoder ( actions . RESERVE , self . reserve ) <EOL> soap_resource . registerDecoder ( actions . RESERVE_COMMIT , self . reserveCommit ) <EOL> soap_resource . registerDecoder ( actions . RESERVE_ABORT , self . reserveAbort ) <EOL> soap_resource . registerDecoder ( actions . PROVISION , self . provision ) <EOL> soap_resource . registerDecoder ( actions . RELEASE , self . release ) <EOL> soap_resource . registerDecoder ( actions . TERMINATE , self . terminate ) <EOL> soap_resource . registerDecoder ( actions . QUERY_SUMMARY , self . querySummary ) <EOL> soap_resource . registerDecoder ( actions . QUERY_SUMMARY_SYNC , self . querySummarySync ) <EOL> soap_resource . registerDecoder ( actions . QUERY_RECURSIVE , self . queryRecursive ) <EOL> def _createSOAPFault ( self , err , provider_nsa , connection_id = None , service_type = None ) : <EOL> log . msg ( '<STR_LIT>' % err . getErrorMessage ( ) , system = LOG_SYSTEM ) <EOL> se = helper . createServiceException ( err , provider_nsa , connection_id ) <EOL> ex_element = se . xml ( nsiconnection . serviceException ) <EOL> soap_fault = soapresource . SOAPFault ( err . getErrorMessage ( ) , ex_element ) <EOL> return soap_fault <EOL> def reserve ( self , soap_data , request_info ) : <EOL> t_start = time . time ( ) <EOL> header , reservation = helper . parseRequest ( soap_data ) <EOL> criteria = reservation . criteria <EOL> service_type = criteria . serviceType <EOL> p2ps = criteria . serviceDefinition <EOL> if type ( p2ps ) is not p2pservices . P2PServiceBaseType : <EOL> err = failure . Failure ( error . PayloadError ( '<STR_LIT>' ) ) <EOL> return self . _createSOAPFault ( err , header . provider_nsa , service_type = service_type ) <EOL> if p2ps . directionality in ( None , '<STR_LIT>' ) : <EOL> err = failure . Failure ( error . MissingParameterError ( '<STR_LIT>' ) ) <EOL> return self . _createSOAPFault ( err , header . provider_nsa ) <EOL> start_time = xmlhelper . parseXMLTimestamp ( criteria . schedule . startTime ) if criteria . schedule . startTime is not None else None <EOL> end_time = xmlhelper . parseXMLTimestamp ( criteria . schedule . endTime ) if criteria . schedule . endTime is not None else None <EOL> schedule = nsa . Schedule ( start_time , end_time ) <EOL> src_stp = helper . createSTP ( p2ps . sourceSTP ) <EOL> dst_stp = helper . createSTP ( p2ps . destSTP ) <EOL> if p2ps . ero : <EOL> err = failure . Failure ( error . PayloadError ( '<STR_LIT>' ) ) <EOL> return self . _createSOAPFault ( err , header . provider_nsa ) <EOL> params = [ ( p . type_ , p . value ) for p in p2ps . parameter ] if p2ps . parameter else None <EOL> symmetric = p2ps . symmetricPath or False <EOL> sd = nsa . Point2PointService ( src_stp , dst_stp , p2ps . capacity , p2ps . directionality , symmetric , None , params ) <EOL> crt = nsa . Criteria ( criteria . version , schedule , sd ) <EOL> t_delta = time . time ( ) - t_start <EOL> log . msg ( '<STR_LIT>' % round ( t_delta , <NUM_LIT:3> ) , profile = True , system = LOG_SYSTEM ) <EOL> d = self . provider . reserve ( header , reservation . connectionId , reservation . globalReservationId , reservation . description , crt , request_info ) <EOL> def createReserveAcknowledgement ( connection_id ) : <EOL> soap_header_element = helper . createProviderHeader ( header . requester_nsa , header . provider_nsa , None , header . correlation_id ) <EOL> reserve_response = nsiconnection . ReserveResponseType ( connection_id ) <EOL> reserve_response_element = reserve_response . xml ( nsiconnection . reserveResponse ) <EOL> payload = minisoap . createSoapPayload ( reserve_response_element , soap_header_element ) <EOL> return payload <EOL> d . addCallbacks ( createReserveAcknowledgement , self . _createSOAPFault , errbackArgs = ( header . provider_nsa , ) ) <EOL> return d <EOL> def reserveCommit ( self , soap_data , request_info ) : <EOL> header , confirm = helper . parseRequest ( soap_data ) <EOL> d = self . provider . reserveCommit ( header , confirm . connectionId , request_info ) <EOL> d . addCallbacks ( lambda _ : helper . createGenericProviderAcknowledgement ( header ) , self . _createSOAPFault , errbackArgs = ( header . provider_nsa , confirm . connectionId ) ) <EOL> return d <EOL> def reserveAbort ( self , soap_data , request_info ) : <EOL> header , request = helper . parseRequest ( soap_data ) <EOL> d = self . provider . reserveAbort ( header , request . connectionId , request_info ) <EOL> d . addCallbacks ( lambda _ : helper . createGenericProviderAcknowledgement ( header ) , self . _createSOAPFault , errbackArgs = ( header . provider_nsa , request . connectionId ) ) <EOL> return d <EOL> def provision ( self , soap_data , request_info ) : <EOL> header , request = helper . parseRequest ( soap_data ) <EOL> d = self . provider . provision ( header , request . connectionId , request_info ) <EOL> d . addCallbacks ( lambda _ : helper . createGenericProviderAcknowledgement ( header ) , self . _createSOAPFault , errbackArgs = ( header . provider_nsa , request . connectionId ) ) <EOL> return d <EOL> def release ( self , soap_data , request_info ) : <EOL> header , request = helper . parseRequest ( soap_data ) <EOL> d = self . provider . release ( header , request . connectionId , request_info ) <EOL> d . addCallbacks ( lambda _ : helper . createGenericProviderAcknowledgement ( header ) , self . _createSOAPFault , errbackArgs = ( header . provider_nsa , request . connectionId ) ) <EOL> return d <EOL> def terminate ( self , soap_data , request_info ) : <EOL> header , request = helper . parseRequest ( soap_data ) <EOL> d = self . provider . terminate ( header , request . connectionId , request_info ) <EOL> d . addCallbacks ( lambda _ : helper . createGenericProviderAcknowledgement ( header ) , self . _createSOAPFault , errbackArgs = ( header . provider_nsa , request . connectionId ) ) <EOL> return d <EOL> def querySummary ( self , soap_data , request_info ) : <EOL> header , query = helper . parseRequest ( soap_data ) <EOL> d = self . provider . querySummary ( header , query . connectionId , query . globalReservationId , request_info ) <EOL> d . addCallbacks ( lambda _ : helper . createGenericProviderAcknowledgement ( header ) , self . _createSOAPFault , errbackArgs = ( header . provider_nsa , ) ) <EOL> return d <EOL> def querySummarySync ( self , soap_data , request_info ) : <EOL> def gotReservations ( reservations , header ) : <EOL> soap_header_element = helper . createProviderHeader ( header . requester_nsa , header . provider_nsa , correlation_id = header . correlation_id ) <EOL> qs_reservations = queryhelper . buildQuerySummaryResultType ( reservations ) <EOL> qsct = nsiconnection . QuerySummaryConfirmedType ( qs_reservations ) <EOL> payload = minisoap . createSoapPayload ( qsct . xml ( nsiconnection . querySummarySyncConfirmed ) , soap_header_element ) <EOL> return payload <EOL> header , query = helper . parseRequest ( soap_data ) <EOL> d = self . provider . querySummarySync ( header , query . connectionId , query . globalReservationId , request_info ) <EOL> d . addCallbacks ( gotReservations , self . _createSOAPFault , callbackArgs = ( header , ) , errbackArgs = ( header . provider_nsa , ) ) <EOL> return d <EOL> def queryRecursive ( self , soap_data , request_info ) : <EOL> header , query = helper . parseRequest ( soap_data ) <EOL> d = self . provider . queryRecursive ( header , query . connectionId , query . globalReservationId , request_info ) <EOL> d . addCallbacks ( lambda _ : helper . createGenericProviderAcknowledgement ( header ) , self . _createSOAPFault , errbackArgs = ( header . provider_nsa , ) ) <EOL> return d </s>
<s> import os , datetime , json <EOL> from twisted . trial import unittest <EOL> from twisted . internet import defer , task <EOL> from opennsa import config , nsa , database <EOL> from opennsa . topology import nml <EOL> from opennsa . backends import ncsvpn <EOL> from . import common <EOL> class NCSVPNBackendTest ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . clock = task . Clock ( ) <EOL> tcf = os . path . expanduser ( '<STR_LIT>' ) <EOL> tc = json . load ( open ( tcf ) ) <EOL> ncs_config = { <EOL> config . NCS_SERVICES_URL : tc [ '<STR_LIT>' ] , <EOL> config . NCS_USER : tc [ '<STR_LIT>' ] , <EOL> config . NCS_PASSWORD : tc [ '<STR_LIT>' ] <EOL> } <EOL> self . requester = common . DUDRequester ( ) <EOL> self . backend = ncsvpn . NCSVPNBackend ( '<STR_LIT>' , self . sr , self . requester , ncs_config ) <EOL> self . backend . scheduler . clock = self . clock <EOL> self . backend . startService ( ) <EOL> database . setupDatabase ( tc [ '<STR_LIT>' ] , tc [ '<STR_LIT>' ] , tc [ '<STR_LIT>' ] ) <EOL> self . requester_nsa = nsa . NetworkServiceAgent ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . provider_nsa = nsa . NetworkServiceAgent ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> source_stp = nsa . STP ( '<STR_LIT>' , '<STR_LIT>' , labels = [ nsa . Label ( nml . ETHERNET_VLAN , '<STR_LIT>' ) ] ) <EOL> dest_stp = nsa . STP ( '<STR_LIT>' , '<STR_LIT>' , labels = [ nsa . Label ( nml . ETHERNET_VLAN , '<STR_LIT>' ) ] ) <EOL> start_time = datetime . datetime . utcnow ( ) + datetime . timedelta ( seconds = <NUM_LIT:2> ) <EOL> end_time = datetime . datetime . utcnow ( ) + datetime . timedelta ( seconds = <NUM_LIT:30> ) <EOL> bandwidth = <NUM_LIT:200> <EOL> self . service_params = nsa . ServiceParameters ( start_time , end_time , source_stp , dest_stp , bandwidth ) <EOL> @ defer . inlineCallbacks <EOL> def tearDown ( self ) : <EOL> from opennsa . backends . common import simplebackend <EOL> yield simplebackend . Simplebackendconnection . deleteAll ( ) <EOL> yield self . backend . stopService ( ) <EOL> @ defer . inlineCallbacks <EOL> def testActivation ( self ) : <EOL> _ , _ , cid , sp = yield self . reserve ( self . requester_nsa , self . provider_nsa , None , None , None , None , self . service_params ) <EOL> yield self . backend . reserveCommit ( self . requester_nsa , self . provider_nsa , None , cid ) <EOL> yield self . backend . provision ( self . requester_nsa , self . provider_nsa , None , cid ) <EOL> self . clock . advance ( <NUM_LIT:3> ) <EOL> connection_id , active , version_consistent , version , timestamp = yield d_up <EOL> self . failUnlessEqual ( cid , connection_id ) <EOL> self . failUnlessEqual ( active , True ) <EOL> self . failUnlessEqual ( version_consistent , True ) <EOL> yield self . backend . terminate ( self . requester_nsa , self . provider_nsa , None , cid ) <EOL> connection_id , active , version_consistent , version , timestamp = yield d_down <EOL> self . failUnlessEqual ( cid , connection_id ) <EOL> self . failUnlessEqual ( active , False ) <EOL> self . failUnlessEqual ( version_consistent , True ) <EOL> testActivation . skip = '<STR_LIT>' </s>
<s> from __future__ import absolute_import <EOL> from . classification import * <EOL> from . generic import * <EOL> from . job import ImageDatasetJob </s>
<s> from __future__ import absolute_import <EOL> from . images import * <EOL> from . job import InferenceJob </s>
<s> from __future__ import absolute_import <EOL> from . caffe_train import CaffeTrainTask <EOL> from . torch_train import TorchTrainTask <EOL> from . train import TrainTask </s>
<s> from __future__ import absolute_import <EOL> import flask <EOL> from flask . ext . socketio import SocketIO <EOL> from gevent import monkey ; monkey . patch_all ( ) <EOL> from . config import config_value <EOL> from digits import utils <EOL> import digits . scheduler <EOL> app = flask . Flask ( __name__ ) <EOL> app . config [ '<STR_LIT>' ] = True <EOL> app . config [ '<STR_LIT>' ] = False <EOL> app . config [ '<STR_LIT>' ] = config_value ( '<STR_LIT>' ) <EOL> app . url_map . redirect_defaults = False <EOL> socketio = SocketIO ( app ) <EOL> scheduler = digits . scheduler . Scheduler ( config_value ( '<STR_LIT>' ) , True ) <EOL> app . jinja_env . globals [ '<STR_LIT>' ] = config_value ( '<STR_LIT>' ) <EOL> app . jinja_env . globals [ '<STR_LIT>' ] = digits . __version__ <EOL> app . jinja_env . filters [ '<STR_LIT>' ] = utils . time_filters . print_time <EOL> app . jinja_env . filters [ '<STR_LIT>' ] = utils . time_filters . print_time_diff <EOL> app . jinja_env . filters [ '<STR_LIT>' ] = utils . time_filters . print_time_since <EOL> app . jinja_env . filters [ '<STR_LIT>' ] = utils . sizeof_fmt <EOL> app . jinja_env . filters [ '<STR_LIT>' ] = utils . auth . has_permission <EOL> app . jinja_env . trim_blocks = True <EOL> app . jinja_env . lstrip_blocks = True <EOL> import digits . views <EOL> app . register_blueprint ( digits . views . blueprint ) <EOL> import digits . dataset . views <EOL> app . register_blueprint ( digits . dataset . views . blueprint , url_prefix = '<STR_LIT>' ) <EOL> import digits . dataset . images . views <EOL> app . register_blueprint ( digits . dataset . images . views . blueprint , url_prefix = '<STR_LIT>' ) <EOL> import digits . dataset . images . classification . views <EOL> app . register_blueprint ( digits . dataset . images . classification . views . blueprint , url_prefix = '<STR_LIT>' ) <EOL> import digits . dataset . images . generic . views <EOL> app . register_blueprint ( digits . dataset . images . generic . views . blueprint , url_prefix = '<STR_LIT>' ) <EOL> import digits . model . views <EOL> app . register_blueprint ( digits . model . views . blueprint , url_prefix = '<STR_LIT>' ) <EOL> import digits . model . images . views <EOL> app . register_blueprint ( digits . model . images . views . blueprint , url_prefix = '<STR_LIT>' ) <EOL> import digits . model . images . classification . views <EOL> app . register_blueprint ( digits . model . images . classification . views . blueprint , url_prefix = '<STR_LIT>' ) <EOL> import digits . model . images . generic . views <EOL> app . register_blueprint ( digits . model . images . generic . views . blueprint , url_prefix = '<STR_LIT>' ) <EOL> def username_decorator ( f ) : <EOL> from functools import wraps <EOL> @ wraps ( f ) <EOL> def decorated ( * args , ** kwargs ) : <EOL> this_username = flask . request . cookies . get ( '<STR_LIT:username>' , None ) <EOL> app . jinja_env . globals [ '<STR_LIT:username>' ] = this_username <EOL> return f ( * args , ** kwargs ) <EOL> return decorated <EOL> for endpoint , function in app . view_functions . iteritems ( ) : <EOL> app . view_functions [ endpoint ] = username_decorator ( function ) <EOL> scheduler . load_past_jobs ( ) </s>
<s> import os <EOL> import unittest <EOL> import requests <EOL> import requests_cache <EOL> from nytcampfin import NytCampfin , NytCampfinError , NytNotFoundError <EOL> CURRENT_CYCLE = <NUM_LIT> <EOL> try : <EOL> API_KEY = os . environ [ '<STR_LIT>' ] <EOL> except : <EOL> print "<STR_LIT>" <EOL> class APITest ( unittest . TestCase ) : <EOL> def check_response ( self , result , url , parse = lambda r : r [ '<STR_LIT>' ] ) : <EOL> with requests_cache . disabled ( ) : <EOL> response = requests . get ( url ) <EOL> if parse and callable ( parse ) : <EOL> response = parse ( response . json ) <EOL> self . assertEqual ( result , response ) <EOL> def setUp ( self ) : <EOL> self . finance = NytCampfin ( API_KEY ) <EOL> class FilingTest ( APITest ) : <EOL> def test_todays_filings ( self ) : <EOL> today = self . finance . filings . today ( offset = <NUM_LIT:20> ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( today , url ) <EOL> def test_filings_for_date ( self ) : <EOL> july4th = self . finance . filings . date ( <NUM_LIT> , <NUM_LIT:0> <NUM_LIT:7> , <NUM_LIT:0> <NUM_LIT:4> ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( july4th , url ) <EOL> def test_form_types ( self ) : <EOL> form_types = self . finance . filings . form_types ( ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( form_types , url ) <EOL> def test_filings_by_form_type ( self ) : <EOL> f2s = self . finance . filings . by_type ( '<STR_LIT>' ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( f2s , url ) <EOL> def test_amended_filings ( self ) : <EOL> amendments = self . finance . filings . amendments ( ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( amendments , url ) <EOL> class IndependentExpenditureTest ( APITest ) : <EOL> def test_latest ( self ) : <EOL> latest = self . finance . indexp . latest ( ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( latest , url ) <EOL> def test_ies_for_date ( self ) : <EOL> july3rd = self . finance . indexp . date ( <NUM_LIT> , <NUM_LIT:0> <NUM_LIT:7> , <NUM_LIT:0> <NUM_LIT:3> ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( july3rd , url ) <EOL> def test_committee_ies ( self ) : <EOL> ies = self . finance . indexp . committee ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( ies , url ) <EOL> def test_race_totals ( self ) : <EOL> races = self . finance . indexp . race_totals ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( races , url ) <EOL> def test_candidate_ies ( self ) : <EOL> ies = self . finance . indexp . candidate ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( ies , url ) <EOL> def test_president_ies ( self ) : <EOL> ies = self . finance . indexp . president ( ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( ies , url ) <EOL> def test_superpacs ( self ) : <EOL> superpacs = self . finance . indexp . superpacs ( ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( superpacs , url ) <EOL> class CandidateTest ( APITest ) : <EOL> def test_latest ( self ) : <EOL> latest = self . finance . candidates . latest ( ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( latest , url ) <EOL> def test_detail ( self ) : <EOL> detail = self . finance . candidates . get ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> response = requests . get ( url ) <EOL> self . check_response ( detail , url , parse = lambda r : r [ '<STR_LIT>' ] [ <NUM_LIT:0> ] ) <EOL> def test_filter ( self ) : <EOL> wilson = self . finance . candidates . filter ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( wilson , url ) <EOL> def test_leaders ( self ) : <EOL> loans = self . finance . candidates . leaders ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( loans , url ) <EOL> def test_candidates_for_state ( self ) : <EOL> candidates = self . finance . candidates . seats ( '<STR_LIT>' ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( candidates , url ) <EOL> def test_candidates_for_state_and_chamber ( self ) : <EOL> candidates = self . finance . candidates . seats ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( candidates , url ) <EOL> def test_candidates_for_state_and_chamber_and_district ( self ) : <EOL> candidates = self . finance . candidates . seats ( '<STR_LIT>' , '<STR_LIT>' , <NUM_LIT:6> ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( candidates , url ) <EOL> def test_late_contributions ( self ) : <EOL> late_contribs = self . finance . candidates . late_contributions ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( late_contribs , url ) <EOL> class CommitteeTest ( APITest ) : <EOL> def test_latest ( self ) : <EOL> latest = self . finance . committees . latest ( ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( latest , url ) <EOL> def test_detail ( self ) : <EOL> detail = self . finance . committees . get ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> response = requests . get ( url ) <EOL> self . check_response ( detail , url , parse = lambda r : r [ '<STR_LIT>' ] [ <NUM_LIT:0> ] ) <EOL> def test_filter ( self ) : <EOL> hallmark = self . finance . committees . filter ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( hallmark , url ) <EOL> def test_contributions ( self ) : <EOL> contributions = self . finance . committees . contributions ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( contributions , url ) <EOL> def test_contributions_to_candidate ( self ) : <EOL> contributions = self . finance . committees . contributions_to_candidate ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( contributions , url ) <EOL> def test_late_contributions ( self ) : <EOL> late_contribs = self . finance . committees . late_contributions ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( late_contribs , url ) <EOL> def test_filings ( self ) : <EOL> filings = self . finance . committees . filings ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( filings , url ) <EOL> def test_ie_totals ( self ) : <EOL> ie_totals = self . finance . committees . ie_totals ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( ie_totals , url ) <EOL> def test_leadership ( self ) : <EOL> leadership = self . finance . committees . leadership ( ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( leadership , url ) <EOL> class LateContributionTest ( APITest ) : <EOL> def test_latest ( self ) : <EOL> late_contribs = self . finance . late_contribs . latest ( ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( late_contribs , url ) <EOL> def test_date ( self ) : <EOL> late_contribs = self . finance . late_contribs . date ( <NUM_LIT> , <NUM_LIT:3> , <NUM_LIT> ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( late_contribs , url ) <EOL> class PresidentTest ( APITest ) : <EOL> def test_candidates ( self ) : <EOL> candidates = self . finance . president . candidates ( ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( candidates , url ) <EOL> def test_detail_using_id ( self ) : <EOL> candidate = self . finance . president . detail ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( candidate , url , parse = lambda r : r [ '<STR_LIT>' ] [ <NUM_LIT:0> ] ) <EOL> def test_detail_using_name ( self ) : <EOL> candidate = self . finance . president . detail ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( candidate , url , parse = lambda r : r [ '<STR_LIT>' ] [ <NUM_LIT:0> ] ) <EOL> def test_state_total ( self ) : <EOL> state = self . finance . president . state ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( state , url ) <EOL> def test_zip_total ( self ) : <EOL> zipcode = self . finance . president . zipcode ( "<STR_LIT>" ) <EOL> url = "<STR_LIT>" % API_KEY <EOL> self . check_response ( zipcode , url ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> from O365 . attachment import Attachment <EOL> from O365 . contact import Contact <EOL> from O365 . group import Group <EOL> import logging <EOL> import json <EOL> import requests <EOL> logging . basicConfig ( filename = '<STR_LIT>' , level = logging . DEBUG ) <EOL> log = logging . getLogger ( __name__ ) <EOL> class Message ( object ) : <EOL> '''<STR_LIT>''' <EOL> att_url = '<STR_LIT>' <EOL> send_url = '<STR_LIT>' <EOL> draft_url = '<STR_LIT>' <EOL> update_url = '<STR_LIT>' <EOL> def __init__ ( self , json = None , auth = None ) : <EOL> '''<STR_LIT>''' <EOL> if json : <EOL> self . json = json <EOL> self . hasAttachments = json [ '<STR_LIT>' ] <EOL> else : <EOL> self . json = { '<STR_LIT>' : { '<STR_LIT>' : { } } , '<STR_LIT>' : { } } <EOL> self . hasAttachments = False <EOL> self . auth = auth <EOL> self . attachments = [ ] <EOL> self . reciever = None <EOL> def fetchAttachments ( self ) : <EOL> '''<STR_LIT>''' <EOL> if not self . hasAttachments : <EOL> log . debug ( '<STR_LIT>' ) <EOL> return False <EOL> response = requests . get ( self . att_url . format ( self . json [ '<STR_LIT>' ] ) , auth = self . auth ) <EOL> log . info ( '<STR_LIT>' , str ( response ) ) <EOL> json = response . json ( ) <EOL> for att in json [ '<STR_LIT:value>' ] : <EOL> try : <EOL> self . attachments . append ( Attachment ( att ) ) <EOL> log . debug ( '<STR_LIT>' , self . auth [ <NUM_LIT:0> ] ) <EOL> except Exception as e : <EOL> log . info ( '<STR_LIT>' , self . auth [ <NUM_LIT:0> ] ) <EOL> return len ( self . attachments ) <EOL> def sendMessage ( self ) : <EOL> '''<STR_LIT>''' <EOL> headers = { '<STR_LIT>' : '<STR_LIT:application/json>' , '<STR_LIT>' : '<STR_LIT>' } <EOL> try : <EOL> data = { '<STR_LIT>' : { '<STR_LIT>' : { } } } <EOL> data [ '<STR_LIT>' ] [ '<STR_LIT>' ] = self . json [ '<STR_LIT>' ] <EOL> data [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] = self . json [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> data [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] = self . json [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> data [ '<STR_LIT>' ] [ '<STR_LIT>' ] = self . json [ '<STR_LIT>' ] <EOL> data [ '<STR_LIT>' ] [ '<STR_LIT>' ] = [ att . json for att in self . attachments ] <EOL> data [ '<STR_LIT>' ] = "<STR_LIT:false>" <EOL> data = json . dumps ( data ) <EOL> log . debug ( str ( data ) ) <EOL> except Exception as e : <EOL> log . error ( str ( e ) ) <EOL> return False <EOL> response = requests . post ( self . send_url , data , headers = headers , auth = self . auth ) <EOL> log . debug ( '<STR_LIT>' + str ( response ) ) <EOL> if response . status_code != <NUM_LIT> : <EOL> return False <EOL> return True <EOL> def markAsRead ( self ) : <EOL> '''<STR_LIT>''' <EOL> read = '<STR_LIT>' <EOL> headers = { '<STR_LIT>' : '<STR_LIT:application/json>' , '<STR_LIT>' : '<STR_LIT:application/json>' } <EOL> try : <EOL> response = requests . patch ( self . update_url . format ( self . json [ '<STR_LIT>' ] ) , read , headers = headers , auth = self . auth ) <EOL> except : <EOL> return False <EOL> return True <EOL> def getSender ( self ) : <EOL> '''<STR_LIT>''' <EOL> return self . json [ '<STR_LIT>' ] <EOL> def getSenderEmail ( self ) : <EOL> '''<STR_LIT>''' <EOL> return self . json [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> def getSenderName ( self ) : <EOL> '''<STR_LIT>''' <EOL> try : <EOL> return self . json [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT:Name>' ] <EOL> except : <EOL> return '<STR_LIT>' <EOL> def getSubject ( self ) : <EOL> '''<STR_LIT>''' <EOL> return self . json [ '<STR_LIT>' ] <EOL> def getBody ( self ) : <EOL> '''<STR_LIT>''' <EOL> return self . json [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> def setRecipients ( self , val ) : <EOL> '''<STR_LIT>''' <EOL> self . json [ '<STR_LIT>' ] = [ ] <EOL> if isinstance ( val , list ) : <EOL> for con in val : <EOL> if isinstance ( con , Contact ) : <EOL> self . addRecipient ( con ) <EOL> elif isinstance ( con , str ) : <EOL> if '<STR_LIT:@>' in con : <EOL> self . addRecipient ( con ) <EOL> elif isinstance ( con , dict ) : <EOL> self . json [ '<STR_LIT>' ] . append ( con ) <EOL> elif isinstance ( val , dict ) : <EOL> self . json [ '<STR_LIT>' ] = [ val ] <EOL> elif isinstance ( val , str ) : <EOL> if '<STR_LIT:@>' in val : <EOL> self . addRecipient ( val ) <EOL> elif isinstance ( val , Contact ) : <EOL> self . addRecipient ( val ) <EOL> elif isinstance ( val , Group ) : <EOL> for person in val : <EOL> self . addRecipient ( person ) <EOL> else : <EOL> return False <EOL> return True <EOL> def addRecipient ( self , address , name = None ) : <EOL> '''<STR_LIT>''' <EOL> if isinstance ( address , Contact ) : <EOL> self . json [ '<STR_LIT>' ] . append ( address . getFirstEmailAddress ( ) ) <EOL> elif isinstance ( address , Group ) : <EOL> for con in address . contacts : <EOL> self . json [ '<STR_LIT>' ] . append ( address . getFirstEmailAddress ( ) ) <EOL> else : <EOL> if name is None : <EOL> name = address [ : address . index ( '<STR_LIT:@>' ) ] <EOL> self . json [ '<STR_LIT>' ] . append ( { '<STR_LIT>' : { '<STR_LIT>' : address , '<STR_LIT:Name>' : name } } ) <EOL> def setSubject ( self , val ) : <EOL> '''<STR_LIT>''' <EOL> self . json [ '<STR_LIT>' ] = val <EOL> def setBody ( self , val ) : <EOL> '''<STR_LIT>''' <EOL> cont = False <EOL> while not cont : <EOL> try : <EOL> self . json [ '<STR_LIT>' ] [ '<STR_LIT>' ] = val <EOL> self . json [ '<STR_LIT>' ] [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> cont = True <EOL> except : <EOL> self . json [ '<STR_LIT>' ] = { } <EOL> def setBodyHTML ( self , val = None ) : <EOL> '''<STR_LIT>''' <EOL> self . json [ '<STR_LIT>' ] [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> if val : <EOL> self . json [ '<STR_LIT>' ] [ '<STR_LIT>' ] = val </s>
<s> from . main import Dora </s>
<s> """<STR_LIT>""" <EOL> import eventlet <EOL> from eventlet import wsgi <EOL> from eventlet . green import time <EOL> from urlparse import parse_qs <EOL> from random import random , choice <EOL> datas = [ '<STR_LIT:hello>' , '<STR_LIT>' ] <EOL> comparators = [ '<STR_LIT:<>' , '<STR_LIT:=>' , '<STR_LIT:>>' , '<STR_LIT:false>' ] <EOL> def parse_response ( env , start_response ) : <EOL> '''<STR_LIT>''' <EOL> delay = random ( ) <EOL> time . sleep ( delay / <NUM_LIT:10> ) <EOL> try : <EOL> params = parse_qs ( env [ '<STR_LIT>' ] ) <EOL> row_index = int ( params [ '<STR_LIT>' ] [ <NUM_LIT:0> ] ) <EOL> char_index = int ( params [ '<STR_LIT>' ] [ <NUM_LIT:0> ] ) - <NUM_LIT:1> <EOL> test_char = int ( params [ '<STR_LIT>' ] [ <NUM_LIT:0> ] ) <EOL> comparator = comparators . index ( params [ '<STR_LIT>' ] [ <NUM_LIT:0> ] ) - <NUM_LIT:1> <EOL> try : <EOL> sleep_int = float ( params [ '<STR_LIT>' ] . pop ( <NUM_LIT:0> ) ) <EOL> except KeyError : <EOL> sleep_int = <NUM_LIT:1> <EOL> current_character = datas [ row_index ] [ char_index ] <EOL> truth = ( cmp ( ord ( current_character ) , test_char ) == comparator ) <EOL> response = types [ env [ '<STR_LIT>' ] ] ( test_char , current_character , comparator , sleep_int , start_response , truth ) <EOL> return response <EOL> except : <EOL> start_response ( '<STR_LIT>' , [ ( '<STR_LIT:Content-Type>' , '<STR_LIT>' ) ] ) <EOL> return [ '<STR_LIT>' ] <EOL> def time_based_blind ( test_char , current_character , comparator , sleep_int , start_response , truth ) : <EOL> sleep_time = sleep_int * truth <EOL> time . sleep ( sleep_time ) <EOL> start_response ( '<STR_LIT>' , [ ( '<STR_LIT:Content-Type>' , '<STR_LIT>' ) ] ) <EOL> return [ '<STR_LIT>' ] <EOL> def boolean_based_error ( test_char , current_character , comparator , env , start_response , truth ) : <EOL> if truth : <EOL> start_response ( '<STR_LIT>' , [ ( '<STR_LIT:Content-Type>' , '<STR_LIT>' ) ] ) <EOL> return [ '<STR_LIT>' ] <EOL> else : <EOL> start_response ( '<STR_LIT>' , [ ( '<STR_LIT:Content-Type>' , '<STR_LIT>' ) ] ) <EOL> return [ '<STR_LIT>' ] <EOL> def boolean_based_size ( test_char , current_character , comparator , env , start_response , truth ) : <EOL> if truth : <EOL> start_response ( '<STR_LIT>' , [ ( '<STR_LIT:Content-Type>' , '<STR_LIT>' ) ] ) <EOL> return [ '<STR_LIT>' ] <EOL> else : <EOL> start_response ( '<STR_LIT>' , [ ( '<STR_LIT:Content-Type>' , '<STR_LIT>' ) ] ) <EOL> return [ '<STR_LIT>' ] <EOL> types = { '<STR_LIT>' : time_based_blind , '<STR_LIT>' : boolean_based_error , '<STR_LIT>' : boolean_based_size } <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> print "<STR_LIT:\n>" <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT>" <EOL> print "<STR_LIT:\n>" <EOL> from sys import argv <EOL> import re <EOL> CHARSET = [ chr ( x ) for x in xrange ( <NUM_LIT:32> , <NUM_LIT> ) ] <EOL> rre = re . compile ( u'<STR_LIT>' ) <EOL> cre = re . compile ( u'<STR_LIT>' ) <EOL> rows = filter ( rre . match , argv ) <EOL> cols = filter ( cre . match , argv ) <EOL> if rows and cols : <EOL> rows = rows [ <NUM_LIT:0> ] <EOL> cols = cols [ <NUM_LIT:0> ] <EOL> CHARSET = [ chr ( x ) for x in xrange ( <NUM_LIT:32> , <NUM_LIT> ) ] <EOL> datas = [ ] <EOL> for asdf in range ( <NUM_LIT:5> ) : <EOL> datas . append ( "<STR_LIT>" ) <EOL> for fdsa in range ( <NUM_LIT:100> ) : <EOL> datas [ - <NUM_LIT:1> ] += choice ( CHARSET ) <EOL> wsgi . server ( eventlet . listen ( ( '<STR_LIT>' , <NUM_LIT> ) ) , parse_response ) </s>
<s> """<STR_LIT>""" <EOL> import xml . etree . ElementTree as ET <EOL> import os <EOL> import cPickle <EOL> import numpy as np <EOL> def parse_rec ( filename ) : <EOL> """<STR_LIT>""" <EOL> tree = ET . parse ( filename ) <EOL> objects = [ ] <EOL> for obj in tree . findall ( '<STR_LIT:object>' ) : <EOL> obj_struct = { } <EOL> obj_struct [ '<STR_LIT:name>' ] = obj . find ( '<STR_LIT:name>' ) . text <EOL> obj_struct [ '<STR_LIT>' ] = obj . find ( '<STR_LIT>' ) . text <EOL> obj_struct [ '<STR_LIT>' ] = int ( obj . find ( '<STR_LIT>' ) . text ) <EOL> obj_struct [ '<STR_LIT>' ] = int ( obj . find ( '<STR_LIT>' ) . text ) <EOL> bbox = obj . find ( '<STR_LIT>' ) <EOL> obj_struct [ '<STR_LIT>' ] = [ int ( bbox . find ( '<STR_LIT>' ) . text ) , <EOL> int ( bbox . find ( '<STR_LIT>' ) . text ) , <EOL> int ( bbox . find ( '<STR_LIT>' ) . text ) , <EOL> int ( bbox . find ( '<STR_LIT>' ) . text ) ] <EOL> objects . append ( obj_struct ) <EOL> return objects <EOL> def voc_ap ( rec , prec , use_07_metric = False ) : <EOL> """<STR_LIT>""" <EOL> if use_07_metric : <EOL> ap = <NUM_LIT:0.> <EOL> for t in np . arange ( <NUM_LIT:0.> , <NUM_LIT> , <NUM_LIT:0.1> ) : <EOL> if np . sum ( rec >= t ) == <NUM_LIT:0> : <EOL> p = <NUM_LIT:0> <EOL> else : <EOL> p = np . max ( prec [ rec >= t ] ) <EOL> ap = ap + p / <NUM_LIT> <EOL> else : <EOL> mrec = np . concatenate ( ( [ <NUM_LIT:0.> ] , rec , [ <NUM_LIT:1.> ] ) ) <EOL> mpre = np . concatenate ( ( [ <NUM_LIT:0.> ] , prec , [ <NUM_LIT:0.> ] ) ) <EOL> for i in range ( mpre . size - <NUM_LIT:1> , <NUM_LIT:0> , - <NUM_LIT:1> ) : <EOL> mpre [ i - <NUM_LIT:1> ] = np . maximum ( mpre [ i - <NUM_LIT:1> ] , mpre [ i ] ) <EOL> i = np . where ( mrec [ <NUM_LIT:1> : ] != mrec [ : - <NUM_LIT:1> ] ) [ <NUM_LIT:0> ] <EOL> ap = np . sum ( ( mrec [ i + <NUM_LIT:1> ] - mrec [ i ] ) * mpre [ i + <NUM_LIT:1> ] ) <EOL> return ap <EOL> def voc_eval ( detpath , <EOL> annopath , <EOL> imagesetfile , <EOL> classname , <EOL> cachedir , <EOL> ovthresh = <NUM_LIT:0.5> , <EOL> use_07_metric = False ) : <EOL> """<STR_LIT>""" <EOL> if not os . path . isdir ( cachedir ) : <EOL> os . mkdir ( cachedir ) <EOL> cachefile = os . path . join ( cachedir , '<STR_LIT>' ) <EOL> with open ( imagesetfile , '<STR_LIT:r>' ) as f : <EOL> lines = f . readlines ( ) <EOL> imagenames = [ x . strip ( ) for x in lines ] <EOL> if not os . path . isfile ( cachefile ) : <EOL> recs = { } <EOL> for i , imagename in enumerate ( imagenames ) : <EOL> recs [ imagename ] = parse_rec ( annopath . format ( imagename ) ) <EOL> if i % <NUM_LIT:100> == <NUM_LIT:0> : <EOL> print '<STR_LIT>' . format ( <EOL> i + <NUM_LIT:1> , len ( imagenames ) ) <EOL> print '<STR_LIT>' . format ( cachefile ) <EOL> with open ( cachefile , '<STR_LIT:w>' ) as f : <EOL> cPickle . dump ( recs , f ) <EOL> else : <EOL> with open ( cachefile , '<STR_LIT:r>' ) as f : <EOL> recs = cPickle . load ( f ) <EOL> class_recs = { } <EOL> npos = <NUM_LIT:0> <EOL> for imagename in imagenames : <EOL> R = [ obj for obj in recs [ imagename ] if obj [ '<STR_LIT:name>' ] == classname ] <EOL> bbox = np . array ( [ x [ '<STR_LIT>' ] for x in R ] ) <EOL> difficult = np . array ( [ x [ '<STR_LIT>' ] for x in R ] ) . astype ( np . bool ) <EOL> det = [ False ] * len ( R ) <EOL> npos = npos + sum ( ~ difficult ) <EOL> class_recs [ imagename ] = { '<STR_LIT>' : bbox , <EOL> '<STR_LIT>' : difficult , <EOL> '<STR_LIT>' : det } <EOL> detfile = detpath . format ( classname ) <EOL> with open ( detfile , '<STR_LIT:r>' ) as f : <EOL> lines = f . readlines ( ) <EOL> splitlines = [ x . strip ( ) . split ( '<STR_LIT:U+0020>' ) for x in lines ] <EOL> image_ids = [ x [ <NUM_LIT:0> ] for x in splitlines ] <EOL> confidence = np . array ( [ float ( x [ <NUM_LIT:1> ] ) for x in splitlines ] ) <EOL> BB = np . array ( [ [ float ( z ) for z in x [ <NUM_LIT:2> : ] ] for x in splitlines ] ) <EOL> sorted_ind = np . argsort ( - confidence ) <EOL> BB = BB [ sorted_ind , : ] <EOL> image_ids = [ image_ids [ x ] for x in sorted_ind ] <EOL> nd = len ( image_ids ) <EOL> tp = np . zeros ( nd ) <EOL> fp = np . zeros ( nd ) <EOL> for d in range ( nd ) : <EOL> R = class_recs [ image_ids [ d ] ] <EOL> bb = BB [ d , : ] . astype ( float ) <EOL> ovmax = - np . inf <EOL> BBGT = R [ '<STR_LIT>' ] . astype ( float ) <EOL> if BBGT . size > <NUM_LIT:0> : <EOL> ixmin = np . maximum ( BBGT [ : , <NUM_LIT:0> ] , bb [ <NUM_LIT:0> ] ) <EOL> iymin = np . maximum ( BBGT [ : , <NUM_LIT:1> ] , bb [ <NUM_LIT:1> ] ) <EOL> ixmax = np . minimum ( BBGT [ : , <NUM_LIT:2> ] , bb [ <NUM_LIT:2> ] ) <EOL> iymax = np . minimum ( BBGT [ : , <NUM_LIT:3> ] , bb [ <NUM_LIT:3> ] ) <EOL> iw = np . maximum ( ixmax - ixmin + <NUM_LIT:1.> , <NUM_LIT:0.> ) <EOL> ih = np . maximum ( iymax - iymin + <NUM_LIT:1.> , <NUM_LIT:0.> ) <EOL> inters = iw * ih <EOL> uni = ( ( bb [ <NUM_LIT:2> ] - bb [ <NUM_LIT:0> ] + <NUM_LIT:1.> ) * ( bb [ <NUM_LIT:3> ] - bb [ <NUM_LIT:1> ] + <NUM_LIT:1.> ) + <EOL> ( BBGT [ : , <NUM_LIT:2> ] - BBGT [ : , <NUM_LIT:0> ] + <NUM_LIT:1.> ) * <EOL> ( BBGT [ : , <NUM_LIT:3> ] - BBGT [ : , <NUM_LIT:1> ] + <NUM_LIT:1.> ) - inters ) <EOL> overlaps = inters / uni <EOL> ovmax = np . max ( overlaps ) <EOL> jmax = np . argmax ( overlaps ) <EOL> if ovmax > ovthresh : <EOL> if not R [ '<STR_LIT>' ] [ jmax ] : <EOL> if not R [ '<STR_LIT>' ] [ jmax ] : <EOL> tp [ d ] = <NUM_LIT:1.> <EOL> R [ '<STR_LIT>' ] [ jmax ] = <NUM_LIT:1> <EOL> else : <EOL> fp [ d ] = <NUM_LIT:1.> <EOL> else : <EOL> fp [ d ] = <NUM_LIT:1.> <EOL> fp = np . cumsum ( fp ) <EOL> tp = np . cumsum ( tp ) <EOL> rec = tp / float ( npos ) <EOL> prec = tp / ( tp + fp + <NUM_LIT> ) <EOL> ap = voc_ap ( rec , prec , use_07_metric ) <EOL> return rec , prec , ap </s>
<s> </s>
<s> import numpy as np <EOL> from ipdb import set_trace <EOL> from struct import pack , unpack <EOL> def ceil_div ( x , y ) : <EOL> return - ( - x // y ) <EOL> def out_dim ( S , X , padding , strides ) : <EOL> return ceil_div ( X - S + <NUM_LIT:1> + <NUM_LIT:2> * padding , strides ) <EOL> def strip_mantissa ( val ) : <EOL> i = unpack ( '<STR_LIT:I>' , pack ( '<STR_LIT:f>' , val ) ) [ <NUM_LIT:0> ] & <NUM_LIT> <EOL> f = unpack ( '<STR_LIT:f>' , pack ( '<STR_LIT:I>' , i ) ) [ <NUM_LIT:0> ] <EOL> return f <EOL> def quantize ( ary , bits , sign = <NUM_LIT:1> ) : <EOL> maxval = float ( np . max ( np . absolute ( ary ) ) ) <EOL> scale = strip_mantissa ( maxval ) / float ( <NUM_LIT:1> << ( bits - sign - <NUM_LIT:1> ) ) <EOL> ary = np . around ( ary * ( <NUM_LIT:1.0> / scale ) ) . astype ( np . int64 ) <EOL> return ary , np . float64 ( scale ) <EOL> def fconv_slice ( q , S , X , padding , strides ) : <EOL> f1 = <NUM_LIT:0> <EOL> f2 = S - <NUM_LIT:1> <EOL> x1 = q * strides - padding <EOL> x2 = x1 + f2 <EOL> if x1 < <NUM_LIT:0> : <EOL> f1 = - x1 <EOL> x1 = <NUM_LIT:0> <EOL> if x2 >= X : <EOL> dif = x2 - X + <NUM_LIT:1> <EOL> f2 -= dif <EOL> x2 -= dif <EOL> return ( slice ( f1 , f2 + <NUM_LIT:1> ) , slice ( x1 , x2 + <NUM_LIT:1> ) , f2 - f1 + <NUM_LIT:1> ) <EOL> def bconv_slice ( x , S , Q , padding , strides ) : <EOL> qs = x - ( S - padding - <NUM_LIT:1> ) <EOL> firstF = None <EOL> for s in range ( S ) : <EOL> q = qs + s <EOL> if q % strides == <NUM_LIT:0> : <EOL> q //= strides <EOL> if q >= <NUM_LIT:0> and q < Q : <EOL> if firstF is None : <EOL> firstF = s <EOL> firstE = q <EOL> lastF = s <EOL> lastE = q <EOL> return ( slice ( firstF , lastF + <NUM_LIT:1> , strides ) , slice ( firstE , lastE + <NUM_LIT:1> , strides ) , <NUM_LIT:0> ) <EOL> def xprop_direct ( I , F , O , padding , strides , backward = False ) : <EOL> if all ( x == <NUM_LIT:1> for x in F . shape [ <NUM_LIT:1> : <NUM_LIT:3> ] ) : <EOL> C = F . shape [ <NUM_LIT:0> ] <EOL> K = F . shape [ <NUM_LIT:4> ] <EOL> if backward : <EOL> O [ : ] = np . dot ( F . reshape ( ( C , - <NUM_LIT:1> ) ) , I . reshape ( ( K , - <NUM_LIT:1> ) ) ) . reshape ( ( O . shape ) ) <EOL> else : <EOL> O [ : ] = np . dot ( F . reshape ( ( C , - <NUM_LIT:1> ) ) . T , I . reshape ( ( C , - <NUM_LIT:1> ) ) ) . reshape ( ( O . shape ) ) <EOL> return <EOL> if backward : <EOL> F = np . transpose ( F [ : , : : - <NUM_LIT:1> , : : - <NUM_LIT:1> , : ] , ( <NUM_LIT:3> , <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:0> ) ) . copy ( ) <EOL> xconv_slice = bconv_slice <EOL> else : <EOL> xconv_slice = fconv_slice <EOL> C , Y , X , N = I . shape <EOL> C , R , S , K = F . shape <EOL> K , P , Q , N = O . shape <EOL> qSlice = [ xconv_slice ( q , S , X , padding [ <NUM_LIT:0> ] , strides [ <NUM_LIT:0> ] ) for q in range ( Q ) ] <EOL> for p in range ( P ) : <EOL> sliceR , sliceY , _ = xconv_slice ( p , R , Y , padding [ <NUM_LIT:1> ] , strides [ <NUM_LIT:1> ] ) <EOL> for q in range ( Q ) : <EOL> sliceS , sliceX , _ = qSlice [ q ] <EOL> slicedF = F [ : , sliceR , sliceS , : ] . reshape ( ( - <NUM_LIT:1> , K ) ) <EOL> slicedI = I [ : , sliceY , sliceX , : ] . reshape ( ( - <NUM_LIT:1> , N ) ) <EOL> O [ : , p , q , : ] = np . dot ( slicedF . T , slicedI ) <EOL> def updat_direct ( I , E , U , padding , strides ) : <EOL> C , Y , X , N = I . shape <EOL> K , P , Q , N = E . shape <EOL> C , R , S , K = U . shape <EOL> if all ( x == <NUM_LIT:1> for x in ( R , S ) ) : <EOL> U [ : ] = np . dot ( I . reshape ( ( C , - <NUM_LIT:1> ) ) , E . reshape ( ( K , - <NUM_LIT:1> ) ) . T ) . reshape ( ( U . shape ) ) <EOL> return <EOL> U . fill ( <NUM_LIT:0.0> ) <EOL> qSlice = [ fconv_slice ( q , S , X , padding [ <NUM_LIT:0> ] , strides [ <NUM_LIT:0> ] ) for q in range ( Q ) ] <EOL> for p in range ( P ) : <EOL> sliceR , sliceY , rlen = fconv_slice ( p , R , Y , padding [ <NUM_LIT:1> ] , strides [ <NUM_LIT:1> ] ) <EOL> for q in range ( Q ) : <EOL> sliceS , sliceX , slen = qSlice [ q ] <EOL> slicedI = I [ : , sliceY , sliceX , : ] . reshape ( ( - <NUM_LIT:1> , N ) ) <EOL> slicedE = E [ : , p , q , : ] <EOL> U [ : , sliceR , sliceS , : ] += np . dot ( slicedI , slicedE . T ) . reshape ( ( C , rlen , slen , K ) ) <EOL> I_4x4_3x3 = ( <EOL> np . array ( [ <EOL> [ <NUM_LIT> , <NUM_LIT:0.0> , - <NUM_LIT> , <NUM_LIT:0.0> , <NUM_LIT:1.0> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , - <NUM_LIT> , - <NUM_LIT> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT> , - <NUM_LIT> , - <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , - <NUM_LIT> , - <NUM_LIT:1.0> , <NUM_LIT> , <NUM_LIT:1.0> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT> , - <NUM_LIT:1.0> , - <NUM_LIT> , <NUM_LIT:1.0> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT> , <NUM_LIT:0.0> , - <NUM_LIT> , <NUM_LIT:0.0> , <NUM_LIT:1.0> ] ] ) , <EOL> np . array ( [ <EOL> [ <NUM_LIT> , <NUM_LIT:0.0> , - <NUM_LIT> , <NUM_LIT:0.0> , <NUM_LIT:1.0> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , - <NUM_LIT> , - <NUM_LIT> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT> , - <NUM_LIT> , - <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , - <NUM_LIT> , - <NUM_LIT:1.0> , <NUM_LIT> , <NUM_LIT:1.0> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT> , - <NUM_LIT:1.0> , - <NUM_LIT> , <NUM_LIT:1.0> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT> , <NUM_LIT:0.0> , - <NUM_LIT> , <NUM_LIT:0.0> , <NUM_LIT:1.0> ] ] ) , <EOL> np . array ( [ <EOL> [ <NUM_LIT:1.0> , <NUM_LIT:0.0> , - <NUM_LIT> / <NUM_LIT> , <NUM_LIT:0.0> , <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT> / <NUM_LIT> , <NUM_LIT> / <NUM_LIT> , - <NUM_LIT:1.0> / <NUM_LIT> , - <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , - <NUM_LIT> / <NUM_LIT> , <NUM_LIT> / <NUM_LIT> , <NUM_LIT:1.0> / <NUM_LIT> , - <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , - <NUM_LIT:1.0> / <NUM_LIT> , - <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT:1.0> / <NUM_LIT> , - <NUM_LIT:1.0> / <NUM_LIT> , - <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT> , <NUM_LIT:0.0> , - <NUM_LIT> , <NUM_LIT:0.0> , <NUM_LIT:1.0> ] ] ) , <EOL> ) <EOL> F_4x4_3x3 = ( <EOL> np . array ( [ <EOL> [ <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:0.0> , <NUM_LIT:0.0> ] , <EOL> [ - <NUM_LIT:1.0> / <NUM_LIT> , - <NUM_LIT:1.0> / <NUM_LIT> , - <NUM_LIT:1.0> / <NUM_LIT> ] , <EOL> [ - <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:1.0> / <NUM_LIT> , - <NUM_LIT:1.0> / <NUM_LIT> ] , <EOL> [ <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:1.0> / <NUM_LIT> ] , <EOL> [ <NUM_LIT:1.0> / <NUM_LIT> , - <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:1.0> / <NUM_LIT> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT:0.0> , <NUM_LIT:1.0> ] ] ) , <EOL> np . array ( [ <EOL> [ <NUM_LIT:1.0> , <NUM_LIT:0.0> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> ] , <EOL> [ <NUM_LIT:1.0> , - <NUM_LIT:1.0> , <NUM_LIT:1.0> ] , <EOL> [ <NUM_LIT:1.0> , <NUM_LIT> , <NUM_LIT> ] , <EOL> [ <NUM_LIT:1.0> , - <NUM_LIT> , <NUM_LIT> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT:0.0> , <NUM_LIT:1.0> ] ] ) , <EOL> np . array ( [ <EOL> [ <NUM_LIT:1.0> , <NUM_LIT:0.0> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> ] , <EOL> [ <NUM_LIT:1.0> , - <NUM_LIT:1.0> , <NUM_LIT:1.0> ] , <EOL> [ <NUM_LIT:1.0> , <NUM_LIT> , <NUM_LIT> ] , <EOL> [ <NUM_LIT:1.0> , - <NUM_LIT> , <NUM_LIT> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT:0.0> , <NUM_LIT:1.0> ] ] ) , <EOL> ) <EOL> O_4x4_3x3 = ( <EOL> np . array ( [ <EOL> [ <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT:1.0> , - <NUM_LIT:1.0> , <NUM_LIT> , - <NUM_LIT> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT:1.0> , - <NUM_LIT:1.0> , <NUM_LIT> , - <NUM_LIT> , <NUM_LIT:1.0> ] ] ) , <EOL> np . array ( [ <EOL> [ <NUM_LIT:1.0> / <NUM_LIT> , - <NUM_LIT:1.0> / <NUM_LIT> , - <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , - <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:1.0> / <NUM_LIT> , - <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , - <NUM_LIT:1.0> / <NUM_LIT> , - <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , - <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:1.0> / <NUM_LIT> , - <NUM_LIT:1.0> / <NUM_LIT> , <NUM_LIT:1.0> ] ] ) , <EOL> np . array ( [ <EOL> [ <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT:1.0> , - <NUM_LIT:1.0> , <NUM_LIT> , - <NUM_LIT> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT:1.0> , <NUM_LIT:1.0> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT:0.0> ] , <EOL> [ <NUM_LIT:0.0> , <NUM_LIT:1.0> , - <NUM_LIT:1.0> , <NUM_LIT> , - <NUM_LIT> , <NUM_LIT:1.0> ] ] ) , <EOL> ) <EOL> rcp3 = <NUM_LIT:1.0> / <NUM_LIT> <EOL> rcp4 = <NUM_LIT:1.0> / <NUM_LIT> <EOL> rcp6 = <NUM_LIT:1.0> / <NUM_LIT> <EOL> rcp12 = <NUM_LIT:1.0> / <NUM_LIT> <EOL> rcp24 = <NUM_LIT:1.0> / <NUM_LIT> <EOL> def trans_I_4x4_3x3 ( Iw , I , minimal = False , trans = False ) : <EOL> if minimal : <EOL> T0 = np . empty ( ( <NUM_LIT:6> , <NUM_LIT:6> ) ) <EOL> T1 = np . empty ( ( <NUM_LIT:6> , <NUM_LIT:6> ) ) <EOL> for O , I in ( ( T0 , I ) , ( T1 , T0 . T ) ) : <EOL> t0 = ( I [ <NUM_LIT:2> , : ] * <NUM_LIT> - I [ <NUM_LIT:4> , : ] ) * rcp6 <EOL> t1 = ( I [ <NUM_LIT:1> , : ] * <NUM_LIT> - I [ <NUM_LIT:3> , : ] ) * rcp6 <EOL> t2 = ( I [ <NUM_LIT:4> , : ] - I [ <NUM_LIT:2> , : ] ) * rcp24 <EOL> t3 = ( I [ <NUM_LIT:3> , : ] - I [ <NUM_LIT:1> , : ] ) * rcp12 <EOL> O [ <NUM_LIT:0> , : ] = I [ <NUM_LIT:0> , : ] + ( I [ <NUM_LIT:2> , : ] * - <NUM_LIT> + I [ <NUM_LIT:4> , : ] ) * rcp4 <EOL> O [ <NUM_LIT:1> , : ] = t0 + t1 <EOL> O [ <NUM_LIT:2> , : ] = t0 - t1 <EOL> O [ <NUM_LIT:3> , : ] = t2 + t3 <EOL> O [ <NUM_LIT:4> , : ] = t2 - t3 <EOL> O [ <NUM_LIT:5> , : ] = I [ <NUM_LIT:1> , : ] * <NUM_LIT> - I [ <NUM_LIT:3> , : ] * <NUM_LIT> + I [ <NUM_LIT:5> , : ] <EOL> Iw [ : ] = T1 . T <EOL> else : <EOL> Iw [ : ] = np . dot ( np . dot ( I_4x4_3x3 [ trans [ <NUM_LIT:0> ] ] , I ) , I_4x4_3x3 [ trans [ <NUM_LIT:1> ] ] . T ) <EOL> def trans_F_4x4_3x3 ( Fw , F , minimal = False , trans = False ) : <EOL> if minimal : <EOL> T0 = np . empty ( ( <NUM_LIT:6> , <NUM_LIT:3> ) ) <EOL> T1 = np . empty ( ( <NUM_LIT:6> , <NUM_LIT:6> ) ) <EOL> for O , I in ( ( T0 , F ) , ( T1 , T0 . T ) ) : <EOL> t0 = I [ <NUM_LIT:0> , : ] + I [ <NUM_LIT:2> , : ] <EOL> t1 = I [ <NUM_LIT:0> , : ] + I [ <NUM_LIT:2> , : ] * <NUM_LIT> <EOL> O [ <NUM_LIT:0> , : ] = I [ <NUM_LIT:0> , : ] <EOL> O [ <NUM_LIT:1> , : ] = t0 + I [ <NUM_LIT:1> , : ] <EOL> O [ <NUM_LIT:2> , : ] = t0 - I [ <NUM_LIT:1> , : ] <EOL> O [ <NUM_LIT:3> , : ] = t1 + I [ <NUM_LIT:1> , : ] * <NUM_LIT> <EOL> O [ <NUM_LIT:4> , : ] = t1 - I [ <NUM_LIT:1> , : ] * <NUM_LIT> <EOL> O [ <NUM_LIT:5> , : ] = I [ <NUM_LIT:2> , : ] <EOL> Fw [ : ] = T1 . T <EOL> else : <EOL> Fw [ : ] = np . dot ( np . dot ( F_4x4_3x3 [ trans [ <NUM_LIT:0> ] ] , F ) , F_4x4_3x3 [ trans [ <NUM_LIT:1> ] ] . T ) <EOL> def trans_O_4x4_3x3 ( Mw , minimal = False , trans = False ) : <EOL> if minimal : <EOL> T0 = np . empty ( ( <NUM_LIT:4> , <NUM_LIT:6> ) ) <EOL> T1 = np . empty ( ( <NUM_LIT:4> , <NUM_LIT:4> ) ) <EOL> for O , I in ( ( T0 , Mw ) , ( T1 , T0 . T ) ) : <EOL> t0 = I [ <NUM_LIT:1> , : ] + I [ <NUM_LIT:2> , : ] <EOL> t1 = I [ <NUM_LIT:3> , : ] + I [ <NUM_LIT:4> , : ] <EOL> t2 = I [ <NUM_LIT:1> , : ] - I [ <NUM_LIT:2> , : ] <EOL> t3 = I [ <NUM_LIT:3> , : ] - I [ <NUM_LIT:4> , : ] <EOL> O [ <NUM_LIT:0> , : ] = t0 + t1 + I [ <NUM_LIT:0> , : ] <EOL> O [ <NUM_LIT:1> , : ] = t2 + t3 * <NUM_LIT> <EOL> O [ <NUM_LIT:2> , : ] = t0 + t1 * <NUM_LIT> <EOL> O [ <NUM_LIT:3> , : ] = t2 + t3 * <NUM_LIT> + I [ <NUM_LIT:5> , : ] <EOL> return T1 . T <EOL> else : <EOL> return np . dot ( np . dot ( O_4x4_3x3 [ trans [ <NUM_LIT:0> ] ] , Mw ) , O_4x4_3x3 [ trans [ <NUM_LIT:1> ] ] . T ) <EOL> def trans_F_3x3_4x4 ( Fw , F , minimal = False , trans = False ) : <EOL> if minimal : <EOL> T0 = np . empty ( ( <NUM_LIT:6> , <NUM_LIT:4> ) ) <EOL> T1 = np . empty ( ( <NUM_LIT:6> , <NUM_LIT:6> ) ) <EOL> for O , I in ( ( T0 , F ) , ( T1 , T0 . T ) ) : <EOL> t0 = I [ <NUM_LIT:0> , : ] + I [ <NUM_LIT:2> , : ] <EOL> t1 = I [ <NUM_LIT:0> , : ] + I [ <NUM_LIT:2> , : ] * <NUM_LIT> <EOL> t2 = I [ <NUM_LIT:1> , : ] + I [ <NUM_LIT:3> , : ] <EOL> t3 = I [ <NUM_LIT:1> , : ] + I [ <NUM_LIT:3> , : ] * <NUM_LIT> <EOL> O [ <NUM_LIT:0> , : ] = I [ <NUM_LIT:0> , : ] <EOL> O [ <NUM_LIT:1> , : ] = t0 + t2 <EOL> O [ <NUM_LIT:2> , : ] = t0 - t2 <EOL> O [ <NUM_LIT:3> , : ] = t1 + t3 * <NUM_LIT> <EOL> O [ <NUM_LIT:4> , : ] = t1 - t3 * <NUM_LIT> <EOL> O [ <NUM_LIT:5> , : ] = I [ <NUM_LIT:3> , : ] <EOL> Fw [ : ] = T1 . T <EOL> else : <EOL> Fw [ : ] = np . dot ( np . dot ( O_4x4_3x3 [ trans [ <NUM_LIT:0> ] ] . T , F ) , O_4x4_3x3 [ trans [ <NUM_LIT:1> ] ] ) <EOL> def trans_O_3x3_4x4 ( Mw , minimal = False , trans = False ) : <EOL> if minimal : <EOL> T0 = np . empty ( ( <NUM_LIT:3> , <NUM_LIT:6> ) ) <EOL> T1 = np . empty ( ( <NUM_LIT:3> , <NUM_LIT:3> ) ) <EOL> for O , I in ( ( T0 , Mw ) , ( T1 , T0 . T ) ) : <EOL> t0 = I [ <NUM_LIT:1> , : ] + I [ <NUM_LIT:2> , : ] <EOL> t1 = I [ <NUM_LIT:3> , : ] + I [ <NUM_LIT:4> , : ] <EOL> O [ <NUM_LIT:0> , : ] = I [ <NUM_LIT:0> , : ] + t0 + t1 <EOL> O [ <NUM_LIT:1> , : ] = I [ <NUM_LIT:1> , : ] - I [ <NUM_LIT:2> , : ] + <NUM_LIT:2> * ( I [ <NUM_LIT:3> , : ] - I [ <NUM_LIT:4> , : ] ) <EOL> O [ <NUM_LIT:2> , : ] = t0 + <NUM_LIT:4> * t1 + I [ <NUM_LIT:5> , : ] <EOL> return T1 . T <EOL> else : <EOL> return np . dot ( np . dot ( F_4x4_3x3 [ trans [ <NUM_LIT:0> ] ] . T , Mw ) , F_4x4_3x3 [ trans [ <NUM_LIT:1> ] ] ) <EOL> def image_slice ( x , X , B , D , pad = <NUM_LIT:0> ) : <EOL> start = x * B - pad <EOL> stop = start + D <EOL> pad = [ <NUM_LIT:0> , <NUM_LIT:0> ] <EOL> if start < <NUM_LIT:0> : <EOL> pad [ <NUM_LIT:0> ] = - start <EOL> start = <NUM_LIT:0> <EOL> if stop - <NUM_LIT:1> >= X : <EOL> pad [ <NUM_LIT:1> ] = stop - X <EOL> return start , stop , pad <EOL> def output_slice ( p , P , B ) : <EOL> p0 = p * B <EOL> p1 = p0 + B <EOL> if p1 > P : <EOL> p1 = P <EOL> return p0 , p1 , p1 - p0 <EOL> def xprop_winograd ( I , F , O , padding , minimal = False , trans = False , backward = False ) : <EOL> if backward : <EOL> F = np . transpose ( F [ : , : : - <NUM_LIT:1> , : : - <NUM_LIT:1> , : ] , ( <NUM_LIT:3> , <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:0> ) ) . copy ( ) <EOL> padding = [ <NUM_LIT:2> - p for p in padding ] <EOL> C , Y , X , N = I . shape <EOL> K , P , Q , N = O . shape <EOL> B = <NUM_LIT:4> <EOL> D = B + <NUM_LIT:2> <EOL> Yw = ceil_div ( P , B ) <EOL> Xw = ceil_div ( Q , B ) <EOL> Fw = np . empty ( ( D , D , C , K ) ) <EOL> Iw = np . empty ( ( D , D , C , Yw , Xw , N ) ) <EOL> Mw = np . empty ( ( D , D , K , Yw , Xw , N ) ) <EOL> for c in range ( C ) : <EOL> for k in range ( K ) : <EOL> trans_F_4x4_3x3 ( Fw [ : , : , c , k ] , F [ c , : , : , k ] , minimal , trans ) <EOL> for y in range ( Yw ) : <EOL> start_y , stop_y , pad_y = image_slice ( y , Y , B , D , padding [ <NUM_LIT:0> ] ) <EOL> for x in range ( Xw ) : <EOL> start_x , stop_x , pad_x = image_slice ( x , X , B , D , padding [ <NUM_LIT:1> ] ) <EOL> sliceI = I [ : , start_y : stop_y , start_x : stop_x , : ] <EOL> if any ( pad_y ) or any ( pad_x ) : <EOL> sliceI = np . pad ( sliceI , ( ( <NUM_LIT:0> , <NUM_LIT:0> ) , pad_y , pad_x , ( <NUM_LIT:0> , <NUM_LIT:0> ) ) , '<STR_LIT>' ) <EOL> for c in range ( C ) : <EOL> for n in range ( N ) : <EOL> trans_I_4x4_3x3 ( Iw [ : , : , c , y , x , n ] , sliceI [ c , : , : , n ] , minimal , trans ) <EOL> for s in range ( D ) : <EOL> for t in range ( D ) : <EOL> Mw [ s , t ] = np . dot ( Fw [ s , t ] . T , Iw [ s , t ] . reshape ( C , - <NUM_LIT:1> ) ) . reshape ( ( K , Yw , Xw , N ) ) <EOL> for y in range ( Yw ) : <EOL> p0 , p1 , plen = output_slice ( y , P , B ) <EOL> for x in range ( Xw ) : <EOL> q0 , q1 , qlen = output_slice ( x , Q , B ) <EOL> for k in range ( K ) : <EOL> for n in range ( N ) : <EOL> Out = trans_O_4x4_3x3 ( Mw [ : , : , k , y , x , n ] , minimal , trans ) <EOL> O [ k , p0 : p1 , q0 : q1 , n ] = Out [ <NUM_LIT:0> : plen , <NUM_LIT:0> : qlen ] <EOL> def updat_winograd ( I , E , U , padding , minimal = False , trans = False , inner = True ) : <EOL> C , Y , X , N = I . shape <EOL> K , P , Q , N = E . shape <EOL> B = <NUM_LIT:4> <EOL> D = B + <NUM_LIT:2> <EOL> Yw = ceil_div ( P , B ) <EOL> Xw = ceil_div ( Q , B ) <EOL> Iw = np . empty ( ( D , D , N , C ) ) <EOL> Ew = np . empty ( ( D , D , N , K ) ) <EOL> if inner : <EOL> Mw = np . empty ( ( D , D , C , K ) ) <EOL> U . fill ( <NUM_LIT:0.0> ) <EOL> else : <EOL> Mw = np . zeros ( ( D , D , C , K ) ) <EOL> for y in range ( Yw ) : <EOL> start_y , stop_y , pad_y = image_slice ( y , Y , B , D , padding [ <NUM_LIT:0> ] ) <EOL> start_p , stop_p , pad_p = image_slice ( y , P , B , B ) <EOL> for x in range ( Xw ) : <EOL> start_x , stop_x , pad_x = image_slice ( x , X , B , D , padding [ <NUM_LIT:1> ] ) <EOL> start_q , stop_q , pad_q = image_slice ( x , Q , B , B ) <EOL> sliceI = I [ : , start_y : stop_y , start_x : stop_x , : ] <EOL> sliceE = E [ : , start_p : stop_p , start_q : stop_q , : ] <EOL> if any ( pad_y ) or any ( pad_x ) : <EOL> sliceI = np . pad ( sliceI , ( ( <NUM_LIT:0> , <NUM_LIT:0> ) , pad_y , pad_x , ( <NUM_LIT:0> , <NUM_LIT:0> ) ) , '<STR_LIT>' ) <EOL> if any ( pad_p ) or any ( pad_q ) : <EOL> sliceE = np . pad ( sliceE , ( ( <NUM_LIT:0> , <NUM_LIT:0> ) , pad_p , pad_q , ( <NUM_LIT:0> , <NUM_LIT:0> ) ) , '<STR_LIT>' ) <EOL> for c in range ( C ) : <EOL> for n in range ( N ) : <EOL> trans_I_4x4_3x3 ( Iw [ : , : , n , c ] , sliceI [ c , : , : , n ] , minimal , trans ) <EOL> for k in range ( K ) : <EOL> for n in range ( N ) : <EOL> trans_F_3x3_4x4 ( Ew [ : , : , n , k ] , sliceE [ k , : , : , n ] , minimal , trans ) <EOL> for s in range ( D ) : <EOL> for t in range ( D ) : <EOL> if inner : <EOL> Mw [ s , t ] = np . dot ( Iw [ s , t ] . T , Ew [ s , t ] ) <EOL> else : <EOL> Mw [ s , t ] += np . dot ( Iw [ s , t ] . T , Ew [ s , t ] ) <EOL> if inner : <EOL> for c in range ( C ) : <EOL> for k in range ( K ) : <EOL> U [ c , : , : , k ] += trans_O_3x3_4x4 ( Mw [ : , : , c , k ] , minimal , trans ) <EOL> if not inner : <EOL> for c in range ( C ) : <EOL> for k in range ( K ) : <EOL> U [ c , : , : , k ] = trans_O_3x3_4x4 ( Mw [ : , : , c , k ] , minimal , trans ) <EOL> np . set_printoptions ( threshold = <NUM_LIT> * <NUM_LIT:4> , linewidth = <NUM_LIT> , formatter = { '<STR_LIT:float>' : lambda x : "<STR_LIT>" % x } ) <EOL> minimal = <NUM_LIT:1> <EOL> trans = ( <NUM_LIT:2> , <NUM_LIT:2> ) <EOL> ones = <NUM_LIT:0> <EOL> N = <NUM_LIT:32> <EOL> C , K = <NUM_LIT:32> , <NUM_LIT:32> <EOL> Y , X = <NUM_LIT:6> , <NUM_LIT:6> <EOL> R , S = <NUM_LIT:3> , <NUM_LIT:3> <EOL> strides = <NUM_LIT:1> , <NUM_LIT:1> <EOL> padding = <NUM_LIT:0> , <NUM_LIT:0> <EOL> P = out_dim ( R , Y , padding [ <NUM_LIT:0> ] , strides [ <NUM_LIT:0> ] ) <EOL> Q = out_dim ( S , X , padding [ <NUM_LIT:1> ] , strides [ <NUM_LIT:1> ] ) <EOL> print P , Q <EOL> dimI = ( C , Y , X , N ) <EOL> dimF = ( C , R , S , K ) <EOL> dimO = ( K , P , Q , N ) <EOL> if ones : <EOL> I = np . zeros ( dimI ) <EOL> F = np . ones ( dimF ) <EOL> E = np . zeros ( dimO ) <EOL> for p , q in np . ndindex ( ( Y , X ) ) : <EOL> I [ : , p , q , : ] = np . identity ( N ) <EOL> for p , q in np . ndindex ( ( P , Q ) ) : <EOL> for n in range ( N ) : <EOL> E [ : , p , q , n ] = range ( K ) <EOL> else : <EOL> I = np . random . uniform ( - <NUM_LIT:1.0> , <NUM_LIT:1.0> , dimI ) <EOL> F = np . random . uniform ( - <NUM_LIT:1.0> , <NUM_LIT:1.0> , dimF ) <EOL> E = np . random . uniform ( - <NUM_LIT:1.0> , <NUM_LIT:1.0> , dimO ) <EOL> Od = np . empty ( dimO ) <EOL> Ow = np . empty ( dimO ) <EOL> Bd = np . empty ( dimI ) <EOL> Bw = np . empty ( dimI ) <EOL> Ud = np . empty ( dimF ) <EOL> Uw = np . empty ( dimF ) <EOL> xprop_direct ( I , F , Od , padding , strides ) <EOL> xprop_winograd ( I , F , Ow , padding , minimal = minimal , trans = trans ) <EOL> xprop_direct ( E , F , Bd , padding , strides , backward = True ) <EOL> xprop_winograd ( E , F , Bw , padding , minimal = minimal , trans = trans , backward = True ) <EOL> updat_direct ( I , E , Ud , padding , strides ) <EOL> updat_winograd ( I , E , Uw , padding , minimal = minimal , trans = trans ) <EOL> difO = Od - Ow <EOL> difB = Bd - Bw <EOL> difU = Ud - Uw <EOL> print abs ( difO ) . max ( ) / Od . max ( ) <EOL> print abs ( difB ) . max ( ) / Bd . max ( ) <EOL> print abs ( difU ) . max ( ) / Ud . max ( ) </s>
<s> from neon . layers . layer import ( Linear , Bias , Affine , Conv , Convolution , GeneralizedCost , Dropout , <EOL> Pooling , Activation , DataTransform , BatchNorm , BatchNormAutodiff , <EOL> Deconv , Deconvolution , GeneralizedCostMask , LookupTable , <EOL> BranchNode , SkipNode , LRN , ColorNoise ) <EOL> from neon . layers . recurrent import ( Recurrent , LSTM , GRU , RecurrentSum , RecurrentMean , RecurrentLast , <EOL> BiRNN , BiLSTM , DeepBiRNN , DeepBiLSTM ) <EOL> from neon . layers . container import ( Tree , Sequential , MergeMultistream , MergeBroadcast , Multicost , <EOL> RoiPooling , MergeSum , SingleOutputTree ) </s>
<s> """<STR_LIT>""" <EOL> from neon . util . argparser import NeonArgparser <EOL> from neon . initializers import Constant , Gaussian <EOL> from neon . layers import Conv , Dropout , Pooling , GeneralizedCost , Affine <EOL> from neon . optimizers import GradientDescentMomentum , MultiOptimizer , Schedule <EOL> from neon . transforms import Rectlin , Softmax , CrossEntropyMulti , TopKMisclassification <EOL> from neon . models import Model <EOL> from neon . data import ImageLoader <EOL> from neon . callbacks . callbacks import Callbacks <EOL> parser = NeonArgparser ( __doc__ ) <EOL> args = parser . parse_args ( ) <EOL> img_set_options = dict ( repo_dir = args . data_dir , <EOL> inner_size = <NUM_LIT> , <EOL> subset_pct = <NUM_LIT> ) <EOL> train = ImageLoader ( set_name = '<STR_LIT:train>' , scale_range = ( <NUM_LIT> , <NUM_LIT> ) , shuffle = False , <EOL> do_transforms = False , ** img_set_options ) <EOL> test = ImageLoader ( set_name = '<STR_LIT>' , scale_range = ( <NUM_LIT> , <NUM_LIT> ) , shuffle = False , <EOL> do_transforms = False , ** img_set_options ) <EOL> layers = [ Conv ( ( <NUM_LIT:11> , <NUM_LIT:11> , <NUM_LIT:64> ) , init = Gaussian ( scale = <NUM_LIT> ) , bias = Constant ( <NUM_LIT:0> ) , <EOL> activation = Rectlin ( ) , padding = <NUM_LIT:3> , strides = <NUM_LIT:4> ) , <EOL> Pooling ( <NUM_LIT:3> , strides = <NUM_LIT:2> ) , <EOL> Conv ( ( <NUM_LIT:5> , <NUM_LIT:5> , <NUM_LIT> ) , init = Gaussian ( scale = <NUM_LIT> ) , bias = Constant ( <NUM_LIT:1> ) , <EOL> activation = Rectlin ( ) , padding = <NUM_LIT:2> ) , <EOL> Pooling ( <NUM_LIT:3> , strides = <NUM_LIT:2> ) , <EOL> Conv ( ( <NUM_LIT:3> , <NUM_LIT:3> , <NUM_LIT> ) , init = Gaussian ( scale = <NUM_LIT> ) , bias = Constant ( <NUM_LIT:0> ) , <EOL> activation = Rectlin ( ) , padding = <NUM_LIT:1> ) , <EOL> Conv ( ( <NUM_LIT:3> , <NUM_LIT:3> , <NUM_LIT> ) , init = Gaussian ( scale = <NUM_LIT> ) , bias = Constant ( <NUM_LIT:1> ) , <EOL> activation = Rectlin ( ) , padding = <NUM_LIT:1> ) , <EOL> Conv ( ( <NUM_LIT:3> , <NUM_LIT:3> , <NUM_LIT> ) , init = Gaussian ( scale = <NUM_LIT> ) , bias = Constant ( <NUM_LIT:1> ) , <EOL> activation = Rectlin ( ) , padding = <NUM_LIT:1> ) , <EOL> Pooling ( <NUM_LIT:3> , strides = <NUM_LIT:2> ) , <EOL> Affine ( nout = <NUM_LIT> , init = Gaussian ( scale = <NUM_LIT> ) , bias = Constant ( <NUM_LIT:1> ) , activation = Rectlin ( ) ) , <EOL> Dropout ( keep = <NUM_LIT:1.0> ) , <EOL> Affine ( nout = <NUM_LIT> , init = Gaussian ( scale = <NUM_LIT> ) , bias = Constant ( <NUM_LIT:1> ) , activation = Rectlin ( ) ) , <EOL> Dropout ( keep = <NUM_LIT:1.0> ) , <EOL> Affine ( nout = <NUM_LIT:1000> , init = Gaussian ( scale = <NUM_LIT> ) , bias = Constant ( - <NUM_LIT:7> ) , activation = Softmax ( ) ) ] <EOL> model = Model ( layers = layers ) <EOL> weight_sched = Schedule ( [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , ( <NUM_LIT:1> / <NUM_LIT> ) ** ( <NUM_LIT:1> / <NUM_LIT> ) ) <EOL> opt_gdm = GradientDescentMomentum ( <NUM_LIT> / <NUM_LIT:10> , <NUM_LIT> , wdecay = <NUM_LIT> , schedule = weight_sched , <EOL> stochastic_round = args . rounding ) <EOL> opt_biases = GradientDescentMomentum ( <NUM_LIT> / <NUM_LIT:10> , <NUM_LIT> , schedule = Schedule ( [ <NUM_LIT> ] , <NUM_LIT:0.1> ) , <EOL> stochastic_round = args . rounding ) <EOL> opt = MultiOptimizer ( { '<STR_LIT:default>' : opt_gdm , '<STR_LIT>' : opt_biases } ) <EOL> valmetric = TopKMisclassification ( k = <NUM_LIT:5> ) <EOL> callbacks = Callbacks ( model , eval_set = test , metric = valmetric , ** args . callback_args ) <EOL> cost = GeneralizedCost ( costfunc = CrossEntropyMulti ( ) ) <EOL> model . fit ( train , optimizer = opt , num_epochs = args . epochs , cost = cost , callbacks = callbacks ) </s>
<s> """<STR_LIT>""" <EOL> import itertools as itt <EOL> import numpy as np <EOL> from neon import NervanaObject <EOL> from neon . layers . layer import Pooling <EOL> from tests . utils import allclose_with_out <EOL> def pytest_generate_tests ( metafunc ) : <EOL> np . random . seed ( <NUM_LIT:1> ) <EOL> if metafunc . config . option . all : <EOL> bsz_rng = [ <NUM_LIT:32> , <NUM_LIT:64> ] <EOL> else : <EOL> bsz_rng = [ <NUM_LIT> ] <EOL> if '<STR_LIT>' in metafunc . fixturenames : <EOL> fargs = [ ] <EOL> if metafunc . config . option . all : <EOL> fs_rng = [ <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:5> ] <EOL> pad_rng = [ <NUM_LIT:0> , <NUM_LIT:1> ] <EOL> nifm_rng = [ <NUM_LIT:16> , <NUM_LIT:32> ] <EOL> in_sz_rng = [ <NUM_LIT:8> , <NUM_LIT:16> ] <EOL> else : <EOL> fs_rng = [ <NUM_LIT:2> , <NUM_LIT:4> ] <EOL> pad_rng = [ <NUM_LIT:0> , <NUM_LIT:1> ] <EOL> nifm_rng = [ <NUM_LIT:8> ] <EOL> in_sz_rng = [ <NUM_LIT:8> ] <EOL> fargs_ = [ ] <EOL> for fs in fs_rng : <EOL> stride_rng = set ( [ <NUM_LIT:1> , fs / <NUM_LIT:2> , fs ] ) <EOL> fargs_ . append ( itt . product ( fs_rng , nifm_rng , pad_rng , stride_rng , in_sz_rng , bsz_rng ) ) <EOL> fargs = itt . chain ( * fargs_ ) <EOL> metafunc . parametrize ( '<STR_LIT>' , fargs ) <EOL> def ref_pooling ( inp , inp_shape , fshape , padding , strides , be , ncheck = None ) : <EOL> inp_lshape = list ( inp_shape ) <EOL> bsz = inp . shape [ - <NUM_LIT:1> ] <EOL> if ncheck is None : <EOL> check_inds = np . arange ( bsz ) <EOL> elif type ( ncheck ) is int : <EOL> check_inds = np . random . permutation ( bsz ) <EOL> check_inds = check_inds [ <NUM_LIT:0> : ncheck ] <EOL> else : <EOL> check_inds = ncheck <EOL> check_inds = np . sort ( check_inds ) <EOL> inp_lshape . append ( bsz ) <EOL> inpa = inp . get ( ) . reshape ( inp_lshape ) <EOL> outshape = ( inp_lshape [ <NUM_LIT:0> ] , <EOL> be . output_dim ( inp_lshape [ <NUM_LIT:1> ] , fshape [ <NUM_LIT:0> ] , padding , strides [ <NUM_LIT:0> ] , pooling = True ) , <EOL> be . output_dim ( inp_lshape [ <NUM_LIT:2> ] , fshape [ <NUM_LIT:1> ] , padding , strides [ <NUM_LIT:1> ] , pooling = True ) , <EOL> len ( check_inds ) ) <EOL> if padding > <NUM_LIT:0> : <EOL> padded_shape = ( inp_lshape [ <NUM_LIT:0> ] , <EOL> inp_lshape [ <NUM_LIT:1> ] + <NUM_LIT:2> * padding , <EOL> inp_lshape [ <NUM_LIT:2> ] + <NUM_LIT:2> * padding , <EOL> inp_lshape [ - <NUM_LIT:1> ] ) <EOL> inp_pad = np . zeros ( padded_shape ) <EOL> inp_pad [ : , padding : - padding , padding : - padding , : ] = inpa [ : , <NUM_LIT:0> : , <NUM_LIT:0> : , : ] <EOL> else : <EOL> inp_pad = inpa <EOL> out_exp = np . zeros ( outshape ) <EOL> for indC in range ( outshape [ <NUM_LIT:0> ] ) : <EOL> for indh in range ( outshape [ <NUM_LIT:1> ] ) : <EOL> hrng = ( indh * strides [ <NUM_LIT:0> ] , indh * strides [ <NUM_LIT:0> ] + fshape [ <NUM_LIT:0> ] ) <EOL> for indw in range ( outshape [ <NUM_LIT:2> ] ) : <EOL> wrng = ( indw * strides [ <NUM_LIT:1> ] , indw * strides [ <NUM_LIT:1> ] + fshape [ <NUM_LIT:1> ] ) <EOL> for cnt , indb in enumerate ( check_inds ) : <EOL> inp_check = inp_pad [ indC , hrng [ <NUM_LIT:0> ] : hrng [ <NUM_LIT:1> ] , wrng [ <NUM_LIT:0> ] : wrng [ <NUM_LIT:1> ] , indb ] <EOL> out_exp [ indC , indh , indw , cnt ] = np . max ( inp_check ) <EOL> return ( out_exp , check_inds ) <EOL> def test_padding ( backend_default , poolargs ) : <EOL> fshape , nifm , padding , stride , in_sz , batch_size = poolargs <EOL> NervanaObject . be . bsz = batch_size <EOL> inshape = ( nifm , in_sz , in_sz ) <EOL> insize = np . prod ( inshape ) <EOL> neon_layer = Pooling ( fshape = fshape , strides = stride , padding = padding ) <EOL> inp = neon_layer . be . array ( np . random . random ( ( insize , batch_size ) ) ) <EOL> inp . lshape = inshape <EOL> neon_layer . configure ( inshape ) <EOL> neon_layer . prev_layer = True <EOL> neon_layer . allocate ( ) <EOL> neon_layer . set_deltas ( [ neon_layer . be . iobuf ( inshape ) ] ) <EOL> out = neon_layer . fprop ( inp ) . get ( ) <EOL> ncheck = [ <NUM_LIT:0> , batch_size / <NUM_LIT:2> , batch_size - <NUM_LIT:1> ] <EOL> ( out_exp , check_inds ) = ref_pooling ( inp , inp . lshape , <EOL> ( fshape , fshape ) , <EOL> padding , <EOL> ( stride , stride ) , <EOL> neon_layer . be , <EOL> ncheck = ncheck ) <EOL> out_shape = list ( out_exp . shape [ <NUM_LIT:0> : <NUM_LIT:3> ] ) <EOL> out_shape . append ( batch_size ) <EOL> outa = out . reshape ( out_shape ) <EOL> assert allclose_with_out ( out_exp , outa [ : , : , : , check_inds ] , atol = <NUM_LIT:0.0> , rtol = <NUM_LIT:0.0> ) </s>
<s> """<STR_LIT>""" <EOL> revision = '<STR_LIT>' <EOL> down_revision = '<STR_LIT>' <EOL> from alembic import op <EOL> import sqlalchemy as sa <EOL> def upgrade ( ) : <EOL> op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . Integer ) ) <EOL> def downgrade ( ) : <EOL> op . drop_column ( '<STR_LIT>' , '<STR_LIT>' ) </s>
<s> from . import view <EOL> from . comp import Card , NewCard </s>
<s> from nagare . i18n import _ <EOL> from nagare import presentation , ajax , security , component <EOL> from . comp import Gallery , Asset , AssetCropper <EOL> def render_image ( self , h , comp , size , randomize = False , ** kw ) : <EOL> metadata = self . assets_manager . get_metadata ( self . filename ) <EOL> src = self . assets_manager . get_image_url ( self . filename , size ) <EOL> if randomize : <EOL> src += '<STR_LIT>' + h . generate_id ( ) <EOL> return h . img ( title = metadata [ '<STR_LIT:filename>' ] , alt = metadata [ '<STR_LIT:filename>' ] , <EOL> src = src , ** kw ) <EOL> def render_file ( self , h , comp , size , ** kw ) : <EOL> kw [ '<STR_LIT:class>' ] += '<STR_LIT>' <EOL> metadata = self . assets_manager . get_metadata ( self . filename ) <EOL> res = [ h . img ( title = metadata [ '<STR_LIT:filename>' ] , alt = metadata [ '<STR_LIT:filename>' ] , <EOL> src = "<STR_LIT>" , ** kw ) ] <EOL> if size == '<STR_LIT>' : <EOL> res . append ( h . span ( metadata [ '<STR_LIT:filename>' ] ) ) <EOL> return res <EOL> CONTENT_TYPES = { '<STR_LIT>' : render_image , <EOL> '<STR_LIT>' : render_image , <EOL> '<STR_LIT>' : render_image , <EOL> '<STR_LIT>' : render_image } <EOL> @ presentation . render_for ( Gallery ) <EOL> def render ( self , h , comp , * args ) : <EOL> with h . div ( id = '<STR_LIT>' + self . comp_id ) : <EOL> with h . div ( class_ = '<STR_LIT>' ) : <EOL> h << comp . render ( h , model = '<STR_LIT>' ) <EOL> with h . div ( id = "<STR_LIT>" ) : <EOL> h << comp . render ( h , self . model ) <EOL> return h . root <EOL> @ presentation . render_for ( Gallery , '<STR_LIT>' ) <EOL> def render_Gallery_view ( self , h , comp , model ) : <EOL> model = '<STR_LIT>' if security . has_permissions ( '<STR_LIT>' , self ) else '<STR_LIT>' <EOL> for asset in self . assets : <EOL> h << asset . render ( h , model ) <EOL> return h . root <EOL> @ presentation . render_for ( Gallery , '<STR_LIT>' ) <EOL> def render_Gallery_crop ( self , h , comp , model ) : <EOL> return self . cropper . on_answer ( self . action ) <EOL> @ presentation . render_for ( Gallery , '<STR_LIT>' ) <EOL> def render_cover ( self , h , comp , model ) : <EOL> cover = self . get_cover ( ) <EOL> if cover : <EOL> h << h . p ( component . Component ( self . get_cover ( ) , model = '<STR_LIT>' ) , class_ = '<STR_LIT>' ) <EOL> return h . root <EOL> @ presentation . render_for ( Gallery , "<STR_LIT:action>" ) <EOL> def render_download ( self , h , comp , * args ) : <EOL> if security . has_permissions ( '<STR_LIT>' , self ) : <EOL> submit_id = h . generate_id ( "<STR_LIT>" ) <EOL> input_id = h . generate_id ( "<STR_LIT>" ) <EOL> h << h . label ( ( h . i ( class_ = '<STR_LIT>' ) , <EOL> _ ( "<STR_LIT>" ) ) , class_ = '<STR_LIT>' , for_ = input_id ) <EOL> with h . form : <EOL> h << h . script ( <EOL> u'''<STR_LIT>''' % <EOL> { <EOL> '<STR_LIT>' : ajax . py2js ( self . assets_manager . max_size ) , <EOL> '<STR_LIT>' : ajax . py2js ( input_id ) , <EOL> '<STR_LIT>' : ajax . py2js ( submit_id ) , <EOL> '<STR_LIT:error>' : ajax . py2js ( <EOL> _ ( u'<STR_LIT>' ) <EOL> ) . decode ( '<STR_LIT>' ) <EOL> } <EOL> ) <EOL> submit_action = ajax . Update ( <EOL> render = lambda r : r . div ( comp . render ( r , model = None ) , r . script ( '<STR_LIT>' ) ) , <EOL> component_to_update = '<STR_LIT>' + self . comp_id , <EOL> ) <EOL> h << h . input ( id = input_id , class_ = '<STR_LIT>' , type = "<STR_LIT:file>" , name = "<STR_LIT:file>" , multiple = "<STR_LIT>" , maxlength = "<STR_LIT:100>" , ) . action ( self . add_assets ) <EOL> h << h . input ( class_ = '<STR_LIT>' , id = submit_id , type = "<STR_LIT>" ) . action ( submit_action ) <EOL> return h . root <EOL> @ presentation . render_for ( Gallery , model = '<STR_LIT>' ) <EOL> def render_gallery_badge ( self , h , * args ) : <EOL> """<STR_LIT>""" <EOL> if self . assets : <EOL> with h . span ( class_ = '<STR_LIT>' ) : <EOL> h << h . span ( h . i ( class_ = '<STR_LIT>' ) , '<STR_LIT:U+0020>' , len ( self . assets ) , class_ = '<STR_LIT:label>' ) <EOL> return h . root <EOL> @ presentation . render_for ( Asset ) <EOL> @ presentation . render_for ( Asset , model = '<STR_LIT>' ) <EOL> @ presentation . render_for ( Asset , model = '<STR_LIT>' ) <EOL> @ presentation . render_for ( Asset , model = '<STR_LIT>' ) <EOL> def render_asset ( self , h , comp , model , * args ) : <EOL> res = [ ] <EOL> metadata = self . assets_manager . get_metadata ( self . filename ) <EOL> kw = { '<STR_LIT>' : True } if model == '<STR_LIT>' else { } <EOL> kw [ '<STR_LIT:class>' ] = model <EOL> if self . is_cover : <EOL> res . append ( h . span ( class_ = '<STR_LIT>' ) ) <EOL> meth = CONTENT_TYPES . get ( metadata [ '<STR_LIT>' ] , render_file ) <EOL> res . append ( meth ( self , h , comp , model , ** kw ) ) <EOL> return res <EOL> @ presentation . render_for ( Asset , model = '<STR_LIT>' ) <EOL> def render_Asset_thumb ( self , h , comp , model , * args ) : <EOL> with h . div ( class_ = '<STR_LIT>' ) : <EOL> action = h . a . action ( lambda : comp . answer ( ( '<STR_LIT>' , self ) ) ) . get ( '<STR_LIT>' ) <EOL> onclick = _ ( u'<STR_LIT>' ) <EOL> onclick = u'<STR_LIT>' % ( onclick , action ) <EOL> with h . a ( class_ = '<STR_LIT>' , title = _ ( u'<STR_LIT>' ) , href = '<STR_LIT:#>' , onclick = onclick ) : <EOL> h << h . i ( class_ = '<STR_LIT>' ) <EOL> if self . is_image ( ) : <EOL> with h . a ( class_ = '<STR_LIT>' , title = _ ( u'<STR_LIT>' ) ) . action ( lambda : comp . answer ( ( '<STR_LIT>' , self ) ) ) : <EOL> if self . is_cover : <EOL> h << { '<STR_LIT>' : '<STR_LIT>' } <EOL> h << h . i ( class_ = '<STR_LIT>' ) <EOL> with h . a ( href = self . assets_manager . get_image_url ( self . filename ) , target = '<STR_LIT>' ) : <EOL> h << comp . render ( h , '<STR_LIT>' ) <EOL> return h . root <EOL> @ presentation . render_for ( Asset , model = "<STR_LIT>" ) <EOL> def render_asset_anonymous ( self , h , comp , model , * args ) : <EOL> with h . div ( class_ = '<STR_LIT>' ) : <EOL> with h . a ( href = self . assets_manager . get_image_url ( self . filename ) , target = '<STR_LIT>' ) : <EOL> h << comp . render ( h , model = "<STR_LIT>" ) <EOL> return h . root <EOL> @ presentation . render_for ( AssetCropper ) <EOL> def render_gallery_cropper ( self , h , comp , * args ) : <EOL> h << h . p ( _ ( '<STR_LIT>' ) ) <EOL> form_id = h . generate_id ( ) <EOL> img_id = h . generate_id ( ) <EOL> with h . form : <EOL> for crop_name in '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' : <EOL> h << h . input ( type = '<STR_LIT>' , id = form_id + '<STR_LIT:_>' + crop_name ) . action ( getattr ( self , crop_name ) ) <EOL> h << h . p ( render_image ( self . asset , h , comp , '<STR_LIT>' , id = img_id ) ) <EOL> h << h . script ( <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" % ( <EOL> ajax . py2js ( img_id ) , <EOL> ajax . py2js ( img_id ) , <EOL> ajax . py2js ( form_id ) , <EOL> ajax . py2js ( self . crop_width ( ) ) , <EOL> ajax . py2js ( self . crop_height ( ) ) <EOL> ) <EOL> ) <EOL> with h . div ( class_ = '<STR_LIT>' ) : <EOL> h << h . button ( _ ( '<STR_LIT>' ) , class_ = '<STR_LIT>' ) . action ( self . commit , comp ) <EOL> if self . asset . is_cover : <EOL> h << '<STR_LIT:U+0020>' <EOL> h << h . button ( _ ( '<STR_LIT>' ) , class_ = '<STR_LIT>' ) . action ( self . remove_cover , comp ) <EOL> h << '<STR_LIT:U+0020>' <EOL> h << h . button ( _ ( '<STR_LIT>' ) , class_ = '<STR_LIT>' ) . action ( self . cancel , comp ) <EOL> return h . root </s>
<s> class EventHandlerMixIn ( object ) : <EOL> """<STR_LIT>""" <EOL> def emit_event ( self , comp , kind , data = None ) : <EOL> event = kind ( data , source = [ self ] ) <EOL> return comp . answer ( event ) <EOL> def handle_event ( self , comp , event ) : <EOL> local_res = None <EOL> local_handler = getattr ( self , '<STR_LIT>' , None ) <EOL> if local_handler : <EOL> local_res = local_handler ( comp , event ) <EOL> event . append ( self ) <EOL> upper_res = comp . answer ( event ) <EOL> return local_res or upper_res <EOL> class Event ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , data , source = [ ] ) : <EOL> """<STR_LIT>""" <EOL> self . _source = source <EOL> self . data = data <EOL> @ property <EOL> def source ( self ) : <EOL> return self . _source . copy ( ) <EOL> @ property <EOL> def emitter ( self ) : <EOL> return self . _source [ <NUM_LIT:0> ] <EOL> @ property <EOL> def last_relay ( self ) : <EOL> return self . _source [ - <NUM_LIT:1> ] <EOL> def is_ ( self , kind ) : <EOL> return type ( self ) is kind <EOL> def is_kind_of ( self , kind ) : <EOL> return isinstance ( self , kind ) <EOL> def append ( self , relay ) : <EOL> self . _source . append ( relay ) <EOL> def cast_as ( self , sub_kind ) : <EOL> return sub_kind ( self . data , self . _source ) <EOL> class ColumnDeleted ( Event ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> class CardClicked ( Event ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> class PopinClosed ( Event ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> class CardEditorClosed ( PopinClosed ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> class CardArchived ( Event ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> class SearchIndexUpdated ( Event ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> class CardDisplayed ( Event ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> class BoardAccessChanged ( Event ) : <EOL> """<STR_LIT>""" <EOL> class BoardDeleted ( BoardAccessChanged ) : <EOL> """<STR_LIT>""" <EOL> class BoardArchived ( BoardAccessChanged ) : <EOL> """<STR_LIT>""" <EOL> class BoardRestored ( BoardAccessChanged ) : <EOL> """<STR_LIT>""" <EOL> class BoardLeft ( BoardAccessChanged ) : <EOL> """<STR_LIT>""" <EOL> class ParentTitleNeeded ( Event ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> class NewTemplateRequested ( Event ) : <EOL> """<STR_LIT>""" <EOL> pass </s>
<s> from . comp import EditableTitle <EOL> from . import view </s>
<s> import genie2 . client . wrapper <EOL> import genie2 . model . ClusterCriteria <EOL> import genie2 . model . Job <EOL> import genie2 . model . FileAttachment <EOL> import time <EOL> genie = genie2 . client . wrapper . Genie2 ( "<STR_LIT>" , <EOL> genie2 . client . wrapper . RetryPolicy ( <EOL> tries = <NUM_LIT:8> , none_on_404 = True , no_retry_http_codes = range ( <NUM_LIT> , <NUM_LIT> ) <EOL> ) ) <EOL> job = genie2 . model . Job . Job ( ) <EOL> job . name = "<STR_LIT>" <EOL> job . user = "<STR_LIT:root>" <EOL> job . version = "<STR_LIT>" <EOL> job . clusterCriterias = list ( ) <EOL> cluster_criteria = genie2 . model . ClusterCriteria . ClusterCriteria ( ) <EOL> criteria = set ( ) <EOL> criteria . add ( "<STR_LIT>" ) <EOL> criteria . add ( "<STR_LIT>" ) <EOL> cluster_criteria . tags = criteria <EOL> job . clusterCriterias . append ( cluster_criteria ) <EOL> command_criteria = set ( ) <EOL> command_criteria . add ( "<STR_LIT>" ) <EOL> job . commandCriteria = command_criteria <EOL> job . fileDependencies = "<STR_LIT>" <EOL> job . commandArgs = "<STR_LIT>" <EOL> job = genie . submitJob ( job ) <EOL> while job . status != "<STR_LIT>" and job . status != "<STR_LIT>" and job . status != "<STR_LIT>" : <EOL> print "<STR_LIT>" + job . id + "<STR_LIT>" + job . status <EOL> time . sleep ( <NUM_LIT:10> ) <EOL> job = genie . getJob ( job . id ) <EOL> print "<STR_LIT>" + job . id + "<STR_LIT>" + job . status </s>
<s> """<STR_LIT>""" <EOL> import logging <EOL> from os import environ <EOL> from aminator . config import conf_action <EOL> from aminator . plugins . finalizer . tagging_base import TaggingBaseFinalizerPlugin <EOL> from aminator . util . linux import sanitize_metadata <EOL> __all__ = ( '<STR_LIT>' , ) <EOL> log = logging . getLogger ( __name__ ) <EOL> class TaggingEBSFinalizerPlugin ( TaggingBaseFinalizerPlugin ) : <EOL> _name = '<STR_LIT>' <EOL> def add_plugin_args ( self ) : <EOL> tagging = super ( TaggingEBSFinalizerPlugin , self ) . add_plugin_args ( ) <EOL> context = self . _config . context <EOL> tagging . add_argument ( '<STR_LIT>' , '<STR_LIT>' , dest = '<STR_LIT:name>' , action = conf_action ( context . ami ) , help = '<STR_LIT>' ) <EOL> def _set_metadata ( self ) : <EOL> super ( TaggingEBSFinalizerPlugin , self ) . _set_metadata ( ) <EOL> context = self . _config . context <EOL> config = self . _config . plugins [ self . full_name ] <EOL> metadata = context . package . attributes <EOL> ami_name = context . ami . get ( '<STR_LIT:name>' , None ) <EOL> if not ami_name : <EOL> ami_name = config . name_format . format ( ** metadata ) <EOL> context . ami . name = sanitize_metadata ( '<STR_LIT>' . format ( ami_name ) ) <EOL> def _snapshot_volume ( self ) : <EOL> log . info ( '<STR_LIT>' ) <EOL> if not self . _cloud . snapshot_volume ( ) : <EOL> return False <EOL> log . info ( '<STR_LIT>' ) <EOL> return True <EOL> def _register_image ( self , block_device_map = None , root_device = None ) : <EOL> log . info ( '<STR_LIT>' ) <EOL> config = self . _config . plugins [ self . full_name ] <EOL> if block_device_map is None : <EOL> block_device_map = config . default_block_device_map <EOL> if root_device is None : <EOL> root_device = config . default_root_device <EOL> if not self . _cloud . register_image ( block_device_map , root_device ) : <EOL> return False <EOL> log . info ( '<STR_LIT>' ) <EOL> return True <EOL> def finalize ( self ) : <EOL> log . info ( '<STR_LIT>' ) <EOL> self . _set_metadata ( ) <EOL> if not self . _snapshot_volume ( ) : <EOL> log . critical ( '<STR_LIT>' ) <EOL> return False <EOL> if not self . _register_image ( ) : <EOL> log . critical ( '<STR_LIT>' ) <EOL> return False <EOL> if not self . _add_tags ( [ '<STR_LIT>' , '<STR_LIT>' ] ) : <EOL> log . critical ( '<STR_LIT>' ) <EOL> return False <EOL> log . info ( '<STR_LIT>' ) <EOL> self . _log_ami_metadata ( ) <EOL> return True <EOL> def __enter__ ( self ) : <EOL> context = self . _config . context <EOL> environ [ "<STR_LIT>" ] = "<STR_LIT>" <EOL> if context . ami . get ( "<STR_LIT:name>" , None ) : <EOL> environ [ "<STR_LIT>" ] = context . ami . name <EOL> return super ( TaggingEBSFinalizerPlugin , self ) . __enter__ ( ) </s>
<s> OFF = <NUM_LIT:0> <EOL> ON = <NUM_LIT:1> <EOL> DISCONNECTED = <NUM_LIT:20> <EOL> CONNECTED = <NUM_LIT:30> <EOL> DEFAULT_EVENT_VERSION = <NUM_LIT:1> <EOL> DEFAULT_ACTION_VERSION = <NUM_LIT:1> </s>
<s> LOG_LEVEL = "<STR_LIT>" <EOL> LOG_FILE = "<STR_LIT>" <EOL> SQLALCHEMY_DATABASE_URI = '<STR_LIT>' <EOL> SQLALCHEMY_POOL_SIZE = <NUM_LIT:50> <EOL> SQLALCHEMY_MAX_OVERFLOW = <NUM_LIT:15> <EOL> ENVIRONMENT = '<STR_LIT>' <EOL> USE_ROUTE53 = False <EOL> FQDN = '<STR_LIT>' <EOL> API_PORT = '<STR_LIT>' <EOL> WEB_PORT = '<STR_LIT>' <EOL> WEB_PATH = '<STR_LIT>' <EOL> FRONTED_BY_NGINX = True <EOL> NGINX_PORT = '<STR_LIT>' <EOL> BASE_URL = '<STR_LIT>' . format ( FQDN ) <EOL> SECRET_KEY = '<STR_LIT>' <EOL> MAIL_DEFAULT_SENDER = '<STR_LIT>' <EOL> SECURITY_REGISTERABLE = True <EOL> SECURITY_CONFIRMABLE = False <EOL> SECURITY_RECOVERABLE = False <EOL> SECURITY_PASSWORD_HASH = '<STR_LIT>' <EOL> SECURITY_PASSWORD_SALT = '<STR_LIT>' <EOL> SECURITY_TRACKABLE = True <EOL> SECURITY_POST_LOGIN_VIEW = BASE_URL <EOL> SECURITY_POST_REGISTER_VIEW = BASE_URL <EOL> SECURITY_POST_CONFIRM_VIEW = BASE_URL <EOL> SECURITY_POST_RESET_VIEW = BASE_URL <EOL> SECURITY_POST_CHANGE_VIEW = BASE_URL <EOL> SECURITY_TEAM_EMAIL = [ ] <EOL> EMAILS_USE_SMTP = False <EOL> SES_REGION = '<STR_LIT>' <EOL> MAIL_SERVER = '<STR_LIT>' <EOL> MAIL_PORT = <NUM_LIT> <EOL> MAIL_USE_SSL = True <EOL> MAIL_USERNAME = '<STR_LIT:username>' <EOL> MAIL_PASSWORD = '<STR_LIT:password>' <EOL> WTF_CSRF_ENABLED = True <EOL> WTF_CSRF_SSL_STRICT = True <EOL> WTF_CSRF_METHODS = [ '<STR_LIT>' , '<STR_LIT:POST>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> SECURITYGROUP_INSTANCE_DETAIL = '<STR_LIT>' <EOL> CORE_THREADS = <NUM_LIT> <EOL> MAX_THREADS = <NUM_LIT:30> </s>
<s> """<STR_LIT>""" <EOL> from security_monkey . auditor import Auditor <EOL> from security_monkey . watchers . rds_security_group import RDSSecurityGroup <EOL> from security_monkey . datastore import NetworkWhitelistEntry <EOL> from security_monkey . auditors . security_group import _check_rfc_1918 <EOL> import ipaddr <EOL> class RDSSecurityGroupAuditor ( Auditor ) : <EOL> index = RDSSecurityGroup . index <EOL> i_am_singular = RDSSecurityGroup . i_am_singular <EOL> i_am_plural = RDSSecurityGroup . i_am_plural <EOL> network_whitelist = [ ] <EOL> def __init__ ( self , accounts = None , debug = False ) : <EOL> super ( RDSSecurityGroupAuditor , self ) . __init__ ( accounts = accounts , debug = debug ) <EOL> def prep_for_audit ( self ) : <EOL> self . network_whitelist = NetworkWhitelistEntry . query . all ( ) <EOL> def _check_inclusion_in_network_whitelist ( self , cidr ) : <EOL> for entry in self . network_whitelist : <EOL> if ipaddr . IPNetwork ( cidr ) in ipaddr . IPNetwork ( str ( entry . cidr ) ) : <EOL> return True <EOL> return False <EOL> def check_rds_ec2_rfc1918 ( self , sg_item ) : <EOL> """<STR_LIT>""" <EOL> tag = "<STR_LIT>" <EOL> severity = <NUM_LIT:8> <EOL> if sg_item . config . get ( "<STR_LIT>" , None ) : <EOL> return <EOL> for ipr in sg_item . config . get ( "<STR_LIT>" , [ ] ) : <EOL> cidr = ipr . get ( "<STR_LIT>" , None ) <EOL> if cidr and _check_rfc_1918 ( cidr ) : <EOL> self . add_issue ( severity , tag , sg_item , notes = cidr ) <EOL> def check_securitygroup_large_subnet ( self , sg_item ) : <EOL> """<STR_LIT>""" <EOL> tag = "<STR_LIT>" <EOL> severity = <NUM_LIT:3> <EOL> for ipr in sg_item . config . get ( "<STR_LIT>" , [ ] ) : <EOL> cidr = ipr . get ( "<STR_LIT>" , None ) <EOL> if cidr and not self . _check_inclusion_in_network_whitelist ( cidr ) : <EOL> if '<STR_LIT:/>' in cidr and not cidr == "<STR_LIT>" and not cidr == "<STR_LIT>" : <EOL> mask = int ( cidr . split ( '<STR_LIT:/>' ) [ <NUM_LIT:1> ] ) <EOL> if mask < <NUM_LIT> and mask > <NUM_LIT:0> : <EOL> self . add_issue ( severity , tag , sg_item , notes = cidr ) <EOL> def check_securitygroup_zero_subnet ( self , sg_item ) : <EOL> """<STR_LIT>""" <EOL> tag = "<STR_LIT>" <EOL> severity = <NUM_LIT:10> <EOL> for ipr in sg_item . config . get ( "<STR_LIT>" , [ ] ) : <EOL> cidr = ipr . get ( "<STR_LIT>" , None ) <EOL> if cidr and '<STR_LIT:/>' in cidr and not cidr == "<STR_LIT>" and not cidr == "<STR_LIT>" : <EOL> mask = int ( cidr . split ( '<STR_LIT:/>' ) [ <NUM_LIT:1> ] ) <EOL> if mask == <NUM_LIT:0> : <EOL> self . add_issue ( severity , tag , sg_item , notes = cidr ) <EOL> def check_securitygroup_any ( self , sg_item ) : <EOL> """<STR_LIT>""" <EOL> tag = "<STR_LIT>" <EOL> severity = <NUM_LIT:5> <EOL> for ipr in sg_item . config . get ( "<STR_LIT>" , [ ] ) : <EOL> cidr = ipr . get ( "<STR_LIT>" ) <EOL> if "<STR_LIT>" == cidr : <EOL> self . add_issue ( severity , tag , sg_item , notes = cidr ) <EOL> return <EOL> def check_securitygroup_10net ( self , sg_item ) : <EOL> """<STR_LIT>""" <EOL> tag = "<STR_LIT>" <EOL> severity = <NUM_LIT:5> <EOL> for ipr in sg_item . config . get ( "<STR_LIT>" , [ ] ) : <EOL> cidr = ipr . get ( "<STR_LIT>" ) <EOL> if "<STR_LIT>" == cidr : <EOL> self . add_issue ( severity , tag , sg_item , notes = cidr ) <EOL> return </s>
<s> """<STR_LIT>""" <EOL> import json <EOL> from security_monkey . datastore import NetworkWhitelistEntry , Account <EOL> from security_monkey . tests import SecurityMonkeyTestCase <EOL> from security_monkey import db <EOL> from security_monkey . watchers . elasticsearch_service import ElasticSearchServiceItem <EOL> CONFIG_ONE = { <EOL> "<STR_LIT:name>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : json . loads ( b"""<STR_LIT>""" ) <EOL> } <EOL> CONFIG_TWO = { <EOL> "<STR_LIT:name>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : json . loads ( b"""<STR_LIT>""" ) <EOL> } <EOL> CONFIG_THREE = { <EOL> "<STR_LIT:name>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : json . loads ( b"""<STR_LIT>""" ) <EOL> } <EOL> CONFIG_FOUR = { <EOL> "<STR_LIT:name>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : json . loads ( b"""<STR_LIT>""" ) <EOL> } <EOL> CONFIG_FIVE = { <EOL> "<STR_LIT:name>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : json . loads ( b"""<STR_LIT>""" ) <EOL> } <EOL> CONFIG_SIX = { <EOL> "<STR_LIT:name>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : json . loads ( b"""<STR_LIT>""" ) <EOL> } <EOL> CONFIG_SEVEN = { <EOL> "<STR_LIT:name>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : json . loads ( b"""<STR_LIT>""" ) <EOL> } <EOL> CONFIG_EIGHT = { <EOL> "<STR_LIT:name>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : json . loads ( b"""<STR_LIT>""" ) <EOL> } <EOL> CONFIG_NINE = { <EOL> "<STR_LIT:name>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : json . loads ( b"""<STR_LIT>""" ) <EOL> } <EOL> WHITELIST_CIDRS = [ <EOL> ( "<STR_LIT>" , "<STR_LIT>" ) , <EOL> ( "<STR_LIT>" , "<STR_LIT>" ) , <EOL> ] <EOL> class ElasticSearchServiceTestCase ( SecurityMonkeyTestCase ) : <EOL> def setUp ( self ) : <EOL> self . es_items = [ <EOL> ElasticSearchServiceItem ( region = "<STR_LIT>" , account = "<STR_LIT>" , name = "<STR_LIT>" , config = CONFIG_ONE ) , <EOL> ElasticSearchServiceItem ( region = "<STR_LIT>" , account = "<STR_LIT>" , name = "<STR_LIT>" , config = CONFIG_TWO ) , <EOL> ElasticSearchServiceItem ( region = "<STR_LIT>" , account = "<STR_LIT>" , name = "<STR_LIT>" , config = CONFIG_THREE ) , <EOL> ElasticSearchServiceItem ( region = "<STR_LIT>" , account = "<STR_LIT>" , name = "<STR_LIT>" , config = CONFIG_FOUR ) , <EOL> ElasticSearchServiceItem ( region = "<STR_LIT>" , account = "<STR_LIT>" , name = "<STR_LIT>" , config = CONFIG_FIVE ) , <EOL> ElasticSearchServiceItem ( region = "<STR_LIT>" , account = "<STR_LIT>" , name = "<STR_LIT>" , config = CONFIG_SIX ) , <EOL> ElasticSearchServiceItem ( region = "<STR_LIT>" , account = "<STR_LIT>" , name = "<STR_LIT>" , config = CONFIG_SEVEN ) , <EOL> ElasticSearchServiceItem ( region = "<STR_LIT>" , account = "<STR_LIT>" , name = "<STR_LIT>" , config = CONFIG_EIGHT ) , <EOL> ElasticSearchServiceItem ( region = "<STR_LIT>" , account = "<STR_LIT>" , name = "<STR_LIT>" , config = CONFIG_NINE ) , <EOL> ] <EOL> test_account = Account ( ) <EOL> test_account . name = "<STR_LIT>" <EOL> test_account . notes = "<STR_LIT>" <EOL> test_account . s3_name = "<STR_LIT>" <EOL> test_account . number = "<STR_LIT>" <EOL> test_account . role_name = "<STR_LIT>" <EOL> db . session . add ( test_account ) <EOL> db . session . commit ( ) <EOL> def tearDown ( self ) : <EOL> test_account = Account . query . filter ( Account . number == "<STR_LIT>" ) . first ( ) <EOL> if test_account is not None : <EOL> db . session . delete ( test_account ) <EOL> db . session . commit ( ) <EOL> def test_es_auditor ( self ) : <EOL> from security_monkey . auditors . elasticsearch_service import ElasticSearchServiceAuditor <EOL> es_auditor = ElasticSearchServiceAuditor ( accounts = [ "<STR_LIT>" ] ) <EOL> es_auditor . network_whitelist = [ ] <EOL> for cidr in WHITELIST_CIDRS : <EOL> whitelist_cidr = NetworkWhitelistEntry ( ) <EOL> whitelist_cidr . cidr = cidr [ <NUM_LIT:1> ] <EOL> whitelist_cidr . name = cidr [ <NUM_LIT:0> ] <EOL> es_auditor . network_whitelist . append ( whitelist_cidr ) <EOL> for es_domain in self . es_items : <EOL> es_auditor . check_es_access_policy ( es_domain ) <EOL> self . assertEquals ( len ( self . es_items [ <NUM_LIT:0> ] . audit_issues ) , <NUM_LIT:1> ) <EOL> self . assertEquals ( self . es_items [ <NUM_LIT:0> ] . audit_issues [ <NUM_LIT:0> ] . score , <NUM_LIT:20> ) <EOL> self . assertEquals ( len ( self . es_items [ <NUM_LIT:1> ] . audit_issues ) , <NUM_LIT:1> ) <EOL> self . assertEquals ( self . es_items [ <NUM_LIT:1> ] . audit_issues [ <NUM_LIT:0> ] . score , <NUM_LIT:20> ) <EOL> self . assertEquals ( len ( self . es_items [ <NUM_LIT:2> ] . audit_issues ) , <NUM_LIT:2> ) <EOL> self . assertEquals ( self . es_items [ <NUM_LIT:2> ] . audit_issues [ <NUM_LIT:0> ] . score , <NUM_LIT:5> ) <EOL> self . assertEquals ( self . es_items [ <NUM_LIT:2> ] . audit_issues [ <NUM_LIT:1> ] . score , <NUM_LIT:7> ) <EOL> self . assertEquals ( len ( self . es_items [ <NUM_LIT:3> ] . audit_issues ) , <NUM_LIT:1> ) <EOL> self . assertEquals ( self . es_items [ <NUM_LIT:3> ] . audit_issues [ <NUM_LIT:0> ] . score , <NUM_LIT:20> ) <EOL> self . assertEquals ( len ( self . es_items [ <NUM_LIT:4> ] . audit_issues ) , <NUM_LIT:0> ) <EOL> self . assertEquals ( len ( self . es_items [ <NUM_LIT:5> ] . audit_issues ) , <NUM_LIT:0> ) <EOL> self . assertEquals ( len ( self . es_items [ <NUM_LIT:6> ] . audit_issues ) , <NUM_LIT:3> ) <EOL> self . assertEquals ( self . es_items [ <NUM_LIT:6> ] . audit_issues [ <NUM_LIT:0> ] . score , <NUM_LIT:5> ) <EOL> self . assertEquals ( self . es_items [ <NUM_LIT:6> ] . audit_issues [ <NUM_LIT:1> ] . score , <NUM_LIT:5> ) <EOL> self . assertEquals ( self . es_items [ <NUM_LIT:6> ] . audit_issues [ <NUM_LIT:2> ] . score , <NUM_LIT:7> ) <EOL> self . assertEquals ( len ( self . es_items [ <NUM_LIT:7> ] . audit_issues ) , <NUM_LIT:1> ) <EOL> self . assertEquals ( self . es_items [ <NUM_LIT:7> ] . audit_issues [ <NUM_LIT:0> ] . score , <NUM_LIT:20> ) <EOL> self . assertEquals ( len ( self . es_items [ <NUM_LIT:8> ] . audit_issues ) , <NUM_LIT:2> ) <EOL> self . assertEquals ( self . es_items [ <NUM_LIT:8> ] . audit_issues [ <NUM_LIT:0> ] . score , <NUM_LIT:6> ) <EOL> self . assertEquals ( self . es_items [ <NUM_LIT:8> ] . audit_issues [ <NUM_LIT:1> ] . score , <NUM_LIT:10> ) </s>
<s> """<STR_LIT>""" <EOL> from security_monkey . watcher import Watcher <EOL> from security_monkey . watcher import ChangeItem <EOL> from security_monkey . constants import TROUBLE_REGIONS <EOL> from security_monkey . exceptions import BotoConnectionIssue <EOL> from security_monkey import app <EOL> from boto . redshift import regions <EOL> class Redshift ( Watcher ) : <EOL> index = '<STR_LIT>' <EOL> i_am_singular = '<STR_LIT>' <EOL> i_am_plural = '<STR_LIT>' <EOL> def __init__ ( self , accounts = None , debug = False ) : <EOL> super ( Redshift , self ) . __init__ ( accounts = accounts , debug = debug ) <EOL> def slurp ( self ) : <EOL> """<STR_LIT>""" <EOL> self . prep_for_slurp ( ) <EOL> from security_monkey . common . sts_connect import connect <EOL> item_list = [ ] <EOL> exception_map = { } <EOL> for account in self . accounts : <EOL> for region in regions ( ) : <EOL> app . logger . debug ( "<STR_LIT>" . format ( self . index , account , region . name ) ) <EOL> try : <EOL> redshift = connect ( account , '<STR_LIT>' , region = region ) <EOL> all_clusters = [ ] <EOL> marker = None <EOL> while True : <EOL> response = self . wrap_aws_rate_limited_call ( <EOL> redshift . describe_clusters , <EOL> marker = marker <EOL> ) <EOL> all_clusters . extend ( response [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) <EOL> if response [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] is not None : <EOL> marker = response [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> else : <EOL> break <EOL> except Exception as e : <EOL> if region . name not in TROUBLE_REGIONS : <EOL> exc = BotoConnectionIssue ( str ( e ) , '<STR_LIT>' , account , region . name ) <EOL> self . slurp_exception ( ( self . index , account , region . name ) , exc , exception_map ) <EOL> continue <EOL> app . logger . debug ( "<STR_LIT>" . format ( len ( all_clusters ) , Redshift . i_am_plural ) ) <EOL> for cluster in all_clusters : <EOL> cluster_id = cluster [ '<STR_LIT>' ] <EOL> if self . check_ignore_list ( cluster_id ) : <EOL> continue <EOL> item = RedshiftCluster ( region = region . name , account = account , name = cluster_id , config = dict ( cluster ) ) <EOL> item_list . append ( item ) <EOL> return item_list , exception_map <EOL> class RedshiftCluster ( ChangeItem ) : <EOL> def __init__ ( self , region = None , account = None , name = None , config = { } ) : <EOL> super ( RedshiftCluster , self ) . __init__ ( <EOL> index = Redshift . index , <EOL> region = region , <EOL> account = account , <EOL> name = name , <EOL> new_config = config ) </s>
<s> '''<STR_LIT>''' <EOL> from __future__ import absolute_import , division , print_function <EOL> import numpy as np <EOL> from neo . core . container import Container <EOL> class RecordingChannelGroup ( Container ) : <EOL> '''<STR_LIT>''' <EOL> _container_child_objects = ( '<STR_LIT>' , ) <EOL> _data_child_objects = ( '<STR_LIT>' , ) <EOL> _multi_child_objects = ( '<STR_LIT>' , ) <EOL> _single_parent_objects = ( '<STR_LIT>' , ) <EOL> _recommended_attrs = ( ( ( '<STR_LIT>' , np . ndarray , <NUM_LIT:1> , np . dtype ( '<STR_LIT:i>' ) ) , <EOL> ( '<STR_LIT>' , np . ndarray , <NUM_LIT:1> , np . dtype ( '<STR_LIT:S>' ) ) ) + <EOL> Container . _recommended_attrs ) <EOL> def __init__ ( self , channel_names = None , channel_indexes = None , name = None , <EOL> description = None , file_origin = None , ** annotations ) : <EOL> '''<STR_LIT>''' <EOL> super ( RecordingChannelGroup , self ) . __init__ ( name = name , <EOL> description = description , <EOL> file_origin = file_origin , <EOL> ** annotations ) <EOL> if channel_indexes is None : <EOL> channel_indexes = np . array ( [ ] , dtype = np . int ) <EOL> if channel_names is None : <EOL> channel_names = np . array ( [ ] , dtype = '<STR_LIT:S>' ) <EOL> self . channel_names = channel_names <EOL> self . channel_indexes = channel_indexes </s>
<s> """<STR_LIT>""" <EOL> import sys <EOL> import ctypes <EOL> import os <EOL> try : <EOL> file <EOL> except NameError : <EOL> import io <EOL> file = io . BufferedReader <EOL> import numpy as np <EOL> import quantities as pq <EOL> from neo . io . baseio import BaseIO <EOL> from neo . core import Segment , AnalogSignal , SpikeTrain , EventArray <EOL> ns_OK = <NUM_LIT:0> <EOL> ns_LIBERROR = - <NUM_LIT:1> <EOL> ns_TYPEERROR = - <NUM_LIT:2> <EOL> ns_FILEERROR = - <NUM_LIT:3> <EOL> ns_BADFILE = - <NUM_LIT:4> <EOL> ns_BADENTITY = - <NUM_LIT:5> <EOL> ns_BADSOURCE = - <NUM_LIT:6> <EOL> ns_BADINDEX = - <NUM_LIT:7> <EOL> class NeuroshareError ( Exception ) : <EOL> def __init__ ( self , lib , errno ) : <EOL> self . lib = lib <EOL> self . errno = errno <EOL> pszMsgBuffer = ctypes . create_string_buffer ( <NUM_LIT> ) <EOL> self . lib . ns_GetLastErrorMsg ( pszMsgBuffer , ctypes . c_uint32 ( <NUM_LIT> ) ) <EOL> errstr = '<STR_LIT>' . format ( errno , pszMsgBuffer . value ) <EOL> Exception . __init__ ( self , errstr ) <EOL> class DllWithError ( ) : <EOL> def __init__ ( self , lib ) : <EOL> self . lib = lib <EOL> def __getattr__ ( self , attr ) : <EOL> f = getattr ( self . lib , attr ) <EOL> return self . decorate_with_error ( f ) <EOL> def decorate_with_error ( self , f ) : <EOL> def func_with_error ( * args ) : <EOL> errno = f ( * args ) <EOL> if errno != ns_OK : <EOL> raise NeuroshareError ( self . lib , errno ) <EOL> return errno <EOL> return func_with_error <EOL> class NeurosharectypesIO ( BaseIO ) : <EOL> """<STR_LIT>""" <EOL> is_readable = True <EOL> is_writable = False <EOL> supported_objects = [ Segment , AnalogSignal , EventArray , SpikeTrain ] <EOL> readable_objects = [ Segment ] <EOL> writeable_objects = [ ] <EOL> has_header = False <EOL> is_streameable = False <EOL> read_params = { Segment : [ ] } <EOL> write_params = None <EOL> name = '<STR_LIT>' <EOL> extensions = [ ] <EOL> mode = '<STR_LIT:file>' <EOL> def __init__ ( self , filename = '<STR_LIT>' , dllname = '<STR_LIT>' ) : <EOL> """<STR_LIT>""" <EOL> BaseIO . __init__ ( self ) <EOL> self . dllname = dllname <EOL> self . filename = filename <EOL> def read_segment ( self , import_neuroshare_segment = True , <EOL> lazy = False , cascade = True ) : <EOL> """<STR_LIT>""" <EOL> seg = Segment ( file_origin = os . path . basename ( self . filename ) , ) <EOL> if sys . platform . startswith ( '<STR_LIT>' ) : <EOL> neuroshare = ctypes . windll . LoadLibrary ( self . dllname ) <EOL> elif sys . platform . startswith ( '<STR_LIT>' ) : <EOL> neuroshare = ctypes . cdll . LoadLibrary ( self . dllname ) <EOL> neuroshare = DllWithError ( neuroshare ) <EOL> info = ns_LIBRARYINFO ( ) <EOL> neuroshare . ns_GetLibraryInfo ( ctypes . byref ( info ) , ctypes . sizeof ( info ) ) <EOL> seg . annotate ( neuroshare_version = str ( info . dwAPIVersionMaj ) + '<STR_LIT:.>' + str ( info . dwAPIVersionMin ) ) <EOL> if not cascade : <EOL> return seg <EOL> hFile = ctypes . c_uint32 ( <NUM_LIT:0> ) <EOL> neuroshare . ns_OpenFile ( ctypes . c_char_p ( self . filename ) , ctypes . byref ( hFile ) ) <EOL> fileinfo = ns_FILEINFO ( ) <EOL> neuroshare . ns_GetFileInfo ( hFile , ctypes . byref ( fileinfo ) , ctypes . sizeof ( fileinfo ) ) <EOL> for dwEntityID in range ( fileinfo . dwEntityCount ) : <EOL> entityInfo = ns_ENTITYINFO ( ) <EOL> neuroshare . ns_GetEntityInfo ( hFile , dwEntityID , ctypes . byref ( entityInfo ) , ctypes . sizeof ( entityInfo ) ) <EOL> if entity_types [ entityInfo . dwEntityType ] == '<STR_LIT>' : <EOL> pEventInfo = ns_EVENTINFO ( ) <EOL> neuroshare . ns_GetEventInfo ( hFile , dwEntityID , ctypes . byref ( pEventInfo ) , ctypes . sizeof ( pEventInfo ) ) <EOL> if pEventInfo . dwEventType == <NUM_LIT:0> : <EOL> pData = ctypes . create_string_buffer ( pEventInfo . dwMaxDataLength ) <EOL> elif pEventInfo . dwEventType == <NUM_LIT:1> : <EOL> pData = ctypes . create_string_buffer ( pEventInfo . dwMaxDataLength ) <EOL> elif pEventInfo . dwEventType == <NUM_LIT:2> : <EOL> pData = ctypes . c_byte ( <NUM_LIT:0> ) <EOL> elif pEventInfo . dwEventType == <NUM_LIT:3> : <EOL> pData = ctypes . c_int16 ( <NUM_LIT:0> ) <EOL> elif pEventInfo . dwEventType == <NUM_LIT:4> : <EOL> pData = ctypes . c_int32 ( <NUM_LIT:0> ) <EOL> pdTimeStamp = ctypes . c_double ( <NUM_LIT:0.> ) <EOL> pdwDataRetSize = ctypes . c_uint32 ( <NUM_LIT:0> ) <EOL> ea = EventArray ( name = str ( entityInfo . szEntityLabel ) , ) <EOL> if not lazy : <EOL> times = [ ] <EOL> labels = [ ] <EOL> for dwIndex in range ( entityInfo . dwItemCount ) : <EOL> neuroshare . ns_GetEventData ( hFile , dwEntityID , dwIndex , <EOL> ctypes . byref ( pdTimeStamp ) , ctypes . byref ( pData ) , <EOL> ctypes . sizeof ( pData ) , ctypes . byref ( pdwDataRetSize ) ) <EOL> times . append ( pdTimeStamp . value ) <EOL> labels . append ( str ( pData . value ) ) <EOL> ea . times = times * pq . s <EOL> ea . labels = np . array ( labels , dtype = '<STR_LIT:S>' ) <EOL> else : <EOL> ea . lazy_shape = entityInfo . dwItemCount <EOL> seg . eventarrays . append ( ea ) <EOL> if entity_types [ entityInfo . dwEntityType ] == '<STR_LIT>' : <EOL> pAnalogInfo = ns_ANALOGINFO ( ) <EOL> neuroshare . ns_GetAnalogInfo ( hFile , dwEntityID , ctypes . byref ( pAnalogInfo ) , ctypes . sizeof ( pAnalogInfo ) ) <EOL> dwIndexCount = entityInfo . dwItemCount <EOL> if lazy : <EOL> signal = [ ] * pq . Quantity ( <NUM_LIT:1> , pAnalogInfo . szUnits ) <EOL> else : <EOL> pdwContCount = ctypes . c_uint32 ( <NUM_LIT:0> ) <EOL> pData = np . zeros ( ( entityInfo . dwItemCount , ) , dtype = '<STR_LIT>' ) <EOL> total_read = <NUM_LIT:0> <EOL> while total_read < entityInfo . dwItemCount : <EOL> dwStartIndex = ctypes . c_uint32 ( total_read ) <EOL> dwStopIndex = ctypes . c_uint32 ( entityInfo . dwItemCount - total_read ) <EOL> neuroshare . ns_GetAnalogData ( hFile , dwEntityID , dwStartIndex , <EOL> dwStopIndex , ctypes . byref ( pdwContCount ) , pData [ total_read : ] . ctypes . data_as ( ctypes . POINTER ( ctypes . c_double ) ) ) <EOL> total_read += pdwContCount . value <EOL> signal = pq . Quantity ( pData , units = pAnalogInfo . szUnits , copy = False ) <EOL> dwIndex = <NUM_LIT:0> <EOL> pdTime = ctypes . c_double ( <NUM_LIT:0> ) <EOL> neuroshare . ns_GetTimeByIndex ( hFile , dwEntityID , dwIndex , ctypes . byref ( pdTime ) ) <EOL> anaSig = AnalogSignal ( signal , <EOL> sampling_rate = pAnalogInfo . dSampleRate * pq . Hz , <EOL> t_start = pdTime . value * pq . s , <EOL> name = str ( entityInfo . szEntityLabel ) , <EOL> ) <EOL> anaSig . annotate ( probe_info = str ( pAnalogInfo . szProbeInfo ) ) <EOL> if lazy : <EOL> anaSig . lazy_shape = entityInfo . dwItemCount <EOL> seg . analogsignals . append ( anaSig ) <EOL> if entity_types [ entityInfo . dwEntityType ] == '<STR_LIT>' and import_neuroshare_segment : <EOL> pdwSegmentInfo = ns_SEGMENTINFO ( ) <EOL> if not str ( entityInfo . szEntityLabel ) . startswith ( '<STR_LIT>' ) : <EOL> continue <EOL> neuroshare . ns_GetSegmentInfo ( hFile , dwEntityID , <EOL> ctypes . byref ( pdwSegmentInfo ) , ctypes . sizeof ( pdwSegmentInfo ) ) <EOL> nsource = pdwSegmentInfo . dwSourceCount <EOL> pszMsgBuffer = ctypes . create_string_buffer ( "<STR_LIT:U+0020>" * <NUM_LIT> ) <EOL> neuroshare . ns_GetLastErrorMsg ( ctypes . byref ( pszMsgBuffer ) , <NUM_LIT> ) <EOL> for dwSourceID in range ( pdwSegmentInfo . dwSourceCount ) : <EOL> pSourceInfo = ns_SEGSOURCEINFO ( ) <EOL> neuroshare . ns_GetSegmentSourceInfo ( hFile , dwEntityID , dwSourceID , <EOL> ctypes . byref ( pSourceInfo ) , ctypes . sizeof ( pSourceInfo ) ) <EOL> if lazy : <EOL> sptr = SpikeTrain ( times , name = str ( entityInfo . szEntityLabel ) , t_stop = <NUM_LIT:0.> * pq . s ) <EOL> sptr . lazy_shape = entityInfo . dwItemCount <EOL> else : <EOL> pdTimeStamp = ctypes . c_double ( <NUM_LIT:0.> ) <EOL> dwDataBufferSize = pdwSegmentInfo . dwMaxSampleCount * pdwSegmentInfo . dwSourceCount <EOL> pData = np . zeros ( ( dwDataBufferSize ) , dtype = '<STR_LIT>' ) <EOL> pdwSampleCount = ctypes . c_uint32 ( <NUM_LIT:0> ) <EOL> pdwUnitID = ctypes . c_uint32 ( <NUM_LIT:0> ) <EOL> nsample = int ( dwDataBufferSize ) <EOL> times = np . empty ( ( entityInfo . dwItemCount ) , dtype = '<STR_LIT:f>' ) <EOL> waveforms = np . empty ( ( entityInfo . dwItemCount , nsource , nsample ) , dtype = '<STR_LIT:f>' ) <EOL> for dwIndex in range ( entityInfo . dwItemCount ) : <EOL> neuroshare . ns_GetSegmentData ( hFile , dwEntityID , dwIndex , <EOL> ctypes . byref ( pdTimeStamp ) , pData . ctypes . data_as ( ctypes . POINTER ( ctypes . c_double ) ) , <EOL> dwDataBufferSize * <NUM_LIT:8> , ctypes . byref ( pdwSampleCount ) , <EOL> ctypes . byref ( pdwUnitID ) ) <EOL> times [ dwIndex ] = pdTimeStamp . value <EOL> waveforms [ dwIndex , : , : ] = pData [ : nsample * nsource ] . reshape ( nsample , nsource ) . transpose ( ) <EOL> sptr = SpikeTrain ( times = pq . Quantity ( times , units = '<STR_LIT:s>' , copy = False ) , <EOL> t_stop = times . max ( ) , <EOL> waveforms = pq . Quantity ( waveforms , units = str ( pdwSegmentInfo . szUnits ) , copy = False ) , <EOL> left_sweep = nsample / <NUM_LIT> / float ( pdwSegmentInfo . dSampleRate ) * pq . s , <EOL> sampling_rate = float ( pdwSegmentInfo . dSampleRate ) * pq . Hz , <EOL> name = str ( entityInfo . szEntityLabel ) , <EOL> ) <EOL> seg . spiketrains . append ( sptr ) <EOL> if entity_types [ entityInfo . dwEntityType ] == '<STR_LIT>' : <EOL> pNeuralInfo = ns_NEURALINFO ( ) <EOL> neuroshare . ns_GetNeuralInfo ( hFile , dwEntityID , <EOL> ctypes . byref ( pNeuralInfo ) , ctypes . sizeof ( pNeuralInfo ) ) <EOL> if lazy : <EOL> times = [ ] * pq . s <EOL> t_stop = <NUM_LIT:0> * pq . s <EOL> else : <EOL> pData = np . zeros ( ( entityInfo . dwItemCount , ) , dtype = '<STR_LIT>' ) <EOL> dwStartIndex = <NUM_LIT:0> <EOL> dwIndexCount = entityInfo . dwItemCount <EOL> neuroshare . ns_GetNeuralData ( hFile , dwEntityID , dwStartIndex , <EOL> dwIndexCount , pData . ctypes . data_as ( ctypes . POINTER ( ctypes . c_double ) ) ) <EOL> times = pData * pq . s <EOL> t_stop = times . max ( ) <EOL> sptr = SpikeTrain ( times , t_stop = t_stop , <EOL> name = str ( entityInfo . szEntityLabel ) , ) <EOL> if lazy : <EOL> sptr . lazy_shape = entityInfo . dwItemCount <EOL> seg . spiketrains . append ( sptr ) <EOL> neuroshare . ns_CloseFile ( hFile ) <EOL> seg . create_many_to_one_relationship ( ) <EOL> return seg <EOL> class ns_FILEDESC ( ctypes . Structure ) : <EOL> _fields_ = [ ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT:32> ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT:8> ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT:8> ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT:16> ) , <EOL> ] <EOL> class ns_LIBRARYINFO ( ctypes . Structure ) : <EOL> _fields_ = [ ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT:64> ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT:64> ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ns_FILEDESC * <NUM_LIT:16> ) , <EOL> ] <EOL> class ns_FILEINFO ( ctypes . Structure ) : <EOL> _fields_ = [ ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT:32> ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT:64> ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT> ) , <EOL> ] <EOL> class ns_ENTITYINFO ( ctypes . Structure ) : <EOL> _fields_ = [ ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT:32> ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ] <EOL> entity_types = { <NUM_LIT:0> : '<STR_LIT>' , <EOL> <NUM_LIT:1> : '<STR_LIT>' , <EOL> <NUM_LIT:2> : '<STR_LIT>' , <EOL> <NUM_LIT:3> : '<STR_LIT>' , <EOL> <NUM_LIT:4> : '<STR_LIT>' , <EOL> } <EOL> class ns_EVENTINFO ( ctypes . Structure ) : <EOL> _fields_ = [ <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT> ) , <EOL> ] <EOL> class ns_ANALOGINFO ( ctypes . Structure ) : <EOL> _fields_ = [ <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT:16> ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT:16> ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT:16> ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT> ) , <EOL> ] <EOL> class ns_SEGMENTINFO ( ctypes . Structure ) : <EOL> _fields_ = [ <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT:32> ) , <EOL> ] <EOL> class ns_SEGSOURCEINFO ( ctypes . Structure ) : <EOL> _fields_ = [ <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT:16> ) , <EOL> ( '<STR_LIT>' , ctypes . c_double ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT:16> ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT> ) , <EOL> ] <EOL> class ns_NEURALINFO ( ctypes . Structure ) : <EOL> _fields_ = [ <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_uint32 ) , <EOL> ( '<STR_LIT>' , ctypes . c_char * <NUM_LIT> ) , <EOL> ] </s>
<s> """<STR_LIT>""" <EOL> from __future__ import absolute_import , division , print_function <EOL> from datetime import datetime <EOL> try : <EOL> import unittest2 as unittest <EOL> except ImportError : <EOL> import unittest <EOL> import numpy as np <EOL> import quantities as pq <EOL> try : <EOL> from IPython . lib . pretty import pretty <EOL> except ImportError as err : <EOL> HAVE_IPYTHON = False <EOL> else : <EOL> HAVE_IPYTHON = True <EOL> from neo . core . segment import Segment <EOL> from neo . core import ( AnalogSignalArray , Block , <EOL> Epoch , EpochArray , <EOL> RecordingChannelGroup , SpikeTrain , Unit ) <EOL> from neo . core . container import filterdata <EOL> from neo . test . tools import ( assert_neo_object_is_compliant , <EOL> assert_same_sub_schema ) <EOL> from neo . test . generate_datasets import ( fake_neo , get_fake_value , <EOL> get_fake_values , get_annotations , <EOL> clone_object , TEST_ANNOTATIONS ) <EOL> class Test__generate_datasets ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> np . random . seed ( <NUM_LIT:0> ) <EOL> self . annotations = dict ( [ ( str ( x ) , TEST_ANNOTATIONS [ x ] ) for x in <EOL> range ( len ( TEST_ANNOTATIONS ) ) ] ) <EOL> def test__get_fake_values ( self ) : <EOL> self . annotations [ '<STR_LIT>' ] = <NUM_LIT:0> <EOL> file_datetime = get_fake_value ( '<STR_LIT>' , datetime , seed = <NUM_LIT:0> ) <EOL> rec_datetime = get_fake_value ( '<STR_LIT>' , datetime , seed = <NUM_LIT:1> ) <EOL> index = get_fake_value ( '<STR_LIT:index>' , int , seed = <NUM_LIT:2> ) <EOL> name = get_fake_value ( '<STR_LIT:name>' , str , seed = <NUM_LIT:3> , obj = Segment ) <EOL> description = get_fake_value ( '<STR_LIT:description>' , str , seed = <NUM_LIT:4> , obj = '<STR_LIT>' ) <EOL> file_origin = get_fake_value ( '<STR_LIT>' , str ) <EOL> attrs1 = { '<STR_LIT>' : file_datetime , <EOL> '<STR_LIT>' : rec_datetime , <EOL> '<STR_LIT:index>' : index , <EOL> '<STR_LIT:name>' : name , <EOL> '<STR_LIT:description>' : description , <EOL> '<STR_LIT>' : file_origin } <EOL> attrs2 = attrs1 . copy ( ) <EOL> attrs2 . update ( self . annotations ) <EOL> res11 = get_fake_values ( Segment , annotate = False , seed = <NUM_LIT:0> ) <EOL> res12 = get_fake_values ( '<STR_LIT>' , annotate = False , seed = <NUM_LIT:0> ) <EOL> res21 = get_fake_values ( Segment , annotate = True , seed = <NUM_LIT:0> ) <EOL> res22 = get_fake_values ( '<STR_LIT>' , annotate = True , seed = <NUM_LIT:0> ) <EOL> self . assertEqual ( res11 , attrs1 ) <EOL> self . assertEqual ( res12 , attrs1 ) <EOL> self . assertEqual ( res21 , attrs2 ) <EOL> self . assertEqual ( res22 , attrs2 ) <EOL> def test__fake_neo__cascade ( self ) : <EOL> self . annotations [ '<STR_LIT>' ] = None <EOL> obj_type = Segment <EOL> cascade = True <EOL> res = fake_neo ( obj_type = obj_type , cascade = cascade ) <EOL> self . assertTrue ( isinstance ( res , Segment ) ) <EOL> assert_neo_object_is_compliant ( res ) <EOL> self . assertEqual ( res . annotations , self . annotations ) <EOL> self . assertEqual ( len ( res . analogsignalarrays ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( len ( res . analogsignals ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( len ( res . irregularlysampledsignals ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( len ( res . spiketrains ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( len ( res . spikes ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( len ( res . events ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( len ( res . epochs ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( len ( res . eventarrays ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( len ( res . epocharrays ) , <NUM_LIT:1> ) <EOL> for child in res . children : <EOL> del child . annotations [ '<STR_LIT:i>' ] <EOL> del child . annotations [ '<STR_LIT>' ] <EOL> self . assertEqual ( res . analogsignalarrays [ <NUM_LIT:0> ] . annotations , <EOL> self . annotations ) <EOL> self . assertEqual ( res . analogsignals [ <NUM_LIT:0> ] . annotations , <EOL> self . annotations ) <EOL> self . assertEqual ( res . irregularlysampledsignals [ <NUM_LIT:0> ] . annotations , <EOL> self . annotations ) <EOL> self . assertEqual ( res . spiketrains [ <NUM_LIT:0> ] . annotations , <EOL> self . annotations ) <EOL> self . assertEqual ( res . spikes [ <NUM_LIT:0> ] . annotations , <EOL> self . annotations ) <EOL> self . assertEqual ( res . events [ <NUM_LIT:0> ] . annotations , <EOL> self . annotations ) <EOL> self . assertEqual ( res . epochs [ <NUM_LIT:0> ] . annotations , <EOL> self . annotations ) <EOL> self . assertEqual ( res . eventarrays [ <NUM_LIT:0> ] . annotations , <EOL> self . annotations ) <EOL> self . assertEqual ( res . epocharrays [ <NUM_LIT:0> ] . annotations , <EOL> self . annotations ) <EOL> def test__fake_neo__nocascade ( self ) : <EOL> self . annotations [ '<STR_LIT>' ] = None <EOL> obj_type = '<STR_LIT>' <EOL> cascade = False <EOL> res = fake_neo ( obj_type = obj_type , cascade = cascade ) <EOL> self . assertTrue ( isinstance ( res , Segment ) ) <EOL> assert_neo_object_is_compliant ( res ) <EOL> self . assertEqual ( res . annotations , self . annotations ) <EOL> self . assertEqual ( len ( res . analogsignalarrays ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( len ( res . analogsignals ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( len ( res . irregularlysampledsignals ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( len ( res . spiketrains ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( len ( res . spikes ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( len ( res . events ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( len ( res . epochs ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( len ( res . eventarrays ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( len ( res . epocharrays ) , <NUM_LIT:0> ) <EOL> class TestSegment ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . nchildren = <NUM_LIT:2> <EOL> blk = fake_neo ( Block , seed = <NUM_LIT:0> , n = self . nchildren ) <EOL> self . unit1 , self . unit2 , self . unit3 , self . unit4 = blk . list_units <EOL> self . seg1 , self . seg2 = blk . segments <EOL> self . targobj = self . seg1 <EOL> self . seed1 = self . seg1 . annotations [ '<STR_LIT>' ] <EOL> self . seed2 = self . seg2 . annotations [ '<STR_LIT>' ] <EOL> del self . seg1 . annotations [ '<STR_LIT:i>' ] <EOL> del self . seg2 . annotations [ '<STR_LIT:i>' ] <EOL> del self . seg1 . annotations [ '<STR_LIT>' ] <EOL> del self . seg2 . annotations [ '<STR_LIT>' ] <EOL> self . sigs1 = self . seg1 . analogsignals <EOL> self . sigs2 = self . seg2 . analogsignals <EOL> self . sigarrs1 = self . seg1 . analogsignalarrays <EOL> self . sigarrs2 = self . seg2 . analogsignalarrays <EOL> self . irsigs1 = self . seg1 . irregularlysampledsignals <EOL> self . irsigs2 = self . seg2 . irregularlysampledsignals <EOL> self . spikes1 = self . seg1 . spikes <EOL> self . spikes2 = self . seg2 . spikes <EOL> self . trains1 = self . seg1 . spiketrains <EOL> self . trains2 = self . seg2 . spiketrains <EOL> self . epcs1 = self . seg1 . epochs <EOL> self . epcs2 = self . seg2 . epochs <EOL> self . epcas1 = self . seg1 . epocharrays <EOL> self . epcas2 = self . seg2 . epocharrays <EOL> self . evts1 = self . seg1 . events <EOL> self . evts2 = self . seg2 . events <EOL> self . evtas1 = self . seg1 . eventarrays <EOL> self . evtas2 = self . seg2 . eventarrays <EOL> self . sigs1a = clone_object ( self . sigs1 ) <EOL> self . sigarrs1a = clone_object ( self . sigarrs1 , n = <NUM_LIT:2> ) <EOL> self . irsigs1a = clone_object ( self . irsigs1 ) <EOL> self . spikes1a = clone_object ( self . spikes1 ) <EOL> self . trains1a = clone_object ( self . trains1 ) <EOL> self . epcs1a = clone_object ( self . epcs1 ) <EOL> self . epcas1a = clone_object ( self . epcas1 ) <EOL> self . evts1a = clone_object ( self . evts1 ) <EOL> self . evtas1a = clone_object ( self . evtas1 ) <EOL> for obj , obja in zip ( self . sigs1 + self . sigarrs1 , <EOL> self . sigs1a + self . sigarrs1a ) : <EOL> obja . channel_index = obj . channel_index <EOL> def test_init ( self ) : <EOL> seg = Segment ( name = '<STR_LIT>' , index = <NUM_LIT:3> ) <EOL> assert_neo_object_is_compliant ( seg ) <EOL> self . assertEqual ( seg . name , '<STR_LIT>' ) <EOL> self . assertEqual ( seg . file_origin , None ) <EOL> self . assertEqual ( seg . index , <NUM_LIT:3> ) <EOL> def check_creation ( self , seg ) : <EOL> assert_neo_object_is_compliant ( seg ) <EOL> seed = seg . annotations [ '<STR_LIT>' ] <EOL> targ0 = get_fake_value ( '<STR_LIT>' , datetime , seed = seed + <NUM_LIT:0> ) <EOL> self . assertEqual ( seg . file_datetime , targ0 ) <EOL> targ1 = get_fake_value ( '<STR_LIT>' , datetime , seed = seed + <NUM_LIT:1> ) <EOL> self . assertEqual ( seg . rec_datetime , targ1 ) <EOL> targ2 = get_fake_value ( '<STR_LIT:index>' , int , seed = seed + <NUM_LIT:2> ) <EOL> self . assertEqual ( seg . index , targ2 ) <EOL> targ3 = get_fake_value ( '<STR_LIT:name>' , str , seed = seed + <NUM_LIT:3> , obj = Segment ) <EOL> self . assertEqual ( seg . name , targ3 ) <EOL> targ4 = get_fake_value ( '<STR_LIT:description>' , str , <EOL> seed = seed + <NUM_LIT:4> , obj = Segment ) <EOL> self . assertEqual ( seg . description , targ4 ) <EOL> targ5 = get_fake_value ( '<STR_LIT>' , str ) <EOL> self . assertEqual ( seg . file_origin , targ5 ) <EOL> targ6 = get_annotations ( ) <EOL> targ6 [ '<STR_LIT>' ] = seed <EOL> self . assertEqual ( seg . annotations , targ6 ) <EOL> self . assertTrue ( hasattr ( seg , '<STR_LIT>' ) ) <EOL> self . assertTrue ( hasattr ( seg , '<STR_LIT>' ) ) <EOL> self . assertTrue ( hasattr ( seg , '<STR_LIT>' ) ) <EOL> self . assertTrue ( hasattr ( seg , '<STR_LIT>' ) ) <EOL> self . assertTrue ( hasattr ( seg , '<STR_LIT>' ) ) <EOL> self . assertTrue ( hasattr ( seg , '<STR_LIT>' ) ) <EOL> self . assertTrue ( hasattr ( seg , '<STR_LIT>' ) ) <EOL> self . assertTrue ( hasattr ( seg , '<STR_LIT>' ) ) <EOL> self . assertTrue ( hasattr ( seg , '<STR_LIT>' ) ) <EOL> self . assertEqual ( len ( seg . analogsignals ) , self . nchildren ** <NUM_LIT:2> ) <EOL> self . assertEqual ( len ( seg . analogsignalarrays ) , self . nchildren ) <EOL> self . assertEqual ( len ( seg . irregularlysampledsignals ) , self . nchildren ** <NUM_LIT:2> ) <EOL> self . assertEqual ( len ( seg . epochs ) , self . nchildren ) <EOL> self . assertEqual ( len ( seg . epocharrays ) , self . nchildren ) <EOL> self . assertEqual ( len ( seg . events ) , self . nchildren ) <EOL> self . assertEqual ( len ( seg . eventarrays ) , self . nchildren ) <EOL> self . assertEqual ( len ( seg . spikes ) , self . nchildren ** <NUM_LIT:2> ) <EOL> self . assertEqual ( len ( seg . spiketrains ) , self . nchildren ** <NUM_LIT:2> ) <EOL> def test__creation ( self ) : <EOL> self . check_creation ( self . seg1 ) <EOL> self . check_creation ( self . seg2 ) <EOL> def test__merge ( self ) : <EOL> seg1a = fake_neo ( Block , seed = self . seed1 , n = self . nchildren ) . segments [ <NUM_LIT:0> ] <EOL> assert_same_sub_schema ( self . seg1 , seg1a ) <EOL> seg1a . spikes . append ( self . spikes2 [ <NUM_LIT:0> ] ) <EOL> seg1a . epocharrays . append ( self . epcas2 [ <NUM_LIT:0> ] ) <EOL> seg1a . annotate ( seed = self . seed2 ) <EOL> seg1a . merge ( self . seg2 ) <EOL> self . check_creation ( self . seg2 ) <EOL> assert_same_sub_schema ( self . sigs1a + self . sigs2 , seg1a . analogsignals ) <EOL> assert_same_sub_schema ( self . sigarrs1a + self . sigarrs2 , <EOL> seg1a . analogsignalarrays ) <EOL> assert_same_sub_schema ( self . irsigs1a + self . irsigs2 , <EOL> seg1a . irregularlysampledsignals ) <EOL> assert_same_sub_schema ( self . epcs1 + self . epcs2 , seg1a . epochs ) <EOL> assert_same_sub_schema ( self . epcas1 + self . epcas2 , seg1a . epocharrays ) <EOL> assert_same_sub_schema ( self . evts1 + self . evts2 , seg1a . events ) <EOL> assert_same_sub_schema ( self . evtas1 + self . evtas2 , seg1a . eventarrays ) <EOL> assert_same_sub_schema ( self . spikes1 + self . spikes2 , seg1a . spikes ) <EOL> assert_same_sub_schema ( self . trains1 + self . trains2 , seg1a . spiketrains ) <EOL> def test__children ( self ) : <EOL> blk = Block ( name = '<STR_LIT>' ) <EOL> blk . segments = [ self . seg1 ] <EOL> blk . create_many_to_one_relationship ( force = True ) <EOL> assert_neo_object_is_compliant ( self . seg1 ) <EOL> assert_neo_object_is_compliant ( blk ) <EOL> childobjs = ( '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' ) <EOL> childconts = ( '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . assertEqual ( self . seg1 . _container_child_objects , ( ) ) <EOL> self . assertEqual ( self . seg1 . _data_child_objects , childobjs ) <EOL> self . assertEqual ( self . seg1 . _single_parent_objects , ( '<STR_LIT>' , ) ) <EOL> self . assertEqual ( self . seg1 . _multi_child_objects , ( ) ) <EOL> self . assertEqual ( self . seg1 . _multi_parent_objects , ( ) ) <EOL> self . assertEqual ( self . seg1 . _child_properties , ( ) ) <EOL> self . assertEqual ( self . seg1 . _single_child_objects , childobjs ) <EOL> self . assertEqual ( self . seg1 . _container_child_containers , ( ) ) <EOL> self . assertEqual ( self . seg1 . _data_child_containers , childconts ) <EOL> self . assertEqual ( self . seg1 . _single_child_containers , childconts ) <EOL> self . assertEqual ( self . seg1 . _single_parent_containers , ( '<STR_LIT>' , ) ) <EOL> self . assertEqual ( self . seg1 . _multi_child_containers , ( ) ) <EOL> self . assertEqual ( self . seg1 . _multi_parent_containers , ( ) ) <EOL> self . assertEqual ( self . seg1 . _child_objects , childobjs ) <EOL> self . assertEqual ( self . seg1 . _child_containers , childconts ) <EOL> self . assertEqual ( self . seg1 . _parent_objects , ( '<STR_LIT>' , ) ) <EOL> self . assertEqual ( self . seg1 . _parent_containers , ( '<STR_LIT>' , ) ) <EOL> totchildren = ( self . nchildren * <NUM_LIT:2> * <NUM_LIT:2> + <EOL> self . nchildren + <EOL> <NUM_LIT:2> * ( self . nchildren ** <NUM_LIT:2> ) + <EOL> <NUM_LIT:2> * ( self . nchildren ** <NUM_LIT:2> ) ) <EOL> self . assertEqual ( len ( self . seg1 . _single_children ) , totchildren ) <EOL> self . assertEqual ( len ( self . seg1 . data_children ) , totchildren ) <EOL> self . assertEqual ( len ( self . seg1 . children ) , totchildren ) <EOL> self . assertEqual ( len ( self . seg1 . data_children_recur ) , totchildren ) <EOL> self . assertEqual ( len ( self . seg1 . children_recur ) , totchildren ) <EOL> self . assertEqual ( len ( self . seg1 . _multi_children ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( len ( self . seg1 . container_children ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( len ( self . seg1 . container_children_recur ) , <NUM_LIT:0> ) <EOL> children = ( self . sigs1a + self . sigarrs1a + <EOL> self . epcs1a + self . epcas1a + <EOL> self . evts1a + self . evtas1a + <EOL> self . irsigs1a + <EOL> self . spikes1a + self . trains1a ) <EOL> assert_same_sub_schema ( list ( self . seg1 . _single_children ) , children ) <EOL> assert_same_sub_schema ( list ( self . seg1 . data_children ) , children ) <EOL> assert_same_sub_schema ( list ( self . seg1 . data_children_recur ) , children ) <EOL> assert_same_sub_schema ( list ( self . seg1 . children ) , children ) <EOL> assert_same_sub_schema ( list ( self . seg1 . children_recur ) , children ) <EOL> self . assertEqual ( len ( self . seg1 . parents ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( self . seg1 . parents [ <NUM_LIT:0> ] . name , '<STR_LIT>' ) <EOL> def test__size ( self ) : <EOL> targ1 = { "<STR_LIT>" : self . nchildren , "<STR_LIT>" : self . nchildren , <EOL> "<STR_LIT>" : self . nchildren ** <NUM_LIT:2> , <EOL> "<STR_LIT>" : self . nchildren ** <NUM_LIT:2> , <EOL> "<STR_LIT>" : self . nchildren ** <NUM_LIT:2> , <EOL> "<STR_LIT>" : self . nchildren ** <NUM_LIT:2> , <EOL> "<STR_LIT>" : self . nchildren , "<STR_LIT>" : self . nchildren , <EOL> "<STR_LIT>" : self . nchildren } <EOL> self . assertEqual ( self . targobj . size , targ1 ) <EOL> def test__filter_none ( self ) : <EOL> targ = [ ] <EOL> res0 = self . targobj . filter ( ) <EOL> res1 = self . targobj . filter ( { } ) <EOL> res2 = self . targobj . filter ( [ ] ) <EOL> res3 = self . targobj . filter ( [ { } ] ) <EOL> res4 = self . targobj . filter ( [ { } , { } ] ) <EOL> res5 = self . targobj . filter ( [ { } , { } ] ) <EOL> res6 = self . targobj . filter ( targdict = { } ) <EOL> res7 = self . targobj . filter ( targdict = [ ] ) <EOL> res8 = self . targobj . filter ( targdict = [ { } ] ) <EOL> res9 = self . targobj . filter ( targdict = [ { } , { } ] ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> assert_same_sub_schema ( res1 , targ ) <EOL> assert_same_sub_schema ( res2 , targ ) <EOL> assert_same_sub_schema ( res3 , targ ) <EOL> assert_same_sub_schema ( res4 , targ ) <EOL> assert_same_sub_schema ( res5 , targ ) <EOL> assert_same_sub_schema ( res6 , targ ) <EOL> assert_same_sub_schema ( res7 , targ ) <EOL> assert_same_sub_schema ( res8 , targ ) <EOL> assert_same_sub_schema ( res9 , targ ) <EOL> def test__filter_annotation_single ( self ) : <EOL> targ = ( self . sigs1a + self . sigarrs1a + <EOL> [ self . epcs1a [ <NUM_LIT:0> ] , self . epcas1a [ <NUM_LIT:0> ] ] + <EOL> [ self . evts1a [ <NUM_LIT:0> ] , self . evtas1a [ <NUM_LIT:0> ] ] + <EOL> self . irsigs1a + <EOL> self . spikes1a + self . trains1a ) <EOL> res0 = self . targobj . filter ( j = <NUM_LIT:0> ) <EOL> res1 = self . targobj . filter ( { '<STR_LIT>' : <NUM_LIT:0> } ) <EOL> res2 = self . targobj . filter ( targdict = { '<STR_LIT>' : <NUM_LIT:0> } ) <EOL> res3 = self . targobj . filter ( [ { '<STR_LIT>' : <NUM_LIT:0> } ] ) <EOL> res4 = self . targobj . filter ( targdict = [ { '<STR_LIT>' : <NUM_LIT:0> } ] ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> assert_same_sub_schema ( res1 , targ ) <EOL> assert_same_sub_schema ( res2 , targ ) <EOL> assert_same_sub_schema ( res3 , targ ) <EOL> assert_same_sub_schema ( res4 , targ ) <EOL> def test__filter_single_annotation_nores ( self ) : <EOL> targ = [ ] <EOL> res0 = self . targobj . filter ( j = <NUM_LIT:5> ) <EOL> res1 = self . targobj . filter ( { '<STR_LIT>' : <NUM_LIT:5> } ) <EOL> res2 = self . targobj . filter ( targdict = { '<STR_LIT>' : <NUM_LIT:5> } ) <EOL> res3 = self . targobj . filter ( [ { '<STR_LIT>' : <NUM_LIT:5> } ] ) <EOL> res4 = self . targobj . filter ( targdict = [ { '<STR_LIT>' : <NUM_LIT:5> } ] ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> assert_same_sub_schema ( res1 , targ ) <EOL> assert_same_sub_schema ( res2 , targ ) <EOL> assert_same_sub_schema ( res3 , targ ) <EOL> assert_same_sub_schema ( res4 , targ ) <EOL> def test__filter_attribute_single ( self ) : <EOL> targ = [ self . epcs1a [ <NUM_LIT:1> ] ] <EOL> res0 = self . targobj . filter ( name = self . epcs1a [ <NUM_LIT:1> ] . name ) <EOL> res1 = self . targobj . filter ( { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name } ) <EOL> res2 = self . targobj . filter ( targdict = { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name } ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> assert_same_sub_schema ( res1 , targ ) <EOL> assert_same_sub_schema ( res2 , targ ) <EOL> def test__filter_attribute_single_nores ( self ) : <EOL> targ = [ ] <EOL> res0 = self . targobj . filter ( name = self . epcs2 [ <NUM_LIT:0> ] . name ) <EOL> res1 = self . targobj . filter ( { '<STR_LIT:name>' : self . epcs2 [ <NUM_LIT:0> ] . name } ) <EOL> res2 = self . targobj . filter ( targdict = { '<STR_LIT:name>' : self . epcs2 [ <NUM_LIT:0> ] . name } ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> assert_same_sub_schema ( res1 , targ ) <EOL> assert_same_sub_schema ( res2 , targ ) <EOL> def test__filter_multi ( self ) : <EOL> targ = ( self . sigs1a + self . sigarrs1a + <EOL> [ self . epcs1a [ <NUM_LIT:0> ] , self . epcas1a [ <NUM_LIT:0> ] ] + <EOL> [ self . evts1a [ <NUM_LIT:0> ] , self . evtas1a [ <NUM_LIT:0> ] ] + <EOL> self . irsigs1a + <EOL> self . spikes1a + self . trains1a + <EOL> [ self . epcs1a [ <NUM_LIT:1> ] ] ) <EOL> res0 = self . targobj . filter ( name = self . epcs1a [ <NUM_LIT:1> ] . name , j = <NUM_LIT:0> ) <EOL> res1 = self . targobj . filter ( { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name , '<STR_LIT>' : <NUM_LIT:0> } ) <EOL> res2 = self . targobj . filter ( targdict = { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name , <EOL> '<STR_LIT>' : <NUM_LIT:0> } ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> assert_same_sub_schema ( res1 , targ ) <EOL> assert_same_sub_schema ( res2 , targ ) <EOL> def test__filter_multi_nores ( self ) : <EOL> targ = [ ] <EOL> res0 = self . targobj . filter ( [ { '<STR_LIT>' : <NUM_LIT:0> } , { } ] ) <EOL> res1 = self . targobj . filter ( { } , ttype = <NUM_LIT:0> ) <EOL> res2 = self . targobj . filter ( [ { } ] , ttype = <NUM_LIT:0> ) <EOL> res3 = self . targobj . filter ( { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name } , j = <NUM_LIT:0> ) <EOL> res4 = self . targobj . filter ( targdict = { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name } , <EOL> j = <NUM_LIT:0> ) <EOL> res5 = self . targobj . filter ( name = self . epcs1a [ <NUM_LIT:1> ] . name , <EOL> targdict = { '<STR_LIT>' : <NUM_LIT:0> } ) <EOL> res6 = self . targobj . filter ( name = self . epcs2 [ <NUM_LIT:0> ] . name , j = <NUM_LIT:5> ) <EOL> res7 = self . targobj . filter ( { '<STR_LIT:name>' : self . epcs2 [ <NUM_LIT:1> ] . name , '<STR_LIT>' : <NUM_LIT:5> } ) <EOL> res8 = self . targobj . filter ( targdict = { '<STR_LIT:name>' : self . epcs2 [ <NUM_LIT:1> ] . name , <EOL> '<STR_LIT>' : <NUM_LIT:5> } ) <EOL> res9 = self . targobj . filter ( { '<STR_LIT:name>' : self . epcs2 [ <NUM_LIT:1> ] . name } , j = <NUM_LIT:5> ) <EOL> res10 = self . targobj . filter ( targdict = { '<STR_LIT:name>' : self . epcs2 [ <NUM_LIT:1> ] . name } , <EOL> j = <NUM_LIT:5> ) <EOL> res11 = self . targobj . filter ( name = self . epcs2 [ <NUM_LIT:1> ] . name , <EOL> targdict = { '<STR_LIT>' : <NUM_LIT:5> } ) <EOL> res12 = self . targobj . filter ( { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name } , j = <NUM_LIT:5> ) <EOL> res13 = self . targobj . filter ( targdict = { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name } , <EOL> j = <NUM_LIT:5> ) <EOL> res14 = self . targobj . filter ( name = self . epcs1a [ <NUM_LIT:1> ] . name , <EOL> targdict = { '<STR_LIT>' : <NUM_LIT:5> } ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> assert_same_sub_schema ( res1 , targ ) <EOL> assert_same_sub_schema ( res2 , targ ) <EOL> assert_same_sub_schema ( res3 , targ ) <EOL> assert_same_sub_schema ( res4 , targ ) <EOL> assert_same_sub_schema ( res5 , targ ) <EOL> assert_same_sub_schema ( res6 , targ ) <EOL> assert_same_sub_schema ( res7 , targ ) <EOL> assert_same_sub_schema ( res8 , targ ) <EOL> assert_same_sub_schema ( res9 , targ ) <EOL> assert_same_sub_schema ( res10 , targ ) <EOL> assert_same_sub_schema ( res11 , targ ) <EOL> assert_same_sub_schema ( res12 , targ ) <EOL> assert_same_sub_schema ( res13 , targ ) <EOL> assert_same_sub_schema ( res14 , targ ) <EOL> def test__filter_multi_partres ( self ) : <EOL> targ = [ self . epcs1a [ <NUM_LIT:1> ] ] <EOL> res0 = self . targobj . filter ( name = self . epcs1a [ <NUM_LIT:1> ] . name , j = <NUM_LIT:5> ) <EOL> res1 = self . targobj . filter ( { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name , '<STR_LIT>' : <NUM_LIT:5> } ) <EOL> res2 = self . targobj . filter ( targdict = { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name , <EOL> '<STR_LIT>' : <NUM_LIT:5> } ) <EOL> res3 = self . targobj . filter ( [ { '<STR_LIT>' : <NUM_LIT:1> } , { '<STR_LIT:i>' : <NUM_LIT:2> } ] ) <EOL> res4 = self . targobj . filter ( { '<STR_LIT>' : <NUM_LIT:1> } , i = <NUM_LIT:2> ) <EOL> res5 = self . targobj . filter ( [ { '<STR_LIT>' : <NUM_LIT:1> } ] , i = <NUM_LIT:2> ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> assert_same_sub_schema ( res1 , targ ) <EOL> assert_same_sub_schema ( res2 , targ ) <EOL> assert_same_sub_schema ( res3 , targ ) <EOL> assert_same_sub_schema ( res4 , targ ) <EOL> assert_same_sub_schema ( res5 , targ ) <EOL> def test__filter_single_annotation_obj_single ( self ) : <EOL> targ = [ self . epcs1a [ <NUM_LIT:1> ] ] <EOL> res0 = self . targobj . filter ( j = <NUM_LIT:1> , objects = '<STR_LIT>' ) <EOL> res1 = self . targobj . filter ( j = <NUM_LIT:1> , objects = Epoch ) <EOL> res2 = self . targobj . filter ( j = <NUM_LIT:1> , objects = [ '<STR_LIT>' ] ) <EOL> res3 = self . targobj . filter ( j = <NUM_LIT:1> , objects = [ Epoch ] ) <EOL> res4 = self . targobj . filter ( j = <NUM_LIT:1> , objects = [ Epoch , <EOL> RecordingChannelGroup ] ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> assert_same_sub_schema ( res1 , targ ) <EOL> assert_same_sub_schema ( res2 , targ ) <EOL> assert_same_sub_schema ( res3 , targ ) <EOL> assert_same_sub_schema ( res4 , targ ) <EOL> def test__filter_single_annotation_obj_multi ( self ) : <EOL> targ = [ self . epcs1a [ <NUM_LIT:1> ] , self . epcas1a [ <NUM_LIT:1> ] ] <EOL> res0 = self . targobj . filter ( j = <NUM_LIT:1> , objects = [ '<STR_LIT>' , EpochArray ] ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> def test__filter_single_annotation_obj_none ( self ) : <EOL> targ = [ ] <EOL> res0 = self . targobj . filter ( j = <NUM_LIT:1> , objects = RecordingChannelGroup ) <EOL> res1 = self . targobj . filter ( j = <NUM_LIT:1> , objects = '<STR_LIT>' ) <EOL> res2 = self . targobj . filter ( j = <NUM_LIT:1> , objects = [ ] ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> assert_same_sub_schema ( res1 , targ ) <EOL> assert_same_sub_schema ( res2 , targ ) <EOL> def test__filter_single_annotation_norecur ( self ) : <EOL> targ = [ self . epcs1a [ <NUM_LIT:1> ] , self . epcas1a [ <NUM_LIT:1> ] , <EOL> self . evts1a [ <NUM_LIT:1> ] , self . evtas1a [ <NUM_LIT:1> ] ] <EOL> res0 = self . targobj . filter ( j = <NUM_LIT:1> , <EOL> recursive = False ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> def test__filter_single_attribute_norecur ( self ) : <EOL> targ = [ self . epcs1a [ <NUM_LIT:1> ] ] <EOL> res0 = self . targobj . filter ( name = self . epcs1a [ <NUM_LIT:1> ] . name , <EOL> recursive = False ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> def test__filter_single_annotation_nodata ( self ) : <EOL> targ = [ ] <EOL> res0 = self . targobj . filter ( j = <NUM_LIT:0> , <EOL> data = False ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> def test__filter_single_attribute_nodata ( self ) : <EOL> targ = [ ] <EOL> res0 = self . targobj . filter ( name = self . epcs1a [ <NUM_LIT:1> ] . name , <EOL> data = False ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> def test__filter_single_annotation_nodata_norecur ( self ) : <EOL> targ = [ ] <EOL> res0 = self . targobj . filter ( j = <NUM_LIT:0> , <EOL> data = False , recursive = False ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> def test__filter_single_attribute_nodata_norecur ( self ) : <EOL> targ = [ ] <EOL> res0 = self . targobj . filter ( name = self . epcs1a [ <NUM_LIT:1> ] . name , <EOL> data = False , recursive = False ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> def test__filter_single_annotation_container ( self ) : <EOL> targ = [ self . epcs1a [ <NUM_LIT:1> ] , self . epcas1a [ <NUM_LIT:1> ] , <EOL> self . evts1a [ <NUM_LIT:1> ] , self . evtas1a [ <NUM_LIT:1> ] ] <EOL> res0 = self . targobj . filter ( j = <NUM_LIT:1> , <EOL> container = True ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> def test__filter_single_attribute_container ( self ) : <EOL> targ = [ self . epcs1a [ <NUM_LIT:1> ] ] <EOL> res0 = self . targobj . filter ( name = self . epcs1a [ <NUM_LIT:1> ] . name , <EOL> container = True ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> def test__filter_single_annotation_container_norecur ( self ) : <EOL> targ = [ self . epcs1a [ <NUM_LIT:1> ] , self . epcas1a [ <NUM_LIT:1> ] , <EOL> self . evts1a [ <NUM_LIT:1> ] , self . evtas1a [ <NUM_LIT:1> ] ] <EOL> res0 = self . targobj . filter ( j = <NUM_LIT:1> , <EOL> container = True , recursive = False ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> def test__filter_single_attribute_container_norecur ( self ) : <EOL> targ = [ self . epcs1a [ <NUM_LIT:1> ] ] <EOL> res0 = self . targobj . filter ( name = self . epcs1a [ <NUM_LIT:1> ] . name , <EOL> container = True , recursive = False ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> def test__filter_single_annotation_nodata_container ( self ) : <EOL> targ = [ ] <EOL> res0 = self . targobj . filter ( j = <NUM_LIT:0> , <EOL> data = False , container = True ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> def test__filter_single_attribute_nodata_container ( self ) : <EOL> targ = [ ] <EOL> res0 = self . targobj . filter ( name = self . epcs1a [ <NUM_LIT:1> ] . name , <EOL> data = False , container = True ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> def test__filter_single_annotation_nodata_container_norecur ( self ) : <EOL> targ = [ ] <EOL> res0 = self . targobj . filter ( j = <NUM_LIT:0> , <EOL> data = False , container = True , <EOL> recursive = False ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> def test__filter_single_attribute_nodata_container_norecur ( self ) : <EOL> targ = [ ] <EOL> res0 = self . targobj . filter ( name = self . epcs1a [ <NUM_LIT:1> ] . name , <EOL> data = False , container = True , <EOL> recursive = False ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> data = self . targobj . children_recur <EOL> targ = ( self . sigs1a + self . sigarrs1a + <EOL> [ self . epcs1a [ <NUM_LIT:0> ] , self . epcas1a [ <NUM_LIT:0> ] ] + <EOL> [ self . evts1a [ <NUM_LIT:0> ] , self . evtas1a [ <NUM_LIT:0> ] ] + <EOL> self . irsigs1a + <EOL> self . spikes1a + self . trains1a + <EOL> [ self . epcs1a [ <NUM_LIT:1> ] ] ) <EOL> res0 = filterdata ( data , name = self . epcs1a [ <NUM_LIT:1> ] . name , j = <NUM_LIT:0> ) <EOL> res1 = filterdata ( data , { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name , '<STR_LIT>' : <NUM_LIT:0> } ) <EOL> res2 = filterdata ( data , targdict = { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name , '<STR_LIT>' : <NUM_LIT:0> } ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> assert_same_sub_schema ( res1 , targ ) <EOL> assert_same_sub_schema ( res2 , targ ) <EOL> def test__filterdata_multi_nores ( self ) : <EOL> data = self . targobj . children_recur <EOL> targ = [ ] <EOL> res0 = filterdata ( data , [ { '<STR_LIT>' : <NUM_LIT:0> } , { } ] ) <EOL> res1 = filterdata ( data , { } , ttype = <NUM_LIT:0> ) <EOL> res2 = filterdata ( data , [ { } ] , ttype = <NUM_LIT:0> ) <EOL> res3 = filterdata ( data , { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name } , j = <NUM_LIT:0> ) <EOL> res4 = filterdata ( data , targdict = { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name } , j = <NUM_LIT:0> ) <EOL> res5 = filterdata ( data , name = self . epcs1a [ <NUM_LIT:1> ] . name , targdict = { '<STR_LIT>' : <NUM_LIT:0> } ) <EOL> res6 = filterdata ( data , name = self . epcs2 [ <NUM_LIT:0> ] . name , j = <NUM_LIT:5> ) <EOL> res7 = filterdata ( data , { '<STR_LIT:name>' : self . epcs2 [ <NUM_LIT:1> ] . name , '<STR_LIT>' : <NUM_LIT:5> } ) <EOL> res8 = filterdata ( data , targdict = { '<STR_LIT:name>' : self . epcs2 [ <NUM_LIT:1> ] . name , '<STR_LIT>' : <NUM_LIT:5> } ) <EOL> res9 = filterdata ( data , { '<STR_LIT:name>' : self . epcs2 [ <NUM_LIT:1> ] . name } , j = <NUM_LIT:5> ) <EOL> res10 = filterdata ( data , targdict = { '<STR_LIT:name>' : self . epcs2 [ <NUM_LIT:1> ] . name } , j = <NUM_LIT:5> ) <EOL> res11 = filterdata ( data , name = self . epcs2 [ <NUM_LIT:1> ] . name , targdict = { '<STR_LIT>' : <NUM_LIT:5> } ) <EOL> res12 = filterdata ( data , { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name } , j = <NUM_LIT:5> ) <EOL> res13 = filterdata ( data , targdict = { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name } , j = <NUM_LIT:5> ) <EOL> res14 = filterdata ( data , name = self . epcs1a [ <NUM_LIT:1> ] . name , targdict = { '<STR_LIT>' : <NUM_LIT:5> } ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> assert_same_sub_schema ( res1 , targ ) <EOL> assert_same_sub_schema ( res2 , targ ) <EOL> assert_same_sub_schema ( res3 , targ ) <EOL> assert_same_sub_schema ( res4 , targ ) <EOL> assert_same_sub_schema ( res5 , targ ) <EOL> assert_same_sub_schema ( res6 , targ ) <EOL> assert_same_sub_schema ( res7 , targ ) <EOL> assert_same_sub_schema ( res8 , targ ) <EOL> assert_same_sub_schema ( res9 , targ ) <EOL> assert_same_sub_schema ( res10 , targ ) <EOL> assert_same_sub_schema ( res11 , targ ) <EOL> assert_same_sub_schema ( res12 , targ ) <EOL> assert_same_sub_schema ( res13 , targ ) <EOL> assert_same_sub_schema ( res14 , targ ) <EOL> def test__filterdata_multi_partres ( self ) : <EOL> data = self . targobj . children_recur <EOL> targ = [ self . epcs1a [ <NUM_LIT:1> ] ] <EOL> res0 = filterdata ( data , name = self . epcs1a [ <NUM_LIT:1> ] . name , j = <NUM_LIT:5> ) <EOL> res1 = filterdata ( data , { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name , '<STR_LIT>' : <NUM_LIT:5> } ) <EOL> res2 = filterdata ( data , targdict = { '<STR_LIT:name>' : self . epcs1a [ <NUM_LIT:1> ] . name , '<STR_LIT>' : <NUM_LIT:5> } ) <EOL> res3 = filterdata ( data , [ { '<STR_LIT>' : <NUM_LIT:1> } , { '<STR_LIT:i>' : <NUM_LIT:2> } ] ) <EOL> res4 = filterdata ( data , { '<STR_LIT>' : <NUM_LIT:1> } , i = <NUM_LIT:2> ) <EOL> res5 = filterdata ( data , [ { '<STR_LIT>' : <NUM_LIT:1> } ] , i = <NUM_LIT:2> ) <EOL> assert_same_sub_schema ( res0 , targ ) <EOL> assert_same_sub_schema ( res1 , targ ) <EOL> assert_same_sub_schema ( res2 , targ ) <EOL> assert_same_sub_schema ( res3 , targ ) <EOL> assert_same_sub_schema ( res4 , targ ) <EOL> assert_same_sub_schema ( res5 , targ ) <EOL> @ unittest . skipUnless ( HAVE_IPYTHON , "<STR_LIT>" ) <EOL> def test__pretty ( self ) : <EOL> ann = get_annotations ( ) <EOL> ann [ '<STR_LIT>' ] = self . seed1 <EOL> ann = pretty ( ann ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> res = pretty ( self . seg1 ) <EOL> sig0 = pretty ( self . sigs1 [ <NUM_LIT:0> ] ) <EOL> sig1 = pretty ( self . sigs1 [ <NUM_LIT:1> ] ) <EOL> sig2 = pretty ( self . sigs1 [ <NUM_LIT:2> ] ) <EOL> sig3 = pretty ( self . sigs1 [ <NUM_LIT:3> ] ) <EOL> sig0 = sig0 . replace ( '<STR_LIT:\n>' , '<STR_LIT>' ) <EOL> sig1 = sig1 . replace ( '<STR_LIT:\n>' , '<STR_LIT>' ) <EOL> sig2 = sig2 . replace ( '<STR_LIT:\n>' , '<STR_LIT>' ) <EOL> sig3 = sig3 . replace ( '<STR_LIT:\n>' , '<STR_LIT>' ) <EOL> sigarr0 = pretty ( self . sigarrs1 [ <NUM_LIT:0> ] ) <EOL> sigarr1 = pretty ( self . sigarrs1 [ <NUM_LIT:1> ] ) <EOL> sigarr0 = sigarr0 . replace ( '<STR_LIT:\n>' , '<STR_LIT>' ) <EOL> sigarr1 = sigarr1 . replace ( '<STR_LIT:\n>' , '<STR_LIT>' ) <EOL> targ = ( "<STR_LIT>" + <EOL> ( "<STR_LIT>" % <EOL> ( len ( self . sigs1a ) , len ( self . sigarrs1a ) ) ) + <EOL> ( "<STR_LIT>" % <EOL> ( len ( self . epcs1a ) , len ( self . epcas1a ) ) ) + <EOL> ( "<STR_LIT>" % <EOL> ( len ( self . evts1a ) , len ( self . evtas1a ) ) ) + <EOL> ( "<STR_LIT>" % <EOL> len ( self . irsigs1a ) ) + <EOL> ( "<STR_LIT>" % <EOL> ( len ( self . spikes1a ) , len ( self . trains1a ) ) ) + <EOL> ( "<STR_LIT>" % <EOL> ( self . seg1 . name , self . seg1 . description ) <EOL> ) + <EOL> ( "<STR_LIT>" % ann ) + <EOL> ( "<STR_LIT>" % len ( self . sigs1a ) ) + <EOL> ( '<STR_LIT>' % ( <NUM_LIT:0> , sig0 ) ) + <EOL> ( '<STR_LIT>' % ( <NUM_LIT:1> , sig1 ) ) + <EOL> ( '<STR_LIT>' % ( <NUM_LIT:2> , sig2 ) ) + <EOL> ( '<STR_LIT>' % ( <NUM_LIT:3> , sig3 ) ) + <EOL> ( "<STR_LIT>" % len ( self . sigarrs1a ) ) + <EOL> ( '<STR_LIT>' % ( <NUM_LIT:0> , sigarr0 ) ) + <EOL> ( '<STR_LIT>' % ( <NUM_LIT:1> , sigarr1 ) ) ) <EOL> self . assertEqual ( res , targ ) <EOL> def test__construct_subsegment_by_unit ( self ) : <EOL> nb_seg = <NUM_LIT:3> <EOL> nb_unit = <NUM_LIT:7> <EOL> unit_with_sig = np . array ( [ <NUM_LIT:0> , <NUM_LIT:2> , <NUM_LIT:5> ] ) <EOL> signal_types = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> sig_len = <NUM_LIT:100> <EOL> rcgs = [ RecordingChannelGroup ( name = '<STR_LIT>' , <EOL> channel_indexes = unit_with_sig ) , <EOL> RecordingChannelGroup ( name = '<STR_LIT>' , <EOL> channel_indexes = unit_with_sig ) ] <EOL> all_unit = [ ] <EOL> for u in range ( nb_unit ) : <EOL> un = Unit ( name = '<STR_LIT>' % u , channel_indexes = np . array ( [ u ] ) ) <EOL> assert_neo_object_is_compliant ( un ) <EOL> all_unit . append ( un ) <EOL> blk = Block ( ) <EOL> blk . recordingchannelgroups = rcgs <EOL> for s in range ( nb_seg ) : <EOL> seg = Segment ( name = '<STR_LIT>' % s ) <EOL> for j in range ( nb_unit ) : <EOL> st = SpikeTrain ( [ <NUM_LIT:1> , <NUM_LIT:2> ] , units = '<STR_LIT>' , <EOL> t_start = <NUM_LIT:0.> , t_stop = <NUM_LIT:10> ) <EOL> st . unit = all_unit [ j ] <EOL> for t in signal_types : <EOL> anasigarr = AnalogSignalArray ( np . zeros ( ( sig_len , <EOL> len ( unit_with_sig ) ) ) , <EOL> units = '<STR_LIT>' , <EOL> sampling_rate = <NUM_LIT> * pq . Hz , <EOL> channel_indexes = unit_with_sig ) <EOL> seg . analogsignalarrays . append ( anasigarr ) <EOL> blk . create_many_to_one_relationship ( ) <EOL> for unit in all_unit : <EOL> assert_neo_object_is_compliant ( unit ) <EOL> for rcg in rcgs : <EOL> assert_neo_object_is_compliant ( rcg ) <EOL> assert_neo_object_is_compliant ( blk ) <EOL> newseg = seg . construct_subsegment_by_unit ( all_unit [ : <NUM_LIT:4> ] ) <EOL> assert_neo_object_is_compliant ( newseg ) <EOL> def test_segment_take_spikes_by_unit ( self ) : <EOL> result1 = self . seg1 . take_spikes_by_unit ( ) <EOL> result21 = self . seg1 . take_spikes_by_unit ( [ self . unit1 ] ) <EOL> result22 = self . seg1 . take_spikes_by_unit ( [ self . unit2 ] ) <EOL> self . assertEqual ( result1 , [ ] ) <EOL> assert_same_sub_schema ( result21 , [ self . spikes1a [ <NUM_LIT:0> ] ] ) <EOL> assert_same_sub_schema ( result22 , [ self . spikes1a [ <NUM_LIT:1> ] ] ) <EOL> def test_segment_take_spiketrains_by_unit ( self ) : <EOL> result1 = self . seg1 . take_spiketrains_by_unit ( ) <EOL> result21 = self . seg1 . take_spiketrains_by_unit ( [ self . unit1 ] ) <EOL> result22 = self . seg1 . take_spiketrains_by_unit ( [ self . unit2 ] ) <EOL> self . assertEqual ( result1 , [ ] ) <EOL> assert_same_sub_schema ( result21 , [ self . trains1a [ <NUM_LIT:0> ] ] ) <EOL> assert_same_sub_schema ( result22 , [ self . trains1a [ <NUM_LIT:1> ] ] ) <EOL> def test_segment_take_analogsignal_by_unit ( self ) : <EOL> result1 = self . seg1 . take_analogsignal_by_unit ( ) <EOL> result21 = self . seg1 . take_analogsignal_by_unit ( [ self . unit1 ] ) <EOL> result22 = self . seg1 . take_analogsignal_by_unit ( [ self . unit2 ] ) <EOL> self . assertEqual ( result1 , [ ] ) <EOL> assert_same_sub_schema ( result21 , [ self . sigs1a [ <NUM_LIT:0> ] ] ) <EOL> assert_same_sub_schema ( result22 , [ self . sigs1a [ <NUM_LIT:1> ] ] ) <EOL> def test_segment_take_analogsignal_by_channelindex ( self ) : <EOL> ind1 = self . unit1 . channel_indexes [ <NUM_LIT:0> ] <EOL> ind2 = self . unit2 . channel_indexes [ <NUM_LIT:0> ] <EOL> result1 = self . seg1 . take_analogsignal_by_channelindex ( ) <EOL> result21 = self . seg1 . take_analogsignal_by_channelindex ( [ ind1 ] ) <EOL> result22 = self . seg1 . take_analogsignal_by_channelindex ( [ ind2 ] ) <EOL> self . assertEqual ( result1 , [ ] ) <EOL> assert_same_sub_schema ( result21 , [ self . sigs1a [ <NUM_LIT:0> ] ] ) <EOL> assert_same_sub_schema ( result22 , [ self . sigs1a [ <NUM_LIT:1> ] ] ) <EOL> def test_seg_take_slice_of_analogsignalarray_by_unit ( self ) : <EOL> seg = self . seg1 <EOL> result1 = seg . take_slice_of_analogsignalarray_by_unit ( ) <EOL> result21 = seg . take_slice_of_analogsignalarray_by_unit ( [ self . unit1 ] ) <EOL> result23 = seg . take_slice_of_analogsignalarray_by_unit ( [ self . unit3 ] ) <EOL> self . assertEqual ( result1 , [ ] ) <EOL> targ1 = [ self . sigarrs1a [ <NUM_LIT:0> ] [ : , np . array ( [ True ] ) ] , <EOL> self . sigarrs1a [ <NUM_LIT:1> ] [ : , np . array ( [ False ] ) ] ] <EOL> targ3 = [ self . sigarrs1a [ <NUM_LIT:0> ] [ : , np . array ( [ False ] ) ] , <EOL> self . sigarrs1a [ <NUM_LIT:1> ] [ : , np . array ( [ True ] ) ] ] <EOL> assert_same_sub_schema ( result21 , targ1 ) <EOL> assert_same_sub_schema ( result23 , targ3 ) <EOL> def test_seg_take_slice_of_analogsignalarray_by_channelindex ( self ) : <EOL> seg = self . seg1 <EOL> ind1 = self . unit1 . channel_indexes [ <NUM_LIT:0> ] <EOL> ind3 = self . unit3 . channel_indexes [ <NUM_LIT:0> ] <EOL> result1 = seg . take_slice_of_analogsignalarray_by_channelindex ( ) <EOL> result21 = seg . take_slice_of_analogsignalarray_by_channelindex ( [ ind1 ] ) <EOL> result23 = seg . take_slice_of_analogsignalarray_by_channelindex ( [ ind3 ] ) <EOL> self . assertEqual ( result1 , [ ] ) <EOL> targ1 = [ self . sigarrs1a [ <NUM_LIT:0> ] [ : , np . array ( [ True ] ) ] , <EOL> self . sigarrs1a [ <NUM_LIT:1> ] [ : , np . array ( [ False ] ) ] ] <EOL> targ3 = [ self . sigarrs1a [ <NUM_LIT:0> ] [ : , np . array ( [ False ] ) ] , <EOL> self . sigarrs1a [ <NUM_LIT:1> ] [ : , np . array ( [ True ] ) ] ] <EOL> assert_same_sub_schema ( result21 , targ1 ) <EOL> assert_same_sub_schema ( result23 , targ3 ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> """<STR_LIT>""" <EOL> from __future__ import absolute_import , division <EOL> try : <EOL> import unittest2 as unittest <EOL> except ImportError : <EOL> import unittest <EOL> from neo . io import NeuroScopeIO <EOL> from neo . test . iotest . common_io_test import BaseTestIO <EOL> class TestNeuroScopeIO ( BaseTestIO , unittest . TestCase , ) : <EOL> ioclass = NeuroScopeIO <EOL> files_to_test = [ '<STR_LIT>' ] <EOL> files_to_download = [ '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> ] <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> from django . http import HttpResponseRedirect <EOL> from neurovault . apps . statmaps . utils import HttpRedirectException <EOL> class CollectionRedirectMiddleware : <EOL> def process_exception ( self , request , exception ) : <EOL> if isinstance ( exception , HttpRedirectException ) : <EOL> return HttpResponseRedirect ( exception . args [ <NUM_LIT:0> ] ) </s>
<s> from __future__ import unicode_literals <EOL> from django . db import models , migrations <EOL> import json , os <EOL> dir = os . path . abspath ( os . path . dirname ( __file__ ) ) <EOL> def populate_cogatlas ( apps , schema_editor ) : <EOL> CognitiveAtlasTask = apps . get_model ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> CognitiveAtlasContrast = apps . get_model ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> json_content = open ( os . path . join ( dir , "<STR_LIT>" ) ) . read ( ) <EOL> json_content = json_content . decode ( "<STR_LIT:utf-8>" ) . replace ( '<STR_LIT:\t>' , '<STR_LIT>' ) <EOL> data = json . loads ( json_content ) <EOL> for item in data : <EOL> task = CognitiveAtlasTask ( name = item [ "<STR_LIT:name>" ] , cog_atlas_id = item [ "<STR_LIT:id>" ] ) <EOL> task . save ( ) <EOL> for contrast in item [ "<STR_LIT>" ] : <EOL> contrast = CognitiveAtlasContrast ( name = contrast [ "<STR_LIT>" ] , cog_atlas_id = contrast [ "<STR_LIT>" ] , task = task ) <EOL> contrast . save ( ) <EOL> class Migration ( migrations . Migration ) : <EOL> dependencies = [ <EOL> ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> ] <EOL> operations = [ <EOL> migrations . RunPython ( populate_cogatlas ) , <EOL> ] </s>
<s> from __future__ import unicode_literals <EOL> from django . db import models , migrations <EOL> class Migration ( migrations . Migration ) : <EOL> dependencies = [ <EOL> ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> ] <EOL> operations = [ <EOL> ] </s>
<s> import os . path <EOL> from django . contrib . auth . models import User <EOL> from django . core . files . uploadedfile import SimpleUploadedFile <EOL> from django . test import TestCase , Client <EOL> from neurovault . apps . statmaps . forms import NIDMResultsForm <EOL> from neurovault . apps . statmaps . models import Collection , StatisticMap , Comparison <EOL> from neurovault . apps . statmaps . utils import count_processing_comparisons , count_existing_comparisons <EOL> from . utils import clearDB <EOL> class Test_Counter ( TestCase ) : <EOL> def setUp ( self ) : <EOL> print "<STR_LIT>" <EOL> self . test_path = os . path . abspath ( os . path . dirname ( __file__ ) ) <EOL> self . user = User . objects . create ( username = '<STR_LIT>' ) <EOL> self . client = Client ( ) <EOL> self . client . login ( username = self . user ) <EOL> self . Collection1 = Collection ( name = '<STR_LIT>' , owner = self . user , <EOL> DOI = '<STR_LIT>' ) <EOL> self . Collection1 . save ( ) <EOL> self . Collection2 = Collection ( name = '<STR_LIT>' , owner = self . user , <EOL> DOI = '<STR_LIT>' ) <EOL> self . Collection2 . save ( ) <EOL> self . Collection3 = Collection ( name = '<STR_LIT>' , owner = self . user , <EOL> DOI = '<STR_LIT>' ) <EOL> self . Collection3 . save ( ) <EOL> def tearDown ( self ) : <EOL> clearDB ( ) <EOL> def test_statmaps_processing ( self ) : <EOL> print "<STR_LIT>" <EOL> Image1 = StatisticMap ( name = '<STR_LIT>' , collection = self . Collection1 , file = '<STR_LIT>' , map_type = "<STR_LIT>" ) <EOL> Image1 . file = SimpleUploadedFile ( '<STR_LIT>' , file ( os . path . join ( self . test_path , '<STR_LIT>' ) ) . read ( ) ) <EOL> Image1 . save ( ) <EOL> images_processing = count_processing_comparisons ( Image1 . pk ) <EOL> print "<STR_LIT>" % ( images_processing ) <EOL> self . assertEqual ( images_processing , <NUM_LIT:0> ) <EOL> Image2 = StatisticMap ( name = '<STR_LIT>' , collection = self . Collection2 , file = '<STR_LIT>' , map_type = "<STR_LIT>" ) <EOL> Image2 . file = SimpleUploadedFile ( '<STR_LIT>' , file ( os . path . join ( self . test_path , '<STR_LIT>' ) ) . read ( ) ) <EOL> Image2 . save ( ) <EOL> images_processing = count_processing_comparisons ( Image1 . pk ) <EOL> print "<STR_LIT>" % ( images_processing ) <EOL> self . assertEqual ( images_processing , <NUM_LIT:0> ) <EOL> total_comparisons = count_existing_comparisons ( Image1 . pk ) <EOL> self . assertEqual ( total_comparisons , <NUM_LIT:1> ) <EOL> def test_adding_nidm ( self ) : <EOL> Image2 = StatisticMap ( name = '<STR_LIT>' , collection = self . Collection1 , file = '<STR_LIT>' , map_type = "<STR_LIT>" ) <EOL> Image2 . file = SimpleUploadedFile ( '<STR_LIT>' , file ( os . path . join ( self . test_path , '<STR_LIT>' ) ) . read ( ) ) <EOL> Image2 . save ( ) <EOL> zip_file = open ( os . path . join ( self . test_path , '<STR_LIT>' ) , '<STR_LIT:rb>' ) <EOL> post_dict = { <EOL> '<STR_LIT:name>' : '<STR_LIT>' , <EOL> '<STR_LIT:description>' : '<STR_LIT>' . format ( '<STR_LIT>' ) , <EOL> '<STR_LIT>' : self . Collection2 . pk } <EOL> fname = os . path . basename ( os . path . join ( self . test_path , '<STR_LIT>' ) ) <EOL> file_dict = { '<STR_LIT>' : SimpleUploadedFile ( fname , zip_file . read ( ) ) } <EOL> zip_file . close ( ) <EOL> form = NIDMResultsForm ( post_dict , file_dict ) <EOL> nidm = form . save ( ) <EOL> print "<STR_LIT>" <EOL> total_comparisons = count_existing_comparisons ( Image2 . pk ) <EOL> self . assertEqual ( total_comparisons , <NUM_LIT:1> ) <EOL> Image2ss = StatisticMap ( name = '<STR_LIT>' , collection = self . Collection3 , file = '<STR_LIT>' , map_type = "<STR_LIT>" , analysis_level = '<STR_LIT:S>' ) <EOL> Image2ss . file = SimpleUploadedFile ( '<STR_LIT>' , file ( os . path . join ( self . test_path , '<STR_LIT>' ) ) . read ( ) ) <EOL> Image2ss . save ( ) <EOL> total_comparisons = count_existing_comparisons ( Image2ss . pk ) <EOL> self . assertEqual ( total_comparisons , <NUM_LIT:0> ) <EOL> number_comparisons = len ( Comparison . objects . all ( ) ) <EOL> print "<STR_LIT>" % ( number_comparisons ) <EOL> self . assertEqual ( number_comparisons > <NUM_LIT:0> , True ) </s>
<s> """<STR_LIT>""" <EOL> from neurovault . settings import PRIVATE_MEDIA_ROOT <EOL> import os <EOL> import os . path <EOL> from neurovault . apps . statmaps . models import * <EOL> def delOldCollDir ( ) : <EOL> collDir = os . path . join ( PRIVATE_MEDIA_ROOT , '<STR_LIT>' ) <EOL> for folder in os . listdir ( collDir ) : <EOL> if not Collection . objects . filter ( pk = folder ) : <EOL> os . rmdir ( os . path . join ( collDir , folder ) ) <EOL> delOldCollDir ( ) </s>
<s> import theano <EOL> from theano import tensor as T <EOL> from theano . sandbox . rng_mrg import MRG_RandomStreams as RandomStreams <EOL> import numpy as np <EOL> from load import mnist <EOL> srng = RandomStreams ( ) <EOL> def floatX ( X ) : <EOL> return np . asarray ( X , dtype = theano . config . floatX ) <EOL> def init_weights ( shape ) : <EOL> return theano . shared ( floatX ( np . random . randn ( * shape ) * <NUM_LIT> ) ) <EOL> def rectify ( X ) : <EOL> return T . maximum ( X , <NUM_LIT:0.> ) <EOL> def softmax ( X ) : <EOL> e_x = T . exp ( X - X . max ( axis = <NUM_LIT:1> ) . dimshuffle ( <NUM_LIT:0> , '<STR_LIT:x>' ) ) <EOL> return e_x / e_x . sum ( axis = <NUM_LIT:1> ) . dimshuffle ( <NUM_LIT:0> , '<STR_LIT:x>' ) <EOL> def RMSprop ( cost , params , lr = <NUM_LIT> , rho = <NUM_LIT> , epsilon = <NUM_LIT> ) : <EOL> grads = T . grad ( cost = cost , wrt = params ) <EOL> updates = [ ] <EOL> for p , g in zip ( params , grads ) : <EOL> acc = theano . shared ( p . get_value ( ) * <NUM_LIT:0.> ) <EOL> acc_new = rho * acc + ( <NUM_LIT:1> - rho ) * g ** <NUM_LIT:2> <EOL> gradient_scaling = T . sqrt ( acc_new + epsilon ) <EOL> g = g / gradient_scaling <EOL> updates . append ( ( acc , acc_new ) ) <EOL> updates . append ( ( p , p - lr * g ) ) <EOL> return updates <EOL> def dropout ( X , p = <NUM_LIT:0.> ) : <EOL> if p > <NUM_LIT:0> : <EOL> retain_prob = <NUM_LIT:1> - p <EOL> X *= srng . binomial ( X . shape , p = retain_prob , dtype = theano . config . floatX ) <EOL> X /= retain_prob <EOL> return X <EOL> def model ( X , w_h , w_h2 , w_o , p_drop_input , p_drop_hidden ) : <EOL> X = dropout ( X , p_drop_input ) <EOL> h = rectify ( T . dot ( X , w_h ) ) <EOL> h = dropout ( h , p_drop_hidden ) <EOL> h2 = rectify ( T . dot ( h , w_h2 ) ) <EOL> h2 = dropout ( h2 , p_drop_hidden ) <EOL> py_x = softmax ( T . dot ( h2 , w_o ) ) <EOL> return h , h2 , py_x <EOL> trX , teX , trY , teY = mnist ( onehot = True ) <EOL> X = T . fmatrix ( ) <EOL> Y = T . fmatrix ( ) <EOL> w_h = init_weights ( ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> w_h2 = init_weights ( ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> w_o = init_weights ( ( <NUM_LIT> , <NUM_LIT:10> ) ) <EOL> noise_h , noise_h2 , noise_py_x = model ( X , w_h , w_h2 , w_o , <NUM_LIT> , <NUM_LIT:0.5> ) <EOL> h , h2 , py_x = model ( X , w_h , w_h2 , w_o , <NUM_LIT:0.> , <NUM_LIT:0.> ) <EOL> y_x = T . argmax ( py_x , axis = <NUM_LIT:1> ) <EOL> cost = T . mean ( T . nnet . categorical_crossentropy ( noise_py_x , Y ) ) <EOL> params = [ w_h , w_h2 , w_o ] <EOL> updates = RMSprop ( cost , params , lr = <NUM_LIT> ) <EOL> train = theano . function ( inputs = [ X , Y ] , outputs = cost , updates = updates , allow_input_downcast = True ) <EOL> predict = theano . function ( inputs = [ X ] , outputs = y_x , allow_input_downcast = True ) <EOL> for i in range ( <NUM_LIT:100> ) : <EOL> for start , end in zip ( range ( <NUM_LIT:0> , len ( trX ) , <NUM_LIT> ) , range ( <NUM_LIT> , len ( trX ) , <NUM_LIT> ) ) : <EOL> cost = train ( trX [ start : end ] , trY [ start : end ] ) <EOL> print np . mean ( np . argmax ( teY , axis = <NUM_LIT:1> ) == predict ( teX ) ) </s>
<s> """<STR_LIT>""" <EOL> from ndscheduler import settings <EOL> from ndscheduler . core . datastore . providers import base <EOL> class DatastorePostgresql ( base . DatastoreBase ) : <EOL> @ classmethod <EOL> def get_db_url ( cls ) : <EOL> """<STR_LIT>""" <EOL> return '<STR_LIT>' % ( <EOL> settings . DATABASE_CONFIG_DICT [ '<STR_LIT:user>' ] , <EOL> settings . DATABASE_CONFIG_DICT [ '<STR_LIT:password>' ] , <EOL> settings . DATABASE_CONFIG_DICT [ '<STR_LIT>' ] , <EOL> settings . DATABASE_CONFIG_DICT [ '<STR_LIT:port>' ] , <EOL> settings . DATABASE_CONFIG_DICT [ '<STR_LIT>' ] , <EOL> settings . DATABASE_CONFIG_DICT [ '<STR_LIT>' ] ) </s>
<s> """<STR_LIT>""" <EOL> import logging <EOL> import requests <EOL> from ndscheduler import job <EOL> logger = logging . getLogger ( __name__ ) <EOL> class CurlJob ( job . JobBase ) : <EOL> TIMEOUT = <NUM_LIT:10> <EOL> @ classmethod <EOL> def meta_info ( cls ) : <EOL> return { <EOL> '<STR_LIT>' : '<STR_LIT>' % ( cls . __module__ , cls . __name__ ) , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : [ <EOL> { '<STR_LIT:type>' : '<STR_LIT:string>' , '<STR_LIT:description>' : '<STR_LIT>' } , <EOL> { '<STR_LIT:type>' : '<STR_LIT:string>' , '<STR_LIT:description>' : '<STR_LIT>' <EOL> '<STR_LIT>' } , <EOL> ] , <EOL> '<STR_LIT>' : ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> } <EOL> def run ( self , url , request_type , * args , ** kwargs ) : <EOL> print ( '<STR_LIT>' % ( url ) ) <EOL> session = requests . Session ( ) <EOL> result = session . request ( request_type , <EOL> url , <EOL> timeout = self . TIMEOUT , <EOL> headers = None , <EOL> data = None ) <EOL> print ( result . text ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> job = CurlJob . create_test_instance ( ) <EOL> job . run ( '<STR_LIT>' ) </s>
<s> import unittest <EOL> from . mock import MagicMock , Mock <EOL> from . util import TrelloElementMock , CommandMock , OperationMock <EOL> from operations import * <EOL> class BaseOperationTests ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . base_operation , self . trello_element = OperationMock . create ( BaseOperation ) <EOL> self . class_mock , self . instance_mock = OperationMock . instance ( self . base_operation ) <EOL> self . collection = TrelloElementMock . collection ( ) <EOL> self . base_operation . collection = TrelloCollection ( self . collection ) <EOL> def test_items_sets_the_collection ( self ) : <EOL> self . base_operation . set_collection = MagicMock ( ) <EOL> self . base_operation . items ( ) <EOL> self . base_operation . set_collection . assert_called_with ( ) <EOL> def test_items_returns_every_name_from_the_collection_with_the_added_options ( self ) : <EOL> self . base_operation . set_collection = MagicMock ( ) <EOL> self . assertEqual ( self . base_operation . items ( ) , [ "<STR_LIT:..>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] ) <EOL> def test_callback_uses_find_to_instantiate_the_operation_if_the_index_is_in_the_collection ( self ) : <EOL> self . base_operation . callback ( <NUM_LIT:3> ) <EOL> self . class_mock . assert_called_with ( self . collection [ <NUM_LIT:0> ] , self . base_operation ) <EOL> def test_callback_calls_execute_on_the_operation ( self ) : <EOL> self . base_operation . callback ( <NUM_LIT:3> ) <EOL> self . instance_mock . execute . assert_called_with ( self . base_operation . command ) <EOL> def test_callback_doesnt_call_find_if_the_index_is_bigger_than_the_collection_length ( self ) : <EOL> big_index = <NUM_LIT> <EOL> self . base_operation . callback ( big_index ) <EOL> assert not self . class_mock . called <EOL> def test_callback_calls_execute_on_the_previous_operation_if_index_is_0 ( self ) : <EOL> self . base_operation . callback ( <NUM_LIT:0> ) <EOL> self . base_operation . previous_operation . execute . assert_called_with ( ) <EOL> def test_callback_calls_the_input_method_on_the_command_with_deferred_add_as_callback_if_index_is_1 ( self ) : <EOL> self . base_operation . command . input = MagicMock ( ) <EOL> self . base_operation . callback ( <NUM_LIT:2> ) <EOL> self . base_operation . command . input . assert_called_with ( "<STR_LIT:Name>" , self . base_operation . deferred_add ) <EOL> def test_base_add_calls_add_with_the_text_and_cleans_the_cache_for_the_element ( self ) : <EOL> text = "<STR_LIT>" <EOL> self . base_operation . add = MagicMock ( ) <EOL> self . base_operation . trello_element . reload = MagicMock ( ) <EOL> self . base_operation . base_add ( text ) <EOL> self . base_operation . add . assert_called_with ( text ) <EOL> self . trello_element . reload . assert_called_with ( ) <EOL> def test_base_add_calls_add_and_execute_if_renavigate_is_true ( self ) : <EOL> text = "<STR_LIT>" <EOL> self . base_operation . command . renavigate = True <EOL> self . base_operation . execute = MagicMock ( ) <EOL> self . base_operation . base_add ( text ) <EOL> self . base_operation . execute . assert_called_with ( ) <EOL> class BoardOperationTests ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . operation , self . trello_element = OperationMock . create ( BoardOperation ) <EOL> self . operation . collection = TrelloCollection ( TrelloElementMock . collection ( ) ) <EOL> def test_items_returns_every_name_from_the_collection_without_goback ( self ) : <EOL> self . operation . set_collection = MagicMock ( ) <EOL> self . assertEqual ( self . operation . items ( ) , [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] ) <EOL> def test_trello_element_property ( self ) : <EOL> self . assertEqual ( self . operation . trello_element_property ( ) , "<STR_LIT>" ) <EOL> def test_callback_calls_execute_command_with_the_index ( self ) : <EOL> self . operation . execute_command = MagicMock ( ) <EOL> self . operation . callback ( <NUM_LIT:5> ) <EOL> self . operation . execute_command . assert_called_with ( <NUM_LIT:3> ) <EOL> def test_callback_calls_the_input_method_on_the_command_with_deferred_add_as_callback_if_index_is_1 ( self ) : <EOL> self . operation . command . input = MagicMock ( ) <EOL> self . operation . callback ( <NUM_LIT:1> ) <EOL> self . operation . command . input . assert_called_with ( "<STR_LIT:Name>" , self . operation . deferred_add ) <EOL> def test_next_operation_class ( self ) : <EOL> self . assertEqual ( self . operation . next_operation_class ( ) , ListOperation ) <EOL> def test_add_creates_a_board_with_the_text ( self ) : <EOL> text = "<STR_LIT>" <EOL> self . trello_element . add_board = MagicMock ( ) <EOL> self . operation . add ( text ) <EOL> self . trello_element . add_board . assert_called_with ( text ) <EOL> class ListOperationTests ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . operation , self . trello_element = OperationMock . create ( ListOperation ) <EOL> def test_trello_element_property ( self ) : <EOL> self . assertEqual ( self . operation . trello_element_property ( ) , "<STR_LIT>" ) <EOL> def test_next_operation_class ( self ) : <EOL> self . assertEqual ( self . operation . next_operation_class ( ) , CardOperation ) <EOL> def test_add_creates_a_list_with_the_text ( self ) : <EOL> text = "<STR_LIT>" <EOL> self . trello_element . add_list = MagicMock ( ) <EOL> self . operation . add ( text ) <EOL> self . trello_element . add_list . assert_called_with ( text ) <EOL> class CardOperationTests ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . operation , self . trello_element = OperationMock . create ( CardOperation ) <EOL> def test_items_returns_every_name_from_the_collection_with_custom_actions ( self ) : <EOL> self . operation . set_collection = MagicMock ( ) <EOL> self . operation . collection = TrelloCollection ( TrelloElementMock . collection ( ) ) <EOL> self . assertEqual ( self . operation . items ( ) , [ '<STR_LIT:..>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> def test_trello_element_property ( self ) : <EOL> self . assertEqual ( self . operation . trello_element_property ( ) , "<STR_LIT>" ) <EOL> def test_next_operation_class ( self ) : <EOL> self . assertEqual ( self . operation . next_operation_class ( ) , CardOptions ) <EOL> def test_add_creates_a_card_with_the_text_and_description ( self ) : <EOL> name = "<STR_LIT>" <EOL> desc = "<STR_LIT>" <EOL> self . trello_element . add_card = MagicMock ( ) <EOL> self . operation . add ( name , desc ) <EOL> self . trello_element . add_card . assert_called_with ( name , desc ) <EOL> def test_split_card_contents_returns_the_name_and_description_splitted_by_new_lines ( self ) : <EOL> content = "<STR_LIT>" <EOL> name , desc = self . operation . split_card_contents ( content ) <EOL> self . assertEqual ( name , "<STR_LIT>" ) <EOL> self . assertEqual ( desc , "<STR_LIT>" ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> unittest . main ( ) </s>
<s> '''<STR_LIT>''' <EOL> from . common import * <EOL> DEBUG = env . bool ( '<STR_LIT>' , default = True ) <EOL> TEMPLATES [ <NUM_LIT:0> ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] = DEBUG <EOL> SECRET_KEY = env ( "<STR_LIT>" , default = '<STR_LIT>' ) <EOL> EMAIL_HOST = '<STR_LIT:localhost>' <EOL> EMAIL_PORT = <NUM_LIT> <EOL> EMAIL_BACKEND = env ( '<STR_LIT>' , <EOL> default = '<STR_LIT>' ) <EOL> CACHES = { <EOL> '<STR_LIT:default>' : { <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' <EOL> } <EOL> } <EOL> MIDDLEWARE_CLASSES += ( '<STR_LIT>' , ) <EOL> INSTALLED_APPS += ( '<STR_LIT>' , ) <EOL> INTERNAL_IPS = ( '<STR_LIT:127.0.0.1>' , '<STR_LIT>' , ) <EOL> DEBUG_TOOLBAR_CONFIG = { <EOL> '<STR_LIT>' : [ <EOL> '<STR_LIT>' , <EOL> ] , <EOL> '<STR_LIT>' : True , <EOL> } <EOL> TEST_RUNNER = '<STR_LIT>' </s>
<s> from django . contrib import messages <EOL> from django . contrib . auth import logout , login , authenticate <EOL> from django . contrib . auth . decorators import login_required <EOL> from django . contrib . auth . models import User <EOL> from django . http import HttpResponseBadRequest , Http404 <EOL> from django . shortcuts import render , redirect , get_object_or_404 <EOL> from reddit . forms import UserForm , ProfileForm <EOL> from reddit . utils . helpers import post_only <EOL> from users . models import RedditUser <EOL> def user_profile ( request , username ) : <EOL> user = get_object_or_404 ( User , username = username ) <EOL> profile = RedditUser . objects . get ( user = user ) <EOL> return render ( request , '<STR_LIT>' , { '<STR_LIT>' : profile } ) <EOL> @ login_required <EOL> def edit_profile ( request ) : <EOL> user = RedditUser . objects . get ( user = request . user ) <EOL> if request . method == '<STR_LIT:GET>' : <EOL> profile_form = ProfileForm ( instance = user ) <EOL> elif request . method == '<STR_LIT:POST>' : <EOL> profile_form = ProfileForm ( request . POST , instance = user ) <EOL> if profile_form . is_valid ( ) : <EOL> profile = profile_form . save ( commit = False ) <EOL> profile . update_profile_data ( ) <EOL> profile . save ( ) <EOL> messages . success ( request , "<STR_LIT>" ) <EOL> else : <EOL> raise Http404 <EOL> return render ( request , '<STR_LIT>' , { '<STR_LIT>' : profile_form } ) <EOL> def user_login ( request ) : <EOL> """<STR_LIT>""" <EOL> if request . user . is_authenticated ( ) : <EOL> messages . warning ( request , "<STR_LIT>" ) <EOL> return render ( request , '<STR_LIT>' ) <EOL> if request . method == "<STR_LIT:POST>" : <EOL> username = request . POST . get ( '<STR_LIT:username>' ) <EOL> password = request . POST . get ( '<STR_LIT:password>' ) <EOL> if not username or not password : <EOL> return HttpResponseBadRequest ( ) <EOL> user = authenticate ( username = username , <EOL> password = password ) <EOL> if user : <EOL> if user . is_active : <EOL> login ( request , user ) <EOL> redirect_url = request . POST . get ( '<STR_LIT>' ) or '<STR_LIT>' <EOL> return redirect ( redirect_url ) <EOL> else : <EOL> return render ( request , '<STR_LIT>' , <EOL> { '<STR_LIT>' : "<STR_LIT>" } ) <EOL> else : <EOL> return render ( request , '<STR_LIT>' , <EOL> { '<STR_LIT>' : "<STR_LIT>" } ) <EOL> return render ( request , '<STR_LIT>' ) <EOL> @ post_only <EOL> def user_logout ( request ) : <EOL> """<STR_LIT>""" <EOL> if request . user . is_authenticated ( ) : <EOL> redirect_page = request . POST . get ( '<STR_LIT>' , '<STR_LIT:/>' ) <EOL> logout ( request ) <EOL> messages . success ( request , '<STR_LIT>' ) <EOL> return redirect ( redirect_page ) <EOL> return redirect ( '<STR_LIT>' ) <EOL> def register ( request ) : <EOL> """<STR_LIT>""" <EOL> user_form = UserForm ( ) <EOL> if request . user . is_authenticated ( ) : <EOL> messages . warning ( request , <EOL> '<STR_LIT>' ) <EOL> return render ( request , '<STR_LIT>' , { '<STR_LIT>' : user_form } ) <EOL> if request . method == "<STR_LIT:POST>" : <EOL> user_form = UserForm ( request . POST ) <EOL> if user_form . is_valid ( ) : <EOL> user = user_form . save ( ) <EOL> user . set_password ( user . password ) <EOL> user . save ( ) <EOL> reddit_user = RedditUser ( ) <EOL> reddit_user . user = user <EOL> reddit_user . save ( ) <EOL> user = authenticate ( username = request . POST [ '<STR_LIT:username>' ] , <EOL> password = request . POST [ '<STR_LIT:password>' ] ) <EOL> login ( request , user ) <EOL> return redirect ( '<STR_LIT>' ) <EOL> return render ( request , '<STR_LIT>' , { '<STR_LIT>' : user_form } ) </s>
<s> import unittest2 <EOL> from pymysql . tests import base <EOL> from pymysql import util <EOL> class TestNextset ( base . PyMySQLTestCase ) : <EOL> def setUp ( self ) : <EOL> super ( TestNextset , self ) . setUp ( ) <EOL> self . con = self . connections [ <NUM_LIT:0> ] <EOL> def test_nextset ( self ) : <EOL> cur = self . con . cursor ( ) <EOL> cur . execute ( "<STR_LIT>" ) <EOL> self . assertEqual ( [ ( <NUM_LIT:1> , ) ] , list ( cur ) ) <EOL> r = cur . nextset ( ) <EOL> self . assertTrue ( r ) <EOL> self . assertEqual ( [ ( <NUM_LIT:2> , ) ] , list ( cur ) ) <EOL> self . assertIsNone ( cur . nextset ( ) ) <EOL> def test_skip_nextset ( self ) : <EOL> cur = self . con . cursor ( ) <EOL> cur . execute ( "<STR_LIT>" ) <EOL> self . assertEqual ( [ ( <NUM_LIT:1> , ) ] , list ( cur ) ) <EOL> cur . execute ( "<STR_LIT>" ) <EOL> self . assertEqual ( [ ( <NUM_LIT> , ) ] , list ( cur ) ) <EOL> def test_ok_and_next ( self ) : <EOL> cur = self . con . cursor ( ) <EOL> cur . execute ( "<STR_LIT>" ) <EOL> self . assertEqual ( [ ( <NUM_LIT:1> , ) ] , list ( cur ) ) <EOL> self . assertTrue ( cur . nextset ( ) ) <EOL> self . assertTrue ( cur . nextset ( ) ) <EOL> self . assertEqual ( [ ( <NUM_LIT:2> , ) ] , list ( cur ) ) <EOL> self . assertFalse ( bool ( cur . nextset ( ) ) ) <EOL> @ unittest2 . expectedFailure <EOL> def test_multi_cursor ( self ) : <EOL> cur1 = self . con . cursor ( ) <EOL> cur2 = self . con . cursor ( ) <EOL> cur1 . execute ( "<STR_LIT>" ) <EOL> cur2 . execute ( "<STR_LIT>" ) <EOL> self . assertEqual ( [ ( <NUM_LIT:1> , ) ] , list ( cur1 ) ) <EOL> self . assertEqual ( [ ( <NUM_LIT> , ) ] , list ( cur2 ) ) <EOL> r = cur1 . nextset ( ) <EOL> self . assertTrue ( r ) <EOL> self . assertEqual ( [ ( <NUM_LIT:2> , ) ] , list ( cur1 ) ) <EOL> self . assertIsNone ( cur1 . nextset ( ) ) <EOL> def test_multi_statement_warnings ( self ) : <EOL> cursor = self . con . cursor ( ) <EOL> try : <EOL> cursor . execute ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> except TypeError : <EOL> self . fail ( ) </s>
<s> """<STR_LIT>""" <EOL> from spyderlib . qt . QtGui import QVBoxLayout , QGroupBox , QLabel <EOL> from spyderlib . qt . QtCore import SIGNAL , Qt <EOL> from spyderlib . baseconfig import get_translation <EOL> _ = get_translation ( "<STR_LIT>" , dirname = "<STR_LIT>" ) <EOL> from spyderlib . utils . qthelpers import get_icon , create_action <EOL> from spyderlib . plugins import SpyderPluginMixin , PluginConfigPage , runconfig <EOL> from spyderplugins . widgets . memoryprofilergui import ( <EOL> MemoryProfilerWidget , is_memoryprofiler_installed ) <EOL> class MemoryProfilerConfigPage ( PluginConfigPage ) : <EOL> """<STR_LIT>""" <EOL> def setup_page ( self ) : <EOL> settings_group = QGroupBox ( _ ( "<STR_LIT>" ) ) <EOL> use_color_box = self . create_checkbox ( <EOL> _ ( "<STR_LIT>" ) , <EOL> '<STR_LIT>' , default = True ) <EOL> results_group = QGroupBox ( _ ( "<STR_LIT>" ) ) <EOL> results_label1 = QLabel ( _ ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" ) ) <EOL> results_label1 . setWordWrap ( True ) <EOL> results_label2 = QLabel ( MemoryProfilerWidget . DATAPATH ) <EOL> results_label2 . setTextInteractionFlags ( Qt . TextSelectableByMouse ) <EOL> results_label2 . setWordWrap ( True ) <EOL> settings_layout = QVBoxLayout ( ) <EOL> settings_layout . addWidget ( use_color_box ) <EOL> settings_group . setLayout ( settings_layout ) <EOL> results_layout = QVBoxLayout ( ) <EOL> results_layout . addWidget ( results_label1 ) <EOL> results_layout . addWidget ( results_label2 ) <EOL> results_group . setLayout ( results_layout ) <EOL> vlayout = QVBoxLayout ( ) <EOL> vlayout . addWidget ( settings_group ) <EOL> vlayout . addWidget ( results_group ) <EOL> vlayout . addStretch ( <NUM_LIT:1> ) <EOL> self . setLayout ( vlayout ) <EOL> class MemoryProfiler ( MemoryProfilerWidget , SpyderPluginMixin ) : <EOL> """<STR_LIT>""" <EOL> CONF_SECTION = '<STR_LIT>' <EOL> CONFIGWIDGET_CLASS = MemoryProfilerConfigPage <EOL> def __init__ ( self , parent = None ) : <EOL> MemoryProfilerWidget . __init__ ( self , parent = parent ) <EOL> SpyderPluginMixin . __init__ ( self , parent ) <EOL> self . initialize_plugin ( ) <EOL> def get_plugin_title ( self ) : <EOL> """<STR_LIT>""" <EOL> return _ ( "<STR_LIT>" ) <EOL> def get_plugin_icon ( self ) : <EOL> """<STR_LIT>""" <EOL> return get_icon ( '<STR_LIT>' ) <EOL> def get_focus_widget ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . datatree <EOL> def get_plugin_actions ( self ) : <EOL> """<STR_LIT>""" <EOL> return [ ] <EOL> def on_first_registration ( self ) : <EOL> """<STR_LIT>""" <EOL> self . main . tabify_plugins ( self . main . inspector , self ) <EOL> self . dockwidget . hide ( ) <EOL> def register_plugin ( self ) : <EOL> """<STR_LIT>""" <EOL> self . connect ( self , SIGNAL ( "<STR_LIT>" ) , <EOL> self . main . editor . load ) <EOL> self . connect ( self , SIGNAL ( '<STR_LIT>' ) , <EOL> self . main . redirect_internalshell_stdio ) <EOL> self . main . add_dockwidget ( self ) <EOL> memoryprofiler_act = create_action ( self , _ ( "<STR_LIT>" ) , <EOL> icon = self . get_plugin_icon ( ) , <EOL> triggered = self . run_memoryprofiler ) <EOL> memoryprofiler_act . setEnabled ( is_memoryprofiler_installed ( ) ) <EOL> self . register_shortcut ( memoryprofiler_act , context = "<STR_LIT>" , <EOL> name = "<STR_LIT>" , default = "<STR_LIT>" ) <EOL> self . main . run_menu_actions += [ memoryprofiler_act ] <EOL> self . main . editor . pythonfile_dependent_actions += [ memoryprofiler_act ] <EOL> def refresh_plugin ( self ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> def closing_plugin ( self , cancelable = False ) : <EOL> """<STR_LIT>""" <EOL> return True <EOL> def apply_plugin_settings ( self , options ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> def run_memoryprofiler ( self ) : <EOL> """<STR_LIT>""" <EOL> self . analyze ( self . main . editor . get_current_filename ( ) ) <EOL> def analyze ( self , filename ) : <EOL> """<STR_LIT>""" <EOL> if self . dockwidget and not self . ismaximized : <EOL> self . dockwidget . setVisible ( True ) <EOL> self . dockwidget . setFocus ( ) <EOL> self . dockwidget . raise_ ( ) <EOL> pythonpath = self . main . get_spyder_pythonpath ( ) <EOL> runconf = runconfig . get_run_configuration ( filename ) <EOL> wdir , args = None , None <EOL> if runconf is not None : <EOL> if runconf . wdir_enabled : <EOL> wdir = runconf . wdir <EOL> if runconf . args_enabled : <EOL> args = runconf . args <EOL> MemoryProfilerWidget . analyze ( <EOL> self , filename , wdir = wdir , args = args , pythonpath = pythonpath , <EOL> use_colors = self . get_option ( '<STR_LIT>' , True ) ) <EOL> PLUGIN_CLASS = MemoryProfiler </s>
<s> from google . protobuf import descriptor as _descriptor <EOL> from google . protobuf import message as _message <EOL> from google . protobuf import reflection as _reflection <EOL> from google . protobuf import descriptor_pb2 <EOL> DESCRIPTOR = _descriptor . FileDescriptor ( <EOL> name = '<STR_LIT>' , <EOL> package = '<STR_LIT>' , <EOL> serialized_pb = '<STR_LIT>' ) <EOL> _PUSHNOTIFICATION = _descriptor . Descriptor ( <EOL> name = '<STR_LIT>' , <EOL> full_name = '<STR_LIT>' , <EOL> filename = None , <EOL> file = DESCRIPTOR , <EOL> containing_type = None , <EOL> fields = [ <EOL> _descriptor . FieldDescriptor ( <EOL> name = '<STR_LIT>' , full_name = '<STR_LIT>' , index = <NUM_LIT:0> , <EOL> number = <NUM_LIT:1> , type = <NUM_LIT:3> , cpp_type = <NUM_LIT:2> , label = <NUM_LIT:1> , <EOL> has_default_value = False , default_value = <NUM_LIT:0> , <EOL> message_type = None , enum_type = None , containing_type = None , <EOL> is_extension = False , extension_scope = None , <EOL> options = None ) , <EOL> _descriptor . FieldDescriptor ( <EOL> name = '<STR_LIT:title>' , full_name = '<STR_LIT>' , index = <NUM_LIT:1> , <EOL> number = <NUM_LIT:2> , type = <NUM_LIT:9> , cpp_type = <NUM_LIT:9> , label = <NUM_LIT:1> , <EOL> has_default_value = False , default_value = unicode ( "<STR_LIT>" , "<STR_LIT:utf-8>" ) , <EOL> message_type = None , enum_type = None , containing_type = None , <EOL> is_extension = False , extension_scope = None , <EOL> options = None ) , <EOL> _descriptor . FieldDescriptor ( <EOL> name = '<STR_LIT:content>' , full_name = '<STR_LIT>' , index = <NUM_LIT:2> , <EOL> number = <NUM_LIT:3> , type = <NUM_LIT:9> , cpp_type = <NUM_LIT:9> , label = <NUM_LIT:1> , <EOL> has_default_value = False , default_value = unicode ( "<STR_LIT>" , "<STR_LIT:utf-8>" ) , <EOL> message_type = None , enum_type = None , containing_type = None , <EOL> is_extension = False , extension_scope = None , <EOL> options = None ) , <EOL> _descriptor . FieldDescriptor ( <EOL> name = '<STR_LIT>' , full_name = '<STR_LIT>' , index = <NUM_LIT:3> , <EOL> number = <NUM_LIT:4> , type = <NUM_LIT:9> , cpp_type = <NUM_LIT:9> , label = <NUM_LIT:1> , <EOL> has_default_value = False , default_value = unicode ( "<STR_LIT>" , "<STR_LIT:utf-8>" ) , <EOL> message_type = None , enum_type = None , containing_type = None , <EOL> is_extension = False , extension_scope = None , <EOL> options = None ) , <EOL> ] , <EOL> extensions = [ <EOL> ] , <EOL> nested_types = [ ] , <EOL> enum_types = [ <EOL> ] , <EOL> options = None , <EOL> is_extendable = False , <EOL> extension_ranges = [ ] , <EOL> serialized_start = <NUM_LIT> , <EOL> serialized_end = <NUM_LIT> , <EOL> ) <EOL> _BATCHNOTIFICATIONREQUEST = _descriptor . Descriptor ( <EOL> name = '<STR_LIT>' , <EOL> full_name = '<STR_LIT>' , <EOL> filename = None , <EOL> file = DESCRIPTOR , <EOL> containing_type = None , <EOL> fields = [ <EOL> _descriptor . FieldDescriptor ( <EOL> name = '<STR_LIT>' , full_name = '<STR_LIT>' , index = <NUM_LIT:0> , <EOL> number = <NUM_LIT:1> , type = <NUM_LIT:11> , cpp_type = <NUM_LIT:10> , label = <NUM_LIT:3> , <EOL> has_default_value = False , default_value = [ ] , <EOL> message_type = None , enum_type = None , containing_type = None , <EOL> is_extension = False , extension_scope = None , <EOL> options = None ) , <EOL> ] , <EOL> extensions = [ <EOL> ] , <EOL> nested_types = [ ] , <EOL> enum_types = [ <EOL> ] , <EOL> options = None , <EOL> is_extendable = False , <EOL> extension_ranges = [ ] , <EOL> serialized_start = <NUM_LIT> , <EOL> serialized_end = <NUM_LIT> , <EOL> ) <EOL> _BATCHNOTIFICATIONREQUEST . fields_by_name [ '<STR_LIT>' ] . message_type = _PUSHNOTIFICATION <EOL> DESCRIPTOR . message_types_by_name [ '<STR_LIT>' ] = _PUSHNOTIFICATION <EOL> DESCRIPTOR . message_types_by_name [ '<STR_LIT>' ] = _BATCHNOTIFICATIONREQUEST <EOL> class PushNotification ( _message . Message ) : <EOL> __metaclass__ = _reflection . GeneratedProtocolMessageType <EOL> DESCRIPTOR = _PUSHNOTIFICATION <EOL> class BatchNotificationRequest ( _message . Message ) : <EOL> __metaclass__ = _reflection . GeneratedProtocolMessageType <EOL> DESCRIPTOR = _BATCHNOTIFICATIONREQUEST <EOL> DESCRIPTOR . has_options = True <EOL> DESCRIPTOR . _options = _descriptor . _ParseOptions ( descriptor_pb2 . FileOptions ( ) , '<STR_LIT>' ) </s>
<s> import pytest <EOL> from pushkin import pushkin_cli <EOL> import tornado . web <EOL> from pushkin import context <EOL> from pushkin . database import database <EOL> from pushkin . request . request_processor import RequestProcessor <EOL> from pushkin . requesthandlers . events import JsonEventHandler <EOL> from pushkin . requesthandlers . notifications import JsonNotificationHandler <EOL> from pushkin import test_config_ini_path <EOL> from pushkin import config <EOL> @ pytest . fixture <EOL> def setup_database ( ) : <EOL> database . create_database ( ) <EOL> @ pytest . fixture <EOL> def mock_processor ( mocker ) : <EOL> '''<STR_LIT>''' <EOL> mocker . patch ( '<STR_LIT>' ) <EOL> mocker . patch ( '<STR_LIT>' ) <EOL> @ pytest . fixture <EOL> def app ( ) : <EOL> pushkin_cli . CONFIGURATION_FILENAME = test_config_ini_path <EOL> pushkin_cli . init ( ) <EOL> return pushkin_cli . create_app ( ) <EOL> @ pytest . fixture <EOL> def notification_batch_json ( ) : <EOL> '''<STR_LIT>''' <EOL> return '''<STR_LIT>''' <EOL> @ pytest . fixture <EOL> def post_notification_url ( base_url ) : <EOL> return base_url + config . json_notification_handler_url <EOL> @ pytest . fixture <EOL> def event_batch_json ( ) : <EOL> '''<STR_LIT>''' <EOL> return '''<STR_LIT>''' <EOL> @ pytest . fixture <EOL> def post_event_url ( base_url ) : <EOL> return base_url + config . json_event_handler_url <EOL> @ pytest . mark . gen_test <EOL> @ pytest . mark . parametrize ( "<STR_LIT:input>" , [ <EOL> ( '<STR_LIT>' ) , <EOL> ( '<STR_LIT>' ) , <EOL> ] ) <EOL> def test_post_notification_empty_request ( setup_database , mock_processor , http_client , post_notification_url , input ) : <EOL> '''<STR_LIT>''' <EOL> request = tornado . httpclient . HTTPRequest ( post_notification_url , method = '<STR_LIT:POST>' , body = input ) <EOL> with pytest . raises ( tornado . httpclient . HTTPError ) : <EOL> yield http_client . fetch ( request ) <EOL> assert not context . request_processor . submit . called <EOL> @ pytest . mark . gen_test <EOL> def test_post_notification ( setup_database , mock_processor , http_client , post_notification_url , <EOL> notification_batch_json ) : <EOL> '''<STR_LIT>''' <EOL> request = tornado . httpclient . HTTPRequest ( post_notification_url , method = '<STR_LIT:POST>' , body = notification_batch_json ) <EOL> response = yield http_client . fetch ( request ) <EOL> assert response . code == <NUM_LIT:200> <EOL> assert context . request_processor . submit . called <EOL> @ pytest . mark . gen_test <EOL> @ pytest . mark . parametrize ( "<STR_LIT:input>" , [ <EOL> ( '<STR_LIT>' ) , <EOL> ( '<STR_LIT>' ) , <EOL> ] ) <EOL> def test_post_event_empty_request ( setup_database , mock_processor , http_client , post_event_url , input ) : <EOL> '''<STR_LIT>''' <EOL> request = tornado . httpclient . HTTPRequest ( post_event_url , method = '<STR_LIT:POST>' , body = input ) <EOL> with pytest . raises ( tornado . httpclient . HTTPError ) : <EOL> yield http_client . fetch ( request ) <EOL> assert not context . request_processor . submit . called <EOL> @ pytest . mark . gen_test <EOL> def test_post_event ( setup_database , mock_processor , http_client , post_event_url , event_batch_json ) : <EOL> '''<STR_LIT>''' <EOL> context . request_processor . submit . return_value = True <EOL> request = tornado . httpclient . HTTPRequest ( post_event_url , method = '<STR_LIT:POST>' , body = event_batch_json ) <EOL> response = yield http_client . fetch ( request ) <EOL> assert response . code == <NUM_LIT:200> <EOL> assert context . request_processor . submit . called <EOL> @ pytest . mark . gen_test <EOL> def test_post_event_service_unavailable ( setup_database , mock_processor , http_client , post_event_url , event_batch_json , <EOL> app ) : <EOL> '''<STR_LIT>''' <EOL> context . request_processor . submit . return_value = False <EOL> request = tornado . httpclient . HTTPRequest ( post_event_url , method = '<STR_LIT:POST>' , body = event_batch_json ) <EOL> RequestProcessor . submit . return_value = False <EOL> with pytest . raises ( tornado . httpclient . HTTPError ) : <EOL> yield http_client . fetch ( request ) </s>
<s> import json <EOL> import os <EOL> import tempfile <EOL> import unittest <EOL> from zipfile import ZipFile <EOL> import shutil <EOL> from nordicsemi . dfu . package import Package <EOL> class TestPackage ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . work_directory = tempfile . mkdtemp ( prefix = "<STR_LIT>" ) <EOL> def tearDown ( self ) : <EOL> shutil . rmtree ( self . work_directory , ignore_errors = True ) <EOL> def test_generate_package_application ( self ) : <EOL> self . p = Package ( <EOL> dev_type = <NUM_LIT:1> , <EOL> dev_rev = <NUM_LIT:2> , <EOL> app_version = <NUM_LIT:100> , <EOL> sd_req = [ <NUM_LIT> , <NUM_LIT> ] , <EOL> app_fw = "<STR_LIT>" <EOL> ) <EOL> pkg_name = "<STR_LIT>" <EOL> self . p . generate_package ( pkg_name , preserve_work_directory = False ) <EOL> expected_zip_content = [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] <EOL> with ZipFile ( pkg_name , '<STR_LIT:r>' ) as pkg : <EOL> infolist = pkg . infolist ( ) <EOL> for file_information in infolist : <EOL> self . assertTrue ( file_information . filename in expected_zip_content ) <EOL> self . assertGreater ( file_information . file_size , <NUM_LIT:0> ) <EOL> pkg . extractall ( self . work_directory ) <EOL> with open ( os . path . join ( self . work_directory , '<STR_LIT>' ) , '<STR_LIT:r>' ) as f : <EOL> _json = json . load ( f ) <EOL> self . assertEqual ( u'<STR_LIT>' , _json [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) <EOL> self . assertEqual ( u'<STR_LIT>' , _json [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) <EOL> self . assertTrue ( u'<STR_LIT>' not in _json [ '<STR_LIT>' ] ) <EOL> self . assertTrue ( u'<STR_LIT>' not in _json [ '<STR_LIT>' ] ) <EOL> self . assertTrue ( u'<STR_LIT>' not in _json [ '<STR_LIT>' ] ) <EOL> def test_generate_package_sd_bl ( self ) : <EOL> self . p = Package ( dev_type = <NUM_LIT:1> , <EOL> dev_rev = <NUM_LIT:2> , <EOL> app_version = <NUM_LIT:100> , <EOL> sd_req = [ <NUM_LIT> , <NUM_LIT> ] , <EOL> softdevice_fw = "<STR_LIT>" , <EOL> bootloader_fw = "<STR_LIT>" ) <EOL> pkg_name = "<STR_LIT>" <EOL> self . p . generate_package ( pkg_name , preserve_work_directory = False ) <EOL> expected_zip_content = [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] <EOL> with ZipFile ( pkg_name , '<STR_LIT:r>' ) as pkg : <EOL> infolist = pkg . infolist ( ) <EOL> for file_information in infolist : <EOL> self . assertTrue ( file_information . filename in expected_zip_content ) <EOL> self . assertGreater ( file_information . file_size , <NUM_LIT:0> ) <EOL> pkg . extractall ( self . work_directory ) <EOL> with open ( os . path . join ( self . work_directory , '<STR_LIT>' ) , '<STR_LIT:r>' ) as f : <EOL> _json = json . load ( f ) <EOL> self . assertEqual ( u'<STR_LIT>' , _json [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) <EOL> self . assertEqual ( u'<STR_LIT>' , _json [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) <EOL> def test_unpack_package_a ( self ) : <EOL> self . p = Package ( dev_type = <NUM_LIT:1> , <EOL> dev_rev = <NUM_LIT:2> , <EOL> app_version = <NUM_LIT:100> , <EOL> sd_req = [ <NUM_LIT> , <NUM_LIT> ] , <EOL> softdevice_fw = "<STR_LIT>" , <EOL> dfu_ver = <NUM_LIT> ) <EOL> pkg_name = os . path . join ( self . work_directory , "<STR_LIT>" ) <EOL> self . p . generate_package ( pkg_name , preserve_work_directory = False ) <EOL> unpacked_dir = os . path . join ( self . work_directory , "<STR_LIT>" ) <EOL> manifest = self . p . unpack_package ( os . path . join ( self . work_directory , pkg_name ) , unpacked_dir ) <EOL> self . assertIsNotNone ( manifest ) <EOL> self . assertEqual ( u'<STR_LIT>' , manifest . softdevice . bin_file ) <EOL> self . assertEqual ( <NUM_LIT:0> , manifest . softdevice . init_packet_data . ext_packet_id ) <EOL> self . assertIsNotNone ( manifest . softdevice . init_packet_data . firmware_crc16 ) <EOL> def test_unpack_package_b ( self ) : <EOL> self . p = Package ( dev_type = <NUM_LIT:1> , <EOL> dev_rev = <NUM_LIT:2> , <EOL> app_version = <NUM_LIT:100> , <EOL> sd_req = [ <NUM_LIT> , <NUM_LIT> ] , <EOL> softdevice_fw = "<STR_LIT>" , <EOL> dfu_ver = <NUM_LIT> ) <EOL> pkg_name = os . path . join ( self . work_directory , "<STR_LIT>" ) <EOL> self . p . generate_package ( pkg_name , preserve_work_directory = False ) <EOL> unpacked_dir = os . path . join ( self . work_directory , "<STR_LIT>" ) <EOL> manifest = self . p . unpack_package ( os . path . join ( self . work_directory , pkg_name ) , unpacked_dir ) <EOL> self . assertIsNotNone ( manifest ) <EOL> self . assertEqual ( u'<STR_LIT>' , manifest . softdevice . bin_file ) <EOL> self . assertEqual ( <NUM_LIT:1> , manifest . softdevice . init_packet_data . ext_packet_id ) <EOL> self . assertIsNone ( manifest . softdevice . init_packet_data . firmware_crc16 ) <EOL> self . assertIsNotNone ( manifest . softdevice . init_packet_data . firmware_hash ) <EOL> def test_unpack_package_c ( self ) : <EOL> self . p = Package ( dev_type = <NUM_LIT:1> , <EOL> dev_rev = <NUM_LIT:2> , <EOL> app_version = <NUM_LIT:100> , <EOL> sd_req = [ <NUM_LIT> , <NUM_LIT> ] , <EOL> softdevice_fw = "<STR_LIT>" , <EOL> key_file = "<STR_LIT>" ) <EOL> pkg_name = os . path . join ( self . work_directory , "<STR_LIT>" ) <EOL> self . p . generate_package ( pkg_name , preserve_work_directory = False ) <EOL> unpacked_dir = os . path . join ( self . work_directory , "<STR_LIT>" ) <EOL> manifest = self . p . unpack_package ( os . path . join ( self . work_directory , pkg_name ) , unpacked_dir ) <EOL> self . assertIsNotNone ( manifest ) <EOL> self . assertEqual ( u'<STR_LIT>' , manifest . softdevice . bin_file ) <EOL> self . assertEqual ( <NUM_LIT:2> , manifest . softdevice . init_packet_data . ext_packet_id ) <EOL> self . assertIsNone ( manifest . softdevice . init_packet_data . firmware_crc16 ) <EOL> self . assertIsNotNone ( manifest . softdevice . init_packet_data . firmware_hash ) <EOL> self . assertIsNotNone ( manifest . softdevice . init_packet_data . init_packet_ecds ) <EOL> self . assertEqual ( manifest . dfu_version , <NUM_LIT> ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> unittest . main ( ) </s>
<s> from agamotto . utils import execute , grepc <EOL> def installed ( package ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> return grepc ( execute ( "<STR_LIT>" % package ) , package ) > <NUM_LIT:0> <EOL> except Exception , _e : <EOL> return False <EOL> def is_installed ( package ) : <EOL> """<STR_LIT>""" <EOL> return installed ( package ) </s>
<s> __author__ = '<STR_LIT>' <EOL> import wx <EOL> from wx import AboutBox , AboutDialogInfo , ClientDC <EOL> from wx . lib . wordwrap import wordwrap <EOL> from odmtools . meta import data <EOL> class frmAbout ( wx . Dialog ) : <EOL> def __init__ ( self , parent ) : <EOL> self . parent = parent <EOL> info = AboutDialogInfo ( ) <EOL> info . Name = data . app_name <EOL> info . Version = data . version <EOL> info . Copyright = data . copyright <EOL> info . Description = wordwrap ( data . description , <NUM_LIT> , ClientDC ( parent ) ) <EOL> info . WebSite = data . website <EOL> info . Developers = data . developers <EOL> info . License = wordwrap ( data . license , <NUM_LIT> , ClientDC ( parent ) ) <EOL> AboutBox ( info ) </s>
<s> import wx <EOL> import wx . grid <EOL> import wx . richtext <EOL> from odmtools . odmdata import Method <EOL> [ wxID_PNLMETHOD , wxID_PNLMETHODSLISTCTRL1 , wxID_PNLMETHODSRBCREATENEW , <EOL> wxID_PNLMETHODSRBGENERATE , wxID_PNLMETHODSRBSELECT , <EOL> wxID_PNLMETHODSRICHTEXTCTRL1 , <EOL> ] = [ wx . NewId ( ) for _init_ctrls in range ( <NUM_LIT:6> ) ] <EOL> from odmtools . common . logger import LoggerTool <EOL> import logging <EOL> tool = LoggerTool ( ) <EOL> logger = tool . setupLogger ( __name__ , __name__ + '<STR_LIT>' , '<STR_LIT:w>' , logging . DEBUG ) <EOL> class pnlMethod ( wx . Panel ) : <EOL> def _init_ctrls ( self , prnt ) : <EOL> wx . Panel . __init__ ( self , id = wxID_PNLMETHOD , name = u'<STR_LIT>' , <EOL> parent = prnt , pos = wx . Point ( <NUM_LIT> , <NUM_LIT> ) , size = wx . Size ( <NUM_LIT> , <NUM_LIT> ) , <EOL> style = wx . TAB_TRAVERSAL ) <EOL> self . SetClientSize ( wx . Size ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> self . rbGenerate = wx . RadioButton ( id = wxID_PNLMETHODSRBGENERATE , <EOL> label = u'<STR_LIT>' , name = u'<STR_LIT>' , <EOL> parent = self , pos = wx . Point ( <NUM_LIT:16> , <NUM_LIT:8> ) , size = wx . Size ( <NUM_LIT> , <NUM_LIT:16> ) , style = <NUM_LIT:0> ) <EOL> self . rbGenerate . SetValue ( True ) <EOL> self . rbGenerate . Bind ( wx . EVT_RADIOBUTTON , self . OnRbGenerateRadiobutton , <EOL> id = wxID_PNLMETHODSRBGENERATE ) <EOL> self . rbSelect = wx . RadioButton ( id = wxID_PNLMETHODSRBSELECT , <EOL> label = u'<STR_LIT>' , name = u'<STR_LIT>' , parent = self , <EOL> pos = wx . Point ( <NUM_LIT:16> , <NUM_LIT:32> ) , size = wx . Size ( <NUM_LIT> , <NUM_LIT> ) , style = <NUM_LIT:0> ) <EOL> self . rbSelect . SetValue ( False ) <EOL> self . rbSelect . Bind ( wx . EVT_RADIOBUTTON , self . OnRbSelectRadiobutton , <EOL> id = wxID_PNLMETHODSRBSELECT ) <EOL> self . rbCreateNew = wx . RadioButton ( id = wxID_PNLMETHODSRBCREATENEW , <EOL> label = u'<STR_LIT>' , name = u'<STR_LIT>' , parent = self , <EOL> pos = wx . Point ( <NUM_LIT:16> , <NUM_LIT> ) , size = wx . Size ( <NUM_LIT> , <NUM_LIT> ) , style = <NUM_LIT:0> ) <EOL> self . rbCreateNew . SetValue ( False ) <EOL> self . rbCreateNew . Bind ( wx . EVT_RADIOBUTTON , self . OnRbCreateNewRadiobutton , <EOL> id = wxID_PNLMETHODSRBCREATENEW ) <EOL> self . txtMethodDescrip = wx . richtext . RichTextCtrl ( id = wxID_PNLMETHODSRICHTEXTCTRL1 , <EOL> parent = self , pos = wx . Point ( <NUM_LIT:16> , <NUM_LIT> ) , size = wx . Size ( <NUM_LIT> , <NUM_LIT> ) , <EOL> style = wx . richtext . RE_MULTILINE , value = u'<STR_LIT>' ) <EOL> self . txtMethodDescrip . Enable ( False ) <EOL> self . txtMethodDescrip . Bind ( wx . EVT_SET_FOCUS , self . OnTxtMethodDescripSetFocus ) <EOL> self . txtMethodDescrip . Bind ( wx . EVT_KILL_FOCUS , self . OnTxtMethodDescripKillFocus ) <EOL> self . lstMethods = wx . ListCtrl ( id = wxID_PNLMETHODSLISTCTRL1 , <EOL> name = '<STR_LIT>' , parent = self , pos = wx . Point ( <NUM_LIT:16> , <NUM_LIT> ) , <EOL> size = wx . Size ( <NUM_LIT> , <NUM_LIT> ) , style = wx . LC_REPORT | wx . LC_SINGLE_SEL ) <EOL> self . lstMethods . InsertColumn ( <NUM_LIT:0> , '<STR_LIT>' ) <EOL> self . lstMethods . InsertColumn ( <NUM_LIT:1> , '<STR_LIT>' ) <EOL> self . lstMethods . InsertColumn ( <NUM_LIT:2> , '<STR_LIT:id>' ) <EOL> self . lstMethods . SetColumnWidth ( <NUM_LIT:0> , <NUM_LIT:200> ) <EOL> self . lstMethods . SetColumnWidth ( <NUM_LIT:1> , <NUM_LIT> ) <EOL> self . lstMethods . SetColumnWidth ( <NUM_LIT:2> , <NUM_LIT:0> ) <EOL> self . lstMethods . Enable ( False ) <EOL> def __init__ ( self , parent , id , pos , size , style , name , sm , method ) : <EOL> self . series_service = sm . get_series_service ( ) <EOL> self . prev_val = method <EOL> self . _init_ctrls ( parent ) <EOL> def OnRbGenerateRadiobutton ( self , event ) : <EOL> self . lstMethods . Enable ( False ) <EOL> self . txtMethodDescrip . Enable ( False ) <EOL> event . Skip ( ) <EOL> def OnRbSelectRadiobutton ( self , event ) : <EOL> self . lstMethods . Enable ( True ) <EOL> self . txtMethodDescrip . Enable ( False ) <EOL> event . Skip ( ) <EOL> def OnRbCreateNewRadiobutton ( self , event ) : <EOL> self . lstMethods . Enable ( False ) <EOL> self . txtMethodDescrip . Enable ( True ) <EOL> event . Skip ( ) <EOL> def OnTxtMethodDescripSetFocus ( self , event ) : <EOL> if self . txtMethodDescrip . GetValue ( ) == "<STR_LIT>" : <EOL> self . txtMethodDescrip . SetValue ( "<STR_LIT>" ) <EOL> event . Skip ( ) <EOL> def OnTxtMethodDescripKillFocus ( self , event ) : <EOL> if self . txtMethodDescrip . GetValue ( ) == "<STR_LIT>" : <EOL> self . txtMethodDescrip . SetValue ( "<STR_LIT>" ) <EOL> event . Skip ( ) <EOL> def getMethod ( self ) : <EOL> m = Method ( ) <EOL> if self . rbGenerate . Value : <EOL> genmethod = "<STR_LIT>" <EOL> try : <EOL> m = self . series_service . get_method_by_description ( genmethod ) <EOL> except : <EOL> m . description = genmethod <EOL> elif self . rbSelect . Value : <EOL> index = self . lstMethods . GetFirstSelected ( ) <EOL> desc = self . lstMethods . GetItem ( index , <NUM_LIT:0> ) . GetText ( ) <EOL> logger . debug ( desc ) <EOL> m = self . series_service . get_method_by_description ( desc ) <EOL> elif self . rbCreateNew . Value : <EOL> m . description = self . txtMethodDescrip . GetValue ( ) <EOL> return m </s>
<s> import wx <EOL> import wx . xrc <EOL> import wx . lib . masked as masked <EOL> class clsDataFilters ( wx . Dialog ) : <EOL> def __init__ ( self , parent ) : <EOL> wx . Dialog . __init__ ( self , parent , id = wx . ID_ANY , title = u"<STR_LIT>" , pos = wx . Point ( <NUM_LIT> , <NUM_LIT> ) , <EOL> size = wx . Size ( <NUM_LIT> , <NUM_LIT> ) , style = wx . DEFAULT_DIALOG_STYLE | wx . RESIZE_BORDER ) <EOL> self . SetSizeHintsSz ( wx . Size ( <NUM_LIT> , <NUM_LIT> ) , wx . DefaultSize ) <EOL> bSizer1 = wx . BoxSizer ( wx . VERTICAL ) <EOL> bSizer3 = wx . BoxSizer ( wx . VERTICAL ) <EOL> bsValueThresh = wx . BoxSizer ( wx . HORIZONTAL ) <EOL> self . rbThreshold = wx . RadioButton ( self , wx . ID_ANY , wx . EmptyString , wx . Point ( <NUM_LIT:10> , <NUM_LIT:8> ) , wx . DefaultSize , wx . RB_GROUP ) <EOL> self . rbThreshold . SetValue ( True ) <EOL> bsValueThresh . Add ( self . rbThreshold , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> sbThreshold = wx . StaticBoxSizer ( wx . StaticBox ( self , wx . ID_ANY , u"<STR_LIT>" ) , wx . VERTICAL ) <EOL> fgSizer1 = wx . FlexGridSizer ( <NUM_LIT:0> , <NUM_LIT:2> , <NUM_LIT:0> , <NUM_LIT:0> ) <EOL> fgSizer1 . SetFlexibleDirection ( wx . HORIZONTAL ) <EOL> fgSizer1 . SetNonFlexibleGrowMode ( wx . FLEX_GROWMODE_SPECIFIED ) <EOL> self . lblChangegt = wx . StaticText ( self , wx . ID_ANY , u"<STR_LIT>" , wx . DefaultPosition , wx . DefaultSize , <NUM_LIT:0> ) <EOL> self . lblChangegt . Wrap ( - <NUM_LIT:1> ) <EOL> fgSizer1 . Add ( self . lblChangegt , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> self . txtThreshValGT = wx . TextCtrl ( self , wx . ID_ANY , wx . EmptyString , wx . DefaultPosition , wx . Size ( <NUM_LIT> , - <NUM_LIT:1> ) , <NUM_LIT:0> ) <EOL> fgSizer1 . Add ( self . txtThreshValGT , <NUM_LIT:1> , wx . ALL | wx . EXPAND , <NUM_LIT:5> ) <EOL> self . lblChangelt = wx . StaticText ( self , wx . ID_ANY , u"<STR_LIT>" , wx . DefaultPosition , wx . DefaultSize , <NUM_LIT:0> ) <EOL> self . lblChangelt . Wrap ( - <NUM_LIT:1> ) <EOL> fgSizer1 . Add ( self . lblChangelt , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> self . txtThreshValLT = wx . TextCtrl ( self , wx . ID_ANY , wx . EmptyString , wx . DefaultPosition , wx . Size ( <NUM_LIT> , - <NUM_LIT:1> ) , <NUM_LIT:0> ) <EOL> fgSizer1 . Add ( self . txtThreshValLT , <NUM_LIT:1> , wx . ALL | wx . EXPAND , <NUM_LIT:5> ) <EOL> sbThreshold . Add ( fgSizer1 , <NUM_LIT:0> , wx . EXPAND , <NUM_LIT:5> ) <EOL> bsValueThresh . Add ( sbThreshold , <NUM_LIT:1> , <NUM_LIT:0> , <NUM_LIT:5> ) <EOL> bSizer3 . Add ( bsValueThresh , <NUM_LIT:1> , wx . EXPAND , <NUM_LIT:5> ) <EOL> bsGaps = wx . BoxSizer ( wx . HORIZONTAL ) <EOL> self . rbDataGaps = wx . RadioButton ( self , wx . ID_ANY , wx . EmptyString , wx . DefaultPosition , wx . DefaultSize , <NUM_LIT:0> ) <EOL> bsGaps . Add ( self . rbDataGaps , <NUM_LIT:1> , wx . ALL , <NUM_LIT:5> ) <EOL> sbGaps = wx . StaticBoxSizer ( wx . StaticBox ( self , wx . ID_ANY , u"<STR_LIT>" ) , wx . VERTICAL ) <EOL> fgSizer2 = wx . FlexGridSizer ( <NUM_LIT:0> , <NUM_LIT:2> , <NUM_LIT:0> , <NUM_LIT:0> ) <EOL> fgSizer2 . SetFlexibleDirection ( wx . HORIZONTAL ) <EOL> fgSizer2 . SetNonFlexibleGrowMode ( wx . FLEX_GROWMODE_SPECIFIED ) <EOL> self . lblGapsVal = wx . StaticText ( self , wx . ID_ANY , u"<STR_LIT>" , wx . DefaultPosition , wx . DefaultSize , <NUM_LIT:0> ) <EOL> self . lblGapsVal . Wrap ( - <NUM_LIT:1> ) <EOL> fgSizer2 . Add ( self . lblGapsVal , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> self . txtGapsVal = wx . TextCtrl ( self , wx . ID_ANY , wx . EmptyString , wx . DefaultPosition , wx . Size ( <NUM_LIT> , - <NUM_LIT:1> ) , <NUM_LIT:0> ) <EOL> fgSizer2 . Add ( self . txtGapsVal , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> self . lblGapsTime = wx . StaticText ( self , wx . ID_ANY , u"<STR_LIT>" , wx . DefaultPosition , wx . DefaultSize , <NUM_LIT:0> ) <EOL> self . lblGapsTime . Wrap ( - <NUM_LIT:1> ) <EOL> fgSizer2 . Add ( self . lblGapsTime , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> cbGapTimeChoices = [ u"<STR_LIT>" , u"<STR_LIT>" , u"<STR_LIT>" , u"<STR_LIT>" ] <EOL> self . cbGapTime = wx . ComboBox ( self , wx . ID_ANY , u"<STR_LIT>" , wx . DefaultPosition , wx . Size ( <NUM_LIT> , - <NUM_LIT:1> ) , cbGapTimeChoices , <EOL> wx . CB_READONLY ) <EOL> fgSizer2 . Add ( self . cbGapTime , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> sbGaps . Add ( fgSizer2 , <NUM_LIT:1> , wx . EXPAND , <NUM_LIT:5> ) <EOL> bsGaps . Add ( sbGaps , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:5> ) <EOL> bSizer3 . Add ( bsGaps , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:5> ) <EOL> bsDate = wx . BoxSizer ( wx . HORIZONTAL ) <EOL> self . rbDate = wx . RadioButton ( self , wx . ID_ANY , wx . EmptyString , wx . DefaultPosition , wx . DefaultSize , <NUM_LIT:0> ) <EOL> bsDate . Add ( self . rbDate , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> sbDate = wx . StaticBoxSizer ( wx . StaticBox ( self , wx . ID_ANY , u"<STR_LIT>" ) , wx . VERTICAL ) <EOL> fgSizer3 = wx . FlexGridSizer ( <NUM_LIT:0> , <NUM_LIT:4> , <NUM_LIT:0> , <NUM_LIT:0> ) <EOL> fgSizer3 . SetFlexibleDirection ( wx . HORIZONTAL ) <EOL> fgSizer3 . SetNonFlexibleGrowMode ( wx . FLEX_GROWMODE_SPECIFIED ) <EOL> self . lblDateAfter = wx . StaticText ( self , wx . ID_ANY , u"<STR_LIT>" , wx . DefaultPosition , wx . DefaultSize , <NUM_LIT:0> ) <EOL> self . lblDateAfter . Wrap ( - <NUM_LIT:1> ) <EOL> fgSizer3 . Add ( self . lblDateAfter , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> self . dpAfter = wx . DatePickerCtrl ( self , wx . ID_ANY , wx . DefaultDateTime , wx . DefaultPosition , wx . Size ( <NUM_LIT> , - <NUM_LIT:1> ) , <EOL> wx . DP_DROPDOWN | wx . DP_SHOWCENTURY ) <EOL> fgSizer3 . Add ( self . dpAfter , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> self . sbAfter = wx . SpinButton ( self , wx . ID_ANY , wx . DefaultPosition , wx . Size ( <NUM_LIT:15> , - <NUM_LIT:1> ) , <NUM_LIT:0> ) <EOL> self . tpAfter = masked . TimeCtrl ( self , wx . ID_ANY , pos = wx . DefaultPosition , size = wx . Size ( <NUM_LIT> , - <NUM_LIT:1> ) , <EOL> name = "<STR_LIT>" , <EOL> fmt24hr = True , spinButton = self . sbAfter , oob_color = "<STR_LIT>" ) <EOL> fgSizer3 . Add ( self . tpAfter , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> fgSizer3 . Add ( self . sbAfter , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> self . lblDateBefore = wx . StaticText ( self , wx . ID_ANY , u"<STR_LIT>" , wx . DefaultPosition , wx . DefaultSize , <NUM_LIT:0> ) <EOL> self . lblDateBefore . Wrap ( - <NUM_LIT:1> ) <EOL> fgSizer3 . Add ( self . lblDateBefore , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> self . dpBefore = wx . DatePickerCtrl ( self , wx . ID_ANY , wx . DefaultDateTime , wx . DefaultPosition , wx . Size ( <NUM_LIT> , - <NUM_LIT:1> ) , <EOL> wx . DP_DROPDOWN | wx . DP_SHOWCENTURY ) <EOL> fgSizer3 . Add ( self . dpBefore , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> self . sbBefore = wx . SpinButton ( self , wx . ID_ANY , wx . DefaultPosition , wx . Size ( <NUM_LIT:15> , - <NUM_LIT:1> ) , wx . SP_WRAP ) <EOL> self . tpBefore = masked . TimeCtrl ( self , wx . ID_ANY , pos = wx . DefaultPosition , size = wx . Size ( <NUM_LIT> , - <NUM_LIT:1> ) , <EOL> name = "<STR_LIT>" , <EOL> fmt24hr = True , spinButton = self . sbBefore , oob_color = '<STR_LIT>' ) <EOL> fgSizer3 . Add ( self . tpBefore , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> fgSizer3 . Add ( self . sbBefore , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> sbDate . Add ( fgSizer3 , <NUM_LIT:1> , wx . EXPAND , <NUM_LIT:5> ) <EOL> bsDate . Add ( sbDate , <NUM_LIT:1> , wx . EXPAND , <NUM_LIT:5> ) <EOL> bSizer3 . Add ( bsDate , <NUM_LIT:0> , wx . EXPAND , <NUM_LIT:5> ) <EOL> bsValChange = wx . BoxSizer ( wx . HORIZONTAL ) <EOL> self . rbVChangeThresh = wx . RadioButton ( self , wx . ID_ANY , wx . EmptyString , wx . DefaultPosition , wx . DefaultSize , <NUM_LIT:0> ) <EOL> bsValChange . Add ( self . rbVChangeThresh , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> sbValChange = wx . StaticBoxSizer ( wx . StaticBox ( self , wx . ID_ANY , u"<STR_LIT>" ) , wx . VERTICAL ) <EOL> fgSizer4 = wx . FlexGridSizer ( <NUM_LIT:0> , <NUM_LIT:2> , <NUM_LIT:0> , <NUM_LIT:0> ) <EOL> fgSizer4 . SetFlexibleDirection ( wx . HORIZONTAL ) <EOL> fgSizer4 . SetNonFlexibleGrowMode ( wx . FLEX_GROWMODE_SPECIFIED ) <EOL> self . lblChangeGT = wx . StaticText ( self , wx . ID_ANY , u"<STR_LIT>" , wx . DefaultPosition , wx . DefaultSize , <NUM_LIT:0> ) <EOL> self . lblChangeGT . Wrap ( - <NUM_LIT:1> ) <EOL> fgSizer4 . Add ( self . lblChangeGT , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> self . txtVChangeGT = wx . TextCtrl ( self , wx . ID_ANY , wx . EmptyString , wx . DefaultPosition , wx . Size ( <NUM_LIT> , - <NUM_LIT:1> ) , <NUM_LIT:0> ) <EOL> fgSizer4 . Add ( self . txtVChangeGT , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> self . lblChangeLT = wx . StaticText ( self , wx . ID_ANY , u"<STR_LIT>" , wx . DefaultPosition , wx . DefaultSize , <NUM_LIT:0> ) <EOL> self . lblChangeLT . Wrap ( - <NUM_LIT:1> ) <EOL> fgSizer4 . Add ( self . lblChangeLT , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> self . txtVChangeLT = wx . TextCtrl ( self , wx . ID_ANY , wx . EmptyString , wx . DefaultPosition , wx . Size ( <NUM_LIT> , - <NUM_LIT:1> ) , <NUM_LIT:0> ) <EOL> fgSizer4 . Add ( self . txtVChangeLT , <NUM_LIT:0> , wx . ALL , <NUM_LIT:5> ) <EOL> sbValChange . Add ( fgSizer4 , <NUM_LIT:1> , wx . EXPAND , <NUM_LIT:5> ) <EOL> bsValChange . Add ( sbValChange , <NUM_LIT:1> , <NUM_LIT:0> , <NUM_LIT:5> ) <EOL> bSizer3 . Add ( bsValChange , <NUM_LIT:1> , wx . EXPAND , <NUM_LIT:5> ) <EOL> self . chkToggleFilterSelection = wx . CheckBox ( self , wx . ID_ANY , u"<STR_LIT>" , wx . DefaultPosition , <EOL> wx . DefaultSize , <NUM_LIT:0> ) <EOL> bSizer3 . Add ( self . chkToggleFilterSelection , <NUM_LIT:1> , wx . ALL | wx . EXPAND , <NUM_LIT:5> ) <EOL> bsButtons = wx . BoxSizer ( wx . HORIZONTAL ) <EOL> self . btnOK = wx . Button ( self , wx . ID_ANY , u"<STR_LIT:OK>" , wx . DefaultPosition , wx . Size ( <NUM_LIT:64> , <NUM_LIT> ) , <NUM_LIT:0> ) <EOL> bsButtons . Add ( self . btnOK , <NUM_LIT:1> , wx . ALL | wx . EXPAND , <NUM_LIT:5> ) <EOL> self . btnCancel = wx . Button ( self , wx . ID_ANY , u"<STR_LIT>" , wx . DefaultPosition , wx . Size ( <NUM_LIT:64> , <NUM_LIT> ) , <NUM_LIT:0> ) <EOL> bsButtons . Add ( self . btnCancel , <NUM_LIT:1> , wx . ALL | wx . EXPAND , <NUM_LIT:5> ) <EOL> self . btnApply = wx . Button ( self , wx . ID_ANY , u"<STR_LIT>" , wx . DefaultPosition , wx . Size ( <NUM_LIT:64> , <NUM_LIT> ) , <NUM_LIT:0> ) <EOL> bsButtons . Add ( self . btnApply , <NUM_LIT:1> , wx . ALL | wx . EXPAND , <NUM_LIT:5> ) <EOL> self . btnClear = wx . Button ( self , wx . ID_ANY , u"<STR_LIT>" , wx . DefaultPosition , wx . Size ( <NUM_LIT:64> , <NUM_LIT> ) , <NUM_LIT:0> ) <EOL> bsButtons . Add ( self . btnClear , <NUM_LIT:1> , wx . ALL | wx . EXPAND , <NUM_LIT:5> ) <EOL> bSizer3 . Add ( bsButtons , <NUM_LIT:1> , wx . EXPAND , <NUM_LIT:0> ) <EOL> bSizer1 . Add ( bSizer3 , <NUM_LIT:1> , wx . EXPAND , <NUM_LIT:5> ) <EOL> self . SetSizer ( bSizer1 ) <EOL> self . Layout ( ) <EOL> self . Centre ( wx . BOTH ) <EOL> self . txtThreshValGT . Bind ( wx . EVT_SET_FOCUS , self . onSetFocus ) <EOL> self . txtThreshValLT . Bind ( wx . EVT_SET_FOCUS , self . onSetFocus ) <EOL> self . txtGapsVal . Bind ( wx . EVT_SET_FOCUS , self . onSetFocus ) <EOL> self . cbGapTime . Bind ( wx . EVT_SET_FOCUS , self . onSetFocus ) <EOL> self . dpAfter . Bind ( wx . EVT_SET_FOCUS , self . onSetFocus ) <EOL> self . tpAfter . Bind ( wx . EVT_SET_FOCUS , self . onSetFocus ) <EOL> self . sbAfter . Bind ( wx . EVT_SET_FOCUS , self . onSetFocus ) <EOL> self . dpBefore . Bind ( wx . EVT_SET_FOCUS , self . onSetFocus ) <EOL> self . tpBefore . Bind ( wx . EVT_SET_FOCUS , self . onSetFocus ) <EOL> self . sbBefore . Bind ( wx . EVT_SET_FOCUS , self . onSetFocus ) <EOL> self . txtVChangeGT . Bind ( wx . EVT_SET_FOCUS , self . onSetFocus ) <EOL> self . txtVChangeLT . Bind ( wx . EVT_SET_FOCUS , self . onSetFocus ) <EOL> self . chkToggleFilterSelection . Bind ( wx . EVT_CHECKBOX , self . onCheckBox ) <EOL> self . btnClear . Bind ( wx . EVT_BUTTON , self . onBtnClearButton ) <EOL> self . btnOK . Bind ( wx . EVT_BUTTON , self . onBtnOKButton ) <EOL> self . btnCancel . Bind ( wx . EVT_BUTTON , self . onBtnCancelButton ) <EOL> self . btnApply . Bind ( wx . EVT_BUTTON , self . onBtnApplyButton ) <EOL> def __del__ ( self ) : <EOL> pass <EOL> def onSetFocus ( self , event ) : <EOL> event . Skip ( ) <EOL> def onCheckBox ( self , event ) : <EOL> event . Skip ( ) <EOL> def onBtnClearButton ( self , event ) : <EOL> event . Skip ( ) <EOL> def onBtnOKButton ( self , event ) : <EOL> event . Skip ( ) <EOL> def onBtnCancelButton ( self , event ) : <EOL> event . Skip ( ) <EOL> def onBtnApplyButton ( self , event ) : <EOL> event . Skip ( ) </s>
<s> from odmtools . odmdata import SessionFactory <EOL> class TestSessionFactory : <EOL> def setup ( self ) : <EOL> self . connection_string = "<STR_LIT>" <EOL> self . session_factory = SessionFactory ( self . connection_string , echo = True ) <EOL> def test_create_session_factory ( self ) : <EOL> assert repr ( self . session_factory ) == "<STR_LIT>" % self . connection_string <EOL> assert self . session_factory . Session != None <EOL> def test_get_session ( self ) : <EOL> session = self . session_factory . get_session ( ) <EOL> assert '<STR_LIT>' in repr ( session ) </s>
<s> """<STR_LIT>""" <EOL> class DataTypeError ( TypeError ) : <EOL> """<STR_LIT>""" <EOL> class DimTypeError ( TypeError ) : <EOL> """<STR_LIT>""" <EOL> class ArityTypeError ( TypeError ) : <EOL> """<STR_LIT>""" <EOL> class IndexTypeError ( TypeError ) : <EOL> """<STR_LIT>""" <EOL> class NameTypeError ( TypeError ) : <EOL> """<STR_LIT>""" <EOL> class SetTypeError ( TypeError ) : <EOL> """<STR_LIT>""" <EOL> class SizeTypeError ( TypeError ) : <EOL> """<STR_LIT>""" <EOL> class SubsetIndexOutOfBounds ( TypeError ) : <EOL> """<STR_LIT>""" <EOL> class SparsityTypeError ( TypeError ) : <EOL> """<STR_LIT>""" <EOL> class MapTypeError ( TypeError ) : <EOL> """<STR_LIT>""" <EOL> class DataSetTypeError ( TypeError ) : <EOL> """<STR_LIT>""" <EOL> class MatTypeError ( TypeError ) : <EOL> """<STR_LIT>""" <EOL> class DatTypeError ( TypeError ) : <EOL> """<STR_LIT>""" <EOL> class KernelTypeError ( TypeError ) : <EOL> """<STR_LIT>""" <EOL> class DataValueError ( ValueError ) : <EOL> """<STR_LIT>""" <EOL> class IndexValueError ( ValueError ) : <EOL> """<STR_LIT>""" <EOL> class ModeValueError ( ValueError ) : <EOL> """<STR_LIT>""" <EOL> class IterateValueError ( ValueError ) : <EOL> """<STR_LIT>""" <EOL> class SetValueError ( ValueError ) : <EOL> """<STR_LIT>""" <EOL> class MapValueError ( ValueError ) : <EOL> """<STR_LIT>""" <EOL> class ConfigurationError ( RuntimeError ) : <EOL> """<STR_LIT>""" <EOL> class CompilationError ( RuntimeError ) : <EOL> """<STR_LIT>""" </s>
<s> import pytest <EOL> import numpy <EOL> from random import randrange <EOL> from pyop2 import plan as _plan <EOL> from pyop2 import op2 <EOL> backends = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> valuetype = numpy . float64 <EOL> NUM_ELE = <NUM_LIT:12> <EOL> NUM_NODES = <NUM_LIT> <EOL> NUM_ENTRIES = <NUM_LIT:4> <EOL> class TestColoring : <EOL> """<STR_LIT>""" <EOL> @ pytest . fixture <EOL> def nodes ( cls ) : <EOL> return op2 . Set ( NUM_NODES , "<STR_LIT>" ) <EOL> @ pytest . fixture <EOL> def elements ( cls ) : <EOL> return op2 . Set ( NUM_ELE , "<STR_LIT>" ) <EOL> @ pytest . fixture <EOL> def dnodes ( cls , nodes ) : <EOL> return op2 . DataSet ( nodes , <NUM_LIT:1> , "<STR_LIT>" ) <EOL> @ pytest . fixture <EOL> def elem_node_map ( cls ) : <EOL> v = [ randrange ( NUM_ENTRIES ) for i in range ( NUM_ELE * <NUM_LIT:3> ) ] <EOL> return numpy . asarray ( v , dtype = numpy . uint32 ) <EOL> @ pytest . fixture <EOL> def elem_node ( cls , elements , nodes , elem_node_map ) : <EOL> return op2 . Map ( elements , nodes , <NUM_LIT:3> , elem_node_map , "<STR_LIT>" ) <EOL> @ pytest . fixture <EOL> def mat ( cls , elem_node , dnodes ) : <EOL> sparsity = op2 . Sparsity ( ( dnodes , dnodes ) , ( elem_node , elem_node ) , "<STR_LIT>" ) <EOL> return op2 . Mat ( sparsity , valuetype , "<STR_LIT>" ) <EOL> @ pytest . fixture <EOL> def x ( cls , dnodes ) : <EOL> return op2 . Dat ( dnodes , numpy . zeros ( NUM_NODES , dtype = numpy . uint32 ) , numpy . uint32 , "<STR_LIT:x>" ) <EOL> def test_thread_coloring ( self , backend , skip_opencl , elements , elem_node_map , elem_node , mat , x ) : <EOL> assert NUM_ELE % <NUM_LIT:2> == <NUM_LIT:0> , "<STR_LIT>" <EOL> plan = _plan . Plan ( elements . all_part , <EOL> mat ( op2 . INC , ( elem_node [ op2 . i [ <NUM_LIT:0> ] ] , <EOL> elem_node [ op2 . i [ <NUM_LIT:1> ] ] ) ) , <EOL> x ( op2 . WRITE , elem_node [ <NUM_LIT:0> ] ) , <EOL> partition_size = NUM_ELE / <NUM_LIT:2> , <EOL> matrix_coloring = True ) <EOL> assert plan . nblocks == <NUM_LIT:2> <EOL> eidx = <NUM_LIT:0> <EOL> for p in range ( plan . nblocks ) : <EOL> for thrcol in range ( plan . nthrcol [ p ] ) : <EOL> counter = numpy . zeros ( NUM_NODES , dtype = numpy . uint32 ) <EOL> for e in range ( eidx , eidx + plan . nelems [ p ] ) : <EOL> if plan . thrcol [ e ] == thrcol : <EOL> counter [ elem_node . values [ e ] [ <NUM_LIT:0> ] ] += <NUM_LIT:1> <EOL> assert ( counter < <NUM_LIT:2> ) . all ( ) <EOL> eidx += plan . nelems [ p ] </s>
<s> """<STR_LIT>""" <EOL> from matplotlib import pyplot as plt <EOL> import oscaar <EOL> import astrometry <EOL> import photometry <EOL> import dataBank <EOL> import systematics <EOL> import IO <EOL> import pyfits <EOL> plt . ion ( ) <EOL> data = dataBank . dataBank ( ) <EOL> allStars = data . getDict ( ) <EOL> outputPath = data . outputPath <EOL> N_exposures = len ( data . getPaths ( ) ) <EOL> meanDarkFrame = data . getMeanDarkFrame ( ) <EOL> masterFlat = data . masterFlat <EOL> plottingThings , statusBarFig , statusBarAx = IO . plottingSettings ( data . trackPlots , data . photPlots ) <EOL> for expNumber in xrange ( N_exposures ) : <EOL> if statusBarAx is not None and expNumber % <NUM_LIT:15> == <NUM_LIT:0> : <EOL> plt . cla ( ) <EOL> statusBarAx . set_title ( '<STR_LIT>' ) <EOL> statusBarAx . set_xlim ( [ <NUM_LIT:0> , <NUM_LIT:100> ] ) <EOL> statusBarAx . set_xlabel ( '<STR_LIT>' ) <EOL> statusBarAx . get_yaxis ( ) . set_ticks ( [ ] ) <EOL> statusBarAx . barh ( [ <NUM_LIT:0> ] , [ <NUM_LIT> * expNumber / len ( data . getPaths ( ) ) ] , <EOL> [ <NUM_LIT:1> ] , color = '<STR_LIT:k>' ) <EOL> image = ( pyfits . getdata ( data . getPaths ( ) [ expNumber ] ) - meanDarkFrame ) / masterFlat <EOL> data . storeTime ( expNumber ) <EOL> for star in allStars : <EOL> est_x , est_y = data . centroidInitialGuess ( expNumber , star ) <EOL> x , y , radius , trackFlag = astrometry . trackSmooth ( image , est_x , est_y , <EOL> data . smoothConst , <EOL> plottingThings , <EOL> zoom = data . trackingZoom , <EOL> plots = data . trackPlots ) <EOL> data . storeCentroid ( star , expNumber , x , y ) <EOL> fluxes , errors , photFlags = photometry . multirad ( image , x , y , <EOL> data . apertureRadii , <EOL> plottingThings , <EOL> ccdGain = data . ccdGain , <EOL> plots = data . photPlots ) <EOL> photFlag = any ( photFlags ) <EOL> data . storeFluxes ( star , expNumber , fluxes , errors ) <EOL> if trackFlag or photFlag and not data . getFlag ( ) : <EOL> data . setFlag ( star , False ) <EOL> if data . trackPlots or data . photPlots : <EOL> plt . draw ( ) <EOL> if statusBarAx is not None and expNumber % <NUM_LIT:15> == <NUM_LIT:0> : <EOL> plt . draw ( ) <EOL> plt . close ( ) <EOL> data . scaleFluxes_multirad ( ) <EOL> meanComparisonStars , meanComparisonStarErrors = data . calcMeanComparison_multirad ( ccdGain = data . ccdGain ) <EOL> lightCurves , lightCurveErrors = data . computeLightCurve_multirad ( meanComparisonStars , <EOL> meanComparisonStarErrors ) <EOL> oscaar . IO . save ( data , outputPath ) <EOL> data . plotLightCurve_multirad ( ) </s>
<s> '''<STR_LIT>''' <EOL> from RESTfulResource import RESTfulResource <EOL> from urlparse import urlparse <EOL> class Observers ( RESTfulResource ) : <EOL> def __init__ ( self ) : <EOL> RESTfulResource . __init__ ( self ) <EOL> self . __schemes = [ '<STR_LIT:http>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> self . __observers = [ ] <EOL> def onUpdate ( self , resource ) : <EOL> self . __onUpdate ( resource ) <EOL> def __onUpdate ( self , resource ) : <EOL> for self . __observer in self . __observers : <EOL> self . __notify ( self . __observer , resource ) <EOL> def __notify ( self , observer , resource ) : <EOL> if type ( observer ) is not callable : <EOL> urlObject = urlparse ( observer ) <EOL> if urlObject . scheme == '<STR_LIT:http>' : <EOL> self . __httpNotify ( observer , resource ) <EOL> elif urlObject . scheme == '<STR_LIT>' : <EOL> self . __coapNotify ( observer , resource ) <EOL> elif urlObject . scheme == '<STR_LIT>' : <EOL> self . __callbackNotify ( observer , resource ) <EOL> else : <EOL> observer ( resource ) <EOL> def __httpNotify ( self , targetURI , resource ) : <EOL> print '<STR_LIT>' <EOL> def __coapNotify ( self , targetURI , resource ) : <EOL> print '<STR_LIT>' <EOL> def __callbackNotify ( self , observer , resource ) : <EOL> print '<STR_LIT>' <EOL> def get ( self , targetURI = None ) : <EOL> if targetURI != None : <EOL> if targetURI in self . __observers : <EOL> return targetURI <EOL> return None <EOL> return self . __observers <EOL> def set ( self , targetURI ) : <EOL> self . create ( targetURI ) <EOL> def create ( self , targetURI ) : <EOL> if urlparse ( targetURI ) . scheme not in self . __schemes : <EOL> return None <EOL> if targetURI not in self . __observers : <EOL> self . __observers . append ( targetURI ) <EOL> return targetURI <EOL> def delete ( self , targetURI ) : <EOL> if targetURI in self . __observers : <EOL> self . __observers . remove ( targetURI ) <EOL> return targetURI <EOL> return None </s>
<s> import json <EOL> import time <EOL> import requests <EOL> from pywechat . excepts import WechatError <EOL> class Basic ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , app_id , app_secret ) : <EOL> """<STR_LIT>""" <EOL> self . __app_id = app_id <EOL> self . __app_secret = app_secret <EOL> self . __access_token = self . access_token <EOL> self . __token_expires_at = None <EOL> @ property <EOL> def access_token ( self ) : <EOL> '''<STR_LIT>''' <EOL> if self . __access_token and self . __token_expires_at : <EOL> if self . __token_expires_at - time . time ( ) > <NUM_LIT> : <EOL> return self . __access_token <EOL> self . _grant_access_token ( ) <EOL> return self . __access_token <EOL> def _send_request ( self , method , url , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> if not kwargs . get ( '<STR_LIT>' ) : <EOL> kwargs [ '<STR_LIT>' ] = { <EOL> "<STR_LIT>" : self . access_token <EOL> } <EOL> if kwargs . get ( '<STR_LIT:data>' ) : <EOL> data = json . dumps ( kwargs [ '<STR_LIT:data>' ] ) . encode ( '<STR_LIT:utf-8>' ) <EOL> kwargs [ "<STR_LIT:data>" ] = data <EOL> request = requests . request ( <EOL> method = method , <EOL> url = url , <EOL> ** kwargs <EOL> ) <EOL> request . raise_for_status ( ) <EOL> json_data = request . json ( ) <EOL> self . _check_wechat_error ( json_data ) <EOL> return json_data <EOL> @ classmethod <EOL> def _check_wechat_error ( cls , json_data ) : <EOL> """<STR_LIT>""" <EOL> errcode = json_data . get ( '<STR_LIT>' ) <EOL> if errcode and errcode != <NUM_LIT:0> : <EOL> raise WechatError ( errcode , json_data . get ( '<STR_LIT>' ) ) <EOL> def _grant_access_token ( self ) : <EOL> """<STR_LIT>""" <EOL> url = '<STR_LIT>' <EOL> params = { <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : self . __app_id , <EOL> "<STR_LIT>" : self . __app_secret <EOL> } <EOL> json_data = self . _send_request ( '<STR_LIT>' , url , params = params ) <EOL> self . __access_token = json_data . get ( '<STR_LIT>' ) <EOL> self . __token_expires_at = int ( <EOL> time . time ( ) ) + json_data . get ( '<STR_LIT>' ) <EOL> return json_data <EOL> def _get_wechat_server_ips ( self ) : <EOL> """<STR_LIT>""" <EOL> url = "<STR_LIT>" <EOL> params = { <EOL> "<STR_LIT>" : self . access_token <EOL> } <EOL> json_data = self . _send_request ( '<STR_LIT>' , url , params = params ) <EOL> return json_data </s>
<s> import json <EOL> from fabric . api import * <EOL> from . deployer . configuration import Configuration <EOL> from . deployer . helpers import mkdir , rmdir <EOL> from . deployer . standard_packages import package_list <EOL> import os <EOL> from StringIO import StringIO <EOL> site_settings = { <EOL> "<STR_LIT>" : '<STR_LIT>' , <EOL> "<STR_LIT>" : '<STR_LIT>' , <EOL> "<STR_LIT>" : '<STR_LIT>' , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : '<STR_LIT>' , <EOL> } <EOL> def load_configuration ( ) : <EOL> with open ( os . path . join ( os . path . dirname ( os . path . abspath ( __file__ ) ) , '<STR_LIT>' ) , '<STR_LIT:r>' ) as f : <EOL> configuration_file = '<STR_LIT>' . join ( f . readlines ( ) ) <EOL> conf = json . JSONDecoder ( ) . decode ( configuration_file ) <EOL> print "<STR_LIT>" . format ( conf [ '<STR_LIT>' ] ) <EOL> env . hosts . append ( conf [ '<STR_LIT>' ] ) <EOL> env . hosts_data = Configuration ( conf , site_settings ) <EOL> load_configuration ( ) <EOL> @ task <EOL> def install_requirements ( ) : <EOL> sudo ( '<STR_LIT>' ) <EOL> sudo ( '<STR_LIT>' ) <EOL> sudo ( '<STR_LIT>' . format ( package_list ( ) ) ) <EOL> @ task <EOL> def create_folders ( ) : <EOL> mkdir ( env . hosts_data . base_path ( ) ) <EOL> mkdir ( env . hosts_data . log_path ( ) ) <EOL> @ task <EOL> def create_virtual_environment ( ) : <EOL> with cd ( env . hosts_data . base_path ( ) ) : <EOL> run ( '<STR_LIT>' . format ( env . hosts_data . virtualenv_path ( ) ) ) <EOL> with prefix ( "<STR_LIT>" . format ( env . hosts_data . virtualenv_activate_path ( ) ) ) : <EOL> run ( '<STR_LIT>' ) <EOL> run ( '<STR_LIT>' . format ( env . hosts_data . requirements_path ( ) ) ) <EOL> if env . hosts_data . is_mysql ( ) : <EOL> run ( '<STR_LIT>' ) <EOL> run ( '<STR_LIT>' ) <EOL> @ task <EOL> def create_local_settings ( ) : <EOL> rmdir ( env . hosts_data . local_settings_path ( ) ) <EOL> put ( StringIO ( env . hosts_data . local_settings ( ) ) , env . hosts_data . local_settings_path ( ) ) <EOL> @ task <EOL> def create_gunicorn_config ( ) : <EOL> rmdir ( env . hosts_data . gunicorn_config_path ( ) ) <EOL> put ( StringIO ( env . hosts_data . gunicorn_config ( ) ) , env . hosts_data . gunicorn_config_path ( ) ) <EOL> sudo ( '<STR_LIT>' . format ( env . hosts_data . gunicorn_config_path ( ) ) ) <EOL> @ task <EOL> def create_demo_superuser ( ) : <EOL> with cd ( env . hosts_data . app_path ( ) ) : <EOL> with prefix ( "<STR_LIT>" . format ( env . hosts_data . virtualenv_activate_path ( ) ) ) : <EOL> commands = [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" <EOL> ] <EOL> run ( '<STR_LIT:U+0020>' . join ( commands ) ) <EOL> @ task <EOL> def create_gunicorn_supervisor ( ) : <EOL> rmdir ( env . hosts_data . gunicorn_supervisor_config_path ( ) ) <EOL> put ( <EOL> StringIO ( env . hosts_data . gunicorn_supervisor_config ( ) ) , <EOL> env . hosts_data . gunicorn_supervisor_config_path ( ) , <EOL> use_sudo = True <EOL> ) <EOL> sudo ( '<STR_LIT>' ) <EOL> sudo ( '<STR_LIT>' ) <EOL> @ task <EOL> def create_celery_supervisor ( ) : <EOL> rmdir ( env . hosts_data . celery_supervisor_config_path ( ) ) <EOL> put ( <EOL> StringIO ( env . hosts_data . celery_supervisor_config ( ) ) , <EOL> env . hosts_data . celery_supervisor_config_path ( ) , <EOL> use_sudo = True <EOL> ) <EOL> sudo ( '<STR_LIT>' ) <EOL> sudo ( '<STR_LIT>' ) <EOL> @ task <EOL> def create_nginx_config ( ) : <EOL> put ( StringIO ( env . hosts_data . nginx_config ( ) ) , env . hosts_data . nginx_available_path ( ) , use_sudo = True ) <EOL> sudo ( '<STR_LIT>' . format ( env . hosts_data . nginx_available_path ( ) , env . hosts_data . nginx_enabled_path ( ) ) ) <EOL> sudo ( '<STR_LIT>' ) <EOL> @ task <EOL> def delete_nginx_config ( ) : <EOL> rmdir ( env . hosts_data . nginx_enabled_path ( ) , sudo_access = True ) <EOL> rmdir ( env . hosts_data . nginx_available_path ( ) , sudo_access = True ) <EOL> sudo ( '<STR_LIT>' ) <EOL> @ task <EOL> def migrate_database ( ) : <EOL> with cd ( env . hosts_data . app_path ( ) ) : <EOL> with prefix ( "<STR_LIT>" . format ( env . hosts_data . virtualenv_activate_path ( ) ) ) : <EOL> run ( "<STR_LIT>" ) <EOL> run ( "<STR_LIT>" ) <EOL> @ task <EOL> def collect_static ( ) : <EOL> with cd ( env . hosts_data . app_path ( ) ) : <EOL> with prefix ( "<STR_LIT>" . format ( env . hosts_data . virtualenv_activate_path ( ) ) ) : <EOL> run ( "<STR_LIT>" ) <EOL> @ task <EOL> def delete_folders ( ) : <EOL> rmdir ( env . hosts_data . base_path ( ) ) <EOL> @ task <EOL> def delete_gunicorn_supervisor ( ) : <EOL> server_stop ( ) <EOL> rmdir ( env . hosts_data . gunicorn_supervisor_config_path ( ) , sudo_access = True ) <EOL> sudo ( '<STR_LIT>' ) <EOL> sudo ( '<STR_LIT>' ) <EOL> @ task <EOL> def delete_celery_supervisor ( ) : <EOL> server_stop ( ) <EOL> rmdir ( env . hosts_data . celery_supervisor_config_path ( ) , sudo_access = True ) <EOL> sudo ( '<STR_LIT>' ) <EOL> sudo ( '<STR_LIT>' ) <EOL> @ task ( default = True ) <EOL> def make_deploy ( ) : <EOL> install_requirements ( ) <EOL> create_folders ( ) <EOL> run ( env . hosts_data . git_clone_command ( ) ) <EOL> with cd ( env . hosts_data . app_path ( ) ) : <EOL> run ( env . hosts_data . git_checkout_command ( ) ) <EOL> create_virtual_environment ( ) <EOL> create_local_settings ( ) <EOL> migrate_database ( ) <EOL> create_demo_superuser ( ) <EOL> collect_static ( ) <EOL> create_gunicorn_config ( ) <EOL> create_gunicorn_supervisor ( ) <EOL> create_celery_supervisor ( ) <EOL> create_nginx_config ( ) <EOL> @ task <EOL> def server_status ( ) : <EOL> sudo ( '<STR_LIT>' . format ( env . hosts_data . application_name ( ) ) ) <EOL> @ task <EOL> def server_stop ( ) : <EOL> sudo ( '<STR_LIT>' . format ( env . hosts_data . application_name ( ) ) ) <EOL> sudo ( '<STR_LIT>' . format ( env . hosts_data . application_name ( ) ) ) <EOL> @ task <EOL> def server_start ( ) : <EOL> sudo ( '<STR_LIT>' . format ( env . hosts_data . application_name ( ) ) ) <EOL> sudo ( '<STR_LIT>' . format ( env . hosts_data . application_name ( ) ) ) <EOL> @ task <EOL> def server_restart ( ) : <EOL> sudo ( '<STR_LIT>' . format ( env . hosts_data . application_name ( ) ) ) <EOL> sudo ( '<STR_LIT>' . format ( env . hosts_data . application_name ( ) ) ) <EOL> @ task <EOL> def destroy_deploy ( ) : <EOL> delete_folders ( ) <EOL> delete_gunicorn_supervisor ( ) <EOL> delete_celery_supervisor ( ) <EOL> delete_nginx_config ( ) <EOL> @ task <EOL> def update_deploy ( ) : <EOL> server_stop ( ) <EOL> with cd ( env . hosts_data . app_path ( ) ) : <EOL> with prefix ( "<STR_LIT>" . format ( env . hosts_data . virtualenv_activate_path ( ) ) ) : <EOL> run ( '<STR_LIT>' ) <EOL> run ( '<STR_LIT>' . format ( env . hosts_data . requirements_path ( ) ) ) <EOL> migrate_database ( ) <EOL> collect_static ( ) <EOL> server_start ( ) </s>
<s> from django . conf . urls import patterns , url , include <EOL> from haystack . views import search_view_factory , SearchView <EOL> from offers . feeds import OfferFeed , OfferAtomFeed <EOL> from offers . forms import OfferSearchForm <EOL> from . import views as offer_views <EOL> urlpatterns = patterns ( '<STR_LIT>' , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = '<STR_LIT>' ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = '<STR_LIT>' ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = "<STR_LIT>" ) , <EOL> url ( r'<STR_LIT>' , search_view_factory ( <EOL> view_class = SearchView , <EOL> form_class = OfferSearchForm , <EOL> template = '<STR_LIT>' , <EOL> results_per_page = <NUM_LIT:8> , <EOL> ) , <EOL> name = '<STR_LIT>' , <EOL> ) , <EOL> url ( r'<STR_LIT>' , OfferFeed ( ) , name = '<STR_LIT>' ) , <EOL> url ( r'<STR_LIT>' , OfferAtomFeed ( ) , name = '<STR_LIT>' ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = "<STR_LIT>" ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = "<STR_LIT>" ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = "<STR_LIT>" ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = "<STR_LIT>" ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = "<STR_LIT>" ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = "<STR_LIT>" ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = "<STR_LIT>" ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = "<STR_LIT>" ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = "<STR_LIT>" ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = "<STR_LIT>" ) , <EOL> url ( <EOL> r'<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> name = "<STR_LIT>" <EOL> ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = "<STR_LIT>" ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = "<STR_LIT>" ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = "<STR_LIT>" ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = "<STR_LIT>" ) , <EOL> ) </s>
<s> __productname__ = '<STR_LIT>' <EOL> __version__ = "<STR_LIT>" <EOL> __copyright__ = "<STR_LIT>" <EOL> __author__ = "<STR_LIT>" <EOL> __author_email__ = "<STR_LIT>" <EOL> __description__ = "<STR_LIT>" <EOL> __license__ = "<STR_LIT>" <EOL> __homepage__ = "<STR_LIT>" <EOL> from imapfw . init import Imapfw <EOL> from imapfw import runtime </s>
<s> from imapfw import runtime <EOL> from . manager import Manager <EOL> class FolderManager ( Manager ) : <EOL> def __init__ ( self ) : <EOL> super ( FolderManager , self ) . __init__ ( ) <EOL> self . rascal = runtime . rascal </s>
<s> '''<STR_LIT>''' <EOL> from __future__ import unicode_literals <EOL> from . . model . hashes import Hashes <EOL> from . . one_drive_object_base import OneDriveObjectBase <EOL> class File ( OneDriveObjectBase ) : <EOL> def __init__ ( self , prop_dict = { } ) : <EOL> self . _prop_dict = prop_dict <EOL> @ property <EOL> def hashes ( self ) : <EOL> """<STR_LIT>""" <EOL> if "<STR_LIT>" in self . _prop_dict : <EOL> if isinstance ( self . _prop_dict [ "<STR_LIT>" ] , OneDriveObjectBase ) : <EOL> return self . _prop_dict [ "<STR_LIT>" ] <EOL> else : <EOL> self . _prop_dict [ "<STR_LIT>" ] = Hashes ( self . _prop_dict [ "<STR_LIT>" ] ) <EOL> return self . _prop_dict [ "<STR_LIT>" ] <EOL> return None <EOL> @ hashes . setter <EOL> def hashes ( self , val ) : <EOL> self . _prop_dict [ "<STR_LIT>" ] = val <EOL> @ property <EOL> def mime_type ( self ) : <EOL> """<STR_LIT>""" <EOL> if "<STR_LIT>" in self . _prop_dict : <EOL> return self . _prop_dict [ "<STR_LIT>" ] <EOL> else : <EOL> return None <EOL> @ mime_type . setter <EOL> def mime_type ( self , val ) : <EOL> self . _prop_dict [ "<STR_LIT>" ] = val </s>
<s> '''<STR_LIT>''' <EOL> class RequestBuilderBase ( object ) : <EOL> def __init__ ( self , request_url , client ) : <EOL> """<STR_LIT>""" <EOL> self . _request_url = request_url <EOL> self . _client = client <EOL> def append_to_request_url ( self , url_segment ) : <EOL> """<STR_LIT>""" <EOL> return self . _request_url + "<STR_LIT:/>" + url_segment </s>
<s> '''<STR_LIT>''' <EOL> from __future__ import unicode_literals <EOL> from . . collection_base import CollectionRequestBase , CollectionResponseBase , CollectionPageBase <EOL> from . . request_builder_base import RequestBuilderBase <EOL> from . . model . item import Item <EOL> import json <EOL> class SharedCollectionRequest ( CollectionRequestBase ) : <EOL> def __init__ ( self , request_url , client , options ) : <EOL> """<STR_LIT>""" <EOL> super ( SharedCollectionRequest , self ) . __init__ ( request_url , client , options ) <EOL> def get ( self ) : <EOL> """<STR_LIT>""" <EOL> self . method = "<STR_LIT:GET>" <EOL> collection_response = SharedCollectionResponse ( json . loads ( self . send ( ) . content ) ) <EOL> return self . _page_from_response ( collection_response ) <EOL> class SharedCollectionRequestBuilder ( RequestBuilderBase ) : <EOL> def __getitem__ ( self , key ) : <EOL> """<STR_LIT>""" <EOL> return ItemRequestBuilder ( self . append_to_request_url ( str ( key ) ) , self . _client ) <EOL> def request ( self , expand = None , select = None , top = None , order_by = None , options = None ) : <EOL> """<STR_LIT>""" <EOL> req = SharedCollectionRequest ( self . _request_url , self . _client , options ) <EOL> req . _set_query_options ( expand = expand , select = select , top = top , order_by = order_by ) <EOL> return req <EOL> def get ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . request ( ) . get ( ) <EOL> class SharedCollectionResponse ( CollectionResponseBase ) : <EOL> @ property <EOL> def collection_page ( self ) : <EOL> """<STR_LIT>""" <EOL> if self . _collection_page : <EOL> self . _collection_page . _prop_list = self . _prop_dict [ "<STR_LIT:value>" ] <EOL> else : <EOL> self . _collection_page = SharedCollectionPage ( self . _prop_dict [ "<STR_LIT:value>" ] ) <EOL> return self . _collection_page <EOL> class SharedCollectionPage ( CollectionPageBase ) : <EOL> def __getitem__ ( self , index ) : <EOL> """<STR_LIT>""" <EOL> return Item ( self . _prop_list [ index ] ) <EOL> def shared ( self ) : <EOL> """<STR_LIT>""" <EOL> for item in self . _prop_list : <EOL> yield Item ( item ) <EOL> def _init_next_page_request ( self , next_page_link , client , options ) : <EOL> """<STR_LIT>""" <EOL> self . _next_page_request = SharedCollectionRequest ( next_page_link , client , options ) <EOL> from . . request . item_request_builder import ItemRequestBuilder </s>
<s> """<STR_LIT>""" <EOL> __version__ = '<STR_LIT>' </s>
<s> from __future__ import absolute_import , division , print_function <EOL> import glob <EOL> import os . path <EOL> from cffi import FFI <EOL> from cffi . verifier import Verifier <EOL> __all__ = [ "<STR_LIT>" ] <EOL> HEADERS = glob . glob ( <EOL> os . path . join ( os . path . abspath ( os . path . dirname ( __file__ ) ) , "<STR_LIT>" ) <EOL> ) <EOL> ffi = FFI ( ) <EOL> for header in sorted ( HEADERS ) : <EOL> with open ( header , "<STR_LIT:r>" ) as hfile : <EOL> ffi . cdef ( hfile . read ( ) ) <EOL> ffi . verifier = Verifier ( <EOL> ffi , <EOL> "<STR_LIT>" , <EOL> libraries = [ "<STR_LIT>" ] , <EOL> ext_package = "<STR_LIT>" , <EOL> ) <EOL> class Library ( object ) : <EOL> def __init__ ( self , ffi ) : <EOL> self . ffi = ffi <EOL> self . _lib = None <EOL> def _compile_module ( * args , ** kwargs ) : <EOL> raise RuntimeError ( "<STR_LIT>" ) <EOL> self . ffi . verifier . compile_module = _compile_module <EOL> def __getattr__ ( self , name ) : <EOL> if self . _lib is None : <EOL> self . _lib = self . ffi . verifier . load_library ( ) <EOL> return getattr ( self . _lib , name ) <EOL> lib = Library ( ffi ) </s>
<s> import sqlite3 <EOL> def migrate ( database_path ) : <EOL> print "<STR_LIT>" <EOL> conn = sqlite3 . connect ( database_path ) <EOL> conn . text_factory = str <EOL> cursor = conn . cursor ( ) <EOL> cursor . execute ( '''<STR_LIT>''' ) <EOL> notifications = cursor . fetchall ( ) <EOL> cursor . execute ( '''<STR_LIT>''' ) <EOL> cursor . execute ( '''<STR_LIT>''' ) <EOL> cursor . execute ( '''<STR_LIT>''' ) <EOL> for n in notifications : <EOL> cursor . execute ( '''<STR_LIT>''' , ( n [ <NUM_LIT:0> ] , n [ <NUM_LIT:1> ] , n [ <NUM_LIT:2> ] , n [ <NUM_LIT:3> ] , n [ <NUM_LIT:4> ] , n [ <NUM_LIT:5> ] , n [ <NUM_LIT:6> ] , n [ <NUM_LIT:7> ] , n [ <NUM_LIT:8> ] ) ) <EOL> cursor . execute ( '''<STR_LIT>''' ) <EOL> conn . commit ( ) <EOL> conn . close ( ) </s>
<s> """<STR_LIT>""" <EOL> import sys <EOL> from twisted . python import log <EOL> DEBUG = <NUM_LIT:5> <EOL> WARNING = <NUM_LIT:4> <EOL> INFO = <NUM_LIT:3> <EOL> ERROR = <NUM_LIT:2> <EOL> CRITICAL = <NUM_LIT:1> <EOL> levels = { "<STR_LIT>" : <NUM_LIT:5> , "<STR_LIT>" : <NUM_LIT:4> , "<STR_LIT:info>" : <NUM_LIT:3> , "<STR_LIT:error>" : <NUM_LIT:2> , "<STR_LIT>" : <NUM_LIT:1> } <EOL> class FileLogObserver ( log . FileLogObserver ) : <EOL> def __init__ ( self , f = None , level = "<STR_LIT:info>" , default = DEBUG ) : <EOL> log . FileLogObserver . __init__ ( self , f or sys . stdout ) <EOL> self . level = levels [ level ] <EOL> self . default = default <EOL> def emit ( self , eventDict ) : <EOL> ll = eventDict . get ( '<STR_LIT>' , self . default ) <EOL> if eventDict [ '<STR_LIT>' ] or '<STR_LIT>' in eventDict or self . level >= ll : <EOL> log . FileLogObserver . emit ( self , eventDict ) <EOL> class Logger ( object ) : <EOL> def __init__ ( self , ** kwargs ) : <EOL> self . kwargs = kwargs <EOL> def msg ( self , message , ** kw ) : <EOL> kw . update ( self . kwargs ) <EOL> if '<STR_LIT>' in kw and not isinstance ( kw [ '<STR_LIT>' ] , str ) : <EOL> kw [ '<STR_LIT>' ] = kw [ '<STR_LIT>' ] . __class__ . __name__ <EOL> log . msg ( message , ** kw ) <EOL> def info ( self , message , ** kw ) : <EOL> kw [ '<STR_LIT>' ] = INFO <EOL> self . msg ( "<STR_LIT>" % message , ** kw ) <EOL> def debug ( self , message , ** kw ) : <EOL> kw [ '<STR_LIT>' ] = DEBUG <EOL> self . msg ( "<STR_LIT>" % message , ** kw ) <EOL> def warning ( self , message , ** kw ) : <EOL> kw [ '<STR_LIT>' ] = WARNING <EOL> self . msg ( "<STR_LIT>" % message , ** kw ) <EOL> def error ( self , message , ** kw ) : <EOL> kw [ '<STR_LIT>' ] = ERROR <EOL> self . msg ( "<STR_LIT>" % message , ** kw ) <EOL> def critical ( self , message , ** kw ) : <EOL> kw [ '<STR_LIT>' ] = CRITICAL <EOL> self . msg ( "<STR_LIT>" % message , ** kw ) <EOL> try : <EOL> theLogger <EOL> except NameError : <EOL> theLogger = Logger ( ) <EOL> msg = theLogger . msg <EOL> info = theLogger . info <EOL> debug = theLogger . debug <EOL> warning = theLogger . warning <EOL> error = theLogger . error <EOL> critical = theLogger . critical </s>
<s> import sys <EOL> _b = sys . version_info [ <NUM_LIT:0> ] < <NUM_LIT:3> and ( lambda x : x ) or ( lambda x : x . encode ( '<STR_LIT>' ) ) <EOL> from google . protobuf import descriptor as _descriptor <EOL> from google . protobuf import message as _message <EOL> from google . protobuf import reflection as _reflection <EOL> from google . protobuf import symbol_database as _symbol_database <EOL> from google . protobuf import descriptor_pb2 <EOL> _sym_db = _symbol_database . Default ( ) <EOL> DESCRIPTOR = _descriptor . FileDescriptor ( <EOL> name = '<STR_LIT>' , <EOL> package = '<STR_LIT>' , <EOL> serialized_pb = _b ( '<STR_LIT>' ) <EOL> ) <EOL> _sym_db . RegisterFileDescriptor ( DESCRIPTOR ) <EOL> _PEERSEEDS = _descriptor . Descriptor ( <EOL> name = '<STR_LIT>' , <EOL> full_name = '<STR_LIT>' , <EOL> filename = None , <EOL> file = DESCRIPTOR , <EOL> containing_type = None , <EOL> fields = [ <EOL> _descriptor . FieldDescriptor ( <EOL> name = '<STR_LIT>' , full_name = '<STR_LIT>' , index = <NUM_LIT:0> , <EOL> number = <NUM_LIT:1> , type = <NUM_LIT:12> , cpp_type = <NUM_LIT:9> , label = <NUM_LIT:3> , <EOL> has_default_value = False , default_value = [ ] , <EOL> message_type = None , enum_type = None , containing_type = None , <EOL> is_extension = False , extension_scope = None , <EOL> options = None ) , <EOL> _descriptor . FieldDescriptor ( <EOL> name = '<STR_LIT>' , full_name = '<STR_LIT>' , index = <NUM_LIT:1> , <EOL> number = <NUM_LIT:2> , type = <NUM_LIT:12> , cpp_type = <NUM_LIT:9> , label = <NUM_LIT:2> , <EOL> has_default_value = False , default_value = _b ( "<STR_LIT>" ) , <EOL> message_type = None , enum_type = None , containing_type = None , <EOL> is_extension = False , extension_scope = None , <EOL> options = None ) , <EOL> ] , <EOL> extensions = [ <EOL> ] , <EOL> nested_types = [ ] , <EOL> enum_types = [ <EOL> ] , <EOL> options = None , <EOL> is_extendable = False , <EOL> extension_ranges = [ ] , <EOL> oneofs = [ <EOL> ] , <EOL> serialized_start = <NUM_LIT:15> , <EOL> serialized_end = <NUM_LIT> , <EOL> ) <EOL> DESCRIPTOR . message_types_by_name [ '<STR_LIT>' ] = _PEERSEEDS <EOL> PeerSeeds = _reflection . GeneratedProtocolMessageType ( '<STR_LIT>' , ( _message . Message , ) , dict ( <EOL> DESCRIPTOR = _PEERSEEDS , <EOL> __module__ = '<STR_LIT>' <EOL> ) ) <EOL> _sym_db . RegisterMessage ( PeerSeeds ) </s>
<s> from kmip . core . enums import Tags <EOL> from kmip . core . primitives import Struct <EOL> from kmip . core . primitives import ByteString <EOL> from kmip . core . utils import BytearrayStream <EOL> class RawKey ( ByteString ) : <EOL> def __init__ ( self , value = None ) : <EOL> super ( RawKey , self ) . __init__ ( value , Tags . KEY_MATERIAL ) <EOL> class OpaqueKey ( ByteString ) : <EOL> def __init__ ( self , value = None ) : <EOL> super ( OpaqueKey , self ) . __init__ ( value , Tags . KEY_MATERIAL ) <EOL> class PKCS1Key ( ByteString ) : <EOL> def __init__ ( self , value = None ) : <EOL> super ( PKCS1Key , self ) . __init__ ( value , Tags . KEY_MATERIAL ) <EOL> class PKCS8Key ( ByteString ) : <EOL> def __init__ ( self , value = None ) : <EOL> super ( PKCS8Key , self ) . __init__ ( value , Tags . KEY_MATERIAL ) <EOL> class X509Key ( ByteString ) : <EOL> def __init__ ( self , value = None ) : <EOL> super ( X509Key , self ) . __init__ ( value , Tags . KEY_MATERIAL ) <EOL> class ECPrivateKey ( ByteString ) : <EOL> def __init__ ( self , value = None ) : <EOL> super ( ECPrivateKey , self ) . __init__ ( value , Tags . KEY_MATERIAL ) <EOL> class TransparentSymmetricKey ( Struct ) : <EOL> class Key ( ByteString ) : <EOL> def __init__ ( self , value = None ) : <EOL> super ( TransparentSymmetricKey . Key , self ) . __init__ ( value , Tags . KEY ) <EOL> def __init__ ( self , key = None ) : <EOL> super ( TransparentSymmetricKey , self ) . __init__ ( Tags . KEY_MATERIAL ) <EOL> self . key = key <EOL> self . validate ( ) <EOL> def read ( self , istream ) : <EOL> super ( TransparentSymmetricKey , self ) . read ( istream ) <EOL> tstream = BytearrayStream ( istream . read ( self . length ) ) <EOL> self . key = TransparentSymmetricKey . Key ( ) <EOL> self . key . read ( tstream ) <EOL> self . is_oversized ( tstream ) <EOL> self . validate ( ) <EOL> def write ( self , ostream ) : <EOL> tstream = BytearrayStream ( ) <EOL> self . key . write ( tstream ) <EOL> self . length = tstream . length ( ) <EOL> super ( TransparentSymmetricKey , self ) . write ( ostream ) <EOL> ostream . write ( tstream . buffer ) <EOL> def validate ( self ) : <EOL> self . __validate ( ) <EOL> def __validate ( self ) : <EOL> pass </s>
<s> import logging <EOL> import sys <EOL> from kmip . core import enums <EOL> from kmip . demos import utils <EOL> from kmip . pie import client <EOL> from kmip . pie import objects <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> logger = utils . build_console_logger ( logging . INFO ) <EOL> parser = utils . build_cli_parser ( ) <EOL> opts , args = parser . parse_args ( sys . argv [ <NUM_LIT:1> : ] ) <EOL> config = opts . config <EOL> value = b'<STR_LIT>' <EOL> opaque_type = enums . OpaqueDataType . NONE <EOL> name = '<STR_LIT>' <EOL> obj = objects . OpaqueObject ( value , opaque_type , name ) <EOL> with client . ProxyKmipClient ( config = config ) as client : <EOL> try : <EOL> uid = client . register ( obj ) <EOL> logger . info ( "<STR_LIT>" <EOL> "<STR_LIT>" . format ( uid ) ) <EOL> except Exception as e : <EOL> logger . error ( e ) </s>
<s> import logging <EOL> import os <EOL> import six <EOL> from six . moves import configparser <EOL> from kmip . core import exceptions <EOL> class KmipServerConfig ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self ) : <EOL> """<STR_LIT>""" <EOL> self . _logger = logging . getLogger ( '<STR_LIT>' ) <EOL> self . settings = dict ( ) <EOL> self . _expected_settings = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT:port>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' <EOL> ] <EOL> def set_setting ( self , setting , value ) : <EOL> """<STR_LIT>""" <EOL> if setting not in self . _expected_settings : <EOL> raise exceptions . ConfigurationError ( <EOL> "<STR_LIT>" . format ( setting ) <EOL> ) <EOL> if setting == '<STR_LIT>' : <EOL> self . _set_hostname ( value ) <EOL> elif setting == '<STR_LIT:port>' : <EOL> self . _set_port ( value ) <EOL> elif setting == '<STR_LIT>' : <EOL> self . _set_certificate_path ( value ) <EOL> elif setting == '<STR_LIT>' : <EOL> self . _set_key_path ( value ) <EOL> elif setting == '<STR_LIT>' : <EOL> self . _set_ca_path ( value ) <EOL> else : <EOL> self . _set_auth_suite ( value ) <EOL> def load_settings ( self , path ) : <EOL> """<STR_LIT>""" <EOL> if not os . path . exists ( path ) : <EOL> raise exceptions . ConfigurationError ( <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" . format ( path ) <EOL> ) <EOL> self . _logger . info ( <EOL> "<STR_LIT>" . format ( path ) <EOL> ) <EOL> parser = configparser . SafeConfigParser ( ) <EOL> parser . read ( path ) <EOL> self . _parse_settings ( parser ) <EOL> def _parse_settings ( self , parser ) : <EOL> if not parser . has_section ( '<STR_LIT>' ) : <EOL> raise exceptions . ConfigurationError ( <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> ) <EOL> settings = [ x [ <NUM_LIT:0> ] for x in parser . items ( '<STR_LIT>' ) ] <EOL> for setting in settings : <EOL> if setting not in self . _expected_settings : <EOL> raise exceptions . ConfigurationError ( <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" . format ( setting ) <EOL> ) <EOL> for setting in self . _expected_settings : <EOL> if setting not in settings : <EOL> raise exceptions . ConfigurationError ( <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" . format ( setting ) <EOL> ) <EOL> if parser . has_option ( '<STR_LIT>' , '<STR_LIT>' ) : <EOL> self . _set_hostname ( parser . get ( '<STR_LIT>' , '<STR_LIT>' ) ) <EOL> if parser . has_option ( '<STR_LIT>' , '<STR_LIT:port>' ) : <EOL> self . _set_port ( parser . getint ( '<STR_LIT>' , '<STR_LIT:port>' ) ) <EOL> if parser . has_option ( '<STR_LIT>' , '<STR_LIT>' ) : <EOL> self . _set_certificate_path ( parser . get ( <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' ) <EOL> ) <EOL> if parser . has_option ( '<STR_LIT>' , '<STR_LIT>' ) : <EOL> self . _set_key_path ( parser . get ( '<STR_LIT>' , '<STR_LIT>' ) ) <EOL> if parser . has_option ( '<STR_LIT>' , '<STR_LIT>' ) : <EOL> self . _set_ca_path ( parser . get ( '<STR_LIT>' , '<STR_LIT>' ) ) <EOL> if parser . has_option ( '<STR_LIT>' , '<STR_LIT>' ) : <EOL> self . _set_auth_suite ( parser . get ( '<STR_LIT>' , '<STR_LIT>' ) ) <EOL> def _set_hostname ( self , value ) : <EOL> if isinstance ( value , six . string_types ) : <EOL> self . settings [ '<STR_LIT>' ] = value <EOL> else : <EOL> raise exceptions . ConfigurationError ( <EOL> "<STR_LIT>" <EOL> ) <EOL> def _set_port ( self , value ) : <EOL> if isinstance ( value , six . integer_types ) : <EOL> if <NUM_LIT:0> < value < <NUM_LIT> : <EOL> self . settings [ '<STR_LIT:port>' ] = value <EOL> else : <EOL> raise exceptions . ConfigurationError ( <EOL> "<STR_LIT>" <EOL> ) <EOL> else : <EOL> raise exceptions . ConfigurationError ( <EOL> "<STR_LIT>" <EOL> ) <EOL> def _set_certificate_path ( self , value ) : <EOL> if value is None : <EOL> self . settings [ '<STR_LIT>' ] = None <EOL> elif isinstance ( value , six . string_types ) : <EOL> if os . path . exists ( value ) : <EOL> self . settings [ '<STR_LIT>' ] = value <EOL> else : <EOL> raise exceptions . ConfigurationError ( <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> ) <EOL> else : <EOL> raise exceptions . ConfigurationError ( <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> ) <EOL> def _set_key_path ( self , value ) : <EOL> if value is None : <EOL> self . settings [ '<STR_LIT>' ] = None <EOL> elif isinstance ( value , six . string_types ) : <EOL> if os . path . exists ( value ) : <EOL> self . settings [ '<STR_LIT>' ] = value <EOL> else : <EOL> raise exceptions . ConfigurationError ( <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> ) <EOL> else : <EOL> raise exceptions . ConfigurationError ( <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> ) <EOL> def _set_ca_path ( self , value ) : <EOL> if value is None : <EOL> self . settings [ '<STR_LIT>' ] = None <EOL> elif isinstance ( value , six . string_types ) : <EOL> if os . path . exists ( value ) : <EOL> self . settings [ '<STR_LIT>' ] = value <EOL> else : <EOL> raise exceptions . ConfigurationError ( <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> ) <EOL> else : <EOL> raise exceptions . ConfigurationError ( <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> ) <EOL> def _set_auth_suite ( self , value ) : <EOL> auth_suites = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> if value not in auth_suites : <EOL> raise exceptions . ConfigurationError ( <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> ) <EOL> else : <EOL> self . settings [ '<STR_LIT>' ] = value </s>
<s> from six . moves import xrange <EOL> from testtools import TestCase <EOL> from kmip . core import utils <EOL> from kmip . core . messages . contents import ProtocolVersion <EOL> from kmip . core . messages . payloads import discover_versions <EOL> class TestDiscoverVersionsRequestPayload ( TestCase ) : <EOL> def setUp ( self ) : <EOL> super ( TestDiscoverVersionsRequestPayload , self ) . setUp ( ) <EOL> self . protocol_versions_empty = list ( ) <EOL> self . protocol_versions_one = list ( ) <EOL> self . protocol_versions_one . append ( ProtocolVersion . create ( <NUM_LIT:1> , <NUM_LIT:0> ) ) <EOL> self . protocol_versions_two = list ( ) <EOL> self . protocol_versions_two . append ( ProtocolVersion . create ( <NUM_LIT:1> , <NUM_LIT:1> ) ) <EOL> self . protocol_versions_two . append ( ProtocolVersion . create ( <NUM_LIT:1> , <NUM_LIT:0> ) ) <EOL> self . encoding_empty = utils . BytearrayStream ( ( <EOL> b'<STR_LIT>' ) ) <EOL> self . encoding_one = utils . BytearrayStream ( ( <EOL> b'<STR_LIT>' <EOL> b'<STR_LIT>' <EOL> b'<STR_LIT>' <EOL> b'<STR_LIT:\x00>' ) ) <EOL> self . encoding_two = utils . BytearrayStream ( ( <EOL> b'<STR_LIT>' <EOL> b'<STR_LIT>' <EOL> b'<STR_LIT>' <EOL> b'<STR_LIT>' <EOL> b'<STR_LIT>' <EOL> b'<STR_LIT>' ) ) <EOL> def tearDown ( self ) : <EOL> super ( TestDiscoverVersionsRequestPayload , self ) . tearDown ( ) <EOL> def test_init_with_none ( self ) : <EOL> discover_versions . DiscoverVersionsRequestPayload ( ) <EOL> def test_init_with_args ( self ) : <EOL> discover_versions . DiscoverVersionsRequestPayload ( <EOL> self . protocol_versions_empty ) <EOL> def test_validate_with_invalid_protocol_versions ( self ) : <EOL> kwargs = { '<STR_LIT>' : '<STR_LIT>' } <EOL> self . assertRaisesRegexp ( <EOL> TypeError , "<STR_LIT>" , <EOL> discover_versions . DiscoverVersionsRequestPayload , ** kwargs ) <EOL> def test_validate_with_invalid_protocol_version ( self ) : <EOL> kwargs = { '<STR_LIT>' : [ '<STR_LIT>' ] } <EOL> self . assertRaisesRegexp ( <EOL> TypeError , "<STR_LIT>" , <EOL> discover_versions . DiscoverVersionsRequestPayload , ** kwargs ) <EOL> def _test_read ( self , stream , payload , protocol_versions ) : <EOL> payload . read ( stream ) <EOL> expected = len ( protocol_versions ) <EOL> observed = len ( payload . protocol_versions ) <EOL> msg = "<STR_LIT>" <EOL> msg += "<STR_LIT>" . format ( <EOL> expected , observed ) <EOL> self . assertEqual ( expected , observed , msg ) <EOL> for i in xrange ( len ( protocol_versions ) ) : <EOL> expected = protocol_versions [ i ] <EOL> observed = payload . protocol_versions [ i ] <EOL> msg = "<STR_LIT>" <EOL> msg += "<STR_LIT>" . format ( expected , observed ) <EOL> self . assertEqual ( expected , observed , msg ) <EOL> def test_read_with_empty_protocol_list ( self ) : <EOL> stream = self . encoding_empty <EOL> payload = discover_versions . DiscoverVersionsRequestPayload ( ) <EOL> protocol_versions = self . protocol_versions_empty <EOL> self . _test_read ( stream , payload , protocol_versions ) <EOL> def test_read_with_one_protocol_version ( self ) : <EOL> stream = self . encoding_one <EOL> payload = discover_versions . DiscoverVersionsRequestPayload ( ) <EOL> protocol_versions = self . protocol_versions_one <EOL> self . _test_read ( stream , payload , protocol_versions ) <EOL> def test_read_with_two_protocol_versions ( self ) : <EOL> stream = self . encoding_two <EOL> payload = discover_versions . DiscoverVersionsRequestPayload ( ) <EOL> protocol_versions = self . protocol_versions_two <EOL> self . _test_read ( stream , payload , protocol_versions ) <EOL> def _test_write ( self , payload , expected ) : <EOL> stream = utils . BytearrayStream ( ) <EOL> payload . write ( stream ) <EOL> length_expected = len ( expected ) <EOL> length_received = len ( stream ) <EOL> msg = "<STR_LIT>" <EOL> msg += "<STR_LIT>" . format ( <EOL> length_expected , length_received ) <EOL> self . assertEqual ( length_expected , length_received , msg ) <EOL> msg = "<STR_LIT>" <EOL> msg += "<STR_LIT>" . format ( expected , stream ) <EOL> self . assertEqual ( expected , stream , msg ) <EOL> def test_write_with_empty_protocol_list ( self ) : <EOL> payload = discover_versions . DiscoverVersionsRequestPayload ( <EOL> self . protocol_versions_empty ) <EOL> expected = self . encoding_empty <EOL> self . _test_write ( payload , expected ) <EOL> def test_write_with_one_protocol_version ( self ) : <EOL> payload = discover_versions . DiscoverVersionsRequestPayload ( <EOL> self . protocol_versions_one ) <EOL> expected = self . encoding_one <EOL> self . _test_write ( payload , expected ) <EOL> def test_write_with_two_protocol_versions ( self ) : <EOL> payload = discover_versions . DiscoverVersionsRequestPayload ( <EOL> self . protocol_versions_two ) <EOL> expected = self . encoding_two <EOL> self . _test_write ( payload , expected ) <EOL> class TestDiscoverVersionsResponsePayload ( TestCase ) : <EOL> def setUp ( self ) : <EOL> super ( TestDiscoverVersionsResponsePayload , self ) . setUp ( ) <EOL> self . protocol_versions_empty = list ( ) <EOL> self . protocol_versions_one = list ( ) <EOL> self . protocol_versions_one . append ( ProtocolVersion . create ( <NUM_LIT:1> , <NUM_LIT:0> ) ) <EOL> self . protocol_versions_two = list ( ) <EOL> self . protocol_versions_two . append ( ProtocolVersion . create ( <NUM_LIT:1> , <NUM_LIT:1> ) ) <EOL> self . protocol_versions_two . append ( ProtocolVersion . create ( <NUM_LIT:1> , <NUM_LIT:0> ) ) <EOL> self . encoding_empty = utils . BytearrayStream ( ( <EOL> b'<STR_LIT>' ) ) <EOL> self . encoding_one = utils . BytearrayStream ( ( <EOL> b'<STR_LIT>' <EOL> b'<STR_LIT>' <EOL> b'<STR_LIT>' <EOL> b'<STR_LIT:\x00>' ) ) <EOL> self . encoding_two = utils . BytearrayStream ( ( <EOL> b'<STR_LIT>' <EOL> b'<STR_LIT>' <EOL> b'<STR_LIT>' <EOL> b'<STR_LIT>' <EOL> b'<STR_LIT>' <EOL> b'<STR_LIT>' ) ) <EOL> def tearDown ( self ) : <EOL> super ( TestDiscoverVersionsResponsePayload , self ) . tearDown ( ) <EOL> def test_init_with_none ( self ) : <EOL> discover_versions . DiscoverVersionsResponsePayload ( ) <EOL> def test_init_with_args ( self ) : <EOL> discover_versions . DiscoverVersionsResponsePayload ( <EOL> self . protocol_versions_empty ) <EOL> def test_validate_with_invalid_protocol_versions ( self ) : <EOL> kwargs = { '<STR_LIT>' : '<STR_LIT>' } <EOL> self . assertRaisesRegexp ( <EOL> TypeError , "<STR_LIT>" , <EOL> discover_versions . DiscoverVersionsResponsePayload , ** kwargs ) <EOL> def test_validate_with_invalid_protocol_version ( self ) : <EOL> kwargs = { '<STR_LIT>' : [ '<STR_LIT>' ] } <EOL> self . assertRaisesRegexp ( <EOL> TypeError , "<STR_LIT>" , <EOL> discover_versions . DiscoverVersionsResponsePayload , ** kwargs ) <EOL> def _test_read ( self , stream , payload , protocol_versions ) : <EOL> payload . read ( stream ) <EOL> expected = len ( protocol_versions ) <EOL> observed = len ( payload . protocol_versions ) <EOL> msg = "<STR_LIT>" <EOL> msg += "<STR_LIT>" . format ( <EOL> expected , observed ) <EOL> self . assertEqual ( expected , observed , msg ) <EOL> for i in xrange ( len ( protocol_versions ) ) : <EOL> expected = protocol_versions [ i ] <EOL> observed = payload . protocol_versions [ i ] <EOL> msg = "<STR_LIT>" <EOL> msg += "<STR_LIT>" . format ( expected , observed ) <EOL> self . assertEqual ( expected , observed , msg ) <EOL> def test_read_with_empty_protocol_list ( self ) : <EOL> stream = self . encoding_empty <EOL> payload = discover_versions . DiscoverVersionsResponsePayload ( ) <EOL> protocol_versions = self . protocol_versions_empty <EOL> self . _test_read ( stream , payload , protocol_versions ) <EOL> def test_read_with_one_protocol_version ( self ) : <EOL> stream = self . encoding_one <EOL> payload = discover_versions . DiscoverVersionsResponsePayload ( ) <EOL> protocol_versions = self . protocol_versions_one <EOL> self . _test_read ( stream , payload , protocol_versions ) <EOL> def test_read_with_two_protocol_versions ( self ) : <EOL> stream = self . encoding_two <EOL> payload = discover_versions . DiscoverVersionsResponsePayload ( ) <EOL> protocol_versions = self . protocol_versions_two <EOL> self . _test_read ( stream , payload , protocol_versions ) <EOL> def _test_write ( self , payload , expected ) : <EOL> stream = utils . BytearrayStream ( ) <EOL> payload . write ( stream ) <EOL> length_expected = len ( expected ) <EOL> length_received = len ( stream ) <EOL> msg = "<STR_LIT>" <EOL> msg += "<STR_LIT>" . format ( <EOL> length_expected , length_received ) <EOL> self . assertEqual ( length_expected , length_received , msg ) <EOL> msg = "<STR_LIT>" <EOL> msg += "<STR_LIT>" . format ( expected , stream ) <EOL> self . assertEqual ( expected , stream , msg ) <EOL> def test_write_with_empty_protocol_list ( self ) : <EOL> payload = discover_versions . DiscoverVersionsResponsePayload ( <EOL> self . protocol_versions_empty ) <EOL> expected = self . encoding_empty <EOL> self . _test_write ( payload , expected ) <EOL> def test_write_with_one_protocol_version ( self ) : <EOL> payload = discover_versions . DiscoverVersionsResponsePayload ( <EOL> self . protocol_versions_one ) <EOL> expected = self . encoding_one <EOL> self . _test_write ( payload , expected ) <EOL> def test_write_with_two_protocol_versions ( self ) : <EOL> payload = discover_versions . DiscoverVersionsResponsePayload ( <EOL> self . protocol_versions_two ) <EOL> expected = self . encoding_two <EOL> self . _test_write ( payload , expected ) </s>
<s> import binascii <EOL> import testtools <EOL> from kmip . core import enums <EOL> from kmip . pie . objects import ManagedObject , OpaqueObject <EOL> from kmip . pie import sqltypes <EOL> from sqlalchemy import create_engine <EOL> from sqlalchemy . orm import sessionmaker <EOL> class TestOpaqueObject ( testtools . TestCase ) : <EOL> """<STR_LIT>""" <EOL> def setUp ( self ) : <EOL> super ( TestOpaqueObject , self ) . setUp ( ) <EOL> self . bytes_a = ( <EOL> b'<STR_LIT>' ) <EOL> self . bytes_b = ( <EOL> b'<STR_LIT>' ) <EOL> self . engine = create_engine ( '<STR_LIT>' , echo = True ) <EOL> sqltypes . Base . metadata . create_all ( self . engine ) <EOL> def tearDown ( self ) : <EOL> super ( TestOpaqueObject , self ) . tearDown ( ) <EOL> def test_init ( self ) : <EOL> """<STR_LIT>""" <EOL> obj = OpaqueObject ( <EOL> self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> self . assertEqual ( obj . value , self . bytes_a ) <EOL> self . assertEqual ( obj . opaque_type , enums . OpaqueDataType . NONE ) <EOL> self . assertEqual ( obj . names , [ '<STR_LIT>' ] ) <EOL> def test_init_with_args ( self ) : <EOL> """<STR_LIT>""" <EOL> obj = OpaqueObject ( <EOL> self . bytes_a , <EOL> enums . OpaqueDataType . NONE , <EOL> name = '<STR_LIT>' ) <EOL> self . assertEqual ( obj . value , self . bytes_a ) <EOL> self . assertEqual ( obj . opaque_type , enums . OpaqueDataType . NONE ) <EOL> self . assertEqual ( obj . names , [ '<STR_LIT>' ] ) <EOL> def test_get_object_type ( self ) : <EOL> """<STR_LIT>""" <EOL> expected = enums . ObjectType . OPAQUE_DATA <EOL> obj = OpaqueObject ( self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> observed = obj . object_type <EOL> self . assertEqual ( expected , observed ) <EOL> def test_validate_on_invalid_value ( self ) : <EOL> """<STR_LIT>""" <EOL> args = ( <NUM_LIT:0> , enums . OpaqueDataType . NONE ) <EOL> self . assertRaises ( TypeError , OpaqueObject , * args ) <EOL> def test_validate_on_invalid_data_type ( self ) : <EOL> """<STR_LIT>""" <EOL> args = ( self . bytes_a , '<STR_LIT>' ) <EOL> self . assertRaises ( TypeError , OpaqueObject , * args ) <EOL> def test_validate_on_invalid_name ( self ) : <EOL> """<STR_LIT>""" <EOL> args = ( self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> kwargs = { '<STR_LIT:name>' : <NUM_LIT:0> } <EOL> self . assertRaises ( TypeError , OpaqueObject , * args , ** kwargs ) <EOL> def test_repr ( self ) : <EOL> """<STR_LIT>""" <EOL> obj = OpaqueObject ( self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> args = "<STR_LIT>" . format ( <EOL> binascii . hexlify ( self . bytes_a ) , enums . OpaqueDataType . NONE ) <EOL> expected = "<STR_LIT>" . format ( args ) <EOL> observed = repr ( obj ) <EOL> self . assertEqual ( expected , observed ) <EOL> def test_str ( self ) : <EOL> """<STR_LIT>""" <EOL> obj = OpaqueObject ( self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> expected = str ( binascii . hexlify ( self . bytes_a ) ) <EOL> observed = str ( obj ) <EOL> self . assertEqual ( expected , observed ) <EOL> def test_equal_on_equal ( self ) : <EOL> """<STR_LIT>""" <EOL> a = OpaqueObject ( self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> b = OpaqueObject ( self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> self . assertTrue ( a == b ) <EOL> self . assertTrue ( b == a ) <EOL> def test_equal_on_not_equal_value ( self ) : <EOL> """<STR_LIT>""" <EOL> a = OpaqueObject ( self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> b = OpaqueObject ( self . bytes_b , enums . OpaqueDataType . NONE ) <EOL> self . assertFalse ( a == b ) <EOL> self . assertFalse ( b == a ) <EOL> def test_equal_on_not_equal_data_type ( self ) : <EOL> """<STR_LIT>""" <EOL> a = OpaqueObject ( self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> b = OpaqueObject ( self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> b . opaque_type = "<STR_LIT>" <EOL> self . assertFalse ( a == b ) <EOL> self . assertFalse ( b == a ) <EOL> def test_equal_on_type_mismatch ( self ) : <EOL> """<STR_LIT>""" <EOL> a = OpaqueObject ( self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> b = "<STR_LIT>" <EOL> self . assertFalse ( a == b ) <EOL> self . assertFalse ( b == a ) <EOL> def test_not_equal_on_equal ( self ) : <EOL> """<STR_LIT>""" <EOL> a = OpaqueObject ( self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> b = OpaqueObject ( self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> self . assertFalse ( a != b ) <EOL> self . assertFalse ( b != a ) <EOL> def test_not_equal_on_not_equal_value ( self ) : <EOL> """<STR_LIT>""" <EOL> a = OpaqueObject ( self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> b = OpaqueObject ( self . bytes_b , enums . OpaqueDataType . NONE ) <EOL> self . assertTrue ( a != b ) <EOL> self . assertTrue ( b != a ) <EOL> def test_not_equal_on_not_equal_data_type ( self ) : <EOL> """<STR_LIT>""" <EOL> a = OpaqueObject ( self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> b = OpaqueObject ( self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> b . opaque_type = "<STR_LIT>" <EOL> self . assertTrue ( a != b ) <EOL> self . assertTrue ( b != a ) <EOL> def test_not_equal_on_type_mismatch ( self ) : <EOL> """<STR_LIT>""" <EOL> a = OpaqueObject ( self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> b = "<STR_LIT>" <EOL> self . assertTrue ( a != b ) <EOL> self . assertTrue ( b != a ) <EOL> def test_save ( self ) : <EOL> """<STR_LIT>""" <EOL> obj = OpaqueObject ( <EOL> self . bytes_a , enums . OpaqueDataType . NONE ) <EOL> Session = sessionmaker ( bind = self . engine ) <EOL> session = Session ( ) <EOL> session . add ( obj ) <EOL> session . commit ( ) <EOL> def test_get ( self ) : <EOL> """<STR_LIT>""" <EOL> test_name = '<STR_LIT>' <EOL> obj = OpaqueObject ( <EOL> self . bytes_a , enums . OpaqueDataType . NONE , name = test_name ) <EOL> Session = sessionmaker ( bind = self . engine ) <EOL> session = Session ( ) <EOL> session . add ( obj ) <EOL> session . commit ( ) <EOL> session = Session ( ) <EOL> get_obj = session . query ( OpaqueObject ) . filter ( <EOL> ManagedObject . unique_identifier == obj . unique_identifier <EOL> ) . one ( ) <EOL> session . commit ( ) <EOL> self . assertEqual ( <NUM_LIT:1> , len ( get_obj . names ) ) <EOL> self . assertEqual ( [ test_name ] , get_obj . names ) <EOL> self . assertEqual ( self . bytes_a , get_obj . value ) <EOL> self . assertEqual ( enums . ObjectType . OPAQUE_DATA , get_obj . object_type ) <EOL> self . assertEqual ( enums . OpaqueDataType . NONE , get_obj . opaque_type ) <EOL> def test_add_multiple_names ( self ) : <EOL> """<STR_LIT>""" <EOL> expected_names = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> obj = OpaqueObject ( <EOL> self . bytes_a , enums . OpaqueDataType . NONE , name = expected_names [ <NUM_LIT:0> ] ) <EOL> obj . names . append ( expected_names [ <NUM_LIT:1> ] ) <EOL> obj . names . append ( expected_names [ <NUM_LIT:2> ] ) <EOL> self . assertEquals ( <NUM_LIT:3> , obj . name_index ) <EOL> expected_mo_names = list ( ) <EOL> for i , name in enumerate ( expected_names ) : <EOL> expected_mo_names . append ( sqltypes . ManagedObjectName ( name , i ) ) <EOL> self . assertEquals ( expected_mo_names , obj . _names ) <EOL> Session = sessionmaker ( bind = self . engine ) <EOL> session = Session ( ) <EOL> session . add ( obj ) <EOL> session . commit ( ) <EOL> session = Session ( ) <EOL> get_obj = session . query ( OpaqueObject ) . filter ( <EOL> ManagedObject . unique_identifier == obj . unique_identifier <EOL> ) . one ( ) <EOL> session . commit ( ) <EOL> self . assertEquals ( expected_mo_names , get_obj . _names ) <EOL> def test_remove_name ( self ) : <EOL> """<STR_LIT>""" <EOL> names = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> remove_index = <NUM_LIT:1> <EOL> obj = OpaqueObject ( <EOL> self . bytes_a , enums . OpaqueDataType . NONE , name = names [ <NUM_LIT:0> ] ) <EOL> obj . names . append ( names [ <NUM_LIT:1> ] ) <EOL> obj . names . append ( names [ <NUM_LIT:2> ] ) <EOL> obj . names . pop ( remove_index ) <EOL> self . assertEquals ( <NUM_LIT:3> , obj . name_index ) <EOL> expected_names = list ( ) <EOL> expected_mo_names = list ( ) <EOL> for i , name in enumerate ( names ) : <EOL> if i != remove_index : <EOL> expected_names . append ( name ) <EOL> expected_mo_names . append ( sqltypes . ManagedObjectName ( name , i ) ) <EOL> self . assertEquals ( expected_names , obj . names ) <EOL> self . assertEquals ( expected_mo_names , obj . _names ) <EOL> Session = sessionmaker ( bind = self . engine ) <EOL> session = Session ( ) <EOL> session . add ( obj ) <EOL> session . commit ( ) <EOL> session = Session ( ) <EOL> get_obj = session . query ( OpaqueObject ) . filter ( <EOL> ManagedObject . unique_identifier == obj . unique_identifier <EOL> ) . one ( ) <EOL> session . commit ( ) <EOL> self . assertEquals ( expected_names , get_obj . names ) <EOL> self . assertEquals ( expected_mo_names , get_obj . _names ) <EOL> def test_remove_and_add_name ( self ) : <EOL> """<STR_LIT>""" <EOL> names = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> obj = OpaqueObject ( <EOL> self . bytes_a , enums . OpaqueDataType . NONE , name = names [ <NUM_LIT:0> ] ) <EOL> obj . names . append ( names [ <NUM_LIT:1> ] ) <EOL> obj . names . append ( names [ <NUM_LIT:2> ] ) <EOL> obj . names . pop ( ) <EOL> obj . names . pop ( ) <EOL> obj . names . append ( '<STR_LIT>' ) <EOL> self . assertEquals ( <NUM_LIT:4> , obj . name_index ) <EOL> expected_names = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> expected_mo_names = list ( ) <EOL> expected_mo_names . append ( sqltypes . ManagedObjectName ( expected_names [ <NUM_LIT:0> ] , <EOL> <NUM_LIT:0> ) ) <EOL> expected_mo_names . append ( sqltypes . ManagedObjectName ( expected_names [ <NUM_LIT:1> ] , <EOL> <NUM_LIT:3> ) ) <EOL> self . assertEquals ( expected_names , obj . names ) <EOL> self . assertEquals ( expected_mo_names , obj . _names ) <EOL> Session = sessionmaker ( bind = self . engine ) <EOL> session = Session ( ) <EOL> session . add ( obj ) <EOL> session . commit ( ) <EOL> session = Session ( ) <EOL> get_obj = session . query ( OpaqueObject ) . filter ( <EOL> ManagedObject . unique_identifier == obj . unique_identifier <EOL> ) . one ( ) <EOL> session . commit ( ) <EOL> self . assertEquals ( expected_names , get_obj . names ) <EOL> self . assertEquals ( expected_mo_names , get_obj . _names ) <EOL> def test_update_with_add_name ( self ) : <EOL> """<STR_LIT>""" <EOL> first_name = '<STR_LIT>' <EOL> obj = OpaqueObject ( <EOL> self . bytes_a , enums . OpaqueDataType . NONE , name = first_name ) <EOL> Session = sessionmaker ( bind = self . engine ) <EOL> session = Session ( ) <EOL> session . add ( obj ) <EOL> session . commit ( ) <EOL> added_name = '<STR_LIT>' <EOL> expected_names = [ first_name , added_name ] <EOL> expected_mo_names = list ( ) <EOL> for i , name in enumerate ( expected_names ) : <EOL> expected_mo_names . append ( sqltypes . ManagedObjectName ( name , i ) ) <EOL> session = Session ( ) <EOL> update_obj = session . query ( OpaqueObject ) . filter ( <EOL> ManagedObject . unique_identifier == obj . unique_identifier <EOL> ) . one ( ) <EOL> update_obj . names . append ( added_name ) <EOL> session . commit ( ) <EOL> session = Session ( ) <EOL> get_obj = session . query ( OpaqueObject ) . filter ( <EOL> ManagedObject . unique_identifier == obj . unique_identifier <EOL> ) . one ( ) <EOL> session . commit ( ) <EOL> self . assertEquals ( expected_names , get_obj . names ) <EOL> self . assertEquals ( expected_mo_names , get_obj . _names ) <EOL> def test_update_with_remove_name ( self ) : <EOL> """<STR_LIT>""" <EOL> names = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> remove_index = <NUM_LIT:1> <EOL> obj = OpaqueObject ( <EOL> self . bytes_a , enums . OpaqueDataType . NONE , name = names [ <NUM_LIT:0> ] ) <EOL> obj . names . append ( names [ <NUM_LIT:1> ] ) <EOL> obj . names . append ( names [ <NUM_LIT:2> ] ) <EOL> Session = sessionmaker ( bind = self . engine ) <EOL> session = Session ( ) <EOL> session . add ( obj ) <EOL> session . commit ( ) <EOL> expected_names = list ( ) <EOL> expected_mo_names = list ( ) <EOL> for i , name in enumerate ( names ) : <EOL> if i != remove_index : <EOL> expected_names . append ( name ) <EOL> expected_mo_names . append ( sqltypes . ManagedObjectName ( name , i ) ) <EOL> session = Session ( ) <EOL> update_obj = session . query ( OpaqueObject ) . filter ( <EOL> ManagedObject . unique_identifier == obj . unique_identifier <EOL> ) . one ( ) <EOL> update_obj . names . pop ( remove_index ) <EOL> session . commit ( ) <EOL> session = Session ( ) <EOL> get_obj = session . query ( OpaqueObject ) . filter ( <EOL> ManagedObject . unique_identifier == obj . unique_identifier <EOL> ) . one ( ) <EOL> session . commit ( ) <EOL> self . assertEquals ( expected_names , get_obj . names ) <EOL> self . assertEquals ( expected_mo_names , get_obj . _names ) <EOL> def test_update_with_remove_and_add_name ( self ) : <EOL> """<STR_LIT>""" <EOL> names = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> obj = OpaqueObject ( <EOL> self . bytes_a , enums . OpaqueDataType . NONE , name = names [ <NUM_LIT:0> ] ) <EOL> obj . names . append ( names [ <NUM_LIT:1> ] ) <EOL> obj . names . append ( names [ <NUM_LIT:2> ] ) <EOL> Session = sessionmaker ( bind = self . engine ) <EOL> session = Session ( ) <EOL> session . add ( obj ) <EOL> session . commit ( ) <EOL> session = Session ( ) <EOL> update_obj = session . query ( OpaqueObject ) . filter ( <EOL> ManagedObject . unique_identifier == obj . unique_identifier <EOL> ) . one ( ) <EOL> update_obj . names . pop ( ) <EOL> update_obj . names . pop ( ) <EOL> update_obj . names . append ( '<STR_LIT>' ) <EOL> session . commit ( ) <EOL> expected_names = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> expected_mo_names = list ( ) <EOL> expected_mo_names . append ( sqltypes . ManagedObjectName ( expected_names [ <NUM_LIT:0> ] , <EOL> <NUM_LIT:0> ) ) <EOL> expected_mo_names . append ( sqltypes . ManagedObjectName ( expected_names [ <NUM_LIT:1> ] , <EOL> <NUM_LIT:3> ) ) <EOL> session = Session ( ) <EOL> get_obj = session . query ( OpaqueObject ) . filter ( <EOL> ManagedObject . unique_identifier == obj . unique_identifier <EOL> ) . one ( ) <EOL> session . commit ( ) <EOL> self . assertEquals ( expected_names , get_obj . names ) <EOL> self . assertEquals ( expected_mo_names , get_obj . _names ) </s>
<s> from setuptools import setup , find_packages <EOL> kwargs = { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : [ '<STR_LIT>' , <EOL> '<STR_LIT>' ] , <EOL> '<STR_LIT:description>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : True , <EOL> '<STR_LIT>' : [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:name>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : { '<STR_LIT>' : [ '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' ] } , <EOL> '<STR_LIT>' : { '<STR_LIT>' : '<STR_LIT:src>' } , <EOL> '<STR_LIT>' : [ '<STR_LIT>' , '<STR_LIT>' ] , <EOL> '<STR_LIT:url>' : '<STR_LIT>' , <EOL> '<STR_LIT:version>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : False } <EOL> setup ( ** kwargs ) </s>
<s> import os . path <EOL> import setuptools <EOL> import sys <EOL> from numpy . distutils . core import setup <EOL> from numpy . distutils . misc_util import Configuration <EOL> include_dirs = [ ] <EOL> library_dirs = [ ] <EOL> if sys . platform == '<STR_LIT:win32>' : <EOL> import types <EOL> def _lib_dir_option ( self , dir ) : <EOL> return '<STR_LIT>' % dir <EOL> from distutils . msvc9compiler import MSVCCompiler <EOL> setattr ( MSVCCompiler , '<STR_LIT>' , <EOL> types . MethodType ( _lib_dir_option , None , MSVCCompiler ) ) <EOL> sdkdir = os . environ . get ( '<STR_LIT>' ) <EOL> if sdkdir : <EOL> include_dirs . append ( os . path . join ( sdkdir , '<STR_LIT>' ) ) <EOL> library_dirs . append ( os . path . join ( sdkdir , '<STR_LIT>' ) ) <EOL> path = os . environ [ '<STR_LIT>' ] . split ( '<STR_LIT:;>' ) <EOL> path . append ( os . path . join ( sdkdir , '<STR_LIT>' ) ) <EOL> os . environ [ '<STR_LIT>' ] = '<STR_LIT:;>' . join ( path ) <EOL> config = Configuration ( name = '<STR_LIT>' ) <EOL> config . add_extension ( '<STR_LIT>' , <EOL> sources = [ '<STR_LIT>' , <EOL> '<STR_LIT>' ] , <EOL> include_dirs = include_dirs , <EOL> library_dirs = library_dirs ) <EOL> config . add_data_files ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> kwds = { '<STR_LIT>' : [ '<STR_LIT>' ] , <EOL> '<STR_LIT:version>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : False , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:url>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : { '<STR_LIT>' : [ '<STR_LIT>' ] } , <EOL> } <EOL> kwds . update ( config . todict ( ) ) <EOL> setup ( ** kwds ) </s>
<s> import sys , os <EOL> extensions = [ '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' <EOL> ] <EOL> templates_path = [ '<STR_LIT>' ] <EOL> source_suffix = '<STR_LIT>' <EOL> master_doc = '<STR_LIT:index>' <EOL> project = u'<STR_LIT>' <EOL> copyright = u'<STR_LIT:None>' <EOL> version = '<STR_LIT>' <EOL> release = '<STR_LIT>' <EOL> today_fmt = '<STR_LIT>' <EOL> exclude_trees = [ '<STR_LIT>' ] <EOL> pygments_style = '<STR_LIT>' <EOL> html_style = '<STR_LIT>' <EOL> html_last_updated_fmt = '<STR_LIT>' <EOL> html_theme = "<STR_LIT:default>" <EOL> html_theme_options = { <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> } <EOL> todo_include_todos = True <EOL> intersphinx_mapping = { '<STR_LIT>' : None } <EOL> autodoc_member_order = '<STR_LIT>' </s>
<s> import glob <EOL> import os . path <EOL> from dirwalk import includingWalk <EOL> from os import system <EOL> from subprocess import Popen , PIPE , STDOUT <EOL> from compmodtimes import compmodtimes <EOL> from PIL import Image <EOL> def resize_image ( fname , max_width = <NUM_LIT> ) : <EOL> im = Image . open ( fname ) <EOL> width , height = tuple ( im . getbbox ( ) [ <NUM_LIT:2> : ] ) <EOL> print '<STR_LIT>' , height , '<STR_LIT>' , width <EOL> if width > max_width : <EOL> wrat = max_width / float ( width ) <EOL> new_w = int ( width * wrat ) <EOL> new_h = int ( height * wrat ) <EOL> newim = im . transform ( ( new_w , new_h ) , Image . EXTENT , <EOL> im . getbbox ( ) , Image . BICUBIC ) <EOL> newim . save ( fname ) <EOL> for diafile in includingWalk ( "<STR_LIT:..>" , [ "<STR_LIT>" ] ) : <EOL> pth = os . path . split ( diafile ) <EOL> dest = pth [ <NUM_LIT:1> ] . split ( '<STR_LIT:.>' ) [ <NUM_LIT:0> ] <EOL> retcode = compmodtimes ( diafile , '<STR_LIT>' + dest + '<STR_LIT>' ) <EOL> if retcode == - <NUM_LIT:1> or retcode == <NUM_LIT:0> : <EOL> print '<STR_LIT>' + dest + '<STR_LIT>' <EOL> else : <EOL> cmd = '<STR_LIT>' + dest + '<STR_LIT>' + diafile <EOL> system ( cmd ) <EOL> resize_image ( os . path . abspath ( os . path . join ( '<STR_LIT>' , dest + '<STR_LIT>' ) ) ) </s>
<s> """<STR_LIT>""" <EOL> import numpy as np <EOL> from openmdao . main . api import Assembly , Component <EOL> from openmdao . lib . datatypes . api import Float <EOL> from openmdao . lib . drivers . api import CaseIteratorDriver <EOL> from openmdao . lib . components . api import MultiFiMetaModel <EOL> from openmdao . lib . surrogatemodels . api import MultiFiCoKrigingSurrogate , KrigingSurrogate <EOL> class Model ( Component ) : <EOL> x = Float ( <NUM_LIT:0> , iotype = "<STR_LIT>" ) <EOL> f_x = Float ( <NUM_LIT:0.0> , iotype = "<STR_LIT>" ) <EOL> def execute ( self ) : <EOL> x = self . x <EOL> self . f_x = ( ( <NUM_LIT:6> * x - <NUM_LIT:2> ) ** <NUM_LIT:2> ) * np . sin ( ( <NUM_LIT:6> * x - <NUM_LIT:2> ) * <NUM_LIT:2> ) <EOL> class LowFidelityModel ( Component ) : <EOL> x = Float ( <NUM_LIT:0.0> , iotype = "<STR_LIT>" ) <EOL> f_x = Float ( <NUM_LIT:0.0> , iotype = "<STR_LIT>" ) <EOL> def execute ( self ) : <EOL> x = self . x <EOL> self . f_x = <NUM_LIT:0.5> * ( ( <NUM_LIT:6> * x - <NUM_LIT:2> ) ** <NUM_LIT:2> ) * np . sin ( ( <NUM_LIT:6> * x - <NUM_LIT:2> ) * <NUM_LIT:2> ) + ( x - <NUM_LIT:0.5> ) * <NUM_LIT> - <NUM_LIT:5> <EOL> class HighFidelityModel ( Model ) : <EOL> pass <EOL> class CasesBuilder ( Assembly ) : <EOL> def __init__ ( self , model , cases ) : <EOL> self . instance = model <EOL> self . cases = cases <EOL> super ( CasesBuilder , self ) . __init__ ( ) <EOL> def configure ( self ) : <EOL> self . add ( "<STR_LIT>" , self . instance ) <EOL> self . add ( "<STR_LIT>" , CaseIteratorDriver ( ) ) <EOL> self . driver . workflow . add ( '<STR_LIT>' ) <EOL> self . driver . add_parameter ( "<STR_LIT>" , low = <NUM_LIT:0> , high = <NUM_LIT:1> ) <EOL> self . driver . add_response ( "<STR_LIT>" ) <EOL> self . driver . case_inputs . model . x = self . cases <EOL> self . create_passthrough ( '<STR_LIT>' ) <EOL> self . create_passthrough ( '<STR_LIT>' ) <EOL> class Simulation ( Assembly ) : <EOL> def __init__ ( self , surrogate , nfi = <NUM_LIT:1> ) : <EOL> self . surrogate = surrogate <EOL> self . nfi = nfi <EOL> super ( Simulation , self ) . __init__ ( ) <EOL> def configure ( self ) : <EOL> doe_e = [ <NUM_LIT:0.0> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT:1.0> ] <EOL> doe_c = [ <NUM_LIT:0.1> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT:0.5> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] + doe_e <EOL> self . add ( '<STR_LIT>' , CasesBuilder ( HighFidelityModel ( ) , doe_e ) ) <EOL> self . add ( '<STR_LIT>' , CasesBuilder ( LowFidelityModel ( ) , doe_c ) ) <EOL> self . add ( "<STR_LIT>" , MultiFiMetaModel ( params = ( '<STR_LIT:x>' , ) , <EOL> responses = ( '<STR_LIT>' , ) , nfi = self . nfi ) ) <EOL> self . meta_model . default_surrogate = self . surrogate <EOL> self . connect ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . connect ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> if self . nfi > <NUM_LIT:1> : <EOL> self . connect ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . connect ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . add ( '<STR_LIT>' , CaseIteratorDriver ( ) ) <EOL> self . add ( '<STR_LIT>' , Model ( ) ) <EOL> self . mm_checker . add_parameter ( "<STR_LIT>" , low = <NUM_LIT:0> , high = <NUM_LIT:1> ) <EOL> self . mm_checker . add_parameter ( "<STR_LIT>" , low = <NUM_LIT:0> , high = <NUM_LIT:1> ) <EOL> self . mm_checker . add_response ( "<STR_LIT>" ) <EOL> self . mm_checker . add_response ( "<STR_LIT>" ) <EOL> ngrid = <NUM_LIT:100> <EOL> self . mm_checker . case_inputs . meta_model . x = np . linspace ( <NUM_LIT:0> , <NUM_LIT:1> , ngrid ) <EOL> self . mm_checker . case_inputs . model . x = np . linspace ( <NUM_LIT:0> , <NUM_LIT:1> , ngrid ) <EOL> self . driver . workflow . add ( '<STR_LIT>' ) <EOL> if self . nfi > <NUM_LIT:1> : <EOL> self . driver . workflow . add ( '<STR_LIT>' ) <EOL> self . driver . workflow . add ( '<STR_LIT>' ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> surrogate = MultiFiCoKrigingSurrogate ( ) <EOL> sim_cok = Simulation ( surrogate , nfi = <NUM_LIT:2> ) <EOL> sim_cok . run ( ) <EOL> predicted_cok = np . array ( [ d . mu for d in sim_cok . mm_checker . case_outputs . meta_model . f_x ] ) <EOL> sigma_cok = np . array ( [ d . sigma for d in sim_cok . mm_checker . case_outputs . meta_model . f_x ] ) <EOL> surrogate = KrigingSurrogate ( ) <EOL> sim_k = Simulation ( surrogate , nfi = <NUM_LIT:1> ) <EOL> sim_k . run ( ) <EOL> predicted_k = np . array ( [ d . mu for d in sim_k . mm_checker . case_outputs . meta_model . f_x ] ) <EOL> sigma_k = np . array ( [ d . sigma for d in sim_k . mm_checker . case_outputs . meta_model . f_x ] ) <EOL> actual = sim_k . mm_checker . case_outputs . model . f_x <EOL> check = sim_k . mm_checker . case_inputs . meta_model . x <EOL> import pylab as plt <EOL> plt . figure ( <NUM_LIT:2> ) <EOL> plt . ioff ( ) <EOL> plt . plot ( check , actual , '<STR_LIT:k>' , label = '<STR_LIT>' ) <EOL> plt . plot ( sim_cok . hifi_cases . x , sim_cok . hifi_cases . f_x , '<STR_LIT>' , label = "<STR_LIT>" ) <EOL> plt . plot ( sim_cok . lofi_cases . x , sim_cok . lofi_cases . f_x , '<STR_LIT>' , label = "<STR_LIT>" ) <EOL> plt . plot ( check , predicted_cok , '<STR_LIT:g>' , label = '<STR_LIT>' ) <EOL> plt . plot ( check , predicted_cok + <NUM_LIT:2> * sigma_cok , '<STR_LIT:g>' , alpha = <NUM_LIT:0.5> , label = '<STR_LIT>' ) <EOL> plt . plot ( check , predicted_cok - <NUM_LIT:2> * sigma_cok , '<STR_LIT:g>' , alpha = <NUM_LIT:0.5> ) <EOL> plt . fill_between ( check , predicted_cok + <NUM_LIT:2> * sigma_cok , <EOL> predicted_cok - <NUM_LIT:2> * sigma_cok , facecolor = '<STR_LIT:g>' , alpha = <NUM_LIT> ) <EOL> plt . plot ( check , predicted_k , '<STR_LIT:b>' , label = '<STR_LIT>' ) <EOL> plt . plot ( check , predicted_k + <NUM_LIT:2> * sigma_k , '<STR_LIT:b>' , alpha = <NUM_LIT:0.5> , label = '<STR_LIT>' ) <EOL> plt . plot ( check , predicted_k - <NUM_LIT:2> * sigma_k , '<STR_LIT:b>' , alpha = <NUM_LIT:0.5> ) <EOL> plt . fill_between ( check , predicted_k + <NUM_LIT:2> * sigma_k , <EOL> predicted_k - <NUM_LIT:2> * sigma_k , facecolor = '<STR_LIT:b>' , alpha = <NUM_LIT> ) <EOL> plt . legend ( loc = '<STR_LIT>' ) <EOL> plt . show ( ) <EOL> error = <NUM_LIT:0.> <EOL> for a , p in zip ( actual , predicted_cok ) : <EOL> error += ( a - p ) ** <NUM_LIT:2> <EOL> error = ( error / len ( actual ) ) <EOL> print "<STR_LIT>" % error <EOL> error = <NUM_LIT:0.> <EOL> for a , p in zip ( actual , predicted_k ) : <EOL> error += ( a - p ) ** <NUM_LIT:2> <EOL> error = ( error / len ( actual ) ) <EOL> print "<STR_LIT>" % error </s>
<s> """<STR_LIT>""" <EOL> import sys <EOL> import os <EOL> import shutil <EOL> import urllib2 <EOL> import subprocess <EOL> import codecs <EOL> from optparse import OptionParser <EOL> def has_setuptools ( ) : <EOL> try : <EOL> import setuptools <EOL> except ImportError : <EOL> return False <EOL> return True <EOL> def make_new_setupfile ( setupfile ) : <EOL> """<STR_LIT>""" <EOL> setupfile = os . path . abspath ( setupfile ) <EOL> newsetupfile = os . path . join ( os . path . dirname ( setupfile ) , <EOL> '<STR_LIT>' + os . path . basename ( setupfile ) ) <EOL> startdir = os . getcwd ( ) <EOL> os . chdir ( os . path . dirname ( setupfile ) ) <EOL> try : <EOL> print "<STR_LIT>" <EOL> if not os . path . isfile ( '<STR_LIT>' ) : <EOL> print "<STR_LIT>" <EOL> resp = urllib2 . urlopen ( '<STR_LIT>' ) <EOL> with open ( '<STR_LIT>' , '<STR_LIT:wb>' ) as easyf : <EOL> shutil . copyfileobj ( resp . fp , easyf ) <EOL> print '<STR_LIT>' <EOL> print "<STR_LIT>" % setupfile <EOL> if not os . path . isfile ( setupfile ) : <EOL> raise IOError ( "<STR_LIT>" % setupfile ) <EOL> setupf = open ( setupfile , '<STR_LIT:r>' ) <EOL> setup_contents = setupf . read ( ) <EOL> setupf . close ( ) <EOL> with open ( newsetupfile , '<STR_LIT:wb>' ) as newf : <EOL> newf . write ( "<STR_LIT>" ) <EOL> newf . write ( "<STR_LIT>" ) <EOL> newf . write ( setup_contents ) <EOL> finally : <EOL> os . chdir ( startdir ) <EOL> return newsetupfile <EOL> def build_dist ( srcdir , destdir = '<STR_LIT:.>' , build_type = '<STR_LIT>' ) : <EOL> """<STR_LIT>""" <EOL> startdir = os . getcwd ( ) <EOL> destdir = os . path . abspath ( os . path . expanduser ( destdir ) ) . replace ( '<STR_LIT:\\>' , '<STR_LIT:/>' ) <EOL> srcdir = os . path . abspath ( os . path . expanduser ( srcdir ) ) . replace ( '<STR_LIT:\\>' , '<STR_LIT:/>' ) <EOL> setupname = os . path . join ( srcdir , '<STR_LIT>' ) <EOL> if not has_setuptools ( ) : <EOL> setupname = make_new_setupfile ( setupname ) <EOL> dirfiles = set ( os . listdir ( destdir ) ) <EOL> print "<STR_LIT>" % srcdir <EOL> cmd = [ sys . executable . replace ( '<STR_LIT:\\>' , '<STR_LIT:/>' ) , <EOL> os . path . basename ( setupname ) , <EOL> ] <EOL> cmd . extend ( build_type . split ( '<STR_LIT:U+0020>' ) ) <EOL> cmd . extend ( [ '<STR_LIT>' , destdir ] ) <EOL> os . chdir ( srcdir ) <EOL> out = codecs . open ( '<STR_LIT>' , '<STR_LIT:wb>' , <EOL> encoding = '<STR_LIT:ascii>' , errors = '<STR_LIT:replace>' ) <EOL> print '<STR_LIT>' % '<STR_LIT:U+0020>' . join ( cmd ) <EOL> try : <EOL> p = subprocess . Popen ( '<STR_LIT:U+0020>' . join ( cmd ) , <EOL> stdout = out , stderr = subprocess . STDOUT , <EOL> shell = True ) <EOL> p . wait ( ) <EOL> finally : <EOL> out . close ( ) <EOL> with open ( '<STR_LIT>' , '<STR_LIT:r>' ) as f : <EOL> print f . read ( ) <EOL> os . chdir ( startdir ) <EOL> newfiles = set ( os . listdir ( destdir ) ) - dirfiles <EOL> if len ( newfiles ) != <NUM_LIT:1> : <EOL> raise RuntimeError ( "<STR_LIT>" % <EOL> list ( newfiles ) ) <EOL> if p . returncode != <NUM_LIT:0> : <EOL> raise RuntimeError ( "<STR_LIT>" % <EOL> ( srcdir , p . returncode ) ) <EOL> distfile = os . path . join ( destdir , newfiles . pop ( ) ) <EOL> print '<STR_LIT>' % distfile <EOL> return distfile <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> parser = OptionParser ( usage = "<STR_LIT>" ) <EOL> parser . add_option ( "<STR_LIT>" , "<STR_LIT>" , action = "<STR_LIT:store>" , type = '<STR_LIT:string>' , <EOL> dest = '<STR_LIT>' , <EOL> help = "<STR_LIT>" ) <EOL> parser . add_option ( "<STR_LIT>" , "<STR_LIT>" , action = "<STR_LIT:store>" , type = '<STR_LIT:string>' , <EOL> dest = '<STR_LIT>' , default = '<STR_LIT:.>' , <EOL> help = "<STR_LIT>" ) <EOL> parser . add_option ( "<STR_LIT>" , "<STR_LIT>" , action = "<STR_LIT:store>" , type = '<STR_LIT:string>' , <EOL> dest = '<STR_LIT>' , default = '<STR_LIT>' , <EOL> help = "<STR_LIT>" ) <EOL> ( options , args ) = parser . parse_args ( sys . argv [ <NUM_LIT:1> : ] ) <EOL> retcode = - <NUM_LIT:1> <EOL> startdir = os . getcwd ( ) <EOL> if not options . srcdir : <EOL> print "<STR_LIT>" <EOL> parser . print_help ( ) <EOL> sys . exit ( retcode ) <EOL> srcdir = os . path . abspath ( os . path . expanduser ( options . srcdir ) ) <EOL> destdir = os . path . abspath ( os . path . expanduser ( options . destdir ) ) <EOL> if not os . path . exists ( srcdir ) : <EOL> print "<STR_LIT>" % srcdir <EOL> sys . exit ( retcode ) <EOL> try : <EOL> distfile = build_dist ( srcdir , destdir , options . buildtype ) <EOL> finally : <EOL> os . chdir ( startdir ) </s>
<s> """<STR_LIT>""" <EOL> from openmdao . lib . casehandlers . caseset import CaseArray , CaseSet , caseiter_to_caseset <EOL> from openmdao . lib . casehandlers . csvcase import CSVCaseIterator , CSVCaseRecorder <EOL> from openmdao . lib . casehandlers . dbcase import DBCaseIterator , DBCaseRecorder , case_db_to_dict <EOL> from openmdao . lib . casehandlers . dumpcase import DumpCaseRecorder <EOL> from openmdao . lib . casehandlers . jsoncase import JSONCaseRecorder , BSONCaseRecorder , verify_json <EOL> from openmdao . lib . casehandlers . listcase import ListCaseRecorder , ListCaseIterator <EOL> from openmdao . lib . casehandlers . caseset import CaseArray , CaseSet , caseiter_to_caseset <EOL> from openmdao . lib . casehandlers . filters import SequenceCaseFilter , SliceCaseFilter , ExprCaseFilter <EOL> from openmdao . lib . casehandlers . query import CaseDataset <EOL> from openmdao . lib . casehandlers . csv_post_processor import caseset_query_to_csv <EOL> from openmdao . lib . casehandlers . dump_post_processor import caseset_query_dump <EOL> from openmdao . lib . casehandlers . html_post_processor import caseset_query_to_html <EOL> try : <EOL> from openmdao . lib . casehandlers . query_hdf5 import CaseDatasetHDF5 <EOL> from openmdao . lib . casehandlers . hdf5case import HDF5CaseRecorder <EOL> except ImportError : <EOL> pass </s>
<s> from weakref import ref <EOL> import numpy as np <EOL> from openmdao . main . api import VariableTree <EOL> from openmdao . lib . casehandlers . query import DictList , ListResult <EOL> _GLOBAL_DICT = dict ( __builtins__ = None ) <EOL> class CaseDatasetHDF5 ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , filename , format ) : <EOL> format = format . lower ( ) <EOL> if format == '<STR_LIT>' : <EOL> self . _reader = _HDF5Reader ( filename ) <EOL> else : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> self . _query_id = self . _query_itername = self . _parent_id = self . _parent_itername = self . _driver_id = self . _driver_name = None <EOL> self . _case_ids = self . _drivers = self . _case_iternames = None <EOL> self . metadata_names = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' ] <EOL> @ property <EOL> def data ( self ) : <EOL> """<STR_LIT>""" <EOL> return QueryHDF5 ( self ) <EOL> @ property <EOL> def drivers ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . _reader . drivers ( ) <EOL> @ property <EOL> def simulation_info ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . _reader . simulation_info <EOL> def _fetch ( self , query ) : <EOL> """<STR_LIT>""" <EOL> self . _setup ( query ) <EOL> if query . vnames : <EOL> tmp = [ ] <EOL> for name in self . metadata_names : <EOL> if name in query . vnames : <EOL> tmp . append ( name ) <EOL> self . metadata_names = tmp <EOL> names = query . vnames <EOL> else : <EOL> if query . driver_name : <EOL> driver_info = self . _drivers [ self . _driver_name ] <EOL> prefix = driver_info [ '<STR_LIT>' ] <EOL> all_names = [ prefix + name <EOL> for name in driver_info [ '<STR_LIT>' ] ] <EOL> else : <EOL> all_names = [ ] <EOL> for driver_info in self . _drivers . values ( ) : <EOL> prefix = driver_info [ '<STR_LIT>' ] <EOL> all_names . extend ( [ prefix + name <EOL> for name in driver_info [ '<STR_LIT>' ] ] ) <EOL> names = sorted ( all_names + self . metadata_names ) <EOL> if query . names : <EOL> return names <EOL> nan = float ( '<STR_LIT>' ) <EOL> rows = ListResult ( ) <EOL> state = { } <EOL> for case_data in self . _reader . cases ( ) : <EOL> data = case_data [ '<STR_LIT:data>' ] <EOL> metadata = case_data [ '<STR_LIT>' ] <EOL> case_id = metadata [ '<STR_LIT>' ] <EOL> case_driver_id = metadata [ '<STR_LIT>' ] <EOL> case_driver_name = metadata [ '<STR_LIT>' ] <EOL> case_itername = metadata [ '<STR_LIT>' ] <EOL> prefix = self . _drivers [ case_driver_name ] [ '<STR_LIT>' ] <EOL> if prefix : <EOL> pass <EOL> else : <EOL> data = data . copy ( ) <EOL> state . update ( data ) <EOL> if self . _driver_name is not None and case_driver_name != self . _driver_name : <EOL> continue <EOL> if self . _case_iternames is None or case_itername in self . _case_iternames : <EOL> for name in self . metadata_names : <EOL> data [ name ] = case_data [ '<STR_LIT>' ] [ name ] <EOL> row = DictList ( names ) <EOL> for name in names : <EOL> if query . local_only : <EOL> if name in self . metadata_names : <EOL> row . append ( data [ name ] ) <EOL> else : <EOL> driver = self . _drivers [ case_driver_name ] <EOL> lnames = [ prefix + rec for rec in driver [ '<STR_LIT>' ] ] <EOL> if name in lnames : <EOL> row . append ( data [ name ] ) <EOL> else : <EOL> row . append ( nan ) <EOL> elif name in state : <EOL> row . append ( state [ name ] ) <EOL> elif name in data : <EOL> row . append ( data [ name ] ) <EOL> else : <EOL> row . append ( nan ) <EOL> rows . append ( row ) <EOL> if case_itername == self . _query_itername or case_itername == self . _parent_itername : <EOL> break <EOL> if self . _query_id and not rows : <EOL> raise ValueError ( '<STR_LIT>' % self . _query_id ) <EOL> if query . transpose : <EOL> tmp = DictList ( names ) <EOL> for i in range ( len ( rows [ <NUM_LIT:0> ] ) ) : <EOL> tmp . append ( [ row [ i ] for row in rows ] ) <EOL> tmp . cds = self <EOL> return tmp <EOL> rows . cds = self <EOL> return rows <EOL> def _write ( self , query , out , format ) : <EOL> raise NotImplementedError <EOL> def _setup ( self , query ) : <EOL> """<STR_LIT>""" <EOL> if query . vnames is not None : <EOL> bad = [ ] <EOL> metadata = self . simulation_info [ '<STR_LIT>' ] <EOL> expressions = self . simulation_info [ '<STR_LIT>' ] <EOL> for name in query . vnames : <EOL> if name not in metadata and name not in [ e [ '<STR_LIT>' ] for e in expressions . values ( ) ] and name not in self . metadata_names : <EOL> bad . append ( name ) <EOL> if bad : <EOL> raise RuntimeError ( '<STR_LIT>' % bad ) <EOL> self . _drivers = { } <EOL> self . _driver_id = None <EOL> self . _driver_name = None <EOL> for driver_info in self . _reader . drivers ( ) : <EOL> _id = driver_info [ '<STR_LIT>' ] <EOL> name = driver_info [ '<STR_LIT:name>' ] <EOL> prefix , _ , name = name . rpartition ( '<STR_LIT:.>' ) <EOL> if prefix : <EOL> prefix += '<STR_LIT:.>' <EOL> driver_info [ '<STR_LIT>' ] = prefix <EOL> self . _drivers [ driver_info [ '<STR_LIT:name>' ] ] = driver_info <EOL> if ( driver_info [ '<STR_LIT:name>' ] ) == query . driver_name : <EOL> self . _driver_name = query . driver_name <EOL> if query . driver_name : <EOL> if self . _driver_name is None : <EOL> raise ValueError ( '<STR_LIT>' % query . driver_name ) <EOL> self . _case_ids = None <EOL> self . _query_id = None <EOL> self . _parent_id = None <EOL> if query . case_itername is not None : <EOL> self . _query_itername = query . case_itername <EOL> self . _case_iternames = set ( ( self . _query_itername , ) ) <EOL> self . _driver_name = None <EOL> elif query . parent_itername is not None : <EOL> self . _parent_itername = query . parent_itername <EOL> self . _case_iternames = set ( ( self . _parent_itername , ) ) <EOL> parent_itername_parts = self . _parent_itername . split ( '<STR_LIT:->' ) <EOL> for case_data in self . _reader . cases ( ) : <EOL> itername = case_data [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> itername_parts = itername . split ( '<STR_LIT:->' ) <EOL> if len ( parent_itername_parts ) + <NUM_LIT:1> == len ( itername_parts ) and itername_parts [ : - <NUM_LIT:1> ] == parent_itername_parts : <EOL> self . _case_iternames . add ( itername ) <EOL> def restore ( self , assembly , case_id ) : <EOL> """<STR_LIT>""" <EOL> raise NotImplementedError <EOL> def _set ( self , assembly , name , value ) : <EOL> """<STR_LIT>""" <EOL> if isinstance ( value , dict ) : <EOL> curr = assembly . get ( name ) <EOL> if isinstance ( curr , VariableTree ) : <EOL> for key , val in value . items ( ) : <EOL> self . _set ( assembly , '<STR_LIT:.>' . join ( ( name , key ) ) , val ) <EOL> elif '<STR_LIT:[>' in name : <EOL> if isinstance ( value , unicode ) : <EOL> value = str ( value ) <EOL> exec ( '<STR_LIT>' % name , _GLOBAL_DICT , locals ( ) ) <EOL> else : <EOL> for key , val in value . items ( ) : <EOL> if isinstance ( val , unicode ) : <EOL> value [ key ] = str ( val ) <EOL> assembly . set ( name , value ) <EOL> else : <EOL> if isinstance ( value , unicode ) : <EOL> value = str ( value ) <EOL> if '<STR_LIT:[>' in name : <EOL> exec ( '<STR_LIT>' % name , _GLOBAL_DICT , locals ( ) ) <EOL> else : <EOL> assembly . set ( name , value ) <EOL> class QueryHDF5 ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , dataset ) : <EOL> self . _dataset = dataset <EOL> self . driver_name = None <EOL> self . case_id = None <EOL> self . case_itername = None <EOL> self . parent_id = None <EOL> self . parent_itername = None <EOL> self . vnames = None <EOL> self . local_only = False <EOL> self . names = False <EOL> self . transpose = False <EOL> def fetch ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . _dataset . _fetch ( self ) <EOL> def write ( self , out , format = None ) : <EOL> """<STR_LIT>""" <EOL> raise NotImplementedError <EOL> def driver ( self , driver_name ) : <EOL> """<STR_LIT>""" <EOL> self . driver_name = driver_name <EOL> return self <EOL> def case ( self , case_itername ) : <EOL> """<STR_LIT>""" <EOL> self . case_itername = case_itername <EOL> self . parent_itername = None <EOL> return self <EOL> def parent_case ( self , parent_case_id ) : <EOL> """<STR_LIT>""" <EOL> self . parent_id = parent_case_id <EOL> self . parent_itername = parent_case_id <EOL> self . case_id = None <EOL> return self <EOL> def vars ( self , * args ) : <EOL> """<STR_LIT>""" <EOL> self . vnames = [ ] <EOL> for arg in args : <EOL> if isinstance ( arg , basestring ) : <EOL> self . vnames . append ( arg ) <EOL> else : <EOL> self . vnames . extend ( arg ) <EOL> return self <EOL> def local ( self ) : <EOL> """<STR_LIT>""" <EOL> self . local_only = True <EOL> return self <EOL> def by_case ( self ) : <EOL> """<STR_LIT>""" <EOL> self . transpose = False <EOL> return self <EOL> def by_variable ( self ) : <EOL> """<STR_LIT>""" <EOL> self . transpose = True <EOL> return self <EOL> def var_names ( self ) : <EOL> """<STR_LIT>""" <EOL> self . names = True <EOL> return self <EOL> class _HDF5Reader ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , filename ) : <EOL> import h5py <EOL> self . _inp = h5py . File ( filename , '<STR_LIT:r>' ) <EOL> self . _simulation_info = self . read_simulation_info ( ) <EOL> self . _state = '<STR_LIT>' <EOL> self . _info = None <EOL> @ property <EOL> def simulation_info ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . _simulation_info <EOL> def read_iteration_case_from_hdf5 ( self , hdf5file , driver_name , iteration_case_name ) : <EOL> info = { } <EOL> driver_grp = self . _inp [ '<STR_LIT>' ] [ driver_name ] <EOL> iteration_grp = self . _inp [ '<STR_LIT>' ] [ driver_name ] [ iteration_case_name ] <EOL> info [ '<STR_LIT>' ] = self . read_from_hdf5 ( iteration_grp [ '<STR_LIT>' ] ) <EOL> data_grp = iteration_grp [ '<STR_LIT:data>' ] <EOL> info [ '<STR_LIT:data>' ] = { } <EOL> float_names = driver_grp [ '<STR_LIT>' ] <EOL> int_names = driver_grp [ '<STR_LIT>' ] <EOL> str_names = driver_grp [ '<STR_LIT>' ] <EOL> for i , name in enumerate ( float_names ) : <EOL> info [ '<STR_LIT:data>' ] [ name ] = data_grp [ '<STR_LIT>' ] [ i ] <EOL> for i , name in enumerate ( str_names ) : <EOL> info [ '<STR_LIT:data>' ] [ name ] = data_grp [ '<STR_LIT>' ] [ i ] <EOL> for i , name in enumerate ( int_names ) : <EOL> info [ '<STR_LIT:data>' ] [ name ] = data_grp [ '<STR_LIT>' ] [ i ] <EOL> for name in data_grp . keys ( ) : <EOL> if name not in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] : <EOL> if '<STR_LIT>' in data_grp [ name ] . attrs : <EOL> info [ '<STR_LIT:data>' ] [ name ] = { } <EOL> for n , v in data_grp [ name ] . items ( ) : <EOL> info [ '<STR_LIT:data>' ] [ name ] [ n ] = self . read_from_hdf5 ( data_grp [ name ] [ n ] ) <EOL> info [ '<STR_LIT:data>' ] [ name ] = self . read_from_hdf5 ( data_grp [ name ] ) <EOL> return info <EOL> def read_from_hdf5 ( self , value ) : <EOL> import h5py <EOL> if isinstance ( value , h5py . _hl . group . Group ) : <EOL> d = { } <EOL> group = value <EOL> for name , value in group . attrs . items ( ) : <EOL> d [ name ] = self . read_from_hdf5 ( value ) <EOL> for name , value in group . items ( ) : <EOL> d [ name ] = self . read_from_hdf5 ( value ) <EOL> return d <EOL> elif value . dtype . names : <EOL> d = { } <EOL> for name in value . dtype . names : <EOL> d [ name ] = value [ name ] [ <NUM_LIT:0> ] <EOL> return d <EOL> else : <EOL> return value [ ( ) ] <EOL> def read_simulation_info ( self ) : <EOL> sim_info_grp = self . _inp [ '<STR_LIT>' ] <EOL> sim_info = { } <EOL> for name , value in sim_info_grp . attrs . items ( ) : <EOL> sim_info [ name ] = self . read_from_hdf5 ( value ) <EOL> for name , value in sim_info_grp . items ( ) : <EOL> sim_info [ name ] = self . read_from_hdf5 ( value ) <EOL> return sim_info <EOL> def drivers ( self ) : <EOL> """<STR_LIT>""" <EOL> driver_info = [ ] <EOL> for name in self . _inp . keys ( ) : <EOL> if name . startswith ( '<STR_LIT>' ) : <EOL> driver_info . append ( self . read_from_hdf5 ( self . _inp [ name ] ) ) <EOL> return driver_info <EOL> def cases ( self ) : <EOL> """<STR_LIT>""" <EOL> iteration_cases_grp = self . _inp [ '<STR_LIT>' ] <EOL> case_timestamps = { } <EOL> for driver_name in iteration_cases_grp : <EOL> for iteration_case_name in iteration_cases_grp [ driver_name ] : <EOL> if iteration_case_name . startswith ( '<STR_LIT>' ) : <EOL> timestamp = iteration_cases_grp [ driver_name ] [ iteration_case_name ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ <NUM_LIT:0> ] <EOL> case_timestamps [ timestamp ] = ( driver_name , iteration_case_name ) <EOL> sorted_timestamps = sorted ( case_timestamps ) <EOL> for timestamp in sorted_timestamps : <EOL> driver_name , iteration_case_name = case_timestamps [ timestamp ] <EOL> info = self . read_iteration_case_from_hdf5 ( self . _inp , driver_name , iteration_case_name ) <EOL> yield info <EOL> def _next ( self ) : <EOL> """<STR_LIT>""" <EOL> pass </s>
<s> """<STR_LIT>""" <EOL> from openmdao . main . api import Component <EOL> from openmdao . main . datatypes . api import Float <EOL> import time <EOL> class SleepComponent ( Component ) : <EOL> """<STR_LIT>""" <EOL> sleep_time = Float ( <NUM_LIT:0.0> , iotype = '<STR_LIT>' , desc = '<STR_LIT>' ) <EOL> def execute ( self ) : <EOL> time . sleep ( self . sleep_time ) </s>
<s> import copy <EOL> from openmdao . lib . datatypes . domain . flow import FlowSolution <EOL> from openmdao . lib . datatypes . domain . grid import GridCoordinates <EOL> CARTESIAN = '<STR_LIT>' <EOL> CYLINDRICAL = '<STR_LIT>' <EOL> _COORD_SYSTEMS = ( CARTESIAN , CYLINDRICAL ) <EOL> class Zone ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self ) : <EOL> self . grid_coordinates = GridCoordinates ( ) <EOL> self . flow_solution = FlowSolution ( ) <EOL> self . reference_state = None <EOL> self . _coordinate_system = CARTESIAN <EOL> self . right_handed = True <EOL> self . symmetry = None <EOL> self . symmetry_axis = None <EOL> self . symmetry_instances = <NUM_LIT:1> <EOL> @ property <EOL> def shape ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . grid_coordinates . shape <EOL> @ property <EOL> def extent ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . grid_coordinates . extent <EOL> def _get_coord_sys ( self ) : <EOL> return self . _coordinate_system <EOL> def _set_coord_sys ( self , sys ) : <EOL> if sys in _COORD_SYSTEMS : <EOL> self . _coordinate_system = sys <EOL> else : <EOL> raise ValueError ( '<STR_LIT>' % sys ) <EOL> coordinate_system = property ( _get_coord_sys , _set_coord_sys , <EOL> doc = '<STR_LIT>' ) <EOL> def copy ( self ) : <EOL> """<STR_LIT>""" <EOL> return copy . deepcopy ( self ) <EOL> def is_equivalent ( self , other , logger , tolerance = <NUM_LIT:0.> ) : <EOL> """<STR_LIT>""" <EOL> if not isinstance ( other , Zone ) : <EOL> logger . debug ( '<STR_LIT>' ) <EOL> return False <EOL> if self . coordinate_system != other . coordinate_system : <EOL> logger . debug ( '<STR_LIT>' ) <EOL> return False <EOL> if self . right_handed != other . right_handed : <EOL> logger . debug ( '<STR_LIT>' ) <EOL> return False <EOL> if self . symmetry != other . symmetry : <EOL> logger . debug ( '<STR_LIT>' ) <EOL> return False <EOL> if self . symmetry_axis != other . symmetry_axis : <EOL> logger . debug ( '<STR_LIT>' ) <EOL> return False <EOL> if self . symmetry_instances != other . symmetry_instances : <EOL> logger . debug ( '<STR_LIT>' ) <EOL> return False <EOL> if not self . grid_coordinates . is_equivalent ( other . grid_coordinates , <EOL> logger , tolerance ) : <EOL> return False <EOL> if not self . flow_solution . is_equivalent ( other . flow_solution , logger , <EOL> tolerance ) : <EOL> return False <EOL> return True <EOL> def extract ( self , imin , imax , jmin = None , jmax = None , kmin = None , kmax = None , <EOL> grid_ghosts = None , flow_ghosts = None ) : <EOL> """<STR_LIT>""" <EOL> zone = Zone ( ) <EOL> zone . grid_coordinates = self . grid_coordinates . extract ( imin , imax , jmin , jmax , kmin , kmax , <EOL> grid_ghosts ) <EOL> zone . flow_solution = self . flow_solution . extract ( imin , imax , jmin , jmax , kmin , kmax , <EOL> flow_ghosts ) <EOL> if self . reference_state is not None : <EOL> zone . reference_state = self . reference_state . copy ( ) <EOL> zone . coordinate_system = self . coordinate_system <EOL> zone . right_handed = self . right_handed <EOL> zone . symmetry = self . symmetry <EOL> zone . symmetry_axis = self . symmetry_axis <EOL> zone . symmetry_instances = self . symmetry_instances <EOL> return zone <EOL> def extend ( self , axis , delta , grid_points , flow_points , normal = None ) : <EOL> """<STR_LIT>""" <EOL> zone = Zone ( ) <EOL> if grid_points > <NUM_LIT:0> : <EOL> zone . grid_coordinates = self . grid_coordinates . extend ( axis , delta , grid_points , normal ) <EOL> else : <EOL> zone . grid_coordinates = self . grid_coordinates . copy ( ) <EOL> if flow_points > <NUM_LIT:0> : <EOL> zone . flow_solution = self . flow_solution . extend ( axis , delta , flow_points ) <EOL> else : <EOL> zone . flow_solution = self . flow_solution . copy ( ) <EOL> if self . reference_state is not None : <EOL> zone . reference_state = self . reference_state . copy ( ) <EOL> zone . coordinate_system = self . coordinate_system <EOL> zone . right_handed = self . right_handed <EOL> zone . symmetry = self . symmetry <EOL> zone . symmetry_axis = self . symmetry_axis <EOL> zone . symmetry_instances = self . symmetry_instances <EOL> return zone <EOL> def make_cartesian ( self , axis = '<STR_LIT:z>' ) : <EOL> """<STR_LIT>""" <EOL> if self . coordinate_system != CARTESIAN : <EOL> self . flow_solution . make_cartesian ( self . grid_coordinates , axis ) <EOL> self . grid_coordinates . make_cartesian ( axis ) <EOL> self . coordinate_system = CARTESIAN <EOL> def make_cylindrical ( self , axis = '<STR_LIT:z>' ) : <EOL> """<STR_LIT>""" <EOL> if self . coordinate_system != CYLINDRICAL : <EOL> self . grid_coordinates . make_cylindrical ( axis ) <EOL> self . flow_solution . make_cylindrical ( self . grid_coordinates , axis ) <EOL> self . coordinate_system = CYLINDRICAL <EOL> def make_left_handed ( self ) : <EOL> """<STR_LIT>""" <EOL> if self . right_handed : <EOL> self . grid_coordinates . flip_z ( ) <EOL> self . flow_solution . flip_z ( ) <EOL> self . right_handed = False <EOL> def make_right_handed ( self ) : <EOL> """<STR_LIT>""" <EOL> if not self . right_handed : <EOL> self . grid_coordinates . flip_z ( ) <EOL> self . flow_solution . flip_z ( ) <EOL> self . right_handed = True <EOL> def translate ( self , delta_x , delta_y , delta_z ) : <EOL> """<STR_LIT>""" <EOL> if self . coordinate_system == CARTESIAN : <EOL> self . grid_coordinates . translate ( delta_x , delta_y , delta_z ) <EOL> else : <EOL> raise RuntimeError ( '<STR_LIT>' ) <EOL> def rotate_about_x ( self , deg ) : <EOL> """<STR_LIT>""" <EOL> if self . coordinate_system == CARTESIAN : <EOL> self . grid_coordinates . rotate_about_x ( deg ) <EOL> self . flow_solution . rotate_about_x ( deg ) <EOL> else : <EOL> raise RuntimeError ( '<STR_LIT>' ) <EOL> def rotate_about_y ( self , deg ) : <EOL> """<STR_LIT>""" <EOL> if self . coordinate_system == CARTESIAN : <EOL> self . grid_coordinates . rotate_about_y ( deg ) <EOL> self . flow_solution . rotate_about_y ( deg ) <EOL> else : <EOL> raise RuntimeError ( '<STR_LIT>' ) <EOL> def rotate_about_z ( self , deg ) : <EOL> """<STR_LIT>""" <EOL> if self . coordinate_system == CARTESIAN : <EOL> self . grid_coordinates . rotate_about_z ( deg ) <EOL> self . flow_solution . rotate_about_z ( deg ) <EOL> else : <EOL> raise RuntimeError ( '<STR_LIT>' ) <EOL> def promote ( self ) : <EOL> """<STR_LIT>""" <EOL> self . grid_coordinates . promote ( ) <EOL> self . flow_solution . promote ( ) <EOL> def demote ( self ) : <EOL> """<STR_LIT>""" <EOL> self . grid_coordinates . demote ( ) <EOL> self . flow_solution . demote ( ) </s>
<s> """<STR_LIT>""" <EOL> from math import isnan <EOL> from numpy import zeros , array <EOL> from slsqp . slsqp import slsqp , closeunit , pyflush <EOL> from openmdao . main . datatypes . api import Enum , Float , Int , Str <EOL> from openmdao . main . driver_uses_derivatives import Driver <EOL> from openmdao . main . hasparameters import HasParameters <EOL> from openmdao . main . hasconstraints import HasConstraints <EOL> from openmdao . main . hasobjective import HasObjective <EOL> from openmdao . main . interfaces import IHasParameters , IHasConstraints , IHasObjective , implements , IOptimizer <EOL> from openmdao . util . decorators import add_delegate <EOL> @ add_delegate ( HasParameters , HasConstraints , HasObjective ) <EOL> class SLSQPdriver ( Driver ) : <EOL> """<STR_LIT>""" <EOL> implements ( IHasParameters , IHasConstraints , IHasObjective , IOptimizer ) <EOL> accuracy = Float ( <NUM_LIT> , iotype = '<STR_LIT>' , <EOL> desc = '<STR_LIT>' ) <EOL> maxiter = Int ( <NUM_LIT:50> , iotype = '<STR_LIT>' , <EOL> desc = '<STR_LIT>' ) <EOL> iprint = Enum ( <NUM_LIT:0> , [ <NUM_LIT:0> , <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] , iotype = '<STR_LIT>' , <EOL> desc = '<STR_LIT>' ) <EOL> iout = Int ( <NUM_LIT:6> , iotype = '<STR_LIT>' , <EOL> desc = '<STR_LIT>' ) <EOL> output_filename = Str ( '<STR_LIT>' , iotype = '<STR_LIT>' , <EOL> desc = '<STR_LIT>' ) <EOL> error_code = Int ( <NUM_LIT:0> , iotype = '<STR_LIT>' , <EOL> desc = '<STR_LIT>' ) <EOL> def __init__ ( self ) : <EOL> super ( SLSQPdriver , self ) . __init__ ( ) <EOL> self . error_messages = { <EOL> - <NUM_LIT:1> : "<STR_LIT>" , <EOL> <NUM_LIT:1> : "<STR_LIT>" , <EOL> <NUM_LIT:2> : "<STR_LIT>" , <EOL> <NUM_LIT:3> : "<STR_LIT>" , <EOL> <NUM_LIT:4> : "<STR_LIT>" , <EOL> <NUM_LIT:5> : "<STR_LIT>" , <EOL> <NUM_LIT:6> : "<STR_LIT>" , <EOL> <NUM_LIT:7> : "<STR_LIT>" , <EOL> <NUM_LIT:8> : "<STR_LIT>" , <EOL> <NUM_LIT:9> : "<STR_LIT>" , <EOL> } <EOL> self . x = zeros ( <NUM_LIT:0> , '<STR_LIT:d>' ) <EOL> self . x_lower_bounds = zeros ( <NUM_LIT:0> , '<STR_LIT:d>' ) <EOL> self . x_upper_bounds = zeros ( <NUM_LIT:0> , '<STR_LIT:d>' ) <EOL> self . inputs = None <EOL> self . obj = None <EOL> self . con = None <EOL> self . nparam = None <EOL> self . ncon = None <EOL> self . neqcon = None <EOL> self . ff = <NUM_LIT:0> <EOL> self . nfunc = <NUM_LIT:0> <EOL> self . ngrad = <NUM_LIT:0> <EOL> self . _continue = None <EOL> def start_iteration ( self ) : <EOL> """<STR_LIT>""" <EOL> super ( SLSQPdriver , self ) . run_iteration ( ) <EOL> self . inputs = self . list_param_group_targets ( ) <EOL> self . obj = self . list_objective_targets ( ) <EOL> self . con = self . list_constraint_targets ( ) <EOL> self . nparam = self . total_parameters ( ) <EOL> self . ncon = self . total_constraints ( ) <EOL> self . neqcon = self . total_eq_constraints ( ) <EOL> self . x = self . eval_parameters ( self . parent ) <EOL> self . x_lower_bounds = self . get_lower_bounds ( ) <EOL> self . x_upper_bounds = self . get_upper_bounds ( ) <EOL> self . ff = <NUM_LIT:0> <EOL> self . nfunc = <NUM_LIT:0> <EOL> self . ngrad = <NUM_LIT:0> <EOL> self . _continue = True <EOL> def run_iteration ( self ) : <EOL> """<STR_LIT>""" <EOL> n = self . nparam <EOL> m = self . ncon <EOL> meq = self . neqcon <EOL> la = max ( m , <NUM_LIT:1> ) <EOL> gg = zeros ( [ la ] , '<STR_LIT:d>' ) <EOL> df = zeros ( [ n + <NUM_LIT:1> ] , '<STR_LIT:d>' ) <EOL> dg = zeros ( [ la , n + <NUM_LIT:1> ] , '<STR_LIT:d>' ) <EOL> mineq = m - meq + <NUM_LIT:2> * ( n + <NUM_LIT:1> ) <EOL> lsq = ( n + <NUM_LIT:1> ) * ( ( n + <NUM_LIT:1> ) + <NUM_LIT:1> ) + meq * ( ( n + <NUM_LIT:1> ) + <NUM_LIT:1> ) + mineq * ( ( n + <NUM_LIT:1> ) + <NUM_LIT:1> ) <EOL> lsi = ( ( n + <NUM_LIT:1> ) - meq + <NUM_LIT:1> ) * ( mineq + <NUM_LIT:2> ) + <NUM_LIT:2> * mineq <EOL> lsei = ( ( n + <NUM_LIT:1> ) + mineq ) * ( ( n + <NUM_LIT:1> ) - meq ) + <NUM_LIT:2> * meq + ( n + <NUM_LIT:1> ) <EOL> slsqpb = ( n + <NUM_LIT:1> ) * ( n / <NUM_LIT:2> ) + <NUM_LIT:2> * m + <NUM_LIT:3> * n + <NUM_LIT:3> * ( n + <NUM_LIT:1> ) + <NUM_LIT:1> <EOL> lw = lsq + lsi + lsei + slsqpb + n + m <EOL> w = zeros ( [ lw ] , '<STR_LIT:d>' ) <EOL> ljw = max ( mineq , ( n + <NUM_LIT:1> ) - meq ) <EOL> jw = zeros ( [ ljw ] , '<STR_LIT:i>' ) <EOL> try : <EOL> dg , self . error_code , self . nfunc , self . ngrad = slsqp ( self . ncon , self . neqcon , la , self . nparam , <EOL> self . x , self . x_lower_bounds , self . x_upper_bounds , <EOL> self . ff , gg , df , dg , self . accuracy , self . maxiter , <EOL> self . iprint - <NUM_LIT:1> , self . iout , self . output_filename , <EOL> self . error_code , w , lw , jw , ljw , <EOL> self . nfunc , self . ngrad , <EOL> self . _func , self . _grad ) <EOL> except Exception as err : <EOL> self . _logger . error ( str ( err ) ) <EOL> raise <EOL> if self . iprint > <NUM_LIT:0> : <EOL> closeunit ( self . iout ) <EOL> if self . error_code != <NUM_LIT:0> : <EOL> self . _logger . warning ( self . error_messages [ self . error_code ] ) <EOL> self . _continue = False <EOL> def _func ( self , m , me , la , n , f , g , xnew ) : <EOL> """<STR_LIT>""" <EOL> self . set_parameters ( xnew ) <EOL> super ( SLSQPdriver , self ) . run_iteration ( ) <EOL> f = self . eval_objective ( ) <EOL> if isnan ( f ) : <EOL> msg = "<STR_LIT>" <EOL> self . raise_exception ( msg , RuntimeError ) <EOL> if self . ncon > <NUM_LIT:0> : <EOL> g = - <NUM_LIT:1.> * array ( self . eval_constraints ( self . parent ) ) <EOL> if self . iprint > <NUM_LIT:0> : <EOL> pyflush ( self . iout ) <EOL> return f , g <EOL> def _grad ( self , m , me , la , n , f , g , df , dg , xnew ) : <EOL> """<STR_LIT>""" <EOL> J = self . _calc_gradient ( self . inputs , self . obj + self . con ) <EOL> df [ <NUM_LIT:0> : self . nparam ] = J [ <NUM_LIT:0> , : ] . ravel ( ) <EOL> if self . ncon > <NUM_LIT:0> : <EOL> dg [ <NUM_LIT:0> : self . ncon , <NUM_LIT:0> : self . nparam ] = - J [ <NUM_LIT:1> : <NUM_LIT:1> + self . ncon , : ] <EOL> return df , dg <EOL> def requires_derivs ( self ) : <EOL> """<STR_LIT>""" <EOL> return True </s>
<s> from sellar import SellarProblem , SellarProblemWithDeriv <EOL> from branin import BraninProblem <EOL> from scalable import UnitScalableProblem <EOL> from polyscale import PolyScalableProblem </s>
<s> """<STR_LIT>""" <EOL> import datetime <EOL> import copy <EOL> import pprint <EOL> import socket <EOL> import sys <EOL> import weakref <EOL> copy . _copy_dispatch [ weakref . ref ] = copy . _copy_immutable <EOL> copy . _deepcopy_dispatch [ weakref . ref ] = copy . _deepcopy_atomic <EOL> copy . _deepcopy_dispatch [ weakref . KeyedRef ] = copy . _deepcopy_atomic <EOL> from zope . interface import Interface , implements <EOL> from numpy import ndarray <EOL> from traits . api import HasTraits , Missing , Python , push_exception_handler , TraitType , CTrait <EOL> from traits . has_traits import FunctionType , _clone_trait , MetaHasTraits <EOL> from traits . trait_base import not_none <EOL> from multiprocessing import connection <EOL> from openmdao . main . datatypes . file import FileRef <EOL> from openmdao . main . datatypes . list import List <EOL> from openmdao . main . datatypes . slot import Slot <EOL> from openmdao . main . datatypes . vtree import VarTree <EOL> from openmdao . main . interfaces import ICaseIterator , IResourceAllocator , IContainer , IVariableTree , IContainerProxy , IOverrideSet <EOL> from openmdao . main . mp_support import ObjectManager , is_instance , CLASSES_TO_PROXY , has_interface <EOL> from openmdao . main . rbac import rbac <EOL> from openmdao . main . variable import Variable , is_legal_name , _missing <EOL> from openmdao . main . array_helpers import flattened_value , get_index <EOL> from openmdao . util . log import Logger , logger <EOL> from openmdao . util import eggloader , eggsaver , eggobserver <EOL> from openmdao . util . eggsaver import SAVE_CPICKLE <EOL> from openmdao . util . typegroups import int_types , complex_or_real_types <EOL> _copydict = { <EOL> '<STR_LIT>' : copy . deepcopy , <EOL> '<STR_LIT>' : copy . copy <EOL> } <EOL> _iodict = { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT:input>' } <EOL> __missing__ = object ( ) <EOL> def get_closest_proxy ( obj , pathname ) : <EOL> """<STR_LIT>""" <EOL> names = pathname . split ( '<STR_LIT:.>' ) <EOL> i = <NUM_LIT:0> <EOL> for name in names : <EOL> if IContainerProxy . providedBy ( obj ) : <EOL> return ( obj , '<STR_LIT:.>' . join ( names [ i : ] ) ) <EOL> try : <EOL> obj = getattr ( obj , name ) <EOL> except AttributeError : <EOL> break <EOL> i += <NUM_LIT:1> <EOL> return ( obj , '<STR_LIT:.>' . join ( names [ i : ] ) ) <EOL> def proxy_parent ( obj , pathname ) : <EOL> """<STR_LIT>""" <EOL> names = pathname . split ( '<STR_LIT:.>' ) <EOL> i = <NUM_LIT:0> <EOL> for name in names [ : - <NUM_LIT:1> ] : <EOL> if IContainerProxy . providedBy ( obj ) : <EOL> return ( obj , '<STR_LIT:.>' . join ( names [ i : ] ) ) <EOL> try : <EOL> obj = getattr ( obj , name ) <EOL> except AttributeError : <EOL> break <EOL> i += <NUM_LIT:1> <EOL> return ( obj , '<STR_LIT:.>' . join ( names [ i : ] ) ) <EOL> push_exception_handler ( handler = lambda o , t , ov , nv : None , <EOL> reraise_exceptions = True , <EOL> main = True , <EOL> locked = True ) <EOL> class _MetaSafe ( MetaHasTraits ) : <EOL> """<STR_LIT>""" <EOL> def __new__ ( mcs , class_name , bases , class_dict ) : <EOL> for name , obj in class_dict . items ( ) : <EOL> if isinstance ( obj , Variable ) : <EOL> for base in bases : <EOL> if name in base . __dict__ : <EOL> raise NameError ( '<STR_LIT>' <EOL> % ( class_name , name , base . __name__ ) ) <EOL> return super ( _MetaSafe , mcs ) . __new__ ( mcs , class_name , bases , class_dict ) <EOL> class SafeHasTraits ( HasTraits ) : <EOL> """<STR_LIT>""" <EOL> __metaclass__ = _MetaSafe <EOL> def _check_bad_default ( name , trait , obj = None ) : <EOL> if trait . vartypename not in [ '<STR_LIT>' , '<STR_LIT>' ] and trait . required is True and not trait . assumed_default and trait . _illegal_default_ is True : <EOL> msg = "<STR_LIT>" % name <EOL> if obj is None : <EOL> raise RuntimeError ( msg ) <EOL> else : <EOL> obj . raise_exception ( msg , RuntimeError ) <EOL> class Container ( SafeHasTraits ) : <EOL> """<STR_LIT>""" <EOL> implements ( IContainer ) <EOL> def __init__ ( self ) : <EOL> self . _parent = None <EOL> self . _name = None <EOL> super ( Container , self ) . __init__ ( ) <EOL> self . _call_cpath_updated = True <EOL> self . _call_configure = True <EOL> self . _managers = { } <EOL> self . _added_traits = { } <EOL> self . _getcache = { } <EOL> self . _setcache = { } <EOL> self . _copycache = { } <EOL> self . _cached_traits_ = None <EOL> self . _repair_trait_info = None <EOL> self . _trait_metadata = { } <EOL> self . _logger = Logger ( '<STR_LIT>' ) <EOL> for name , obj in self . items ( ) : <EOL> if isinstance ( obj , FileRef ) : <EOL> setattr ( self , name , obj . copy ( owner = self ) ) <EOL> for name , obj in self . __class__ . __dict__ [ '<STR_LIT>' ] . items ( ) : <EOL> ttype = obj . trait_type <EOL> if isinstance ( ttype , VarTree ) : <EOL> variable_tree = getattr ( self , name ) <EOL> if not obj . required : <EOL> new_tree = variable_tree . copy ( ) <EOL> setattr ( self , name , new_tree ) <EOL> if obj . required : <EOL> _check_bad_default ( name , obj , self ) <EOL> @ property <EOL> def parent ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . _parent <EOL> @ parent . setter <EOL> def parent ( self , value ) : <EOL> """<STR_LIT>""" <EOL> if self . _parent is not value : <EOL> self . _parent = value <EOL> self . _fix_loggers ( self , recurse = True ) <EOL> self . _branch_moved ( ) <EOL> def _branch_moved ( self ) : <EOL> self . _call_cpath_updated = True <EOL> for n , cont in self . items ( ) : <EOL> if is_instance ( cont , Container ) and cont is not self . _parent : <EOL> cont . _branch_moved ( ) <EOL> @ property <EOL> def name ( self ) : <EOL> """<STR_LIT>""" <EOL> if self . _name is None : <EOL> if self . parent : <EOL> self . _name = find_name ( self . parent , self ) <EOL> self . _fix_loggers ( self , recurse = True ) <EOL> elif self . _call_cpath_updated is False : <EOL> self . _name = '<STR_LIT>' <EOL> else : <EOL> return '<STR_LIT>' <EOL> return self . _name <EOL> @ name . setter <EOL> def name ( self , name ) : <EOL> """<STR_LIT>""" <EOL> if not is_legal_name ( name ) : <EOL> raise NameError ( "<STR_LIT>" % name ) <EOL> if self . _name != name : <EOL> self . _name = name <EOL> self . _fix_loggers ( self , recurse = True ) <EOL> def _fix_loggers ( self , container , recurse ) : <EOL> """<STR_LIT>""" <EOL> container . _logger . rename ( container . get_pathname ( ) . replace ( '<STR_LIT:.>' , '<STR_LIT:U+002C>' ) ) <EOL> if recurse : <EOL> for name in container . list_containers ( ) : <EOL> obj = getattr ( container , name ) <EOL> self . _fix_loggers ( obj , recurse ) <EOL> @ rbac ( ( '<STR_LIT>' , '<STR_LIT:user>' ) ) <EOL> def get_pathname ( self , rel_to_scope = None ) : <EOL> """<STR_LIT>""" <EOL> path = [ ] <EOL> obj = self <EOL> name = obj . name <EOL> while obj is not rel_to_scope and name : <EOL> path . append ( name ) <EOL> obj = obj . parent <EOL> if obj is None : <EOL> break <EOL> name = obj . name <EOL> return '<STR_LIT:.>' . join ( path [ : : - <NUM_LIT:1> ] ) <EOL> def get_trait ( self , name , copy = False ) : <EOL> """<STR_LIT>""" <EOL> if self . _cached_traits_ is None : <EOL> self . _cached_traits_ = self . traits ( ) <EOL> self . _cached_traits_ . update ( self . _instance_traits ( ) ) <EOL> if copy : <EOL> if self . _cached_traits_ . get ( name ) : <EOL> return self . trait ( name , copy = copy ) <EOL> else : <EOL> return None <EOL> else : <EOL> return self . _cached_traits_ . get ( name ) <EOL> def __deepcopy__ ( self , memo ) : <EOL> """<STR_LIT>""" <EOL> id_self = id ( self ) <EOL> if id_self in memo : <EOL> return memo [ id_self ] <EOL> memo [ '<STR_LIT>' ] = "<STR_LIT>" <EOL> saved_p = self . _parent <EOL> saved_c = self . _cached_traits_ <EOL> saved_s = self . _setcache <EOL> saved_g = self . _getcache <EOL> self . _parent = None <EOL> self . _cached_traits_ = None <EOL> self . _getcache = { } <EOL> self . _setcache = { } <EOL> try : <EOL> result = super ( Container , self ) . __deepcopy__ ( memo ) <EOL> finally : <EOL> self . _parent = saved_p <EOL> self . _cached_traits_ = saved_c <EOL> self . _getcache = saved_g <EOL> self . _setcache = saved_s <EOL> olditraits = self . _instance_traits ( ) <EOL> for name , trait in olditraits . items ( ) : <EOL> if trait . type is not '<STR_LIT>' and name in self . _added_traits : <EOL> if isinstance ( trait . trait_type , VarTree ) : <EOL> if name not in result . _added_traits : <EOL> result . add_trait ( name , _clone_trait ( trait ) ) <EOL> else : <EOL> result . add_trait ( name , _clone_trait ( trait ) ) <EOL> if name in self . __dict__ : <EOL> result . __dict__ [ name ] = copy . deepcopy ( self . __dict__ [ name ] ) <EOL> return result <EOL> def __getstate__ ( self ) : <EOL> """<STR_LIT>""" <EOL> state = super ( Container , self ) . __getstate__ ( ) <EOL> dct = { } <EOL> for name , trait in state [ '<STR_LIT>' ] . items ( ) : <EOL> if trait . transient is not True : <EOL> dct [ name ] = trait <EOL> state [ '<STR_LIT>' ] = dct <EOL> state [ '<STR_LIT>' ] = None <EOL> state [ '<STR_LIT>' ] = { } <EOL> state [ '<STR_LIT>' ] = { } <EOL> return state <EOL> def __setstate__ ( self , state ) : <EOL> """<STR_LIT>""" <EOL> super ( Container , self ) . __setstate__ ( { } ) <EOL> self . __dict__ . update ( state ) <EOL> self . _repair_trait_info = { } <EOL> self . _cached_traits_ = None <EOL> traits = self . _alltraits ( ) <EOL> for name , trait in self . _added_traits . items ( ) : <EOL> if name not in traits : <EOL> self . add_trait ( name , trait , refresh = False ) <EOL> fixups = [ ] <EOL> for name , trait in traits . items ( ) : <EOL> try : <EOL> get = trait . trait_type . get <EOL> except AttributeError : <EOL> continue <EOL> if get is not None : <EOL> if name not in self . _added_traits : <EOL> try : <EOL> val = getattr ( self , name ) <EOL> self . remove_trait ( name ) <EOL> self . add_trait ( name , trait ) <EOL> setattr ( self , name , val ) <EOL> except Exception as exc : <EOL> self . _logger . warning ( '<STR_LIT>' , <EOL> name , val , exc ) <EOL> fixups . append ( ( name , trait ) ) <EOL> self . _repair_trait_info [ '<STR_LIT>' ] = fixups <EOL> fixups = [ ] <EOL> for name , val in self . __dict__ . items ( ) : <EOL> if not name . startswith ( '<STR_LIT>' ) and not self . get_trait ( name ) : <EOL> try : <EOL> setattr ( self , name , val ) <EOL> except Exception as exc : <EOL> self . _logger . warning ( '<STR_LIT>' , <EOL> name , val , exc ) <EOL> fixups . append ( ( name , val ) ) <EOL> self . _repair_trait_info [ '<STR_LIT>' ] = fixups <EOL> fixups = [ ] <EOL> for name , trait in self . _alltraits ( ) . items ( ) : <EOL> if isinstance ( trait . trait_type , List ) : <EOL> try : <EOL> setattr ( self , name , getattr ( self , name ) ) <EOL> except Exception as exc : <EOL> self . _logger . warning ( '<STR_LIT>' , <EOL> name , val , exc ) <EOL> fixups . append ( name ) <EOL> self . _repair_trait_info [ '<STR_LIT:list>' ] = fixups <EOL> self . _cached_traits_ = None <EOL> def _repair_traits ( self ) : <EOL> """<STR_LIT>""" <EOL> if self . _repair_trait_info is None : <EOL> return <EOL> for name , trait in self . _repair_trait_info [ '<STR_LIT>' ] : <EOL> val = getattr ( self , name ) <EOL> self . remove_trait ( name ) <EOL> self . add_trait ( name , trait ) <EOL> setattr ( self , name , val ) <EOL> for name , val in self . _repair_trait_info [ '<STR_LIT>' ] : <EOL> setattr ( self , name , val ) <EOL> for name in self . _repair_trait_info [ '<STR_LIT:list>' ] : <EOL> setattr ( self , name , getattr ( self , name ) ) <EOL> self . _repair_trait_info = None <EOL> @ classmethod <EOL> def add_class_trait ( cls , name , * trait ) : <EOL> """<STR_LIT>""" <EOL> bases = [ cls ] <EOL> bases . extend ( cls . __bases__ ) <EOL> for base in bases : <EOL> if name in base . __dict__ : <EOL> raise NameError ( '<STR_LIT>' <EOL> % ( name , base . __name__ ) ) <EOL> for t in trait : <EOL> _check_bad_default ( name , t ) <EOL> break <EOL> if name in cls . _trait_metadata : <EOL> del cls . _trait_metadata [ name ] <EOL> return super ( Container , cls ) . add_class_trait ( name , * trait ) <EOL> def add_trait ( self , name , trait , refresh = True ) : <EOL> """<STR_LIT>""" <EOL> if name . endswith ( '<STR_LIT>' ) and trait . type == '<STR_LIT>' : <EOL> super ( Container , self ) . add_trait ( name , trait ) <EOL> return <EOL> bases = [ self . __class__ ] <EOL> bases . extend ( self . __class__ . __bases__ ) <EOL> for base in bases : <EOL> if name in base . __dict__ : <EOL> raise NameError ( '<STR_LIT>' <EOL> % ( name , base . __name__ ) ) <EOL> _check_bad_default ( name , trait , self ) <EOL> if name not in self . _added_traits : <EOL> self . _added_traits [ name ] = trait <EOL> super ( Container , self ) . add_trait ( name , trait ) <EOL> if self . _cached_traits_ is not None : <EOL> self . _cached_traits_ [ name ] = self . trait ( name ) <EOL> if name in self . _trait_metadata : <EOL> del self . _trait_metadata [ name ] <EOL> if refresh : <EOL> getattr ( self , name ) <EOL> def remove_trait ( self , name ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> del self . _added_traits [ name ] <EOL> except KeyError : <EOL> pass <EOL> try : <EOL> del self . _cached_traits_ [ name ] <EOL> except ( KeyError , TypeError ) : <EOL> pass <EOL> try : <EOL> del self . _trait_metadata [ name ] <EOL> except KeyError : <EOL> pass <EOL> super ( Container , self ) . remove_trait ( name ) <EOL> @ rbac ( ( '<STR_LIT>' , '<STR_LIT:user>' ) ) <EOL> def get_attr_w_copy ( self , path ) : <EOL> """<STR_LIT>""" <EOL> obj = self . get ( path ) <EOL> copy = self . _copycache . get ( path , _missing ) <EOL> if copy is _missing : <EOL> copy = self . get_metadata ( path . split ( '<STR_LIT:[>' , <NUM_LIT:1> ) [ <NUM_LIT:0> ] , '<STR_LIT>' ) <EOL> self . _copycache [ path ] = copy <EOL> if copy : <EOL> if isinstance ( obj , Container ) : <EOL> obj = obj . copy ( ) <EOL> else : <EOL> obj = _copydict [ copy ] ( obj ) <EOL> return obj <EOL> def _add_after_parent_set ( self , name , obj ) : <EOL> pass <EOL> def _prep_for_add ( self , name , obj ) : <EOL> """<STR_LIT>""" <EOL> if '<STR_LIT:.>' in name : <EOL> self . raise_exception ( <EOL> '<STR_LIT>' % <EOL> name , ValueError ) <EOL> elif not is_legal_name ( name ) : <EOL> self . raise_exception ( "<STR_LIT>" % name , <EOL> NameError ) <EOL> removed = False <EOL> if has_interface ( obj , IContainer ) : <EOL> if self . contains ( name ) and getattr ( self , name ) : <EOL> self . remove ( name ) <EOL> removed = True <EOL> if has_interface ( obj , IContainer ) : <EOL> self . _check_recursion ( obj ) <EOL> if IContainerProxy . providedBy ( obj ) : <EOL> obj . parent = self . _get_proxy ( obj ) <EOL> else : <EOL> obj . parent = self <EOL> obj . name = name <EOL> self . _add_after_parent_set ( name , obj ) <EOL> if self . _call_cpath_updated is False : <EOL> obj . cpath_updated ( ) <EOL> return removed <EOL> def _post_container_add ( self , name , obj , removed ) : <EOL> pass <EOL> def add ( self , name , obj ) : <EOL> """<STR_LIT>""" <EOL> removed = self . _prep_for_add ( name , obj ) <EOL> if has_interface ( obj , IContainer ) : <EOL> setattr ( self , name , obj ) <EOL> if self . _cached_traits_ is None : <EOL> self . get_trait ( name ) <EOL> else : <EOL> self . _cached_traits_ [ name ] = self . trait ( name ) <EOL> self . _post_container_add ( name , obj , removed ) <EOL> elif is_instance ( obj , TraitType ) : <EOL> self . add_trait ( name , obj ) <EOL> else : <EOL> setattr ( self , name , obj ) <EOL> return obj <EOL> def _check_recursion ( self , obj ) : <EOL> """<STR_LIT>""" <EOL> ancestor = self <EOL> while is_instance ( ancestor , Container ) : <EOL> if obj is ancestor : <EOL> self . raise_exception ( '<STR_LIT>' , <EOL> ValueError ) <EOL> ancestor = ancestor . parent <EOL> def _get_proxy ( self , proxy ) : <EOL> """<STR_LIT>""" <EOL> addr_type = connection . address_type ( proxy . _token . address ) <EOL> addr = proxy . _token . address [ <NUM_LIT:0> ] if addr_type == '<STR_LIT>' else None <EOL> key = ( addr_type , addr , proxy . _authkey ) <EOL> try : <EOL> manager = self . _managers [ key ] <EOL> except KeyError : <EOL> if addr_type == '<STR_LIT>' : <EOL> ip_addr = socket . gethostbyname ( socket . gethostname ( ) ) <EOL> address = ( ip_addr , <NUM_LIT:0> ) <EOL> allowed_hosts = [ addr ] <EOL> if addr == ip_addr : <EOL> allowed_hosts . append ( '<STR_LIT:127.0.0.1>' ) <EOL> else : <EOL> address = None <EOL> allowed_hosts = None <EOL> name = self . name or '<STR_LIT>' <EOL> access = addr if addr_type == '<STR_LIT>' else addr_type <EOL> name = '<STR_LIT>' % ( name , access ) <EOL> manager = ObjectManager ( self , address , authkey = proxy . _authkey , <EOL> name = name , allowed_hosts = allowed_hosts ) <EOL> self . _managers [ key ] = manager <EOL> return manager . proxy <EOL> def _check_rename ( self , oldname , newname ) : <EOL> if '<STR_LIT:.>' in oldname or '<STR_LIT:.>' in newname : <EOL> self . raise_exception ( "<STR_LIT>" <EOL> "<STR_LIT>" % <EOL> ( oldname , newname ) , RuntimeError ) <EOL> if not self . contains ( oldname ) : <EOL> self . raise_exception ( "<STR_LIT>" % <EOL> ( oldname , newname , oldname ) , RuntimeError ) <EOL> if self . contains ( newname ) : <EOL> self . raise_exception ( "<STR_LIT>" % <EOL> ( oldname , newname , newname ) , RuntimeError ) <EOL> def rename ( self , oldname , newname ) : <EOL> """<STR_LIT>""" <EOL> self . _check_rename ( oldname , newname ) <EOL> obj = self . remove ( oldname ) <EOL> self . add ( newname , obj ) <EOL> def remove ( self , name ) : <EOL> """<STR_LIT>""" <EOL> if '<STR_LIT:.>' in name : <EOL> self . raise_exception ( <EOL> '<STR_LIT>' % <EOL> name , NameError ) <EOL> try : <EOL> obj = getattr ( self , name ) <EOL> except AttributeError : <EOL> return None <EOL> trait = self . get_trait ( name ) <EOL> if trait is None : <EOL> delattr ( self , name ) <EOL> else : <EOL> if trait . is_trait_type ( Slot ) : <EOL> try : <EOL> setattr ( self , name , None ) <EOL> except TypeError as err : <EOL> self . raise_exception ( str ( err ) , RuntimeError ) <EOL> else : <EOL> self . remove_trait ( name ) <EOL> return obj <EOL> @ rbac ( ( '<STR_LIT>' , '<STR_LIT:user>' ) ) <EOL> def configure ( self ) : <EOL> pass <EOL> @ rbac ( ( '<STR_LIT>' , '<STR_LIT:user>' ) ) <EOL> def copy ( self ) : <EOL> """<STR_LIT>""" <EOL> cp = copy . deepcopy ( self ) <EOL> cp . _relink ( ) <EOL> return cp <EOL> def _relink ( self ) : <EOL> """<STR_LIT>""" <EOL> for name in self . list_containers ( ) : <EOL> container = getattr ( self , name ) <EOL> if container is not self . _parent : <EOL> container . _parent = self <EOL> container . _relink ( ) <EOL> @ rbac ( ( '<STR_LIT>' , '<STR_LIT:user>' ) ) <EOL> def cpath_updated ( self ) : <EOL> """<STR_LIT>""" <EOL> self . _fix_loggers ( self , recurse = False ) <EOL> self . _call_cpath_updated = False <EOL> for cont in self . list_containers ( ) : <EOL> cont = getattr ( self , cont ) <EOL> if cont is not self . _parent : <EOL> cont . cpath_updated ( ) <EOL> def revert_to_defaults ( self , recurse = True ) : <EOL> """<STR_LIT>""" <EOL> self . reset_traits ( iotype = '<STR_LIT>' ) <EOL> if recurse : <EOL> for cname in self . list_containers ( ) : <EOL> getattr ( self , cname ) . revert_to_defaults ( recurse ) <EOL> def _items ( self , visited , recurse = False , ** metadata ) : <EOL> """<STR_LIT>""" <EOL> if id ( self ) not in visited : <EOL> visited . add ( id ( self ) ) <EOL> match_dict = self . _alltraits ( ** metadata ) <EOL> if recurse : <EOL> for name in self . list_containers ( ) : <EOL> obj = getattr ( self , name ) <EOL> if name in match_dict and id ( obj ) not in visited : <EOL> yield ( name , obj ) <EOL> if obj : <EOL> for chname , child in obj . _items ( visited , recurse , <EOL> ** metadata ) : <EOL> yield ( '<STR_LIT:.>' . join ( ( name , chname ) ) , child ) <EOL> for name , trait in match_dict . items ( ) : <EOL> obj = getattr ( self , name , Missing ) <EOL> if obj is not Missing : <EOL> if is_instance ( obj , ( Container , VarTree ) ) and id ( obj ) not in visited : <EOL> if not recurse : <EOL> yield ( name , obj ) <EOL> elif trait . iotype is not None : <EOL> yield ( name , obj ) <EOL> def items ( self , recurse = False , ** metadata ) : <EOL> """<STR_LIT>""" <EOL> return self . _items ( set ( [ id ( self . parent ) ] ) , recurse , ** metadata ) <EOL> def list_containers ( self ) : <EOL> """<STR_LIT>""" <EOL> return [ n for n , v in self . items ( ) if is_instance ( v , Container ) ] <EOL> def list_vars ( self ) : <EOL> """<STR_LIT>""" <EOL> return [ k for k , v in self . items ( iotype = not_none ) ] <EOL> @ rbac ( ( '<STR_LIT>' , '<STR_LIT:user>' ) ) <EOL> def _alltraits ( self , traits = None , events = False , ** metadata ) : <EOL> """<STR_LIT>""" <EOL> if traits is None : <EOL> if self . _cached_traits_ : <EOL> traits = self . _cached_traits_ <EOL> else : <EOL> traits = self . traits ( ) <EOL> traits . update ( self . _instance_traits ( ) ) <EOL> self . _cached_traits_ = traits <EOL> result = { } <EOL> for name , trait in traits . items ( ) : <EOL> if not events and trait . type is '<STR_LIT>' : <EOL> continue <EOL> for meta_name , meta_eval in metadata . items ( ) : <EOL> if type ( meta_eval ) is FunctionType : <EOL> if not meta_eval ( getattr ( trait , meta_name ) ) : <EOL> break <EOL> elif meta_eval != getattr ( trait , meta_name ) : <EOL> break <EOL> else : <EOL> result [ name ] = trait <EOL> return result <EOL> @ rbac ( ( '<STR_LIT>' , '<STR_LIT:user>' ) ) <EOL> def contains ( self , path ) : <EOL> """<STR_LIT>""" <EOL> childname , _ , restofpath = path . partition ( '<STR_LIT:.>' ) <EOL> if restofpath : <EOL> obj = getattr ( self , childname , Missing ) <EOL> if obj is Missing : <EOL> return False <EOL> elif is_instance ( obj , Container ) : <EOL> return obj . contains ( restofpath ) <EOL> else : <EOL> return hasattr ( obj , restofpath ) <EOL> return hasattr ( self , path ) <EOL> def _get_metadata_failed ( self , traitpath , metaname ) : <EOL> self . raise_exception ( "<STR_LIT>" % traitpath , <EOL> AttributeError ) <EOL> @ rbac ( ( '<STR_LIT>' , '<STR_LIT:user>' ) ) <EOL> def get_metadata ( self , traitpath , metaname = None ) : <EOL> """<STR_LIT>""" <EOL> childname , _ , restofpath = traitpath . partition ( '<STR_LIT:.>' ) <EOL> if restofpath : <EOL> obj = getattr ( self , childname , Missing ) <EOL> if obj is Missing : <EOL> return self . _get_metadata_failed ( traitpath , metaname ) <EOL> elif hasattr ( obj , '<STR_LIT>' ) : <EOL> return obj . get_metadata ( restofpath , metaname ) <EOL> else : <EOL> t = self . get_trait ( childname ) <EOL> if t is not None and t . iotype and metaname == '<STR_LIT>' : <EOL> return t . iotype <EOL> else : <EOL> self . _get_metadata_failed ( traitpath , metaname ) <EOL> varname , _ , _ = traitpath . partition ( '<STR_LIT:[>' ) <EOL> try : <EOL> mdict = self . _trait_metadata [ varname ] <EOL> except KeyError : <EOL> t = self . get_trait ( varname ) <EOL> if t : <EOL> t = t . trait_type <EOL> mdict = t . _metadata . copy ( ) <EOL> mdict . setdefault ( '<STR_LIT>' , t . __class__ . __name__ ) <EOL> else : <EOL> mdict = self . _get_metadata_failed ( traitpath , None ) <EOL> self . _trait_metadata [ varname ] = mdict <EOL> if metaname is None : <EOL> return mdict <EOL> else : <EOL> return mdict . get ( metaname , None ) <EOL> @ rbac ( ( '<STR_LIT>' , '<STR_LIT:user>' ) ) <EOL> def set_metadata ( self , traitpath , metaname , value ) : <EOL> """<STR_LIT>""" <EOL> if metaname in ( '<STR_LIT>' , ) : <EOL> self . raise_exception ( "<STR_LIT>" <EOL> % ( metaname , traitpath ) , TypeError ) <EOL> self . get_metadata ( traitpath ) [ metaname ] = value <EOL> @ rbac ( ( '<STR_LIT>' , '<STR_LIT:user>' ) , proxy_types = [ FileRef ] ) <EOL> def get ( self , path ) : <EOL> """<STR_LIT>""" <EOL> expr = self . _getcache . get ( path ) <EOL> if expr is not None : <EOL> return eval ( expr , self . __dict__ ) <EOL> obj , restofpath = get_closest_proxy ( self , path ) <EOL> if restofpath and IContainerProxy . providedBy ( obj ) : <EOL> return obj . get ( restofpath ) <EOL> expr = compile ( path , path , mode = '<STR_LIT>' ) <EOL> try : <EOL> val = eval ( expr , self . __dict__ ) <EOL> except ( AttributeError , NameError ) as err : <EOL> if not restofpath : <EOL> return obj <EOL> self . raise_exception ( str ( err ) , AttributeError ) <EOL> else : <EOL> self . _getcache [ path ] = expr <EOL> return val <EOL> @ rbac ( ( '<STR_LIT>' , '<STR_LIT:user>' ) , proxy_types = [ FileRef ] ) <EOL> def get_flattened_value ( self , path ) : <EOL> """<STR_LIT>""" <EOL> return flattened_value ( path , self . get ( path ) ) <EOL> @ rbac ( ( '<STR_LIT>' , '<STR_LIT:user>' ) ) <EOL> def set_flattened_value ( self , path , value ) : <EOL> obj , restofpath = proxy_parent ( self , path ) <EOL> if restofpath and IContainerProxy . providedBy ( obj ) : <EOL> obj . set_flattened_value ( restofpath , value ) <EOL> return <EOL> val = self . get ( path ) <EOL> if not isinstance ( val , int_types ) and isinstance ( val , complex_or_real_types ) : <EOL> self . set ( path , value [ <NUM_LIT:0> ] ) <EOL> return <EOL> elif hasattr ( val , '<STR_LIT>' ) : <EOL> val . set_flattened_value ( value ) <EOL> return <EOL> elif isinstance ( val , ndarray ) : <EOL> try : <EOL> newshape = value . shape <EOL> self . set ( path , value . reshape ( val . shape ) ) <EOL> except Exception as err : <EOL> self . reraise_exception ( "<STR_LIT>" <EOL> % ( self . get_pathname ( ) , path , val . shape , newshape ) , <EOL> sys . exc_info ( ) ) <EOL> return <EOL> val = self . get ( path . split ( '<STR_LIT:[>' , <NUM_LIT:1> ) [ <NUM_LIT:0> ] ) <EOL> idx = get_index ( path ) <EOL> if isinstance ( val , int_types ) : <EOL> pass <EOL> elif hasattr ( val , '<STR_LIT>' ) and idx is not None : <EOL> if isinstance ( val [ idx ] , complex_or_real_types ) : <EOL> val [ idx ] = value [ <NUM_LIT:0> ] <EOL> else : <EOL> val [ idx ] = value <EOL> return <EOL> elif IVariableTree . providedBy ( val ) : <EOL> raise NotImplementedError ( "<STR_LIT>" ) <EOL> elif hasattr ( val , '<STR_LIT>' ) : <EOL> val . set_flattened_value ( value ) <EOL> return <EOL> self . raise_exception ( "<STR_LIT>" % path , TypeError ) <EOL> def get_iotype ( self , name ) : <EOL> return self . get_trait ( name ) . iotype <EOL> @ rbac ( ( '<STR_LIT>' , '<STR_LIT:user>' ) ) <EOL> def set ( self , path , value ) : <EOL> """<STR_LIT>""" <EOL> _local_setter_ = value <EOL> expr = self . _setcache . get ( path ) <EOL> if expr is not None : <EOL> exec ( expr ) <EOL> return <EOL> obj , restofpath = proxy_parent ( self , path ) <EOL> if IOverrideSet . providedBy ( obj ) or ( restofpath and IContainerProxy . providedBy ( obj ) ) : <EOL> obj . set ( restofpath , value ) <EOL> return <EOL> assign = "<STR_LIT>" % path <EOL> expr = compile ( assign , assign , mode = '<STR_LIT>' ) <EOL> try : <EOL> exec ( expr ) <EOL> except Exception as err : <EOL> self . raise_exception ( str ( err ) , err . __class__ ) <EOL> else : <EOL> self . _setcache [ path ] = expr <EOL> def save_to_egg ( self , name , version , py_dir = None , src_dir = None , <EOL> src_files = None , child_objs = None , dst_dir = None , <EOL> observer = None , need_requirements = True ) : <EOL> """<STR_LIT>""" <EOL> assert name and isinstance ( name , basestring ) <EOL> assert version and isinstance ( version , basestring ) <EOL> if not version . endswith ( '<STR_LIT:.>' ) : <EOL> version += '<STR_LIT:.>' <EOL> now = datetime . datetime . now ( ) <EOL> tstamp = '<STR_LIT>' % ( now . year , now . month , now . day , now . hour , now . minute ) <EOL> version += tstamp <EOL> observer = eggobserver . EggObserver ( observer , self . _logger ) <EOL> entry_pts = [ ( self , name , _get_entry_group ( self ) ) ] <EOL> if child_objs is not None : <EOL> root_pathname = self . get_pathname ( ) <EOL> root_start = root_pathname . rfind ( '<STR_LIT:.>' ) <EOL> root_start = root_start + <NUM_LIT:1> if root_start >= <NUM_LIT:0> else <NUM_LIT:0> <EOL> root_pathname += '<STR_LIT:.>' <EOL> for child in child_objs : <EOL> pathname = child . get_pathname ( ) <EOL> if not pathname . startswith ( root_pathname ) : <EOL> msg = '<STR_LIT>' % ( pathname , root_pathname ) <EOL> observer . exception ( msg ) <EOL> self . raise_exception ( msg , RuntimeError ) <EOL> entry_pts . append ( ( child , pathname [ root_start : ] , <EOL> _get_entry_group ( child ) ) ) <EOL> parent = self . parent <EOL> self . parent = None <EOL> try : <EOL> return eggsaver . save_to_egg ( entry_pts , version , py_dir , <EOL> src_dir , src_files , dst_dir , <EOL> self . _logger , observer . observer , <EOL> need_requirements ) <EOL> except Exception : <EOL> self . reraise_exception ( info = sys . exc_info ( ) ) <EOL> finally : <EOL> self . parent = parent <EOL> def save ( self , outstream , fmt = SAVE_CPICKLE , proto = - <NUM_LIT:1> ) : <EOL> """<STR_LIT>""" <EOL> parent = self . parent <EOL> self . parent = None <EOL> try : <EOL> eggsaver . save ( self , outstream , fmt , proto , self . _logger ) <EOL> except Exception : <EOL> self . reraise_exception ( info = sys . exc_info ( ) ) <EOL> finally : <EOL> self . parent = parent <EOL> @ staticmethod <EOL> def load_from_eggfile ( filename , observer = None , log = None ) : <EOL> """<STR_LIT>""" <EOL> entry_group = '<STR_LIT>' <EOL> entry_name = '<STR_LIT>' <EOL> log = log or logger <EOL> return eggloader . load_from_eggfile ( filename , entry_group , entry_name , <EOL> log , observer ) <EOL> @ staticmethod <EOL> def load_from_eggpkg ( package , entry_name = None , instance_name = None , <EOL> observer = None ) : <EOL> """<STR_LIT>""" <EOL> entry_group = '<STR_LIT>' <EOL> if not entry_name : <EOL> entry_name = package <EOL> return eggloader . load_from_eggpkg ( package , entry_group , entry_name , <EOL> instance_name , logger , observer ) <EOL> @ staticmethod <EOL> def load ( instream , fmt = SAVE_CPICKLE , package = None , call_post_load = True , <EOL> name = None ) : <EOL> """<STR_LIT>""" <EOL> top = eggloader . load ( instream , fmt , package , logger ) <EOL> top . cpath_updated ( ) <EOL> if name : <EOL> top . name = name <EOL> if call_post_load : <EOL> top . parent = None <EOL> top . post_load ( ) <EOL> return top <EOL> def post_load ( self ) : <EOL> """<STR_LIT>""" <EOL> self . _repair_traits ( ) <EOL> for name in self . list_containers ( ) : <EOL> getattr ( self , name ) . post_load ( ) <EOL> @ rbac ( '<STR_LIT>' ) <EOL> def pre_delete ( self ) : <EOL> """<STR_LIT>""" <EOL> for name in self . list_containers ( ) : <EOL> getattr ( self , name ) . pre_delete ( ) <EOL> @ rbac ( ( '<STR_LIT>' , '<STR_LIT:user>' ) , proxy_types = [ CTrait ] ) <EOL> def get_dyn_trait ( self , pathname , iotype = None , trait = None ) : <EOL> """<STR_LIT>""" <EOL> if pathname . startswith ( '<STR_LIT>' ) : <EOL> return None <EOL> cname , _ , restofpath = pathname . partition ( '<STR_LIT:.>' ) <EOL> if restofpath : <EOL> child = getattr ( self , cname ) <EOL> if is_instance ( child , Container ) : <EOL> return child . get_dyn_trait ( restofpath , iotype , trait ) <EOL> else : <EOL> if deep_hasattr ( child , restofpath ) : <EOL> return None <EOL> else : <EOL> trait = self . get_trait ( cname ) <EOL> if trait is not None : <EOL> if iotype is not None : <EOL> if isinstance ( trait . trait_type , Python ) : <EOL> obj = getattr ( self , cname ) <EOL> t_iotype = getattr ( obj , '<STR_LIT>' , None ) <EOL> else : <EOL> t_iotype = self . get_iotype ( cname ) <EOL> if ( iotype == '<STR_LIT>' and t_iotype not in ( '<STR_LIT>' , '<STR_LIT:state>' ) ) or ( iotype == '<STR_LIT>' and t_iotype not in ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT:state>' , '<STR_LIT>' ) ) : <EOL> self . raise_exception ( "<STR_LIT>" % <EOL> ( pathname , _iodict [ iotype ] ) , <EOL> RuntimeError ) <EOL> return trait <EOL> elif trait is None and self . contains ( cname ) : <EOL> return None <EOL> self . raise_exception ( "<STR_LIT>" % <EOL> pathname , AttributeError ) <EOL> @ rbac ( ( '<STR_LIT>' , '<STR_LIT:user>' ) ) <EOL> def get_trait_typenames ( self , pathname , iotype = None ) : <EOL> """<STR_LIT>""" <EOL> if not pathname : <EOL> obj = self <EOL> else : <EOL> trait = self . get_dyn_trait ( pathname , iotype = iotype ) <EOL> if trait is None : <EOL> return [ ] <EOL> trait = trait . trait_type or trait . trait or trait <EOL> if trait . target : <EOL> trait = self . get_dyn_trait ( trait . target ) <EOL> try : <EOL> ttype = trait . trait_type <EOL> except AttributeError : <EOL> pass <EOL> else : <EOL> if ttype is not None : <EOL> trait = ttype <EOL> if isinstance ( trait , Python ) : <EOL> obj = self . get ( pathname ) <EOL> else : <EOL> obj = trait <EOL> names = [ ] <EOL> Container . _bases ( type ( obj ) , names ) <EOL> return names <EOL> @ staticmethod <EOL> def _bases ( cls , names ) : <EOL> """<STR_LIT>""" <EOL> names . append ( '<STR_LIT>' % ( cls . __module__ , cls . __name__ ) ) <EOL> for base in cls . __bases__ : <EOL> Container . _bases ( base , names ) <EOL> def raise_exception ( self , msg , exception_class = Exception ) : <EOL> """<STR_LIT>""" <EOL> coords = '<STR_LIT>' <EOL> obj = self <EOL> while obj is not None : <EOL> try : <EOL> coords = obj . get_itername ( ) <EOL> except AttributeError : <EOL> try : <EOL> obj = obj . parent <EOL> except AttributeError : <EOL> break <EOL> else : <EOL> break <EOL> if coords : <EOL> full_msg = '<STR_LIT>' % ( self . get_pathname ( ) , coords , msg ) <EOL> else : <EOL> full_msg = '<STR_LIT>' % ( self . get_pathname ( ) , msg ) <EOL> raise exception_class ( full_msg ) <EOL> def reraise_exception ( self , msg = '<STR_LIT>' , info = None ) : <EOL> """<STR_LIT>""" <EOL> if info is None : <EOL> exc_type , exc_value , exc_traceback = sys . exc_info ( ) <EOL> else : <EOL> exc_type , exc_value , exc_traceback = info <EOL> if msg : <EOL> msg = '<STR_LIT>' % ( msg , exc_value ) <EOL> else : <EOL> msg = '<STR_LIT:%s>' % exc_value <EOL> prefix = '<STR_LIT>' % self . get_pathname ( ) <EOL> if not msg . startswith ( prefix ) : <EOL> msg = prefix + msg <EOL> new_exc = exc_type ( msg ) <EOL> raise exc_type , new_exc , exc_traceback <EOL> def build_trait ( self , ref_name , iotype = None , trait = None ) : <EOL> """<STR_LIT>""" <EOL> self . raise_exception ( '<STR_LIT>' , NotImplementedError ) <EOL> CLASSES_TO_PROXY . append ( Container ) <EOL> CLASSES_TO_PROXY . append ( FileRef ) <EOL> def _get_entry_group ( obj ) : <EOL> """<STR_LIT>""" <EOL> if _get_entry_group . group_map is None : <EOL> from openmdao . main . component import Component <EOL> from openmdao . main . driver import Driver <EOL> _get_entry_group . group_map = [ <EOL> ( Variable , '<STR_LIT>' ) , <EOL> ( Driver , '<STR_LIT>' ) , <EOL> ( ICaseIterator , '<STR_LIT>' ) , <EOL> ( IResourceAllocator , '<STR_LIT>' ) , <EOL> ( Component , '<STR_LIT>' ) , <EOL> ( Container , '<STR_LIT>' ) , <EOL> ] <EOL> for cls , group in _get_entry_group . group_map : <EOL> if issubclass ( cls , Interface ) : <EOL> if cls . providedBy ( obj ) : <EOL> return group <EOL> else : <EOL> if isinstance ( obj , cls ) : <EOL> return group <EOL> return None <EOL> _get_entry_group . group_map = None <EOL> def dump ( cont , recurse = False , stream = None , ** metadata ) : <EOL> """<STR_LIT>""" <EOL> pprint . pprint ( dict ( [ ( n , str ( v ) ) <EOL> for n , v in cont . items ( recurse = recurse , <EOL> ** metadata ) ] ) , <EOL> stream ) <EOL> def find_name ( parent , obj ) : <EOL> """<STR_LIT>""" <EOL> for name , val in parent . __dict__ . items ( ) : <EOL> if val is obj : <EOL> return name <EOL> return '<STR_LIT>' <EOL> def get_default_name ( obj , scope ) : <EOL> """<STR_LIT>""" <EOL> classname = obj . __class__ . __name__ . lower ( ) <EOL> if scope is None : <EOL> sdict = { } <EOL> else : <EOL> sdict = scope . __dict__ <EOL> ver = <NUM_LIT:1> <EOL> while '<STR_LIT>' % ( classname , ver ) in sdict : <EOL> ver += <NUM_LIT:1> <EOL> return '<STR_LIT>' % ( classname , ver ) <EOL> def find_trait_and_value ( obj , pathname ) : <EOL> """<STR_LIT>""" <EOL> names = pathname . split ( '<STR_LIT:.>' ) <EOL> for name in names [ : - <NUM_LIT:1> ] : <EOL> obj = getattr ( obj , name ) <EOL> if is_instance ( obj , Container ) : <EOL> objtrait = obj . get_trait ( names [ - <NUM_LIT:1> ] ) <EOL> elif isinstance ( obj , HasTraits ) : <EOL> objtrait = obj . trait ( names [ - <NUM_LIT:1> ] ) <EOL> else : <EOL> objtrait = None <EOL> return ( objtrait , getattr ( obj , names [ - <NUM_LIT:1> ] ) ) <EOL> def create_io_traits ( cont , obj_info , iotype = '<STR_LIT>' ) : <EOL> """<STR_LIT>""" <EOL> if isinstance ( obj_info , ( basestring , tuple ) ) : <EOL> it = [ obj_info ] <EOL> else : <EOL> it = obj_info <EOL> for entry in it : <EOL> iostat = iotype <EOL> trait = None <EOL> if isinstance ( entry , basestring ) : <EOL> ref_name = entry <EOL> name = entry . replace ( '<STR_LIT:.>' , '<STR_LIT:_>' ) <EOL> elif isinstance ( entry , tuple ) : <EOL> ref_name = entry [ <NUM_LIT:0> ] <EOL> name = entry [ <NUM_LIT:1> ] or ref_name . replace ( '<STR_LIT:.>' , '<STR_LIT:_>' ) <EOL> try : <EOL> iostat = entry [ <NUM_LIT:2> ] <EOL> trait = entry [ <NUM_LIT:3> ] <EOL> except IndexError : <EOL> pass <EOL> else : <EOL> cont . raise_exception ( '<STR_LIT>' % entry , <EOL> RuntimeError ) <EOL> if '<STR_LIT:.>' in name : <EOL> cont . raise_exception ( "<STR_LIT>" <EOL> "<STR_LIT>" % name , NameError ) <EOL> newtrait = cont . get_trait ( name ) <EOL> if newtrait is not None : <EOL> cont . raise_exception ( <EOL> "<STR_LIT>" % name , <EOL> RuntimeError ) <EOL> if not cont . contains ( ref_name ) : <EOL> cont . raise_exception ( "<STR_LIT>" <EOL> "<STR_LIT>" % ref_name , AttributeError ) <EOL> cont . add_trait ( name , cont . build_trait ( ref_name , iostat , trait ) ) </s>
<s> """<STR_LIT>""" <EOL> __all__ = [ "<STR_LIT>" ] <EOL> from traits . api import Instance <EOL> from openmdao . main . variable import Variable , gui_excludes <EOL> class VarTree ( Variable ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , default_value , allow_none = True , ** metadata ) : <EOL> from openmdao . main . vartree import VariableTree <EOL> if isinstance ( default_value , VariableTree ) : <EOL> klass = default_value . __class__ <EOL> if '<STR_LIT>' in metadata : <EOL> default_value . _iotype = metadata [ '<STR_LIT>' ] <EOL> else : <EOL> metadata [ '<STR_LIT>' ] = default_value . iotype <EOL> else : <EOL> raise TypeError ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> metadata . setdefault ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . _allow_none = allow_none <EOL> self . klass = klass <EOL> self . _instance = Instance ( klass = klass , allow_none = False , factory = None , <EOL> args = None , kw = None , ** metadata ) <EOL> self . _instance . default_value = default_value <EOL> super ( VarTree , self ) . __init__ ( default_value , ** metadata ) <EOL> def validate ( self , obj , name , value ) : <EOL> """<STR_LIT>""" <EOL> if value is None : <EOL> if self . _allow_none : <EOL> return value <EOL> self . validate_failed ( obj , name , value ) <EOL> try : <EOL> value = self . _instance . validate ( obj , name , value ) <EOL> except Exception : <EOL> obj . raise_exception ( '<STR_LIT>' % <EOL> ( name , self . _instance . klass . __module__ , <EOL> self . _instance . klass . __name__ , type ( value ) ) , <EOL> TypeError ) <EOL> return value <EOL> def post_setattr ( self , obj , name , value ) : <EOL> """<STR_LIT>""" <EOL> if value . parent is not obj : <EOL> value . parent = obj <EOL> value . name = name <EOL> value . _iotype = self . iotype <EOL> def get_attribute ( self , name , value , trait , meta ) : <EOL> """<STR_LIT>""" <EOL> io_attr = { } <EOL> io_attr [ '<STR_LIT:name>' ] = name <EOL> io_attr [ '<STR_LIT:type>' ] = trait . trait_type . klass . __name__ <EOL> io_attr [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> for field in meta : <EOL> if field not in gui_excludes : <EOL> io_attr [ field ] = meta [ field ] <EOL> return io_attr , None </s>
<s> import os <EOL> import sys <EOL> import numpy <EOL> from contextlib import contextmanager <EOL> def _redirect_streams ( to_fd ) : <EOL> """<STR_LIT>""" <EOL> original_stdout_fd = sys . stdout . fileno ( ) <EOL> original_stderr_fd = sys . stderr . fileno ( ) <EOL> sys . stdout . close ( ) <EOL> sys . stderr . close ( ) <EOL> os . dup2 ( to_fd , original_stdout_fd ) <EOL> os . dup2 ( to_fd , original_stderr_fd ) <EOL> sys . stdout = os . fdopen ( original_stdout_fd , '<STR_LIT:wb>' , <NUM_LIT:0> ) <EOL> sys . stderr = os . fdopen ( original_stderr_fd , '<STR_LIT:wb>' , <NUM_LIT:0> ) <EOL> def use_proc_files ( ) : <EOL> if MPI is not None : <EOL> rank = MPI . COMM_WORLD . rank <EOL> sname = "<STR_LIT>" % rank <EOL> ofile = open ( sname , '<STR_LIT:wb>' ) <EOL> _redirect_streams ( ofile . fileno ( ) ) <EOL> def under_mpirun ( ) : <EOL> """<STR_LIT>""" <EOL> for name in os . environ . keys ( ) : <EOL> if name . startswith ( '<STR_LIT>' ) or name . startswith ( '<STR_LIT>' ) : <EOL> return True <EOL> return False <EOL> class PETSc ( object ) : <EOL> def __init__ ( self ) : <EOL> self . needs_ksp = False <EOL> self . _PETSc = None <EOL> @ property <EOL> def installed ( self ) : <EOL> try : <EOL> if self . _PETSc is None : <EOL> PETSc = _import_petsc ( ) <EOL> del sys . modules [ '<STR_LIT>' ] <EOL> self . _PETSc = PETSc <EOL> return True <EOL> except ImportError : <EOL> self . _PETSc = None <EOL> return False <EOL> def __getattr__ ( self , name ) : <EOL> if self . installed : <EOL> return getattr ( self . _PETSc , name ) <EOL> raise AttributeError ( name ) <EOL> def create_petsc_vec ( comm , arr ) : <EOL> if under_mpirun ( ) or PETSc . needs_ksp : <EOL> if PETSc . installed and ( MPI is None or comm != MPI . COMM_NULL ) : <EOL> return PETSc . Vec ( ) . createWithArray ( arr , comm = comm ) <EOL> return None <EOL> def _import_petsc ( ) : <EOL> import petsc4py <EOL> from petsc4py import PETSc <EOL> return PETSc <EOL> if under_mpirun ( ) : <EOL> from mpi4py import MPI <EOL> PETSc = _import_petsc ( ) <EOL> PETSc . installed = True <EOL> COMM_NULL = MPI . COMM_NULL <EOL> else : <EOL> MPI = None <EOL> COMM_NULL = None <EOL> PETSc = PETSc ( ) <EOL> class MPI_info ( object ) : <EOL> def __init__ ( self ) : <EOL> self . requested_cpus = ( <NUM_LIT:1> , <NUM_LIT:1> ) <EOL> self . comm = COMM_NULL <EOL> @ property <EOL> def size ( self ) : <EOL> if MPI and self . comm != COMM_NULL : <EOL> return self . comm . size <EOL> return <NUM_LIT:1> <EOL> @ property <EOL> def rank ( self ) : <EOL> if MPI : <EOL> if self . comm != COMM_NULL : <EOL> return self . comm . rank <EOL> else : <EOL> return - <NUM_LIT:1> <EOL> return <NUM_LIT:0> <EOL> def get_norm ( vec , order = None ) : <EOL> """<STR_LIT>""" <EOL> if MPI : <EOL> vec . petsc_vec . assemble ( ) <EOL> return vec . petsc_vec . norm ( ) <EOL> else : <EOL> return numpy . linalg . norm ( vec . array , ord = order ) <EOL> idx_arr_type = PETSc . IntType if MPI else '<STR_LIT:i>' <EOL> def make_idx_array ( start , end ) : <EOL> """<STR_LIT>""" <EOL> return numpy . arange ( start , end , dtype = idx_arr_type ) <EOL> def to_idx_array ( idxs ) : <EOL> """<STR_LIT>""" <EOL> return numpy . array ( idxs , dtype = idx_arr_type ) <EOL> def evenly_distrib_idxs ( num_divisions , arr_size ) : <EOL> """<STR_LIT>""" <EOL> base = arr_size / num_divisions <EOL> leftover = arr_size % num_divisions <EOL> sizes = numpy . ones ( num_divisions , dtype = "<STR_LIT:int>" ) * base <EOL> sizes [ : leftover ] += <NUM_LIT:1> <EOL> offsets = numpy . zeros ( num_divisions , dtype = "<STR_LIT:int>" ) <EOL> offsets [ <NUM_LIT:1> : ] = numpy . cumsum ( sizes ) [ : - <NUM_LIT:1> ] <EOL> return sizes , offsets <EOL> @ contextmanager <EOL> def MPIContext ( ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> yield <EOL> except : <EOL> exc_type , exc_val , exc_tb = sys . exc_info ( ) <EOL> if exc_val is not None : <EOL> fail = True <EOL> else : <EOL> fail = False <EOL> fails = MPI . COMM_WORLD . allgather ( fail ) <EOL> if fail or not any ( fails ) : <EOL> raise exc_type , exc_val , exc_tb <EOL> else : <EOL> for i , f in enumerate ( fails ) : <EOL> if f : <EOL> raise RuntimeError ( "<STR_LIT>" % i ) <EOL> if os . environ . get ( '<STR_LIT>' ) : <EOL> use_proc_files ( ) </s>
<s> import unittest <EOL> from openmdao . main . api import Assembly , Component <EOL> from openmdao . main . datatypes . api import Float , Array <EOL> from openmdao . lib . drivers . api import CONMINdriver , BroydenSolver , SensitivityDriver , FixedPointIterator <EOL> from openmdao . lib . optproblems import sellar <EOL> class Dis12Linear ( Component ) : <EOL> """<STR_LIT>""" <EOL> z1 = Float ( <NUM_LIT:0.> , iotype = '<STR_LIT>' ) <EOL> z2 = Float ( <NUM_LIT:0.> , iotype = '<STR_LIT>' ) <EOL> z_store = Array ( [ <NUM_LIT:0.> , <NUM_LIT:0.> ] , iotype = '<STR_LIT>' ) <EOL> ssa_F = Array ( [ <NUM_LIT:0.0> ] , iotype = '<STR_LIT>' ) <EOL> ssa_G = Array ( [ <NUM_LIT:0.0> , <NUM_LIT:0.0> ] , iotype = '<STR_LIT>' ) <EOL> ssa_dF = Array ( [ <NUM_LIT:0.0> , <NUM_LIT:0.0> ] , iotype = '<STR_LIT>' ) <EOL> ssa_dG = Array ( [ [ <NUM_LIT:0.0> , <NUM_LIT:0.0> ] , [ <NUM_LIT:0.0> , <NUM_LIT:0.0> ] ] , iotype = '<STR_LIT>' ) <EOL> obj = Float ( <NUM_LIT:0.0> , iotype = '<STR_LIT>' ) <EOL> con1 = Float ( <NUM_LIT:0.0> , iotype = '<STR_LIT>' ) <EOL> con2 = Float ( <NUM_LIT:0.0> , iotype = '<STR_LIT>' ) <EOL> def execute ( self ) : <EOL> self . obj = self . ssa_F [ <NUM_LIT:0> ] + self . ssa_dF [ <NUM_LIT:0> ] * ( self . z_store [ <NUM_LIT:0> ] - self . z1 ) + self . ssa_dF [ <NUM_LIT:1> ] * ( self . z_store [ <NUM_LIT:1> ] - self . z2 ) <EOL> self . con1 = self . ssa_G [ <NUM_LIT:0> ] + self . ssa_dG [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] * ( self . z_store [ <NUM_LIT:0> ] - self . z1 ) + self . ssa_dG [ <NUM_LIT:0> ] [ <NUM_LIT:1> ] * ( self . z_store [ <NUM_LIT:1> ] - self . z2 ) <EOL> self . con2 = self . ssa_G [ <NUM_LIT:1> ] + self . ssa_dG [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] * ( self . z_store [ <NUM_LIT:0> ] - self . z1 ) + self . ssa_dG [ <NUM_LIT:1> ] [ <NUM_LIT:1> ] * ( self . z_store [ <NUM_LIT:1> ] - self . z2 ) <EOL> class SellarBLISS ( Assembly ) : <EOL> z_store = Array ( [ <NUM_LIT:0.> , <NUM_LIT:0.> ] , dtype = Float , iotype = '<STR_LIT>' ) <EOL> def configure ( self ) : <EOL> """<STR_LIT>""" <EOL> self . add ( '<STR_LIT>' , Dis12Linear ( ) ) <EOL> self . connect ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . add ( '<STR_LIT>' , CONMINdriver ( ) ) <EOL> self . sysopt . add_parameter ( '<STR_LIT>' , low = - <NUM_LIT> , high = <NUM_LIT> , start = <NUM_LIT> ) <EOL> self . sysopt . add_objective ( '<STR_LIT>' ) <EOL> self . driver . workflow . add ( [ '<STR_LIT>' ] ) <EOL> self . sysopt . workflow . add ( [ '<STR_LIT>' ] ) <EOL> class BndryFullSubTestCase ( unittest . TestCase ) : <EOL> def test_MDF ( self ) : <EOL> prob = SellarBLISS ( ) <EOL> prob . name = '<STR_LIT>' <EOL> prob . run ( ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> unittest . main ( ) </s>
<s> import numpy as np <EOL> import unittest <EOL> from openmdao . main . api import Assembly , Component , Driver , set_as_top <EOL> from openmdao . main . datatypes . api import Float , Array <EOL> from openmdao . main . hasconstraints import HasConstraints , HasEqConstraints , HasIneqConstraints , Constraint , Has2SidedConstraints <EOL> from openmdao . main . interfaces import IHas2SidedConstraints , implements <EOL> from openmdao . main . pseudocomp import SimpleEQConPComp , SimpleEQ0PComp <EOL> from openmdao . main . test . simpledriver import SimpleDriver <EOL> from openmdao . test . execcomp import ExecComp <EOL> from openmdao . units . units import PhysicalQuantity <EOL> from openmdao . util . decorators import add_delegate <EOL> from openmdao . util . testutil import assert_rel_error <EOL> @ add_delegate ( HasConstraints ) <EOL> class MyDriver ( Driver ) : <EOL> pass <EOL> @ add_delegate ( HasEqConstraints ) <EOL> class MyEqDriver ( Driver ) : <EOL> pass <EOL> @ add_delegate ( HasIneqConstraints ) <EOL> class MyInEqDriver ( Driver ) : <EOL> pass <EOL> @ add_delegate ( HasConstraints , Has2SidedConstraints ) <EOL> class My2SDriver ( Driver ) : <EOL> implements ( IHas2SidedConstraints ) <EOL> class SimpleUnits ( Component ) : <EOL> a = Float ( iotype = '<STR_LIT>' , units = '<STR_LIT>' ) <EOL> b = Float ( iotype = '<STR_LIT>' , units = '<STR_LIT>' ) <EOL> c = Float ( iotype = '<STR_LIT>' , units = '<STR_LIT>' ) <EOL> d = Float ( iotype = '<STR_LIT>' , units = '<STR_LIT>' ) <EOL> arr = Array ( [ <NUM_LIT:1.> , <NUM_LIT> , <NUM_LIT> ] , iotype = '<STR_LIT>' , units = '<STR_LIT>' ) <EOL> arr_out = Array ( [ <NUM_LIT:1.> , <NUM_LIT> , <NUM_LIT> ] , iotype = '<STR_LIT>' , units = '<STR_LIT>' ) <EOL> def __init__ ( self ) : <EOL> super ( SimpleUnits , self ) . __init__ ( ) <EOL> self . a = <NUM_LIT:1> <EOL> self . b = <NUM_LIT:2> <EOL> self . c = <NUM_LIT:3> <EOL> self . d = - <NUM_LIT:1> <EOL> def execute ( self ) : <EOL> self . c = PhysicalQuantity ( self . a + self . b , '<STR_LIT>' ) . in_units_of ( '<STR_LIT>' ) . value <EOL> self . d = PhysicalQuantity ( self . a - self . b , '<STR_LIT>' ) . in_units_of ( '<STR_LIT>' ) . value <EOL> class Simple ( Component ) : <EOL> a = Float ( iotype = '<STR_LIT>' ) <EOL> b = Float ( iotype = '<STR_LIT>' ) <EOL> c = Float ( iotype = '<STR_LIT>' ) <EOL> d = Float ( iotype = '<STR_LIT>' ) <EOL> def __init__ ( self ) : <EOL> super ( Simple , self ) . __init__ ( ) <EOL> self . a = <NUM_LIT:1> <EOL> self . b = <NUM_LIT:2> <EOL> self . c = <NUM_LIT:3> <EOL> self . d = - <NUM_LIT:1> <EOL> def execute ( self ) : <EOL> self . c = self . a + self . b <EOL> self . d = self . a - self . b <EOL> def list_deriv_vars ( self ) : <EOL> return ( '<STR_LIT:a>' , '<STR_LIT:b>' ) , ( '<STR_LIT:c>' , '<STR_LIT:d>' ) <EOL> def provideJ ( self ) : <EOL> der = <NUM_LIT:1.0> <EOL> return np . array ( [ [ der , der ] , [ der , der ] ] ) <EOL> class HasConstraintsTestCase ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . asm = set_as_top ( Assembly ( ) ) <EOL> self . asm . add ( '<STR_LIT>' , Simple ( ) ) <EOL> self . asm . add ( '<STR_LIT>' , Simple ( ) ) <EOL> self . asm . add ( '<STR_LIT>' , SimpleUnits ( ) ) <EOL> self . asm . add ( '<STR_LIT>' , SimpleUnits ( ) ) <EOL> def test_list_constraints ( self ) : <EOL> drv = self . asm . add ( '<STR_LIT>' , MyDriver ( ) ) <EOL> self . asm . run ( ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> self . assertEqual ( drv . list_constraints ( ) , <EOL> [ '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> def test_list_eq_constraints ( self ) : <EOL> drv = self . asm . add ( '<STR_LIT>' , MyEqDriver ( ) ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> self . assertEqual ( drv . list_constraints ( ) , <EOL> [ '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> def test_list_ineq_constraints ( self ) : <EOL> drv = self . asm . add ( '<STR_LIT>' , MyDriver ( ) ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> self . assertEqual ( drv . list_constraints ( ) , <EOL> [ '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> def _check_ineq_add_constraint ( self , drv ) : <EOL> self . asm . add ( '<STR_LIT>' , drv ) <EOL> try : <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> except Exception as err : <EOL> self . assertEqual ( str ( err ) , "<STR_LIT>" ) <EOL> else : <EOL> self . fail ( "<STR_LIT>" ) <EOL> self . assertEqual ( len ( drv . get_ineq_constraints ( ) ) , <NUM_LIT:0> ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> try : <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> except Exception as err : <EOL> self . assertEqual ( str ( err ) , <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> else : <EOL> self . fail ( "<STR_LIT>" ) <EOL> self . assertEqual ( len ( drv . get_ineq_constraints ( ) ) , <NUM_LIT:1> ) <EOL> drv . remove_constraint ( '<STR_LIT>' ) <EOL> self . assertEqual ( len ( drv . get_ineq_constraints ( ) ) , <NUM_LIT:0> ) <EOL> try : <EOL> drv . remove_constraint ( '<STR_LIT>' ) <EOL> except Exception as err : <EOL> self . assertEqual ( str ( err ) , <EOL> "<STR_LIT>" ) <EOL> else : <EOL> self . fail ( "<STR_LIT>" ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> self . assertEqual ( len ( drv . get_ineq_constraints ( ) ) , <NUM_LIT:1> ) <EOL> drv . add_constraint ( '<STR_LIT>' , name = '<STR_LIT>' ) <EOL> self . assertEqual ( len ( drv . get_ineq_constraints ( ) ) , <NUM_LIT:2> ) <EOL> try : <EOL> drv . add_constraint ( '<STR_LIT>' , name = '<STR_LIT>' ) <EOL> except Exception as err : <EOL> self . assertEqual ( str ( err ) , '<STR_LIT>' ) <EOL> else : <EOL> self . fail ( "<STR_LIT>" ) <EOL> self . assertEqual ( len ( drv . get_ineq_constraints ( ) ) , <NUM_LIT:2> ) <EOL> drv . remove_constraint ( '<STR_LIT>' ) <EOL> self . assertEqual ( len ( drv . get_ineq_constraints ( ) ) , <NUM_LIT:1> ) <EOL> drv . clear_constraints ( ) <EOL> self . assertEqual ( len ( drv . get_ineq_constraints ( ) ) , <NUM_LIT:0> ) <EOL> try : <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> except ValueError as err : <EOL> self . assertEqual ( str ( err ) , <EOL> "<STR_LIT>" ) <EOL> else : <EOL> self . fail ( '<STR_LIT>' ) <EOL> def _check_eq_add_constraint ( self , drv ) : <EOL> self . asm . add ( '<STR_LIT>' , drv ) <EOL> self . assertEqual ( len ( drv . get_eq_constraints ( ) ) , <NUM_LIT:0> ) <EOL> self . assertEqual ( len ( drv . get_eq_constraints ( ) ) , <NUM_LIT:0> ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> self . assertEqual ( len ( drv . get_eq_constraints ( ) ) , <NUM_LIT:1> ) <EOL> try : <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> except Exception as err : <EOL> self . assertEqual ( str ( err ) , <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> else : <EOL> self . fail ( "<STR_LIT>" ) <EOL> drv . remove_constraint ( '<STR_LIT>' ) <EOL> self . assertEqual ( len ( drv . get_eq_constraints ( ) ) , <NUM_LIT:0> ) <EOL> try : <EOL> drv . remove_constraint ( '<STR_LIT>' ) <EOL> except Exception as err : <EOL> self . assertEqual ( str ( err ) , <EOL> "<STR_LIT>" ) <EOL> else : <EOL> self . fail ( "<STR_LIT>" ) <EOL> self . assertEqual ( len ( drv . get_eq_constraints ( ) ) , <NUM_LIT:0> ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> self . assertEqual ( len ( drv . get_eq_constraints ( ) ) , <NUM_LIT:1> ) <EOL> drv . add_constraint ( '<STR_LIT>' , name = '<STR_LIT>' ) <EOL> self . assertEqual ( len ( drv . get_eq_constraints ( ) ) , <NUM_LIT:2> ) <EOL> try : <EOL> drv . add_constraint ( '<STR_LIT>' , name = '<STR_LIT>' ) <EOL> except Exception as err : <EOL> self . assertEqual ( str ( err ) , '<STR_LIT>' ) <EOL> else : <EOL> self . fail ( "<STR_LIT>" ) <EOL> drv . remove_constraint ( '<STR_LIT>' ) <EOL> self . assertEqual ( len ( drv . get_eq_constraints ( ) ) , <NUM_LIT:1> ) <EOL> drv . clear_constraints ( ) <EOL> self . assertEqual ( len ( drv . get_eq_constraints ( ) ) , <NUM_LIT:0> ) <EOL> try : <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> except ValueError as err : <EOL> self . assertEqual ( str ( err ) , <EOL> "<STR_LIT>" ) <EOL> else : <EOL> self . fail ( '<STR_LIT>' ) <EOL> def _check_eq_eval_constraints ( self , drv ) : <EOL> self . asm . add ( '<STR_LIT>' , drv ) <EOL> vals = drv . eval_eq_constraints ( ) <EOL> self . assertEqual ( len ( vals ) , <NUM_LIT:0> ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . comp1 . a = <NUM_LIT:4> <EOL> self . asm . comp1 . b = <NUM_LIT:5> <EOL> self . asm . comp1 . c = <NUM_LIT:9> <EOL> self . asm . comp1 . d = - <NUM_LIT:1> <EOL> self . asm . run ( ) <EOL> vals = drv . eval_eq_constraints ( ) <EOL> self . assertEqual ( len ( vals ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( vals [ <NUM_LIT:0> ] , <NUM_LIT> ) <EOL> vals = drv . get_eq_constraints ( ) <EOL> self . assertEqual ( len ( vals ) , <NUM_LIT:1> ) <EOL> self . assertTrue ( isinstance ( vals [ '<STR_LIT>' ] , Constraint ) ) <EOL> def _check_ineq_eval_constraints ( self , drv ) : <EOL> self . asm . add ( '<STR_LIT>' , drv ) <EOL> vals = drv . eval_ineq_constraints ( ) <EOL> self . assertEqual ( len ( vals ) , <NUM_LIT:0> ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . comp1 . a = <NUM_LIT:4> <EOL> self . asm . comp1 . b = <NUM_LIT:5> <EOL> self . asm . comp1 . c = <NUM_LIT:9> <EOL> self . asm . comp1 . d = - <NUM_LIT:1> <EOL> self . asm . run ( ) <EOL> vals = drv . eval_ineq_constraints ( ) <EOL> self . assertEqual ( len ( vals ) , <NUM_LIT:1> ) <EOL> self . assertEqual ( vals [ <NUM_LIT:0> ] , <NUM_LIT:1> ) <EOL> vals = drv . get_ineq_constraints ( ) <EOL> self . assertEqual ( len ( vals ) , <NUM_LIT:1> ) <EOL> self . assertTrue ( isinstance ( vals [ '<STR_LIT>' ] , Constraint ) ) <EOL> def test_constraint_scaler_adder ( self ) : <EOL> drv = self . asm . add ( '<STR_LIT>' , MyDriver ( ) ) <EOL> self . asm . comp1 . a = <NUM_LIT> <EOL> self . asm . comp1 . b = <NUM_LIT> <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . run ( ) <EOL> result = drv . eval_ineq_constraints ( ) <EOL> self . assertEqual ( result [ <NUM_LIT:0> ] , - <NUM_LIT> ) <EOL> drv . remove_constraint ( '<STR_LIT>' ) <EOL> result = drv . eval_ineq_constraints ( ) <EOL> self . assertEqual ( result , [ ] ) <EOL> def test_add_constraint_eq_eq ( self ) : <EOL> drv = MyDriver ( ) <EOL> self . asm . add ( '<STR_LIT>' , drv ) <EOL> try : <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> except Exception as err : <EOL> self . assertEqual ( str ( err ) , "<STR_LIT>" ) <EOL> else : <EOL> self . fail ( "<STR_LIT>" ) <EOL> def test_add_constraint ( self ) : <EOL> drv = MyDriver ( ) <EOL> self . _check_eq_add_constraint ( drv ) <EOL> self . _check_ineq_add_constraint ( drv ) <EOL> def test_add_eq_constraint ( self ) : <EOL> self . _check_eq_add_constraint ( MyEqDriver ( ) ) <EOL> def test_add_ineq_constraint ( self ) : <EOL> self . _check_ineq_add_constraint ( MyInEqDriver ( ) ) <EOL> def test_implicit_constraint ( self ) : <EOL> drv = self . asm . add ( '<STR_LIT>' , MyEqDriver ( ) ) <EOL> try : <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> except ValueError , err : <EOL> self . assertEqual ( str ( err ) , <EOL> "<STR_LIT>" ) <EOL> else : <EOL> self . fail ( '<STR_LIT>' ) <EOL> def test_eval_constraint ( self ) : <EOL> self . _check_eq_eval_constraints ( MyDriver ( ) ) <EOL> self . _check_ineq_eval_constraints ( MyDriver ( ) ) <EOL> def test_eval_eq_constraint ( self ) : <EOL> self . _check_eq_eval_constraints ( MyEqDriver ( ) ) <EOL> def test_eval_ineq_constraint ( self ) : <EOL> self . _check_ineq_eval_constraints ( MyInEqDriver ( ) ) <EOL> def test_pseudocomps ( self ) : <EOL> self . asm . add ( '<STR_LIT>' , MyDriver ( ) ) <EOL> self . asm . driver . workflow . add ( [ '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> self . asm . _setup ( ) <EOL> self . assertEqual ( self . asm . _depgraph . list_connections ( ) , <EOL> [ ] ) <EOL> self . asm . driver . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . _setup ( ) <EOL> self . assertEqual ( self . asm . _pseudo_0 . _orig_expr , '<STR_LIT>' ) <EOL> self . assertEqual ( set ( self . asm . _depgraph . list_connections ( drivers = False ) ) , <EOL> set ( [ ( '<STR_LIT>' , '<STR_LIT>' ) , ( '<STR_LIT>' , '<STR_LIT>' ) ] ) ) <EOL> self . asm . driver . remove_constraint ( '<STR_LIT>' ) <EOL> self . asm . _setup ( ) <EOL> self . assertEqual ( self . asm . _depgraph . list_connections ( drivers = False ) , [ ] ) <EOL> self . asm . driver . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . _setup ( ) <EOL> self . assertEqual ( set ( self . asm . _depgraph . list_connections ( drivers = False ) ) , <EOL> set ( [ ( '<STR_LIT>' , '<STR_LIT>' ) ] ) ) <EOL> self . asm . _setup ( ) <EOL> self . assertEqual ( self . asm . _pseudo_1 . _orig_expr , '<STR_LIT>' ) <EOL> self . asm . driver . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . _setup ( ) <EOL> self . assertEqual ( self . asm . _pseudo_2 . _orig_expr , '<STR_LIT>' ) <EOL> self . asm . driver . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . _setup ( ) <EOL> self . assertEqual ( self . asm . _pseudo_3 . _orig_expr , '<STR_LIT>' ) <EOL> self . asm . driver . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . _setup ( ) <EOL> self . assertEqual ( self . asm . _pseudo_4 . _orig_expr , '<STR_LIT>' ) <EOL> self . asm . driver . clear_constraints ( ) <EOL> self . asm . comp1 . a = <NUM_LIT:2> <EOL> self . asm . comp1 . b = <NUM_LIT:1> <EOL> self . asm . comp2 . a = <NUM_LIT:4> <EOL> self . asm . comp2 . b = <NUM_LIT:2> <EOL> self . asm . driver . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . driver . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . driver . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . run ( ) <EOL> self . assertEqual ( self . asm . _pseudo_5 . out0 , <NUM_LIT:1.0> ) <EOL> self . assertEqual ( self . asm . _pseudo_6 . out0 , - <NUM_LIT:1.0> ) <EOL> self . assertEqual ( self . asm . _pseudo_7 . out0 , <NUM_LIT> ) <EOL> def test_custom_pseudocomp_creation ( self ) : <EOL> self . asm . add ( '<STR_LIT>' , MyDriver ( ) ) <EOL> arg = { } <EOL> result = { } <EOL> self . asm . driver . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . _setup ( ) <EOL> self . assertEqual ( self . asm . _pseudo_0 . __class__ , SimpleEQ0PComp ) <EOL> self . asm . run ( ) <EOL> arg [ '<STR_LIT>' ] = np . array ( [ <NUM_LIT> ] ) <EOL> result [ '<STR_LIT>' ] = np . array ( [ <NUM_LIT:0.0> ] ) <EOL> self . asm . _pseudo_0 . apply_deriv ( arg , result ) <EOL> self . assertEqual ( result [ '<STR_LIT>' ] [ <NUM_LIT:0> ] , <NUM_LIT> ) <EOL> self . asm . driver . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . _setup ( ) <EOL> self . assertEqual ( self . asm . _pseudo_1 . __class__ , SimpleEQ0PComp ) <EOL> self . asm . run ( ) <EOL> arg [ '<STR_LIT>' ] = np . array ( [ <NUM_LIT> ] ) <EOL> result [ '<STR_LIT>' ] = np . array ( [ <NUM_LIT:0.0> ] ) <EOL> self . asm . _pseudo_1 . apply_deriv ( arg , result ) <EOL> self . assertEqual ( result [ '<STR_LIT>' ] [ <NUM_LIT:0> ] , <NUM_LIT> ) <EOL> self . asm . driver . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . _setup ( ) <EOL> self . assertEqual ( self . asm . _pseudo_2 . __class__ , SimpleEQConPComp ) <EOL> self . asm . run ( ) <EOL> arg [ '<STR_LIT>' ] = np . array ( [ <NUM_LIT> ] ) <EOL> arg [ '<STR_LIT>' ] = np . array ( [ <NUM_LIT> ] ) <EOL> result [ '<STR_LIT>' ] = np . array ( [ <NUM_LIT:0.0> ] ) <EOL> self . asm . _pseudo_2 . apply_deriv ( arg , result ) <EOL> self . assertEqual ( result [ '<STR_LIT>' ] [ <NUM_LIT:0> ] , <NUM_LIT> ) <EOL> self . asm . driver . clear_constraints ( ) <EOL> self . asm . driver . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . _setup ( ) <EOL> self . assertEqual ( self . asm . _pseudo_3 . __class__ , SimpleEQConPComp ) <EOL> self . asm . run ( ) <EOL> arg [ '<STR_LIT>' ] = np . array ( [ <NUM_LIT> ] ) <EOL> arg [ '<STR_LIT>' ] = np . array ( [ <NUM_LIT> ] ) <EOL> result [ '<STR_LIT>' ] = np . array ( [ <NUM_LIT:0.0> ] ) <EOL> self . asm . _pseudo_3 . apply_deriv ( arg , result ) <EOL> self . assertEqual ( result [ '<STR_LIT>' ] [ <NUM_LIT:0> ] , <NUM_LIT> ) <EOL> self . asm . driver . clear_constraints ( ) <EOL> self . asm . driver . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . _setup ( ) <EOL> self . assertEqual ( self . asm . _pseudo_4 . __class__ , SimpleEQConPComp ) <EOL> self . asm . run ( ) <EOL> arg [ '<STR_LIT>' ] = np . array ( [ <NUM_LIT> ] ) <EOL> arg [ '<STR_LIT>' ] = np . array ( [ <NUM_LIT> ] ) <EOL> result [ '<STR_LIT>' ] = np . array ( [ <NUM_LIT:0.0> ] ) <EOL> self . asm . _pseudo_4 . apply_deriv ( arg , result ) <EOL> self . assertEqual ( result [ '<STR_LIT>' ] [ <NUM_LIT:0> ] , <NUM_LIT> ) <EOL> def test_custom_jacobian ( self ) : <EOL> class AComp ( Component ) : <EOL> x = Array ( [ [ <NUM_LIT:1.0> , <NUM_LIT> ] , [ - <NUM_LIT> , <NUM_LIT> ] ] , iotype = '<STR_LIT>' ) <EOL> y = Array ( np . zeros ( ( <NUM_LIT:2> , <NUM_LIT:2> ) ) , iotype = '<STR_LIT>' ) <EOL> def __init__ ( self ) : <EOL> super ( AComp , self ) . __init__ ( ) <EOL> self . J = np . array ( [ [ <NUM_LIT> , - <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> [ <NUM_LIT> , <NUM_LIT> , - <NUM_LIT> , <NUM_LIT> ] , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> [ <NUM_LIT:0.1> , <NUM_LIT> , <NUM_LIT> , - <NUM_LIT> ] ] ) <EOL> def execute ( self ) : <EOL> """<STR_LIT>""" <EOL> y = self . J . dot ( self . x . flatten ( ) ) <EOL> self . y = y . reshape ( ( <NUM_LIT:2> , <NUM_LIT:2> ) ) <EOL> def list_deriv_vars ( self ) : <EOL> """<STR_LIT>""" <EOL> input_keys = ( '<STR_LIT:x>' , ) <EOL> output_keys = ( '<STR_LIT:y>' , ) <EOL> return input_keys , output_keys <EOL> def provideJ ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . J <EOL> def fake_jac ( ) : <EOL> """<STR_LIT>""" <EOL> jacs = { } <EOL> jacs [ '<STR_LIT>' ] = np . array ( [ [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] ] ) <EOL> return jacs <EOL> top = set_as_top ( Assembly ( ) ) <EOL> top . add ( '<STR_LIT>' , SimpleDriver ( ) ) <EOL> top . add ( '<STR_LIT>' , AComp ( ) ) <EOL> top . driver . workflow . add ( '<STR_LIT>' ) <EOL> top . driver . add_parameter ( '<STR_LIT>' , low = <NUM_LIT:10> , high = <NUM_LIT:10> ) <EOL> top . driver . add_constraint ( '<STR_LIT>' , jacs = fake_jac ) <EOL> top . _setup ( ) <EOL> top . run ( ) <EOL> J = top . driver . calc_gradient ( mode = '<STR_LIT>' , return_format = '<STR_LIT>' ) <EOL> J = J [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> diff = np . abs ( J - top . comp . J ) <EOL> assert_rel_error ( self , diff . max ( ) , <NUM_LIT:0.0> , <NUM_LIT> ) <EOL> J = top . driver . calc_gradient ( mode = '<STR_LIT>' , return_format = '<STR_LIT>' ) <EOL> J = J [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> diff = np . abs ( J - fake_jac ( ) [ '<STR_LIT>' ] ) <EOL> assert_rel_error ( self , diff . max ( ) , <NUM_LIT:0.0> , <NUM_LIT> ) <EOL> top . driver . clear_constraints ( ) <EOL> top . _pseudo_count = <NUM_LIT:0> <EOL> top . driver . add_constraint ( '<STR_LIT>' , jacs = fake_jac ) <EOL> top . _setup ( ) <EOL> top . run ( ) <EOL> J = top . driver . calc_gradient ( mode = '<STR_LIT>' , return_format = '<STR_LIT>' ) <EOL> J = J [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> diff = np . abs ( J - top . comp . J ) <EOL> assert_rel_error ( self , diff . max ( ) , <NUM_LIT:0.0> , <NUM_LIT> ) <EOL> J = top . driver . calc_gradient ( mode = '<STR_LIT>' , return_format = '<STR_LIT>' ) <EOL> J = J [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> diff = np . abs ( J - fake_jac ( ) [ '<STR_LIT>' ] ) <EOL> assert_rel_error ( self , diff . max ( ) , <NUM_LIT:0.0> , <NUM_LIT> ) <EOL> top . driver . clear_constraints ( ) <EOL> top . _pseudo_count = <NUM_LIT:0> <EOL> top . driver . add_constraint ( '<STR_LIT>' , jacs = fake_jac ) <EOL> top . _setup ( ) <EOL> top . run ( ) <EOL> J = top . driver . calc_gradient ( mode = '<STR_LIT>' , return_format = '<STR_LIT>' ) <EOL> J = J [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> diff = np . abs ( J - top . comp . J ) <EOL> assert_rel_error ( self , diff . max ( ) , <NUM_LIT:0.0> , <NUM_LIT> ) <EOL> J = top . driver . calc_gradient ( mode = '<STR_LIT>' , return_format = '<STR_LIT>' ) <EOL> J = J [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> diff = np . abs ( J - fake_jac ( ) [ '<STR_LIT>' ] ) <EOL> assert_rel_error ( self , diff . max ( ) , <NUM_LIT:0.0> , <NUM_LIT> ) <EOL> top . driver . clear_constraints ( ) <EOL> top . _pseudo_count = <NUM_LIT:0> <EOL> top . driver . add_constraint ( '<STR_LIT>' , jacs = fake_jac ) <EOL> top . driver . gradient_options . lin_solver = '<STR_LIT>' <EOL> top . _setup ( ) <EOL> top . run ( ) <EOL> J = top . driver . calc_gradient ( mode = '<STR_LIT>' , return_format = '<STR_LIT>' ) <EOL> J = J [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> diff = np . abs ( J - top . comp . J ) <EOL> assert_rel_error ( self , diff . max ( ) , <NUM_LIT:0.0> , <NUM_LIT> ) <EOL> J = top . driver . calc_gradient ( mode = '<STR_LIT>' , return_format = '<STR_LIT>' ) <EOL> J = J [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> diff = np . abs ( J - fake_jac ( ) [ '<STR_LIT>' ] ) <EOL> assert_rel_error ( self , diff . max ( ) , <NUM_LIT:0.0> , <NUM_LIT> ) <EOL> def fake_jac2 ( ) : <EOL> """<STR_LIT>""" <EOL> jacs = { } <EOL> jacs [ '<STR_LIT>' ] = np . array ( [ [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] ] ) <EOL> return jacs <EOL> top . driver . clear_constraints ( ) <EOL> top . _pseudo_count = <NUM_LIT:0> <EOL> top . driver . add_constraint ( '<STR_LIT>' , jacs = fake_jac2 ) <EOL> top . _setup ( ) <EOL> top . run ( ) <EOL> J = top . driver . calc_gradient ( mode = '<STR_LIT>' , return_format = '<STR_LIT>' ) <EOL> J = J [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> diff = np . abs ( J - top . comp . J ) <EOL> assert_rel_error ( self , diff . max ( ) , <NUM_LIT:0.0> , <NUM_LIT> ) <EOL> J = top . driver . calc_gradient ( mode = '<STR_LIT>' , return_format = '<STR_LIT>' ) <EOL> J = J [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> J_abs = np . abs ( J ) <EOL> assert_rel_error ( self , J_abs . max ( ) , <NUM_LIT:0.0> , <NUM_LIT> ) <EOL> class Has2SidedConstraintsTestCase ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . asm = set_as_top ( Assembly ( ) ) <EOL> self . asm . add ( '<STR_LIT>' , Simple ( ) ) <EOL> self . asm . add ( '<STR_LIT>' , Simple ( ) ) <EOL> self . asm . add ( '<STR_LIT>' , SimpleUnits ( ) ) <EOL> self . asm . add ( '<STR_LIT>' , SimpleUnits ( ) ) <EOL> def test_unsupported ( self ) : <EOL> drv = self . asm . add ( '<STR_LIT>' , MyDriver ( ) ) <EOL> self . asm . run ( ) <EOL> try : <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> except AttributeError as err : <EOL> self . assertEqual ( str ( err ) , "<STR_LIT>" ) <EOL> else : <EOL> self . fail ( "<STR_LIT>" ) <EOL> def test_get_2sided_constraints ( self ) : <EOL> drv = self . asm . add ( '<STR_LIT>' , My2SDriver ( ) ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . run ( ) <EOL> cons = drv . get_2sided_constraints ( ) <EOL> self . assertTrue ( len ( cons ) == <NUM_LIT:2> ) <EOL> con1 = cons [ '<STR_LIT>' ] <EOL> self . assertEqual ( self . asm . comp1 . a , con1 . evaluate ( self . asm ) [ <NUM_LIT:0> ] ) <EOL> self . assertEqual ( con1 . low , - <NUM_LIT> ) <EOL> self . assertEqual ( con1 . high , <NUM_LIT> ) <EOL> con1 = cons [ '<STR_LIT>' ] <EOL> self . assertEqual ( self . asm . comp1 . c , con1 . evaluate ( self . asm ) [ <NUM_LIT:0> ] ) <EOL> self . assertEqual ( con1 . low , <NUM_LIT> ) <EOL> self . assertEqual ( con1 . high , <NUM_LIT> ) <EOL> cons = drv . get_constraints ( ) <EOL> self . assertTrue ( len ( cons ) == <NUM_LIT:0> ) <EOL> def test_list_constraints ( self ) : <EOL> drv = self . asm . add ( '<STR_LIT>' , My2SDriver ( ) ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . run ( ) <EOL> cons = drv . list_constraints ( ) <EOL> self . assertTrue ( '<STR_LIT>' in cons ) <EOL> self . assertTrue ( '<STR_LIT>' in cons ) <EOL> def test_gradient ( self ) : <EOL> drv = self . asm . add ( '<STR_LIT>' , My2SDriver ( ) ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . run ( ) <EOL> J = drv . calc_gradient ( inputs = [ '<STR_LIT>' ] ) <EOL> assert_rel_error ( self , J [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] , <NUM_LIT> , <NUM_LIT> ) <EOL> assert_rel_error ( self , J [ <NUM_LIT:1> ] [ <NUM_LIT:0> ] , <NUM_LIT:1.0> , <NUM_LIT> ) <EOL> assert_rel_error ( self , J [ <NUM_LIT:2> ] [ <NUM_LIT:0> ] , <NUM_LIT:1.0> , <NUM_LIT> ) <EOL> assert_rel_error ( self , J [ <NUM_LIT:3> ] [ <NUM_LIT:0> ] , <NUM_LIT> , <NUM_LIT> ) <EOL> def test_replace ( self ) : <EOL> drv = self . asm . add ( '<STR_LIT>' , My2SDriver ( ) ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> drv . add_constraint ( '<STR_LIT>' ) <EOL> self . asm . run ( ) <EOL> self . asm . replace ( '<STR_LIT>' , My2SDriver ( ) ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> """<STR_LIT>""" <EOL> import unittest <EOL> from openmdao . main . api import Component , Assembly <EOL> from openmdao . main . datatypes . api import Float , List , Array <EOL> from numpy import array , zeros <EOL> class MyDefComp ( Component ) : <EOL> f_in = Float ( <NUM_LIT> , iotype = '<STR_LIT>' ) <EOL> f_out = Float ( iotype = '<STR_LIT>' ) <EOL> arr_in = Array ( [ <NUM_LIT:1.> , <NUM_LIT> , <NUM_LIT> ] , iotype = '<STR_LIT>' ) <EOL> list_in = List ( value = [ '<STR_LIT:a>' , '<STR_LIT:b>' , '<STR_LIT:c>' ] , iotype = '<STR_LIT>' ) <EOL> def execute ( self ) : <EOL> self . f_out = self . f_in + <NUM_LIT:1.> <EOL> class MyNoDefComp ( Component ) : <EOL> f_in = Float ( iotype = '<STR_LIT>' ) <EOL> f_out = Float ( iotype = '<STR_LIT>' ) <EOL> arr_in = Array ( iotype = '<STR_LIT>' ) <EOL> list_in = List ( iotype = '<STR_LIT>' ) <EOL> def execute ( self ) : <EOL> self . f_out = self . f_in + <NUM_LIT:1.> <EOL> class SetDefaultsTestCase ( unittest . TestCase ) : <EOL> def test_set_to_unset_default ( self ) : <EOL> comp = MyNoDefComp ( ) <EOL> self . assertEqual ( <NUM_LIT:0.> , comp . f_in ) <EOL> comp . f_in = <NUM_LIT> <EOL> comp . arr_in = array ( [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> comp . list_in = [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ] <EOL> comp . run ( ) <EOL> comp . revert_to_defaults ( ) <EOL> self . assertEqual ( <NUM_LIT:0.> , comp . f_in ) <EOL> self . assertTrue ( all ( zeros ( <NUM_LIT:0> , '<STR_LIT:d>' ) == comp . arr_in ) ) <EOL> self . assertEqual ( [ ] , comp . list_in ) <EOL> def test_set_to_default ( self ) : <EOL> comp = MyDefComp ( ) <EOL> self . assertEqual ( <NUM_LIT> , comp . f_in ) <EOL> comp . f_in = <NUM_LIT> <EOL> comp . arr_in = array ( [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> self . assertFalse ( array ( [ <NUM_LIT:1.> , <NUM_LIT> , <NUM_LIT> ] ) == comp . arr_in ) <EOL> comp . run ( ) <EOL> comp . revert_to_defaults ( ) <EOL> self . assertEqual ( <NUM_LIT> , comp . f_in ) <EOL> self . assertTrue ( all ( array ( [ <NUM_LIT:1.> , <NUM_LIT> , <NUM_LIT> ] ) == comp . arr_in ) ) <EOL> def test_set_recursive ( self ) : <EOL> asm = Assembly ( ) <EOL> asm . add ( '<STR_LIT>' , MyDefComp ( ) ) <EOL> asm . add ( '<STR_LIT>' , MyNoDefComp ( ) ) <EOL> self . assertEqual ( <NUM_LIT:0.> , asm . nodefcomp . f_in ) <EOL> self . assertEqual ( <NUM_LIT> , asm . defcomp . f_in ) <EOL> asm . nodefcomp . f_in = <NUM_LIT> <EOL> asm . defcomp . f_in = <NUM_LIT> <EOL> asm . revert_to_defaults ( ) <EOL> self . assertEqual ( <NUM_LIT:0.> , asm . nodefcomp . f_in ) <EOL> self . assertEqual ( <NUM_LIT> , asm . defcomp . f_in ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> unittest . main ( ) </s>
<s> """<STR_LIT>""" <EOL> from setuptools import setup <EOL> __author__ = '<STR_LIT>' <EOL> setup ( <EOL> name = '<STR_LIT:foo>' , <EOL> version = '<STR_LIT>' , <EOL> description = __doc__ , <EOL> author = __author__ , <EOL> packages = [ ] , <EOL> py_modules = [ '<STR_LIT:foo>' ] , <EOL> entry_points = """<STR_LIT>""" <EOL> ) </s>
<s> """<STR_LIT>""" <EOL> import re <EOL> from pyparsing import CaselessLiteral , Combine , OneOrMore , Optional , TokenConverter , Word , nums , oneOf , printables , ParserElement , alphanums <EOL> from numpy import append , array , zeros <EOL> def _getformat ( val ) : <EOL> if int ( val ) == val : <EOL> return "<STR_LIT>" <EOL> else : <EOL> return "<STR_LIT>" <EOL> class _SubHelper ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self ) : <EOL> self . newtext = "<STR_LIT>" <EOL> self . replace_location = <NUM_LIT:0> <EOL> self . current_location = <NUM_LIT:0> <EOL> self . counter = <NUM_LIT:0> <EOL> self . start_location = <NUM_LIT:0> <EOL> self . end_location = <NUM_LIT:0> <EOL> def set ( self , newtext , location ) : <EOL> """<STR_LIT>""" <EOL> self . newtext = newtext <EOL> self . replace_location = location <EOL> self . current_location = <NUM_LIT:0> <EOL> def set_array ( self , newtext , start_location , end_location ) : <EOL> """<STR_LIT>""" <EOL> self . newtext = newtext <EOL> self . start_location = start_location <EOL> self . end_location = end_location <EOL> self . current_location = <NUM_LIT:0> <EOL> def replace ( self , text ) : <EOL> """<STR_LIT>""" <EOL> self . current_location += <NUM_LIT:1> <EOL> if self . current_location == self . replace_location : <EOL> if isinstance ( self . newtext , float ) : <EOL> return _getformat ( self . newtext ) % self . newtext <EOL> else : <EOL> return str ( self . newtext ) <EOL> else : <EOL> return text . group ( ) <EOL> def replace_array ( self , text ) : <EOL> """<STR_LIT>""" <EOL> self . current_location += <NUM_LIT:1> <EOL> end = len ( self . newtext ) <EOL> if self . current_location >= self . start_location and self . current_location <= self . end_location and self . counter < end : <EOL> if isinstance ( self . newtext [ self . counter ] , float ) : <EOL> val = self . newtext [ self . counter ] <EOL> newval = _getformat ( val ) % val <EOL> else : <EOL> newval = str ( self . newtext [ self . counter ] ) <EOL> self . counter += <NUM_LIT:1> <EOL> return newval <EOL> else : <EOL> return text . group ( ) <EOL> class ToInteger ( TokenConverter ) : <EOL> """<STR_LIT>""" <EOL> def postParse ( self , instring , loc , tokenlist ) : <EOL> """<STR_LIT>""" <EOL> return int ( tokenlist [ <NUM_LIT:0> ] ) <EOL> class ToFloat ( TokenConverter ) : <EOL> """<STR_LIT>""" <EOL> def postParse ( self , instring , loc , tokenlist ) : <EOL> """<STR_LIT>""" <EOL> return float ( tokenlist [ <NUM_LIT:0> ] . replace ( '<STR_LIT:D>' , '<STR_LIT:E>' ) ) <EOL> class ToNan ( TokenConverter ) : <EOL> """<STR_LIT>""" <EOL> def postParse ( self , instring , loc , tokenlist ) : <EOL> """<STR_LIT>""" <EOL> return float ( '<STR_LIT>' ) <EOL> class ToInf ( TokenConverter ) : <EOL> """<STR_LIT>""" <EOL> def postParse ( self , instring , loc , tokenlist ) : <EOL> """<STR_LIT>""" <EOL> return float ( '<STR_LIT>' ) <EOL> class InputFileGenerator ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self ) : <EOL> self . template_filename = [ ] <EOL> self . output_filename = [ ] <EOL> self . delimiter = "<STR_LIT:U+0020>" <EOL> self . reg = re . compile ( '<STR_LIT>' ) <EOL> self . data = [ ] <EOL> self . current_row = <NUM_LIT:0> <EOL> self . anchored = False <EOL> def set_template_file ( self , filename ) : <EOL> """<STR_LIT>""" <EOL> self . template_filename = filename <EOL> templatefile = open ( filename , '<STR_LIT:r>' ) <EOL> self . data = templatefile . readlines ( ) <EOL> templatefile . close ( ) <EOL> def set_generated_file ( self , filename ) : <EOL> """<STR_LIT>""" <EOL> self . output_filename = filename <EOL> def set_delimiters ( self , delimiter ) : <EOL> """<STR_LIT>""" <EOL> self . delimiter = delimiter <EOL> self . reg = re . compile ( '<STR_LIT>' + delimiter + '<STR_LIT>' ) <EOL> def mark_anchor ( self , anchor , occurrence = <NUM_LIT:1> ) : <EOL> """<STR_LIT>""" <EOL> if not isinstance ( occurrence , int ) : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> instance = <NUM_LIT:0> <EOL> if occurrence > <NUM_LIT:0> : <EOL> count = <NUM_LIT:0> <EOL> max_lines = len ( self . data ) <EOL> for index in xrange ( self . current_row , max_lines ) : <EOL> line = self . data [ index ] <EOL> if count == <NUM_LIT:0> and self . anchored : <EOL> line = line . split ( anchor ) [ - <NUM_LIT:1> ] <EOL> if line . find ( anchor ) > - <NUM_LIT:1> : <EOL> instance += <NUM_LIT:1> <EOL> if instance == occurrence : <EOL> self . current_row += count <EOL> self . anchored = True <EOL> return <EOL> count += <NUM_LIT:1> <EOL> elif occurrence < <NUM_LIT:0> : <EOL> max_lines = len ( self . data ) - <NUM_LIT:1> <EOL> count = max_lines <EOL> for index in xrange ( max_lines , - <NUM_LIT:1> , - <NUM_LIT:1> ) : <EOL> line = self . data [ index ] <EOL> if count == max_lines and self . anchored : <EOL> line = line . split ( anchor ) [ <NUM_LIT:0> ] <EOL> if line . find ( anchor ) > - <NUM_LIT:1> : <EOL> instance += - <NUM_LIT:1> <EOL> if instance == occurrence : <EOL> self . current_row = count <EOL> self . anchored = True <EOL> return <EOL> count -= <NUM_LIT:1> <EOL> else : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> raise RuntimeError ( "<STR_LIT>" % ( anchor , self . template_filename ) ) <EOL> def reset_anchor ( self ) : <EOL> """<STR_LIT>""" <EOL> self . current_row = <NUM_LIT:0> <EOL> self . anchored = False <EOL> def transfer_var ( self , value , row , field ) : <EOL> """<STR_LIT>""" <EOL> j = self . current_row + row <EOL> line = self . data [ j ] <EOL> sub = _SubHelper ( ) <EOL> sub . set ( value , field ) <EOL> newline = re . sub ( self . reg , sub . replace , line ) <EOL> self . data [ j ] = newline <EOL> def transfer_array ( self , value , row_start , field_start , field_end , <EOL> row_end = None , sep = "<STR_LIT:U+002CU+0020>" ) : <EOL> """<STR_LIT>""" <EOL> if row_end == None : <EOL> row_end = row_start <EOL> sub = _SubHelper ( ) <EOL> for row in range ( row_start , row_end + <NUM_LIT:1> ) : <EOL> j = self . current_row + row <EOL> line = self . data [ j ] <EOL> if row == row_end : <EOL> f_end = field_end <EOL> else : <EOL> f_end = <NUM_LIT> <EOL> sub . set_array ( value , field_start , f_end ) <EOL> field_start = <NUM_LIT:0> <EOL> newline = re . sub ( self . reg , sub . replace_array , line ) <EOL> self . data [ j ] = newline <EOL> if sub . counter < len ( value ) : <EOL> for val in value [ sub . counter : ] : <EOL> newline = newline . rstrip ( ) + sep + str ( val ) <EOL> self . data [ j ] = newline <EOL> elif sub . counter > len ( value ) : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> self . data [ j ] += "<STR_LIT:\n>" <EOL> def transfer_2Darray ( self , value , row_start , row_end , field_start , <EOL> field_end , sep = "<STR_LIT:U+002CU+0020>" ) : <EOL> """<STR_LIT>""" <EOL> sub = _SubHelper ( ) <EOL> i = <NUM_LIT:0> <EOL> for row in range ( row_start , row_end + <NUM_LIT:1> ) : <EOL> j = self . current_row + row <EOL> line = self . data [ j ] <EOL> sub . set_array ( value [ i , : ] , field_start , field_end ) <EOL> newline = re . sub ( self . reg , sub . replace_array , line ) <EOL> self . data [ j ] = newline <EOL> sub . current_location = <NUM_LIT:0> <EOL> sub . counter = <NUM_LIT:0> <EOL> i += <NUM_LIT:1> <EOL> def clearline ( self , row ) : <EOL> """<STR_LIT>""" <EOL> self . data [ self . current_row + row ] = "<STR_LIT:\n>" <EOL> def generate ( self ) : <EOL> """<STR_LIT>""" <EOL> infile = open ( self . output_filename , '<STR_LIT:w>' ) <EOL> infile . writelines ( self . data ) <EOL> infile . close ( ) <EOL> class FileParser ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , end_of_line_comment_char = None , full_line_comment_char = None ) : <EOL> self . filename = [ ] <EOL> self . data = [ ] <EOL> self . delimiter = "<STR_LIT>" <EOL> self . end_of_line_comment_char = end_of_line_comment_char <EOL> self . full_line_comment_char = full_line_comment_char <EOL> self . current_row = <NUM_LIT:0> <EOL> self . anchored = False <EOL> self . set_delimiters ( self . delimiter ) <EOL> def set_file ( self , filename ) : <EOL> """<STR_LIT>""" <EOL> self . filename = filename <EOL> inputfile = open ( filename , '<STR_LIT:r>' ) <EOL> if not self . end_of_line_comment_char and not self . full_line_comment_char : <EOL> self . data = inputfile . readlines ( ) <EOL> else : <EOL> self . data = [ ] <EOL> for line in inputfile : <EOL> if line [ <NUM_LIT:0> ] == self . full_line_comment_char : <EOL> continue <EOL> self . data . append ( line . split ( self . end_of_line_comment_char ) [ <NUM_LIT:0> ] ) <EOL> inputfile . close ( ) <EOL> def set_delimiters ( self , delimiter ) : <EOL> """<STR_LIT>""" <EOL> self . delimiter = delimiter <EOL> if delimiter != "<STR_LIT>" : <EOL> ParserElement . setDefaultWhitespaceChars ( str ( delimiter ) ) <EOL> self . _reset_tokens ( ) <EOL> def mark_anchor ( self , anchor , occurrence = <NUM_LIT:1> ) : <EOL> """<STR_LIT>""" <EOL> if not isinstance ( occurrence , int ) : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> instance = <NUM_LIT:0> <EOL> if occurrence > <NUM_LIT:0> : <EOL> count = <NUM_LIT:0> <EOL> max_lines = len ( self . data ) <EOL> for index in xrange ( self . current_row , max_lines ) : <EOL> line = self . data [ index ] <EOL> if count == <NUM_LIT:0> and self . anchored : <EOL> line = line . split ( anchor ) [ - <NUM_LIT:1> ] <EOL> if anchor in line : <EOL> instance += <NUM_LIT:1> <EOL> if instance == occurrence : <EOL> self . current_row += count <EOL> self . anchored = True <EOL> return <EOL> count += <NUM_LIT:1> <EOL> elif occurrence < <NUM_LIT:0> : <EOL> max_lines = len ( self . data ) - <NUM_LIT:1> <EOL> count = max_lines <EOL> for index in xrange ( max_lines , - <NUM_LIT:1> , - <NUM_LIT:1> ) : <EOL> line = self . data [ index ] <EOL> if count == max_lines and self . anchored : <EOL> line = line . split ( anchor ) [ <NUM_LIT:0> ] <EOL> if anchor in line : <EOL> instance += - <NUM_LIT:1> <EOL> if instance == occurrence : <EOL> self . current_row = count <EOL> self . anchored = True <EOL> return <EOL> count -= <NUM_LIT:1> <EOL> else : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> raise RuntimeError ( "<STR_LIT>" % ( anchor , self . filename ) ) <EOL> def reset_anchor ( self ) : <EOL> """<STR_LIT>""" <EOL> self . current_row = <NUM_LIT:0> <EOL> self . anchored = False <EOL> def transfer_line ( self , row ) : <EOL> """<STR_LIT>""" <EOL> return self . data [ self . current_row + row ] . rstrip ( ) <EOL> def transfer_var ( self , row , field , fieldend = None ) : <EOL> """<STR_LIT>""" <EOL> j = self . current_row + row <EOL> line = self . data [ j ] <EOL> if self . delimiter == "<STR_LIT>" : <EOL> if not fieldend : <EOL> line = line [ ( field - <NUM_LIT:1> ) : ] <EOL> else : <EOL> line = line [ ( field - <NUM_LIT:1> ) : ( fieldend ) ] <EOL> data = self . _parse_line ( ) . parseString ( line ) <EOL> if len ( data ) > <NUM_LIT:1> : <EOL> return line <EOL> else : <EOL> return data [ <NUM_LIT:0> ] <EOL> else : <EOL> data = self . _parse_line ( ) . parseString ( line ) <EOL> return data [ field - <NUM_LIT:1> ] <EOL> def transfer_keyvar ( self , key , field , occurrence = <NUM_LIT:1> , rowoffset = <NUM_LIT:0> ) : <EOL> """<STR_LIT>""" <EOL> if not isinstance ( occurrence , int ) or occurrence == <NUM_LIT:0> : <EOL> msg = "<STR_LIT>" <EOL> raise ValueError ( msg ) <EOL> instance = <NUM_LIT:0> <EOL> if occurrence > <NUM_LIT:0> : <EOL> row = <NUM_LIT:0> <EOL> for line in self . data [ self . current_row : ] : <EOL> if line . find ( key ) > - <NUM_LIT:1> : <EOL> instance += <NUM_LIT:1> <EOL> if instance == occurrence : <EOL> break <EOL> row += <NUM_LIT:1> <EOL> elif occurrence < <NUM_LIT:0> : <EOL> row = - <NUM_LIT:1> <EOL> for line in reversed ( self . data [ self . current_row : ] ) : <EOL> if line . find ( key ) > - <NUM_LIT:1> : <EOL> instance += - <NUM_LIT:1> <EOL> if instance == occurrence : <EOL> break <EOL> row -= <NUM_LIT:1> <EOL> j = self . current_row + row + rowoffset <EOL> line = self . data [ j ] <EOL> fields = self . _parse_line ( ) . parseString ( line . replace ( key , "<STR_LIT>" ) ) <EOL> return fields [ field ] <EOL> def transfer_array ( self , rowstart , fieldstart , rowend = None , fieldend = None ) : <EOL> """<STR_LIT>""" <EOL> j1 = self . current_row + rowstart <EOL> if rowend is None : <EOL> j2 = j1 + <NUM_LIT:1> <EOL> else : <EOL> j2 = self . current_row + rowend + <NUM_LIT:1> <EOL> if not fieldend : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> lines = self . data [ j1 : j2 ] <EOL> data = zeros ( shape = ( <NUM_LIT:0> , <NUM_LIT:0> ) ) <EOL> for i , line in enumerate ( lines ) : <EOL> if self . delimiter == "<STR_LIT>" : <EOL> line = line [ ( fieldstart - <NUM_LIT:1> ) : fieldend ] <EOL> line = line . strip ( ) <EOL> parsed = self . _parse_line ( ) . parseString ( line ) <EOL> newdata = array ( parsed [ : ] ) <EOL> if '<STR_LIT>' in str ( newdata . dtype ) : <EOL> newdata = array ( line ) <EOL> data = append ( data , newdata ) <EOL> else : <EOL> parsed = self . _parse_line ( ) . parseString ( line ) <EOL> if i == j2 - j1 - <NUM_LIT:1> : <EOL> data = append ( data , array ( parsed [ ( fieldstart - <NUM_LIT:1> ) : fieldend ] ) ) <EOL> else : <EOL> data = append ( data , array ( parsed [ ( fieldstart - <NUM_LIT:1> ) : ] ) ) <EOL> fieldstart = <NUM_LIT:1> <EOL> return data <EOL> def transfer_2Darray ( self , rowstart , fieldstart , rowend , fieldend = None ) : <EOL> """<STR_LIT>""" <EOL> if fieldend and ( fieldstart > fieldend ) : <EOL> msg = "<STR_LIT>" <EOL> raise ValueError ( msg ) <EOL> if rowstart > rowend : <EOL> msg = "<STR_LIT>" <EOL> raise ValueError ( msg ) <EOL> j1 = self . current_row + rowstart <EOL> j2 = self . current_row + rowend + <NUM_LIT:1> <EOL> lines = list ( self . data [ j1 : j2 ] ) <EOL> if self . delimiter == "<STR_LIT>" : <EOL> if fieldend : <EOL> line = lines [ <NUM_LIT:0> ] [ ( fieldstart - <NUM_LIT:1> ) : fieldend ] <EOL> else : <EOL> line = lines [ <NUM_LIT:0> ] [ ( fieldstart - <NUM_LIT:1> ) : ] <EOL> parsed = self . _parse_line ( ) . parseString ( line ) <EOL> row = array ( parsed [ : ] ) <EOL> data = zeros ( shape = ( abs ( j2 - j1 ) , len ( row ) ) ) <EOL> data [ <NUM_LIT:0> , : ] = row <EOL> for i , line in enumerate ( list ( lines [ <NUM_LIT:1> : ] ) ) : <EOL> if fieldend : <EOL> line = line [ ( fieldstart - <NUM_LIT:1> ) : fieldend ] <EOL> else : <EOL> line = line [ ( fieldstart - <NUM_LIT:1> ) : ] <EOL> parsed = self . _parse_line ( ) . parseString ( line ) <EOL> data [ i + <NUM_LIT:1> , : ] = array ( parsed [ : ] ) <EOL> else : <EOL> parsed = self . _parse_line ( ) . parseString ( lines [ <NUM_LIT:0> ] ) <EOL> if fieldend : <EOL> row = array ( parsed [ ( fieldstart - <NUM_LIT:1> ) : fieldend ] ) <EOL> else : <EOL> row = array ( parsed [ ( fieldstart - <NUM_LIT:1> ) : ] ) <EOL> data = zeros ( shape = ( abs ( j2 - j1 ) , len ( row ) ) ) <EOL> data [ <NUM_LIT:0> , : ] = row <EOL> for i , line in enumerate ( list ( lines [ <NUM_LIT:1> : ] ) ) : <EOL> parsed = self . _parse_line ( ) . parseString ( line ) <EOL> if fieldend : <EOL> try : <EOL> data [ i + <NUM_LIT:1> , : ] = array ( parsed [ ( fieldstart - <NUM_LIT:1> ) : fieldend ] ) <EOL> except : <EOL> print data <EOL> else : <EOL> data [ i + <NUM_LIT:1> , : ] = array ( parsed [ ( fieldstart - <NUM_LIT:1> ) : ] ) <EOL> return data <EOL> def _parse_line ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . line_parse_token <EOL> def _reset_tokens ( self ) : <EOL> '''<STR_LIT>''' <EOL> if self . delimiter . isspace ( ) : <EOL> textchars = printables <EOL> else : <EOL> textchars = alphanums <EOL> symbols = [ '<STR_LIT:.>' , '<STR_LIT:/>' , '<STR_LIT:+>' , '<STR_LIT:*>' , '<STR_LIT>' , '<STR_LIT:(>' , '<STR_LIT:)>' , '<STR_LIT:[>' , '<STR_LIT:]>' , '<STR_LIT:=>' , <EOL> '<STR_LIT::>' , '<STR_LIT:;>' , '<STR_LIT:?>' , '<STR_LIT:%>' , '<STR_LIT:&>' , '<STR_LIT:!>' , '<STR_LIT:#>' , '<STR_LIT:|>' , '<STR_LIT:<>' , '<STR_LIT:>>' , <EOL> '<STR_LIT:{>' , '<STR_LIT:}>' , '<STR_LIT:->' , '<STR_LIT:_>' , '<STR_LIT:@>' , '<STR_LIT:$>' , '<STR_LIT>' ] <EOL> for symbol in symbols : <EOL> if symbol not in self . delimiter : <EOL> textchars = textchars + symbol <EOL> digits = Word ( nums ) <EOL> dot = "<STR_LIT:.>" <EOL> sign = oneOf ( "<STR_LIT>" ) <EOL> ee = CaselessLiteral ( '<STR_LIT:E>' ) | CaselessLiteral ( '<STR_LIT:D>' ) <EOL> num_int = ToInteger ( Combine ( Optional ( sign ) + digits ) ) <EOL> num_float = ToFloat ( Combine ( Optional ( sign ) + <EOL> ( ( digits + dot + Optional ( digits ) ) | <EOL> ( dot + digits ) ) + <EOL> Optional ( ee + Optional ( sign ) + digits ) <EOL> ) ) <EOL> mixed_exp = ToFloat ( Combine ( digits + ee + Optional ( sign ) + digits ) ) <EOL> nan = ToInf ( oneOf ( "<STR_LIT>" ) ) | ToNan ( oneOf ( "<STR_LIT>" + "<STR_LIT>" ) ) <EOL> string_text = Word ( textchars ) <EOL> self . line_parse_token = ( OneOrMore ( ( nan | num_float | mixed_exp | num_int | <EOL> string_text ) ) ) </s>
<s> from __future__ import print_function <EOL> from openmdao . api import Component , Group , Problem , Newton , ScipyGMRES <EOL> class Line ( Component ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self ) : <EOL> super ( Line , self ) . __init__ ( ) <EOL> self . add_param ( '<STR_LIT:x>' , <NUM_LIT:1.0> ) <EOL> self . add_output ( '<STR_LIT:y>' , <NUM_LIT:0.0> ) <EOL> self . slope = - <NUM_LIT> <EOL> self . intercept = <NUM_LIT> <EOL> def solve_nonlinear ( self , params , unknowns , resids ) : <EOL> """<STR_LIT>""" <EOL> x = params [ '<STR_LIT:x>' ] <EOL> m = self . slope <EOL> b = self . intercept <EOL> unknowns [ '<STR_LIT:y>' ] = m * x + b <EOL> def linearize ( self , params , unknowns , resids ) : <EOL> """<STR_LIT>""" <EOL> m = self . slope <EOL> J = { } <EOL> J [ '<STR_LIT:y>' , '<STR_LIT:x>' ] = m <EOL> return J <EOL> class Parabola ( Component ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self ) : <EOL> super ( Parabola , self ) . __init__ ( ) <EOL> self . add_param ( '<STR_LIT:x>' , <NUM_LIT:1.0> ) <EOL> self . add_output ( '<STR_LIT:y>' , <NUM_LIT:0.0> ) <EOL> self . a = <NUM_LIT> <EOL> self . b = <NUM_LIT:0.0> <EOL> self . c = - <NUM_LIT> <EOL> def solve_nonlinear ( self , params , unknowns , resids ) : <EOL> """<STR_LIT>""" <EOL> x = params [ '<STR_LIT:x>' ] <EOL> a = self . a <EOL> b = self . b <EOL> c = self . c <EOL> unknowns [ '<STR_LIT:y>' ] = a * x ** <NUM_LIT:2> + b * x + c <EOL> def linearize ( self , params , unknowns , resids ) : <EOL> """<STR_LIT>""" <EOL> x = params [ '<STR_LIT:x>' ] <EOL> a = self . a <EOL> b = self . b <EOL> J = { } <EOL> J [ '<STR_LIT:y>' , '<STR_LIT:x>' ] = <NUM_LIT> * a * x + b <EOL> return J <EOL> class Balance ( Component ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self ) : <EOL> super ( Balance , self ) . __init__ ( ) <EOL> self . add_param ( '<STR_LIT>' , <NUM_LIT:0.0> ) <EOL> self . add_param ( '<STR_LIT>' , <NUM_LIT:0.0> ) <EOL> self . add_state ( '<STR_LIT:x>' , <NUM_LIT> ) <EOL> def solve_nonlinear ( self , params , unknowns , resids ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> def apply_nonlinear ( self , params , unknowns , resids ) : <EOL> """<STR_LIT>""" <EOL> y1 = params [ '<STR_LIT>' ] <EOL> y2 = params [ '<STR_LIT>' ] <EOL> resids [ '<STR_LIT:x>' ] = y1 - y2 <EOL> def linearize ( self , params , unknowns , resids ) : <EOL> """<STR_LIT>""" <EOL> J = { } <EOL> J [ '<STR_LIT:x>' , '<STR_LIT>' ] = <NUM_LIT:1.0> <EOL> J [ '<STR_LIT:x>' , '<STR_LIT>' ] = - <NUM_LIT:1.0> <EOL> return J <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> top = Problem ( ) <EOL> root = top . root = Group ( ) <EOL> root . add ( '<STR_LIT>' , Line ( ) ) <EOL> root . add ( '<STR_LIT>' , Parabola ( ) ) <EOL> root . add ( '<STR_LIT>' , Balance ( ) ) <EOL> root . connect ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> root . connect ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> root . connect ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> root . connect ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> root . nl_solver = Newton ( ) <EOL> root . ln_solver = ScipyGMRES ( ) <EOL> top . setup ( ) <EOL> top [ '<STR_LIT>' ] = <NUM_LIT> <EOL> root . list_states ( ) <EOL> top . run ( ) <EOL> print ( '<STR_LIT>' % ( top [ '<STR_LIT>' ] , top [ '<STR_LIT>' ] , top [ '<STR_LIT>' ] ) ) <EOL> top [ '<STR_LIT>' ] = - <NUM_LIT> <EOL> root . list_states ( ) <EOL> top . run ( ) <EOL> print ( '<STR_LIT>' % ( top [ '<STR_LIT>' ] , top [ '<STR_LIT>' ] , top [ '<STR_LIT>' ] ) ) </s>
<s> """<STR_LIT>""" <EOL> import warnings <EOL> from openmdao . components . exec_comp import ExecComp <EOL> class ConstraintComp ( ExecComp ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , expr , out = '<STR_LIT>' ) : <EOL> warnings . simplefilter ( '<STR_LIT>' , DeprecationWarning ) <EOL> warnings . warn ( "<STR_LIT>" , <EOL> DeprecationWarning , stacklevel = <NUM_LIT:2> ) <EOL> warnings . simplefilter ( '<STR_LIT:ignore>' , DeprecationWarning ) <EOL> newexpr = _combined_expr ( expr ) <EOL> super ( ConstraintComp , self ) . __init__ ( "<STR_LIT>" % ( out , newexpr ) ) <EOL> def _combined_expr ( expr ) : <EOL> """<STR_LIT>""" <EOL> lhs , op , rhs = _parse_constraint ( expr ) <EOL> first , second = ( rhs , lhs ) if op . startswith ( '<STR_LIT:>>' ) else ( lhs , rhs ) <EOL> try : <EOL> if float ( first ) == <NUM_LIT:0> : <EOL> return "<STR_LIT>" % second <EOL> except Exception : <EOL> pass <EOL> try : <EOL> if float ( second ) == <NUM_LIT:0.> : <EOL> return first <EOL> except Exception : <EOL> pass <EOL> return '<STR_LIT>' % ( first , second ) <EOL> def _parse_constraint ( expr_string ) : <EOL> """<STR_LIT>""" <EOL> for comparator in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT:>>' , '<STR_LIT:<>' , '<STR_LIT:=>' ] : <EOL> parts = expr_string . split ( comparator ) <EOL> if len ( parts ) == <NUM_LIT:2> : <EOL> if comparator == '<STR_LIT>' : <EOL> break <EOL> return ( parts [ <NUM_LIT:0> ] . strip ( ) , comparator , parts [ <NUM_LIT:1> ] . strip ( ) ) <EOL> msg = "<STR_LIT>" <EOL> raise ValueError ( msg ) </s>
<s> """<STR_LIT>""" <EOL> from __future__ import print_function <EOL> import os <EOL> import sys <EOL> import json <EOL> import warnings <EOL> import traceback <EOL> from collections import OrderedDict <EOL> from itertools import chain <EOL> from six import iteritems , itervalues <EOL> from six . moves import cStringIO <EOL> import networkx as nx <EOL> import numpy as np <EOL> from openmdao . core . system import System <EOL> from openmdao . core . group import Group <EOL> from openmdao . core . component import Component <EOL> from openmdao . core . parallel_group import ParallelGroup <EOL> from openmdao . core . parallel_fd_group import ParallelFDGroup <EOL> from openmdao . core . basic_impl import BasicImpl <EOL> from openmdao . core . _checks import check_connections , _both_names <EOL> from openmdao . core . driver import Driver <EOL> from openmdao . core . mpi_wrap import MPI , under_mpirun , debug <EOL> from openmdao . core . relevance import Relevance <EOL> from openmdao . components . indep_var_comp import IndepVarComp <EOL> from openmdao . solvers . scipy_gmres import ScipyGMRES <EOL> from openmdao . solvers . ln_direct import DirectSolver <EOL> from openmdao . solvers . ln_gauss_seidel import LinearGaussSeidel <EOL> from openmdao . units . units import get_conversion_tuple <EOL> from openmdao . util . string_util import get_common_ancestor , nearest_child , name_relative_to <EOL> from openmdao . util . graph import plain_bfs <EOL> from openmdao . util . options import OptionsDictionary <EOL> force_check = os . environ . get ( '<STR_LIT>' ) <EOL> trace = os . environ . get ( '<STR_LIT>' ) <EOL> class _ProbData ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self ) : <EOL> self . top_lin_gs = False <EOL> self . in_complex_step = False <EOL> class Problem ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , root = None , driver = None , impl = None , comm = None ) : <EOL> super ( Problem , self ) . __init__ ( ) <EOL> self . root = root <EOL> self . _probdata = _ProbData ( ) <EOL> if MPI : <EOL> from openmdao . core . petsc_impl import PetscImpl <EOL> if impl != PetscImpl : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> if impl is None : <EOL> self . _impl = BasicImpl <EOL> else : <EOL> self . _impl = impl <EOL> self . comm = comm <EOL> if driver is None : <EOL> self . driver = Driver ( ) <EOL> else : <EOL> self . driver = driver <EOL> self . pathname = '<STR_LIT>' <EOL> def __getitem__ ( self , name ) : <EOL> """<STR_LIT>""" <EOL> if name in self . root . unknowns : <EOL> return self . root . unknowns [ name ] <EOL> elif name in self . root . params : <EOL> return self . root . params [ name ] <EOL> elif name in self . root . _sysdata . to_abs_pnames : <EOL> for p in self . root . _sysdata . to_abs_pnames [ name ] : <EOL> return self . _rec_get_param ( p ) <EOL> elif name in self . _dangling : <EOL> for p in self . _dangling [ name ] : <EOL> return self . _rec_get_param ( p ) <EOL> else : <EOL> raise KeyError ( "<STR_LIT>" % name ) <EOL> def _rec_get_param ( self , absname ) : <EOL> parts = absname . rsplit ( '<STR_LIT:.>' , <NUM_LIT:1> ) <EOL> if len ( parts ) == <NUM_LIT:1> : <EOL> return self . root . params [ absname ] <EOL> else : <EOL> grp = self . root . _subsystem ( parts [ <NUM_LIT:0> ] ) <EOL> return grp . params [ parts [ <NUM_LIT:1> ] ] <EOL> def __setitem__ ( self , name , val ) : <EOL> """<STR_LIT>""" <EOL> if name in self . root . unknowns : <EOL> self . root . unknowns [ name ] = val <EOL> elif name in self . _dangling : <EOL> for p in self . _dangling [ name ] : <EOL> parts = p . rsplit ( '<STR_LIT:.>' , <NUM_LIT:1> ) <EOL> if len ( parts ) == <NUM_LIT:1> : <EOL> self . root . params [ p ] = val <EOL> else : <EOL> grp = self . root . _subsystem ( parts [ <NUM_LIT:0> ] ) <EOL> grp . params [ parts [ <NUM_LIT:1> ] ] = val <EOL> else : <EOL> raise KeyError ( "<STR_LIT>" % name ) <EOL> def _setup_connections ( self , params_dict , unknowns_dict ) : <EOL> """<STR_LIT>""" <EOL> to_prom_name = self . _probdata . to_prom_name <EOL> connections = self . root . _get_explicit_connections ( ) <EOL> prom_noconns = self . _add_implicit_connections ( connections ) <EOL> input_graph = nx . DiGraph ( ) <EOL> self . _dangling = { } <EOL> to_abs_pnames = self . root . _sysdata . to_abs_pnames <EOL> usrcs = set ( ) <EOL> for tgt , srcs in iteritems ( connections ) : <EOL> for src , idxs in srcs : <EOL> input_graph . add_edge ( src , tgt , idxs = idxs ) <EOL> if src in unknowns_dict : <EOL> usrcs . add ( src ) <EOL> for prom , plist in iteritems ( to_abs_pnames ) : <EOL> input_graph . add_nodes_from ( plist ) <EOL> if prom in prom_noconns : <EOL> start = plist [ <NUM_LIT:0> ] <EOL> input_graph . add_edges_from ( ( ( start , p ) for p in plist [ <NUM_LIT:1> : ] ) , <EOL> idxs = None ) <EOL> newconns = { } <EOL> for src in usrcs : <EOL> newconns [ src ] = None <EOL> src_idxs = { src : None } <EOL> for s , t in nx . dfs_edges ( input_graph , src ) : <EOL> tidxs = input_graph [ s ] [ t ] [ '<STR_LIT>' ] <EOL> sidxs = src_idxs [ s ] <EOL> if tidxs is None : <EOL> tidxs = sidxs <EOL> elif sidxs is not None : <EOL> tidxs = np . array ( sidxs ) [ tidxs ] <EOL> src_idxs [ t ] = tidxs <EOL> if t in newconns : <EOL> newconns [ t ] . append ( ( src , tidxs ) ) <EOL> else : <EOL> newconns [ t ] = [ ( src , tidxs ) ] <EOL> self . _input_inputs = { } <EOL> for node in input_graph . nodes_iter ( ) : <EOL> if node not in newconns and len ( input_graph . pred [ node ] ) == <NUM_LIT:0> : <EOL> nosrc = [ node ] <EOL> for s , t in nx . dfs_edges ( input_graph , node ) : <EOL> if t in newconns : <EOL> src = newconns [ t ] [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] <EOL> for n in nosrc : <EOL> newconns [ n ] = [ ( src , None ) ] <EOL> break <EOL> else : <EOL> nosrc . append ( t ) <EOL> else : <EOL> set_nosrc = set ( nosrc ) <EOL> for n in nosrc : <EOL> self . _dangling [ to_prom_name [ n ] ] = set_nosrc <EOL> self . _input_inputs [ n ] = nosrc <EOL> connections = OrderedDict ( ) <EOL> for tgt , srcs in sorted ( newconns . items ( ) ) : <EOL> if srcs is not None : <EOL> if len ( srcs ) > <NUM_LIT:1> : <EOL> src_names = ( n for n , idx in srcs ) <EOL> self . _setup_errors . append ( "<STR_LIT>" <EOL> "<STR_LIT>" % <EOL> ( tgt , sorted ( src_names ) ) ) <EOL> connections [ tgt ] = srcs [ <NUM_LIT:0> ] <EOL> return connections <EOL> def _check_input_diffs ( self , connections , params_dict , unknowns_dict ) : <EOL> """<STR_LIT>""" <EOL> for tgt , connected_inputs in iteritems ( self . _input_inputs ) : <EOL> tgt_idx = connected_inputs . index ( tgt ) <EOL> units = [ params_dict [ n ] . get ( '<STR_LIT>' ) for n in connected_inputs ] <EOL> vals = [ params_dict [ n ] [ '<STR_LIT>' ] for n in connected_inputs ] <EOL> diff_units = [ ] <EOL> for i , u in enumerate ( units ) : <EOL> if i != tgt_idx and u != units [ tgt_idx ] : <EOL> if units [ tgt_idx ] is None : <EOL> sname , s = connected_inputs [ i ] , u <EOL> tname , t = connected_inputs [ tgt_idx ] , units [ tgt_idx ] <EOL> else : <EOL> sname , s = connected_inputs [ tgt_idx ] , units [ tgt_idx ] <EOL> tname , t = connected_inputs [ i ] , u <EOL> diff_units . append ( ( connected_inputs [ i ] , u ) ) <EOL> if isinstance ( vals [ tgt_idx ] , np . ndarray ) : <EOL> diff_vals = [ ( connected_inputs [ i ] , v ) for i , v in <EOL> enumerate ( vals ) if not <EOL> ( isinstance ( v , np . ndarray ) and <EOL> v . shape == vals [ tgt_idx ] . shape and <EOL> ( v == vals [ tgt_idx ] ) . all ( ) ) ] <EOL> else : <EOL> vtype = type ( vals [ tgt_idx ] ) <EOL> diff_vals = [ ( connected_inputs [ i ] , v ) for i , v in <EOL> enumerate ( vals ) if vtype != type ( v ) or <EOL> v != vals [ tgt_idx ] ] <EOL> if diff_units : <EOL> filt = set ( [ u for n , u in diff_units ] ) <EOL> if None in filt : <EOL> filt . remove ( None ) <EOL> if filt : <EOL> proms = set ( [ params_dict [ item ] [ '<STR_LIT>' ] for item in connected_inputs ] ) <EOL> if len ( proms ) == <NUM_LIT:1> : <EOL> msg = "<STR_LIT>" + "<STR_LIT>" % proms . pop ( ) <EOL> else : <EOL> msg = "<STR_LIT>" + "<STR_LIT>" <EOL> msg += "<STR_LIT>" % sorted ( [ ( tgt , params_dict [ tgt ] . get ( '<STR_LIT>' ) ) ] + diff_units ) <EOL> correct_src = params_dict [ connected_inputs [ <NUM_LIT:0> ] ] [ '<STR_LIT>' ] <EOL> msg += "<STR_LIT>" % correct_src + "<STR_LIT>" <EOL> self . _setup_errors . append ( msg ) <EOL> if diff_vals : <EOL> msg = ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" % <EOL> ( sorted ( [ ( tgt , params_dict [ tgt ] [ '<STR_LIT>' ] ) ] + <EOL> diff_vals ) ) ) <EOL> self . _setup_errors . append ( msg ) <EOL> for promname , absnames in iteritems ( self . root . _sysdata . to_abs_pnames ) : <EOL> if len ( absnames ) > <NUM_LIT:1> : <EOL> step_sizes , step_types , forms = { } , { } , { } <EOL> for name in absnames : <EOL> meta = self . root . _params_dict [ name ] <EOL> ss = meta . get ( '<STR_LIT>' ) <EOL> if ss is not None : <EOL> step_sizes [ ss ] = name <EOL> st = meta . get ( '<STR_LIT>' ) <EOL> if st is not None : <EOL> step_types [ st ] = name <EOL> f = meta . get ( '<STR_LIT>' ) <EOL> if f is not None : <EOL> forms [ f ] = name <EOL> if len ( step_sizes ) > <NUM_LIT:1> : <EOL> self . _setup_errors . append ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" % ( promname , <EOL> sorted ( [ ( v , k ) for k , v in step_sizes . items ( ) ] ) ) ) <EOL> if len ( step_types ) > <NUM_LIT:1> : <EOL> self . _setup_errors . append ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" % ( promname , <EOL> sorted ( [ ( v , k ) for k , v in step_types . items ( ) ] ) ) ) <EOL> if len ( forms ) > <NUM_LIT:1> : <EOL> self . _setup_errors . append ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" % ( promname , <EOL> sorted ( [ ( v , k ) for k , v in forms . items ( ) ] ) ) ) <EOL> def _get_ubc_vars ( self , connections ) : <EOL> """<STR_LIT>""" <EOL> full_order = { s . pathname : i for i , s in <EOL> enumerate ( self . root . subsystems ( recurse = True ) ) } <EOL> ubcs = [ ] <EOL> for tgt , srcs in iteritems ( connections ) : <EOL> tsys = tgt . rsplit ( '<STR_LIT:.>' , <NUM_LIT:1> ) [ <NUM_LIT:0> ] <EOL> ssys = srcs [ <NUM_LIT:0> ] . rsplit ( '<STR_LIT:.>' , <NUM_LIT:1> ) [ <NUM_LIT:0> ] <EOL> if full_order [ ssys ] > full_order [ tsys ] : <EOL> ubcs . append ( tgt ) <EOL> return ubcs <EOL> def setup ( self , check = True , out_stream = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> self . _setup_errors = [ ] <EOL> tree_changed = False <EOL> meta_changed = False <EOL> self . _probdata = _ProbData ( ) <EOL> if isinstance ( self . root . ln_solver , LinearGaussSeidel ) : <EOL> self . _probdata . top_lin_gs = True <EOL> self . driver . root = self . root <EOL> self . root . _init_sys_data ( self . pathname , self . _probdata ) <EOL> self . _setup_communicators ( ) <EOL> params_dict , unknowns_dict = self . root . _setup_variables ( ) <EOL> self . _probdata . params_dict = params_dict <EOL> self . _probdata . unknowns_dict = unknowns_dict <EOL> self . _probdata . to_prom_name = self . root . _sysdata . to_prom_name <EOL> connections = self . _setup_connections ( params_dict , unknowns_dict ) <EOL> self . _probdata . connections = connections <EOL> for tgt , ( src , idxs ) in iteritems ( connections ) : <EOL> tmeta = params_dict [ tgt ] <EOL> if '<STR_LIT>' not in tmeta or not tmeta [ '<STR_LIT>' ] : <EOL> if tmeta [ '<STR_LIT>' ] == ( ) : <EOL> smeta = unknowns_dict [ src ] <EOL> if idxs is not None : <EOL> size = len ( idxs ) <EOL> tmeta [ '<STR_LIT>' ] = ( size , ) <EOL> tmeta [ '<STR_LIT:size>' ] = size <EOL> tmeta [ '<STR_LIT>' ] = smeta [ '<STR_LIT>' ] [ np . array ( idxs ) ] <EOL> else : <EOL> tmeta [ '<STR_LIT>' ] = smeta [ '<STR_LIT>' ] <EOL> tmeta [ '<STR_LIT:size>' ] = smeta [ '<STR_LIT:size>' ] <EOL> tmeta [ '<STR_LIT>' ] = smeta [ '<STR_LIT>' ] <EOL> if idxs is not None : <EOL> if isinstance ( idxs , np . ndarray ) : <EOL> tmeta [ '<STR_LIT>' ] = idxs <EOL> else : <EOL> tmeta [ '<STR_LIT>' ] = np . array ( idxs , <EOL> dtype = self . _impl . idx_arr_type ) <EOL> if MPI : <EOL> for s in self . root . components ( recurse = True ) : <EOL> if hasattr ( s , '<STR_LIT>' ) or ( <EOL> hasattr ( s , '<STR_LIT>' ) and ( s . setup_distrib <EOL> is not Component . setup_distrib ) ) : <EOL> meta_changed = True <EOL> if tree_changed : <EOL> return self . setup ( check = check , out_stream = out_stream ) <EOL> elif meta_changed : <EOL> params_dict , unknowns_dict = self . root . _setup_variables ( compute_indices = True ) <EOL> self . _setup_errors . extend ( check_connections ( connections , params_dict , <EOL> unknowns_dict , <EOL> self . root . _sysdata . to_prom_name ) ) <EOL> self . _setup_units ( connections , params_dict , unknowns_dict ) <EOL> to_prom_name = self . root . _sysdata . to_prom_name <EOL> self . _probdata . to_prom_name = to_prom_name <EOL> for path , meta in iteritems ( params_dict ) : <EOL> meta [ '<STR_LIT>' ] = to_prom_name [ path ] <EOL> if path not in connections : <EOL> if '<STR_LIT>' not in meta or not meta [ '<STR_LIT>' ] : <EOL> if meta [ '<STR_LIT>' ] == ( ) : <EOL> self . _setup_errors . append ( "<STR_LIT>" <EOL> "<STR_LIT>" . format ( path ) ) <EOL> for path , meta in iteritems ( unknowns_dict ) : <EOL> meta [ '<STR_LIT>' ] = to_prom_name [ path ] <EOL> param_owners = _assign_parameters ( connections ) <EOL> pois = self . driver . desvars_of_interest ( ) <EOL> oois = self . driver . outputs_of_interest ( ) <EOL> self . _driver_vois = set ( ) <EOL> for tup in chain ( pois , oois ) : <EOL> self . _driver_vois . update ( tup ) <EOL> promoted_unknowns = self . root . _sysdata . to_abs_uname <EOL> parallel_p = False <EOL> for vnames in pois : <EOL> if len ( vnames ) > <NUM_LIT:1> : <EOL> parallel_p = True <EOL> for v in vnames : <EOL> if v not in promoted_unknowns : <EOL> raise NameError ( "<STR_LIT>" % v ) <EOL> parallel_u = False <EOL> for vnames in oois : <EOL> if len ( vnames ) > <NUM_LIT:1> : <EOL> parallel_u = True <EOL> for v in vnames : <EOL> if v not in promoted_unknowns : <EOL> raise NameError ( "<STR_LIT>" % v ) <EOL> mode = self . _check_for_parallel_derivs ( pois , oois , parallel_u , parallel_p ) <EOL> self . _probdata . relevance = Relevance ( self . root , params_dict , <EOL> unknowns_dict , connections , <EOL> pois , oois , mode ) <EOL> for s in self . root . subgroups ( recurse = True , include_self = True ) : <EOL> if not s . _order_set : <EOL> order = None <EOL> broken_edges = None <EOL> if self . comm . rank == <NUM_LIT:0> : <EOL> order , broken_edges = s . list_auto_order ( ) <EOL> if MPI : <EOL> if trace : <EOL> debug ( "<STR_LIT>" ) <EOL> order , broken_edges = self . comm . bcast ( ( order , broken_edges ) , root = <NUM_LIT:0> ) <EOL> if trace : <EOL> debug ( "<STR_LIT>" ) <EOL> s . set_order ( order ) <EOL> for edge in broken_edges : <EOL> cname = edge [ <NUM_LIT:1> ] <EOL> head_sys = self . root <EOL> for name in cname . split ( '<STR_LIT:.>' ) : <EOL> head_sys = getattr ( head_sys , name ) <EOL> head_sys . _run_apply = True <EOL> self . _check_input_diffs ( connections , params_dict , unknowns_dict ) <EOL> alloc_derivs = not self . root . fd_options [ '<STR_LIT>' ] <EOL> for sub in self . root . subgroups ( recurse = True , include_self = True ) : <EOL> alloc_derivs = alloc_derivs or sub . nl_solver . supports [ '<STR_LIT>' ] <EOL> self . root . _setup_vectors ( param_owners , impl = self . _impl , alloc_derivs = alloc_derivs ) <EOL> self . driver . _setup ( ) <EOL> self . _poi_indices , self . _qoi_indices = self . driver . _map_voi_indices ( ) <EOL> for sub in self . root . subgroups ( recurse = True , include_self = True ) : <EOL> sub . nl_solver . setup ( sub ) <EOL> sub . ln_solver . setup ( sub ) <EOL> self . _check_solvers ( ) <EOL> self . _start_recorders ( ) <EOL> if self . _setup_errors : <EOL> stream = cStringIO ( ) <EOL> stream . write ( "<STR_LIT>" ) <EOL> for err in self . _setup_errors : <EOL> stream . write ( "<STR_LIT>" % err ) <EOL> raise RuntimeError ( stream . getvalue ( ) ) <EOL> OptionsDictionary . locked = True <EOL> if check or force_check : <EOL> return self . check_setup ( out_stream ) <EOL> return { } <EOL> def cleanup ( self ) : <EOL> """<STR_LIT>""" <EOL> self . driver . cleanup ( ) <EOL> self . root . cleanup ( ) <EOL> def _check_solvers ( self ) : <EOL> """<STR_LIT>""" <EOL> iterated_states = set ( ) <EOL> group_states = [ ] <EOL> has_iter_solver = { } <EOL> for group in self . root . subgroups ( recurse = True , include_self = True ) : <EOL> try : <EOL> has_iter_solver [ group . pathname ] = ( group . ln_solver . options [ '<STR_LIT>' ] > <NUM_LIT:1> ) <EOL> except KeyError : <EOL> if isinstance ( group . ln_solver , DirectSolver ) : <EOL> has_iter_solver [ group . pathname ] = ( True ) <EOL> opt = group . fd_options <EOL> if opt [ '<STR_LIT>' ] == True and opt [ '<STR_LIT>' ] == '<STR_LIT>' : <EOL> if group . name != '<STR_LIT>' : <EOL> msg = "<STR_LIT>" <EOL> msg += "<STR_LIT>" <EOL> self . _setup_errors . append ( msg ) <EOL> for sub in self . root . subgroups ( recurse = True , include_self = True ) : <EOL> if hasattr ( sub . nl_solver , '<STR_LIT>' ) : <EOL> msg = "<STR_LIT>" <EOL> msg += "<STR_LIT>" <EOL> self . _setup_errors . append ( msg . format ( sub . name ) ) <EOL> parts = group . pathname . split ( '<STR_LIT:.>' ) <EOL> for i in range ( len ( parts ) ) : <EOL> if has_iter_solver [ '<STR_LIT:.>' . join ( parts [ : i ] ) ] : <EOL> is_iterated_somewhere = True <EOL> break <EOL> else : <EOL> is_iterated_somewhere = False <EOL> if is_iterated_somewhere : <EOL> continue <EOL> if isinstance ( group . ln_solver , LinearGaussSeidel ) and group . ln_solver . options [ '<STR_LIT>' ] == <NUM_LIT:1> : <EOL> graph = group . _get_sys_graph ( ) <EOL> strong = [ sorted ( s ) for s in nx . strongly_connected_components ( graph ) <EOL> if len ( s ) > <NUM_LIT:1> ] <EOL> if strong : <EOL> self . _setup_errors . append ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> % ( group . pathname , strong ) ) <EOL> states = [ n for n , m in iteritems ( group . _unknowns_dict ) if m . get ( '<STR_LIT:state>' ) ] <EOL> if states : <EOL> group_states . append ( ( group , states ) ) <EOL> if isinstance ( group . ln_solver , DirectSolver ) or group . ln_solver . options [ '<STR_LIT>' ] > <NUM_LIT:1> : <EOL> iterated_states . update ( states ) <EOL> else : <EOL> for s in states : <EOL> if s not in iterated_states : <EOL> cname = s . rsplit ( '<STR_LIT:.>' , <NUM_LIT:1> ) [ <NUM_LIT:0> ] <EOL> comp = self . root <EOL> for name in cname . split ( '<STR_LIT:.>' ) : <EOL> comp = getattr ( comp , name ) <EOL> if not _needs_iteration ( comp ) : <EOL> iterated_states . add ( s ) <EOL> for group , states in group_states : <EOL> uniterated_states = [ s for s in states if s not in iterated_states ] <EOL> if uniterated_states : <EOL> self . _setup_errors . append ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" % <EOL> ( group . pathname , uniterated_states ) ) <EOL> def _check_dangling_params ( self , out_stream = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> to_prom_name = self . root . _sysdata . to_prom_name <EOL> dangling_params = sorted ( set ( [ <EOL> to_prom_name [ p ] for p , m in iteritems ( self . root . _params_dict ) <EOL> if p not in self . root . connections <EOL> ] ) ) <EOL> if dangling_params : <EOL> print ( "<STR_LIT>" , <EOL> file = out_stream ) <EOL> for d in dangling_params : <EOL> print ( d , file = out_stream ) <EOL> return dangling_params <EOL> def _check_mode ( self , out_stream = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> if self . _calculated_mode != self . root . _probdata . relevance . mode : <EOL> print ( "<STR_LIT>" <EOL> "<STR_LIT>" % ( self . root . _probdata . relevance . mode , <EOL> self . _calculated_mode , <EOL> self . _p_length , <EOL> self . _u_length ) , <EOL> file = out_stream ) <EOL> return ( self . root . _probdata . relevance . mode , self . _calculated_mode ) <EOL> def _check_no_unknown_comps ( self , out_stream = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> nocomps = sorted ( [ c . pathname for c in self . root . components ( recurse = True , <EOL> local = True ) <EOL> if len ( c . unknowns ) == <NUM_LIT:0> ] ) <EOL> if nocomps : <EOL> print ( "<STR_LIT>" , file = out_stream ) <EOL> for n in nocomps : <EOL> print ( n , file = out_stream ) <EOL> return nocomps <EOL> def _check_no_recorders ( self , out_stream = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> recorders = [ ] <EOL> recorders . extend ( self . driver . recorders ) <EOL> for grp in self . root . subgroups ( recurse = True , local = True , <EOL> include_self = True ) : <EOL> recorders . extend ( grp . nl_solver . recorders ) <EOL> recorders . extend ( grp . ln_solver . recorders ) <EOL> if not recorders : <EOL> print ( "<STR_LIT>" , <EOL> file = out_stream ) <EOL> return recorders <EOL> def _check_no_connect_comps ( self , out_stream = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> conn_comps = set ( [ t . rsplit ( '<STR_LIT:.>' , <NUM_LIT:1> ) [ <NUM_LIT:0> ] <EOL> for t in self . root . connections ] ) <EOL> conn_comps . update ( [ s . rsplit ( '<STR_LIT:.>' , <NUM_LIT:1> ) [ <NUM_LIT:0> ] <EOL> for s , i in itervalues ( self . root . connections ) ] ) <EOL> noconn_comps = sorted ( [ c . pathname <EOL> for c in self . root . components ( recurse = True , local = True ) <EOL> if c . pathname not in conn_comps ] ) <EOL> if noconn_comps : <EOL> print ( "<STR_LIT>" , file = out_stream ) <EOL> for comp in noconn_comps : <EOL> print ( comp , file = out_stream ) <EOL> return noconn_comps <EOL> def _check_mpi ( self , out_stream = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> if under_mpirun ( ) : <EOL> parr = True <EOL> if self . comm . rank == <NUM_LIT:0> : <EOL> for grp in self . root . subgroups ( recurse = True , include_self = True ) : <EOL> if ( isinstance ( grp , ParallelGroup ) or <EOL> isinstance ( grp , ParallelFDGroup ) ) : <EOL> break <EOL> else : <EOL> parr = False <EOL> print ( "<STR_LIT>" , <EOL> file = out_stream ) <EOL> mincpu , maxcpu = self . root . get_req_procs ( ) <EOL> if maxcpu is not None and self . comm . size > maxcpu : <EOL> print ( "<STR_LIT>" % <EOL> ( self . comm . size , maxcpu ) ) <EOL> return ( self . comm . size , maxcpu , parr ) <EOL> else : <EOL> pargrps = [ ] <EOL> for grp in self . root . subgroups ( recurse = True , include_self = True ) : <EOL> if isinstance ( grp , ParallelGroup ) : <EOL> print ( "<STR_LIT>" % <EOL> grp . pathname , file = out_stream ) <EOL> pargrps . append ( grp . pathname ) <EOL> return sorted ( pargrps ) <EOL> def _check_graph ( self , out_stream = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> cycles = [ ] <EOL> ooo = [ ] <EOL> for grp in self . root . subgroups ( recurse = True , include_self = True ) : <EOL> graph = grp . _get_sys_graph ( ) <EOL> strong = [ s for s in nx . strongly_connected_components ( graph ) <EOL> if len ( s ) > <NUM_LIT:1> ] <EOL> if strong : <EOL> relstrong = [ ] <EOL> for slist in strong : <EOL> relstrong . append ( [ ] ) <EOL> for s in slist : <EOL> relstrong [ - <NUM_LIT:1> ] . append ( nearest_child ( grp . pathname , s ) ) <EOL> subs = [ s for s in grp . _subsystems ] <EOL> tups = sorted ( [ ( subs . index ( s ) , s ) for s in relstrong [ - <NUM_LIT:1> ] ] ) <EOL> relstrong [ - <NUM_LIT:1> ] = [ t [ <NUM_LIT:1> ] for t in tups ] <EOL> print ( "<STR_LIT>" % <EOL> ( grp . pathname , relstrong ) , file = out_stream ) <EOL> cycles . append ( relstrong ) <EOL> graph , _ = grp . _break_cycles ( grp . list_order ( ) , graph ) <EOL> visited = set ( ) <EOL> out_of_order = { } <EOL> for sub in itervalues ( grp . _subsystems ) : <EOL> visited . add ( sub . pathname ) <EOL> for u , v in nx . dfs_edges ( graph , sub . pathname ) : <EOL> if v in visited : <EOL> out_of_order . setdefault ( nearest_child ( grp . pathname , v ) , <EOL> set ( ) ) . add ( sub . pathname ) <EOL> if out_of_order : <EOL> for name in out_of_order : <EOL> out_of_order [ name ] = sorted ( [ <EOL> nearest_child ( grp . pathname , n ) for n in out_of_order [ name ] <EOL> ] ) <EOL> print ( "<STR_LIT>" % <EOL> grp . pathname , file = out_stream ) <EOL> for n , subs in iteritems ( out_of_order ) : <EOL> print ( "<STR_LIT>" % ( n , subs ) , file = out_stream ) <EOL> ooo . append ( ( grp . pathname , list ( iteritems ( out_of_order ) ) ) ) <EOL> print ( "<STR_LIT>" % grp . list_auto_order ( ) [ <NUM_LIT:0> ] , <EOL> file = out_stream ) <EOL> return ( cycles , sorted ( ooo ) ) <EOL> def _check_gmres_under_mpi ( self , out_stream = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> if under_mpirun ( ) : <EOL> has_parallel = False <EOL> for s in self . root . subgroups ( recurse = True , include_self = True ) : <EOL> if isinstance ( s , ParallelGroup ) : <EOL> has_parallel = True <EOL> break <EOL> if has_parallel and isinstance ( self . root . ln_solver , ScipyGMRES ) : <EOL> print ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" , file = out_stream ) <EOL> def _check_ubcs ( self , out_stream = sys . stdout ) : <EOL> ubcs = self . _get_ubc_vars ( self . root . connections ) <EOL> if ubcs : <EOL> print ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" % ubcs , file = out_stream ) <EOL> return ubcs <EOL> def _check_unmarked_pbos ( self , out_stream = sys . stdout ) : <EOL> pbos = [ ] <EOL> for comp in self . root . components ( recurse = True , include_self = True ) : <EOL> if comp . _pbo_warns : <EOL> pbos . append ( ( comp . pathname , comp . _pbo_warns ) ) <EOL> if pbos : <EOL> print ( "<STR_LIT>" <EOL> "<STR_LIT>" , file = out_stream ) <EOL> for cname , pbo_warns in sorted ( pbos , key = lambda x : x [ <NUM_LIT:0> ] ) : <EOL> for vname , val in pbo_warns : <EOL> print ( "<STR_LIT>" % ( '<STR_LIT:.>' . join ( ( cname , vname ) ) , <EOL> type ( val ) . __name__ ) , file = out_stream ) <EOL> return pbos <EOL> def _check_relevant_pbos ( self , out_stream = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> if self . driver . __class__ is Driver or self . driver . supports [ '<STR_LIT>' ] is False or self . root . fd_options [ '<STR_LIT>' ] : <EOL> return [ ] <EOL> vec = self . root . unknowns <EOL> pbos = [ var for var in vec if vec . metadata ( var ) . get ( '<STR_LIT>' ) ] <EOL> rels = set ( ) <EOL> for key , rel in iteritems ( self . _probdata . relevance . relevant ) : <EOL> rels . update ( rel ) <EOL> rel_pbos = rels . intersection ( pbos ) <EOL> if rel_pbos : <EOL> rel_conns = [ ] <EOL> for src in rel_pbos : <EOL> for tgt , src_tuple in iteritems ( self . root . connections ) : <EOL> if src_tuple [ <NUM_LIT:0> ] == src and tgt in rels : <EOL> rel_conns . append ( ( src , tgt ) ) <EOL> if rel_conns : <EOL> print ( "<STR_LIT>" , <EOL> file = out_stream ) <EOL> for src , tgt in rel_conns : <EOL> val = vec [ src ] <EOL> print ( "<STR_LIT>" % ( src , tgt , type ( val ) . __name__ ) , <EOL> file = out_stream ) <EOL> else : <EOL> print ( "<STR_LIT>" <EOL> "<STR_LIT>" , sorted ( rel_pbos ) ) <EOL> print ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" , <EOL> file = out_stream ) <EOL> return list ( rel_pbos ) <EOL> def check_setup ( self , out_stream = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> print ( "<STR_LIT>" , file = out_stream ) <EOL> print ( "<STR_LIT>" , file = out_stream ) <EOL> results = { } <EOL> results [ '<STR_LIT>' ] = self . _check_no_recorders ( out_stream ) <EOL> results [ '<STR_LIT>' ] = self . _check_mpi ( out_stream ) <EOL> results [ '<STR_LIT>' ] = self . _check_dangling_params ( out_stream ) <EOL> results [ '<STR_LIT>' ] = self . _check_mode ( out_stream ) <EOL> results [ '<STR_LIT>' ] = self . _check_no_unknown_comps ( out_stream ) <EOL> results [ '<STR_LIT>' ] = self . _check_no_connect_comps ( out_stream ) <EOL> results [ '<STR_LIT>' ] , results [ '<STR_LIT>' ] = self . _check_graph ( out_stream ) <EOL> results [ '<STR_LIT>' ] = self . _check_ubcs ( out_stream ) <EOL> results [ '<STR_LIT>' ] = self . _check_gmres_under_mpi ( out_stream ) <EOL> results [ '<STR_LIT>' ] = self . _check_unmarked_pbos ( out_stream ) <EOL> results [ '<STR_LIT>' ] = self . _check_relevant_pbos ( out_stream ) <EOL> for s in self . root . subsystems ( recurse = True , local = True , include_self = True ) : <EOL> stream = cStringIO ( ) <EOL> s . check_setup ( out_stream = stream ) <EOL> content = stream . getvalue ( ) <EOL> if content : <EOL> print ( "<STR_LIT>" % ( s . pathname , content ) , file = out_stream ) <EOL> results [ "<STR_LIT>" % s . pathname ] = content <EOL> print ( "<STR_LIT>" , file = out_stream ) <EOL> print ( "<STR_LIT>" , file = out_stream ) <EOL> return results <EOL> def pre_run_check ( self ) : <EOL> """<STR_LIT>""" <EOL> if not self . root . fd_options . locked : <EOL> msg = "<STR_LIT>" <EOL> raise RuntimeError ( msg ) <EOL> def run ( self ) : <EOL> """<STR_LIT>""" <EOL> self . pre_run_check ( ) <EOL> if self . root . is_active ( ) : <EOL> self . driver . run ( self ) <EOL> if MPI : <EOL> if trace : debug ( "<STR_LIT>" ) <EOL> self . root . comm . barrier ( ) <EOL> if trace : debug ( "<STR_LIT>" ) <EOL> def run_once ( self ) : <EOL> """<STR_LIT>""" <EOL> self . pre_run_check ( ) <EOL> root = self . root <EOL> driver = self . driver <EOL> if root . is_active ( ) : <EOL> driver . run_once ( self ) <EOL> with root . _dircontext : <EOL> root . apply_nonlinear ( root . params , root . unknowns , root . resids , <EOL> metadata = driver . metadata ) <EOL> if MPI : <EOL> if trace : debug ( "<STR_LIT>" ) <EOL> root . comm . barrier ( ) <EOL> if trace : debug ( "<STR_LIT>" ) <EOL> def _mode ( self , mode , indep_list , unknown_list ) : <EOL> """<STR_LIT>""" <EOL> self . _p_length = <NUM_LIT:0> <EOL> self . _u_length = <NUM_LIT:0> <EOL> uset = set ( ) <EOL> for unames in unknown_list : <EOL> if isinstance ( unames , tuple ) : <EOL> uset . update ( unames ) <EOL> else : <EOL> uset . add ( unames ) <EOL> pset = set ( ) <EOL> for pnames in indep_list : <EOL> if isinstance ( pnames , tuple ) : <EOL> pset . update ( pnames ) <EOL> else : <EOL> pset . add ( pnames ) <EOL> to_prom_name = self . root . _sysdata . to_prom_name <EOL> for path , meta in chain ( iteritems ( self . root . _unknowns_dict ) , <EOL> iteritems ( self . root . _params_dict ) ) : <EOL> prom_name = to_prom_name [ path ] <EOL> if prom_name in uset : <EOL> self . _u_length += meta [ '<STR_LIT:size>' ] <EOL> uset . remove ( prom_name ) <EOL> if prom_name in pset : <EOL> self . _p_length += meta [ '<STR_LIT:size>' ] <EOL> pset . remove ( prom_name ) <EOL> if uset : <EOL> raise RuntimeError ( "<STR_LIT>" % list ( uset ) ) <EOL> if pset : <EOL> raise RuntimeError ( "<STR_LIT>" % list ( pset ) ) <EOL> if self . _p_length > self . _u_length : <EOL> self . _calculated_mode = '<STR_LIT>' <EOL> else : <EOL> self . _calculated_mode = '<STR_LIT>' <EOL> if mode == '<STR_LIT>' : <EOL> mode = self . root . ln_solver . options [ '<STR_LIT>' ] <EOL> if mode == '<STR_LIT>' : <EOL> mode = self . _calculated_mode <EOL> return mode <EOL> def calc_gradient ( self , indep_list , unknown_list , mode = '<STR_LIT>' , <EOL> return_format = '<STR_LIT>' , dv_scale = None , cn_scale = None , <EOL> sparsity = None ) : <EOL> """<STR_LIT>""" <EOL> if mode not in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] : <EOL> msg = "<STR_LIT>" <EOL> raise ValueError ( msg ) <EOL> if return_format not in [ '<STR_LIT>' , '<STR_LIT>' ] : <EOL> msg = "<STR_LIT>" <EOL> raise ValueError ( msg ) <EOL> with self . root . _dircontext : <EOL> if mode == '<STR_LIT>' or self . root . fd_options [ '<STR_LIT>' ] : <EOL> return self . _calc_gradient_fd ( indep_list , unknown_list , <EOL> return_format , dv_scale = dv_scale , <EOL> cn_scale = cn_scale , sparsity = sparsity ) <EOL> else : <EOL> return self . _calc_gradient_ln_solver ( indep_list , unknown_list , <EOL> return_format , mode , <EOL> dv_scale = dv_scale , <EOL> cn_scale = cn_scale , <EOL> sparsity = sparsity ) <EOL> def _calc_gradient_fd ( self , indep_list , unknown_list , return_format , <EOL> dv_scale = None , cn_scale = None , sparsity = None ) : <EOL> """<STR_LIT>""" <EOL> root = self . root <EOL> unknowns = root . unknowns <EOL> params = root . params <EOL> to_prom_name = root . _sysdata . to_prom_name <EOL> to_abs_pnames = root . _sysdata . to_abs_pnames <EOL> to_abs_uname = root . _sysdata . to_abs_uname <EOL> if dv_scale is None : <EOL> dv_scale = { } <EOL> if cn_scale is None : <EOL> cn_scale = { } <EOL> abs_params = [ ] <EOL> fd_unknowns = [ var for var in unknown_list if var not in indep_list ] <EOL> pass_unknowns = [ var for var in unknown_list if var in indep_list ] <EOL> for name in indep_list : <EOL> if name in unknowns : <EOL> name = to_abs_uname [ name ] <EOL> for tgt , ( src , idxs ) in iteritems ( root . connections ) : <EOL> if name == src : <EOL> name = tgt <EOL> break <EOL> abs_params . append ( name ) <EOL> Jfd = root . fd_jacobian ( params , unknowns , root . resids , total_derivs = True , <EOL> fd_params = abs_params , fd_unknowns = fd_unknowns , <EOL> pass_unknowns = pass_unknowns , <EOL> poi_indices = self . _poi_indices , <EOL> qoi_indices = self . _qoi_indices ) <EOL> def get_fd_ikey ( ikey ) : <EOL> if isinstance ( ikey , tuple ) : <EOL> ikey = ikey [ <NUM_LIT:0> ] <EOL> fd_ikey = ikey <EOL> if fd_ikey not in params : <EOL> for tgt , ( src , idxs ) in iteritems ( root . connections ) : <EOL> if src == ikey : <EOL> fd_ikey = tgt <EOL> break <EOL> if fd_ikey not in params : <EOL> for key , meta in iteritems ( params ) : <EOL> if to_prom_name [ key ] == fd_ikey : <EOL> fd_ikey = meta [ '<STR_LIT>' ] <EOL> break <EOL> return fd_ikey <EOL> if return_format == '<STR_LIT>' : <EOL> J = OrderedDict ( ) <EOL> for okey in unknown_list : <EOL> J [ okey ] = OrderedDict ( ) <EOL> for j , ikey in enumerate ( indep_list ) : <EOL> if sparsity is not None : <EOL> if ikey not in sparsity [ okey ] : <EOL> continue <EOL> abs_ikey = abs_params [ j ] <EOL> fd_ikey = get_fd_ikey ( abs_ikey ) <EOL> if ( okey , fd_ikey ) not in Jfd : <EOL> fd_ikey = to_abs_pnames [ fd_ikey ] [ <NUM_LIT:0> ] <EOL> J [ okey ] [ ikey ] = Jfd [ ( okey , fd_ikey ) ] <EOL> if ikey in dv_scale : <EOL> J [ okey ] [ ikey ] *= dv_scale [ ikey ] <EOL> if okey in cn_scale : <EOL> J [ okey ] [ ikey ] *= cn_scale [ okey ] <EOL> else : <EOL> usize = <NUM_LIT:0> <EOL> psize = <NUM_LIT:0> <EOL> for u in unknown_list : <EOL> if u in self . _qoi_indices : <EOL> idx = self . _qoi_indices [ u ] <EOL> usize += len ( idx ) <EOL> else : <EOL> usize += self . root . unknowns . metadata ( u ) [ '<STR_LIT:size>' ] <EOL> for p in indep_list : <EOL> if p in self . _poi_indices : <EOL> idx = self . _poi_indices [ p ] <EOL> psize += len ( idx ) <EOL> else : <EOL> psize += self . root . unknowns . metadata ( p ) [ '<STR_LIT:size>' ] <EOL> J = np . zeros ( ( usize , psize ) ) <EOL> ui = <NUM_LIT:0> <EOL> for u in unknown_list : <EOL> pi = <NUM_LIT:0> <EOL> for j , p in enumerate ( indep_list ) : <EOL> abs_ikey = abs_params [ j ] <EOL> fd_ikey = get_fd_ikey ( abs_ikey ) <EOL> if ( u , fd_ikey ) not in Jfd : <EOL> fd_ikey = to_abs_pnames [ fd_ikey ] [ <NUM_LIT:0> ] <EOL> pd = Jfd [ u , fd_ikey ] <EOL> rows , cols = pd . shape <EOL> for row in range ( <NUM_LIT:0> , rows ) : <EOL> for col in range ( <NUM_LIT:0> , cols ) : <EOL> J [ ui + row ] [ pi + col ] = pd [ row ] [ col ] <EOL> if p in dv_scale : <EOL> J [ ui + row ] [ pi + col ] *= dv_scale [ p ] <EOL> if u in cn_scale : <EOL> J [ ui + row ] [ pi + col ] *= cn_scale [ u ] <EOL> pi += cols <EOL> ui += rows <EOL> return J <EOL> def _calc_gradient_ln_solver ( self , indep_list , unknown_list , return_format , mode , <EOL> dv_scale = None , cn_scale = None , sparsity = None ) : <EOL> """<STR_LIT>""" <EOL> root = self . root <EOL> relevance = root . _probdata . relevance <EOL> unknowns = root . unknowns <EOL> unknowns_dict = root . _unknowns_dict <EOL> to_abs_uname = root . _sysdata . to_abs_uname <EOL> comm = root . comm <EOL> iproc = comm . rank <EOL> nproc = comm . size <EOL> owned = root . _owning_ranks <EOL> if dv_scale is None : <EOL> dv_scale = { } <EOL> if cn_scale is None : <EOL> cn_scale = { } <EOL> mode = self . _mode ( mode , indep_list , unknown_list ) <EOL> fwd = mode == '<STR_LIT>' <EOL> root . clear_dparams ( ) <EOL> for names in root . _probdata . relevance . vars_of_interest ( mode ) : <EOL> for name in names : <EOL> if name in root . dumat : <EOL> root . dumat [ name ] . vec [ : ] = <NUM_LIT:0.0> <EOL> root . drmat [ name ] . vec [ : ] = <NUM_LIT:0.0> <EOL> root . dumat [ None ] . vec [ : ] = <NUM_LIT:0.0> <EOL> root . drmat [ None ] . vec [ : ] = <NUM_LIT:0.0> <EOL> root . _sys_linearize ( root . params , unknowns , root . resids ) <EOL> if return_format == '<STR_LIT>' : <EOL> J = OrderedDict ( ) <EOL> for okeys in unknown_list : <EOL> if isinstance ( okeys , str ) : <EOL> okeys = ( okeys , ) <EOL> for okey in okeys : <EOL> J [ okey ] = OrderedDict ( ) <EOL> for ikeys in indep_list : <EOL> if isinstance ( ikeys , str ) : <EOL> ikeys = ( ikeys , ) <EOL> for ikey in ikeys : <EOL> if sparsity is not None : <EOL> if ikey not in sparsity [ okey ] : <EOL> continue <EOL> J [ okey ] [ ikey ] = None <EOL> else : <EOL> usize = <NUM_LIT:0> <EOL> psize = <NUM_LIT:0> <EOL> Jslices = OrderedDict ( ) <EOL> for u in unknown_list : <EOL> start = usize <EOL> if u in self . _qoi_indices : <EOL> idx = self . _qoi_indices [ u ] <EOL> usize += len ( idx ) <EOL> else : <EOL> usize += self . root . unknowns . metadata ( u ) [ '<STR_LIT:size>' ] <EOL> Jslices [ u ] = slice ( start , usize ) <EOL> for p in indep_list : <EOL> start = psize <EOL> if p in self . _poi_indices : <EOL> idx = self . _poi_indices [ p ] <EOL> psize += len ( idx ) <EOL> else : <EOL> psize += unknowns . metadata ( p ) [ '<STR_LIT:size>' ] <EOL> Jslices [ p ] = slice ( start , psize ) <EOL> J = np . zeros ( ( usize , psize ) ) <EOL> if fwd : <EOL> input_list , output_list = indep_list , unknown_list <EOL> poi_indices , qoi_indices = self . _poi_indices , self . _qoi_indices <EOL> in_scale , un_scale = dv_scale , cn_scale <EOL> else : <EOL> input_list , output_list = unknown_list , indep_list <EOL> qoi_indices , poi_indices = self . _poi_indices , self . _qoi_indices <EOL> in_scale , un_scale = cn_scale , dv_scale <EOL> all_vois = self . root . _probdata . relevance . vars_of_interest ( mode ) <EOL> input_set = set ( ) <EOL> for inp in input_list : <EOL> if isinstance ( inp , str ) : <EOL> input_set . add ( inp ) <EOL> else : <EOL> input_set . update ( inp ) <EOL> voi_sets = [ ] <EOL> for voi_set in all_vois : <EOL> for voi in voi_set : <EOL> if voi in input_set : <EOL> voi_sets . append ( voi_set ) <EOL> break <EOL> flat_voi = [ item for sublist in all_vois for item in sublist ] <EOL> for items in input_list : <EOL> if isinstance ( items , str ) : <EOL> items = ( items , ) <EOL> for item in items : <EOL> if item not in flat_voi : <EOL> voi_sets . append ( ( item , ) ) <EOL> voi_srcs = { } <EOL> for params in voi_sets : <EOL> rhs = OrderedDict ( ) <EOL> voi_idxs = { } <EOL> old_size = None <EOL> for voi in params : <EOL> vkey = self . _get_voi_key ( voi , params ) <EOL> duvec = self . root . dumat [ vkey ] <EOL> rhs [ vkey ] = np . empty ( ( len ( duvec . vec ) , ) ) <EOL> voi_srcs [ vkey ] = voi <EOL> if voi in duvec : <EOL> in_idxs = duvec . _get_local_idxs ( voi , poi_indices ) <EOL> else : <EOL> in_idxs = [ ] <EOL> if len ( in_idxs ) == <NUM_LIT:0> : <EOL> if voi in poi_indices : <EOL> in_idxs = duvec . to_idx_array ( poi_indices [ voi ] ) <EOL> else : <EOL> in_idxs = np . arange ( <NUM_LIT:0> , unknowns_dict [ to_abs_uname [ voi ] ] [ '<STR_LIT:size>' ] , dtype = int ) <EOL> if old_size is None : <EOL> old_size = len ( in_idxs ) <EOL> elif old_size != len ( in_idxs ) : <EOL> raise RuntimeError ( "<STR_LIT>" <EOL> "<STR_LIT>" % ( params , old_size , len ( in_idxs ) ) ) <EOL> voi_idxs [ vkey ] = in_idxs <EOL> for i in range ( len ( in_idxs ) ) : <EOL> for voi in params : <EOL> vkey = self . _get_voi_key ( voi , params ) <EOL> rhs [ vkey ] [ : ] = <NUM_LIT:0.0> <EOL> if self . root . _owning_ranks [ voi_srcs [ vkey ] ] == iproc : <EOL> rhs [ vkey ] [ voi_idxs [ vkey ] [ i ] ] = - <NUM_LIT:1.0> <EOL> dx_mat = root . ln_solver . solve ( rhs , root , mode ) <EOL> for param , dx in iteritems ( dx_mat ) : <EOL> vkey = self . _get_voi_key ( param , params ) <EOL> if param is None : <EOL> param = params [ <NUM_LIT:0> ] <EOL> for item in output_list : <EOL> if sparsity is not None : <EOL> if fwd and param not in sparsity [ item ] : <EOL> continue <EOL> elif not fwd and item not in sparsity [ param ] : <EOL> continue <EOL> if relevance . is_relevant ( vkey , item ) : <EOL> if fwd or owned [ item ] == iproc : <EOL> out_idxs = self . root . dumat [ vkey ] . _get_local_idxs ( item , <EOL> qoi_indices , <EOL> get_slice = True ) <EOL> dxval = dx [ out_idxs ] <EOL> if dxval . size == <NUM_LIT:0> : <EOL> dxval = None <EOL> else : <EOL> dxval = None <EOL> if nproc > <NUM_LIT:1> : <EOL> if trace : <EOL> debug ( "<STR_LIT>" % <EOL> ( dxval , owned [ item ] , param , item ) ) <EOL> dxval = comm . bcast ( dxval , root = owned [ item ] ) <EOL> if trace : <EOL> debug ( "<STR_LIT>" ) <EOL> else : <EOL> if item in qoi_indices : <EOL> zsize = len ( qoi_indices [ item ] ) <EOL> else : <EOL> zsize = unknowns . metadata ( item ) [ '<STR_LIT:size>' ] <EOL> dxval = np . zeros ( zsize ) <EOL> if dxval is not None : <EOL> nk = len ( dxval ) <EOL> if return_format == '<STR_LIT>' : <EOL> if fwd : <EOL> if J [ item ] [ param ] is None : <EOL> J [ item ] [ param ] = np . zeros ( ( nk , len ( in_idxs ) ) ) <EOL> J [ item ] [ param ] [ : , i ] = dxval <EOL> if param in in_scale : <EOL> J [ item ] [ param ] [ : , i ] *= in_scale [ param ] <EOL> if item in un_scale : <EOL> J [ item ] [ param ] [ : , i ] *= un_scale [ item ] <EOL> else : <EOL> if J [ param ] [ item ] is None : <EOL> J [ param ] [ item ] = np . zeros ( ( len ( in_idxs ) , nk ) ) <EOL> J [ param ] [ item ] [ i , : ] = dxval <EOL> if param in in_scale : <EOL> J [ param ] [ item ] [ i , : ] *= in_scale [ param ] <EOL> if item in un_scale : <EOL> J [ param ] [ item ] [ i , : ] *= un_scale [ item ] <EOL> else : <EOL> if fwd : <EOL> J [ Jslices [ item ] , Jslices [ param ] . start + i ] = dxval <EOL> if param in in_scale : <EOL> J [ Jslices [ item ] , Jslices [ param ] . start + i ] *= in_scale [ param ] <EOL> if item in un_scale : <EOL> J [ Jslices [ item ] , Jslices [ param ] . start + i ] *= un_scale [ item ] <EOL> else : <EOL> J [ Jslices [ param ] . start + i , Jslices [ item ] ] = dxval <EOL> if param in in_scale : <EOL> J [ Jslices [ param ] . start + i , Jslices [ item ] ] *= in_scale [ param ] <EOL> if item in un_scale : <EOL> J [ Jslices [ param ] . start + i , Jslices [ item ] ] *= un_scale [ item ] <EOL> root . clear_dparams ( ) <EOL> return J <EOL> def _get_voi_key ( self , voi , grp ) : <EOL> """<STR_LIT>""" <EOL> if ( voi in self . _driver_vois and <EOL> isinstance ( self . root . ln_solver , LinearGaussSeidel ) ) : <EOL> if ( len ( grp ) > <NUM_LIT:1> or <EOL> self . root . ln_solver . options [ '<STR_LIT>' ] ) : <EOL> return voi <EOL> return None <EOL> def check_partial_derivatives ( self , out_stream = sys . stdout , comps = None , <EOL> compact_print = False ) : <EOL> """<STR_LIT>""" <EOL> root = self . root <EOL> if self . driver . iter_count < <NUM_LIT:1> : <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> self . run_once ( ) <EOL> root . _sys_linearize ( root . params , root . unknowns , root . resids ) <EOL> if out_stream is not None : <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> data = { } <EOL> voi = None <EOL> allcomps = root . components ( recurse = True ) <EOL> if comps is None : <EOL> comps = allcomps <EOL> else : <EOL> allcompnames = set ( [ c . pathname for c in allcomps ] ) <EOL> requested = set ( comps ) <EOL> diff = requested . difference ( allcompnames ) <EOL> if diff : <EOL> sorted_diff = list ( diff ) <EOL> sorted_diff . sort ( ) <EOL> msg = "<STR_LIT>" <EOL> msg += str ( sorted_diff ) <EOL> raise RuntimeError ( msg ) <EOL> comps = [ root . _subsystem ( c_name ) for c_name in comps ] <EOL> for comp in comps : <EOL> cname = comp . pathname <EOL> opt = comp . fd_options <EOL> fwd_rev = True <EOL> if opt [ '<STR_LIT>' ] : <EOL> f_d_2 = True <EOL> fd_desc = opt [ '<STR_LIT>' ] <EOL> fd_desc2 = opt [ '<STR_LIT>' ] <EOL> else : <EOL> f_d_2 = False <EOL> fd_desc = None <EOL> fd_desc2 = None <EOL> if opt [ '<STR_LIT>' ] : <EOL> if not f_d_2 : <EOL> continue <EOL> fwd_rev = False <EOL> if isinstance ( comp , IndepVarComp ) : <EOL> continue <EOL> data [ cname ] = { } <EOL> jac_fwd = OrderedDict ( ) <EOL> jac_rev = OrderedDict ( ) <EOL> jac_fd = OrderedDict ( ) <EOL> jac_fd2 = OrderedDict ( ) <EOL> params = comp . params <EOL> unknowns = comp . unknowns <EOL> resids = comp . resids <EOL> dparams = comp . dpmat [ voi ] <EOL> dunknowns = comp . dumat [ voi ] <EOL> dresids = comp . drmat [ voi ] <EOL> states = comp . states <EOL> if len ( dparams ) == <NUM_LIT:0> : <EOL> continue <EOL> param_list = [ item for item in dparams if not dparams . metadata ( item ) . get ( '<STR_LIT>' ) ] <EOL> param_list . extend ( states ) <EOL> unkn_list = [ item for item in dunknowns if not dunknowns . metadata ( item ) . get ( '<STR_LIT>' ) ] <EOL> if out_stream is not None : <EOL> out_stream . write ( '<STR_LIT:->' * ( len ( cname ) + <NUM_LIT:15> ) + '<STR_LIT:\n>' ) <EOL> out_stream . write ( "<STR_LIT>" % cname ) <EOL> out_stream . write ( '<STR_LIT:->' * ( len ( cname ) + <NUM_LIT:15> ) + '<STR_LIT:\n>' ) <EOL> for p_name in param_list : <EOL> if not fwd_rev : <EOL> break <EOL> dinputs = dunknowns if p_name in states else dparams <EOL> p_size = np . size ( dinputs [ p_name ] ) <EOL> for u_name in unkn_list : <EOL> u_size = np . size ( dunknowns [ u_name ] ) <EOL> if comp . _jacobian_cache : <EOL> if ( u_name , p_name ) in comp . _jacobian_cache : <EOL> user = comp . _jacobian_cache [ ( u_name , p_name ) ] . shape <EOL> if len ( user ) < <NUM_LIT:2> : <EOL> user = ( user [ <NUM_LIT:0> ] , <NUM_LIT:1> ) <EOL> if user [ <NUM_LIT:0> ] != u_size or user [ <NUM_LIT:1> ] != p_size : <EOL> msg = "<STR_LIT>" + "<STR_LIT>" <EOL> msg = msg . format ( cname , u_name , p_name , ( u_size , p_size ) , user ) <EOL> raise ValueError ( msg ) <EOL> jac_fwd [ ( u_name , p_name ) ] = np . zeros ( ( u_size , p_size ) ) <EOL> jac_rev [ ( u_name , p_name ) ] = np . zeros ( ( u_size , p_size ) ) <EOL> if fwd_rev : <EOL> for u_name in unkn_list : <EOL> u_size = np . size ( dunknowns [ u_name ] ) <EOL> for idx in range ( u_size ) : <EOL> dresids . vec [ : ] = <NUM_LIT:0.0> <EOL> root . clear_dparams ( ) <EOL> dunknowns . vec [ : ] = <NUM_LIT:0.0> <EOL> dresids . _dat [ u_name ] . val [ idx ] = <NUM_LIT:1.0> <EOL> try : <EOL> comp . apply_linear ( params , unknowns , dparams , <EOL> dunknowns , dresids , '<STR_LIT>' ) <EOL> finally : <EOL> dparams . _apply_unit_derivatives ( ) <EOL> for p_name in param_list : <EOL> dinputs = dunknowns if p_name in states else dparams <EOL> jac_rev [ ( u_name , p_name ) ] [ idx , : ] = dinputs . _dat [ p_name ] . val <EOL> if fwd_rev : <EOL> for p_name in param_list : <EOL> dinputs = dunknowns if p_name in states else dparams <EOL> p_size = np . size ( dinputs [ p_name ] ) <EOL> for idx in range ( p_size ) : <EOL> dresids . vec [ : ] = <NUM_LIT:0.0> <EOL> root . clear_dparams ( ) <EOL> dunknowns . vec [ : ] = <NUM_LIT:0.0> <EOL> dinputs . _dat [ p_name ] . val [ idx ] = <NUM_LIT:1.0> <EOL> dparams . _apply_unit_derivatives ( ) <EOL> comp . apply_linear ( params , unknowns , dparams , <EOL> dunknowns , dresids , '<STR_LIT>' ) <EOL> for u_name , u_val in dresids . vec_val_iter ( ) : <EOL> jac_fwd [ ( u_name , p_name ) ] [ : , idx ] = u_val <EOL> dresids . vec [ : ] = <NUM_LIT:0.0> <EOL> root . clear_dparams ( ) <EOL> dunknowns . vec [ : ] = <NUM_LIT:0.0> <EOL> if opt [ '<STR_LIT>' ] == '<STR_LIT>' : <EOL> fd_func = comp . complex_step_jacobian <EOL> else : <EOL> fd_func = comp . fd_jacobian <EOL> jac_fd = fd_func ( params , unknowns , resids ) <EOL> if f_d_2 : <EOL> dresids . vec [ : ] = <NUM_LIT:0.0> <EOL> root . clear_dparams ( ) <EOL> dunknowns . vec [ : ] = <NUM_LIT:0.0> <EOL> if opt [ '<STR_LIT>' ] == '<STR_LIT>' : <EOL> fd_func = comp . complex_step_jacobian <EOL> else : <EOL> fd_func = comp . fd_jacobian <EOL> save_form = opt [ '<STR_LIT>' ] <EOL> OptionsDictionary . locked = False <EOL> opt [ '<STR_LIT>' ] = opt [ '<STR_LIT>' ] <EOL> jac_fd2 = fd_func ( params , unknowns , resids ) <EOL> opt [ '<STR_LIT>' ] = save_form <EOL> OptionsDictionary . locked = True <EOL> _assemble_deriv_data ( chain ( dparams , states ) , resids , data [ cname ] , <EOL> jac_fwd , jac_rev , jac_fd , out_stream , <EOL> c_name = cname , jac_fd2 = jac_fd2 , fd_desc = fd_desc , <EOL> fd_desc2 = fd_desc2 , compact_print = compact_print ) <EOL> return data <EOL> def check_total_derivatives ( self , out_stream = sys . stdout ) : <EOL> """<STR_LIT>""" <EOL> root = self . root <EOL> driver = self . driver <EOL> if driver . iter_count < <NUM_LIT:1> : <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> self . run_once ( ) <EOL> if out_stream is not None : <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> if len ( driver . _desvars ) > <NUM_LIT:0> : <EOL> param_srcs = list ( driver . _desvars . keys ( ) ) <EOL> to_abs_name = root . _sysdata . to_abs_uname <EOL> indep_list = [ p for p in param_srcs if not root . _unknowns_dict [ to_abs_name [ p ] ] . get ( '<STR_LIT>' ) ] <EOL> else : <EOL> abs_indep_list = root . _get_fd_params ( ) <EOL> param_srcs = [ root . connections [ p ] for p in abs_indep_list if not root . _params_dict [ p ] . get ( '<STR_LIT>' ) ] <EOL> to_prom_name = self . root . _sysdata . to_prom_name <EOL> indep_list = [ <EOL> to_prom_name [ p ] for p , idxs in param_srcs <EOL> ] <EOL> if len ( driver . _objs ) > <NUM_LIT:0> or len ( driver . _cons ) > <NUM_LIT:0> : <EOL> unknown_list = list ( driver . _objs . keys ( ) ) <EOL> unknown_list . extend ( list ( driver . _cons . keys ( ) ) ) <EOL> unknown_list = [ item for item in unknown_list if not root . unknowns . metadata ( item ) . get ( '<STR_LIT>' ) ] <EOL> else : <EOL> unknown_list = root . _get_fd_unknowns ( ) <EOL> unknown_list = [ item for item in unknown_list if not root . unknowns . metadata ( item ) . get ( '<STR_LIT>' ) ] <EOL> if root . ln_solver . options . get ( '<STR_LIT>' ) : <EOL> mode = self . _mode ( '<STR_LIT>' , indep_list , unknown_list ) <EOL> if mode == '<STR_LIT>' : <EOL> fwd , rev = True , False <EOL> Jrev = None <EOL> if out_stream is not None : <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> else : <EOL> fwd , rev = False , True <EOL> Jfor = None <EOL> if out_stream is not None : <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> else : <EOL> fwd = rev = True <EOL> if fwd : <EOL> Jfor = self . calc_gradient ( indep_list , unknown_list , mode = '<STR_LIT>' , <EOL> return_format = '<STR_LIT>' ) <EOL> Jfor = _jac_to_flat_dict ( Jfor ) <EOL> if rev : <EOL> Jrev = self . calc_gradient ( indep_list , unknown_list , mode = '<STR_LIT>' , <EOL> return_format = '<STR_LIT>' ) <EOL> Jrev = _jac_to_flat_dict ( Jrev ) <EOL> Jfd = self . calc_gradient ( indep_list , unknown_list , mode = '<STR_LIT>' , <EOL> return_format = '<STR_LIT>' ) <EOL> Jfd = _jac_to_flat_dict ( Jfd ) <EOL> data = { } <EOL> _assemble_deriv_data ( indep_list , unknown_list , data , <EOL> Jfor , Jrev , Jfd , out_stream ) <EOL> return data <EOL> def _start_recorders ( self ) : <EOL> """<STR_LIT>""" <EOL> self . driver . recorders . startup ( self . root ) <EOL> self . driver . recorders . record_metadata ( self . root ) <EOL> for group in self . root . subgroups ( recurse = True , include_self = True ) : <EOL> for solver in ( group . nl_solver , group . ln_solver ) : <EOL> solver . recorders . startup ( group ) <EOL> solver . recorders . record_metadata ( self . root ) <EOL> def _check_for_parallel_derivs ( self , params , unknowns , par_u , par_p ) : <EOL> """<STR_LIT>""" <EOL> mode = self . _mode ( '<STR_LIT>' , params , unknowns ) <EOL> if mode == '<STR_LIT>' : <EOL> has_parallel_derivs = par_p <EOL> else : <EOL> has_parallel_derivs = par_u <EOL> if ( isinstance ( self . root . ln_solver , LinearGaussSeidel ) and <EOL> self . root . ln_solver . options [ '<STR_LIT>' ] ) and has_parallel_derivs : <EOL> for sub in self . root . subgroups ( recurse = True ) : <EOL> sub_mode = sub . ln_solver . options [ '<STR_LIT>' ] <EOL> if isinstance ( sub . ln_solver , LinearGaussSeidel ) and sub_mode not in ( mode , '<STR_LIT>' ) : <EOL> msg = "<STR_LIT>" "<STR_LIT>" <EOL> msg = msg . format ( name = sub . name , submode = sub_mode , rootmode = mode ) <EOL> self . _setup_errors . append ( msg ) <EOL> return mode <EOL> def _json_system_tree ( self ) : <EOL> """<STR_LIT>""" <EOL> def _tree_dict ( system ) : <EOL> dct = OrderedDict ( ) <EOL> for s in system . subsystems ( recurse = True ) : <EOL> if isinstance ( s , Group ) : <EOL> dct [ s . name ] = _tree_dict ( s ) <EOL> else : <EOL> dct [ s . name ] = OrderedDict ( ) <EOL> for vname , meta in iteritems ( s . unknowns ) : <EOL> dct [ s . name ] [ vname ] = m = meta . copy ( ) <EOL> for mname in m : <EOL> if isinstance ( m [ mname ] , np . ndarray ) : <EOL> m [ mname ] = m [ mname ] . tolist ( ) <EOL> return dct <EOL> tree = OrderedDict ( ) <EOL> tree [ '<STR_LIT:root>' ] = _tree_dict ( self . root ) <EOL> return json . dumps ( tree ) <EOL> def _setup_communicators ( self ) : <EOL> if self . comm is None : <EOL> self . comm = self . _impl . world_comm ( ) <EOL> minproc , maxproc = self . driver . get_req_procs ( ) <EOL> if MPI : <EOL> if not ( maxproc is None or maxproc >= self . comm . size ) : <EOL> raise RuntimeError ( "<STR_LIT>" <EOL> "<STR_LIT>" % <EOL> ( self . comm . size , minproc , maxproc ) ) <EOL> elif self . comm . size < minproc : <EOL> if maxproc is None : <EOL> maxproc = '<STR_LIT>' <EOL> raise RuntimeError ( "<STR_LIT>" <EOL> "<STR_LIT>" % <EOL> ( self . comm . size , minproc , maxproc ) ) <EOL> self . driver . _setup_communicators ( self . comm , os . getcwd ( ) ) <EOL> def _setup_units ( self , connections , params_dict , unknowns_dict ) : <EOL> """<STR_LIT>""" <EOL> to_prom_name = self . root . _sysdata . to_prom_name <EOL> for target , ( source , idxs ) in iteritems ( connections ) : <EOL> tmeta = params_dict [ target ] <EOL> smeta = unknowns_dict [ source ] <EOL> if '<STR_LIT>' not in tmeta or '<STR_LIT>' not in smeta : <EOL> continue <EOL> src_unit = smeta [ '<STR_LIT>' ] <EOL> tgt_unit = tmeta [ '<STR_LIT>' ] <EOL> try : <EOL> scale , offset = get_conversion_tuple ( src_unit , tgt_unit ) <EOL> except TypeError as err : <EOL> if str ( err ) == "<STR_LIT>" : <EOL> msg = "<STR_LIT>" "<STR_LIT>" "<STR_LIT>" . format ( src_unit , <EOL> _both_names ( smeta , to_prom_name ) , <EOL> tgt_unit , <EOL> _both_names ( tmeta , to_prom_name ) ) <EOL> self . _setup_errors . append ( msg ) <EOL> continue <EOL> else : <EOL> raise <EOL> if scale != <NUM_LIT:1.0> or offset != <NUM_LIT:0.0> : <EOL> tmeta [ '<STR_LIT>' ] = ( scale , offset ) <EOL> def _add_implicit_connections ( self , connections ) : <EOL> """<STR_LIT>""" <EOL> dangling = set ( ) <EOL> abs_unames = self . root . _sysdata . to_abs_uname <EOL> for prom_name , pabs_list in iteritems ( self . root . _sysdata . to_abs_pnames ) : <EOL> if prom_name in abs_unames : <EOL> for pabs in pabs_list : <EOL> connections . setdefault ( pabs , [ ] ) . append ( ( abs_unames [ prom_name ] , None ) ) <EOL> else : <EOL> dangling . add ( prom_name ) <EOL> return dangling <EOL> def print_all_convergence ( self ) : <EOL> """<STR_LIT>""" <EOL> root = self . root <EOL> root . ln_solver . print_all_convergence ( ) <EOL> root . nl_solver . print_all_convergence ( ) <EOL> for grp in root . subgroups ( recurse = True ) : <EOL> grp . ln_solver . print_all_convergence ( ) <EOL> grp . nl_solver . print_all_convergence ( ) <EOL> def _assign_parameters ( connections ) : <EOL> """<STR_LIT>""" <EOL> param_owners = { } <EOL> for par , ( unk , idxs ) in iteritems ( connections ) : <EOL> param_owners . setdefault ( get_common_ancestor ( par , unk ) , set ( ) ) . add ( par ) <EOL> return param_owners <EOL> def _jac_to_flat_dict ( jac ) : <EOL> """<STR_LIT>""" <EOL> new_jac = OrderedDict ( ) <EOL> for key1 , val1 in iteritems ( jac ) : <EOL> for key2 , val2 in iteritems ( val1 ) : <EOL> new_jac [ ( key1 , key2 ) ] = val2 <EOL> return new_jac <EOL> def _pad_name ( name , pad_num = <NUM_LIT> , quotes = True ) : <EOL> """<STR_LIT>""" <EOL> l_name = len ( name ) <EOL> if l_name < pad_num : <EOL> pad = pad_num - l_name <EOL> if quotes : <EOL> pad_str = "<STR_LIT>" <EOL> else : <EOL> pad_str = "<STR_LIT>" <EOL> pad_name = pad_str . format ( name = name , sep = '<STR_LIT>' , pad = pad ) <EOL> return pad_name <EOL> else : <EOL> return '<STR_LIT>' . format ( name ) <EOL> def _assemble_deriv_data ( params , resids , cdata , jac_fwd , jac_rev , jac_fd , <EOL> out_stream , c_name = '<STR_LIT:root>' , jac_fd2 = None , fd_desc = None , <EOL> fd_desc2 = None , compact_print = False ) : <EOL> """<STR_LIT>""" <EOL> started = False <EOL> for p_name in params : <EOL> for u_name in resids : <EOL> key = ( u_name , p_name ) <EOL> if key not in jac_fd : <EOL> continue <EOL> ldata = cdata [ key ] = { } <EOL> Jsub_fd = jac_fd [ key ] <EOL> ldata [ '<STR_LIT>' ] = Jsub_fd <EOL> magfd = np . linalg . norm ( Jsub_fd ) <EOL> if jac_fwd : <EOL> Jsub_for = jac_fwd [ key ] <EOL> ldata [ '<STR_LIT>' ] = Jsub_for <EOL> magfor = np . linalg . norm ( Jsub_for ) <EOL> else : <EOL> magfor = None <EOL> if jac_rev : <EOL> Jsub_rev = jac_rev [ key ] <EOL> ldata [ '<STR_LIT>' ] = Jsub_rev <EOL> magrev = np . linalg . norm ( Jsub_rev ) <EOL> else : <EOL> magrev = None <EOL> if jac_fd2 : <EOL> Jsub_fd2 = jac_fd2 [ key ] <EOL> ldata [ '<STR_LIT>' ] = Jsub_fd2 <EOL> magfd2 = np . linalg . norm ( Jsub_fd2 ) <EOL> else : <EOL> magfd2 = None <EOL> ldata [ '<STR_LIT>' ] = ( magfor , magrev , magfd ) <EOL> if jac_fwd : <EOL> abs1 = np . linalg . norm ( Jsub_for - Jsub_fd ) <EOL> else : <EOL> abs1 = None <EOL> if jac_rev : <EOL> abs2 = np . linalg . norm ( Jsub_rev - Jsub_fd ) <EOL> else : <EOL> abs2 = None <EOL> if jac_fwd and jac_rev : <EOL> abs3 = np . linalg . norm ( Jsub_for - Jsub_rev ) <EOL> else : <EOL> abs3 = None <EOL> if jac_fd2 : <EOL> abs4 = np . linalg . norm ( Jsub_fd2 - Jsub_fd ) <EOL> else : <EOL> abs4 = None <EOL> ldata [ '<STR_LIT>' ] = ( abs1 , abs2 , abs3 ) <EOL> if magfd == <NUM_LIT:0.0> : <EOL> rel1 = rel2 = rel3 = rel4 = float ( '<STR_LIT>' ) <EOL> else : <EOL> if jac_fwd : <EOL> rel1 = np . linalg . norm ( Jsub_for - Jsub_fd ) / magfd <EOL> else : <EOL> rel1 = None <EOL> if jac_rev : <EOL> rel2 = np . linalg . norm ( Jsub_rev - Jsub_fd ) / magfd <EOL> else : <EOL> rel2 = None <EOL> if jac_fwd and jac_rev : <EOL> rel3 = np . linalg . norm ( Jsub_for - Jsub_rev ) / magfd <EOL> else : <EOL> rel3 = None <EOL> if jac_fd2 : <EOL> rel4 = np . linalg . norm ( Jsub_fd2 - Jsub_fd ) / magfd <EOL> else : <EOL> rel4 = None <EOL> ldata [ '<STR_LIT>' ] = ( rel1 , rel2 , rel3 ) <EOL> if out_stream is None : <EOL> continue <EOL> if compact_print : <EOL> if jac_fwd and jac_rev : <EOL> if not started : <EOL> tmp1 = "<STR_LIT>" <EOL> out_str = tmp1 . format ( _pad_name ( '<STR_LIT>' ) , _pad_name ( '<STR_LIT>' ) , <EOL> _pad_name ( '<STR_LIT>' , <NUM_LIT:10> , quotes = False ) , <EOL> _pad_name ( '<STR_LIT>' , <NUM_LIT:10> , quotes = False ) , <EOL> _pad_name ( '<STR_LIT>' , <NUM_LIT:10> , quotes = False ) , <EOL> _pad_name ( '<STR_LIT>' , <NUM_LIT:10> , quotes = False ) , <EOL> _pad_name ( '<STR_LIT>' , <NUM_LIT:10> , quotes = False ) , <EOL> _pad_name ( '<STR_LIT>' , <NUM_LIT:10> , quotes = False ) , <EOL> _pad_name ( '<STR_LIT>' , <NUM_LIT:10> , quotes = False ) <EOL> ) <EOL> out_stream . write ( out_str ) <EOL> out_stream . write ( '<STR_LIT:->' * len ( out_str ) + '<STR_LIT:\n>' ) <EOL> started = True <EOL> tmp1 = "<STR_LIT>" <EOL> out_stream . write ( tmp1 . format ( _pad_name ( u_name ) , _pad_name ( p_name ) , <EOL> magfor , magrev , magfd , abs1 , abs2 , <EOL> rel1 , rel2 ) ) <EOL> elif jac_fd and jac_fd2 : <EOL> if not started : <EOL> tmp1 = "<STR_LIT>" <EOL> out_str = tmp1 . format ( _pad_name ( '<STR_LIT>' ) , _pad_name ( '<STR_LIT>' ) , <EOL> _pad_name ( '<STR_LIT>' , <NUM_LIT> , quotes = False ) , <EOL> _pad_name ( '<STR_LIT>' , <NUM_LIT:12> , quotes = False ) , <EOL> _pad_name ( '<STR_LIT>' , <NUM_LIT:12> , quotes = False ) , <EOL> _pad_name ( '<STR_LIT>' , <NUM_LIT:12> , quotes = False ) <EOL> ) <EOL> out_stream . write ( out_str ) <EOL> out_stream . write ( '<STR_LIT:->' * len ( out_str ) + '<STR_LIT:\n>' ) <EOL> started = True <EOL> tmp1 = "<STR_LIT>" <EOL> out_stream . write ( tmp1 . format ( _pad_name ( u_name ) , _pad_name ( p_name ) , <EOL> magfd , magfd2 , abs4 , rel4 ) ) <EOL> else : <EOL> if started : <EOL> out_stream . write ( '<STR_LIT>' * <NUM_LIT:30> + '<STR_LIT:\n>' ) <EOL> else : <EOL> started = True <EOL> out_stream . write ( "<STR_LIT>" % ( c_name , u_name , p_name ) ) <EOL> if jac_fwd : <EOL> out_stream . write ( '<STR_LIT>' % magfor ) <EOL> if jac_rev : <EOL> out_stream . write ( '<STR_LIT>' % magrev ) <EOL> if not jac_fwd and not jac_rev : <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> if jac_fd : <EOL> out_stream . write ( '<STR_LIT>' % magfd ) <EOL> if fd_desc : <EOL> out_stream . write ( '<STR_LIT>' % fd_desc ) <EOL> out_stream . write ( '<STR_LIT:\n>' ) <EOL> if jac_fd2 : <EOL> out_stream . write ( '<STR_LIT>' % magfd2 ) <EOL> if fd_desc2 : <EOL> out_stream . write ( '<STR_LIT>' % fd_desc2 ) <EOL> out_stream . write ( '<STR_LIT:\n>' ) <EOL> out_stream . write ( '<STR_LIT:\n>' ) <EOL> if jac_fwd : <EOL> out_stream . write ( '<STR_LIT>' % abs1 ) <EOL> if jac_rev : <EOL> out_stream . write ( '<STR_LIT>' % abs2 ) <EOL> if jac_fwd and jac_rev : <EOL> out_stream . write ( '<STR_LIT>' % abs3 ) <EOL> if jac_fd2 : <EOL> out_stream . write ( '<STR_LIT>' % abs4 ) <EOL> out_stream . write ( '<STR_LIT:\n>' ) <EOL> if jac_fwd : <EOL> out_stream . write ( '<STR_LIT>' % rel1 ) <EOL> if jac_rev : <EOL> out_stream . write ( '<STR_LIT>' % rel2 ) <EOL> if jac_fwd and jac_rev : <EOL> out_stream . write ( '<STR_LIT>' % rel3 ) <EOL> if jac_fd2 : <EOL> out_stream . write ( '<STR_LIT>' % rel4 ) <EOL> out_stream . write ( '<STR_LIT:\n>' ) <EOL> if jac_fwd : <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> out_stream . write ( str ( Jsub_for ) ) <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> if jac_rev : <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> out_stream . write ( str ( Jsub_rev ) ) <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> out_stream . write ( str ( Jsub_fd ) ) <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> if jac_fd2 : <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> out_stream . write ( str ( Jsub_fd2 ) ) <EOL> out_stream . write ( '<STR_LIT>' ) <EOL> def _needs_iteration ( comp ) : <EOL> """<STR_LIT>""" <EOL> if isinstance ( comp , Component ) and comp . is_active ( ) and comp . states : <EOL> for klass in comp . __class__ . __mro__ : <EOL> if klass is Component : <EOL> break <EOL> if '<STR_LIT>' in klass . __dict__ : <EOL> return False <EOL> return True <EOL> return False <EOL> def _get_gmres_name ( ) : <EOL> if MPI : <EOL> return '<STR_LIT>' <EOL> else : <EOL> return '<STR_LIT>' </s>
<s> """<STR_LIT>""" <EOL> from collections import OrderedDict <EOL> from sqlitedict import SqliteDict <EOL> from openmdao . recorders . base_recorder import BaseRecorder <EOL> from openmdao . util . record_util import format_iteration_coordinate <EOL> from openmdao . core . mpi_wrap import MPI <EOL> class SqliteRecorder ( BaseRecorder ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , out , ** sqlite_dict_args ) : <EOL> super ( SqliteRecorder , self ) . __init__ ( ) <EOL> if MPI and MPI . COMM_WORLD . rank > <NUM_LIT:0> : <EOL> self . _open_close_sqlitedict = False <EOL> else : <EOL> self . _open_close_sqlitedict = True <EOL> if self . _open_close_sqlitedict : <EOL> sqlite_dict_args . setdefault ( '<STR_LIT>' , True ) <EOL> sqlite_dict_args . setdefault ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . out = SqliteDict ( filename = out , flag = '<STR_LIT:n>' , ** sqlite_dict_args ) <EOL> else : <EOL> self . out = None <EOL> def record_metadata ( self , group ) : <EOL> """<STR_LIT>""" <EOL> params = group . params . iteritems ( ) <EOL> resids = group . resids . iteritems ( ) <EOL> unknowns = group . unknowns . iteritems ( ) <EOL> data = OrderedDict ( [ ( '<STR_LIT>' , dict ( params ) ) , <EOL> ( '<STR_LIT>' , dict ( unknowns ) ) , <EOL> ] ) <EOL> self . out [ '<STR_LIT>' ] = data <EOL> def record_iteration ( self , params , unknowns , resids , metadata ) : <EOL> """<STR_LIT>""" <EOL> data = OrderedDict ( ) <EOL> iteration_coordinate = metadata [ '<STR_LIT>' ] <EOL> timestamp = metadata [ '<STR_LIT>' ] <EOL> group_name = format_iteration_coordinate ( iteration_coordinate ) <EOL> data [ '<STR_LIT>' ] = timestamp <EOL> data [ '<STR_LIT:success>' ] = metadata [ '<STR_LIT:success>' ] <EOL> data [ '<STR_LIT>' ] = metadata [ '<STR_LIT>' ] <EOL> if self . options [ '<STR_LIT>' ] : <EOL> data [ '<STR_LIT>' ] = self . _filter_vector ( params , '<STR_LIT:p>' , iteration_coordinate ) <EOL> if self . options [ '<STR_LIT>' ] : <EOL> data [ '<STR_LIT>' ] = self . _filter_vector ( unknowns , '<STR_LIT:u>' , iteration_coordinate ) <EOL> if self . options [ '<STR_LIT>' ] : <EOL> data [ '<STR_LIT>' ] = self . _filter_vector ( resids , '<STR_LIT:r>' , iteration_coordinate ) <EOL> self . out [ group_name ] = data <EOL> def record_derivatives ( self , derivs , metadata ) : <EOL> """<STR_LIT>""" <EOL> data = OrderedDict ( ) <EOL> iteration_coordinate = metadata [ '<STR_LIT>' ] <EOL> timestamp = metadata [ '<STR_LIT>' ] <EOL> group_name = format_iteration_coordinate ( iteration_coordinate ) <EOL> group_name = '<STR_LIT>' % group_name <EOL> data [ '<STR_LIT>' ] = timestamp <EOL> data [ '<STR_LIT:success>' ] = metadata [ '<STR_LIT:success>' ] <EOL> data [ '<STR_LIT>' ] = metadata [ '<STR_LIT>' ] <EOL> data [ '<STR_LIT>' ] = derivs <EOL> self . out [ group_name ] = data <EOL> def close ( self ) : <EOL> """<STR_LIT>""" <EOL> if self . _open_close_sqlitedict : <EOL> if self . out is not None : <EOL> self . out . close ( ) <EOL> self . out = None </s>
<s> """<STR_LIT>""" <EOL> import numpy as np <EOL> from numpy import atleast_2d as array2d <EOL> from scipy import linalg <EOL> from scipy . optimize import minimize <EOL> from scipy . spatial . distance import squareform <EOL> from openmdao . surrogate_models . surrogate_model import MultiFiSurrogateModel <EOL> import logging <EOL> _logger = logging . getLogger ( ) <EOL> MACHINE_EPSILON = np . finfo ( np . double ) . eps <EOL> NUGGET = <NUM_LIT> * MACHINE_EPSILON <EOL> INITIAL_RANGE_DEFAULT = <NUM_LIT> <EOL> TOLERANCE_DEFAULT = <NUM_LIT> <EOL> THETA0_DEFAULT = <NUM_LIT:0.5> <EOL> THETAL_DEFAULT = <NUM_LIT> <EOL> THETAU_DEFAULT = <NUM_LIT:50> <EOL> if hasattr ( linalg , '<STR_LIT>' ) : <EOL> solve_triangular = linalg . solve_triangular <EOL> else : <EOL> def solve_triangular ( x , y , lower = True ) : <EOL> return linalg . solve ( x , y ) <EOL> def constant_regression ( x ) : <EOL> """<STR_LIT>""" <EOL> x = np . asarray ( x , dtype = np . float ) <EOL> n_eval = x . shape [ <NUM_LIT:0> ] <EOL> f = np . ones ( [ n_eval , <NUM_LIT:1> ] ) <EOL> return f <EOL> def linear_regression ( x ) : <EOL> """<STR_LIT>""" <EOL> x = np . asarray ( x , dtype = np . float ) <EOL> n_eval = x . shape [ <NUM_LIT:0> ] <EOL> f = np . hstack ( [ np . ones ( [ n_eval , <NUM_LIT:1> ] ) , x ] ) <EOL> return f <EOL> def squared_exponential_correlation ( theta , d ) : <EOL> """<STR_LIT>""" <EOL> theta = np . asarray ( theta , dtype = np . float ) <EOL> d = np . asarray ( d , dtype = np . float ) <EOL> if d . ndim > <NUM_LIT:1> : <EOL> n_features = d . shape [ <NUM_LIT:1> ] <EOL> else : <EOL> n_features = <NUM_LIT:1> <EOL> if theta . size == <NUM_LIT:1> : <EOL> return np . exp ( - theta [ <NUM_LIT:0> ] * np . sum ( d ** <NUM_LIT:2> , axis = <NUM_LIT:1> ) ) <EOL> elif theta . size != n_features : <EOL> raise ValueError ( "<STR_LIT>" % n_features ) <EOL> else : <EOL> return np . exp ( - np . sum ( theta . reshape ( <NUM_LIT:1> , n_features ) * d ** <NUM_LIT:2> , axis = <NUM_LIT:1> ) ) <EOL> def l1_cross_distances ( X , Y = None ) : <EOL> """<STR_LIT>""" <EOL> if Y is None : <EOL> X = array2d ( X ) <EOL> n_samples , n_features = X . shape <EOL> n_nonzero_cross_dist = n_samples * ( n_samples - <NUM_LIT:1> ) // <NUM_LIT:2> <EOL> D = np . zeros ( ( n_nonzero_cross_dist , n_features ) ) <EOL> ll_1 = <NUM_LIT:0> <EOL> for k in range ( n_samples - <NUM_LIT:1> ) : <EOL> ll_0 = ll_1 <EOL> ll_1 = ll_0 + n_samples - k - <NUM_LIT:1> <EOL> D [ ll_0 : ll_1 ] = np . abs ( X [ k ] - X [ ( k + <NUM_LIT:1> ) : ] ) <EOL> return D <EOL> else : <EOL> X = array2d ( X ) <EOL> Y = array2d ( Y ) <EOL> n_samples_X , n_features_X = X . shape <EOL> n_samples_Y , n_features_Y = Y . shape <EOL> if n_features_X != n_features_Y : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> n_features = n_features_X <EOL> n_nonzero_cross_dist = n_samples_X * n_samples_Y <EOL> D = np . zeros ( ( n_nonzero_cross_dist , n_features ) ) <EOL> ll_1 = <NUM_LIT:0> <EOL> for k in range ( n_samples_X ) : <EOL> ll_0 = ll_1 <EOL> ll_1 = ll_0 + n_samples_Y <EOL> D [ ll_0 : ll_1 ] = np . abs ( X [ k ] - Y ) <EOL> return D <EOL> class MultiFiCoKriging ( object ) : <EOL> """<STR_LIT>""" <EOL> _regression_types = { <EOL> '<STR_LIT>' : constant_regression , <EOL> '<STR_LIT>' : linear_regression } <EOL> def __init__ ( self , regr = '<STR_LIT>' , rho_regr = '<STR_LIT>' , <EOL> theta = None , theta0 = None , thetaL = None , thetaU = None ) : <EOL> self . corr = squared_exponential_correlation <EOL> self . regr = regr <EOL> self . rho_regr = rho_regr <EOL> self . theta = theta <EOL> self . theta0 = theta0 <EOL> self . thetaL = thetaL <EOL> self . thetaU = thetaU <EOL> self . _nfev = <NUM_LIT:0> <EOL> def _build_R ( self , lvl , theta ) : <EOL> """<STR_LIT>""" <EOL> D = self . D [ lvl ] <EOL> n_samples = self . n_samples [ lvl ] <EOL> R = np . eye ( n_samples ) * ( <NUM_LIT:1.> + NUGGET ) <EOL> corr = squareform ( self . corr ( theta , D ) ) <EOL> R = R + corr <EOL> return R <EOL> def fit ( self , X , y , <EOL> initial_range = INITIAL_RANGE_DEFAULT , tol = TOLERANCE_DEFAULT ) : <EOL> """<STR_LIT>""" <EOL> self . _check_list_structure ( X , y ) <EOL> self . _check_params ( ) <EOL> X = self . X <EOL> y = self . y <EOL> nlevel = self . nlevel <EOL> n_samples = self . n_samples <EOL> self . beta = nlevel * [ <NUM_LIT:0> ] <EOL> self . beta_rho = nlevel * [ None ] <EOL> self . beta_regr = nlevel * [ None ] <EOL> self . C = nlevel * [ <NUM_LIT:0> ] <EOL> self . D = nlevel * [ <NUM_LIT:0> ] <EOL> self . F = nlevel * [ <NUM_LIT:0> ] <EOL> self . p = nlevel * [ <NUM_LIT:0> ] <EOL> self . q = nlevel * [ <NUM_LIT:0> ] <EOL> self . G = nlevel * [ <NUM_LIT:0> ] <EOL> self . sigma2 = nlevel * [ <NUM_LIT:0> ] <EOL> self . _R_adj = nlevel * [ None ] <EOL> y_best = y [ nlevel - <NUM_LIT:1> ] <EOL> for i in range ( nlevel - <NUM_LIT:1> ) [ : : - <NUM_LIT:1> ] : <EOL> y_best = np . concatenate ( ( y [ i ] [ : - n_samples [ i + <NUM_LIT:1> ] ] , y_best ) ) <EOL> self . y_best = y_best <EOL> self . y_mean = np . zeros ( <NUM_LIT:1> ) <EOL> self . y_std = np . ones ( <NUM_LIT:1> ) <EOL> self . X_mean = np . zeros ( <NUM_LIT:1> ) <EOL> self . X_std = np . ones ( <NUM_LIT:1> ) <EOL> for lvl in range ( nlevel ) : <EOL> self . D [ lvl ] = l1_cross_distances ( X [ lvl ] ) <EOL> if ( np . min ( np . sum ( self . D [ lvl ] , axis = <NUM_LIT:1> ) ) == <NUM_LIT:0.> ) : <EOL> raise Exception ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> self . F [ lvl ] = self . regr ( X [ lvl ] ) <EOL> self . p [ lvl ] = self . F [ lvl ] . shape [ <NUM_LIT:1> ] <EOL> if lvl > <NUM_LIT:0> : <EOL> F_rho = self . rho_regr ( X [ lvl ] ) <EOL> self . q [ lvl ] = F_rho . shape [ <NUM_LIT:1> ] <EOL> self . F [ lvl ] = np . hstack ( ( F_rho * np . dot ( ( self . y [ lvl - <NUM_LIT:1> ] ) [ - n_samples [ lvl ] : ] , <EOL> np . ones ( ( <NUM_LIT:1> , self . q [ lvl ] ) ) ) , self . F [ lvl ] ) ) <EOL> else : <EOL> self . q [ lvl ] = <NUM_LIT:0> <EOL> n_samples_F_i = self . F [ lvl ] . shape [ <NUM_LIT:0> ] <EOL> if n_samples_F_i != n_samples [ lvl ] : <EOL> raise Exception ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> if int ( self . p [ lvl ] + self . q [ lvl ] ) >= n_samples_F_i : <EOL> raise Exception ( ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> % ( n_samples [ i ] , self . p [ lvl ] + self . q [ lvl ] ) ) <EOL> self . X = X <EOL> self . y = y <EOL> self . rlf_value = np . zeros ( nlevel ) <EOL> for lvl in range ( nlevel ) : <EOL> if self . theta [ lvl ] is None : <EOL> sol = self . _max_rlf ( lvl = lvl , initial_range = initial_range , tol = tol ) <EOL> self . theta [ lvl ] = sol [ '<STR_LIT>' ] <EOL> self . rlf_value [ lvl ] = sol [ '<STR_LIT>' ] <EOL> if np . isinf ( self . rlf_value [ lvl ] ) : <EOL> raise Exception ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> else : <EOL> self . rlf_value [ lvl ] = self . rlf ( lvl = lvl ) <EOL> if np . isinf ( self . rlf_value [ lvl ] ) : <EOL> raise Exception ( "<STR_LIT>" ) <EOL> return <EOL> def rlf ( self , lvl , theta = None ) : <EOL> """<STR_LIT>""" <EOL> if theta is None : <EOL> theta = self . theta [ lvl ] <EOL> rlf_value = <NUM_LIT> <EOL> n_samples = self . n_samples [ lvl ] <EOL> y = self . y [ lvl ] <EOL> F = self . F [ lvl ] <EOL> p = self . p [ lvl ] <EOL> q = self . q [ lvl ] <EOL> R = self . _build_R ( lvl , theta ) <EOL> try : <EOL> C = linalg . cholesky ( R , lower = True ) <EOL> except linalg . LinAlgError : <EOL> _logger . warning ( ( '<STR_LIT>' % lvl ) + <EOL> '<STR_LIT>' + str ( theta ) ) <EOL> return rlf_value <EOL> Ft = solve_triangular ( C , F , lower = True ) <EOL> Yt = solve_triangular ( C , y , lower = True ) <EOL> try : <EOL> Q , G = linalg . qr ( Ft , econ = True ) <EOL> except : <EOL> Q , G = linalg . qr ( Ft , mode = '<STR_LIT>' ) <EOL> pass <EOL> beta = solve_triangular ( G , np . dot ( Q . T , Yt ) ) <EOL> err = Yt - np . dot ( Ft , beta ) <EOL> err2 = np . dot ( err . T , err ) [ <NUM_LIT:0> , <NUM_LIT:0> ] <EOL> self . _err = err <EOL> sigma2 = err2 / ( n_samples - p - q ) <EOL> detR = ( ( np . diag ( C ) ) ** ( <NUM_LIT> / n_samples ) ) . prod ( ) <EOL> rlf_value = ( n_samples - p - q ) * np . log10 ( sigma2 ) + n_samples * np . log10 ( detR ) <EOL> self . beta_rho [ lvl ] = beta [ : q ] <EOL> self . beta_regr [ lvl ] = beta [ q : ] <EOL> self . beta [ lvl ] = beta <EOL> self . sigma2 [ lvl ] = sigma2 <EOL> self . C [ lvl ] = C <EOL> self . G [ lvl ] = G <EOL> return rlf_value <EOL> def _max_rlf ( self , lvl , initial_range , tol ) : <EOL> """<STR_LIT>""" <EOL> thetaL = self . thetaL [ lvl ] <EOL> thetaU = self . thetaU [ lvl ] <EOL> def rlf_transform ( x ) : <EOL> return self . rlf ( theta = <NUM_LIT> ** x , lvl = lvl ) <EOL> theta0 = self . theta0 [ lvl ] <EOL> x0 = np . log10 ( theta0 [ <NUM_LIT:0> ] ) <EOL> constraints = [ ] <EOL> for i in range ( theta0 . size ) : <EOL> constraints . append ( { '<STR_LIT:type>' : '<STR_LIT>' , '<STR_LIT>' : lambda log10t , i = i : <EOL> log10t [ i ] - np . log10 ( thetaL [ <NUM_LIT:0> ] [ i ] ) } ) <EOL> constraints . append ( { '<STR_LIT:type>' : '<STR_LIT>' , '<STR_LIT>' : lambda log10t , i = i : <EOL> np . log10 ( thetaU [ <NUM_LIT:0> ] [ i ] ) - log10t [ i ] } ) <EOL> constraints = tuple ( constraints ) <EOL> sol = minimize ( rlf_transform , x0 , method = '<STR_LIT>' , <EOL> constraints = constraints , <EOL> options = { '<STR_LIT>' : initial_range , <EOL> '<STR_LIT>' : tol , '<STR_LIT>' : <NUM_LIT:0> } ) <EOL> log10_optimal_x = sol [ '<STR_LIT:x>' ] <EOL> optimal_rlf_value = sol [ '<STR_LIT>' ] <EOL> self . _nfev += sol [ '<STR_LIT>' ] <EOL> optimal_theta = <NUM_LIT> ** log10_optimal_x <EOL> res = { } <EOL> res [ '<STR_LIT>' ] = optimal_theta <EOL> res [ '<STR_LIT>' ] = optimal_rlf_value <EOL> return res <EOL> def predict ( self , X , eval_MSE = True ) : <EOL> """<STR_LIT>""" <EOL> X = array2d ( X ) <EOL> nlevel = self . nlevel <EOL> n_eval , n_features_X = X . shape <EOL> mu = np . zeros ( ( n_eval , nlevel ) ) <EOL> f = self . regr ( X ) <EOL> f0 = self . regr ( X ) <EOL> dx = l1_cross_distances ( X , Y = self . X [ <NUM_LIT:0> ] ) <EOL> F = self . F [ <NUM_LIT:0> ] <EOL> C = self . C [ <NUM_LIT:0> ] <EOL> beta = self . beta [ <NUM_LIT:0> ] <EOL> Ft = solve_triangular ( C , F , lower = True ) <EOL> yt = solve_triangular ( C , self . y [ <NUM_LIT:0> ] , lower = True ) <EOL> r_ = self . corr ( self . theta [ <NUM_LIT:0> ] , dx ) . reshape ( n_eval , self . n_samples [ <NUM_LIT:0> ] ) <EOL> gamma = solve_triangular ( C . T , yt - np . dot ( Ft , beta ) , lower = False ) <EOL> mu [ : , <NUM_LIT:0> ] = ( np . dot ( f , beta ) + np . dot ( r_ , gamma ) ) . ravel ( ) <EOL> if eval_MSE : <EOL> self . sigma2_rho = nlevel * [ None ] <EOL> MSE = np . zeros ( ( n_eval , nlevel ) ) <EOL> r_t = solve_triangular ( C , r_ . T , lower = True ) <EOL> G = self . G [ <NUM_LIT:0> ] <EOL> u_ = solve_triangular ( G . T , f . T - np . dot ( Ft . T , r_t ) , lower = True ) <EOL> MSE [ : , <NUM_LIT:0> ] = self . sigma2 [ <NUM_LIT:0> ] * ( <NUM_LIT:1> - ( r_t ** <NUM_LIT:2> ) . sum ( axis = <NUM_LIT:0> ) + ( u_ ** <NUM_LIT:2> ) . sum ( axis = <NUM_LIT:0> ) ) <EOL> for i in range ( <NUM_LIT:1> , nlevel ) : <EOL> C = self . C [ i ] <EOL> F = self . F [ i ] <EOL> g = self . rho_regr ( X ) <EOL> dx = l1_cross_distances ( X , Y = self . X [ i ] ) <EOL> r_ = self . corr ( self . theta [ i ] , dx ) . reshape ( n_eval , self . n_samples [ i ] ) <EOL> f = np . vstack ( ( g . T * mu [ : , i - <NUM_LIT:1> ] , f0 . T ) ) <EOL> Ft = solve_triangular ( C , F , lower = True ) <EOL> yt = solve_triangular ( C , self . y [ i ] , lower = True ) <EOL> r_t = solve_triangular ( C , r_ . T , lower = True ) <EOL> G = self . G [ i ] <EOL> beta = self . beta [ i ] <EOL> mu [ : , i ] = ( np . dot ( f . T , beta ) + np . dot ( r_t . T , yt - np . dot ( Ft , beta ) ) ) . ravel ( ) <EOL> if eval_MSE : <EOL> Q_ = ( np . dot ( ( yt - np . dot ( Ft , beta ) ) . T , yt - np . dot ( Ft , beta ) ) ) [ <NUM_LIT:0> , <NUM_LIT:0> ] <EOL> u_ = solve_triangular ( G . T , f - np . dot ( Ft . T , r_t ) , lower = True ) <EOL> sigma2_rho = np . dot ( g , self . sigma2 [ i ] * linalg . inv ( np . dot ( G . T , G ) ) [ : self . q [ i ] , : self . q [ i ] ] + np . dot ( beta [ : self . q [ i ] ] , beta [ : self . q [ i ] ] . T ) ) <EOL> sigma2_rho = ( sigma2_rho * g ) . sum ( axis = <NUM_LIT:1> ) <EOL> MSE [ : , i ] = sigma2_rho * MSE [ : , i - <NUM_LIT:1> ] + Q_ / ( <NUM_LIT:2> * ( self . n_samples [ i ] - self . p [ i ] - self . q [ i ] ) ) * ( <NUM_LIT:1> - ( r_t ** <NUM_LIT:2> ) . sum ( axis = <NUM_LIT:0> ) ) + self . sigma2 [ i ] * ( u_ ** <NUM_LIT:2> ) . sum ( axis = <NUM_LIT:0> ) <EOL> for i in range ( nlevel ) : <EOL> mu [ : , i ] = self . y_mean + self . y_std * mu [ : , i ] <EOL> if eval_MSE : <EOL> MSE [ : , i ] = self . y_std ** <NUM_LIT:2> * MSE [ : , i ] <EOL> if eval_MSE : <EOL> return mu [ : , - <NUM_LIT:1> ] . reshape ( ( n_eval , <NUM_LIT:1> ) ) , MSE [ : , - <NUM_LIT:1> ] . reshape ( ( n_eval , <NUM_LIT:1> ) ) <EOL> else : <EOL> return mu [ : , - <NUM_LIT:1> ] . reshape ( ( n_eval , <NUM_LIT:1> ) ) <EOL> def _check_list_structure ( self , X , y ) : <EOL> if type ( X ) is not list : <EOL> nlevel = <NUM_LIT:1> <EOL> X = [ X ] <EOL> else : <EOL> nlevel = len ( X ) <EOL> if type ( y ) is not list : <EOL> y = [ y ] <EOL> if len ( X ) != len ( y ) : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> n_samples = np . zeros ( nlevel , dtype = int ) <EOL> n_features = np . zeros ( nlevel , dtype = int ) <EOL> n_samples_y = np . zeros ( nlevel , dtype = int ) <EOL> for i in range ( nlevel ) : <EOL> n_samples [ i ] , n_features [ i ] = X [ i ] . shape <EOL> if i > <NUM_LIT:1> and n_features [ i ] != n_features [ i - <NUM_LIT:1> ] : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> y [ i ] = np . asarray ( y [ i ] ) . ravel ( ) [ : , np . newaxis ] <EOL> n_samples_y [ i ] = y [ i ] . shape [ <NUM_LIT:0> ] <EOL> if n_samples [ i ] != n_samples_y [ i ] : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> self . n_features = n_features [ <NUM_LIT:0> ] <EOL> if type ( self . theta ) is not list : <EOL> self . theta = nlevel * [ self . theta ] <EOL> elif len ( self . theta ) != nlevel : <EOL> raise ValueError ( "<STR_LIT>" % nlevel ) <EOL> if type ( self . theta0 ) is not list : <EOL> self . theta0 = nlevel * [ self . theta0 ] <EOL> elif len ( self . theta0 ) != nlevel : <EOL> raise ValueError ( "<STR_LIT>" % nlevel ) <EOL> if type ( self . thetaL ) is not list : <EOL> self . thetaL = nlevel * [ self . thetaL ] <EOL> elif len ( self . thetaL ) != nlevel : <EOL> raise ValueError ( "<STR_LIT>" % nlevel ) <EOL> if type ( self . thetaU ) is not list : <EOL> self . thetaU = nlevel * [ self . thetaU ] <EOL> elif len ( self . thetaU ) != nlevel : <EOL> raise ValueError ( "<STR_LIT>" % nlevel ) <EOL> self . nlevel = nlevel <EOL> self . X = X [ : ] <EOL> self . y = y [ : ] <EOL> self . n_samples = n_samples <EOL> return <EOL> def _check_params ( self ) : <EOL> if not callable ( self . regr ) : <EOL> if self . regr in self . _regression_types : <EOL> self . regr = self . _regression_types [ self . regr ] <EOL> else : <EOL> raise ValueError ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> % ( self . _regression_types . keys ( ) , self . regr ) ) <EOL> if not callable ( self . rho_regr ) : <EOL> if self . rho_regr in self . _regression_types : <EOL> self . rho_regr = self . _regression_types [ self . rho_regr ] <EOL> else : <EOL> raise ValueError ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> % ( self . _regression_types . keys ( ) , self . rho_regr ) ) <EOL> for i in range ( self . nlevel ) : <EOL> if self . theta [ i ] is not None : <EOL> self . theta [ i ] = array2d ( self . theta [ i ] ) <EOL> if np . any ( self . theta [ i ] <= <NUM_LIT:0> ) : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> if self . theta0 [ i ] is not None : <EOL> self . theta0 [ i ] = array2d ( self . theta0 [ i ] ) <EOL> if np . any ( self . theta0 [ i ] <= <NUM_LIT:0> ) : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> else : <EOL> self . theta0 [ i ] = array2d ( self . n_features * [ THETA0_DEFAULT ] ) <EOL> lth = self . theta0 [ i ] . size <EOL> if self . thetaL [ i ] is not None : <EOL> self . thetaL [ i ] = array2d ( self . thetaL [ i ] ) <EOL> if self . thetaL [ i ] . size != lth : <EOL> raise ValueError ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> else : <EOL> self . thetaL [ i ] = array2d ( self . n_features * [ THETAL_DEFAULT ] ) <EOL> if self . thetaU [ i ] is not None : <EOL> self . thetaU [ i ] = array2d ( self . thetaU [ i ] ) <EOL> if self . thetaU [ i ] . size != lth : <EOL> raise ValueError ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> else : <EOL> self . thetaU [ i ] = array2d ( self . n_features * [ THETAU_DEFAULT ] ) <EOL> if np . any ( self . thetaL [ i ] <= <NUM_LIT:0> ) or np . any ( self . thetaU [ i ] < self . thetaL [ i ] ) : <EOL> raise ValueError ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> return <EOL> class MultiFiCoKrigingSurrogate ( MultiFiSurrogateModel ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , regr = '<STR_LIT>' , rho_regr = '<STR_LIT>' , <EOL> theta = None , theta0 = None , thetaL = None , thetaU = None , <EOL> tolerance = TOLERANCE_DEFAULT , initial_range = INITIAL_RANGE_DEFAULT ) : <EOL> super ( MultiFiCoKrigingSurrogate , self ) . __init__ ( ) <EOL> self . tolerance = tolerance <EOL> self . initial_range = initial_range <EOL> self . model = MultiFiCoKriging ( regr = regr , rho_regr = rho_regr , theta = theta , <EOL> theta0 = theta0 , thetaL = thetaL , thetaU = thetaU ) <EOL> def predict ( self , new_x ) : <EOL> """<STR_LIT>""" <EOL> Y_pred , MSE = self . model . predict ( [ new_x ] ) <EOL> return Y_pred , np . sqrt ( np . abs ( MSE ) ) <EOL> def train_multifi ( self , X , Y ) : <EOL> """<STR_LIT>""" <EOL> X , Y = self . _fit_adapter ( X , Y ) <EOL> self . model . fit ( X , Y , tol = self . tolerance , initial_range = self . initial_range ) <EOL> def _fit_adapter ( self , X , Y ) : <EOL> if len ( np . shape ( np . array ( X [ <NUM_LIT:0> ] ) ) ) == <NUM_LIT:1> : <EOL> X = [ X ] <EOL> Y = [ Y ] <EOL> X = [ np . array ( x ) for x in reversed ( X ) ] <EOL> Y = [ np . array ( y ) for y in reversed ( Y ) ] <EOL> return ( X , Y ) <EOL> class FloatMultiFiCoKrigingSurrogate ( MultiFiCoKrigingSurrogate ) : <EOL> """<STR_LIT>""" <EOL> def predict ( self , new_x ) : <EOL> dist = super ( FloatMultiFiCoKrigingSurrogate , self ) . predict ( new_x ) <EOL> return dist . mu <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> import doctest <EOL> doctest . testmod ( ) </s>
<s> """<STR_LIT>""" <EOL> from __future__ import print_function <EOL> import re <EOL> from six . moves import range <EOL> from pyparsing import CaselessLiteral , Combine , OneOrMore , Optional , TokenConverter , Word , nums , oneOf , printables , ParserElement , alphanums <EOL> import numpy as np <EOL> __all__ = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> def _getformat ( val ) : <EOL> if int ( val ) == val : <EOL> return "<STR_LIT>" <EOL> else : <EOL> return "<STR_LIT>" <EOL> class _SubHelper ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self ) : <EOL> self . newtext = "<STR_LIT>" <EOL> self . replace_location = <NUM_LIT:0> <EOL> self . current_location = <NUM_LIT:0> <EOL> self . counter = <NUM_LIT:0> <EOL> self . start_location = <NUM_LIT:0> <EOL> self . end_location = <NUM_LIT:0> <EOL> def set ( self , newtext , location ) : <EOL> """<STR_LIT>""" <EOL> self . newtext = newtext <EOL> self . replace_location = location <EOL> self . current_location = <NUM_LIT:0> <EOL> def set_array ( self , newtext , start_location , end_location ) : <EOL> """<STR_LIT>""" <EOL> self . newtext = newtext <EOL> self . start_location = start_location <EOL> self . end_location = end_location <EOL> self . current_location = <NUM_LIT:0> <EOL> def replace ( self , text ) : <EOL> """<STR_LIT>""" <EOL> self . current_location += <NUM_LIT:1> <EOL> if self . current_location == self . replace_location : <EOL> if isinstance ( self . newtext , float ) : <EOL> return _getformat ( self . newtext ) % self . newtext <EOL> else : <EOL> return str ( self . newtext ) <EOL> else : <EOL> return text . group ( ) <EOL> def replace_array ( self , text ) : <EOL> """<STR_LIT>""" <EOL> self . current_location += <NUM_LIT:1> <EOL> end = len ( self . newtext ) <EOL> if self . current_location >= self . start_location and self . current_location <= self . end_location and self . counter < end : <EOL> if isinstance ( self . newtext [ self . counter ] , float ) : <EOL> val = self . newtext [ self . counter ] <EOL> newval = _getformat ( val ) % val <EOL> else : <EOL> newval = str ( self . newtext [ self . counter ] ) <EOL> self . counter += <NUM_LIT:1> <EOL> return newval <EOL> else : <EOL> return text . group ( ) <EOL> class ToInteger ( TokenConverter ) : <EOL> """<STR_LIT>""" <EOL> def postParse ( self , instring , loc , tokenlist ) : <EOL> """<STR_LIT>""" <EOL> return int ( tokenlist [ <NUM_LIT:0> ] ) <EOL> class ToFloat ( TokenConverter ) : <EOL> """<STR_LIT>""" <EOL> def postParse ( self , instring , loc , tokenlist ) : <EOL> """<STR_LIT>""" <EOL> return float ( tokenlist [ <NUM_LIT:0> ] . replace ( '<STR_LIT:D>' , '<STR_LIT:E>' ) ) <EOL> class ToNan ( TokenConverter ) : <EOL> """<STR_LIT>""" <EOL> def postParse ( self , instring , loc , tokenlist ) : <EOL> """<STR_LIT>""" <EOL> return float ( '<STR_LIT>' ) <EOL> class ToInf ( TokenConverter ) : <EOL> """<STR_LIT>""" <EOL> def postParse ( self , instring , loc , tokenlist ) : <EOL> """<STR_LIT>""" <EOL> return float ( '<STR_LIT>' ) <EOL> class InputFileGenerator ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self ) : <EOL> self . template_filename = [ ] <EOL> self . output_filename = [ ] <EOL> self . delimiter = "<STR_LIT:U+0020>" <EOL> self . reg = re . compile ( '<STR_LIT>' ) <EOL> self . data = [ ] <EOL> self . current_row = <NUM_LIT:0> <EOL> self . anchored = False <EOL> def set_template_file ( self , filename ) : <EOL> """<STR_LIT>""" <EOL> self . template_filename = filename <EOL> templatefile = open ( filename , '<STR_LIT:r>' ) <EOL> self . data = templatefile . readlines ( ) <EOL> templatefile . close ( ) <EOL> def set_generated_file ( self , filename ) : <EOL> """<STR_LIT>""" <EOL> self . output_filename = filename <EOL> def set_delimiters ( self , delimiter ) : <EOL> """<STR_LIT>""" <EOL> self . delimiter = delimiter <EOL> self . reg = re . compile ( '<STR_LIT>' + delimiter + '<STR_LIT>' ) <EOL> def mark_anchor ( self , anchor , occurrence = <NUM_LIT:1> ) : <EOL> """<STR_LIT>""" <EOL> if not isinstance ( occurrence , int ) : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> instance = <NUM_LIT:0> <EOL> if occurrence > <NUM_LIT:0> : <EOL> count = <NUM_LIT:0> <EOL> max_lines = len ( self . data ) <EOL> for index in range ( self . current_row , max_lines ) : <EOL> line = self . data [ index ] <EOL> if count == <NUM_LIT:0> and self . anchored : <EOL> line = line . split ( anchor ) [ - <NUM_LIT:1> ] <EOL> if line . find ( anchor ) > - <NUM_LIT:1> : <EOL> instance += <NUM_LIT:1> <EOL> if instance == occurrence : <EOL> self . current_row += count <EOL> self . anchored = True <EOL> return <EOL> count += <NUM_LIT:1> <EOL> elif occurrence < <NUM_LIT:0> : <EOL> max_lines = len ( self . data ) - <NUM_LIT:1> <EOL> count = max_lines <EOL> for index in range ( max_lines , - <NUM_LIT:1> , - <NUM_LIT:1> ) : <EOL> line = self . data [ index ] <EOL> if count == max_lines and self . anchored : <EOL> line = line . split ( anchor ) [ <NUM_LIT:0> ] <EOL> if line . find ( anchor ) > - <NUM_LIT:1> : <EOL> instance += - <NUM_LIT:1> <EOL> if instance == occurrence : <EOL> self . current_row = count <EOL> self . anchored = True <EOL> return <EOL> count -= <NUM_LIT:1> <EOL> else : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> raise RuntimeError ( "<STR_LIT>" % ( anchor , self . template_filename ) ) <EOL> def reset_anchor ( self ) : <EOL> """<STR_LIT>""" <EOL> self . current_row = <NUM_LIT:0> <EOL> self . anchored = False <EOL> def transfer_var ( self , value , row , field ) : <EOL> """<STR_LIT>""" <EOL> j = self . current_row + row <EOL> line = self . data [ j ] <EOL> sub = _SubHelper ( ) <EOL> sub . set ( value , field ) <EOL> newline = re . sub ( self . reg , sub . replace , line ) <EOL> self . data [ j ] = newline <EOL> def transfer_array ( self , value , row_start , field_start , field_end , <EOL> row_end = None , sep = "<STR_LIT:U+002CU+0020>" ) : <EOL> """<STR_LIT>""" <EOL> if row_end is None : <EOL> row_end = row_start <EOL> sub = _SubHelper ( ) <EOL> for row in range ( row_start , row_end + <NUM_LIT:1> ) : <EOL> j = self . current_row + row <EOL> line = self . data [ j ] <EOL> if row == row_end : <EOL> f_end = field_end <EOL> else : <EOL> f_end = <NUM_LIT> <EOL> sub . set_array ( value , field_start , f_end ) <EOL> field_start = <NUM_LIT:0> <EOL> newline = re . sub ( self . reg , sub . replace_array , line ) <EOL> self . data [ j ] = newline <EOL> if sub . counter < len ( value ) : <EOL> for val in value [ sub . counter : ] : <EOL> newline = newline . rstrip ( ) + sep + str ( val ) <EOL> self . data [ j ] = newline <EOL> elif sub . counter > len ( value ) : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> self . data [ j ] += "<STR_LIT:\n>" <EOL> def transfer_2Darray ( self , value , row_start , row_end , field_start , <EOL> field_end ) : <EOL> """<STR_LIT>""" <EOL> sub = _SubHelper ( ) <EOL> i = <NUM_LIT:0> <EOL> for row in range ( row_start , row_end + <NUM_LIT:1> ) : <EOL> j = self . current_row + row <EOL> line = self . data [ j ] <EOL> sub . set_array ( value [ i , : ] , field_start , field_end ) <EOL> newline = re . sub ( self . reg , sub . replace_array , line ) <EOL> self . data [ j ] = newline <EOL> sub . current_location = <NUM_LIT:0> <EOL> sub . counter = <NUM_LIT:0> <EOL> i += <NUM_LIT:1> <EOL> def clearline ( self , row ) : <EOL> """<STR_LIT>""" <EOL> self . data [ self . current_row + row ] = "<STR_LIT:\n>" <EOL> def generate ( self ) : <EOL> """<STR_LIT>""" <EOL> infile = open ( self . output_filename , '<STR_LIT:w>' ) <EOL> infile . writelines ( self . data ) <EOL> infile . close ( ) <EOL> class FileParser ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , end_of_line_comment_char = None , full_line_comment_char = None ) : <EOL> self . filename = [ ] <EOL> self . data = [ ] <EOL> self . delimiter = "<STR_LIT>" <EOL> self . end_of_line_comment_char = end_of_line_comment_char <EOL> self . full_line_comment_char = full_line_comment_char <EOL> self . current_row = <NUM_LIT:0> <EOL> self . anchored = False <EOL> self . set_delimiters ( self . delimiter ) <EOL> def set_file ( self , filename ) : <EOL> """<STR_LIT>""" <EOL> self . filename = filename <EOL> inputfile = open ( filename , '<STR_LIT:r>' ) <EOL> if not self . end_of_line_comment_char and not self . full_line_comment_char : <EOL> self . data = inputfile . readlines ( ) <EOL> else : <EOL> self . data = [ ] <EOL> for line in inputfile : <EOL> if line [ <NUM_LIT:0> ] == self . full_line_comment_char : <EOL> continue <EOL> self . data . append ( line . split ( self . end_of_line_comment_char ) [ <NUM_LIT:0> ] ) <EOL> inputfile . close ( ) <EOL> def set_delimiters ( self , delimiter ) : <EOL> """<STR_LIT>""" <EOL> self . delimiter = delimiter <EOL> if delimiter != "<STR_LIT>" : <EOL> ParserElement . setDefaultWhitespaceChars ( str ( delimiter ) ) <EOL> self . _reset_tokens ( ) <EOL> def mark_anchor ( self , anchor , occurrence = <NUM_LIT:1> ) : <EOL> """<STR_LIT>""" <EOL> if not isinstance ( occurrence , int ) : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> instance = <NUM_LIT:0> <EOL> if occurrence > <NUM_LIT:0> : <EOL> count = <NUM_LIT:0> <EOL> max_lines = len ( self . data ) <EOL> for index in range ( self . current_row , max_lines ) : <EOL> line = self . data [ index ] <EOL> if count == <NUM_LIT:0> and self . anchored : <EOL> line = line . split ( anchor ) [ - <NUM_LIT:1> ] <EOL> if anchor in line : <EOL> instance += <NUM_LIT:1> <EOL> if instance == occurrence : <EOL> self . current_row += count <EOL> self . anchored = True <EOL> return <EOL> count += <NUM_LIT:1> <EOL> elif occurrence < <NUM_LIT:0> : <EOL> max_lines = len ( self . data ) - <NUM_LIT:1> <EOL> count = max_lines <EOL> for index in range ( max_lines , - <NUM_LIT:1> , - <NUM_LIT:1> ) : <EOL> line = self . data [ index ] <EOL> if count == max_lines and self . anchored : <EOL> line = line . split ( anchor ) [ <NUM_LIT:0> ] <EOL> if anchor in line : <EOL> instance += - <NUM_LIT:1> <EOL> if instance == occurrence : <EOL> self . current_row = count <EOL> self . anchored = True <EOL> return <EOL> count -= <NUM_LIT:1> <EOL> else : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> raise RuntimeError ( "<STR_LIT>" % ( anchor , self . filename ) ) <EOL> def reset_anchor ( self ) : <EOL> """<STR_LIT>""" <EOL> self . current_row = <NUM_LIT:0> <EOL> self . anchored = False <EOL> def transfer_line ( self , row ) : <EOL> """<STR_LIT>""" <EOL> return self . data [ self . current_row + row ] . rstrip ( ) <EOL> def transfer_var ( self , row , field , fieldend = None ) : <EOL> """<STR_LIT>""" <EOL> j = self . current_row + row <EOL> line = self . data [ j ] <EOL> if self . delimiter == "<STR_LIT>" : <EOL> if not fieldend : <EOL> line = line [ ( field - <NUM_LIT:1> ) : ] <EOL> else : <EOL> line = line [ ( field - <NUM_LIT:1> ) : ( fieldend ) ] <EOL> data = self . _parse_line ( ) . parseString ( line ) <EOL> if len ( data ) > <NUM_LIT:1> : <EOL> return line <EOL> else : <EOL> return data [ <NUM_LIT:0> ] <EOL> else : <EOL> data = self . _parse_line ( ) . parseString ( line ) <EOL> return data [ field - <NUM_LIT:1> ] <EOL> def transfer_keyvar ( self , key , field , occurrence = <NUM_LIT:1> , rowoffset = <NUM_LIT:0> ) : <EOL> """<STR_LIT>""" <EOL> if not isinstance ( occurrence , int ) or occurrence == <NUM_LIT:0> : <EOL> msg = "<STR_LIT>" <EOL> raise ValueError ( msg ) <EOL> instance = <NUM_LIT:0> <EOL> if occurrence > <NUM_LIT:0> : <EOL> row = <NUM_LIT:0> <EOL> for line in self . data [ self . current_row : ] : <EOL> if line . find ( key ) > - <NUM_LIT:1> : <EOL> instance += <NUM_LIT:1> <EOL> if instance == occurrence : <EOL> break <EOL> row += <NUM_LIT:1> <EOL> elif occurrence < <NUM_LIT:0> : <EOL> row = - <NUM_LIT:1> <EOL> for line in reversed ( self . data [ self . current_row : ] ) : <EOL> if line . find ( key ) > - <NUM_LIT:1> : <EOL> instance += - <NUM_LIT:1> <EOL> if instance == occurrence : <EOL> break <EOL> row -= <NUM_LIT:1> <EOL> j = self . current_row + row + rowoffset <EOL> line = self . data [ j ] <EOL> fields = self . _parse_line ( ) . parseString ( line . replace ( key , "<STR_LIT>" ) ) <EOL> return fields [ field ] <EOL> def transfer_array ( self , rowstart , fieldstart , rowend = None , fieldend = None ) : <EOL> """<STR_LIT>""" <EOL> j1 = self . current_row + rowstart <EOL> if rowend is None : <EOL> j2 = j1 + <NUM_LIT:1> <EOL> else : <EOL> j2 = self . current_row + rowend + <NUM_LIT:1> <EOL> if not fieldend : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> lines = self . data [ j1 : j2 ] <EOL> data = np . zeros ( shape = ( <NUM_LIT:0> , <NUM_LIT:0> ) ) <EOL> for i , line in enumerate ( lines ) : <EOL> if self . delimiter == "<STR_LIT>" : <EOL> line = line [ ( fieldstart - <NUM_LIT:1> ) : fieldend ] <EOL> line = line . strip ( ) <EOL> parsed = self . _parse_line ( ) . parseString ( line ) <EOL> newdata = np . array ( parsed [ : ] ) <EOL> if newdata . dtype . type is np . str_ : <EOL> newdata = np . array ( line ) <EOL> data = np . append ( data , newdata ) <EOL> else : <EOL> parsed = self . _parse_line ( ) . parseString ( line ) <EOL> if i == j2 - j1 - <NUM_LIT:1> : <EOL> data = np . append ( data , np . array ( parsed [ ( fieldstart - <NUM_LIT:1> ) : fieldend ] ) ) <EOL> else : <EOL> data = np . append ( data , np . array ( parsed [ ( fieldstart - <NUM_LIT:1> ) : ] ) ) <EOL> fieldstart = <NUM_LIT:1> <EOL> return data <EOL> def transfer_2Darray ( self , rowstart , fieldstart , rowend , fieldend = None ) : <EOL> """<STR_LIT>""" <EOL> if fieldend and ( fieldstart > fieldend ) : <EOL> msg = "<STR_LIT>" <EOL> raise ValueError ( msg ) <EOL> if rowstart > rowend : <EOL> msg = "<STR_LIT>" <EOL> raise ValueError ( msg ) <EOL> j1 = self . current_row + rowstart <EOL> j2 = self . current_row + rowend + <NUM_LIT:1> <EOL> lines = list ( self . data [ j1 : j2 ] ) <EOL> if self . delimiter == "<STR_LIT>" : <EOL> if fieldend : <EOL> line = lines [ <NUM_LIT:0> ] [ ( fieldstart - <NUM_LIT:1> ) : fieldend ] <EOL> else : <EOL> line = lines [ <NUM_LIT:0> ] [ ( fieldstart - <NUM_LIT:1> ) : ] <EOL> parsed = self . _parse_line ( ) . parseString ( line ) <EOL> row = np . array ( parsed [ : ] ) <EOL> data = np . zeros ( shape = ( abs ( j2 - j1 ) , len ( row ) ) ) <EOL> data [ <NUM_LIT:0> , : ] = row <EOL> for i , line in enumerate ( list ( lines [ <NUM_LIT:1> : ] ) ) : <EOL> if fieldend : <EOL> line = line [ ( fieldstart - <NUM_LIT:1> ) : fieldend ] <EOL> else : <EOL> line = line [ ( fieldstart - <NUM_LIT:1> ) : ] <EOL> parsed = self . _parse_line ( ) . parseString ( line ) <EOL> data [ i + <NUM_LIT:1> , : ] = np . array ( parsed [ : ] ) <EOL> else : <EOL> parsed = self . _parse_line ( ) . parseString ( lines [ <NUM_LIT:0> ] ) <EOL> if fieldend : <EOL> row = np . array ( parsed [ ( fieldstart - <NUM_LIT:1> ) : fieldend ] ) <EOL> else : <EOL> row = np . array ( parsed [ ( fieldstart - <NUM_LIT:1> ) : ] ) <EOL> data = np . zeros ( shape = ( abs ( j2 - j1 ) , len ( row ) ) ) <EOL> data [ <NUM_LIT:0> , : ] = row <EOL> for i , line in enumerate ( list ( lines [ <NUM_LIT:1> : ] ) ) : <EOL> parsed = self . _parse_line ( ) . parseString ( line ) <EOL> if fieldend : <EOL> try : <EOL> data [ i + <NUM_LIT:1> , : ] = np . array ( parsed [ ( fieldstart - <NUM_LIT:1> ) : fieldend ] ) <EOL> except : <EOL> print ( data ) <EOL> else : <EOL> data [ i + <NUM_LIT:1> , : ] = np . array ( parsed [ ( fieldstart - <NUM_LIT:1> ) : ] ) <EOL> return data <EOL> def _parse_line ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . line_parse_token <EOL> def _reset_tokens ( self ) : <EOL> """<STR_LIT>""" <EOL> if self . delimiter . isspace ( ) : <EOL> textchars = printables <EOL> else : <EOL> textchars = alphanums <EOL> symbols = [ '<STR_LIT:.>' , '<STR_LIT:/>' , '<STR_LIT:+>' , '<STR_LIT:*>' , '<STR_LIT>' , '<STR_LIT:(>' , '<STR_LIT:)>' , '<STR_LIT:[>' , '<STR_LIT:]>' , '<STR_LIT:=>' , <EOL> '<STR_LIT::>' , '<STR_LIT:;>' , '<STR_LIT:?>' , '<STR_LIT:%>' , '<STR_LIT:&>' , '<STR_LIT:!>' , '<STR_LIT:#>' , '<STR_LIT:|>' , '<STR_LIT:<>' , '<STR_LIT:>>' , <EOL> '<STR_LIT:{>' , '<STR_LIT:}>' , '<STR_LIT:->' , '<STR_LIT:_>' , '<STR_LIT:@>' , '<STR_LIT:$>' , '<STR_LIT>' ] <EOL> for symbol in symbols : <EOL> if symbol not in self . delimiter : <EOL> textchars = textchars + symbol <EOL> digits = Word ( nums ) <EOL> dot = "<STR_LIT:.>" <EOL> sign = oneOf ( "<STR_LIT>" ) <EOL> ee = CaselessLiteral ( '<STR_LIT:E>' ) | CaselessLiteral ( '<STR_LIT:D>' ) <EOL> num_int = ToInteger ( Combine ( Optional ( sign ) + digits ) ) <EOL> num_float = ToFloat ( Combine ( Optional ( sign ) + <EOL> ( ( digits + dot + Optional ( digits ) ) | <EOL> ( dot + digits ) ) + <EOL> Optional ( ee + Optional ( sign ) + digits ) <EOL> ) ) <EOL> mixed_exp = ToFloat ( Combine ( digits + ee + Optional ( sign ) + digits ) ) <EOL> nan = ToInf ( oneOf ( "<STR_LIT>" ) ) | ToNan ( oneOf ( "<STR_LIT>" + "<STR_LIT>" ) ) <EOL> string_text = Word ( textchars ) <EOL> self . line_parse_token = ( OneOrMore ( ( nan | num_float | mixed_exp | num_int | <EOL> string_text ) ) ) </s>
<s> from django import template <EOL> register = template . Library ( ) <EOL> @ register . filter ( name = '<STR_LIT>' ) <EOL> def get_item ( dictionary , key ) : <EOL> return getattr ( dictionary , key ) </s>
<s> """<STR_LIT>""" <EOL> import sys <EOL> import os <EOL> import time <EOL> if sys . version_info < ( <NUM_LIT:2> , <NUM_LIT:6> , <NUM_LIT:0> ) : <EOL> print ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> elif sys . version_info >= ( <NUM_LIT:3> , <NUM_LIT:0> , <NUM_LIT:0> ) : <EOL> sys . stderr . write ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> sys . exit ( <NUM_LIT:2> ) <EOL> sys . path . insert ( <NUM_LIT:0> , '<STR_LIT>' ) <EOL> sys . path . insert ( <NUM_LIT:0> , os . getcwd ( ) ) <EOL> import shutil <EOL> import optparse <EOL> import requests <EOL> import subprocess <EOL> try : <EOL> import instances_creator_conf as icc <EOL> import psycopg2 <EOL> except ImportError : <EOL> sys . stderr . write ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> sys . exit ( <NUM_LIT:3> ) <EOL> os . environ [ '<STR_LIT>' ] = icc . DB_PASSWORD <EOL> class AskbotInstance ( ) : <EOL> def __init__ ( self ) : <EOL> """<STR_LIT>""" <EOL> if not os . environ [ '<STR_LIT>' ] == '<STR_LIT:root>' : <EOL> self . abort ( '<STR_LIT>' ) <EOL> sys . path . insert ( <NUM_LIT:0> , icc . DEFAULT_INSTANCE_DIR ) <EOL> def _populate_file ( self , original_file , values ) : <EOL> """<STR_LIT>""" <EOL> f = open ( original_file , '<STR_LIT:r>' ) <EOL> file_content = f . read ( ) <EOL> f . close ( ) <EOL> populated_settings = file_content . format ( ** values ) <EOL> f = open ( original_file , '<STR_LIT:w>' ) <EOL> f . write ( populated_settings ) <EOL> f . close ( ) <EOL> def create_instance ( self , instance_name , instance_db_name ) : <EOL> """<STR_LIT>""" <EOL> INSTANCE_DIR = os . path . join ( icc . DEFAULT_INSTANCE_DIR , instance_name ) <EOL> try : <EOL> shutil . copytree ( icc . SKEL_DIR , INSTANCE_DIR ) <EOL> os . chdir ( INSTANCE_DIR ) <EOL> template = os . path . join ( INSTANCE_DIR , '<STR_LIT>' ) <EOL> os . symlink ( <EOL> os . path . join ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) , <EOL> os . path . join ( INSTANCE_DIR , '<STR_LIT>' ) ) <EOL> values = { <EOL> '<STR_LIT>' : instance_name , <EOL> '<STR_LIT>' : instance_db_name , <EOL> '<STR_LIT>' : icc . DB_HOST , <EOL> '<STR_LIT>' : icc . BASE_URL <EOL> } <EOL> self . _populate_file ( template , values ) <EOL> print ( '<STR_LIT>' . format ( instance_name ) ) <EOL> except : <EOL> self . abort ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> def create_db ( self , instance_db_name ) : <EOL> """<STR_LIT>""" <EOL> createdb = subprocess . Popen ( ( '<STR_LIT>' <EOL> '<STR_LIT>' ) % ( instance_db_name , <EOL> icc . DB_USER ) , shell = True ) <EOL> createdb . wait ( ) <EOL> try : <EOL> psycopg2 . connect ( <EOL> database = instance_db_name , <EOL> user = icc . DB_USER , <EOL> password = icc . DB_PASSWORD , <EOL> host = icc . DB_HOST <EOL> ) <EOL> print ( '<STR_LIT>' <EOL> '<STR_LIT>' . format ( instance_db_name ) ) <EOL> except : <EOL> self . abort ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> def syncdb_and_migrate ( self , instance_name ) : <EOL> """<STR_LIT>""" <EOL> working_dir = os . path . join ( icc . DEFAULT_INSTANCE_DIR , instance_name ) <EOL> os . chdir ( working_dir ) <EOL> syncdb = subprocess . Popen ( ( '<STR_LIT>' <EOL> '<STR_LIT>' ) , shell = True ) <EOL> syncdb . wait ( ) <EOL> def collect_static ( seld , instance_name ) : <EOL> """<STR_LIT>""" <EOL> working_dir = os . path . join ( icc . DEFAULT_INSTANCE_DIR , instance_name ) <EOL> os . chdir ( working_dir ) <EOL> collectstatic = subprocess . Popen ( ( '<STR_LIT>' <EOL> '<STR_LIT>' ) , <EOL> shell = True ) <EOL> collectstatic . wait ( ) <EOL> def add_instance_to_supervisor ( self , instance_name ) : <EOL> """<STR_LIT>""" <EOL> INSTANCE_DIR = os . path . join ( icc . DEFAULT_INSTANCE_DIR , instance_name ) <EOL> try : <EOL> template = os . path . join ( INSTANCE_DIR , '<STR_LIT>' ) <EOL> values = { <EOL> '<STR_LIT>' : instance_name , <EOL> '<STR_LIT>' : INSTANCE_DIR <EOL> } <EOL> self . _populate_file ( template , values ) <EOL> os . symlink ( template , os . path . join ( <EOL> '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' % instance_name ) ) <EOL> print ( '<STR_LIT>' ) <EOL> except : <EOL> self . abort ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> def add_instance_to_nginx ( self , instance_name ) : <EOL> """<STR_LIT>""" <EOL> INSTANCE_DIR = os . path . join ( icc . DEFAULT_INSTANCE_DIR , instance_name ) <EOL> try : <EOL> template = os . path . join ( INSTANCE_DIR , '<STR_LIT>' ) <EOL> values = { '<STR_LIT>' : instance_name } <EOL> self . _populate_file ( template , values ) <EOL> template = os . path . join ( INSTANCE_DIR , '<STR_LIT>' ) <EOL> values = { '<STR_LIT>' : instance_name } <EOL> self . _populate_file ( template , values ) <EOL> print ( '<STR_LIT>' ) <EOL> except : <EOL> self . abort ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> def restart_server ( self ) : <EOL> supervisord = subprocess . Popen ( ( '<STR_LIT>' <EOL> '<STR_LIT>' ) , shell = True ) <EOL> supervisord . wait ( ) <EOL> nginx = subprocess . Popen ( ( '<STR_LIT>' <EOL> '<STR_LIT>' ) , shell = True ) <EOL> nginx . wait ( ) <EOL> time . sleep ( <NUM_LIT:5> ) <EOL> def update_entries_metadata ( self ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> update_metadata = subprocess . Popen ( ( '<STR_LIT>' <EOL> '<STR_LIT>' ) , <EOL> shell = True ) <EOL> update_metadata . wait ( ) <EOL> url = ( '<STR_LIT>' <EOL> '<STR_LIT>' ) % icc . META_REFRESH_KEY <EOL> requests . get ( url ) <EOL> except : <EOL> self . abort ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> def disable_instance ( self , instance_name ) : <EOL> """<STR_LIT>""" <EOL> INSTANCE_DIR = os . path . join ( icc . DEFAULT_INSTANCE_DIR , instance_name ) <EOL> try : <EOL> if not os . path . isdir ( icc . DEFAULT_DISABLED_INSTANCES_DIR ) : <EOL> os . makedirs ( icc . DEFAULT_DISABLED_INSTANCES_DIR ) <EOL> shutil . copy ( INSTANCE_DIR , icc . DEFAULT_DISABLED_INSTANCES_DIR ) <EOL> shutil . rmtree ( INSTANCE_DIR ) <EOL> print ( '<STR_LIT>' . format ( instance_name ) ) <EOL> except : <EOL> self . abort ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> def destroy_instance ( self , instance_name ) : <EOL> """<STR_LIT>""" <EOL> INSTANCE_DIR = os . path . join ( icc . DEFAULT_INSTANCE_DIR , instance_name ) <EOL> sys . path . insert ( <NUM_LIT:0> , INSTANCE_DIR ) <EOL> try : <EOL> import instance_settings <EOL> except : <EOL> self . abort ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> try : <EOL> instance_db_name = instance_settings . DATABASE_NAME <EOL> dropdb = subprocess . Popen ( '<STR_LIT>' % <EOL> instance_db_name , shell = True ) <EOL> dropdb . wait ( ) <EOL> shutil . rmtree ( INSTANCE_DIR ) <EOL> os . remove ( os . path . join ( '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' % instance_name ) ) <EOL> print ( '<STR_LIT>' . format ( instance_name ) ) <EOL> except : <EOL> self . abort ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> def abort ( self , msg , status = <NUM_LIT:1> ) : <EOL> sys . stderr . write ( msg ) <EOL> sys . exit ( status ) <EOL> parser = optparse . OptionParser ( <EOL> description = ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) , <EOL> version = '<STR_LIT>' <EOL> ) <EOL> parser . add_option ( <EOL> '<STR_LIT:-c>' , <EOL> '<STR_LIT>' , <EOL> help = '<STR_LIT>' , <EOL> dest = '<STR_LIT>' , <EOL> action = '<STR_LIT:store>' , <EOL> nargs = <NUM_LIT:2> <EOL> ) <EOL> parser . add_option ( <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> help = '<STR_LIT>' , <EOL> dest = '<STR_LIT>' <EOL> ) <EOL> parser . add_option ( <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> help = '<STR_LIT>' , <EOL> dest = '<STR_LIT>' <EOL> ) <EOL> parser . add_option ( <EOL> '<STR_LIT>' , <EOL> help = '<STR_LIT>' , <EOL> action = '<STR_LIT:store_true>' , <EOL> dest = '<STR_LIT>' <EOL> ) <EOL> ( opts , args ) = parser . parse_args ( ) <EOL> inst = AskbotInstance ( ) <EOL> if opts . instance_data : <EOL> INSTANCE_NAME = opts . instance_data [ <NUM_LIT:0> ] <EOL> INSTANCE_DB_NAME = opts . instance_data [ <NUM_LIT:1> ] <EOL> inst . create_instance ( INSTANCE_NAME , INSTANCE_DB_NAME ) <EOL> inst . add_instance_to_supervisor ( INSTANCE_NAME ) <EOL> inst . add_instance_to_nginx ( INSTANCE_NAME ) <EOL> inst . create_db ( INSTANCE_DB_NAME ) <EOL> inst . syncdb_and_migrate ( INSTANCE_NAME ) <EOL> inst . collect_static ( INSTANCE_NAME ) <EOL> inst . restart_server ( ) <EOL> if not opts . no_metadata : <EOL> inst . update_entries_metadata ( ) <EOL> elif opts . disable_instance_name : <EOL> INSTANCE_NAME = opts . disable_instance_name <EOL> inst . disable_instance ( INSTANCE_NAME ) <EOL> elif opts . destroy_instance_name : <EOL> INSTANCE_NAME = opts . destroy_instance_name <EOL> inst . destroy_instance ( INSTANCE_NAME ) </s>
<s> default_app_config = '<STR_LIT>' </s>
<s> from . . utils . access_permissions import BaseAccessPermissions <EOL> class MediafileAccessPermissions ( BaseAccessPermissions ) : <EOL> """<STR_LIT>""" <EOL> def can_retrieve ( self , user ) : <EOL> """<STR_LIT>""" <EOL> return user . has_perm ( '<STR_LIT>' ) <EOL> def get_serializer_class ( self , user = None ) : <EOL> """<STR_LIT>""" <EOL> from . serializers import MediafileSerializer <EOL> return MediafileSerializer </s>
<s> from __future__ import unicode_literals <EOL> from django . db import migrations , models <EOL> import openslides . utils . models <EOL> class Migration ( migrations . Migration ) : <EOL> initial = True <EOL> dependencies = [ <EOL> ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> ] <EOL> operations = [ <EOL> migrations . CreateModel ( <EOL> name = '<STR_LIT>' , <EOL> fields = [ <EOL> ( '<STR_LIT:id>' , models . AutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = '<STR_LIT>' ) ) , <EOL> ( '<STR_LIT:password>' , models . CharField ( max_length = <NUM_LIT> , verbose_name = '<STR_LIT:password>' ) ) , <EOL> ( '<STR_LIT>' , models . DateTimeField ( blank = True , null = True , verbose_name = '<STR_LIT>' ) ) , <EOL> ( '<STR_LIT>' , models . BooleanField ( <EOL> default = False , <EOL> help_text = '<STR_LIT>' , <EOL> verbose_name = '<STR_LIT>' ) ) , <EOL> ( '<STR_LIT:username>' , models . CharField ( blank = True , max_length = <NUM_LIT:255> , unique = True ) ) , <EOL> ( '<STR_LIT>' , models . CharField ( blank = True , max_length = <NUM_LIT:255> ) ) , <EOL> ( '<STR_LIT>' , models . CharField ( blank = True , max_length = <NUM_LIT:255> ) ) , <EOL> ( '<STR_LIT>' , models . CharField ( blank = True , default = '<STR_LIT>' , max_length = <NUM_LIT:255> ) ) , <EOL> ( '<STR_LIT:title>' , models . CharField ( blank = True , default = '<STR_LIT>' , max_length = <NUM_LIT:50> ) ) , <EOL> ( '<STR_LIT>' , models . TextField ( blank = True , default = '<STR_LIT>' ) ) , <EOL> ( '<STR_LIT>' , models . TextField ( blank = True , default = '<STR_LIT>' ) ) , <EOL> ( '<STR_LIT>' , models . CharField ( blank = True , default = '<STR_LIT>' , max_length = <NUM_LIT:100> ) ) , <EOL> ( '<STR_LIT>' , models . BooleanField ( default = True ) ) , <EOL> ( '<STR_LIT>' , models . BooleanField ( default = False ) ) , <EOL> ( '<STR_LIT>' , models . ManyToManyField ( <EOL> blank = True , <EOL> help_text = '<STR_LIT>' , <EOL> related_name = '<STR_LIT>' , <EOL> related_query_name = '<STR_LIT:user>' , <EOL> to = '<STR_LIT>' , <EOL> verbose_name = '<STR_LIT>' ) ) , <EOL> ( '<STR_LIT>' , models . ManyToManyField ( <EOL> blank = True , <EOL> help_text = '<STR_LIT>' , <EOL> related_name = '<STR_LIT>' , <EOL> related_query_name = '<STR_LIT:user>' , <EOL> to = '<STR_LIT>' , <EOL> verbose_name = '<STR_LIT>' ) ) , <EOL> ] , <EOL> options = { <EOL> '<STR_LIT>' : ( <EOL> ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> ( '<STR_LIT>' , '<STR_LIT>' ) ) , <EOL> '<STR_LIT>' : ( ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT:username>' ) , <EOL> } , <EOL> bases = ( openslides . utils . models . RESTModelMixin , models . Model ) , <EOL> ) , <EOL> ] </s>
<s> import json <EOL> from django . core . urlresolvers import reverse <EOL> from django . dispatch import receiver <EOL> from rest_framework import status <EOL> from rest_framework . test import APIClient <EOL> from openslides import __version__ as version <EOL> from openslides . core . config import ConfigVariable , config <EOL> from openslides . core . models import CustomSlide , Projector <EOL> from openslides . core . signals import config_signal <EOL> from openslides . utils . rest_api import ValidationError <EOL> from openslides . utils . test import TestCase <EOL> class ProjectorAPI ( TestCase ) : <EOL> """<STR_LIT>""" <EOL> def test_slide_on_default_projector ( self ) : <EOL> self . client . login ( username = '<STR_LIT>' , password = '<STR_LIT>' ) <EOL> customslide = CustomSlide . objects . create ( title = '<STR_LIT>' , text = '<STR_LIT>' ) <EOL> default_projector = Projector . objects . get ( pk = <NUM_LIT:1> ) <EOL> default_projector . config = { <EOL> '<STR_LIT>' : { '<STR_LIT:name>' : '<STR_LIT>' , '<STR_LIT:id>' : customslide . id } } <EOL> default_projector . save ( ) <EOL> response = self . client . get ( reverse ( '<STR_LIT>' , args = [ '<STR_LIT:1>' ] ) ) <EOL> self . assertEqual ( response . status_code , status . HTTP_200_OK ) <EOL> self . assertEqual ( json . loads ( response . content . decode ( ) ) , { <EOL> '<STR_LIT:id>' : <NUM_LIT:1> , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : <EOL> { '<STR_LIT:id>' : customslide . id , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:name>' : '<STR_LIT>' } } , <EOL> '<STR_LIT>' : <NUM_LIT:0> , <EOL> '<STR_LIT>' : <NUM_LIT:0> } ) <EOL> def test_invalid_slide_on_default_projector ( self ) : <EOL> self . client . login ( username = '<STR_LIT>' , password = '<STR_LIT>' ) <EOL> default_projector = Projector . objects . get ( pk = <NUM_LIT:1> ) <EOL> default_projector . config = { <EOL> '<STR_LIT>' : { '<STR_LIT:name>' : '<STR_LIT>' } } <EOL> default_projector . save ( ) <EOL> response = self . client . get ( reverse ( '<STR_LIT>' , args = [ '<STR_LIT:1>' ] ) ) <EOL> self . assertEqual ( response . status_code , status . HTTP_200_OK ) <EOL> self . assertEqual ( json . loads ( response . content . decode ( ) ) , { <EOL> '<STR_LIT:id>' : <NUM_LIT:1> , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : <EOL> { '<STR_LIT:name>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:error>' : '<STR_LIT>' } } , <EOL> '<STR_LIT>' : <NUM_LIT:0> , <EOL> '<STR_LIT>' : <NUM_LIT:0> } ) <EOL> class VersionView ( TestCase ) : <EOL> """<STR_LIT>""" <EOL> def test_get ( self ) : <EOL> self . client . login ( username = '<STR_LIT>' , password = '<STR_LIT>' ) <EOL> response = self . client . get ( reverse ( '<STR_LIT>' ) ) <EOL> self . assertEqual ( json . loads ( response . content . decode ( ) ) , { <EOL> '<STR_LIT>' : version , <EOL> '<STR_LIT>' : [ <EOL> { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:description>' : '<STR_LIT>' , <EOL> '<STR_LIT:version>' : '<STR_LIT>' } ] } ) <EOL> class ConfigViewSet ( TestCase ) : <EOL> """<STR_LIT>""" <EOL> def test_retrieve ( self ) : <EOL> self . client . login ( username = '<STR_LIT>' , password = '<STR_LIT>' ) <EOL> config [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> response = self . client . get ( reverse ( '<STR_LIT>' , args = [ '<STR_LIT>' ] ) ) <EOL> self . assertEqual ( <EOL> response . data , <EOL> { '<STR_LIT:key>' : '<STR_LIT>' , <EOL> '<STR_LIT:value>' : '<STR_LIT>' } ) <EOL> def test_update ( self ) : <EOL> self . client = APIClient ( ) <EOL> self . client . login ( username = '<STR_LIT>' , password = '<STR_LIT>' ) <EOL> response = self . client . put ( <EOL> reverse ( '<STR_LIT>' , args = [ '<STR_LIT>' ] ) , <EOL> { '<STR_LIT:value>' : '<STR_LIT>' } ) <EOL> self . assertEqual ( response . status_code , status . HTTP_200_OK ) <EOL> self . assertEqual ( config [ '<STR_LIT>' ] , '<STR_LIT>' ) <EOL> def test_update_wrong_datatype ( self ) : <EOL> self . client = APIClient ( ) <EOL> self . client . login ( username = '<STR_LIT>' , password = '<STR_LIT>' ) <EOL> response = self . client . put ( <EOL> reverse ( '<STR_LIT>' , args = [ '<STR_LIT>' ] ) , <EOL> { '<STR_LIT:value>' : '<STR_LIT>' } ) <EOL> self . assertEqual ( response . status_code , status . HTTP_400_BAD_REQUEST ) <EOL> self . assertEqual ( response . data , { '<STR_LIT>' : "<STR_LIT>" } ) <EOL> def test_update_wrong_datatype_that_can_be_converted ( self ) : <EOL> """<STR_LIT>""" <EOL> self . client = APIClient ( ) <EOL> self . client . login ( username = '<STR_LIT>' , password = '<STR_LIT>' ) <EOL> response = self . client . put ( <EOL> reverse ( '<STR_LIT>' , args = [ '<STR_LIT>' ] ) , <EOL> { '<STR_LIT:value>' : '<STR_LIT>' } ) <EOL> self . assertEqual ( response . status_code , <NUM_LIT:200> ) <EOL> def test_update_good_choice ( self ) : <EOL> self . client = APIClient ( ) <EOL> self . client . login ( username = '<STR_LIT>' , password = '<STR_LIT>' ) <EOL> response = self . client . put ( <EOL> reverse ( '<STR_LIT>' , args = [ '<STR_LIT>' ] ) , <EOL> { '<STR_LIT:value>' : '<STR_LIT>' } ) <EOL> self . assertEqual ( response . status_code , status . HTTP_200_OK ) <EOL> self . assertEqual ( config [ '<STR_LIT>' ] , '<STR_LIT>' ) <EOL> def test_update_bad_choice ( self ) : <EOL> self . client = APIClient ( ) <EOL> self . client . login ( username = '<STR_LIT>' , password = '<STR_LIT>' ) <EOL> response = self . client . put ( <EOL> reverse ( '<STR_LIT>' , args = [ '<STR_LIT>' ] ) , <EOL> { '<STR_LIT:value>' : '<STR_LIT>' } ) <EOL> self . assertEqual ( response . status_code , status . HTTP_400_BAD_REQUEST ) <EOL> self . assertEqual ( response . data , { '<STR_LIT>' : '<STR_LIT>' } ) <EOL> def test_update_validator_ok ( self ) : <EOL> self . client = APIClient ( ) <EOL> self . client . login ( username = '<STR_LIT>' , password = '<STR_LIT>' ) <EOL> response = self . client . put ( <EOL> reverse ( '<STR_LIT>' , args = [ '<STR_LIT>' ] ) , <EOL> { '<STR_LIT:value>' : '<STR_LIT>' } ) <EOL> self . assertEqual ( response . status_code , status . HTTP_200_OK ) <EOL> self . assertEqual ( config [ '<STR_LIT>' ] , '<STR_LIT>' ) <EOL> def test_update_validator_invalid ( self ) : <EOL> self . client = APIClient ( ) <EOL> self . client . login ( username = '<STR_LIT>' , password = '<STR_LIT>' ) <EOL> response = self . client . put ( <EOL> reverse ( '<STR_LIT>' , args = [ '<STR_LIT>' ] ) , <EOL> { '<STR_LIT:value>' : '<STR_LIT>' } ) <EOL> self . assertEqual ( response . status_code , status . HTTP_400_BAD_REQUEST ) <EOL> self . assertEqual ( response . data , { '<STR_LIT>' : '<STR_LIT>' } ) <EOL> def test_update_only_with_key ( self ) : <EOL> self . client = APIClient ( ) <EOL> self . client . login ( username = '<STR_LIT>' , password = '<STR_LIT>' ) <EOL> response = self . client . put ( <EOL> reverse ( '<STR_LIT>' , args = [ '<STR_LIT>' ] ) ) <EOL> self . assertEqual ( response . status_code , status . HTTP_400_BAD_REQUEST ) <EOL> self . assertEqual ( response . data , { '<STR_LIT>' : '<STR_LIT>' } ) <EOL> def test_metadata_with_hidden ( self ) : <EOL> self . client . login ( username = '<STR_LIT>' , password = '<STR_LIT>' ) <EOL> response = self . client . options ( reverse ( '<STR_LIT>' ) ) <EOL> filter_obj = filter ( <EOL> lambda item : item [ '<STR_LIT:key>' ] == '<STR_LIT>' , <EOL> response . data [ '<STR_LIT>' ] [ <NUM_LIT:0> ] [ '<STR_LIT>' ] [ <NUM_LIT:0> ] [ '<STR_LIT>' ] ) <EOL> self . assertEqual ( len ( list ( filter_obj ) ) , <NUM_LIT:0> ) <EOL> def validator_for_testing ( value ) : <EOL> """<STR_LIT>""" <EOL> if value == '<STR_LIT>' : <EOL> raise ValidationError ( { '<STR_LIT>' : '<STR_LIT>' } ) <EOL> @ receiver ( config_signal , dispatch_uid = '<STR_LIT>' ) <EOL> def set_simple_config_view_integration_config_test ( sender , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> yield ConfigVariable ( <EOL> name = '<STR_LIT>' , <EOL> default_value = None , <EOL> label = '<STR_LIT>' ) <EOL> yield ConfigVariable ( <EOL> name = '<STR_LIT>' , <EOL> default_value = '<STR_LIT>' ) <EOL> yield ConfigVariable ( <EOL> name = '<STR_LIT>' , <EOL> default_value = <NUM_LIT:0> , <EOL> input_type = '<STR_LIT>' ) <EOL> yield ConfigVariable ( <EOL> name = '<STR_LIT>' , <EOL> default_value = '<STR_LIT>' , <EOL> input_type = '<STR_LIT>' , <EOL> choices = ( <EOL> { '<STR_LIT:value>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT:value>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ) ) <EOL> yield ConfigVariable ( <EOL> name = '<STR_LIT>' , <EOL> default_value = '<STR_LIT>' , <EOL> validators = ( validator_for_testing , ) ) <EOL> yield ConfigVariable ( <EOL> name = '<STR_LIT>' , <EOL> default_value = None , <EOL> label = '<STR_LIT>' , <EOL> hidden = True ) </s>
<s> from unittest import TestCase <EOL> from unittest . mock import MagicMock , patch <EOL> from openslides . users . serializers import UserFullSerializer <EOL> from openslides . utils . rest_api import ValidationError <EOL> class UserCreateUpdateSerializerTest ( TestCase ) : <EOL> def test_validate_no_data ( self ) : <EOL> """<STR_LIT>""" <EOL> serializer = UserFullSerializer ( ) <EOL> data = { } <EOL> with self . assertRaises ( ValidationError ) : <EOL> serializer . validate ( data ) <EOL> @ patch ( '<STR_LIT>' ) <EOL> def test_validate_no_username ( self , generate_username ) : <EOL> """<STR_LIT>""" <EOL> generate_username . return_value = '<STR_LIT>' <EOL> serializer = UserFullSerializer ( ) <EOL> data = { '<STR_LIT>' : '<STR_LIT>' } <EOL> new_data = serializer . validate ( data ) <EOL> self . assertEqual ( new_data [ '<STR_LIT:username>' ] , '<STR_LIT>' ) <EOL> def test_validate_no_username_in_patch_request ( self ) : <EOL> """<STR_LIT>""" <EOL> view = MagicMock ( action = '<STR_LIT>' ) <EOL> serializer = UserFullSerializer ( context = { '<STR_LIT>' : view } ) <EOL> data = { '<STR_LIT>' : '<STR_LIT>' } <EOL> new_data = serializer . validate ( data ) <EOL> self . assertIsNone ( new_data . get ( '<STR_LIT:username>' ) ) </s>
<s> """<STR_LIT>""" <EOL> import re <EOL> URL_REGEX = re . compile ( <EOL> r'<STR_LIT>' <EOL> r'<STR_LIT>' <EOL> r'<STR_LIT>' <EOL> r'<STR_LIT>' <EOL> r'<STR_LIT>' <EOL> r'<STR_LIT>' , re . IGNORECASE ) <EOL> USERNAME_REGEX = re . compile ( r'<STR_LIT>' , re . I ) <EOL> FULLNAME_REGEX = re . compile ( r'<STR_LIT>' , re . U ) <EOL> EMAIL_REGEX = re . compile ( r'<STR_LIT>' , re . IGNORECASE ) <EOL> class CheckValue ( object ) : <EOL> def __init__ ( self ) : <EOL> pass <EOL> def length ( self , data , minimum = - <NUM_LIT:1> , maximum = - <NUM_LIT:1> ) : <EOL> """<STR_LIT>""" <EOL> len_input = len ( data ) <EOL> if len_input < minimum or maximum != - <NUM_LIT:1> and len_input > maximum : <EOL> return False <EOL> return True <EOL> def regexp ( self , data , regex , flags = <NUM_LIT:0> ) : <EOL> """<STR_LIT>""" <EOL> regex = re . compile ( regex , flags ) <EOL> if regex . match ( data ) : <EOL> return True <EOL> return False <EOL> def username ( self , data ) : <EOL> """<STR_LIT>""" <EOL> if USERNAME_REGEX . match ( data ) : <EOL> return True <EOL> return False <EOL> def full_name ( self , data ) : <EOL> """<STR_LIT>""" <EOL> if FULLNAME_REGEX . match ( data ) : <EOL> return True <EOL> return False <EOL> def email ( self , data ) : <EOL> """<STR_LIT>""" <EOL> if EMAIL_REGEX . match ( data ) : <EOL> return True <EOL> return False <EOL> def url ( self , data ) : <EOL> """<STR_LIT>""" <EOL> if URL_REGEX . match ( data ) : <EOL> return True <EOL> return False <EOL> def url_two ( self , data ) : <EOL> """<STR_LIT>""" <EOL> regex = re . compile ( r'<STR_LIT>' , re . IGNORECASE ) <EOL> if regex . match ( data ) : <EOL> return True <EOL> return False <EOL> def is_integer ( self , data ) : <EOL> """<STR_LIT:U+0020>""" <EOL> try : <EOL> tmp = int ( data ) <EOL> return True <EOL> except : <EOL> return False <EOL> def float ( self , data ) : <EOL> """<STR_LIT:U+0020>""" <EOL> try : <EOL> tmp = float ( data ) <EOL> return True <EOL> except : <EOL> return False </s>
<s> </s>
<s> import logging <EOL> import socket <EOL> from bagpipe . bgp . common import utils <EOL> from bagpipe . bgp . common import logDecorator <EOL> from bagpipe . bgp . vpn . vpn_instance import VPNInstance <EOL> from bagpipe . bgp . engine import RouteEvent <EOL> from bagpipe . bgp . vpn . dataplane_drivers import DummyDataplaneDriver as _DummyDataplaneDriver <EOL> from bagpipe . bgp . common . looking_glass import LookingGlass , LGMap <EOL> from bagpipe . exabgp . structure . vpn import RouteDistinguisher , VPNLabelledPrefix <EOL> from bagpipe . exabgp . structure . mpls import LabelStackEntry <EOL> from bagpipe . exabgp . structure . address import AFI , SAFI <EOL> from bagpipe . exabgp . structure . ip import Inet , Prefix <EOL> from bagpipe . exabgp . message . update . route import Route <EOL> from bagpipe . exabgp . message . update . attribute . nexthop import NextHop <EOL> from bagpipe . exabgp . message . update . attribute . communities import ECommunities <EOL> class DummyDataplaneDriver ( _DummyDataplaneDriver ) : <EOL> pass <EOL> class VRF ( VPNInstance , LookingGlass ) : <EOL> type = "<STR_LIT>" <EOL> afi = AFI ( AFI . ipv4 ) <EOL> safi = SAFI ( SAFI . mpls_vpn ) <EOL> @ logDecorator . log <EOL> def __init__ ( self , * args , ** kwargs ) : <EOL> VPNInstance . __init__ ( self , * args , ** kwargs ) <EOL> self . readvertised = set ( ) <EOL> def _routeFrom ( self , prefix , label , rd ) : <EOL> return Route ( VPNLabelledPrefix ( self . afi , self . safi , prefix , rd , <EOL> [ LabelStackEntry ( label , True ) ] <EOL> ) ) <EOL> def generateVifBGPRoute ( self , macAdress , ipPrefix , prefixLen , label ) : <EOL> route = self . _routeFrom ( Prefix ( self . afi , ipPrefix , prefixLen ) , label , <EOL> RouteDistinguisher ( <EOL> RouteDistinguisher . TYPE_IP_LOC , None , <EOL> self . bgpManager . getLocalAddress ( ) , <EOL> self . instanceId ) <EOL> ) <EOL> self . log . debug ( "<STR_LIT>" , route . attributes ) <EOL> return self . _newRouteEntry ( self . afi , self . safi , self . exportRTs , <EOL> route . nlri , route . attributes ) <EOL> def _getLocalLabels ( self ) : <EOL> for portData in self . macAddress2LocalPortData . itervalues ( ) : <EOL> yield portData [ '<STR_LIT:label>' ] <EOL> def _getRDFromLabel ( self , label ) : <EOL> return RouteDistinguisher ( RouteDistinguisher . TYPE_IP_LOC , None , <EOL> self . bgpManager . getLocalAddress ( ) , <EOL> <NUM_LIT> + label ) <EOL> def _routeForReAdvertisement ( self , prefix , label ) : <EOL> route = self . _routeFrom ( prefix , label , <EOL> self . _getRDFromLabel ( label ) ) <EOL> nh = Inet ( <NUM_LIT:1> , socket . inet_pton ( socket . AF_INET , <EOL> self . dataplane . driver . getLocalAddress ( ) ) ) <EOL> route . attributes . add ( NextHop ( nh ) ) <EOL> route . attributes . add ( ECommunities ( self . readvertiseToRTs ) ) <EOL> routeEntry = self . _newRouteEntry ( self . afi , self . safi , <EOL> self . readvertiseToRTs , <EOL> route . nlri , route . attributes ) <EOL> return routeEntry <EOL> @ logDecorator . log <EOL> def _readvertise ( self , nlri ) : <EOL> self . log . debug ( "<STR_LIT>" , nlri . prefix ) <EOL> for label in self . _getLocalLabels ( ) : <EOL> self . log . debug ( "<STR_LIT>" , <EOL> nlri . prefix , label ) <EOL> routeEntry = self . _routeForReAdvertisement ( nlri . prefix , label ) <EOL> self . _pushEvent ( RouteEvent ( RouteEvent . ADVERTISE , routeEntry ) ) <EOL> self . readvertised . add ( nlri . prefix ) <EOL> @ logDecorator . log <EOL> def _readvertiseStop ( self , nlri ) : <EOL> self . log . debug ( "<STR_LIT>" , nlri . prefix ) <EOL> for label in self . _getLocalLabels ( ) : <EOL> self . log . debug ( "<STR_LIT>" , <EOL> nlri . prefix , label ) <EOL> routeEntry = self . _routeForReAdvertisement ( nlri . prefix , label ) <EOL> self . _pushEvent ( RouteEvent ( RouteEvent . WITHDRAW , routeEntry ) ) <EOL> self . readvertised . remove ( nlri . prefix ) <EOL> def vifPlugged ( self , macAddress , ipAddressPrefix , localPort , <EOL> advertiseSubnet ) : <EOL> VPNInstance . vifPlugged ( self , macAddress , ipAddressPrefix , localPort , <EOL> advertiseSubnet ) <EOL> label = self . macAddress2LocalPortData [ macAddress ] [ '<STR_LIT:label>' ] <EOL> for prefix in self . readvertised : <EOL> self . log . debug ( "<STR_LIT>" , <EOL> prefix ) <EOL> routeEntry = self . _routeForReAdvertisement ( prefix , label ) <EOL> self . _pushEvent ( RouteEvent ( RouteEvent . ADVERTISE , routeEntry ) ) <EOL> def vifUnplugged ( self , macAddress , ipAddressPrefix , advertiseSubnet ) : <EOL> label = self . macAddress2LocalPortData [ macAddress ] [ '<STR_LIT:label>' ] <EOL> for prefix in self . readvertised : <EOL> self . log . debug ( "<STR_LIT>" , <EOL> prefix ) <EOL> routeEntry = self . _routeForReAdvertisement ( prefix , label ) <EOL> self . _pushEvent ( RouteEvent ( RouteEvent . WITHDRAW , routeEntry ) ) <EOL> VPNInstance . vifUnplugged ( self , macAddress , ipAddressPrefix , <EOL> advertiseSubnet ) <EOL> def _route2trackedEntry ( self , route ) : <EOL> if isinstance ( route . nlri , VPNLabelledPrefix ) : <EOL> return route . nlri . prefix <EOL> else : <EOL> self . log . error ( "<STR_LIT>" , <EOL> type ( route . nlri ) ) <EOL> return None <EOL> def _toReadvertise ( self , route ) : <EOL> return ( len ( set ( route . routeTargets ) . intersection ( <EOL> set ( self . readvertiseFromRTs ) ) ) > <NUM_LIT:0> ) <EOL> def _imported ( self , route ) : <EOL> return ( len ( set ( route . routeTargets ) . intersection ( <EOL> set ( self . importRTs ) ) ) > <NUM_LIT:0> ) <EOL> @ utils . synchronized <EOL> @ logDecorator . log <EOL> def _newBestRoute ( self , entry , newRoute ) : <EOL> prefix = entry <EOL> if self . readvertise : <EOL> self . log . debug ( "<STR_LIT>" , newRoute . routeTargets ) <EOL> self . log . debug ( "<STR_LIT>" , self . readvertiseFromRTs ) <EOL> if self . _toReadvertise ( newRoute ) : <EOL> self . log . debug ( "<STR_LIT>" , prefix ) <EOL> self . _readvertise ( newRoute . nlri ) <EOL> if not self . _imported ( newRoute ) : <EOL> self . log . debug ( "<STR_LIT>" , prefix ) <EOL> return <EOL> encaps = self . _checkEncaps ( newRoute ) <EOL> if not encaps : <EOL> return <EOL> self . dataplane . setupDataplaneForRemoteEndpoint ( <EOL> prefix , newRoute . attributes . get ( NextHop . ID ) . next_hop , <EOL> newRoute . nlri . labelStack [ <NUM_LIT:0> ] . labelValue , newRoute . nlri , encaps ) <EOL> @ utils . synchronized <EOL> @ logDecorator . log <EOL> def _bestRouteRemoved ( self , entry , oldRoute , last ) : <EOL> prefix = entry <EOL> if self . readvertise and last : <EOL> if self . _toReadvertise ( oldRoute ) : <EOL> self . log . debug ( "<STR_LIT>" , prefix ) <EOL> self . _readvertiseStop ( oldRoute . nlri ) <EOL> if not self . _imported ( oldRoute ) : <EOL> self . log . debug ( "<STR_LIT>" , prefix ) <EOL> return <EOL> if self . _skipRouteRemoval ( last ) : <EOL> self . log . debug ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> return <EOL> self . dataplane . removeDataplaneForRemoteEndpoint ( <EOL> prefix , oldRoute . attributes . get ( NextHop . ID ) . next_hop , <EOL> oldRoute . nlri . labelStack [ <NUM_LIT:0> ] . labelValue , oldRoute . nlri ) <EOL> def getLGMap ( self ) : <EOL> return { <EOL> "<STR_LIT>" : ( LGMap . VALUE , [ repr ( prefix ) for prefix in <EOL> self . readvertised ] ) <EOL> } </s>
<s> """<STR_LIT>""" <EOL> from bagpipe . exabgp . message . update . attribute import AttributeID , Flag , Attribute <EOL> class Origin ( Attribute ) : <EOL> ID = AttributeID . ORIGIN <EOL> FLAG = Flag . TRANSITIVE <EOL> MULTIPLE = False <EOL> IGP = <NUM_LIT> <EOL> EGP = <NUM_LIT> <EOL> INCOMPLETE = <NUM_LIT> <EOL> def __init__ ( self , origin ) : <EOL> self . origin = origin <EOL> def pack ( self ) : <EOL> return self . _attribute ( chr ( self . origin ) ) <EOL> def __len__ ( self ) : <EOL> return len ( self . pack ( ) ) <EOL> def __str__ ( self ) : <EOL> if self . origin == <NUM_LIT> : return '<STR_LIT>' <EOL> if self . origin == <NUM_LIT> : return '<STR_LIT>' <EOL> if self . origin == <NUM_LIT> : return '<STR_LIT>' <EOL> return '<STR_LIT>' <EOL> def __repr__ ( self ) : <EOL> return str ( self ) <EOL> def __cmp__ ( self , other ) : <EOL> if ( not isinstance ( other , Origin ) <EOL> or ( self . origin != other . origin ) <EOL> ) : <EOL> return - <NUM_LIT:1> <EOL> else : <EOL> return <NUM_LIT:0> </s>
<s> import setuptools <EOL> setuptools . setup ( <EOL> setup_requires = [ '<STR_LIT>' ] , <EOL> pbr = True ) </s>
<s> __doc__ = """<STR_LIT>""" <EOL> __author__ = """<STR_LIT>""" <EOL> if __name__ != '<STR_LIT:__main__>' : raise ImportError ( '<STR_LIT>' ) <EOL> import os <EOL> import sys <EOL> DIRECTORY = os . path . abspath ( os . path . dirname ( __file__ ) ) <EOL> sys . path . insert ( <NUM_LIT:0> , os . path . abspath ( os . path . join ( DIRECTORY , '<STR_LIT:..>' , '<STR_LIT:..>' , '<STR_LIT:..>' ) ) ) <EOL> unforkedPid = os . getpid ( ) <EOL> childProcessPid = <NUM_LIT:0> <EOL> from twisted . internet import protocol , defer <EOL> from twisted . python . log import FileLogObserver , textFromEventDict <EOL> from twisted . python . util import untilConcludes <EOL> import signal <EOL> DEFAULT_REACTORS = { <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> } <EOL> def set_reactor ( ) : <EOL> import platform <EOL> REACTORNAME = DEFAULT_REACTORS . get ( platform . system ( ) , '<STR_LIT>' ) <EOL> if REACTORNAME == '<STR_LIT>' : <EOL> from twisted . internet import kqreactor <EOL> kqreactor . install ( ) <EOL> elif REACTORNAME == '<STR_LIT>' : <EOL> from twisted . internet import epollreactor <EOL> epollreactor . install ( ) <EOL> elif REACTORNAME == '<STR_LIT>' : <EOL> from twisted . internet import pollreactor <EOL> pollreactor . install ( ) <EOL> else : <EOL> from twisted . internet import selectreactor <EOL> selectreactor . install ( ) <EOL> from twisted . internet import reactor <EOL> set_reactor = lambda : reactor <EOL> return reactor <EOL> class ManagedLogger ( FileLogObserver ) : <EOL> """<STR_LIT>""" <EOL> timeFormat = "<STR_LIT>" <EOL> def emit ( self , eventDict ) : <EOL> """<STR_LIT>""" <EOL> text = textFromEventDict ( eventDict ) <EOL> if text is None : return <EOL> untilConcludes ( self . write , text ) <EOL> untilConcludes ( self . flush ) <EOL> class DaemonProtocol ( protocol . ProcessProtocol ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , name , label , r , deferred , ** kwargs ) : <EOL> self . deferred = deferred <EOL> self . reactor = r <EOL> out = { <EOL> '<STR_LIT:type>' : '<STR_LIT>' % ( name , label ) <EOL> } <EOL> err = { <EOL> '<STR_LIT:type>' : '<STR_LIT>' % ( name , label ) <EOL> } <EOL> self . name = name <EOL> self . label = label <EOL> import droned . logging <EOL> self . log_stdout = droned . logging . logWithContext ( ** out ) <EOL> self . log_stderr = droned . logging . logWithContext ( ** err ) <EOL> def inConnectionLost ( self ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> def errReceived ( self , data ) : <EOL> """<STR_LIT>""" <EOL> self . log_stderr ( str ( data ) ) <EOL> def outReceived ( self , data ) : <EOL> """<STR_LIT>""" <EOL> self . log_stdout ( str ( data ) ) <EOL> def outConnectionLost ( self ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> def errConnectionLost ( self ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> def connectionMade ( self ) : <EOL> """<STR_LIT>""" <EOL> global closestdin <EOL> if closestdin : <EOL> self . transport . closeStdin ( ) <EOL> global childProcessPid <EOL> global unforkedPid <EOL> x = unforkedPid <EOL> unforkedPid = <NUM_LIT:0> <EOL> if x : self . reactor . callLater ( <NUM_LIT> , os . kill , x , signal . SIGTERM ) <EOL> childProcessPid = self . transport . pid <EOL> sys . stdout . write ( '<STR_LIT>' % ( self . name , self . label , childProcessPid ) ) <EOL> def processExited ( self , reason ) : <EOL> """<STR_LIT>""" <EOL> sys . stdout . write ( '<STR_LIT>' % ( self . name , ) ) <EOL> if not self . deferred . called : <EOL> self . deferred . errback ( reason ) <EOL> global unforkedPid <EOL> global childProcessPid <EOL> childProcessPid = <NUM_LIT:0> <EOL> if unforkedPid : os . kill ( unforkedPid , signal . SIGTERM ) <EOL> processEnded = processExited <EOL> class DaemonWrapper ( object ) : <EOL> """<STR_LIT>""" <EOL> SIGNALS = dict ( ( k , v ) for v , k in signal . __dict__ . iteritems ( ) if v . startswith ( '<STR_LIT>' ) and not v . startswith ( '<STR_LIT>' ) ) <EOL> def __init__ ( self , r , name , label , cmd , args , env ) : <EOL> self . reactor = r <EOL> self . name = name <EOL> self . label = label <EOL> self . fqcmd = cmd <EOL> self . args = args <EOL> self . env = env <EOL> self . exitCode = <NUM_LIT:0> <EOL> self . deferred = defer . succeed ( None ) <EOL> import droned . logging <EOL> self . log = droned . logging . logWithContext ( type = '<STR_LIT>' ) <EOL> def routeSignal ( self , signum , frame ) : <EOL> """<STR_LIT>""" <EOL> if signum == signal . SIGTERM : <EOL> signal . signal ( signal . SIGTERM , signal . SIG_IGN ) <EOL> self . reactor . callLater ( <NUM_LIT> , self . reactor . stop ) <EOL> global childProcessPid <EOL> if childProcessPid : <EOL> self . log ( '<STR_LIT>' % ( self . SIGNALS [ signum ] , childProcessPid ) ) <EOL> try : os . kill ( childProcessPid , signum ) <EOL> except : <EOL> droned . logging . err ( '<STR_LIT>' % ( self . SIGNALS [ signum ] , childProcessPid ) ) <EOL> def processResult ( self , result ) : <EOL> """<STR_LIT>""" <EOL> self . reactor . callLater ( <NUM_LIT> , self . reactor . stop ) <EOL> return result <EOL> def running ( self ) : <EOL> """<STR_LIT>""" <EOL> global masksignals <EOL> if masksignals : <EOL> for signum , signame in self . SIGNALS . items ( ) : <EOL> if signame in ( '<STR_LIT>' , ) : continue <EOL> try : signal . signal ( signum , self . routeSignal ) <EOL> except RuntimeError : pass <EOL> from droned . clients import command <EOL> self . log ( '<STR_LIT>' % ( self . name , self . label ) ) <EOL> pargs = ( self . name , self . label , self . reactor ) <EOL> pkwargs = { } <EOL> global usetty <EOL> global path <EOL> self . deferred = command ( self . fqcmd , self . args , self . env , <EOL> path , usetty , { } , DaemonProtocol , <EOL> * pargs , ** pkwargs <EOL> ) <EOL> self . deferred . addBoth ( self . processResult ) <EOL> return self . deferred <EOL> env = os . environ . copy ( ) <EOL> args = tuple ( sys . argv [ <NUM_LIT:1> : ] ) <EOL> logdir = env . pop ( '<STR_LIT>' , os . path . join ( os . path . sep , '<STR_LIT>' ) ) <EOL> masksignals = bool ( env . pop ( '<STR_LIT>' , True ) ) <EOL> closestdin = bool ( env . pop ( '<STR_LIT>' , True ) ) <EOL> name = env . pop ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> label = env . pop ( '<STR_LIT>' , '<STR_LIT:0>' ) <EOL> usetty = bool ( env . pop ( '<STR_LIT>' , '<STR_LIT:0>' ) ) <EOL> path = env . pop ( '<STR_LIT>' , os . path . sep ) <EOL> if name not in logdir : <EOL> t = os . path . join ( logdir , name , label ) <EOL> try : <EOL> if not os . path . exists ( t ) : <EOL> os . makedirs ( t , mode = <NUM_LIT:0> <NUM_LIT> ) <EOL> logdir = t <EOL> except : pass <EOL> if args and os . path . exists ( args [ <NUM_LIT:0> ] ) : <EOL> try : os . setsid ( ) <EOL> except : pass <EOL> if os . fork ( ) == <NUM_LIT:0> : <EOL> os . chdir ( os . path . sep ) <EOL> os . umask ( <NUM_LIT:0> ) <EOL> sys . stdout . write ( '<STR_LIT>' % ( os . getpid ( ) , ) ) <EOL> sys . stderr . flush ( ) <EOL> sys . stdout . flush ( ) <EOL> import droned . logging <EOL> sys . stdout = droned . logging . StdioKabob ( <NUM_LIT:0> ) <EOL> sys . stderr = droned . logging . StdioKabob ( <NUM_LIT:1> ) <EOL> maxfd = <NUM_LIT> <EOL> try : <EOL> import resource <EOL> maxfd = resource . getrlimit ( resource . RLIMIT_NOFILE ) [ <NUM_LIT:1> ] <EOL> if ( maxfd == resource . RLIM_INFINITY ) : <EOL> maxfd = <NUM_LIT> <EOL> except : pass <EOL> for fd in range ( <NUM_LIT:0> , maxfd ) : <EOL> try : os . close ( fd ) <EOL> except OSError : pass <EOL> os . open ( <EOL> hasattr ( os , "<STR_LIT>" ) and os . devnull or "<STR_LIT>" , <EOL> os . O_RDWR <EOL> ) <EOL> os . dup2 ( <NUM_LIT:0> , <NUM_LIT:1> ) <EOL> os . dup2 ( <NUM_LIT:0> , <NUM_LIT:2> ) <EOL> loggers = [ <EOL> '<STR_LIT>' % ( name , label ) , <EOL> '<STR_LIT>' % ( name , label ) , <EOL> ] <EOL> droned . logging . logToDir ( directory = logdir ) <EOL> reactor = set_reactor ( ) <EOL> droned . logging . logToDir ( <EOL> directory = logdir , <EOL> LOG_TYPE = tuple ( loggers ) , <EOL> OBSERVER = ManagedLogger <EOL> ) <EOL> dmx = DaemonWrapper ( reactor , name , label , args [ <NUM_LIT:0> ] , args [ <NUM_LIT:1> : ] , env ) <EOL> def killGroup ( ) : <EOL> """<STR_LIT>""" <EOL> dmx . log ( '<STR_LIT>' ) <EOL> signal . signal ( signal . SIGTERM , signal . SIG_IGN ) <EOL> os . kill ( - os . getpgid ( os . getpid ( ) ) , signal . SIGTERM ) <EOL> reactor . addSystemEventTrigger ( '<STR_LIT>' , '<STR_LIT>' , killGroup ) <EOL> reactor . callWhenRunning ( dmx . running ) <EOL> reactor . run ( ) <EOL> sys . exit ( dmx . exitCode ) <EOL> else : <EOL> reactor = set_reactor ( ) <EOL> reactor . callLater ( <NUM_LIT> , sys . exit , <NUM_LIT:1> ) <EOL> reactor . run ( ) <EOL> sys . exit ( <NUM_LIT:0> ) <EOL> sys . exit ( <NUM_LIT:255> ) </s>
<s> from droned . models . team import Team , SupportAgent <EOL> from droned . models . issue import Issue <EOL> from droned . responders import responder <EOL> @ responder ( pattern = "<STR_LIT>" , form = "<STR_LIT>" , help = "<STR_LIT>" ) <EOL> def teams ( conversation ) : <EOL> teamlist = '<STR_LIT:\n>' . join ( "<STR_LIT>" % ( team . name , len ( team . agents ) ) for team in Team . objects ) <EOL> conversation . say ( '<STR_LIT:\n>' + teamlist , useHTML = False ) <EOL> @ responder ( pattern = "<STR_LIT>" , form = "<STR_LIT>" , help = "<STR_LIT>" ) <EOL> def members ( conversation , name ) : <EOL> if not Team . exists ( name ) : <EOL> conversation . say ( "<STR_LIT>" % name ) <EOL> else : <EOL> team = Team ( name ) <EOL> if team . agents : <EOL> members = '<STR_LIT:U+002C>' . join ( agent . jid for agent in team . agents ) <EOL> heading = "<STR_LIT>" % name <EOL> conversation . say ( heading + members , useHTML = False ) <EOL> else : <EOL> conversation . say ( "<STR_LIT>" ) <EOL> @ responder ( pattern = "<STR_LIT>" , form = "<STR_LIT>" , help = "<STR_LIT>" ) <EOL> def join ( conversation , name ) : <EOL> if not Team . exists ( name ) : <EOL> conversation . say ( "<STR_LIT>" % name ) <EOL> else : <EOL> team = Team ( name ) <EOL> team . addMember ( conversation . buddy ) <EOL> conversation . say ( "<STR_LIT>" % name ) <EOL> @ responder ( pattern = "<STR_LIT>" , form = "<STR_LIT>" , help = "<STR_LIT>" ) <EOL> def leave ( conversation , name ) : <EOL> if not Team . exists ( name ) : <EOL> conversation . say ( "<STR_LIT>" % name ) <EOL> else : <EOL> team = Team ( name ) <EOL> team . removeMember ( conversation . buddy ) <EOL> conversation . say ( "<STR_LIT>" % name ) <EOL> @ responder ( pattern = "<STR_LIT>" , form = "<STR_LIT>" , help = "<STR_LIT>" ) <EOL> def busy ( conversation ) : <EOL> agent = SupportAgent ( conversation . buddy ) <EOL> agent . ready = False <EOL> conversation . say ( "<STR_LIT>" ) <EOL> @ responder ( pattern = "<STR_LIT>" , form = "<STR_LIT>" , help = "<STR_LIT>" ) <EOL> def free ( conversation ) : <EOL> agent = SupportAgent ( conversation . buddy ) <EOL> agent . ready = True <EOL> conversation . say ( "<STR_LIT>" ) <EOL> @ responder ( pattern = "<STR_LIT>" , form = "<STR_LIT>" , help = "<STR_LIT>" ) <EOL> def announce ( conversation , message ) : <EOL> agent = SupportAgent ( conversation . buddy ) <EOL> message = "<STR_LIT>" % ( agent . name , message ) <EOL> told = <NUM_LIT:0> <EOL> for team in agent . teams : <EOL> for otherAgent in team . agents : <EOL> if otherAgent is agent : continue <EOL> otherAgent . tell ( message ) <EOL> told += <NUM_LIT:1> <EOL> if told : <EOL> agent . tell ( '<STR_LIT>' % told ) <EOL> else : <EOL> agent . tell ( '<STR_LIT>' ) <EOL> @ responder ( pattern = "<STR_LIT>" , form = '<STR_LIT>' , help = '<STR_LIT>' ) <EOL> def issues ( conversation ) : <EOL> issues = sorted ( [ i for i in Issue . objects if not i . resolved ] , key = lambda i : i . id ) <EOL> summaries = [ ] <EOL> for issue in issues : <EOL> summary = "<STR_LIT>" % ( issue . id , issue . description ) <EOL> if issue . context [ '<STR_LIT>' ] : <EOL> summary += "<STR_LIT>" % issue . context [ '<STR_LIT>' ] . name <EOL> elif isinstance ( issue . context [ '<STR_LIT>' ] , SupportAgent ) : <EOL> summary += "<STR_LIT>" % issue . context [ '<STR_LIT>' ] . name <EOL> elif issue . context [ '<STR_LIT>' ] is None : <EOL> summary += "<STR_LIT>" <EOL> summaries . append ( summary ) <EOL> heading = '<STR_LIT>' % len ( issues ) <EOL> listing = '<STR_LIT:\n>' . join ( summaries ) <EOL> conversation . say ( heading + listing , useHTML = False ) <EOL> @ responder ( pattern = "<STR_LIT>" , form = "<STR_LIT>" , help = "<STR_LIT>" ) <EOL> def grab ( conversation , id ) : <EOL> id = int ( id ) <EOL> issue = Issue . byID ( id ) <EOL> if not issue : <EOL> conversation . say ( "<STR_LIT>" % id ) <EOL> elif not issue . hasSOP : <EOL> conversation . say ( "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> conversation . say ( issue . description ) <EOL> contextSummary = '<STR_LIT:\n>' . join ( "<STR_LIT>" % info for info in issue . context . data . items ( ) ) <EOL> conversation . say ( contextSummary , useHTML = False ) <EOL> else : <EOL> existingAgent = issue . context [ '<STR_LIT>' ] <EOL> if existingAgent : <EOL> if existingAgent . conversation is conversation : <EOL> conversation . say ( "<STR_LIT>" ) <EOL> return <EOL> existingAgent . conversation . say ( "<STR_LIT>" % conversation . buddyName ) <EOL> existingAgent . currentIssue = None <EOL> existingAgent . conversation . nevermind ( ) <EOL> conversation . say ( "<STR_LIT>" % id ) <EOL> agent = SupportAgent ( conversation . buddy ) <EOL> agent . ready = True <EOL> agent . currentIssue = None <EOL> agent . conversation . nevermind ( ) <EOL> agent . engage ( issue ) <EOL> @ responder ( pattern = '<STR_LIT>' , form = '<STR_LIT>' , <EOL> help = '<STR_LIT>' ) <EOL> def resolve ( conversation , id , resolution ) : <EOL> id = int ( id ) <EOL> issue = Issue . byID ( id ) <EOL> if not issue : <EOL> conversation . say ( "<STR_LIT>" % id ) <EOL> elif issue . hasSOP : <EOL> conversation . say ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> else : <EOL> conversation . say ( "<STR_LIT>" % id ) <EOL> issue . resolve ( resolution ) </s>
<s> from kitt . interfaces import moduleProvides , IDroneDService <EOL> moduleProvides ( IDroneDService ) <EOL> from kitt . util import dictwrapper <EOL> import config <EOL> SERVICENAME = '<STR_LIT>' <EOL> SERVICECONFIG = dictwrapper ( { <EOL> '<STR_LIT>' : { <EOL> config . LOG_DIR : [ <EOL> ( '<STR_LIT>' , int ( <NUM_LIT:7> * len ( config . AUTOSTART_SERVICES ) ) ) , <EOL> ] , <EOL> } <EOL> } ) <EOL> import os , re , time <EOL> from twisted . application . service import Service <EOL> from twisted . internet import defer , task <EOL> from droned . logging import logWithContext <EOL> from kitt . decorators import synchronizedDeferred , deferredAsThread <EOL> import copy <EOL> __doc__ = """<STR_LIT>""" <EOL> log = logWithContext ( type = SERVICENAME ) <EOL> def ageCompare ( f1 , f2 ) : <EOL> t1 = os . path . getmtime ( f1 ) <EOL> t2 = os . path . getmtime ( f2 ) <EOL> if t1 > t2 : return <NUM_LIT:1> <EOL> if t2 == t2 : return <NUM_LIT:0> <EOL> if t2 < t2 : return - <NUM_LIT:1> <EOL> class Janitizer ( Service ) : <EOL> minute = property ( lambda foo : <NUM_LIT> ) <EOL> hour = property ( lambda foo : <NUM_LIT> ) <EOL> day = property ( lambda foo : <NUM_LIT> ) <EOL> week = property ( lambda f : <NUM_LIT> ) <EOL> oldfiles = { } <EOL> watchDict = property ( lambda s : SERVICECONFIG . wrapped . get ( '<STR_LIT>' , { } ) ) <EOL> busy = defer . DeferredLock ( ) <EOL> def update ( self , watchDict ) : <EOL> """<STR_LIT>""" <EOL> tmp = copy . deepcopy ( self . watchDict ) <EOL> tmp . update ( watchDict ) <EOL> SERVICECONFIG . JANITIZE = tmp <EOL> @ synchronizedDeferred ( busy ) <EOL> @ deferredAsThread <EOL> def garbageCheck ( self ) : <EOL> """<STR_LIT>""" <EOL> watchDict = copy . deepcopy ( self . watchDict ) <EOL> for directory , garbageList in watchDict . iteritems ( ) : <EOL> if not os . path . exists ( directory ) : continue <EOL> for pattern , limit in garbageList : <EOL> self . cleanupLinks ( directory ) <EOL> files = [ os . path . join ( directory , f ) for f in os . listdir ( directory ) if re . search ( pattern , f ) ] <EOL> files = sorted ( files ) <EOL> if len ( files ) > int ( limit ) : <EOL> log ( '<STR_LIT>' % '<STR_LIT>' . join ( files ) ) <EOL> while len ( files ) > int ( limit ) : <EOL> oldfile = files . pop ( <NUM_LIT:0> ) <EOL> log ( '<STR_LIT>' % oldfile ) <EOL> if os . path . islink ( oldfile ) : continue <EOL> if os . path . isdir ( oldfile ) : <EOL> for base , dirs , myfiles in os . walk ( oldfile , topdown = False ) : <EOL> for name in myfiles : <EOL> os . remove ( os . path . join ( base , name ) ) <EOL> for name in dirs : <EOL> os . rmdir ( os . path . join ( base , name ) ) <EOL> os . rmdir ( oldfile ) <EOL> else : os . unlink ( oldfile ) <EOL> self . cleanupLinks ( directory ) <EOL> def cleanupLinks ( self , directory ) : <EOL> """<STR_LIT>""" <EOL> files = [ os . path . join ( directory , f ) for f in os . listdir ( directory ) ] <EOL> for f in files [ : ] : <EOL> if not os . path . exists ( f ) : <EOL> log ( '<STR_LIT>' % f ) <EOL> os . unlink ( f ) <EOL> files . remove ( f ) <EOL> return files <EOL> def clean_old_files ( self , directory , age , recurse = True ) : <EOL> """<STR_LIT>""" <EOL> self . oldfiles [ directory ] = ( age , recurse ) <EOL> @ synchronizedDeferred ( busy ) <EOL> @ deferredAsThread <EOL> def clean_elderly ( self ) : <EOL> """<STR_LIT>""" <EOL> for directory in self . oldfiles : <EOL> self . recursive_clean ( directory , * self . oldfiles [ directory ] ) <EOL> def recursive_clean ( self , directory , age , recurse ) : <EOL> """<STR_LIT>""" <EOL> try : data = map ( lambda n : os . path . join ( directory , n ) , os . listdir ( directory ) ) <EOL> except : <EOL> log ( '<STR_LIT>' % directory ) <EOL> return <EOL> for node in data : <EOL> if os . path . isdir ( node ) and recurse : <EOL> empty = self . recursive_clean ( node , age , recurse ) <EOL> if empty : <EOL> try : os . rmdir ( node ) <EOL> except : log ( '<STR_LIT>' % node ) <EOL> continue <EOL> if os . path . isdir ( node ) : continue <EOL> if ( time . time ( ) - os . stat ( node ) . st_mtime ) > age : <EOL> try : os . remove ( node ) <EOL> except : log ( '<STR_LIT>' % node ) <EOL> return bool ( os . listdir ( directory ) ) <EOL> def startService ( self ) : <EOL> """<STR_LIT>""" <EOL> self . GARBAGE_CHECK = task . LoopingCall ( self . garbageCheck ) <EOL> self . ELDERLY_CHECK = task . LoopingCall ( self . clean_elderly ) <EOL> Service . startService ( self ) <EOL> self . GARBAGE_CHECK . start ( self . minute * <NUM_LIT:20> ) <EOL> self . ELDERLY_CHECK . start ( self . minute ) <EOL> def stopService ( self ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> if self . GARBAGE_CHECK . running : <EOL> self . GARBAGE_CHECK . stop ( ) <EOL> if self . ELDERLY_CHECK . running : <EOL> self . ELDERLY_CHECK . stop ( ) <EOL> except : pass <EOL> Service . stopService ( self ) <EOL> parentService = None <EOL> service = None <EOL> def update ( watchDict ) : <EOL> global service <EOL> if not running ( ) : <EOL> raise AssertionError ( '<STR_LIT>' ) <EOL> return service . update ( watchDict ) <EOL> def install ( _parentService ) : <EOL> global parentService <EOL> parentService = _parentService <EOL> def start ( ) : <EOL> global service <EOL> if not running ( ) : <EOL> service = Janitizer ( ) <EOL> service . setName ( SERVICENAME ) <EOL> service . setServiceParent ( parentService ) <EOL> def stop ( ) : <EOL> global service <EOL> if running ( ) : <EOL> service . disownServiceParent ( ) <EOL> service . stopService ( ) <EOL> service = None <EOL> def running ( ) : <EOL> return bool ( service ) and service . running <EOL> __all__ = [ '<STR_LIT>' , '<STR_LIT:start>' , '<STR_LIT>' , '<STR_LIT>' ] </s>
<s> """<STR_LIT>""" <EOL> from OpenPNM . Geometry import models as gm <EOL> from OpenPNM . Geometry import GenericGeometry <EOL> class SGL10 ( GenericGeometry ) : <EOL> r"""<STR_LIT>""" <EOL> def __init__ ( self , ** kwargs ) : <EOL> super ( ) . __init__ ( ** kwargs ) <EOL> self . _generate ( ) <EOL> def _generate ( self ) : <EOL> self . models . add ( propname = '<STR_LIT>' , <EOL> model = gm . pore_misc . random , <EOL> num_range = [ <NUM_LIT:0> , <NUM_LIT> ] , <EOL> regen_mode = '<STR_LIT>' ) <EOL> self . models . add ( propname = '<STR_LIT>' , <EOL> model = gm . throat_misc . neighbor , <EOL> pore_prop = '<STR_LIT>' , <EOL> mode = '<STR_LIT>' ) <EOL> self . models . add ( propname = '<STR_LIT>' , <EOL> model = gm . pore_diameter . sphere , <EOL> psd_name = '<STR_LIT>' , <EOL> psd_shape = <NUM_LIT> , <EOL> psd_loc = <NUM_LIT> , <EOL> psd_scale = <NUM_LIT> , <EOL> psd_offset = <NUM_LIT> ) <EOL> self . models . add ( propname = '<STR_LIT>' , <EOL> model = gm . pore_area . spherical ) <EOL> self . models . add ( propname = '<STR_LIT>' , <EOL> model = gm . pore_volume . sphere ) <EOL> self . models . add ( propname = '<STR_LIT>' , <EOL> model = gm . throat_diameter . cylinder , <EOL> tsd_name = '<STR_LIT>' , <EOL> tsd_shape = <NUM_LIT> , <EOL> tsd_loc = <NUM_LIT> , <EOL> tsd_scale = <NUM_LIT> , <EOL> tsd_offset = <NUM_LIT> ) <EOL> self . models . add ( propname = '<STR_LIT>' , <EOL> model = gm . throat_length . straight ) <EOL> self . models . add ( propname = '<STR_LIT>' , <EOL> model = gm . throat_volume . cylinder ) <EOL> self . models . add ( propname = '<STR_LIT>' , <EOL> model = gm . throat_area . cylinder ) <EOL> self . models . add ( propname = '<STR_LIT>' , <EOL> model = gm . throat_surface_area . cylinder ) </s>
<s> r"""<STR_LIT>""" <EOL> import scipy as _sp <EOL> def pore_to_pore ( geometry , ** kwargs ) : <EOL> r"""<STR_LIT>""" <EOL> network = geometry . _net <EOL> throats = network . throats ( geometry . name ) <EOL> pores = network . find_connected_pores ( throats , flatten = False ) <EOL> C0 = network [ '<STR_LIT>' ] [ pores , <NUM_LIT:0> ] <EOL> C1 = network [ '<STR_LIT>' ] [ pores , <NUM_LIT:1> ] <EOL> V = C1 - C0 <EOL> L = _sp . array ( _sp . sqrt ( _sp . sum ( V [ : , : ] ** <NUM_LIT:2> , axis = <NUM_LIT:1> ) ) , ndmin = <NUM_LIT:1> ) <EOL> value = V / _sp . array ( L , ndmin = <NUM_LIT:2> ) . T <EOL> return value </s>
<s> r"""<STR_LIT>""" <EOL> import scipy as sp <EOL> def standard ( phase , <EOL> pore_MW = '<STR_LIT>' , <EOL> pore_density = '<STR_LIT>' , <EOL> ** kwargs ) : <EOL> r"""<STR_LIT>""" <EOL> MW = phase [ pore_MW ] <EOL> rho = phase [ pore_density ] <EOL> value = rho / MW <EOL> return value <EOL> def ideal_gas ( phase , <EOL> pore_pressure = '<STR_LIT>' , <EOL> pore_temperature = '<STR_LIT>' , <EOL> ** kwargs ) : <EOL> r"""<STR_LIT>""" <EOL> R = <NUM_LIT> <EOL> P = phase [ pore_pressure ] <EOL> T = phase [ pore_temperature ] <EOL> value = P / ( R * T ) <EOL> return value <EOL> def vanderwaals ( phase , <EOL> pore_P = '<STR_LIT>' , <EOL> pore_T = '<STR_LIT>' , <EOL> pore_Pc = '<STR_LIT>' , <EOL> pore_Tc = '<STR_LIT>' , <EOL> ** kwargs ) : <EOL> r"""<STR_LIT>""" <EOL> P = phase [ pore_P ] / <NUM_LIT> <EOL> T = phase [ pore_T ] <EOL> Pc = phase [ pore_Pc ] / <NUM_LIT> <EOL> Tc = phase [ pore_Tc ] <EOL> R = <NUM_LIT> <EOL> a = <NUM_LIT> * ( R ** <NUM_LIT:2> ) * ( Tc ** <NUM_LIT:2> ) / ( <NUM_LIT:64> * Pc ) <EOL> b = R * Tc / ( <NUM_LIT:8> * Pc ) <EOL> a1 = - <NUM_LIT:1> / b <EOL> a2 = ( R * T + b * P ) / ( a * b ) <EOL> a3 = - P / ( a * b ) <EOL> a0 = sp . ones ( sp . shape ( a1 ) ) <EOL> coeffs = sp . vstack ( ( a0 , a1 , a2 , a3 ) ) . T <EOL> density = sp . array ( [ sp . roots ( C ) for C in coeffs ] ) <EOL> value = sp . real ( density [ : , <NUM_LIT:2> ] ) * <NUM_LIT> <EOL> return value </s>
<s> import os <EOL> import sys <EOL> from distutils . util import convert_path <EOL> try : <EOL> from setuptools import setup <EOL> except ImportError : <EOL> from distutils . core import setup <EOL> sys . path . append ( os . getcwd ( ) ) <EOL> main_ = { } <EOL> ver_path = convert_path ( '<STR_LIT>' ) <EOL> with open ( ver_path ) as f : <EOL> for line in f : <EOL> if line . startswith ( '<STR_LIT>' ) : <EOL> exec ( line , main_ ) <EOL> setup ( <EOL> name = '<STR_LIT>' , <EOL> description = '<STR_LIT>' , <EOL> version = main_ [ '<STR_LIT>' ] , <EOL> classifiers = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' <EOL> ] , <EOL> packages = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' <EOL> ] , <EOL> install_requires = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' <EOL> ] , <EOL> author = '<STR_LIT>' , <EOL> author_email = '<STR_LIT>' , <EOL> download_url = '<STR_LIT>' , <EOL> url = '<STR_LIT>' <EOL> ) </s>
<s> class PoreCentroidTest : <EOL> def test_voronoi ( self ) : <EOL> pass </s>
<s> import pytest <EOL> import OpenPNM <EOL> class GenericPhaseTest : <EOL> def setup_class ( self ) : <EOL> self . net = OpenPNM . Network . Cubic ( shape = [ <NUM_LIT:5> , <NUM_LIT:5> , <NUM_LIT:5> ] ) <EOL> def test_init_w_no_network ( self ) : <EOL> OpenPNM . Phases . GenericPhase ( ) <EOL> def test_init_w_components ( self ) : <EOL> comp1 = OpenPNM . Phases . GenericPhase ( network = self . net ) <EOL> comp2 = OpenPNM . Phases . GenericPhase ( network = self . net ) <EOL> OpenPNM . Phases . GenericPhase ( network = self . net , <EOL> components = [ comp1 , comp2 ] ) <EOL> def test_set_component_add ( self ) : <EOL> comp1 = OpenPNM . Phases . GenericPhase ( network = self . net ) <EOL> comp2 = OpenPNM . Phases . GenericPhase ( network = self . net ) <EOL> phase = OpenPNM . Phases . GenericPhase ( network = self . net ) <EOL> phase . set_component ( comp1 ) <EOL> phase . set_component ( comp2 ) <EOL> def test_set_component_add_twice ( self ) : <EOL> comp1 = OpenPNM . Phases . GenericPhase ( network = self . net ) <EOL> phase = OpenPNM . Phases . GenericPhase ( network = self . net ) <EOL> phase . set_component ( comp1 ) <EOL> with pytest . raises ( Exception ) : <EOL> phase . set_components ( comp1 ) <EOL> def test_set_component_remove ( self ) : <EOL> comp1 = OpenPNM . Phases . GenericPhase ( network = self . net ) <EOL> comp2 = OpenPNM . Phases . GenericPhase ( network = self . net ) <EOL> phase = OpenPNM . Phases . GenericPhase ( network = self . net , <EOL> components = [ comp1 , comp2 ] ) <EOL> phase . set_component ( comp1 , mode = '<STR_LIT>' ) <EOL> phase . set_component ( comp2 , mode = '<STR_LIT>' ) <EOL> def test_set_component_remove_twice ( self ) : <EOL> comp1 = OpenPNM . Phases . GenericPhase ( network = self . net ) <EOL> comp2 = OpenPNM . Phases . GenericPhase ( network = self . net ) <EOL> phase = OpenPNM . Phases . GenericPhase ( network = self . net , <EOL> components = [ comp1 , comp2 ] ) <EOL> phase . set_component ( comp1 , mode = '<STR_LIT>' ) <EOL> with pytest . raises ( Exception ) : <EOL> phase . set_component ( comp1 , mode = '<STR_LIT>' ) </s>
<s> </s>
<s> import pdb <EOL> import os , sys <EOL> import itertools <EOL> from cPickle import * <EOL> from collections import defaultdict , namedtuple <EOL> from pbtools . pbtranscript . Utils import check_ids_unique <EOL> import pbtools . pbtranscript . tofu_wrap as tofu_wrap <EOL> import pbtools . pbtranscript . BioReaders as BioReaders <EOL> import pbtools . pbtranscript . branch . branch_simple2 as branch_simple2 <EOL> import pbtools . pbtranscript . counting . compare_junctions as compare_junctions <EOL> from pbtools . pbtranscript . io . SeqReaders import LazyFastaReader , LazyFastqReader <EOL> from pbcore . io . FastaIO import FastaWriter <EOL> from pbcore . io . FastqIO import FastqWriter <EOL> from bx . intervals . cluster import ClusterTree <EOL> def pick_rep ( fa_fq_filename , sam_filename , gff_filename , group_filename , output_filename , is_fq = False , pick_least_err_instead = False ) : <EOL> """<STR_LIT>""" <EOL> if is_fq : <EOL> fd = LazyFastqReader ( fa_fq_filename ) <EOL> fout = FastqWriter ( output_filename ) <EOL> else : <EOL> fd = LazyFastaReader ( fa_fq_filename ) <EOL> fout = FastaWriter ( output_filename ) <EOL> rep_info = { } <EOL> id_to_rep = { } <EOL> for line in open ( group_filename ) : <EOL> pb_id , members = line . strip ( ) . split ( '<STR_LIT:\t>' ) <EOL> print >> sys . stderr , "<STR_LIT>" , pb_id <EOL> best_id = None <EOL> best_seq = None <EOL> best_qual = None <EOL> best_err = <NUM_LIT> <EOL> err = <NUM_LIT> <EOL> max_len = <NUM_LIT:0> <EOL> for x in members . split ( '<STR_LIT:U+002C>' ) : <EOL> if is_fq and pick_least_err_instead : <EOL> err = sum ( i ** - ( i / <NUM_LIT> ) for i in fd [ x ] . quality ) <EOL> if ( is_fq and pick_least_err_instead and err < best_err ) or ( ( not is_fq or not pick_least_err_instead ) and len ( fd [ x ] . sequence ) >= max_len ) : <EOL> best_id = x <EOL> best_seq = fd [ x ] . sequence <EOL> if is_fq : <EOL> best_qual = fd [ x ] . quality <EOL> best_err = err <EOL> max_len = len ( fd [ x ] . sequence ) <EOL> rep_info [ pb_id ] = ( best_id , best_seq , best_qual ) <EOL> id_to_rep [ best_id ] = pb_id <EOL> f_gff = open ( gff_filename , '<STR_LIT:w>' ) <EOL> coords = { } <EOL> record_storage = { } <EOL> for r in BioReaders . GMAPSAMReader ( sam_filename , True ) : <EOL> if r . qID in id_to_rep : <EOL> pb_id = id_to_rep [ r . qID ] <EOL> best_id , best_seq , best_qual = rep_info [ pb_id ] <EOL> if r . qID not in coords : <EOL> coords [ r . qID ] = "<STR_LIT>" . format ( r . sID , r . sStart , r . sEnd , r . flag . strand ) <EOL> isoform_index = <NUM_LIT:1> <EOL> record_storage [ pb_id ] = r <EOL> else : <EOL> coords [ r . qID ] += "<STR_LIT>" . format ( r . sID , r . sStart , r . sEnd , r . flag . strand ) <EOL> isoform_index = <NUM_LIT:1> <EOL> old_r = record_storage [ pb_id ] <EOL> f_gff . write ( "<STR_LIT>" . format ( chr = old_r . sID , s = old_r . segments [ <NUM_LIT:0> ] . start + <NUM_LIT:1> , e = old_r . segments [ - <NUM_LIT:1> ] . end , pi = pb_id , j = isoform_index , strand = old_r . flag . strand ) ) <EOL> for s in old_r . segments : <EOL> f_gff . write ( "<STR_LIT>" . format ( chr = old_r . sID , s = s . start + <NUM_LIT:1> , e = s . end , pi = pb_id , j = isoform_index , strand = old_r . flag . strand ) ) <EOL> isoform_index = <NUM_LIT:2> <EOL> f_gff . write ( "<STR_LIT>" . format ( chr = r . sID , s = r . segments [ <NUM_LIT:0> ] . start + <NUM_LIT:1> , e = r . segments [ - <NUM_LIT:1> ] . end , pi = pb_id , j = isoform_index , strand = r . flag . strand ) ) <EOL> for s in r . segments : <EOL> f_gff . write ( "<STR_LIT>" . format ( chr = r . sID , s = s . start + <NUM_LIT:1> , e = s . end , pi = pb_id , j = isoform_index , strand = r . flag . strand ) ) <EOL> f_gff . close ( ) <EOL> for pb_id in rep_info : <EOL> best_id , best_seq , best_qual = rep_info [ pb_id ] <EOL> _id_ = "<STR_LIT>" . format ( pb_id , coords [ best_id ] , best_id ) <EOL> _seq_ = best_seq <EOL> if is_fq : <EOL> fout . writeRecord ( _id_ , _seq_ , best_qual ) <EOL> else : <EOL> fout . writeRecord ( _id_ , _seq_ ) <EOL> def sep_by_strand ( records ) : <EOL> output = { '<STR_LIT:+>' : [ ] , '<STR_LIT:->' : [ ] } <EOL> for r in records : <EOL> output [ r . flag . strand ] . append ( r ) <EOL> return output <EOL> def is_fusion_compatible ( r1 , r2 , max_fusion_point_dist , max_exon_end_dist , allow_extra_5_exons ) : <EOL> """<STR_LIT>""" <EOL> assert r1 . flag . strand == r2 . flag . strand <EOL> if r1 . qStart <= <NUM_LIT> * r1 . qLen : <EOL> if r2 . qStart > <NUM_LIT> * r2 . qLen : <EOL> return False <EOL> in_5_portion = True <EOL> else : <EOL> if r2 . qStart <= <NUM_LIT> * r2 . qLen : <EOL> return False <EOL> in_5_portion = False <EOL> plus_is_5end = ( r1 . flag . strand == '<STR_LIT:+>' ) <EOL> type = compare_junctions . compare_junctions ( r1 , r2 ) <EOL> if type == '<STR_LIT>' : <EOL> if len ( r1 . segments ) == <NUM_LIT:1> : <EOL> if len ( r2 . segments ) == <NUM_LIT:1> : <EOL> if in_5_portion and plus_is_5end : dist = abs ( r1 . sStart - r2 . sStart ) <EOL> else : dist = abs ( r1 . sEnd - r2 . sEnd ) <EOL> return dist <= max_fusion_point_dist <EOL> else : <EOL> raise Exception , "<STR_LIT>" + "<STR_LIT>" <EOL> else : <EOL> return True <EOL> elif type == '<STR_LIT>' or type == '<STR_LIT>' : <EOL> if allow_extra_5_exons : <EOL> if in_5_portion and plus_is_5end : <EOL> if abs ( r1 . segments [ - <NUM_LIT:1> ] . start - r2 . segments [ - <NUM_LIT:1> ] . start ) > max_exon_end_dist : return False <EOL> if abs ( r1 . segments [ - <NUM_LIT:1> ] . end - r2 . segments [ - <NUM_LIT:1> ] . end ) > max_fusion_point_dist : return False <EOL> return True <EOL> elif in_5_portion and ( not plus_is_5end ) : <EOL> if abs ( r1 . segments [ <NUM_LIT:0> ] . end - r2 . segments [ <NUM_LIT:0> ] . end ) > max_exon_end_dist : return False <EOL> if abs ( r1 . segments [ <NUM_LIT:0> ] . start - r2 . segments [ <NUM_LIT:0> ] . start ) > max_fusion_point_dist : return False <EOL> return True <EOL> else : <EOL> return False <EOL> else : <EOL> return False <EOL> else : <EOL> return False <EOL> def merge_fusion_exons ( records , max_fusion_point_dist , max_exon_end_dist , allow_extra_5_exons ) : <EOL> """<STR_LIT>""" <EOL> output = [ [ records [ <NUM_LIT:0> ] ] ] <EOL> for r1 in records [ <NUM_LIT:1> : ] : <EOL> merged = False <EOL> for i , r2s in enumerate ( output ) : <EOL> if all ( is_fusion_compatible ( r1 , r2 , max_fusion_point_dist , max_exon_end_dist , allow_extra_5_exons ) for r2 in r2s ) : <EOL> output [ i ] . append ( r1 ) <EOL> merged = True <EOL> break <EOL> if not merged : <EOL> output . append ( [ r1 ] ) <EOL> return output <EOL> def iter_gmap_sam_for_fusion ( gmap_sam_filename , fusion_candidates , transfrag_len_dict ) : <EOL> """<STR_LIT>""" <EOL> records = [ ] <EOL> iter = BioReaders . GMAPSAMReader ( gmap_sam_filename , True , query_len_dict = transfrag_len_dict ) <EOL> for r in iter : <EOL> if r . qID in fusion_candidates : <EOL> records = [ r ] <EOL> break <EOL> for r in iter : <EOL> if len ( records ) >= <NUM_LIT:1> and ( r . sID == records [ - <NUM_LIT:1> ] . sID and r . sStart < records [ - <NUM_LIT:1> ] . sStart ) : <EOL> print >> sys . stderr , "<STR_LIT>" <EOL> sys . exit ( - <NUM_LIT:1> ) <EOL> if len ( records ) >= <NUM_LIT:1> and ( r . sID != records [ <NUM_LIT:0> ] . sID or r . sStart > records [ - <NUM_LIT:1> ] . sEnd ) : <EOL> yield ( sep_by_strand ( records ) ) <EOL> records = [ ] <EOL> if r . qID in fusion_candidates : <EOL> records . append ( r ) <EOL> if len ( records ) > <NUM_LIT:0> : <EOL> yield ( sep_by_strand ( records ) ) <EOL> def find_fusion_candidates ( sam_filename , query_len_dict , min_locus_coverage = <NUM_LIT> , min_locus_coverage_bp = <NUM_LIT:1> , min_total_coverage = <NUM_LIT> , min_dist_between_loci = <NUM_LIT> ) : <EOL> """<STR_LIT>""" <EOL> TmpRec = namedtuple ( '<STR_LIT>' , [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> def total_coverage ( tmprecs ) : <EOL> tree = ClusterTree ( <NUM_LIT:0> , <NUM_LIT:0> ) <EOL> for r in tmprecs : tree . insert ( r . qStart , r . qEnd , - <NUM_LIT:1> ) <EOL> return sum ( reg [ <NUM_LIT:1> ] - reg [ <NUM_LIT:0> ] for reg in tree . getregions ( ) ) <EOL> d = defaultdict ( lambda : [ ] ) <EOL> reader = BioReaders . GMAPSAMReader ( sam_filename , True , query_len_dict = query_len_dict ) <EOL> for r in reader : <EOL> if r . sID == '<STR_LIT:*>' : continue <EOL> if r . flag . strand == '<STR_LIT:+>' : <EOL> d [ r . qID ] . append ( TmpRec ( qCov = r . qCoverage , qLen = r . qLen , qStart = r . qStart , qEnd = r . qEnd , sStart = r . sStart , sEnd = r . sEnd , iden = r . identity ) ) <EOL> else : <EOL> d [ r . qID ] . append ( TmpRec ( qCov = r . qCoverage , qLen = r . qLen , qStart = r . qLen - r . qEnd , qEnd = r . qLen - r . qStart , sStart = r . sStart , sEnd = r . sEnd , iden = r . identity ) ) <EOL> fusion_candidates = [ ] <EOL> for k , data in d . iteritems ( ) : <EOL> if len ( data ) > <NUM_LIT:1> and all ( a . iden >= <NUM_LIT> for a in data ) and all ( a . qCov >= min_locus_coverage for a in data ) and all ( a . qCov * a . qLen >= min_locus_coverage_bp for a in data ) and total_coverage ( data ) * <NUM_LIT:1.> / data [ <NUM_LIT:0> ] . qLen >= min_total_coverage and all ( max ( a . sStart , b . sStart ) - min ( a . sEnd , b . sEnd ) >= min_dist_between_loci for a , b in itertools . combinations ( data , <NUM_LIT:2> ) ) : <EOL> fusion_candidates . append ( k ) <EOL> return fusion_candidates <EOL> def fusion_main ( fa_or_fq_filename , sam_filename , output_prefix , is_fq = False , allow_extra_5_exons = True , skip_5_exon_alt = True , prefix_dict_pickle_filename = None , min_locus_coverage = <NUM_LIT> , min_total_coverage = <NUM_LIT> , min_locus_coverage_bp = <NUM_LIT:1> , min_dist_between_loci = <NUM_LIT> ) : <EOL> """<STR_LIT>""" <EOL> compressed_records_pointer_dict = defaultdict ( lambda : [ ] ) <EOL> merged_exons = [ ] <EOL> merged_i = <NUM_LIT:0> <EOL> check_ids_unique ( fa_or_fq_filename , is_fq = is_fq ) <EOL> bs = branch_simple2 . BranchSimple ( fa_or_fq_filename , is_fq = is_fq ) <EOL> fusion_candidates = find_fusion_candidates ( sam_filename , bs . transfrag_len_dict , min_locus_coverage , min_locus_coverage_bp , min_total_coverage , min_dist_between_loci ) <EOL> for recs in iter_gmap_sam_for_fusion ( sam_filename , fusion_candidates , bs . transfrag_len_dict ) : <EOL> for v in recs . itervalues ( ) : <EOL> if len ( v ) > <NUM_LIT:0> : <EOL> o = merge_fusion_exons ( v , max_fusion_point_dist = <NUM_LIT:100> , max_exon_end_dist = <NUM_LIT:0> , allow_extra_5_exons = allow_extra_5_exons ) <EOL> for group in o : <EOL> merged_exons . append ( group ) <EOL> for r in group : compressed_records_pointer_dict [ r . qID ] . append ( merged_i ) <EOL> merged_i += <NUM_LIT:1> <EOL> f_group = open ( '<STR_LIT>' , '<STR_LIT:w>' ) <EOL> gene_index = <NUM_LIT:1> <EOL> already_seen = set ( ) <EOL> for qid , indices in compressed_records_pointer_dict . iteritems ( ) : <EOL> combo = tuple ( indices ) <EOL> if combo in already_seen : <EOL> print "<STR_LIT>" , combo <EOL> continue <EOL> already_seen . add ( combo ) <EOL> for isoform_index , i in enumerate ( indices ) : <EOL> bs . cuff_index = gene_index <EOL> records = merged_exons [ i ] <EOL> f_group . write ( "<STR_LIT>" . format ( p = "<STR_LIT>" , i = gene_index , j = isoform_index , ids = "<STR_LIT:U+002C>" . join ( r . qID for r in records ) ) ) <EOL> gene_index += <NUM_LIT:1> <EOL> f_group . close ( ) <EOL> f_group = open ( output_prefix + '<STR_LIT>' , '<STR_LIT:w>' ) <EOL> group_info = { } <EOL> count = <NUM_LIT:0> <EOL> with open ( '<STR_LIT>' ) as f : <EOL> while True : <EOL> line = f . readline ( ) . strip ( ) <EOL> if len ( line ) == <NUM_LIT:0> : break <EOL> pbid1 , groups1 = line . strip ( ) . split ( '<STR_LIT:\t>' ) <EOL> pbid2 , groups2 = f . readline ( ) . strip ( ) . split ( '<STR_LIT:\t>' ) <EOL> assert pbid1 . split ( '<STR_LIT:.>' ) [ <NUM_LIT:1> ] == pbid2 . split ( '<STR_LIT:.>' ) [ <NUM_LIT:1> ] <EOL> group = set ( groups1 . split ( '<STR_LIT:U+002C>' ) ) . intersection ( groups2 . split ( '<STR_LIT:U+002C>' ) ) <EOL> f_group . write ( "<STR_LIT>" . format ( pbid1 [ : pbid1 . rfind ( '<STR_LIT:.>' ) ] , "<STR_LIT:U+002C>" . join ( group ) ) ) <EOL> group_info [ pbid1 [ : pbid1 . rfind ( '<STR_LIT:.>' ) ] ] = list ( group ) <EOL> count += <NUM_LIT:1> <EOL> f_group . close ( ) <EOL> gff_filename = output_prefix + '<STR_LIT>' <EOL> group_filename = output_prefix + '<STR_LIT>' <EOL> if is_fq : <EOL> output_filename = output_prefix + '<STR_LIT>' <EOL> else : <EOL> output_filename = output_prefix + '<STR_LIT>' <EOL> pick_rep ( fa_or_fq_filename , sam_filename , gff_filename , group_filename , output_filename , is_fq = is_fq , pick_least_err_instead = False ) <EOL> print >> sys . stderr , "<STR_LIT>" . format ( count ) <EOL> print >> sys . stderr , "<STR_LIT>" . format ( output_prefix , output_filename ) <EOL> if prefix_dict_pickle_filename is not None : <EOL> with open ( prefix_dict_pickle_filename ) as f : <EOL> d = load ( f ) <EOL> d1 = d [ '<STR_LIT>' ] <EOL> d1 . update ( d [ '<STR_LIT>' ] ) <EOL> tofu_wrap . get_abundance ( output_prefix , d1 , output_prefix ) <EOL> print >> sys . stderr , "<STR_LIT>" . format ( output_prefix ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> from argparse import ArgumentParser <EOL> parser = ArgumentParser ( ) <EOL> parser . add_argument ( "<STR_LIT>" , help = "<STR_LIT>" ) <EOL> parser . add_argument ( "<STR_LIT>" , default = False , action = "<STR_LIT:store_true>" , help = "<STR_LIT>" ) <EOL> parser . add_argument ( "<STR_LIT>" , "<STR_LIT>" , required = True , help = "<STR_LIT>" ) <EOL> parser . add_argument ( "<STR_LIT>" , "<STR_LIT>" , required = True , help = "<STR_LIT>" ) <EOL> parser . add_argument ( "<STR_LIT>" , action = "<STR_LIT>" , dest = "<STR_LIT>" , default = True , help = "<STR_LIT>" ) <EOL> parser . add_argument ( "<STR_LIT>" , default = None , help = "<STR_LIT>" ) <EOL> parser . add_argument ( "<STR_LIT:-c>" , "<STR_LIT>" , type = float , default = <NUM_LIT> , help = "<STR_LIT>" ) <EOL> parser . add_argument ( "<STR_LIT>" , type = int , default = <NUM_LIT:1> , help = "<STR_LIT>" ) <EOL> parser . add_argument ( "<STR_LIT>" , "<STR_LIT>" , type = float , default = <NUM_LIT> , help = "<STR_LIT>" ) <EOL> parser . add_argument ( "<STR_LIT>" , "<STR_LIT>" , type = int , default = <NUM_LIT> , help = "<STR_LIT>" ) <EOL> args = parser . parse_args ( ) <EOL> fusion_main ( args . input , args . sam , args . prefix , <EOL> is_fq = args . fq , allow_extra_5_exons = args . allow_extra_5exon , <EOL> skip_5_exon_alt = False , prefix_dict_pickle_filename = args . prefix_dict_pickle_filename , <EOL> min_locus_coverage = args . min_locus_coverage , min_locus_coverage_bp = args . min_locus_coverage_bp , <EOL> min_total_coverage = args . min_total_coverage , <EOL> min_dist_between_loci = args . min_dist_between_loci ) </s>
<s> __author__ = '<STR_LIT>' <EOL> import pdb <EOL> import os , sys , subprocess <EOL> import numpy <EOL> from pbtools . pbtranscript . io . BLASRRecord import BLASRRecord <EOL> from pbtools . pbtranscript . ice . IceUtils import HitItem , eval_blasr_alignment , alignment_has_large_nonmatch <EOL> from pbtools . pbtranscript . ice . c_IceAlign import get_ece_arr_from_alignment <EOL> class LAshowAlignReader : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , las_out_filename ) : <EOL> self . las_out_filename = las_out_filename <EOL> self . f = open ( las_out_filename ) <EOL> def __iter__ ( self ) : <EOL> return self <EOL> def next ( self ) : <EOL> """<STR_LIT>""" <EOL> raw = self . f . readline ( ) . strip ( ) . split ( ) <EOL> if raw [ <NUM_LIT:0> ] == '<STR_LIT:+>' and raw [ <NUM_LIT:1> ] == '<STR_LIT:+>' : <EOL> raise StopIteration <EOL> qID = int ( raw [ <NUM_LIT:0> ] ) + <NUM_LIT:1> <EOL> sID = int ( raw [ <NUM_LIT:1> ] ) + <NUM_LIT:1> <EOL> score = int ( raw [ <NUM_LIT:2> ] ) <EOL> iden = float ( raw [ <NUM_LIT:3> ] ) <EOL> qStrand = int ( raw [ <NUM_LIT:4> ] ) <EOL> qStart = int ( raw [ <NUM_LIT:5> ] ) <EOL> qEnd = int ( raw [ <NUM_LIT:6> ] ) <EOL> qLen = int ( raw [ <NUM_LIT:7> ] ) <EOL> sStrand = int ( raw [ <NUM_LIT:8> ] ) <EOL> sStart = int ( raw [ <NUM_LIT:9> ] ) <EOL> sEnd = int ( raw [ <NUM_LIT:10> ] ) <EOL> sLen = int ( raw [ <NUM_LIT:11> ] ) <EOL> self . f . readline ( ) <EOL> _qStart , qAln = self . f . readline ( ) . strip ( ) . split ( ) <EOL> assert ( qStrand == <NUM_LIT:0> and int ( _qStart ) - <NUM_LIT:1> == qStart ) or ( qStrand == <NUM_LIT:1> and int ( _qStart ) - <NUM_LIT:1> == qLen - qEnd ) <EOL> alnStr = self . f . readline ( ) . strip ( ) <EOL> _sStart , sAln = self . f . readline ( ) . strip ( ) . split ( ) [ : <NUM_LIT:2> ] <EOL> assert ( sStrand == <NUM_LIT:0> and int ( _sStart ) - <NUM_LIT:1> == sStart ) or ( sStrand == <NUM_LIT:1> and int ( _sStart ) - <NUM_LIT:1> == sLen - sEnd ) <EOL> return BLASRRecord ( qID , qLen , qStart , qEnd , qStrand , sID , sLen , sStart , sEnd , sStrand , score , None , qAln = qAln , alnStr = alnStr , sAln = sAln , identity = iden , strand = '<STR_LIT:+>' if qStrand == sStrand else '<STR_LIT:->' ) <EOL> def dalign_against_ref ( dazz_query_obj , dazz_db_obj , las_out_filename , is_FL , sID_starts_with_c , <EOL> qver_get_func , qvmean_get_func , qv_prob_threshold = <NUM_LIT> , <EOL> ece_penalty = <NUM_LIT:1> , ece_min_len = <NUM_LIT:20> , same_strand_only = True , no_qv_or_aln_checking = False , <EOL> max_missed_start = <NUM_LIT:200> , max_missed_end = <NUM_LIT:50> ) : <EOL> """<STR_LIT>""" <EOL> for r in LAshowAlignReader ( las_out_filename ) : <EOL> missed_q = r . qStart + r . qLength - r . qEnd <EOL> missed_t = r . sStart + r . sLength - r . sEnd <EOL> r . qID = dazz_query_obj [ r . qID ] <EOL> r . sID = dazz_db_obj [ r . sID ] <EOL> if sID_starts_with_c : <EOL> assert r . sID . startswith ( '<STR_LIT:c>' ) <EOL> if r . sID . find ( '<STR_LIT:/>' ) > <NUM_LIT:0> : <EOL> r . sID = r . sID . split ( '<STR_LIT:/>' ) [ <NUM_LIT:0> ] <EOL> if r . sID . endswith ( '<STR_LIT>' ) : <EOL> cID = int ( r . sID [ <NUM_LIT:1> : - <NUM_LIT:4> ] ) <EOL> else : <EOL> cID = int ( r . sID [ <NUM_LIT:1> : ] ) <EOL> else : <EOL> cID = r . sID <EOL> if ( cID == r . qID or <EOL> ( r . strand == '<STR_LIT:->' and same_strand_only ) ) : <EOL> yield HitItem ( qID = r . qID , cID = cID ) <EOL> continue <EOL> if no_qv_or_aln_checking : <EOL> yield HitItem ( qID = r . qID , cID = cID , <EOL> qStart = r . qStart , qEnd = r . qEnd , <EOL> missed_q = missed_q * <NUM_LIT:1.> / r . qLength , <EOL> missed_t = missed_t * <NUM_LIT:1.> / r . sLength , <EOL> fakecigar = <NUM_LIT:1> , <EOL> ece_arr = <NUM_LIT:1> ) <EOL> continue <EOL> if ( is_FL and ( r . sStart > max_missed_start or r . qStart > max_missed_start or <EOL> ( r . sLength - r . sEnd > max_missed_end ) or <EOL> ( r . qLength - r . qEnd > max_missed_end ) ) ) : <EOL> yield HitItem ( qID = r . qID , cID = cID ) <EOL> else : <EOL> cigar_str , ece_arr = eval_blasr_alignment ( <EOL> record = r , <EOL> qver_get_func = qver_get_func , <EOL> sID_starts_with_c = sID_starts_with_c , <EOL> qv_prob_threshold = qv_prob_threshold , <EOL> qvmean_get_func = qvmean_get_func ) <EOL> if alignment_has_large_nonmatch ( ece_arr , <EOL> ece_penalty , ece_min_len ) : <EOL> yield HitItem ( qID = r . qID , cID = cID ) <EOL> else : <EOL> yield HitItem ( qID = r . qID , cID = cID , <EOL> qStart = r . qStart , qEnd = r . qEnd , <EOL> missed_q = missed_q * <NUM_LIT:1.> / r . qLength , <EOL> missed_t = missed_t * <NUM_LIT:1.> / r . sLength , <EOL> fakecigar = cigar_str , <EOL> ece_arr = ece_arr ) </s>
<s> """<STR_LIT>""" <EOL> import unittest <EOL> class TestInitICE ( unittest . TestCase ) : <EOL> """<STR_LIT>""" <EOL> def setUp ( self ) : <EOL> """<STR_LIT>""" <EOL> self . rootDir = op . dirname ( op . dirname ( op . abspath ( __file__ ) ) ) <EOL> self . testDir = op . join ( self . rootDir , "<STR_LIT>" ) </s>
<s> """<STR_LIT>""" <EOL> __version__ = '<STR_LIT>' <EOL> __all__ = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> ] <EOL> import copy as _copy <EOL> import os as _os <EOL> import re as _re <EOL> import sys as _sys <EOL> import textwrap as _textwrap <EOL> from gettext import gettext as _ <EOL> try : <EOL> set <EOL> except NameError : <EOL> from sets import Set as set <EOL> try : <EOL> basestring <EOL> except NameError : <EOL> basestring = str <EOL> try : <EOL> sorted <EOL> except NameError : <EOL> def sorted ( iterable , reverse = False ) : <EOL> result = list ( iterable ) <EOL> result . sort ( ) <EOL> if reverse : <EOL> result . reverse ( ) <EOL> return result <EOL> def _callable ( obj ) : <EOL> return hasattr ( obj , '<STR_LIT>' ) or hasattr ( obj , '<STR_LIT>' ) <EOL> SUPPRESS = '<STR_LIT>' <EOL> OPTIONAL = '<STR_LIT:?>' <EOL> ZERO_OR_MORE = '<STR_LIT:*>' <EOL> ONE_OR_MORE = '<STR_LIT:+>' <EOL> PARSER = '<STR_LIT>' <EOL> REMAINDER = '<STR_LIT>' <EOL> _UNRECOGNIZED_ARGS_ATTR = '<STR_LIT>' <EOL> class _AttributeHolder ( object ) : <EOL> """<STR_LIT>""" <EOL> def __repr__ ( self ) : <EOL> type_name = type ( self ) . __name__ <EOL> arg_strings = [ ] <EOL> for arg in self . _get_args ( ) : <EOL> arg_strings . append ( repr ( arg ) ) <EOL> for name , value in self . _get_kwargs ( ) : <EOL> arg_strings . append ( '<STR_LIT>' % ( name , value ) ) <EOL> return '<STR_LIT>' % ( type_name , '<STR_LIT:U+002CU+0020>' . join ( arg_strings ) ) <EOL> def _get_kwargs ( self ) : <EOL> return sorted ( self . __dict__ . items ( ) ) <EOL> def _get_args ( self ) : <EOL> return [ ] <EOL> def _ensure_value ( namespace , name , value ) : <EOL> if getattr ( namespace , name , None ) is None : <EOL> setattr ( namespace , name , value ) <EOL> return getattr ( namespace , name ) <EOL> class HelpFormatter ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , <EOL> prog , <EOL> indent_increment = <NUM_LIT:2> , <EOL> max_help_position = <NUM_LIT> , <EOL> width = None ) : <EOL> if width is None : <EOL> try : <EOL> width = int ( _os . environ [ '<STR_LIT>' ] ) <EOL> except ( KeyError , ValueError ) : <EOL> width = <NUM_LIT> <EOL> width -= <NUM_LIT:2> <EOL> self . _prog = prog <EOL> self . _indent_increment = indent_increment <EOL> self . _max_help_position = max_help_position <EOL> self . _width = width <EOL> self . _current_indent = <NUM_LIT:0> <EOL> self . _level = <NUM_LIT:0> <EOL> self . _action_max_length = <NUM_LIT:0> <EOL> self . _root_section = self . _Section ( self , None ) <EOL> self . _current_section = self . _root_section <EOL> self . _whitespace_matcher = _re . compile ( r'<STR_LIT>' ) <EOL> self . _long_break_matcher = _re . compile ( r'<STR_LIT>' ) <EOL> def _indent ( self ) : <EOL> self . _current_indent += self . _indent_increment <EOL> self . _level += <NUM_LIT:1> <EOL> def _dedent ( self ) : <EOL> self . _current_indent -= self . _indent_increment <EOL> assert self . _current_indent >= <NUM_LIT:0> , '<STR_LIT>' <EOL> self . _level -= <NUM_LIT:1> <EOL> class _Section ( object ) : <EOL> def __init__ ( self , formatter , parent , heading = None ) : <EOL> self . formatter = formatter <EOL> self . parent = parent <EOL> self . heading = heading <EOL> self . items = [ ] <EOL> def format_help ( self ) : <EOL> if self . parent is not None : <EOL> self . formatter . _indent ( ) <EOL> join = self . formatter . _join_parts <EOL> for func , args in self . items : <EOL> func ( * args ) <EOL> item_help = join ( [ func ( * args ) for func , args in self . items ] ) <EOL> if self . parent is not None : <EOL> self . formatter . _dedent ( ) <EOL> if not item_help : <EOL> return '<STR_LIT>' <EOL> if self . heading is not SUPPRESS and self . heading is not None : <EOL> current_indent = self . formatter . _current_indent <EOL> heading = '<STR_LIT>' % ( current_indent , '<STR_LIT>' , self . heading ) <EOL> else : <EOL> heading = '<STR_LIT>' <EOL> return join ( [ '<STR_LIT:\n>' , heading , item_help , '<STR_LIT:\n>' ] ) <EOL> def _add_item ( self , func , args ) : <EOL> self . _current_section . items . append ( ( func , args ) ) <EOL> def start_section ( self , heading ) : <EOL> self . _indent ( ) <EOL> section = self . _Section ( self , self . _current_section , heading ) <EOL> self . _add_item ( section . format_help , [ ] ) <EOL> self . _current_section = section <EOL> def end_section ( self ) : <EOL> self . _current_section = self . _current_section . parent <EOL> self . _dedent ( ) <EOL> def add_text ( self , text ) : <EOL> if text is not SUPPRESS and text is not None : <EOL> self . _add_item ( self . _format_text , [ text ] ) <EOL> def add_usage ( self , usage , actions , groups , prefix = None ) : <EOL> if usage is not SUPPRESS : <EOL> args = usage , actions , groups , prefix <EOL> self . _add_item ( self . _format_usage , args ) <EOL> def add_argument ( self , action ) : <EOL> if action . help is not SUPPRESS : <EOL> get_invocation = self . _format_action_invocation <EOL> invocations = [ get_invocation ( action ) ] <EOL> for subaction in self . _iter_indented_subactions ( action ) : <EOL> invocations . append ( get_invocation ( subaction ) ) <EOL> invocation_length = max ( [ len ( s ) for s in invocations ] ) <EOL> action_length = invocation_length + self . _current_indent <EOL> self . _action_max_length = max ( self . _action_max_length , <EOL> action_length ) <EOL> self . _add_item ( self . _format_action , [ action ] ) <EOL> def add_arguments ( self , actions ) : <EOL> for action in actions : <EOL> self . add_argument ( action ) <EOL> def format_help ( self ) : <EOL> help = self . _root_section . format_help ( ) <EOL> if help : <EOL> help = self . _long_break_matcher . sub ( '<STR_LIT>' , help ) <EOL> help = help . strip ( '<STR_LIT:\n>' ) + '<STR_LIT:\n>' <EOL> return help <EOL> def _join_parts ( self , part_strings ) : <EOL> return '<STR_LIT>' . join ( [ part <EOL> for part in part_strings <EOL> if part and part is not SUPPRESS ] ) <EOL> def _format_usage ( self , usage , actions , groups , prefix ) : <EOL> if prefix is None : <EOL> prefix = _ ( '<STR_LIT>' ) <EOL> if usage is not None : <EOL> usage = usage % dict ( prog = self . _prog ) <EOL> elif usage is None and not actions : <EOL> usage = '<STR_LIT>' % dict ( prog = self . _prog ) <EOL> elif usage is None : <EOL> prog = '<STR_LIT>' % dict ( prog = self . _prog ) <EOL> optionals = [ ] <EOL> positionals = [ ] <EOL> for action in actions : <EOL> if action . option_strings : <EOL> optionals . append ( action ) <EOL> else : <EOL> positionals . append ( action ) <EOL> format = self . _format_actions_usage <EOL> action_usage = format ( optionals + positionals , groups ) <EOL> usage = '<STR_LIT:U+0020>' . join ( [ s for s in [ prog , action_usage ] if s ] ) <EOL> text_width = self . _width - self . _current_indent <EOL> if len ( prefix ) + len ( usage ) > text_width : <EOL> part_regexp = r'<STR_LIT>' <EOL> opt_usage = format ( optionals , groups ) <EOL> pos_usage = format ( positionals , groups ) <EOL> opt_parts = _re . findall ( part_regexp , opt_usage ) <EOL> pos_parts = _re . findall ( part_regexp , pos_usage ) <EOL> assert '<STR_LIT:U+0020>' . join ( opt_parts ) == opt_usage <EOL> assert '<STR_LIT:U+0020>' . join ( pos_parts ) == pos_usage <EOL> def get_lines ( parts , indent , prefix = None ) : <EOL> lines = [ ] <EOL> line = [ ] <EOL> if prefix is not None : <EOL> line_len = len ( prefix ) - <NUM_LIT:1> <EOL> else : <EOL> line_len = len ( indent ) - <NUM_LIT:1> <EOL> for part in parts : <EOL> if line_len + <NUM_LIT:1> + len ( part ) > text_width : <EOL> lines . append ( indent + '<STR_LIT:U+0020>' . join ( line ) ) <EOL> line = [ ] <EOL> line_len = len ( indent ) - <NUM_LIT:1> <EOL> line . append ( part ) <EOL> line_len += len ( part ) + <NUM_LIT:1> <EOL> if line : <EOL> lines . append ( indent + '<STR_LIT:U+0020>' . join ( line ) ) <EOL> if prefix is not None : <EOL> lines [ <NUM_LIT:0> ] = lines [ <NUM_LIT:0> ] [ len ( indent ) : ] <EOL> return lines <EOL> if len ( prefix ) + len ( prog ) <= <NUM_LIT> * text_width : <EOL> indent = '<STR_LIT:U+0020>' * ( len ( prefix ) + len ( prog ) + <NUM_LIT:1> ) <EOL> if opt_parts : <EOL> lines = get_lines ( [ prog ] + opt_parts , indent , prefix ) <EOL> lines . extend ( get_lines ( pos_parts , indent ) ) <EOL> elif pos_parts : <EOL> lines = get_lines ( [ prog ] + pos_parts , indent , prefix ) <EOL> else : <EOL> lines = [ prog ] <EOL> else : <EOL> indent = '<STR_LIT:U+0020>' * len ( prefix ) <EOL> parts = opt_parts + pos_parts <EOL> lines = get_lines ( parts , indent ) <EOL> if len ( lines ) > <NUM_LIT:1> : <EOL> lines = [ ] <EOL> lines . extend ( get_lines ( opt_parts , indent ) ) <EOL> lines . extend ( get_lines ( pos_parts , indent ) ) <EOL> lines = [ prog ] + lines <EOL> usage = '<STR_LIT:\n>' . join ( lines ) <EOL> return '<STR_LIT>' % ( prefix , usage ) <EOL> def _format_actions_usage ( self , actions , groups ) : <EOL> group_actions = set ( ) <EOL> inserts = { } <EOL> for group in groups : <EOL> try : <EOL> start = actions . index ( group . _group_actions [ <NUM_LIT:0> ] ) <EOL> except ValueError : <EOL> continue <EOL> else : <EOL> end = start + len ( group . _group_actions ) <EOL> if actions [ start : end ] == group . _group_actions : <EOL> for action in group . _group_actions : <EOL> group_actions . add ( action ) <EOL> if not group . required : <EOL> if start in inserts : <EOL> inserts [ start ] += '<STR_LIT>' <EOL> else : <EOL> inserts [ start ] = '<STR_LIT:[>' <EOL> inserts [ end ] = '<STR_LIT:]>' <EOL> else : <EOL> if start in inserts : <EOL> inserts [ start ] += '<STR_LIT>' <EOL> else : <EOL> inserts [ start ] = '<STR_LIT:(>' <EOL> inserts [ end ] = '<STR_LIT:)>' <EOL> for i in range ( start + <NUM_LIT:1> , end ) : <EOL> inserts [ i ] = '<STR_LIT:|>' <EOL> parts = [ ] <EOL> for i , action in enumerate ( actions ) : <EOL> if action . help is SUPPRESS : <EOL> parts . append ( None ) <EOL> if inserts . get ( i ) == '<STR_LIT:|>' : <EOL> inserts . pop ( i ) <EOL> elif inserts . get ( i + <NUM_LIT:1> ) == '<STR_LIT:|>' : <EOL> inserts . pop ( i + <NUM_LIT:1> ) <EOL> elif not action . option_strings : <EOL> part = self . _format_args ( action , action . dest ) <EOL> if action in group_actions : <EOL> if part [ <NUM_LIT:0> ] == '<STR_LIT:[>' and part [ - <NUM_LIT:1> ] == '<STR_LIT:]>' : <EOL> part = part [ <NUM_LIT:1> : - <NUM_LIT:1> ] <EOL> parts . append ( part ) <EOL> else : <EOL> option_string = action . option_strings [ <NUM_LIT:0> ] <EOL> if action . nargs == <NUM_LIT:0> : <EOL> part = '<STR_LIT:%s>' % option_string <EOL> else : <EOL> default = action . dest . upper ( ) <EOL> args_string = self . _format_args ( action , default ) <EOL> part = '<STR_LIT>' % ( option_string , args_string ) <EOL> if not action . required and action not in group_actions : <EOL> part = '<STR_LIT>' % part <EOL> parts . append ( part ) <EOL> for i in sorted ( inserts , reverse = True ) : <EOL> parts [ i : i ] = [ inserts [ i ] ] <EOL> text = '<STR_LIT:U+0020>' . join ( [ item for item in parts if item is not None ] ) <EOL> open = r'<STR_LIT>' <EOL> close = r'<STR_LIT>' <EOL> text = _re . sub ( r'<STR_LIT>' % open , r'<STR_LIT>' , text ) <EOL> text = _re . sub ( r'<STR_LIT>' % close , r'<STR_LIT>' , text ) <EOL> text = _re . sub ( r'<STR_LIT>' % ( open , close ) , r'<STR_LIT>' , text ) <EOL> text = _re . sub ( r'<STR_LIT>' , r'<STR_LIT>' , text ) <EOL> text = text . strip ( ) <EOL> return text <EOL> def _format_text ( self , text ) : <EOL> if '<STR_LIT>' in text : <EOL> text = text % dict ( prog = self . _prog ) <EOL> text_width = self . _width - self . _current_indent <EOL> indent = '<STR_LIT:U+0020>' * self . _current_indent <EOL> return self . _fill_text ( text , text_width , indent ) + '<STR_LIT>' <EOL> def _format_action ( self , action ) : <EOL> help_position = min ( self . _action_max_length + <NUM_LIT:2> , <EOL> self . _max_help_position ) <EOL> help_width = self . _width - help_position <EOL> action_width = help_position - self . _current_indent - <NUM_LIT:2> <EOL> action_header = self . _format_action_invocation ( action ) <EOL> if not action . help : <EOL> tup = self . _current_indent , '<STR_LIT>' , action_header <EOL> action_header = '<STR_LIT>' % tup <EOL> elif len ( action_header ) <= action_width : <EOL> tup = self . _current_indent , '<STR_LIT>' , action_width , action_header <EOL> action_header = '<STR_LIT>' % tup <EOL> indent_first = <NUM_LIT:0> <EOL> else : <EOL> tup = self . _current_indent , '<STR_LIT>' , action_header <EOL> action_header = '<STR_LIT>' % tup <EOL> indent_first = help_position <EOL> parts = [ action_header ] <EOL> if action . help : <EOL> help_text = self . _expand_help ( action ) <EOL> help_lines = self . _split_lines ( help_text , help_width ) <EOL> parts . append ( '<STR_LIT>' % ( indent_first , '<STR_LIT>' , help_lines [ <NUM_LIT:0> ] ) ) <EOL> for line in help_lines [ <NUM_LIT:1> : ] : <EOL> parts . append ( '<STR_LIT>' % ( help_position , '<STR_LIT>' , line ) ) <EOL> elif not action_header . endswith ( '<STR_LIT:\n>' ) : <EOL> parts . append ( '<STR_LIT:\n>' ) <EOL> for subaction in self . _iter_indented_subactions ( action ) : <EOL> parts . append ( self . _format_action ( subaction ) ) <EOL> return self . _join_parts ( parts ) <EOL> def _format_action_invocation ( self , action ) : <EOL> if not action . option_strings : <EOL> metavar , = self . _metavar_formatter ( action , action . dest ) ( <NUM_LIT:1> ) <EOL> return metavar <EOL> else : <EOL> parts = [ ] <EOL> if action . nargs == <NUM_LIT:0> : <EOL> parts . extend ( action . option_strings ) <EOL> else : <EOL> default = action . dest . upper ( ) <EOL> args_string = self . _format_args ( action , default ) <EOL> for option_string in action . option_strings : <EOL> parts . append ( '<STR_LIT>' % ( option_string , args_string ) ) <EOL> return '<STR_LIT:U+002CU+0020>' . join ( parts ) <EOL> def _metavar_formatter ( self , action , default_metavar ) : <EOL> if action . metavar is not None : <EOL> result = action . metavar <EOL> elif action . choices is not None : <EOL> choice_strs = [ str ( choice ) for choice in action . choices ] <EOL> result = '<STR_LIT>' % '<STR_LIT:U+002C>' . join ( choice_strs ) <EOL> else : <EOL> result = default_metavar <EOL> def format ( tuple_size ) : <EOL> if isinstance ( result , tuple ) : <EOL> return result <EOL> else : <EOL> return ( result , ) * tuple_size <EOL> return format <EOL> def _format_args ( self , action , default_metavar ) : <EOL> get_metavar = self . _metavar_formatter ( action , default_metavar ) <EOL> if action . nargs is None : <EOL> result = '<STR_LIT:%s>' % get_metavar ( <NUM_LIT:1> ) <EOL> elif action . nargs == OPTIONAL : <EOL> result = '<STR_LIT>' % get_metavar ( <NUM_LIT:1> ) <EOL> elif action . nargs == ZERO_OR_MORE : <EOL> result = '<STR_LIT>' % get_metavar ( <NUM_LIT:2> ) <EOL> elif action . nargs == ONE_OR_MORE : <EOL> result = '<STR_LIT>' % get_metavar ( <NUM_LIT:2> ) <EOL> elif action . nargs == REMAINDER : <EOL> result = '<STR_LIT>' <EOL> elif action . nargs == PARSER : <EOL> result = '<STR_LIT>' % get_metavar ( <NUM_LIT:1> ) <EOL> else : <EOL> formats = [ '<STR_LIT:%s>' for _ in range ( action . nargs ) ] <EOL> result = '<STR_LIT:U+0020>' . join ( formats ) % get_metavar ( action . nargs ) <EOL> return result <EOL> def _expand_help ( self , action ) : <EOL> params = dict ( vars ( action ) , prog = self . _prog ) <EOL> for name in list ( params ) : <EOL> if params [ name ] is SUPPRESS : <EOL> del params [ name ] <EOL> for name in list ( params ) : <EOL> if hasattr ( params [ name ] , '<STR_LIT>' ) : <EOL> params [ name ] = params [ name ] . __name__ <EOL> if params . get ( '<STR_LIT>' ) is not None : <EOL> choices_str = '<STR_LIT:U+002CU+0020>' . join ( [ str ( c ) for c in params [ '<STR_LIT>' ] ] ) <EOL> params [ '<STR_LIT>' ] = choices_str <EOL> return self . _get_help_string ( action ) % params <EOL> def _iter_indented_subactions ( self , action ) : <EOL> try : <EOL> get_subactions = action . _get_subactions <EOL> except AttributeError : <EOL> pass <EOL> else : <EOL> self . _indent ( ) <EOL> for subaction in get_subactions ( ) : <EOL> yield subaction <EOL> self . _dedent ( ) <EOL> def _split_lines ( self , text , width ) : <EOL> text = self . _whitespace_matcher . sub ( '<STR_LIT:U+0020>' , text ) . strip ( ) <EOL> return _textwrap . wrap ( text , width ) <EOL> def _fill_text ( self , text , width , indent ) : <EOL> text = self . _whitespace_matcher . sub ( '<STR_LIT:U+0020>' , text ) . strip ( ) <EOL> return _textwrap . fill ( text , width , initial_indent = indent , <EOL> subsequent_indent = indent ) <EOL> def _get_help_string ( self , action ) : <EOL> return action . help <EOL> class RawDescriptionHelpFormatter ( HelpFormatter ) : <EOL> """<STR_LIT>""" <EOL> def _fill_text ( self , text , width , indent ) : <EOL> return '<STR_LIT>' . join ( [ indent + line for line in text . splitlines ( True ) ] ) <EOL> class RawTextHelpFormatter ( RawDescriptionHelpFormatter ) : <EOL> """<STR_LIT>""" <EOL> def _split_lines ( self , text , width ) : <EOL> return text . splitlines ( ) <EOL> class ArgumentDefaultsHelpFormatter ( HelpFormatter ) : <EOL> """<STR_LIT>""" <EOL> def _get_help_string ( self , action ) : <EOL> help = action . help <EOL> if '<STR_LIT>' not in action . help : <EOL> if action . default is not SUPPRESS : <EOL> defaulting_nargs = [ OPTIONAL , ZERO_OR_MORE ] <EOL> if action . option_strings or action . nargs in defaulting_nargs : <EOL> help += '<STR_LIT>' <EOL> return help <EOL> def _get_action_name ( argument ) : <EOL> if argument is None : <EOL> return None <EOL> elif argument . option_strings : <EOL> return '<STR_LIT:/>' . join ( argument . option_strings ) <EOL> elif argument . metavar not in ( None , SUPPRESS ) : <EOL> return argument . metavar <EOL> elif argument . dest not in ( None , SUPPRESS ) : <EOL> return argument . dest <EOL> else : <EOL> return None <EOL> class ArgumentError ( Exception ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , argument , message ) : <EOL> self . argument_name = _get_action_name ( argument ) <EOL> self . message = message <EOL> def __str__ ( self ) : <EOL> if self . argument_name is None : <EOL> format = '<STR_LIT>' <EOL> else : <EOL> format = '<STR_LIT>' <EOL> return format % dict ( message = self . message , <EOL> argument_name = self . argument_name ) <EOL> class ArgumentTypeError ( Exception ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> class Action ( _AttributeHolder ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , <EOL> option_strings , <EOL> dest , <EOL> nargs = None , <EOL> const = None , <EOL> default = None , <EOL> type = None , <EOL> choices = None , <EOL> required = False , <EOL> help = None , <EOL> metavar = None ) : <EOL> self . option_strings = option_strings <EOL> self . dest = dest <EOL> self . nargs = nargs <EOL> self . const = const <EOL> self . default = default <EOL> self . type = type <EOL> self . choices = choices <EOL> self . required = required <EOL> self . help = help <EOL> self . metavar = metavar <EOL> def _get_kwargs ( self ) : <EOL> names = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT:default>' , <EOL> '<STR_LIT:type>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> ] <EOL> return [ ( name , getattr ( self , name ) ) for name in names ] <EOL> def __call__ ( self , parser , namespace , values , option_string = None ) : <EOL> raise NotImplementedError ( _ ( '<STR_LIT>' ) ) <EOL> class _StoreAction ( Action ) : <EOL> def __init__ ( self , <EOL> option_strings , <EOL> dest , <EOL> nargs = None , <EOL> const = None , <EOL> default = None , <EOL> type = None , <EOL> choices = None , <EOL> required = False , <EOL> help = None , <EOL> metavar = None ) : <EOL> if nargs == <NUM_LIT:0> : <EOL> raise ValueError ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> if const is not None and nargs != OPTIONAL : <EOL> raise ValueError ( '<STR_LIT>' % OPTIONAL ) <EOL> super ( _StoreAction , self ) . __init__ ( <EOL> option_strings = option_strings , <EOL> dest = dest , <EOL> nargs = nargs , <EOL> const = const , <EOL> default = default , <EOL> type = type , <EOL> choices = choices , <EOL> required = required , <EOL> help = help , <EOL> metavar = metavar ) <EOL> def __call__ ( self , parser , namespace , values , option_string = None ) : <EOL> setattr ( namespace , self . dest , values ) <EOL> class _StoreConstAction ( Action ) : <EOL> def __init__ ( self , <EOL> option_strings , <EOL> dest , <EOL> const , <EOL> default = None , <EOL> required = False , <EOL> help = None , <EOL> metavar = None ) : <EOL> super ( _StoreConstAction , self ) . __init__ ( <EOL> option_strings = option_strings , <EOL> dest = dest , <EOL> nargs = <NUM_LIT:0> , <EOL> const = const , <EOL> default = default , <EOL> required = required , <EOL> help = help ) <EOL> def __call__ ( self , parser , namespace , values , option_string = None ) : <EOL> setattr ( namespace , self . dest , self . const ) <EOL> class _StoreTrueAction ( _StoreConstAction ) : <EOL> def __init__ ( self , <EOL> option_strings , <EOL> dest , <EOL> default = False , <EOL> required = False , <EOL> help = None ) : <EOL> super ( _StoreTrueAction , self ) . __init__ ( <EOL> option_strings = option_strings , <EOL> dest = dest , <EOL> const = True , <EOL> default = default , <EOL> required = required , <EOL> help = help ) <EOL> class _StoreFalseAction ( _StoreConstAction ) : <EOL> def __init__ ( self , <EOL> option_strings , <EOL> dest , <EOL> default = True , <EOL> required = False , <EOL> help = None ) : <EOL> super ( _StoreFalseAction , self ) . __init__ ( <EOL> option_strings = option_strings , <EOL> dest = dest , <EOL> const = False , <EOL> default = default , <EOL> required = required , <EOL> help = help ) <EOL> class _AppendAction ( Action ) : <EOL> def __init__ ( self , <EOL> option_strings , <EOL> dest , <EOL> nargs = None , <EOL> const = None , <EOL> default = None , <EOL> type = None , <EOL> choices = None , <EOL> required = False , <EOL> help = None , <EOL> metavar = None ) : <EOL> if nargs == <NUM_LIT:0> : <EOL> raise ValueError ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> if const is not None and nargs != OPTIONAL : <EOL> raise ValueError ( '<STR_LIT>' % OPTIONAL ) <EOL> super ( _AppendAction , self ) . __init__ ( <EOL> option_strings = option_strings , <EOL> dest = dest , <EOL> nargs = nargs , <EOL> const = const , <EOL> default = default , <EOL> type = type , <EOL> choices = choices , <EOL> required = required , <EOL> help = help , <EOL> metavar = metavar ) <EOL> def __call__ ( self , parser , namespace , values , option_string = None ) : <EOL> items = _copy . copy ( _ensure_value ( namespace , self . dest , [ ] ) ) <EOL> items . append ( values ) <EOL> setattr ( namespace , self . dest , items ) <EOL> class _AppendConstAction ( Action ) : <EOL> def __init__ ( self , <EOL> option_strings , <EOL> dest , <EOL> const , <EOL> default = None , <EOL> required = False , <EOL> help = None , <EOL> metavar = None ) : <EOL> super ( _AppendConstAction , self ) . __init__ ( <EOL> option_strings = option_strings , <EOL> dest = dest , <EOL> nargs = <NUM_LIT:0> , <EOL> const = const , <EOL> default = default , <EOL> required = required , <EOL> help = help , <EOL> metavar = metavar ) <EOL> def __call__ ( self , parser , namespace , values , option_string = None ) : <EOL> items = _copy . copy ( _ensure_value ( namespace , self . dest , [ ] ) ) <EOL> items . append ( self . const ) <EOL> setattr ( namespace , self . dest , items ) <EOL> class _CountAction ( Action ) : <EOL> def __init__ ( self , <EOL> option_strings , <EOL> dest , <EOL> default = None , <EOL> required = False , <EOL> help = None ) : <EOL> super ( _CountAction , self ) . __init__ ( <EOL> option_strings = option_strings , <EOL> dest = dest , <EOL> nargs = <NUM_LIT:0> , <EOL> default = default , <EOL> required = required , <EOL> help = help ) <EOL> def __call__ ( self , parser , namespace , values , option_string = None ) : <EOL> new_count = _ensure_value ( namespace , self . dest , <NUM_LIT:0> ) + <NUM_LIT:1> <EOL> setattr ( namespace , self . dest , new_count ) <EOL> class _HelpAction ( Action ) : <EOL> def __init__ ( self , <EOL> option_strings , <EOL> dest = SUPPRESS , <EOL> default = SUPPRESS , <EOL> help = None ) : <EOL> super ( _HelpAction , self ) . __init__ ( <EOL> option_strings = option_strings , <EOL> dest = dest , <EOL> default = default , <EOL> nargs = <NUM_LIT:0> , <EOL> help = help ) <EOL> def __call__ ( self , parser , namespace , values , option_string = None ) : <EOL> parser . print_help ( ) <EOL> parser . exit ( ) <EOL> class _VersionAction ( Action ) : <EOL> def __init__ ( self , <EOL> option_strings , <EOL> version = None , <EOL> dest = SUPPRESS , <EOL> default = SUPPRESS , <EOL> help = "<STR_LIT>" ) : <EOL> super ( _VersionAction , self ) . __init__ ( <EOL> option_strings = option_strings , <EOL> dest = dest , <EOL> default = default , <EOL> nargs = <NUM_LIT:0> , <EOL> help = help ) <EOL> self . version = version <EOL> def __call__ ( self , parser , namespace , values , option_string = None ) : <EOL> version = self . version <EOL> if version is None : <EOL> version = parser . version <EOL> formatter = parser . _get_formatter ( ) <EOL> formatter . add_text ( version ) <EOL> parser . exit ( message = formatter . format_help ( ) ) <EOL> class _SubParsersAction ( Action ) : <EOL> class _ChoicesPseudoAction ( Action ) : <EOL> def __init__ ( self , name , help ) : <EOL> sup = super ( _SubParsersAction . _ChoicesPseudoAction , self ) <EOL> sup . __init__ ( option_strings = [ ] , dest = name , help = help ) <EOL> def __init__ ( self , <EOL> option_strings , <EOL> prog , <EOL> parser_class , <EOL> dest = SUPPRESS , <EOL> help = None , <EOL> metavar = None ) : <EOL> self . _prog_prefix = prog <EOL> self . _parser_class = parser_class <EOL> self . _name_parser_map = { } <EOL> self . _choices_actions = [ ] <EOL> super ( _SubParsersAction , self ) . __init__ ( <EOL> option_strings = option_strings , <EOL> dest = dest , <EOL> nargs = PARSER , <EOL> choices = self . _name_parser_map , <EOL> help = help , <EOL> metavar = metavar ) <EOL> def add_parser ( self , name , ** kwargs ) : <EOL> if kwargs . get ( '<STR_LIT>' ) is None : <EOL> kwargs [ '<STR_LIT>' ] = '<STR_LIT>' % ( self . _prog_prefix , name ) <EOL> if '<STR_LIT>' in kwargs : <EOL> help = kwargs . pop ( '<STR_LIT>' ) <EOL> choice_action = self . _ChoicesPseudoAction ( name , help ) <EOL> self . _choices_actions . append ( choice_action ) <EOL> parser = self . _parser_class ( ** kwargs ) <EOL> self . _name_parser_map [ name ] = parser <EOL> return parser <EOL> def _get_subactions ( self ) : <EOL> return self . _choices_actions <EOL> def __call__ ( self , parser , namespace , values , option_string = None ) : <EOL> parser_name = values [ <NUM_LIT:0> ] <EOL> arg_strings = values [ <NUM_LIT:1> : ] <EOL> if self . dest is not SUPPRESS : <EOL> setattr ( namespace , self . dest , parser_name ) <EOL> try : <EOL> parser = self . _name_parser_map [ parser_name ] <EOL> except KeyError : <EOL> tup = parser_name , '<STR_LIT:U+002CU+0020>' . join ( self . _name_parser_map ) <EOL> msg = _ ( '<STR_LIT>' % tup ) <EOL> raise ArgumentError ( self , msg ) <EOL> namespace , arg_strings = parser . parse_known_args ( arg_strings , namespace ) <EOL> if arg_strings : <EOL> vars ( namespace ) . setdefault ( _UNRECOGNIZED_ARGS_ATTR , [ ] ) <EOL> getattr ( namespace , _UNRECOGNIZED_ARGS_ATTR ) . extend ( arg_strings ) <EOL> class FileType ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , mode = '<STR_LIT:r>' , bufsize = None ) : <EOL> self . _mode = mode <EOL> self . _bufsize = bufsize <EOL> def __call__ ( self , string ) : <EOL> if string == '<STR_LIT:->' : <EOL> if '<STR_LIT:r>' in self . _mode : <EOL> return _sys . stdin <EOL> elif '<STR_LIT:w>' in self . _mode : <EOL> return _sys . stdout <EOL> else : <EOL> msg = _ ( '<STR_LIT>' % self . _mode ) <EOL> raise ValueError ( msg ) <EOL> if self . _bufsize : <EOL> return open ( string , self . _mode , self . _bufsize ) <EOL> else : <EOL> return open ( string , self . _mode ) <EOL> def __repr__ ( self ) : <EOL> args = [ self . _mode , self . _bufsize ] <EOL> args_str = '<STR_LIT:U+002CU+0020>' . join ( [ repr ( arg ) for arg in args if arg is not None ] ) <EOL> return '<STR_LIT>' % ( type ( self ) . __name__ , args_str ) <EOL> class Namespace ( _AttributeHolder ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , ** kwargs ) : <EOL> for name in kwargs : <EOL> setattr ( self , name , kwargs [ name ] ) <EOL> __hash__ = None <EOL> def __eq__ ( self , other ) : <EOL> return vars ( self ) == vars ( other ) <EOL> def __ne__ ( self , other ) : <EOL> return not ( self == other ) <EOL> def __contains__ ( self , key ) : <EOL> return key in self . __dict__ <EOL> class _ActionsContainer ( object ) : <EOL> def __init__ ( self , <EOL> description , <EOL> prefix_chars , <EOL> argument_default , <EOL> conflict_handler ) : <EOL> super ( _ActionsContainer , self ) . __init__ ( ) <EOL> self . description = description <EOL> self . argument_default = argument_default <EOL> self . prefix_chars = prefix_chars <EOL> self . conflict_handler = conflict_handler <EOL> self . _registries = { } <EOL> self . register ( '<STR_LIT:action>' , None , _StoreAction ) <EOL> self . register ( '<STR_LIT:action>' , '<STR_LIT:store>' , _StoreAction ) <EOL> self . register ( '<STR_LIT:action>' , '<STR_LIT>' , _StoreConstAction ) <EOL> self . register ( '<STR_LIT:action>' , '<STR_LIT:store_true>' , _StoreTrueAction ) <EOL> self . register ( '<STR_LIT:action>' , '<STR_LIT>' , _StoreFalseAction ) <EOL> self . register ( '<STR_LIT:action>' , '<STR_LIT>' , _AppendAction ) <EOL> self . register ( '<STR_LIT:action>' , '<STR_LIT>' , _AppendConstAction ) <EOL> self . register ( '<STR_LIT:action>' , '<STR_LIT:count>' , _CountAction ) <EOL> self . register ( '<STR_LIT:action>' , '<STR_LIT>' , _HelpAction ) <EOL> self . register ( '<STR_LIT:action>' , '<STR_LIT:version>' , _VersionAction ) <EOL> self . register ( '<STR_LIT:action>' , '<STR_LIT>' , _SubParsersAction ) <EOL> self . _get_handler ( ) <EOL> self . _actions = [ ] <EOL> self . _option_string_actions = { } <EOL> self . _action_groups = [ ] <EOL> self . _mutually_exclusive_groups = [ ] <EOL> self . _defaults = { } <EOL> self . _negative_number_matcher = _re . compile ( r'<STR_LIT>' ) <EOL> self . _has_negative_number_optionals = [ ] <EOL> def register ( self , registry_name , value , object ) : <EOL> registry = self . _registries . setdefault ( registry_name , { } ) <EOL> registry [ value ] = object <EOL> def _registry_get ( self , registry_name , value , default = None ) : <EOL> return self . _registries [ registry_name ] . get ( value , default ) <EOL> def set_defaults ( self , ** kwargs ) : <EOL> self . _defaults . update ( kwargs ) <EOL> for action in self . _actions : <EOL> if action . dest in kwargs : <EOL> action . default = kwargs [ action . dest ] <EOL> def get_default ( self , dest ) : <EOL> for action in self . _actions : <EOL> if action . dest == dest and action . default is not None : <EOL> return action . default <EOL> return self . _defaults . get ( dest , None ) <EOL> def add_argument ( self , * args , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> chars = self . prefix_chars <EOL> if not args or len ( args ) == <NUM_LIT:1> and args [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] not in chars : <EOL> if args and '<STR_LIT>' in kwargs : <EOL> raise ValueError ( '<STR_LIT>' ) <EOL> kwargs = self . _get_positional_kwargs ( * args , ** kwargs ) <EOL> else : <EOL> kwargs = self . _get_optional_kwargs ( * args , ** kwargs ) <EOL> if '<STR_LIT:default>' not in kwargs : <EOL> dest = kwargs [ '<STR_LIT>' ] <EOL> if dest in self . _defaults : <EOL> kwargs [ '<STR_LIT:default>' ] = self . _defaults [ dest ] <EOL> elif self . argument_default is not None : <EOL> kwargs [ '<STR_LIT:default>' ] = self . argument_default <EOL> action_class = self . _pop_action_class ( kwargs ) <EOL> if not _callable ( action_class ) : <EOL> raise ValueError ( '<STR_LIT>' % action_class ) <EOL> action = action_class ( ** kwargs ) <EOL> type_func = self . _registry_get ( '<STR_LIT:type>' , action . type , action . type ) <EOL> if not _callable ( type_func ) : <EOL> raise ValueError ( '<STR_LIT>' % type_func ) <EOL> return self . _add_action ( action ) <EOL> def add_argument_group ( self , * args , ** kwargs ) : <EOL> group = _ArgumentGroup ( self , * args , ** kwargs ) <EOL> self . _action_groups . append ( group ) <EOL> return group <EOL> def add_mutually_exclusive_group ( self , ** kwargs ) : <EOL> group = _MutuallyExclusiveGroup ( self , ** kwargs ) <EOL> self . _mutually_exclusive_groups . append ( group ) <EOL> return group <EOL> def _add_action ( self , action ) : <EOL> self . _check_conflict ( action ) <EOL> self . _actions . append ( action ) <EOL> action . container = self <EOL> for option_string in action . option_strings : <EOL> self . _option_string_actions [ option_string ] = action <EOL> for option_string in action . option_strings : <EOL> if self . _negative_number_matcher . match ( option_string ) : <EOL> if not self . _has_negative_number_optionals : <EOL> self . _has_negative_number_optionals . append ( True ) <EOL> return action <EOL> def _remove_action ( self , action ) : <EOL> self . _actions . remove ( action ) <EOL> def _add_container_actions ( self , container ) : <EOL> title_group_map = { } <EOL> for group in self . _action_groups : <EOL> if group . title in title_group_map : <EOL> msg = _ ( '<STR_LIT>' ) <EOL> raise ValueError ( msg % ( group . title ) ) <EOL> title_group_map [ group . title ] = group <EOL> group_map = { } <EOL> for group in container . _action_groups : <EOL> if group . title not in title_group_map : <EOL> title_group_map [ group . title ] = self . add_argument_group ( <EOL> title = group . title , <EOL> description = group . description , <EOL> conflict_handler = group . conflict_handler ) <EOL> for action in group . _group_actions : <EOL> group_map [ action ] = title_group_map [ group . title ] <EOL> for group in container . _mutually_exclusive_groups : <EOL> mutex_group = self . add_mutually_exclusive_group ( <EOL> required = group . required ) <EOL> for action in group . _group_actions : <EOL> group_map [ action ] = mutex_group <EOL> for action in container . _actions : <EOL> group_map . get ( action , self ) . _add_action ( action ) <EOL> def _get_positional_kwargs ( self , dest , ** kwargs ) : <EOL> if '<STR_LIT>' in kwargs : <EOL> msg = _ ( "<STR_LIT>" ) <EOL> raise TypeError ( msg ) <EOL> if kwargs . get ( '<STR_LIT>' ) not in [ OPTIONAL , ZERO_OR_MORE ] : <EOL> kwargs [ '<STR_LIT>' ] = True <EOL> if kwargs . get ( '<STR_LIT>' ) == ZERO_OR_MORE and '<STR_LIT:default>' not in kwargs : <EOL> kwargs [ '<STR_LIT>' ] = True <EOL> return dict ( kwargs , dest = dest , option_strings = [ ] ) <EOL> def _get_optional_kwargs ( self , * args , ** kwargs ) : <EOL> option_strings = [ ] <EOL> long_option_strings = [ ] <EOL> for option_string in args : <EOL> if not option_string [ <NUM_LIT:0> ] in self . prefix_chars : <EOL> msg = _ ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> tup = option_string , self . prefix_chars <EOL> raise ValueError ( msg % tup ) <EOL> option_strings . append ( option_string ) <EOL> if option_string [ <NUM_LIT:0> ] in self . prefix_chars : <EOL> if len ( option_string ) > <NUM_LIT:1> : <EOL> if option_string [ <NUM_LIT:1> ] in self . prefix_chars : <EOL> long_option_strings . append ( option_string ) <EOL> dest = kwargs . pop ( '<STR_LIT>' , None ) <EOL> if dest is None : <EOL> if long_option_strings : <EOL> dest_option_string = long_option_strings [ <NUM_LIT:0> ] <EOL> else : <EOL> dest_option_string = option_strings [ <NUM_LIT:0> ] <EOL> dest = dest_option_string . lstrip ( self . prefix_chars ) <EOL> if not dest : <EOL> msg = _ ( '<STR_LIT>' ) <EOL> raise ValueError ( msg % option_string ) <EOL> dest = dest . replace ( '<STR_LIT:->' , '<STR_LIT:_>' ) <EOL> return dict ( kwargs , dest = dest , option_strings = option_strings ) <EOL> def _pop_action_class ( self , kwargs , default = None ) : <EOL> action = kwargs . pop ( '<STR_LIT:action>' , default ) <EOL> return self . _registry_get ( '<STR_LIT:action>' , action , action ) <EOL> def _get_handler ( self ) : <EOL> handler_func_name = '<STR_LIT>' % self . conflict_handler <EOL> try : <EOL> return getattr ( self , handler_func_name ) <EOL> except AttributeError : <EOL> msg = _ ( '<STR_LIT>' ) <EOL> raise ValueError ( msg % self . conflict_handler ) <EOL> def _check_conflict ( self , action ) : <EOL> confl_optionals = [ ] <EOL> for option_string in action . option_strings : <EOL> if option_string in self . _option_string_actions : <EOL> confl_optional = self . _option_string_actions [ option_string ] <EOL> confl_optionals . append ( ( option_string , confl_optional ) ) <EOL> if confl_optionals : <EOL> conflict_handler = self . _get_handler ( ) <EOL> conflict_handler ( action , confl_optionals ) <EOL> def _handle_conflict_error ( self , action , conflicting_actions ) : <EOL> message = _ ( '<STR_LIT>' ) <EOL> conflict_string = '<STR_LIT:U+002CU+0020>' . join ( [ option_string <EOL> for option_string , action <EOL> in conflicting_actions ] ) <EOL> raise ArgumentError ( action , message % conflict_string ) <EOL> def _handle_conflict_resolve ( self , action , conflicting_actions ) : <EOL> for option_string , action in conflicting_actions : <EOL> action . option_strings . remove ( option_string ) <EOL> self . _option_string_actions . pop ( option_string , None ) <EOL> if not action . option_strings : <EOL> action . container . _remove_action ( action ) <EOL> class _ArgumentGroup ( _ActionsContainer ) : <EOL> def __init__ ( self , container , title = None , description = None , ** kwargs ) : <EOL> update = kwargs . setdefault <EOL> update ( '<STR_LIT>' , container . conflict_handler ) <EOL> update ( '<STR_LIT>' , container . prefix_chars ) <EOL> update ( '<STR_LIT>' , container . argument_default ) <EOL> super_init = super ( _ArgumentGroup , self ) . __init__ <EOL> super_init ( description = description , ** kwargs ) <EOL> self . title = title <EOL> self . _group_actions = [ ] <EOL> self . _registries = container . _registries <EOL> self . _actions = container . _actions <EOL> self . _option_string_actions = container . _option_string_actions <EOL> self . _defaults = container . _defaults <EOL> self . _has_negative_number_optionals = container . _has_negative_number_optionals <EOL> def _add_action ( self , action ) : <EOL> action = super ( _ArgumentGroup , self ) . _add_action ( action ) <EOL> self . _group_actions . append ( action ) <EOL> return action <EOL> def _remove_action ( self , action ) : <EOL> super ( _ArgumentGroup , self ) . _remove_action ( action ) <EOL> self . _group_actions . remove ( action ) <EOL> class _MutuallyExclusiveGroup ( _ArgumentGroup ) : <EOL> def __init__ ( self , container , required = False ) : <EOL> super ( _MutuallyExclusiveGroup , self ) . __init__ ( container ) <EOL> self . required = required <EOL> self . _container = container <EOL> def _add_action ( self , action ) : <EOL> if action . required : <EOL> msg = _ ( '<STR_LIT>' ) <EOL> raise ValueError ( msg ) <EOL> action = self . _container . _add_action ( action ) <EOL> self . _group_actions . append ( action ) <EOL> return action <EOL> def _remove_action ( self , action ) : <EOL> self . _container . _remove_action ( action ) <EOL> self . _group_actions . remove ( action ) <EOL> class ArgumentParser ( _AttributeHolder , _ActionsContainer ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , <EOL> prog = None , <EOL> usage = None , <EOL> description = None , <EOL> epilog = None , <EOL> version = None , <EOL> parents = [ ] , <EOL> formatter_class = HelpFormatter , <EOL> prefix_chars = '<STR_LIT:->' , <EOL> fromfile_prefix_chars = None , <EOL> argument_default = None , <EOL> conflict_handler = '<STR_LIT:error>' , <EOL> add_help = True ) : <EOL> if version is not None : <EOL> import warnings <EOL> warnings . warn ( <EOL> """<STR_LIT>""" <EOL> """<STR_LIT>""" <EOL> """<STR_LIT>""" <EOL> """<STR_LIT>""" , DeprecationWarning ) <EOL> superinit = super ( ArgumentParser , self ) . __init__ <EOL> superinit ( description = description , <EOL> prefix_chars = prefix_chars , <EOL> argument_default = argument_default , <EOL> conflict_handler = conflict_handler ) <EOL> if prog is None : <EOL> prog = _os . path . basename ( _sys . argv [ <NUM_LIT:0> ] ) <EOL> self . prog = prog <EOL> self . usage = usage <EOL> self . epilog = epilog <EOL> self . version = version <EOL> self . formatter_class = formatter_class <EOL> self . fromfile_prefix_chars = fromfile_prefix_chars <EOL> self . add_help = add_help <EOL> add_group = self . add_argument_group <EOL> self . _positionals = add_group ( _ ( '<STR_LIT>' ) ) <EOL> self . _optionals = add_group ( _ ( '<STR_LIT>' ) ) <EOL> self . _subparsers = None <EOL> def identity ( string ) : <EOL> return string <EOL> self . register ( '<STR_LIT:type>' , None , identity ) <EOL> if '<STR_LIT:->' in prefix_chars : <EOL> default_prefix = '<STR_LIT:->' <EOL> else : <EOL> default_prefix = prefix_chars [ <NUM_LIT:0> ] <EOL> if self . add_help : <EOL> self . add_argument ( <EOL> default_prefix + '<STR_LIT:h>' , default_prefix * <NUM_LIT:2> + '<STR_LIT>' , <EOL> action = '<STR_LIT>' , default = SUPPRESS , <EOL> help = _ ( '<STR_LIT>' ) ) <EOL> if self . version : <EOL> self . add_argument ( <EOL> default_prefix + '<STR_LIT:v>' , default_prefix * <NUM_LIT:2> + '<STR_LIT:version>' , <EOL> action = '<STR_LIT:version>' , default = SUPPRESS , <EOL> version = self . version , <EOL> help = _ ( "<STR_LIT>" ) ) <EOL> for parent in parents : <EOL> self . _add_container_actions ( parent ) <EOL> try : <EOL> defaults = parent . _defaults <EOL> except AttributeError : <EOL> pass <EOL> else : <EOL> self . _defaults . update ( defaults ) <EOL> def _get_kwargs ( self ) : <EOL> names = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT:description>' , <EOL> '<STR_LIT:version>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> ] <EOL> return [ ( name , getattr ( self , name ) ) for name in names ] <EOL> def add_subparsers ( self , ** kwargs ) : <EOL> if self . _subparsers is not None : <EOL> self . error ( _ ( '<STR_LIT>' ) ) <EOL> kwargs . setdefault ( '<STR_LIT>' , type ( self ) ) <EOL> if '<STR_LIT:title>' in kwargs or '<STR_LIT:description>' in kwargs : <EOL> title = _ ( kwargs . pop ( '<STR_LIT:title>' , '<STR_LIT>' ) ) <EOL> description = _ ( kwargs . pop ( '<STR_LIT:description>' , None ) ) <EOL> self . _subparsers = self . add_argument_group ( title , description ) <EOL> else : <EOL> self . _subparsers = self . _positionals <EOL> if kwargs . get ( '<STR_LIT>' ) is None : <EOL> formatter = self . _get_formatter ( ) <EOL> positionals = self . _get_positional_actions ( ) <EOL> groups = self . _mutually_exclusive_groups <EOL> formatter . add_usage ( self . usage , positionals , groups , '<STR_LIT>' ) <EOL> kwargs [ '<STR_LIT>' ] = formatter . format_help ( ) . strip ( ) <EOL> parsers_class = self . _pop_action_class ( kwargs , '<STR_LIT>' ) <EOL> action = parsers_class ( option_strings = [ ] , ** kwargs ) <EOL> self . _subparsers . _add_action ( action ) <EOL> return action <EOL> def _add_action ( self , action ) : <EOL> if action . option_strings : <EOL> self . _optionals . _add_action ( action ) <EOL> else : <EOL> self . _positionals . _add_action ( action ) <EOL> return action <EOL> def _get_optional_actions ( self ) : <EOL> return [ action <EOL> for action in self . _actions <EOL> if action . option_strings ] <EOL> def _get_positional_actions ( self ) : <EOL> return [ action <EOL> for action in self . _actions <EOL> if not action . option_strings ] <EOL> def parse_args ( self , args = None , namespace = None ) : <EOL> args , argv = self . parse_known_args ( args , namespace ) <EOL> if argv : <EOL> msg = _ ( '<STR_LIT>' ) <EOL> self . error ( msg % '<STR_LIT:U+0020>' . join ( argv ) ) <EOL> return args <EOL> def parse_known_args ( self , args = None , namespace = None ) : <EOL> if args is None : <EOL> args = _sys . argv [ <NUM_LIT:1> : ] <EOL> if namespace is None : <EOL> namespace = Namespace ( ) <EOL> for action in self . _actions : <EOL> if action . dest is not SUPPRESS : <EOL> if not hasattr ( namespace , action . dest ) : <EOL> if action . default is not SUPPRESS : <EOL> default = action . default <EOL> if isinstance ( action . default , basestring ) : <EOL> default = self . _get_value ( action , default ) <EOL> setattr ( namespace , action . dest , default ) <EOL> for dest in self . _defaults : <EOL> if not hasattr ( namespace , dest ) : <EOL> setattr ( namespace , dest , self . _defaults [ dest ] ) <EOL> try : <EOL> namespace , args = self . _parse_known_args ( args , namespace ) <EOL> if hasattr ( namespace , _UNRECOGNIZED_ARGS_ATTR ) : <EOL> args . extend ( getattr ( namespace , _UNRECOGNIZED_ARGS_ATTR ) ) <EOL> delattr ( namespace , _UNRECOGNIZED_ARGS_ATTR ) <EOL> return namespace , args <EOL> except ArgumentError : <EOL> err = _sys . exc_info ( ) [ <NUM_LIT:1> ] <EOL> self . error ( str ( err ) ) <EOL> def _parse_known_args ( self , arg_strings , namespace ) : <EOL> if self . fromfile_prefix_chars is not None : <EOL> arg_strings = self . _read_args_from_files ( arg_strings ) <EOL> action_conflicts = { } <EOL> for mutex_group in self . _mutually_exclusive_groups : <EOL> group_actions = mutex_group . _group_actions <EOL> for i , mutex_action in enumerate ( mutex_group . _group_actions ) : <EOL> conflicts = action_conflicts . setdefault ( mutex_action , [ ] ) <EOL> conflicts . extend ( group_actions [ : i ] ) <EOL> conflicts . extend ( group_actions [ i + <NUM_LIT:1> : ] ) <EOL> option_string_indices = { } <EOL> arg_string_pattern_parts = [ ] <EOL> arg_strings_iter = iter ( arg_strings ) <EOL> for i , arg_string in enumerate ( arg_strings_iter ) : <EOL> if arg_string == '<STR_LIT>' : <EOL> arg_string_pattern_parts . append ( '<STR_LIT:->' ) <EOL> for arg_string in arg_strings_iter : <EOL> arg_string_pattern_parts . append ( '<STR_LIT:A>' ) <EOL> else : <EOL> option_tuple = self . _parse_optional ( arg_string ) <EOL> if option_tuple is None : <EOL> pattern = '<STR_LIT:A>' <EOL> else : <EOL> option_string_indices [ i ] = option_tuple <EOL> pattern = '<STR_LIT:O>' <EOL> arg_string_pattern_parts . append ( pattern ) <EOL> arg_strings_pattern = '<STR_LIT>' . join ( arg_string_pattern_parts ) <EOL> seen_actions = set ( ) <EOL> seen_non_default_actions = set ( ) <EOL> def take_action ( action , argument_strings , option_string = None ) : <EOL> seen_actions . add ( action ) <EOL> argument_values = self . _get_values ( action , argument_strings ) <EOL> if argument_values is not action . default : <EOL> seen_non_default_actions . add ( action ) <EOL> for conflict_action in action_conflicts . get ( action , [ ] ) : <EOL> if conflict_action in seen_non_default_actions : <EOL> msg = _ ( '<STR_LIT>' ) <EOL> action_name = _get_action_name ( conflict_action ) <EOL> raise ArgumentError ( action , msg % action_name ) <EOL> if argument_values is not SUPPRESS : <EOL> action ( self , namespace , argument_values , option_string ) <EOL> def consume_optional ( start_index ) : <EOL> option_tuple = option_string_indices [ start_index ] <EOL> action , option_string , explicit_arg = option_tuple <EOL> match_argument = self . _match_argument <EOL> action_tuples = [ ] <EOL> while True : <EOL> if action is None : <EOL> extras . append ( arg_strings [ start_index ] ) <EOL> return start_index + <NUM_LIT:1> <EOL> if explicit_arg is not None : <EOL> arg_count = match_argument ( action , '<STR_LIT:A>' ) <EOL> chars = self . prefix_chars <EOL> if arg_count == <NUM_LIT:0> and option_string [ <NUM_LIT:1> ] not in chars : <EOL> action_tuples . append ( ( action , [ ] , option_string ) ) <EOL> char = option_string [ <NUM_LIT:0> ] <EOL> option_string = char + explicit_arg [ <NUM_LIT:0> ] <EOL> new_explicit_arg = explicit_arg [ <NUM_LIT:1> : ] or None <EOL> optionals_map = self . _option_string_actions <EOL> if option_string in optionals_map : <EOL> action = optionals_map [ option_string ] <EOL> explicit_arg = new_explicit_arg <EOL> else : <EOL> msg = _ ( '<STR_LIT>' ) <EOL> raise ArgumentError ( action , msg % explicit_arg ) <EOL> elif arg_count == <NUM_LIT:1> : <EOL> stop = start_index + <NUM_LIT:1> <EOL> args = [ explicit_arg ] <EOL> action_tuples . append ( ( action , args , option_string ) ) <EOL> break <EOL> else : <EOL> msg = _ ( '<STR_LIT>' ) <EOL> raise ArgumentError ( action , msg % explicit_arg ) <EOL> else : <EOL> start = start_index + <NUM_LIT:1> <EOL> selected_patterns = arg_strings_pattern [ start : ] <EOL> arg_count = match_argument ( action , selected_patterns ) <EOL> stop = start + arg_count <EOL> args = arg_strings [ start : stop ] <EOL> action_tuples . append ( ( action , args , option_string ) ) <EOL> break <EOL> assert action_tuples <EOL> for action , args , option_string in action_tuples : <EOL> take_action ( action , args , option_string ) <EOL> return stop <EOL> positionals = self . _get_positional_actions ( ) <EOL> def consume_positionals ( start_index ) : <EOL> match_partial = self . _match_arguments_partial <EOL> selected_pattern = arg_strings_pattern [ start_index : ] <EOL> arg_counts = match_partial ( positionals , selected_pattern ) <EOL> for action , arg_count in zip ( positionals , arg_counts ) : <EOL> args = arg_strings [ start_index : start_index + arg_count ] <EOL> start_index += arg_count <EOL> take_action ( action , args ) <EOL> positionals [ : ] = positionals [ len ( arg_counts ) : ] <EOL> return start_index <EOL> extras = [ ] <EOL> start_index = <NUM_LIT:0> <EOL> if option_string_indices : <EOL> max_option_string_index = max ( option_string_indices ) <EOL> else : <EOL> max_option_string_index = - <NUM_LIT:1> <EOL> while start_index <= max_option_string_index : <EOL> next_option_string_index = min ( [ <EOL> index <EOL> for index in option_string_indices <EOL> if index >= start_index ] ) <EOL> if start_index != next_option_string_index : <EOL> positionals_end_index = consume_positionals ( start_index ) <EOL> if positionals_end_index > start_index : <EOL> start_index = positionals_end_index <EOL> continue <EOL> else : <EOL> start_index = positionals_end_index <EOL> if start_index not in option_string_indices : <EOL> strings = arg_strings [ start_index : next_option_string_index ] <EOL> extras . extend ( strings ) <EOL> start_index = next_option_string_index <EOL> start_index = consume_optional ( start_index ) <EOL> stop_index = consume_positionals ( start_index ) <EOL> extras . extend ( arg_strings [ stop_index : ] ) <EOL> if positionals : <EOL> self . error ( _ ( '<STR_LIT>' ) ) <EOL> for action in self . _actions : <EOL> if action . required : <EOL> if action not in seen_actions : <EOL> name = _get_action_name ( action ) <EOL> self . error ( _ ( '<STR_LIT>' ) % name ) <EOL> for group in self . _mutually_exclusive_groups : <EOL> if group . required : <EOL> for action in group . _group_actions : <EOL> if action in seen_non_default_actions : <EOL> break <EOL> else : <EOL> names = [ _get_action_name ( action ) <EOL> for action in group . _group_actions <EOL> if action . help is not SUPPRESS ] <EOL> msg = _ ( '<STR_LIT>' ) <EOL> self . error ( msg % '<STR_LIT:U+0020>' . join ( names ) ) <EOL> return namespace , extras <EOL> def _read_args_from_files ( self , arg_strings ) : <EOL> new_arg_strings = [ ] <EOL> for arg_string in arg_strings : <EOL> if arg_string [ <NUM_LIT:0> ] not in self . fromfile_prefix_chars : <EOL> new_arg_strings . append ( arg_string ) <EOL> else : <EOL> try : <EOL> args_file = open ( arg_string [ <NUM_LIT:1> : ] ) <EOL> try : <EOL> arg_strings = [ ] <EOL> for arg_line in args_file . read ( ) . splitlines ( ) : <EOL> for arg in self . convert_arg_line_to_args ( arg_line ) : <EOL> arg_strings . append ( arg ) <EOL> arg_strings = self . _read_args_from_files ( arg_strings ) <EOL> new_arg_strings . extend ( arg_strings ) <EOL> finally : <EOL> args_file . close ( ) <EOL> except IOError : <EOL> err = _sys . exc_info ( ) [ <NUM_LIT:1> ] <EOL> self . error ( str ( err ) ) <EOL> return new_arg_strings <EOL> def convert_arg_line_to_args ( self , arg_line ) : <EOL> return [ arg_line ] <EOL> def _match_argument ( self , action , arg_strings_pattern ) : <EOL> nargs_pattern = self . _get_nargs_pattern ( action ) <EOL> match = _re . match ( nargs_pattern , arg_strings_pattern ) <EOL> if match is None : <EOL> nargs_errors = { <EOL> None : _ ( '<STR_LIT>' ) , <EOL> OPTIONAL : _ ( '<STR_LIT>' ) , <EOL> ONE_OR_MORE : _ ( '<STR_LIT>' ) , <EOL> } <EOL> default = _ ( '<STR_LIT>' ) % action . nargs <EOL> msg = nargs_errors . get ( action . nargs , default ) <EOL> raise ArgumentError ( action , msg ) <EOL> return len ( match . group ( <NUM_LIT:1> ) ) <EOL> def _match_arguments_partial ( self , actions , arg_strings_pattern ) : <EOL> result = [ ] <EOL> for i in range ( len ( actions ) , <NUM_LIT:0> , - <NUM_LIT:1> ) : <EOL> actions_slice = actions [ : i ] <EOL> pattern = '<STR_LIT>' . join ( [ self . _get_nargs_pattern ( action ) <EOL> for action in actions_slice ] ) <EOL> match = _re . match ( pattern , arg_strings_pattern ) <EOL> if match is not None : <EOL> result . extend ( [ len ( string ) for string in match . groups ( ) ] ) <EOL> break <EOL> return result <EOL> def _parse_optional ( self , arg_string ) : <EOL> if not arg_string : <EOL> return None <EOL> if not arg_string [ <NUM_LIT:0> ] in self . prefix_chars : <EOL> return None <EOL> if arg_string in self . _option_string_actions : <EOL> action = self . _option_string_actions [ arg_string ] <EOL> return action , arg_string , None <EOL> if len ( arg_string ) == <NUM_LIT:1> : <EOL> return None <EOL> if '<STR_LIT:=>' in arg_string : <EOL> option_string , explicit_arg = arg_string . split ( '<STR_LIT:=>' , <NUM_LIT:1> ) <EOL> if option_string in self . _option_string_actions : <EOL> action = self . _option_string_actions [ option_string ] <EOL> return action , option_string , explicit_arg <EOL> option_tuples = self . _get_option_tuples ( arg_string ) <EOL> if len ( option_tuples ) > <NUM_LIT:1> : <EOL> options = '<STR_LIT:U+002CU+0020>' . join ( [ option_string <EOL> for action , option_string , explicit_arg in option_tuples ] ) <EOL> tup = arg_string , options <EOL> self . error ( _ ( '<STR_LIT>' ) % tup ) <EOL> elif len ( option_tuples ) == <NUM_LIT:1> : <EOL> option_tuple , = option_tuples <EOL> return option_tuple <EOL> if self . _negative_number_matcher . match ( arg_string ) : <EOL> if not self . _has_negative_number_optionals : <EOL> return None <EOL> if '<STR_LIT:U+0020>' in arg_string : <EOL> return None <EOL> return None , arg_string , None <EOL> def _get_option_tuples ( self , option_string ) : <EOL> result = [ ] <EOL> chars = self . prefix_chars <EOL> if option_string [ <NUM_LIT:0> ] in chars and option_string [ <NUM_LIT:1> ] in chars : <EOL> if '<STR_LIT:=>' in option_string : <EOL> option_prefix , explicit_arg = option_string . split ( '<STR_LIT:=>' , <NUM_LIT:1> ) <EOL> else : <EOL> option_prefix = option_string <EOL> explicit_arg = None <EOL> for option_string in self . _option_string_actions : <EOL> if option_string . startswith ( option_prefix ) : <EOL> action = self . _option_string_actions [ option_string ] <EOL> tup = action , option_string , explicit_arg <EOL> result . append ( tup ) <EOL> elif option_string [ <NUM_LIT:0> ] in chars and option_string [ <NUM_LIT:1> ] not in chars : <EOL> option_prefix = option_string <EOL> explicit_arg = None <EOL> short_option_prefix = option_string [ : <NUM_LIT:2> ] <EOL> short_explicit_arg = option_string [ <NUM_LIT:2> : ] <EOL> for option_string in self . _option_string_actions : <EOL> if option_string == short_option_prefix : <EOL> action = self . _option_string_actions [ option_string ] <EOL> tup = action , option_string , short_explicit_arg <EOL> result . append ( tup ) <EOL> elif option_string . startswith ( option_prefix ) : <EOL> action = self . _option_string_actions [ option_string ] <EOL> tup = action , option_string , explicit_arg <EOL> result . append ( tup ) <EOL> else : <EOL> self . error ( _ ( '<STR_LIT>' ) % option_string ) <EOL> return result <EOL> def _get_nargs_pattern ( self , action ) : <EOL> nargs = action . nargs <EOL> if nargs is None : <EOL> nargs_pattern = '<STR_LIT>' <EOL> elif nargs == OPTIONAL : <EOL> nargs_pattern = '<STR_LIT>' <EOL> elif nargs == ZERO_OR_MORE : <EOL> nargs_pattern = '<STR_LIT>' <EOL> elif nargs == ONE_OR_MORE : <EOL> nargs_pattern = '<STR_LIT>' <EOL> elif nargs == REMAINDER : <EOL> nargs_pattern = '<STR_LIT>' <EOL> elif nargs == PARSER : <EOL> nargs_pattern = '<STR_LIT>' <EOL> else : <EOL> nargs_pattern = '<STR_LIT>' % '<STR_LIT>' . join ( '<STR_LIT:A>' * nargs ) <EOL> if action . option_strings : <EOL> nargs_pattern = nargs_pattern . replace ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> nargs_pattern = nargs_pattern . replace ( '<STR_LIT:->' , '<STR_LIT>' ) <EOL> return nargs_pattern <EOL> def _get_values ( self , action , arg_strings ) : <EOL> if action . nargs not in [ PARSER , REMAINDER ] : <EOL> arg_strings = [ s for s in arg_strings if s != '<STR_LIT>' ] <EOL> if not arg_strings and action . nargs == OPTIONAL : <EOL> if action . option_strings : <EOL> value = action . const <EOL> else : <EOL> value = action . default <EOL> if isinstance ( value , basestring ) : <EOL> value = self . _get_value ( action , value ) <EOL> self . _check_value ( action , value ) <EOL> elif ( not arg_strings and action . nargs == ZERO_OR_MORE and <EOL> not action . option_strings ) : <EOL> if action . default is not None : <EOL> value = action . default <EOL> else : <EOL> value = arg_strings <EOL> self . _check_value ( action , value ) <EOL> elif len ( arg_strings ) == <NUM_LIT:1> and action . nargs in [ None , OPTIONAL ] : <EOL> arg_string , = arg_strings <EOL> value = self . _get_value ( action , arg_string ) <EOL> self . _check_value ( action , value ) <EOL> elif action . nargs == REMAINDER : <EOL> value = [ self . _get_value ( action , v ) for v in arg_strings ] <EOL> elif action . nargs == PARSER : <EOL> value = [ self . _get_value ( action , v ) for v in arg_strings ] <EOL> self . _check_value ( action , value [ <NUM_LIT:0> ] ) <EOL> else : <EOL> value = [ self . _get_value ( action , v ) for v in arg_strings ] <EOL> for v in value : <EOL> self . _check_value ( action , v ) <EOL> return value <EOL> def _get_value ( self , action , arg_string ) : <EOL> type_func = self . _registry_get ( '<STR_LIT:type>' , action . type , action . type ) <EOL> if not _callable ( type_func ) : <EOL> msg = _ ( '<STR_LIT>' ) <EOL> raise ArgumentError ( action , msg % type_func ) <EOL> try : <EOL> result = type_func ( arg_string ) <EOL> except ArgumentTypeError : <EOL> name = getattr ( action . type , '<STR_LIT>' , repr ( action . type ) ) <EOL> msg = str ( _sys . exc_info ( ) [ <NUM_LIT:1> ] ) <EOL> raise ArgumentError ( action , msg ) <EOL> except ( TypeError , ValueError ) : <EOL> name = getattr ( action . type , '<STR_LIT>' , repr ( action . type ) ) <EOL> msg = _ ( '<STR_LIT>' ) <EOL> raise ArgumentError ( action , msg % ( name , arg_string ) ) <EOL> return result <EOL> def _check_value ( self , action , value ) : <EOL> if action . choices is not None and value not in action . choices : <EOL> tup = value , '<STR_LIT:U+002CU+0020>' . join ( map ( repr , action . choices ) ) <EOL> msg = _ ( '<STR_LIT>' ) % tup <EOL> raise ArgumentError ( action , msg ) <EOL> def format_usage ( self ) : <EOL> formatter = self . _get_formatter ( ) <EOL> formatter . add_usage ( self . usage , self . _actions , <EOL> self . _mutually_exclusive_groups ) <EOL> return formatter . format_help ( ) <EOL> def format_help ( self ) : <EOL> formatter = self . _get_formatter ( ) <EOL> formatter . add_usage ( self . usage , self . _actions , <EOL> self . _mutually_exclusive_groups ) <EOL> formatter . add_text ( self . description ) <EOL> for action_group in self . _action_groups : <EOL> formatter . start_section ( action_group . title ) <EOL> formatter . add_text ( action_group . description ) <EOL> formatter . add_arguments ( action_group . _group_actions ) <EOL> formatter . end_section ( ) <EOL> formatter . add_text ( self . epilog ) <EOL> return formatter . format_help ( ) <EOL> def format_version ( self ) : <EOL> import warnings <EOL> warnings . warn ( <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' , <EOL> DeprecationWarning ) <EOL> formatter = self . _get_formatter ( ) <EOL> formatter . add_text ( self . version ) <EOL> return formatter . format_help ( ) <EOL> def _get_formatter ( self ) : <EOL> return self . formatter_class ( prog = self . prog ) <EOL> def print_usage ( self , file = None ) : <EOL> if file is None : <EOL> file = _sys . stdout <EOL> self . _print_message ( self . format_usage ( ) , file ) <EOL> def print_help ( self , file = None ) : <EOL> if file is None : <EOL> file = _sys . stdout <EOL> self . _print_message ( self . format_help ( ) , file ) <EOL> def print_version ( self , file = None ) : <EOL> import warnings <EOL> warnings . warn ( <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' , <EOL> DeprecationWarning ) <EOL> self . _print_message ( self . format_version ( ) , file ) <EOL> def _print_message ( self , message , file = None ) : <EOL> if message : <EOL> if file is None : <EOL> file = _sys . stderr <EOL> file . write ( message ) <EOL> def exit ( self , status = <NUM_LIT:0> , message = None ) : <EOL> if message : <EOL> self . _print_message ( message , _sys . stderr ) <EOL> _sys . exit ( status ) <EOL> def error ( self , message ) : <EOL> """<STR_LIT>""" <EOL> self . print_usage ( _sys . stderr ) <EOL> self . exit ( <NUM_LIT:2> , _ ( '<STR_LIT>' ) % ( self . prog , message ) ) </s>
<s> """<STR_LIT>""" <EOL> import sys <EOL> import os <EOL> import traceback <EOL> libpath = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> sys . path [ : <NUM_LIT:0> ] = [ os . path . join ( libpath , '<STR_LIT>' ) ] <EOL> import common <EOL> import environment <EOL> import xmltodict <EOL> from collections import OrderedDict <EOL> logger = common . logging . getLogger ( ) . getChild ( '<STR_LIT>' ) <EOL> try : <EOL> import splunk . Intersplunk <EOL> import splunk . entity as entity <EOL> except ImportError as e : <EOL> logger . error ( "<STR_LIT>" <EOL> "<STR_LIT>" % __file__ ) <EOL> sys . exit ( <NUM_LIT:3> ) <EOL> libpath = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> sys . path [ : <NUM_LIT:0> ] = [ os . path . join ( libpath , '<STR_LIT>' ) ] <EOL> sys . path [ : <NUM_LIT:0> ] = [ os . path . join ( libpath , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) ] <EOL> sys . path [ : <NUM_LIT:0> ] = [ os . path . join ( libpath , '<STR_LIT>' , '<STR_LIT>' ) ] <EOL> try : <EOL> import pandevice . base <EOL> import pan . xapi <EOL> except ImportError : <EOL> print "<STR_LIT>" <EOL> exit ( <NUM_LIT:3> ) <EOL> from common import log <EOL> def usage ( ) : <EOL> common . exit_with_error ( "<STR_LIT>" ) <EOL> def parse_apps ( apps_xml ) : <EOL> obj = xmltodict . parse ( apps_xml ) <EOL> try : <EOL> apps = obj [ '<STR_LIT>' ] [ '<STR_LIT:result>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> except KeyError as e : <EOL> logger . error ( "<STR_LIT>" ) <EOL> raise e <EOL> csv_apps = [ ] <EOL> for app in apps : <EOL> a = OrderedDict ( ) <EOL> try : <EOL> a [ '<STR_LIT>' ] = app [ '<STR_LIT>' ] <EOL> a [ '<STR_LIT>' ] = app . get ( '<STR_LIT>' , "<STR_LIT>" ) <EOL> a [ '<STR_LIT>' ] = app . get ( '<STR_LIT>' , "<STR_LIT>" ) <EOL> a [ '<STR_LIT>' ] = app . get ( '<STR_LIT>' , "<STR_LIT>" ) <EOL> a [ '<STR_LIT>' ] = app [ '<STR_LIT>' ] <EOL> a [ '<STR_LIT>' ] = app [ '<STR_LIT>' ] <EOL> a [ '<STR_LIT>' ] = app [ '<STR_LIT>' ] <EOL> a [ '<STR_LIT>' ] = app [ '<STR_LIT>' ] <EOL> a [ '<STR_LIT>' ] = app [ '<STR_LIT>' ] <EOL> a [ '<STR_LIT>' ] = app [ '<STR_LIT>' ] <EOL> a [ '<STR_LIT>' ] = app [ '<STR_LIT>' ] <EOL> if a [ '<STR_LIT>' ] != u"<STR_LIT:yes>" and a [ '<STR_LIT>' ] != u"<STR_LIT>" : <EOL> a [ '<STR_LIT>' ] = a [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> a [ '<STR_LIT>' ] = app [ '<STR_LIT>' ] <EOL> a [ '<STR_LIT>' ] = app [ '<STR_LIT>' ] <EOL> a [ '<STR_LIT>' ] = app . get ( '<STR_LIT>' , "<STR_LIT>" ) <EOL> a [ '<STR_LIT>' ] = "<STR_LIT>" <EOL> try : <EOL> default = app [ '<STR_LIT:default>' ] <EOL> if isinstance ( default , list ) : <EOL> for d in default : <EOL> a [ '<STR_LIT>' ] = d [ '<STR_LIT:port>' ] [ '<STR_LIT>' ] <EOL> break <EOL> else : <EOL> a [ '<STR_LIT>' ] = default [ '<STR_LIT:port>' ] [ '<STR_LIT>' ] <EOL> except KeyError : <EOL> pass <EOL> else : <EOL> if not isinstance ( a [ '<STR_LIT>' ] , basestring ) : <EOL> a [ '<STR_LIT>' ] = "<STR_LIT:|>" . join ( a [ '<STR_LIT>' ] ) <EOL> except Exception as e : <EOL> logger . error ( "<STR_LIT>" % app [ '<STR_LIT>' ] ) <EOL> logger . error ( traceback . format_exc ( ) ) <EOL> common . exit_with_error ( str ( e ) ) <EOL> for key in a : <EOL> a [ key ] = str ( a [ key ] ) <EOL> csv_apps . append ( a ) <EOL> logger . info ( "<STR_LIT>" % len ( csv_apps ) ) <EOL> return csv_apps <EOL> def parse_threats ( threats_xml ) : <EOL> obj = xmltodict . parse ( threats_xml ) <EOL> try : <EOL> phone_home = obj [ '<STR_LIT>' ] [ '<STR_LIT:result>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> vulnerability = obj [ '<STR_LIT>' ] [ '<STR_LIT:result>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> threats = phone_home + vulnerability <EOL> except KeyError as e : <EOL> logger . error ( "<STR_LIT>" ) <EOL> raise e <EOL> csv_threats = [ ] <EOL> for threat in threats : <EOL> a = OrderedDict ( ) <EOL> try : <EOL> a [ '<STR_LIT>' ] = threat [ '<STR_LIT>' ] <EOL> a [ '<STR_LIT>' ] = threat [ '<STR_LIT>' ] <EOL> a [ '<STR_LIT>' ] = threat [ '<STR_LIT>' ] <EOL> a [ '<STR_LIT>' ] = threat [ '<STR_LIT>' ] <EOL> a [ '<STR_LIT>' ] = threat . get ( '<STR_LIT>' , None ) <EOL> if a [ '<STR_LIT>' ] is not None : <EOL> a [ '<STR_LIT>' ] = threat [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> if not isinstance ( a [ '<STR_LIT>' ] , basestring ) : <EOL> a [ '<STR_LIT>' ] = "<STR_LIT:U+002CU+0020>" . join ( a [ '<STR_LIT>' ] ) <EOL> else : <EOL> a [ '<STR_LIT>' ] = "<STR_LIT>" <EOL> except KeyError as e : <EOL> logger . error ( "<STR_LIT>" % threat [ '<STR_LIT>' ] ) <EOL> raise e <EOL> for key in a : <EOL> a [ key ] = str ( a [ key ] ) <EOL> csv_threats . append ( a ) <EOL> logger . info ( "<STR_LIT>" % len ( csv_threats ) ) <EOL> return csv_threats <EOL> def main ( ) : <EOL> args , kwargs = splunk . Intersplunk . getKeywordsAndOptions ( ) <EOL> debug = common . check_debug ( kwargs ) <EOL> if len ( args ) < <NUM_LIT:2> : <EOL> logger . error ( "<STR_LIT>" % len ( args ) ) <EOL> usage ( ) <EOL> if args [ <NUM_LIT:1> ] == "<STR_LIT>" : <EOL> logger . info ( "<STR_LIT>" % args [ <NUM_LIT:0> ] ) <EOL> elif args [ <NUM_LIT:1> ] == "<STR_LIT>" : <EOL> logger . info ( "<STR_LIT>" % args [ <NUM_LIT:0> ] ) <EOL> else : <EOL> usage ( ) <EOL> results , unused1 , settings = splunk . Intersplunk . getOrganizedResults ( ) <EOL> sessionKey = settings [ '<STR_LIT>' ] <EOL> log ( debug , "<STR_LIT>" ) <EOL> apikey = common . apikey ( sessionKey , args [ <NUM_LIT:0> ] , debug ) <EOL> device = pandevice . base . PanDevice ( args [ <NUM_LIT:0> ] , api_key = apikey ) <EOL> try : <EOL> if args [ <NUM_LIT:1> ] == "<STR_LIT>" : <EOL> device . xapi . get ( "<STR_LIT>" ) <EOL> app_xml = device . xapi . xml_document <EOL> csv = parse_apps ( app_xml ) <EOL> else : <EOL> device . xapi . get ( "<STR_LIT>" ) <EOL> threat_xml = device . xapi . xml_document <EOL> csv = parse_threats ( threat_xml ) <EOL> except pan . xapi . PanXapiError as e : <EOL> common . exit_with_error ( str ( e ) ) <EOL> splunk . Intersplunk . outputResults ( csv ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> main ( ) </s>
<s> from __future__ import division <EOL> """<STR_LIT>""" <EOL> __license__ = """<STR_LIT>""" <EOL> __all__ = [ "<STR_LIT>" ] <EOL> import itertools <EOL> import logging <EOL> import socket <EOL> import sys <EOL> import time <EOL> import traceback <EOL> from uuid import uuid4 <EOL> import weakref <EOL> from kazoo . client import KazooClient <EOL> from kazoo . handlers . gevent import SequentialGeventHandler <EOL> from kazoo . exceptions import NoNodeException , NodeExistsError <EOL> from kazoo . recipe . watchers import ChildrenWatch <EOL> from . common import OffsetType <EOL> from . exceptions import KafkaException , PartitionOwnedError , ConsumerStoppedException <EOL> from . handlers import GEventHandler <EOL> from . simpleconsumer import SimpleConsumer <EOL> from . utils . compat import range , get_bytes , itervalues , iteritems , get_string <EOL> try : <EOL> from . import rdkafka <EOL> except ImportError : <EOL> rdkafka = False <EOL> log = logging . getLogger ( __name__ ) <EOL> def _catch_thread_exception ( fn ) : <EOL> """<STR_LIT>""" <EOL> def wrapped ( self , * args , ** kwargs ) : <EOL> try : <EOL> ret = fn ( self , * args , ** kwargs ) <EOL> except Exception : <EOL> self . _worker_exception = sys . exc_info ( ) <EOL> else : <EOL> return ret <EOL> return wrapped <EOL> class BalancedConsumer ( object ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , <EOL> topic , <EOL> cluster , <EOL> consumer_group , <EOL> fetch_message_max_bytes = <NUM_LIT> * <NUM_LIT> , <EOL> num_consumer_fetchers = <NUM_LIT:1> , <EOL> auto_commit_enable = False , <EOL> auto_commit_interval_ms = <NUM_LIT> * <NUM_LIT:1000> , <EOL> queued_max_messages = <NUM_LIT> , <EOL> fetch_min_bytes = <NUM_LIT:1> , <EOL> fetch_wait_max_ms = <NUM_LIT:100> , <EOL> offsets_channel_backoff_ms = <NUM_LIT:1000> , <EOL> offsets_commit_max_retries = <NUM_LIT:5> , <EOL> auto_offset_reset = OffsetType . EARLIEST , <EOL> consumer_timeout_ms = - <NUM_LIT:1> , <EOL> rebalance_max_retries = <NUM_LIT:5> , <EOL> rebalance_backoff_ms = <NUM_LIT:2> * <NUM_LIT:1000> , <EOL> zookeeper_connection_timeout_ms = <NUM_LIT:6> * <NUM_LIT:1000> , <EOL> zookeeper_connect = '<STR_LIT>' , <EOL> zookeeper = None , <EOL> auto_start = True , <EOL> reset_offset_on_start = False , <EOL> post_rebalance_callback = None , <EOL> use_rdkafka = False , <EOL> compacted_topic = False ) : <EOL> """<STR_LIT>""" <EOL> self . _cluster = cluster <EOL> if not isinstance ( consumer_group , bytes ) : <EOL> raise TypeError ( "<STR_LIT>" ) <EOL> self . _consumer_group = consumer_group <EOL> self . _topic = topic <EOL> self . _auto_commit_enable = auto_commit_enable <EOL> self . _auto_commit_interval_ms = auto_commit_interval_ms <EOL> self . _fetch_message_max_bytes = fetch_message_max_bytes <EOL> self . _fetch_min_bytes = fetch_min_bytes <EOL> self . _rebalance_max_retries = rebalance_max_retries <EOL> self . _num_consumer_fetchers = num_consumer_fetchers <EOL> self . _queued_max_messages = queued_max_messages <EOL> self . _fetch_wait_max_ms = fetch_wait_max_ms <EOL> self . _rebalance_backoff_ms = rebalance_backoff_ms <EOL> self . _consumer_timeout_ms = consumer_timeout_ms <EOL> self . _offsets_channel_backoff_ms = offsets_channel_backoff_ms <EOL> self . _offsets_commit_max_retries = offsets_commit_max_retries <EOL> self . _auto_offset_reset = auto_offset_reset <EOL> self . _zookeeper_connect = zookeeper_connect <EOL> self . _zookeeper_connection_timeout_ms = zookeeper_connection_timeout_ms <EOL> self . _reset_offset_on_start = reset_offset_on_start <EOL> self . _post_rebalance_callback = post_rebalance_callback <EOL> self . _generation_id = - <NUM_LIT:1> <EOL> self . _running = False <EOL> self . _worker_exception = None <EOL> self . _worker_trace_logged = False <EOL> self . _is_compacted_topic = compacted_topic <EOL> if not rdkafka and use_rdkafka : <EOL> raise ImportError ( "<STR_LIT>" ) <EOL> if isinstance ( self . _cluster . handler , GEventHandler ) and use_rdkafka : <EOL> raise ImportError ( "<STR_LIT>" ) <EOL> self . _use_rdkafka = rdkafka and use_rdkafka <EOL> self . _rebalancing_lock = cluster . handler . Lock ( ) <EOL> self . _consumer = None <EOL> self . _consumer_id = get_bytes ( "<STR_LIT>" . format ( <EOL> hostname = socket . gethostname ( ) , <EOL> uuid = uuid4 ( ) <EOL> ) ) <EOL> self . _setting_watches = True <EOL> self . _topic_path = '<STR_LIT>' . format ( <EOL> group = self . _consumer_group , <EOL> topic = self . _topic . name ) <EOL> self . _consumer_id_path = '<STR_LIT>' . format ( <EOL> group = self . _consumer_group ) <EOL> self . _zookeeper = None <EOL> self . _owns_zookeeper = zookeeper is None <EOL> if zookeeper is not None : <EOL> self . _zookeeper = zookeeper <EOL> if auto_start is True : <EOL> self . start ( ) <EOL> def __del__ ( self ) : <EOL> log . debug ( "<STR_LIT>" . format ( self ) ) <EOL> if self . _running : <EOL> self . stop ( ) <EOL> def __repr__ ( self ) : <EOL> return "<STR_LIT>" . format ( <EOL> module = self . __class__ . __module__ , <EOL> name = self . __class__ . __name__ , <EOL> id_ = hex ( id ( self ) ) , <EOL> group = self . _consumer_group <EOL> ) <EOL> def _raise_worker_exceptions ( self ) : <EOL> """<STR_LIT>""" <EOL> if self . _worker_exception is not None : <EOL> _ , ex , tb = self . _worker_exception <EOL> if not self . _worker_trace_logged : <EOL> self . _worker_trace_logged = True <EOL> log . error ( "<STR_LIT>" , <EOL> "<STR_LIT>" . join ( traceback . format_tb ( tb ) ) ) <EOL> raise ex <EOL> @ property <EOL> def topic ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . _topic <EOL> @ property <EOL> def partitions ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . _consumer . partitions if self . _consumer else dict ( ) <EOL> @ property <EOL> def _partitions ( self ) : <EOL> """<STR_LIT>""" <EOL> return set ( <EOL> [ ] if self . partitions is None else itervalues ( self . partitions ) ) <EOL> @ property <EOL> def held_offsets ( self ) : <EOL> """<STR_LIT>""" <EOL> if not self . _consumer : <EOL> return None <EOL> return self . _consumer . held_offsets <EOL> def start ( self ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> if self . _zookeeper is None : <EOL> self . _setup_zookeeper ( self . _zookeeper_connect , <EOL> self . _zookeeper_connection_timeout_ms ) <EOL> self . _zookeeper . ensure_path ( self . _topic_path ) <EOL> self . _add_self ( ) <EOL> self . _running = True <EOL> self . _set_watches ( ) <EOL> self . _rebalance ( ) <EOL> except Exception : <EOL> log . exception ( "<STR_LIT>" ) <EOL> self . stop ( ) <EOL> def stop ( self ) : <EOL> """<STR_LIT>""" <EOL> log . debug ( "<STR_LIT>" . format ( self ) ) <EOL> with self . _rebalancing_lock : <EOL> self . _running = False <EOL> if self . _consumer is not None : <EOL> self . _consumer . stop ( ) <EOL> if self . _owns_zookeeper : <EOL> self . _zookeeper . stop ( ) <EOL> else : <EOL> self . _remove_partitions ( self . _get_held_partitions ( ) ) <EOL> try : <EOL> self . _zookeeper . delete ( self . _path_self ) <EOL> except NoNodeException : <EOL> pass <EOL> def _setup_zookeeper ( self , zookeeper_connect , timeout ) : <EOL> """<STR_LIT>""" <EOL> kazoo_kwargs = { '<STR_LIT>' : timeout / <NUM_LIT:1000> } <EOL> if isinstance ( self . _cluster . handler , GEventHandler ) : <EOL> kazoo_kwargs [ '<STR_LIT>' ] = SequentialGeventHandler ( ) <EOL> self . _zookeeper = KazooClient ( zookeeper_connect , ** kazoo_kwargs ) <EOL> self . _zookeeper . start ( ) <EOL> def _setup_internal_consumer ( self , partitions = None , start = True ) : <EOL> """<STR_LIT>""" <EOL> if partitions is None : <EOL> partitions = [ ] <EOL> if partitions != self . _partitions : <EOL> cns = self . _get_internal_consumer ( partitions = list ( partitions ) , start = start ) <EOL> if self . _post_rebalance_callback is not None : <EOL> old_offsets = ( self . _consumer . held_offsets <EOL> if self . _consumer else dict ( ) ) <EOL> new_offsets = cns . held_offsets <EOL> try : <EOL> reset_offsets = self . _post_rebalance_callback ( <EOL> self , old_offsets , new_offsets ) <EOL> except Exception : <EOL> log . exception ( "<STR_LIT>" ) <EOL> self . _worker_exception = sys . exc_info ( ) <EOL> return False <EOL> if reset_offsets : <EOL> cns . reset_offsets ( partition_offsets = [ <EOL> ( cns . partitions [ id_ ] , offset ) for <EOL> ( id_ , offset ) in iteritems ( reset_offsets ) ] ) <EOL> self . _consumer = cns <EOL> return True <EOL> def _get_internal_consumer ( self , partitions = None , start = True ) : <EOL> """<STR_LIT>""" <EOL> if partitions is None : <EOL> partitions = [ ] <EOL> reset_offset_on_start = self . _reset_offset_on_start <EOL> if self . _consumer is not None : <EOL> self . _consumer . stop ( ) <EOL> reset_offset_on_start = False <EOL> Cls = ( rdkafka . RdKafkaSimpleConsumer <EOL> if self . _use_rdkafka else SimpleConsumer ) <EOL> return Cls ( <EOL> self . _topic , <EOL> self . _cluster , <EOL> consumer_group = self . _consumer_group , <EOL> partitions = partitions , <EOL> auto_commit_enable = self . _auto_commit_enable , <EOL> auto_commit_interval_ms = self . _auto_commit_interval_ms , <EOL> fetch_message_max_bytes = self . _fetch_message_max_bytes , <EOL> fetch_min_bytes = self . _fetch_min_bytes , <EOL> num_consumer_fetchers = self . _num_consumer_fetchers , <EOL> queued_max_messages = self . _queued_max_messages , <EOL> fetch_wait_max_ms = self . _fetch_wait_max_ms , <EOL> consumer_timeout_ms = self . _consumer_timeout_ms , <EOL> offsets_channel_backoff_ms = self . _offsets_channel_backoff_ms , <EOL> offsets_commit_max_retries = self . _offsets_commit_max_retries , <EOL> auto_offset_reset = self . _auto_offset_reset , <EOL> reset_offset_on_start = reset_offset_on_start , <EOL> auto_start = start , <EOL> compacted_topic = self . _is_compacted_topic , <EOL> generation_id = self . _generation_id , <EOL> consumer_id = self . _consumer_id <EOL> ) <EOL> def _decide_partitions ( self , participants , consumer_id = None ) : <EOL> """<STR_LIT>""" <EOL> p_to_str = lambda p : '<STR_LIT:->' . join ( [ str ( p . topic . name ) , str ( p . leader . id ) , str ( p . id ) ] ) <EOL> all_parts = self . _topic . partitions . values ( ) <EOL> all_parts = sorted ( all_parts , key = p_to_str ) <EOL> participants = sorted ( participants ) <EOL> idx = participants . index ( consumer_id or self . _consumer_id ) <EOL> parts_per_consumer = len ( all_parts ) // len ( participants ) <EOL> remainder_ppc = len ( all_parts ) % len ( participants ) <EOL> start = parts_per_consumer * idx + min ( idx , remainder_ppc ) <EOL> num_parts = parts_per_consumer + ( <NUM_LIT:0> if ( idx + <NUM_LIT:1> > remainder_ppc ) else <NUM_LIT:1> ) <EOL> new_partitions = itertools . islice ( all_parts , start , start + num_parts ) <EOL> new_partitions = set ( new_partitions ) <EOL> log . info ( '<STR_LIT>' , <EOL> self . _consumer_id , len ( participants ) , len ( all_parts ) , <EOL> len ( new_partitions ) ) <EOL> log . debug ( '<STR_LIT>' , [ p_to_str ( p ) for p in new_partitions ] ) <EOL> return new_partitions <EOL> def _get_participants ( self ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> consumer_ids = self . _zookeeper . get_children ( self . _consumer_id_path ) <EOL> except NoNodeException : <EOL> log . debug ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> return [ ] <EOL> participants = [ ] <EOL> for id_ in consumer_ids : <EOL> try : <EOL> topic , stat = self . _zookeeper . get ( "<STR_LIT>" % ( self . _consumer_id_path , id_ ) ) <EOL> if topic == self . _topic . name : <EOL> participants . append ( get_bytes ( id_ ) ) <EOL> except NoNodeException : <EOL> pass <EOL> participants = sorted ( participants ) <EOL> return participants <EOL> def _build_watch_callback ( self , fn , proxy ) : <EOL> """<STR_LIT>""" <EOL> def _callback ( children ) : <EOL> try : <EOL> proxy . __repr__ ( ) <EOL> except ReferenceError : <EOL> return False <EOL> return fn ( proxy , children ) <EOL> return _callback <EOL> def _set_watches ( self ) : <EOL> """<STR_LIT>""" <EOL> proxy = weakref . proxy ( self ) <EOL> _brokers_changed = self . _build_watch_callback ( BalancedConsumer . _brokers_changed , proxy ) <EOL> _topics_changed = self . _build_watch_callback ( BalancedConsumer . _topics_changed , proxy ) <EOL> _consumers_changed = self . _build_watch_callback ( BalancedConsumer . _consumers_changed , proxy ) <EOL> self . _setting_watches = True <EOL> broker_path = '<STR_LIT>' <EOL> try : <EOL> self . _broker_watcher = ChildrenWatch ( <EOL> self . _zookeeper , broker_path , <EOL> _brokers_changed <EOL> ) <EOL> except NoNodeException : <EOL> raise Exception ( <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> % broker_path ) <EOL> self . _topics_watcher = ChildrenWatch ( <EOL> self . _zookeeper , <EOL> '<STR_LIT>' , <EOL> _topics_changed <EOL> ) <EOL> self . _consumer_watcher = ChildrenWatch ( <EOL> self . _zookeeper , self . _consumer_id_path , <EOL> _consumers_changed <EOL> ) <EOL> self . _setting_watches = False <EOL> def _add_self ( self ) : <EOL> """<STR_LIT>""" <EOL> participants = self . _get_participants ( ) <EOL> if len ( self . _topic . partitions ) <= len ( participants ) : <EOL> raise KafkaException ( "<STR_LIT>" ) <EOL> self . _zookeeper . create ( <EOL> self . _path_self , self . _topic . name , ephemeral = True , makepath = True ) <EOL> @ property <EOL> def _path_self ( self ) : <EOL> """<STR_LIT>""" <EOL> return '<STR_LIT>' . format ( <EOL> path = self . _consumer_id_path , <EOL> id_ = get_string ( self . _consumer_id ) <EOL> ) <EOL> def _update_member_assignment ( self ) : <EOL> """<STR_LIT>""" <EOL> for i in range ( self . _rebalance_max_retries ) : <EOL> try : <EOL> participants = self . _get_participants ( ) <EOL> if self . _consumer_id not in participants : <EOL> self . _add_self ( ) <EOL> participants . append ( self . _consumer_id ) <EOL> new_partitions = self . _decide_partitions ( participants ) <EOL> if not new_partitions : <EOL> log . warning ( "<STR_LIT>" , <EOL> self . _consumer_id ) <EOL> current_zk_parts = self . _get_held_partitions ( ) <EOL> self . _remove_partitions ( current_zk_parts - new_partitions ) <EOL> self . _add_partitions ( new_partitions - current_zk_parts ) <EOL> if self . _setup_internal_consumer ( new_partitions ) : <EOL> log . info ( '<STR_LIT>' ) <EOL> break <EOL> except PartitionOwnedError as ex : <EOL> if i == self . _rebalance_max_retries - <NUM_LIT:1> : <EOL> log . warning ( '<STR_LIT>' , <EOL> ex . partition , i ) <EOL> raise <EOL> log . info ( '<STR_LIT>' , ex . partition ) <EOL> self . _cluster . handler . sleep ( i * ( self . _rebalance_backoff_ms / <NUM_LIT:1000> ) ) <EOL> def _rebalance ( self ) : <EOL> """<STR_LIT>""" <EOL> if self . _consumer is not None : <EOL> self . commit_offsets ( ) <EOL> with self . _rebalancing_lock : <EOL> if not self . _running : <EOL> raise ConsumerStoppedException <EOL> log . info ( '<STR_LIT>' % ( <EOL> self . _consumer_id , self . _topic . name ) ) <EOL> self . _update_member_assignment ( ) <EOL> def _path_from_partition ( self , p ) : <EOL> """<STR_LIT>""" <EOL> return "<STR_LIT>" % ( self . _topic_path , p . leader . id , p . id ) <EOL> def _remove_partitions ( self , partitions ) : <EOL> """<STR_LIT>""" <EOL> for p in partitions : <EOL> self . _zookeeper . delete ( self . _path_from_partition ( p ) ) <EOL> def _add_partitions ( self , partitions ) : <EOL> """<STR_LIT>""" <EOL> for p in partitions : <EOL> try : <EOL> self . _zookeeper . create ( <EOL> self . _path_from_partition ( p ) , <EOL> value = get_bytes ( self . _consumer_id ) , <EOL> ephemeral = True <EOL> ) <EOL> except NodeExistsError : <EOL> raise PartitionOwnedError ( p ) <EOL> def _get_held_partitions ( self ) : <EOL> """<STR_LIT>""" <EOL> zk_partition_ids = set ( ) <EOL> all_partitions = self . _zookeeper . get_children ( self . _topic_path ) <EOL> for partition_slug in all_partitions : <EOL> try : <EOL> owner_id , stat = self . _zookeeper . get ( <EOL> '<STR_LIT>' . format ( <EOL> path = self . _topic_path , slug = partition_slug ) ) <EOL> if owner_id == get_bytes ( self . _consumer_id ) : <EOL> zk_partition_ids . add ( int ( partition_slug . split ( '<STR_LIT:->' ) [ <NUM_LIT:1> ] ) ) <EOL> except NoNodeException : <EOL> pass <EOL> return set ( self . _topic . partitions [ _id ] for _id in zk_partition_ids ) <EOL> @ _catch_thread_exception <EOL> def _brokers_changed ( self , brokers ) : <EOL> if not self . _running : <EOL> return False <EOL> if self . _setting_watches : <EOL> return <EOL> log . debug ( "<STR_LIT>" . format ( <EOL> self . _consumer_id ) ) <EOL> self . _rebalance ( ) <EOL> @ _catch_thread_exception <EOL> def _consumers_changed ( self , consumers ) : <EOL> if not self . _running : <EOL> return False <EOL> if self . _setting_watches : <EOL> return <EOL> log . debug ( "<STR_LIT>" . format ( <EOL> self . _consumer_id ) ) <EOL> self . _rebalance ( ) <EOL> @ _catch_thread_exception <EOL> def _topics_changed ( self , topics ) : <EOL> if not self . _running : <EOL> return False <EOL> if self . _setting_watches : <EOL> return <EOL> log . debug ( "<STR_LIT>" . format ( <EOL> self . _consumer_id ) ) <EOL> self . _rebalance ( ) <EOL> def reset_offsets ( self , partition_offsets = None ) : <EOL> """<STR_LIT>""" <EOL> self . _raise_worker_exceptions ( ) <EOL> if not self . _consumer : <EOL> raise ConsumerStoppedException ( "<STR_LIT>" ) <EOL> self . _consumer . reset_offsets ( partition_offsets = partition_offsets ) <EOL> def consume ( self , block = True ) : <EOL> """<STR_LIT>""" <EOL> def consumer_timed_out ( ) : <EOL> """<STR_LIT>""" <EOL> if self . _consumer_timeout_ms == - <NUM_LIT:1> : <EOL> return False <EOL> disp = ( time . time ( ) - self . _last_message_time ) * <NUM_LIT> <EOL> return disp > self . _consumer_timeout_ms <EOL> message = None <EOL> self . _last_message_time = time . time ( ) <EOL> while message is None and not consumer_timed_out ( ) : <EOL> self . _raise_worker_exceptions ( ) <EOL> try : <EOL> message = self . _consumer . consume ( block = block ) <EOL> except ( ConsumerStoppedException , AttributeError ) : <EOL> if not self . _running : <EOL> raise ConsumerStoppedException <EOL> continue <EOL> if message : <EOL> self . _last_message_time = time . time ( ) <EOL> if not block : <EOL> return message <EOL> return message <EOL> def __iter__ ( self ) : <EOL> """<STR_LIT>""" <EOL> while True : <EOL> message = self . consume ( block = True ) <EOL> if not message : <EOL> raise StopIteration <EOL> yield message <EOL> def commit_offsets ( self ) : <EOL> """<STR_LIT>""" <EOL> self . _raise_worker_exceptions ( ) <EOL> if not self . _consumer : <EOL> raise KafkaException ( "<STR_LIT>" ) <EOL> return self . _consumer . commit_offsets ( ) </s>
<s> __license__ = """<STR_LIT>""" </s>
<s> from itertools import cycle <EOL> from streamparse import Spout <EOL> class WordSpout ( Spout ) : <EOL> outputs = [ '<STR_LIT>' ] <EOL> def initialize ( self , stormconf , context ) : <EOL> self . words = cycle ( [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> def next_tuple ( self ) : <EOL> word = next ( self . words ) <EOL> self . emit ( [ word ] ) </s>
<s> """<STR_LIT>""" <EOL> from . stream import Grouping , Stream <EOL> from . topology import Topology </s>
<s> """<STR_LIT>""" </s>
<s> from . constants import eStart , eError , eItsMe <EOL> HZ_cls = ( <EOL> <NUM_LIT:1> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:4> , <NUM_LIT:0> , <NUM_LIT:5> , <NUM_LIT:2> , <NUM_LIT:0> , <EOL> <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <EOL> <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <EOL> <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <EOL> <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <EOL> <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <EOL> <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <EOL> <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <EOL> <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <EOL> <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <EOL> <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <EOL> <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <EOL> <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <EOL> <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <EOL> <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <EOL> <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <EOL> <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> , <EOL> ) <EOL> HZ_st = ( <EOL> eStart , eError , <NUM_LIT:3> , eStart , eStart , eStart , eError , eError , <EOL> eError , eError , eError , eError , eItsMe , eItsMe , eItsMe , eItsMe , <EOL> eItsMe , eItsMe , eError , eError , eStart , eStart , <NUM_LIT:4> , eError , <EOL> <NUM_LIT:5> , eError , <NUM_LIT:6> , eError , <NUM_LIT:5> , <NUM_LIT:5> , <NUM_LIT:4> , eError , <EOL> <NUM_LIT:4> , eError , <NUM_LIT:4> , <NUM_LIT:4> , <NUM_LIT:4> , eError , <NUM_LIT:4> , eError , <EOL> <NUM_LIT:4> , eItsMe , eStart , eStart , eStart , eStart , eStart , eStart , <EOL> ) <EOL> HZCharLenTable = ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> ) <EOL> HZSMModel = { '<STR_LIT>' : HZ_cls , <EOL> '<STR_LIT>' : <NUM_LIT:6> , <EOL> '<STR_LIT>' : HZ_st , <EOL> '<STR_LIT>' : HZCharLenTable , <EOL> '<STR_LIT:name>' : "<STR_LIT>" } <EOL> ISO2022CN_cls = ( <EOL> <NUM_LIT:2> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:3> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:4> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> ) <EOL> ISO2022CN_st = ( <EOL> eStart , <NUM_LIT:3> , eError , eStart , eStart , eStart , eStart , eStart , <EOL> eStart , eError , eError , eError , eError , eError , eError , eError , <EOL> eError , eError , eItsMe , eItsMe , eItsMe , eItsMe , eItsMe , eItsMe , <EOL> eItsMe , eItsMe , eItsMe , eError , eError , eError , <NUM_LIT:4> , eError , <EOL> eError , eError , eError , eItsMe , eError , eError , eError , eError , <EOL> <NUM_LIT:5> , <NUM_LIT:6> , eError , eError , eError , eError , eError , eError , <EOL> eError , eError , eError , eItsMe , eError , eError , eError , eError , <EOL> eError , eError , eError , eError , eError , eItsMe , eError , eStart , <EOL> ) <EOL> ISO2022CNCharLenTable = ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> ) <EOL> ISO2022CNSMModel = { '<STR_LIT>' : ISO2022CN_cls , <EOL> '<STR_LIT>' : <NUM_LIT:9> , <EOL> '<STR_LIT>' : ISO2022CN_st , <EOL> '<STR_LIT>' : ISO2022CNCharLenTable , <EOL> '<STR_LIT:name>' : "<STR_LIT>" } <EOL> ISO2022JP_cls = ( <EOL> <NUM_LIT:2> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:7> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:3> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:6> , <NUM_LIT:0> , <NUM_LIT:4> , <NUM_LIT:0> , <NUM_LIT:8> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:9> , <NUM_LIT:5> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> ) <EOL> ISO2022JP_st = ( <EOL> eStart , <NUM_LIT:3> , eError , eStart , eStart , eStart , eStart , eStart , <EOL> eStart , eStart , eError , eError , eError , eError , eError , eError , <EOL> eError , eError , eError , eError , eItsMe , eItsMe , eItsMe , eItsMe , <EOL> eItsMe , eItsMe , eItsMe , eItsMe , eItsMe , eItsMe , eError , eError , <EOL> eError , <NUM_LIT:5> , eError , eError , eError , <NUM_LIT:4> , eError , eError , <EOL> eError , eError , eError , <NUM_LIT:6> , eItsMe , eError , eItsMe , eError , <EOL> eError , eError , eError , eError , eError , eError , eItsMe , eItsMe , <EOL> eError , eError , eError , eItsMe , eError , eError , eError , eError , <EOL> eError , eError , eError , eError , eItsMe , eError , eStart , eStart , <EOL> ) <EOL> ISO2022JPCharLenTable = ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> ) <EOL> ISO2022JPSMModel = { '<STR_LIT>' : ISO2022JP_cls , <EOL> '<STR_LIT>' : <NUM_LIT:10> , <EOL> '<STR_LIT>' : ISO2022JP_st , <EOL> '<STR_LIT>' : ISO2022JPCharLenTable , <EOL> '<STR_LIT:name>' : "<STR_LIT>" } <EOL> ISO2022KR_cls = ( <EOL> <NUM_LIT:2> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:1> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:3> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:4> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:5> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <NUM_LIT:2> , <EOL> ) <EOL> ISO2022KR_st = ( <EOL> eStart , <NUM_LIT:3> , eError , eStart , eStart , eStart , eError , eError , <EOL> eError , eError , eError , eError , eItsMe , eItsMe , eItsMe , eItsMe , <EOL> eItsMe , eItsMe , eError , eError , eError , <NUM_LIT:4> , eError , eError , <EOL> eError , eError , eError , eError , <NUM_LIT:5> , eError , eError , eError , <EOL> eError , eError , eError , eItsMe , eStart , eStart , eStart , eStart , <EOL> ) <EOL> ISO2022KRCharLenTable = ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> ) <EOL> ISO2022KRSMModel = { '<STR_LIT>' : ISO2022KR_cls , <EOL> '<STR_LIT>' : <NUM_LIT:6> , <EOL> '<STR_LIT>' : ISO2022KR_st , <EOL> '<STR_LIT>' : ISO2022KRCharLenTable , <EOL> '<STR_LIT:name>' : "<STR_LIT>" } </s>
<s> """<STR_LIT>""" <EOL> import argparse <EOL> import sys <EOL> import time <EOL> import inspect <EOL> import logging <EOL> import signal <EOL> import sys <EOL> from multiprocessing import Process <EOL> import tasa <EOL> from tasa . worker import BaseWorker <EOL> logger = logging . getLogger ( __name__ ) <EOL> logging . basicConfig ( level = logging . INFO ) <EOL> def signal_handler ( signal , frame ) : <EOL> sys . exit ( <NUM_LIT:0> ) <EOL> def _get_argparser ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> '<STR_LIT>' , '<STR_LIT>' , action = '<STR_LIT:version>' , <EOL> version = '<STR_LIT>' % ( <EOL> tasa . __version__ , sys . version ) ) <EOL> return parser <EOL> def run ( ) : <EOL> sys . path . insert ( <NUM_LIT:0> , '<STR_LIT>' ) <EOL> parser = _get_argparser ( ) <EOL> parser . description = '<STR_LIT>' <EOL> parser . add_argument ( '<STR_LIT>' , <EOL> type = lambda w : w . partition ( '<STR_LIT::>' ) [ : : <NUM_LIT:2> ] , <EOL> help = '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> args = parser . parse_args ( ) <EOL> worker_class_name = args . worker [ <NUM_LIT:1> ] or '<STR_LIT>' <EOL> worker_module = __import__ ( args . worker [ <NUM_LIT:0> ] , globals ( ) , locals ( ) , <EOL> [ worker_class_name ] ) <EOL> try : <EOL> WorkerClass = getattr ( worker_module , worker_class_name ) <EOL> except AttributeError : <EOL> print "<STR_LIT>" <EOL> potential_workers = inspect . getmembers ( <EOL> worker_module , <EOL> lambda x : type ( x ) == type and issubclass ( x , BaseWorker ) ) <EOL> if potential_workers : <EOL> print "<STR_LIT>" <EOL> for name , value in potential_workers : <EOL> print '<STR_LIT::>' . join ( [ args . worker [ <NUM_LIT:0> ] , name ] ) <EOL> exit ( <NUM_LIT:1> ) <EOL> worker = WorkerClass ( ) <EOL> print '<STR_LIT>' % ( args . worker [ <NUM_LIT:0> ] , <EOL> worker . __class__ . __name__ ) <EOL> try : <EOL> for job in worker : <EOL> if job : <EOL> logger . info ( "<STR_LIT>" , <EOL> worker . __class__ . __name__ , <EOL> str ( job ) [ : <NUM_LIT:50> ] ) <EOL> else : <EOL> time . sleep ( <NUM_LIT> ) <EOL> except KeyboardInterrupt : <EOL> print '<STR_LIT>' <EOL> def runm ( ) : <EOL> """<STR_LIT>""" <EOL> signal . signal ( signal . SIGINT , signal_handler ) <EOL> count = int ( sys . argv . pop ( <NUM_LIT:1> ) ) <EOL> processes = [ Process ( target = run , args = ( ) ) for x in range ( count ) ] <EOL> try : <EOL> for p in processes : <EOL> p . start ( ) <EOL> except KeyError : <EOL> pass <EOL> finally : <EOL> for p in processes : <EOL> p . join ( ) <EOL> def log ( ) : <EOL> parser = _get_argparser ( ) <EOL> parser . description = '<STR_LIT>' <EOL> args = parser . parse_args ( ) <EOL> raise NotImplemented ( ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> cmd = '<STR_LIT>' if len ( sys . argv ) < <NUM_LIT:2> else sys . argv . pop ( <NUM_LIT:1> ) <EOL> if cmd == '<STR_LIT>' : <EOL> run ( ) <EOL> elif cmd == '<STR_LIT>' : <EOL> log ( ) <EOL> else : <EOL> print "<STR_LIT>" </s>
<s> from datetime import date , timedelta <EOL> import uuid <EOL> import phonenumbers <EOL> from django . conf import settings <EOL> from django . db import models <EOL> from django . core . validators import RegexValidator <EOL> from django . utils import timezone <EOL> from django . utils . translation import ugettext as _ <EOL> from . behaviors import TimeStampedModel <EOL> from . import helpers , managers <EOL> class Tag ( models . Model ) : <EOL> """<STR_LIT>""" <EOL> color_regex = RegexValidator ( regex = r'<STR_LIT>' , message = "<STR_LIT>" ) <EOL> name = models . CharField ( max_length = <NUM_LIT:64> , unique = True , help_text = '<STR_LIT>' ) <EOL> color = models . CharField ( max_length = <NUM_LIT:6> , validators = [ color_regex ] , help_text = '<STR_LIT>' ) <EOL> description = models . CharField ( max_length = <NUM_LIT:64> , blank = True , help_text = '<STR_LIT>' ) <EOL> class Meta : <EOL> ordering = [ '<STR_LIT:name>' ] <EOL> def __str__ ( self ) : <EOL> return self . name <EOL> def save ( self , * args , ** kwargs ) : <EOL> self . color = self . color . lower ( ) <EOL> super ( Tag , self ) . save ( * args , ** kwargs ) <EOL> class Person ( models . Model ) : <EOL> """<STR_LIT>""" <EOL> phone_regex = RegexValidator ( regex = r'<STR_LIT>' , message = "<STR_LIT>" ) <EOL> DEVELOPER_ROLE = '<STR_LIT>' <EOL> QUALITY_ASSURANCE_ROLE = '<STR_LIT>' <EOL> OPERATIONS_ROLE = '<STR_LIT>' <EOL> MANAGER_ROLE = '<STR_LIT>' <EOL> SECURITY_OFFICER_ROLE = '<STR_LIT>' <EOL> SECURITY_CHAMPION_ROLE = '<STR_LIT>' <EOL> ROLE_CHOICES = ( <EOL> ( DEVELOPER_ROLE , '<STR_LIT>' ) , <EOL> ( QUALITY_ASSURANCE_ROLE , '<STR_LIT>' ) , <EOL> ( OPERATIONS_ROLE , '<STR_LIT>' ) , <EOL> ( MANAGER_ROLE , '<STR_LIT>' ) , <EOL> ( SECURITY_OFFICER_ROLE , '<STR_LIT>' ) , <EOL> ( SECURITY_CHAMPION_ROLE , '<STR_LIT>' ) , <EOL> ) <EOL> first_name = models . CharField ( max_length = <NUM_LIT:64> ) <EOL> last_name = models . CharField ( max_length = <NUM_LIT:64> ) <EOL> email = models . EmailField ( max_length = <NUM_LIT> , unique = True ) <EOL> role = models . CharField ( max_length = <NUM_LIT> , choices = ROLE_CHOICES ) <EOL> phone_work = models . CharField ( max_length = <NUM_LIT:15> , validators = [ phone_regex ] , blank = True ) <EOL> phone_mobile = models . CharField ( max_length = <NUM_LIT:15> , validators = [ phone_regex ] , blank = True ) <EOL> job_title = models . CharField ( max_length = <NUM_LIT> , blank = True ) <EOL> class Meta : <EOL> ordering = [ '<STR_LIT>' ] <EOL> verbose_name_plural = '<STR_LIT>' <EOL> def __str__ ( self ) : <EOL> return self . first_name + '<STR_LIT:U+0020>' + self . last_name <EOL> def save ( self , * args , ** kwargs ) : <EOL> if self . phone_work : <EOL> self . phone_work = phonenumbers . format_number ( phonenumbers . parse ( self . phone_work , '<STR_LIT>' ) , phonenumbers . PhoneNumberFormat . E164 ) <EOL> if self . phone_mobile : <EOL> self . phone_mobile = phonenumbers . format_number ( phonenumbers . parse ( self . phone_mobile , '<STR_LIT>' ) , phonenumbers . PhoneNumberFormat . E164 ) <EOL> self . email = self . email . lower ( ) <EOL> super ( Person , self ) . save ( * args , ** kwargs ) <EOL> class Organization ( models . Model ) : <EOL> """<STR_LIT>""" <EOL> name = models . CharField ( max_length = <NUM_LIT:32> , unique = True , help_text = '<STR_LIT>' ) <EOL> description = models . TextField ( blank = True , help_text = '<STR_LIT>' ) <EOL> people = models . ManyToManyField ( Person , blank = True ) <EOL> class Meta : <EOL> ordering = [ '<STR_LIT:name>' ] <EOL> def __str__ ( self ) : <EOL> return self . name <EOL> class DataElement ( models . Model ) : <EOL> """<STR_LIT>""" <EOL> GLOBAL_CATEGORY = '<STR_LIT>' <EOL> PERSONAL_CATEGORY = '<STR_LIT>' <EOL> COMPANY_CATEGORY = '<STR_LIT>' <EOL> STUDENT_CATEGORY = '<STR_LIT>' <EOL> GOVERNMENT_CATEGORY = '<STR_LIT>' <EOL> PCI_CATEGORY = '<STR_LIT>' <EOL> MEDICAL_CATEGORY = '<STR_LIT>' <EOL> CATEGORY_CHOICES = ( <EOL> ( GLOBAL_CATEGORY , '<STR_LIT>' ) , <EOL> ( PERSONAL_CATEGORY , '<STR_LIT>' ) , <EOL> ( COMPANY_CATEGORY , '<STR_LIT>' ) , <EOL> ( STUDENT_CATEGORY , '<STR_LIT>' ) , <EOL> ( GOVERNMENT_CATEGORY , '<STR_LIT>' ) , <EOL> ( PCI_CATEGORY , '<STR_LIT>' ) , <EOL> ( MEDICAL_CATEGORY , '<STR_LIT>' ) , <EOL> ) <EOL> name = models . CharField ( max_length = <NUM_LIT> , unique = True ) <EOL> description = models . TextField ( blank = True ) <EOL> category = models . CharField ( max_length = <NUM_LIT:10> , choices = CATEGORY_CHOICES ) <EOL> weight = models . PositiveIntegerField ( ) <EOL> class Meta : <EOL> ordering = [ '<STR_LIT:id>' ] <EOL> def __str__ ( self ) : <EOL> return self . name <EOL> class Technology ( models . Model ) : <EOL> """<STR_LIT>""" <EOL> PROGRAMMING_LANGUAGE_CATEGORY = '<STR_LIT>' <EOL> OPERATING_SYSTEM_CATEGORY = '<STR_LIT>' <EOL> DATA_STORE_CATEGORY = '<STR_LIT>' <EOL> FRAMEWORK_CATEGORY = '<STR_LIT>' <EOL> THIRD_PARTY_COMPONENT = '<STR_LIT>' <EOL> WEB_SERVER_CATEGORY = '<STR_LIT>' <EOL> APPLICATION_SERVER_CATEGORY = '<STR_LIT>' <EOL> HOSTING_PROVIDER_CATEGORY = '<STR_LIT>' <EOL> DENIAL_OF_SERVICE_CATEGORY = '<STR_LIT>' <EOL> FIREWALL_CATEGORY = '<STR_LIT>' <EOL> CATEGORY_CHOICES = ( <EOL> ( PROGRAMMING_LANGUAGE_CATEGORY , '<STR_LIT>' ) , <EOL> ( OPERATING_SYSTEM_CATEGORY , '<STR_LIT>' ) , <EOL> ( DATA_STORE_CATEGORY , '<STR_LIT>' ) , <EOL> ( FRAMEWORK_CATEGORY , '<STR_LIT>' ) , <EOL> ( THIRD_PARTY_COMPONENT , '<STR_LIT>' ) , <EOL> ( APPLICATION_SERVER_CATEGORY , '<STR_LIT>' ) , <EOL> ( WEB_SERVER_CATEGORY , '<STR_LIT>' ) , <EOL> ( HOSTING_PROVIDER_CATEGORY , '<STR_LIT>' ) , <EOL> ( DENIAL_OF_SERVICE_CATEGORY , '<STR_LIT>' ) , <EOL> ( FIREWALL_CATEGORY , '<STR_LIT>' ) , <EOL> ) <EOL> name = models . CharField ( max_length = <NUM_LIT:64> , help_text = '<STR_LIT>' ) <EOL> category = models . CharField ( max_length = <NUM_LIT> , choices = CATEGORY_CHOICES , help_text = '<STR_LIT>' ) <EOL> description = models . CharField ( max_length = <NUM_LIT> , blank = True , help_text = '<STR_LIT>' ) <EOL> reference = models . URLField ( blank = True , help_text = '<STR_LIT>' ) <EOL> class Meta : <EOL> ordering = [ '<STR_LIT>' , '<STR_LIT:name>' ] <EOL> verbose_name_plural = '<STR_LIT>' <EOL> def __str__ ( self ) : <EOL> return self . get_category_display ( ) + '<STR_LIT>' + self . name <EOL> class Regulation ( models . Model ) : <EOL> """<STR_LIT>""" <EOL> PRIVACY_CATEGORY = '<STR_LIT>' <EOL> FINANCE_CATEGORY = '<STR_LIT>' <EOL> EDUCATION_CATEGORY = '<STR_LIT>' <EOL> MEDICAL_CATEGORY = '<STR_LIT>' <EOL> OTHER_CATEGORY = '<STR_LIT>' <EOL> CATEGORY_CHOICES = ( <EOL> ( PRIVACY_CATEGORY , '<STR_LIT>' ) , <EOL> ( FINANCE_CATEGORY , '<STR_LIT>' ) , <EOL> ( EDUCATION_CATEGORY , '<STR_LIT>' ) , <EOL> ( MEDICAL_CATEGORY , '<STR_LIT>' ) , <EOL> ( OTHER_CATEGORY , '<STR_LIT>' ) , <EOL> ) <EOL> name = models . CharField ( max_length = <NUM_LIT> , help_text = '<STR_LIT>' ) <EOL> acronym = models . CharField ( max_length = <NUM_LIT:20> , unique = True , help_text = '<STR_LIT>' ) <EOL> category = models . CharField ( max_length = <NUM_LIT:9> , choices = CATEGORY_CHOICES , help_text = '<STR_LIT>' ) <EOL> jurisdiction = models . CharField ( max_length = <NUM_LIT:64> , help_text = '<STR_LIT>' ) <EOL> description = models . TextField ( blank = True , help_text = '<STR_LIT>' ) <EOL> reference = models . URLField ( blank = True , help_text = '<STR_LIT>' ) <EOL> class Meta : <EOL> ordering = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT:name>' ] <EOL> def __str__ ( self ) : <EOL> return self . acronym + '<STR_LIT>' + self . jurisdiction + '<STR_LIT:)>' <EOL> class ServiceLevelAgreement ( models . Model ) : <EOL> """<STR_LIT>""" <EOL> name = models . CharField ( max_length = <NUM_LIT:64> , help_text = '<STR_LIT>' ) <EOL> description = models . CharField ( max_length = <NUM_LIT> , blank = True , help_text = '<STR_LIT>' ) <EOL> class Meta : <EOL> ordering = [ '<STR_LIT:name>' ] <EOL> def __str__ ( self ) : <EOL> return self . name <EOL> class ThreadFix ( models . Model ) : <EOL> """<STR_LIT>""" <EOL> name = models . CharField ( max_length = <NUM_LIT:32> , unique = True , help_text = '<STR_LIT>' ) <EOL> host = models . URLField ( help_text = '<STR_LIT>' ) <EOL> api_key = models . CharField ( max_length = <NUM_LIT:50> , help_text = '<STR_LIT>' ) <EOL> verify_ssl = models . BooleanField ( default = True , help_text = '<STR_LIT>' ) <EOL> class Meta : <EOL> verbose_name = '<STR_LIT>' <EOL> verbose_name_plural = '<STR_LIT>' <EOL> def __str__ ( self ) : <EOL> return self . name + '<STR_LIT>' + self . host <EOL> class Application ( TimeStampedModel , models . Model ) : <EOL> """<STR_LIT>""" <EOL> WEB_PLATFORM = '<STR_LIT>' <EOL> DESKTOP_PLATFORM = '<STR_LIT>' <EOL> MOBILE_PLATFORM = '<STR_LIT>' <EOL> WEB_SERVICE_PLATFORM = '<STR_LIT>' <EOL> PLATFORM_CHOICES = ( <EOL> ( WEB_PLATFORM , '<STR_LIT>' ) , <EOL> ( DESKTOP_PLATFORM , '<STR_LIT>' ) , <EOL> ( MOBILE_PLATFORM , '<STR_LIT>' ) , <EOL> ( WEB_SERVICE_PLATFORM , '<STR_LIT>' ) , <EOL> ) <EOL> IDEA_LIFECYCLE = '<STR_LIT>' <EOL> EXPLORE_LIFECYCLE = '<STR_LIT>' <EOL> VALIDATE_LIFECYCLE = '<STR_LIT>' <EOL> GROW_LIFECYCLE = '<STR_LIT>' <EOL> SUSTAIN_LIFECYCLE = '<STR_LIT>' <EOL> RETIRE_LIFECYCLE = '<STR_LIT>' <EOL> LIFECYCLE_CHOICES = ( <EOL> ( IDEA_LIFECYCLE , '<STR_LIT>' ) , <EOL> ( EXPLORE_LIFECYCLE , '<STR_LIT>' ) , <EOL> ( VALIDATE_LIFECYCLE , '<STR_LIT>' ) , <EOL> ( GROW_LIFECYCLE , '<STR_LIT>' ) , <EOL> ( SUSTAIN_LIFECYCLE , '<STR_LIT>' ) , <EOL> ( RETIRE_LIFECYCLE , '<STR_LIT>' ) , <EOL> ) <EOL> THIRD_PARTY_LIBRARY_ORIGIN = '<STR_LIT>' <EOL> PURCHASED_ORIGIN = '<STR_LIT>' <EOL> CONTRACTOR_ORIGIN = '<STR_LIT>' <EOL> INTERNALLY_DEVELOPED_ORIGIN = '<STR_LIT>' <EOL> OPEN_SOURCE_ORIGIN = '<STR_LIT>' <EOL> OUTSOURCED_ORIGIN = '<STR_LIT>' <EOL> ORIGIN_CHOICES = ( <EOL> ( THIRD_PARTY_LIBRARY_ORIGIN , '<STR_LIT>' ) , <EOL> ( PURCHASED_ORIGIN , '<STR_LIT>' ) , <EOL> ( CONTRACTOR_ORIGIN , '<STR_LIT>' ) , <EOL> ( INTERNALLY_DEVELOPED_ORIGIN , '<STR_LIT>' ) , <EOL> ( OPEN_SOURCE_ORIGIN , '<STR_LIT>' ) , <EOL> ( OUTSOURCED_ORIGIN , '<STR_LIT>' ) , <EOL> ) <EOL> VERY_HIGH_CRITICALITY = '<STR_LIT>' <EOL> HIGH_CRITICALITY = '<STR_LIT>' <EOL> MEDIUM_CRITICALITY = '<STR_LIT>' <EOL> LOW_CRITICALITY = '<STR_LIT>' <EOL> VERY_LOW_CRITICALITY = '<STR_LIT>' <EOL> NONE_CRITICALITY = '<STR_LIT:none>' <EOL> BUSINESS_CRITICALITY_CHOICES = ( <EOL> ( VERY_HIGH_CRITICALITY , '<STR_LIT>' ) , <EOL> ( HIGH_CRITICALITY , '<STR_LIT>' ) , <EOL> ( MEDIUM_CRITICALITY , '<STR_LIT>' ) , <EOL> ( LOW_CRITICALITY , '<STR_LIT>' ) , <EOL> ( VERY_LOW_CRITICALITY , '<STR_LIT>' ) , <EOL> ( NONE_CRITICALITY , '<STR_LIT:None>' ) , <EOL> ) <EOL> DCL_1 = <NUM_LIT:1> <EOL> DCL_2 = <NUM_LIT:2> <EOL> DCL_3 = <NUM_LIT:3> <EOL> DCL_4 = <NUM_LIT:4> <EOL> DATA_CLASSIFICATION_CHOICES = ( <EOL> ( None , '<STR_LIT>' ) , <EOL> ( DCL_1 , '<STR_LIT>' ) , <EOL> ( DCL_2 , '<STR_LIT>' ) , <EOL> ( DCL_3 , '<STR_LIT>' ) , <EOL> ( DCL_4 , '<STR_LIT>' ) , <EOL> ) <EOL> ASVS_0 = <NUM_LIT:0> <EOL> ASVS_1 = <NUM_LIT:1> <EOL> ASVS_2 = <NUM_LIT:2> <EOL> ASVS_3 = <NUM_LIT:3> <EOL> ASVS_CHOICES = ( <EOL> ( None , '<STR_LIT>' ) , <EOL> ( ASVS_0 , '<STR_LIT:0>' ) , <EOL> ( ASVS_1 , '<STR_LIT:1>' ) , <EOL> ( ASVS_2 , '<STR_LIT:2>' ) , <EOL> ( ASVS_3 , '<STR_LIT:3>' ) , <EOL> ) <EOL> name = models . CharField ( max_length = <NUM_LIT> , unique = True , help_text = '<STR_LIT>' ) <EOL> description = models . TextField ( blank = True , help_text = '<STR_LIT>' ) <EOL> business_criticality = models . CharField ( max_length = <NUM_LIT:9> , choices = BUSINESS_CRITICALITY_CHOICES , blank = True , null = True ) <EOL> platform = models . CharField ( max_length = <NUM_LIT:11> , choices = PLATFORM_CHOICES , blank = True , null = True ) <EOL> lifecycle = models . CharField ( max_length = <NUM_LIT:8> , choices = LIFECYCLE_CHOICES , blank = True , null = True ) <EOL> origin = models . CharField ( max_length = <NUM_LIT> , choices = ORIGIN_CHOICES , blank = True , null = True ) <EOL> user_records = models . PositiveIntegerField ( blank = True , null = True , help_text = '<STR_LIT>' ) <EOL> revenue = models . DecimalField ( max_digits = <NUM_LIT:15> , decimal_places = <NUM_LIT:2> , blank = True , null = True , help_text = '<STR_LIT>' ) <EOL> external_audience = models . BooleanField ( default = False , help_text = '<STR_LIT>' ) <EOL> internet_accessible = models . BooleanField ( default = False , help_text = '<STR_LIT>' ) <EOL> requestable = models . NullBooleanField ( default = True , help_text = _ ( '<STR_LIT>' ) ) <EOL> technologies = models . ManyToManyField ( Technology , blank = True ) <EOL> regulations = models . ManyToManyField ( Regulation , blank = True ) <EOL> service_level_agreements = models . ManyToManyField ( ServiceLevelAgreement , blank = True ) <EOL> data_elements = models . ManyToManyField ( DataElement , blank = True ) <EOL> override_dcl = models . IntegerField ( choices = DATA_CLASSIFICATION_CHOICES , blank = True , null = True , help_text = '<STR_LIT>' ) <EOL> override_reason = models . TextField ( blank = True , help_text = '<STR_LIT>' ) <EOL> threadfix = models . ForeignKey ( ThreadFix , blank = True , null = True , help_text = '<STR_LIT>' ) <EOL> threadfix_team_id = models . PositiveIntegerField ( blank = True , null = True , help_text = '<STR_LIT>' ) <EOL> threadfix_application_id = models . PositiveIntegerField ( blank = True , null = True , help_text = '<STR_LIT>' ) <EOL> asvs_level = models . IntegerField ( choices = ASVS_CHOICES , blank = True , null = True , help_text = '<STR_LIT>' ) <EOL> asvs_level_percent_achieved = models . PositiveIntegerField ( blank = True , null = True , help_text = '<STR_LIT>' ) <EOL> asvs_doc_url = models . URLField ( blank = True , help_text = '<STR_LIT>' ) <EOL> asvs_level_target = models . IntegerField ( choices = ASVS_CHOICES , blank = True , null = True , help_text = '<STR_LIT>' ) <EOL> """<STR_LIT>""" <EOL> organization = models . ForeignKey ( Organization , help_text = '<STR_LIT>' ) <EOL> people = models . ManyToManyField ( Person , through = '<STR_LIT>' , blank = True ) <EOL> tags = models . ManyToManyField ( Tag , blank = True ) <EOL> objects = managers . ApplicationManager . from_queryset ( managers . ApplicationQuerySet ) ( ) <EOL> class Meta : <EOL> get_latest_by = '<STR_LIT>' <EOL> ordering = [ '<STR_LIT:name>' ] <EOL> def __str__ ( self ) : <EOL> return self . name <EOL> def data_classification_level ( self ) : <EOL> """<STR_LIT>""" <EOL> return helpers . data_classification_level ( self . data_sensitivity_value ( ) ) <EOL> def data_sensitivity_value ( self ) : <EOL> """<STR_LIT>""" <EOL> return helpers . data_sensitivity_value ( self . data_elements . all ( ) ) <EOL> def is_new ( self ) : <EOL> """<STR_LIT>""" <EOL> delta = self . created_date - timezone . now ( ) <EOL> return delta >= timedelta ( days = - <NUM_LIT:7> ) <EOL> class ThreadFixMetrics ( TimeStampedModel , models . Model ) : <EOL> """<STR_LIT>""" <EOL> critical_count = models . PositiveIntegerField ( default = <NUM_LIT:0> ) <EOL> high_count = models . PositiveIntegerField ( default = <NUM_LIT:0> ) <EOL> medium_count = models . PositiveIntegerField ( default = <NUM_LIT:0> ) <EOL> low_count = models . PositiveIntegerField ( default = <NUM_LIT:0> ) <EOL> informational_count = models . PositiveIntegerField ( default = <NUM_LIT:0> ) <EOL> application = models . ForeignKey ( Application ) <EOL> class Meta : <EOL> get_latest_by = '<STR_LIT>' <EOL> verbose_name = '<STR_LIT>' <EOL> verbose_name_plural = '<STR_LIT>' <EOL> def total ( self ) : <EOL> return self . critical_count + self . high_count + self . medium_count + self . low_count + self . informational_count <EOL> class Relation ( models . Model ) : <EOL> """<STR_LIT>""" <EOL> owner = models . BooleanField ( default = False , help_text = '<STR_LIT>' ) <EOL> emergency = models . BooleanField ( default = False , help_text = '<STR_LIT>' ) <EOL> notes = models . TextField ( blank = True , help_text = '<STR_LIT>' ) <EOL> person = models . ForeignKey ( Person , help_text = '<STR_LIT>' ) <EOL> application = models . ForeignKey ( Application ) <EOL> class Meta : <EOL> unique_together = ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> def __str__ ( self ) : <EOL> return self . person . first_name + '<STR_LIT:U+0020>' + self . person . last_name + '<STR_LIT>' + self . application . name <EOL> class Environment ( models . Model ) : <EOL> """<STR_LIT>""" <EOL> DEVELOPMENT_ENVIRONMENT = '<STR_LIT>' <EOL> INTEGRATION_ENVIRONMENT = '<STR_LIT:int>' <EOL> QUALITY_ASSURANCE_ENVIRONMENT = '<STR_LIT>' <EOL> PRE_PRODUCTION_ENVIRONMENT = '<STR_LIT>' <EOL> CUSTOMER_ACCEPTANCE_ENVIRONMENT = '<STR_LIT>' <EOL> PRODUCTION_ENVIRONMENT = '<STR_LIT>' <EOL> ENVIRONMENT_CHOICES = ( <EOL> ( DEVELOPMENT_ENVIRONMENT , '<STR_LIT>' ) , <EOL> ( INTEGRATION_ENVIRONMENT , '<STR_LIT>' ) , <EOL> ( QUALITY_ASSURANCE_ENVIRONMENT , '<STR_LIT>' ) , <EOL> ( PRE_PRODUCTION_ENVIRONMENT , '<STR_LIT>' ) , <EOL> ( CUSTOMER_ACCEPTANCE_ENVIRONMENT , '<STR_LIT>' ) , <EOL> ( PRODUCTION_ENVIRONMENT , '<STR_LIT>' ) , <EOL> ) <EOL> environment_type = models . CharField ( max_length = <NUM_LIT:4> , choices = ENVIRONMENT_CHOICES , help_text = '<STR_LIT>' ) <EOL> description = models . TextField ( blank = True , help_text = '<STR_LIT>' ) <EOL> testing_approved = models . BooleanField ( default = False , help_text = '<STR_LIT>' ) <EOL> application = models . ForeignKey ( Application ) <EOL> class Meta : <EOL> ordering = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> def __str__ ( self ) : <EOL> return self . application . name + '<STR_LIT>' + dict ( Environment . ENVIRONMENT_CHOICES ) [ self . environment_type ] + '<STR_LIT:)>' <EOL> class EnvironmentLocation ( models . Model ) : <EOL> """<STR_LIT>""" <EOL> location = models . URLField ( help_text = '<STR_LIT>' ) <EOL> notes = models . TextField ( blank = True , help_text = '<STR_LIT>' ) <EOL> environment = models . ForeignKey ( Environment ) <EOL> def __str__ ( self ) : <EOL> return self . location <EOL> class EnvironmentCredentials ( TimeStampedModel , models . Model ) : <EOL> """<STR_LIT>""" <EOL> username = models . CharField ( max_length = <NUM_LIT> , blank = True ) <EOL> password = models . CharField ( max_length = <NUM_LIT> , blank = True ) <EOL> role_description = models . CharField ( max_length = <NUM_LIT> , blank = True , help_text = '<STR_LIT>' ) <EOL> notes = models . TextField ( blank = True , help_text = '<STR_LIT>' ) <EOL> environment = models . ForeignKey ( Environment ) <EOL> class Meta : <EOL> verbose_name_plural = '<STR_LIT>' <EOL> ordering = [ '<STR_LIT:username>' , '<STR_LIT:password>' ] <EOL> class Engagement ( TimeStampedModel , models . Model ) : <EOL> """<STR_LIT>""" <EOL> PENDING_STATUS = '<STR_LIT>' <EOL> OPEN_STATUS = '<STR_LIT>' <EOL> CLOSED_STATUS = '<STR_LIT>' <EOL> STATUS_CHOICES = ( <EOL> ( PENDING_STATUS , '<STR_LIT>' ) , <EOL> ( OPEN_STATUS , '<STR_LIT>' ) , <EOL> ( CLOSED_STATUS , '<STR_LIT>' ) <EOL> ) <EOL> status = models . CharField ( max_length = <NUM_LIT:7> , choices = STATUS_CHOICES , default = PENDING_STATUS ) <EOL> start_date = models . DateField ( help_text = '<STR_LIT>' ) <EOL> end_date = models . DateField ( help_text = '<STR_LIT>' ) <EOL> description = models . TextField ( blank = True ) <EOL> open_date = models . DateTimeField ( blank = True , null = True , help_text = '<STR_LIT>' ) <EOL> close_date = models . DateTimeField ( blank = True , null = True , help_text = '<STR_LIT>' ) <EOL> duration = models . DurationField ( blank = True , null = True ) <EOL> requestor = models . ForeignKey ( Person , blank = True , null = True , help_text = '<STR_LIT>' ) <EOL> application = models . ForeignKey ( Application ) <EOL> objects = managers . EngagementManager . from_queryset ( managers . EngagementQuerySet ) ( ) <EOL> metrics = managers . EngagementMetrics . from_queryset ( managers . EngagementQuerySet ) ( ) <EOL> class Meta : <EOL> get_latest_by = '<STR_LIT>' <EOL> ordering = [ '<STR_LIT>' ] <EOL> def save ( self , * args , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> if self . pk is not None : <EOL> engagement = Engagement . objects . get ( pk = self . pk ) <EOL> now = timezone . now ( ) <EOL> if engagement . status != self . status : <EOL> if self . status == Engagement . PENDING_STATUS : <EOL> self . open_date = None <EOL> self . close_date = None <EOL> elif self . status == Engagement . OPEN_STATUS : <EOL> self . open_date = now <EOL> self . close_date = None <EOL> elif self . status == Engagement . CLOSED_STATUS : <EOL> if self . open_date is None : <EOL> self . open_date = now <EOL> self . close_date = now <EOL> if self . open_date is not None and self . close_date is not None : <EOL> self . duration = self . close_date - self . open_date <EOL> super ( Engagement , self ) . save ( * args , ** kwargs ) <EOL> def is_pending ( self ) : <EOL> return self . status == Engagement . PENDING_STATUS <EOL> def is_open ( self ) : <EOL> return self . status == Engagement . OPEN_STATUS <EOL> def is_closed ( self ) : <EOL> return self . status == Engagement . CLOSED_STATUS <EOL> def is_ready_for_work ( self ) : <EOL> """<STR_LIT>""" <EOL> if self . status == Engagement . PENDING_STATUS : <EOL> if date . today ( ) >= self . start_date : <EOL> return True <EOL> return False <EOL> def is_past_due ( self ) : <EOL> """<STR_LIT>""" <EOL> if self . status == Engagement . PENDING_STATUS or self . status == Engagement . OPEN_STATUS : <EOL> if date . today ( ) > self . end_date : <EOL> return True <EOL> return False <EOL> class ActivityType ( TimeStampedModel , models . Model ) : <EOL> """<STR_LIT>""" <EOL> name = models . CharField ( max_length = <NUM_LIT> , unique = True , help_text = _ ( '<STR_LIT>' ) ) <EOL> documentation = models . TextField ( blank = True , help_text = _ ( '<STR_LIT>' ) ) <EOL> objects = managers . ActivityTypeManager . from_queryset ( managers . ActivityTypeQuerySet ) ( ) <EOL> metrics = managers . ActivityTypeMetrics . from_queryset ( managers . ActivityTypeQuerySet ) ( ) <EOL> class Meta : <EOL> ordering = [ '<STR_LIT:name>' ] <EOL> def __str__ ( self ) : <EOL> return self . name <EOL> class Activity ( models . Model ) : <EOL> """<STR_LIT>""" <EOL> PENDING_STATUS = '<STR_LIT>' <EOL> OPEN_STATUS = '<STR_LIT>' <EOL> CLOSED_STATUS = '<STR_LIT>' <EOL> STATUS_CHOICES = ( <EOL> ( PENDING_STATUS , '<STR_LIT>' ) , <EOL> ( OPEN_STATUS , '<STR_LIT>' ) , <EOL> ( CLOSED_STATUS , '<STR_LIT>' ) <EOL> ) <EOL> status = models . CharField ( max_length = <NUM_LIT:7> , choices = STATUS_CHOICES , default = PENDING_STATUS ) <EOL> description = models . TextField ( blank = True ) <EOL> open_date = models . DateTimeField ( blank = True , null = True , help_text = '<STR_LIT>' ) <EOL> close_date = models . DateTimeField ( blank = True , null = True , help_text = '<STR_LIT>' ) <EOL> duration = models . DurationField ( blank = True , null = True ) <EOL> activity_type = models . ForeignKey ( ActivityType ) <EOL> engagement = models . ForeignKey ( Engagement ) <EOL> users = models . ManyToManyField ( settings . AUTH_USER_MODEL , blank = True ) <EOL> objects = managers . ActivityManager . from_queryset ( managers . ActivityQuerySet ) ( ) <EOL> class Meta : <EOL> ordering = [ '<STR_LIT>' ] <EOL> verbose_name_plural = '<STR_LIT>' <EOL> def __str__ ( self ) : <EOL> return self . activity_type . name <EOL> def save ( self , * args , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> if self . pk is not None : <EOL> activity = Activity . objects . get ( pk = self . pk ) <EOL> if activity . status != self . status : <EOL> now = timezone . now ( ) <EOL> if self . status == Activity . PENDING_STATUS : <EOL> self . open_date = None <EOL> self . close_date = None <EOL> elif self . status == Activity . OPEN_STATUS : <EOL> self . open_date = now <EOL> self . close_date = None <EOL> if self . engagement . status is not Engagement . OPEN_STATUS : <EOL> self . engagement . status = Engagement . OPEN_STATUS <EOL> self . engagement . save ( ) <EOL> elif self . status == Activity . CLOSED_STATUS : <EOL> if self . open_date is None : <EOL> self . open_date = now <EOL> self . close_date = now <EOL> close = True <EOL> for current_activity in self . engagement . activity_set . exclude ( id = self . id ) : <EOL> if current_activity . status != Activity . CLOSED_STATUS : <EOL> close = False <EOL> break <EOL> if close : <EOL> self . engagement . status = Engagement . CLOSED_STATUS <EOL> self . engagement . save ( ) <EOL> if self . open_date is not None and self . close_date is not None : <EOL> self . duration = self . close_date - self . open_date <EOL> super ( Activity , self ) . save ( * args , ** kwargs ) <EOL> def is_pending ( self ) : <EOL> return self . status == Activity . PENDING_STATUS <EOL> def is_open ( self ) : <EOL> return self . status == Activity . OPEN_STATUS <EOL> def is_closed ( self ) : <EOL> return self . status == Activity . CLOSED_STATUS <EOL> def is_ready_for_work ( self ) : <EOL> """<STR_LIT>""" <EOL> if self . status == Activity . PENDING_STATUS : <EOL> if date . today ( ) >= self . engagement . start_date : <EOL> return True <EOL> return False <EOL> def is_past_due ( self ) : <EOL> """<STR_LIT>""" <EOL> if self . status == Activity . PENDING_STATUS or self . status == Activity . OPEN_STATUS : <EOL> if date . today ( ) > self . engagement . end_date : <EOL> return True <EOL> return False <EOL> class Comment ( TimeStampedModel , models . Model ) : <EOL> """<STR_LIT>""" <EOL> message = models . TextField ( ) <EOL> user = models . ForeignKey ( settings . AUTH_USER_MODEL ) <EOL> def __str__ ( self ) : <EOL> return self . message <EOL> class Meta : <EOL> abstract = True <EOL> class EngagementComment ( Comment ) : <EOL> """<STR_LIT>""" <EOL> engagement = models . ForeignKey ( Engagement ) <EOL> class ActivityComment ( Comment ) : <EOL> """<STR_LIT>""" <EOL> activity = models . ForeignKey ( Activity ) <EOL> class ExternalRequest ( TimeStampedModel , models . Model ) : <EOL> """<STR_LIT>""" <EOL> token = models . UUIDField ( default = uuid . uuid4 , editable = False ) <EOL> requestor = models . ForeignKey ( Person ) <EOL> application = models . ForeignKey ( Application , blank = True ) <EOL> activities = models . ManyToManyField ( ActivityType , limit_choices_to = { '<STR_LIT>' : True } ) <EOL> class FileUpload ( TimeStampedModel , models . Model ) : <EOL> """<STR_LIT>""" <EOL> file = models . FileField ( ) <EOL> user = models . ForeignKey ( settings . AUTH_USER_MODEL ) <EOL> class Meta : <EOL> abstract = True <EOL> class ApplicationFileUpload ( FileUpload ) : <EOL> """<STR_LIT>""" <EOL> REPORT_FILE_TYPE = '<STR_LIT>' <EOL> DOCUMENTATION_FILE_TYPE = '<STR_LIT>' <EOL> FILE_TYPE_CHOICES = ( <EOL> ( REPORT_FILE_TYPE , '<STR_LIT>' ) , <EOL> ( DOCUMENTATION_FILE_TYPE , '<STR_LIT>' ) , <EOL> ) <EOL> file_type = models . CharField ( max_length = <NUM_LIT> , choices = FILE_TYPE_CHOICES ) <EOL> application = models . ForeignKey ( Application ) </s>
<s> """<STR_LIT>""" <EOL> from time import sleep <EOL> from flask import Flask <EOL> from flask_tut . models import ( <EOL> db , <EOL> User , <EOL> Address , <EOL> ) <EOL> app = Flask ( __name__ ) <EOL> with app . app_context ( ) : <EOL> db . create_all ( ) <EOL> i = <NUM_LIT:0> <EOL> while i < <NUM_LIT:30> : <EOL> address = Address ( description = '<STR_LIT>' + str ( i ) . rjust ( <NUM_LIT:2> , "<STR_LIT:0>" ) ) <EOL> db . session . add ( address ) <EOL> user = User ( name = '<STR_LIT>' + str ( i ) . rjust ( <NUM_LIT:2> , "<STR_LIT:0>" ) ) <EOL> user . address = address <EOL> db . session . add ( user ) <EOL> sleep ( <NUM_LIT:1> ) <EOL> i += <NUM_LIT:1> <EOL> db . session . commit ( ) </s>
<s> import urllib2 <EOL> import google <EOL> import time <EOL> import pyprind <EOL> import os <EOL> import random <EOL> from urlparse import urlparse <EOL> """<STR_LIT>""" <EOL> class Crawler ( object ) : <EOL> version = "<STR_LIT>" <EOL> outputDir = "<STR_LIT>" <EOL> languageDir = "<STR_LIT>" <EOL> basicString = "<STR_LIT>" <EOL> searchString = "<STR_LIT>" <EOL> def __init__ ( self , language = "<STR_LIT>" ) : <EOL> """<STR_LIT>""" <EOL> self . language = language . lower ( ) <EOL> self . parsedUrls = [ ] <EOL> self . foundedAccounts = <NUM_LIT:0> <EOL> def change_language ( self , language = "<STR_LIT>" ) : <EOL> """<STR_LIT>""" <EOL> if os . path . isfile ( self . languageDir + "<STR_LIT:/>" + language + "<STR_LIT>" ) : <EOL> self . language = language <EOL> return True <EOL> else : <EOL> return False <EOL> def search_links ( self ) : <EOL> """<STR_LIT>""" <EOL> for url in google . search ( self . searchString , num = <NUM_LIT:30> , stop = <NUM_LIT:1> ) : <EOL> parsed = urlparse ( url ) <EOL> self . parsedUrls . append ( parsed . scheme + "<STR_LIT>" + parsed . netloc ) <EOL> def search_accounts ( self , url = None ) : <EOL> """<STR_LIT>""" <EOL> if not self . parsedUrls : <EOL> return "<STR_LIT>" <EOL> try : <EOL> if not url : <EOL> url = random . choice ( self . parsedUrls ) <EOL> fileName = self . languageDir + "<STR_LIT:/>" + self . language + "<STR_LIT>" <EOL> fileLength = self . file_length ( fileName ) <EOL> progressBar = pyprind . ProgBar ( fileLength , title = "<STR_LIT>" + url + "<STR_LIT>" , stream = <NUM_LIT:1> , monitor = True ) <EOL> foundedAccounts = <NUM_LIT:0> <EOL> with open ( fileName ) as f : <EOL> rows = f . readlines ( ) <EOL> for row in rows : <EOL> opener = urllib2 . build_opener ( ) <EOL> opener . addheaders = [ ( '<STR_LIT>' , '<STR_LIT>' ) ] <EOL> response = opener . open ( url + self . basicString % ( row . rstrip ( ) . lstrip ( ) , row . rstrip ( ) . lstrip ( ) ) ) <EOL> fetched = response . read ( ) <EOL> fileLength = fileLength - <NUM_LIT:1> <EOL> progressBar . update ( ) <EOL> if len ( fetched ) > <NUM_LIT:0> : <EOL> newPath = self . outputDir + "<STR_LIT:/>" + url . replace ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> self . create_file ( row , newPath , fetched ) <EOL> self . parsedUrls . remove ( url ) <EOL> if self . foundedAccounts != <NUM_LIT:0> : <EOL> return "<STR_LIT>" + url + "<STR_LIT>" + str ( self . foundedAccounts ) <EOL> else : <EOL> return "<STR_LIT>" + url <EOL> except IOError : <EOL> return "<STR_LIT>" <EOL> except urllib2 . HTTPError , e : <EOL> return "<STR_LIT>" + str ( e . code ) <EOL> except urllib2 . URLError , e : <EOL> return "<STR_LIT>" + str ( e . reason ) <EOL> except Exception : <EOL> return "<STR_LIT>" <EOL> def create_file ( self , row , newPath , fetched ) : <EOL> """<STR_LIT>""" <EOL> if os . path . exists ( newPath ) is False : <EOL> os . makedirs ( newPath ) <EOL> outputFile = open ( str ( newPath ) + "<STR_LIT>" % row . rstrip ( ) . lstrip ( ) , "<STR_LIT:w>" ) <EOL> outputFile . write ( fetched ) <EOL> self . foundedAccounts = self . foundedAccounts + <NUM_LIT:1> <EOL> outputFile . close ( ) <EOL> def file_length ( self , fileName ) : <EOL> """<STR_LIT>""" <EOL> with open ( fileName ) as f : <EOL> for i , l in enumerate ( f ) : <EOL> pass <EOL> return i + <NUM_LIT:1> </s>
<s> from cStringIO import StringIO <EOL> from binascii import b2a_hex <EOL> from urllib import quote <EOL> import Connecter <EOL> try : <EOL> True <EOL> except : <EOL> True = <NUM_LIT:1> <EOL> False = <NUM_LIT:0> <EOL> DEBUG = False <EOL> protocol_name = '<STR_LIT>' <EOL> option_pattern = chr ( <NUM_LIT:0> ) * <NUM_LIT:8> <EOL> def toint ( s ) : <EOL> return long ( b2a_hex ( s ) , <NUM_LIT:16> ) <EOL> def tohex ( s ) : <EOL> return b2a_hex ( s ) . upper ( ) <EOL> def make_readable ( s ) : <EOL> if not s : <EOL> return '<STR_LIT>' <EOL> if quote ( s ) . find ( '<STR_LIT:%>' ) >= <NUM_LIT:0> : <EOL> return tohex ( s ) <EOL> return '<STR_LIT:">' + s + '<STR_LIT:">' <EOL> streamno = <NUM_LIT:0> <EOL> class StreamCheck : <EOL> def __init__ ( self ) : <EOL> global streamno <EOL> self . no = streamno <EOL> streamno += <NUM_LIT:1> <EOL> self . buffer = StringIO ( ) <EOL> self . next_len , self . next_func = <NUM_LIT:1> , self . read_header_len <EOL> def read_header_len ( self , s ) : <EOL> if ord ( s ) != len ( protocol_name ) : <EOL> print self . no , '<STR_LIT>' <EOL> return len ( protocol_name ) , self . read_header <EOL> def read_header ( self , s ) : <EOL> if s != protocol_name : <EOL> print self . no , '<STR_LIT>' <EOL> return <NUM_LIT:8> , self . read_reserved <EOL> def read_reserved ( self , s ) : <EOL> return <NUM_LIT:20> , self . read_download_id <EOL> def read_download_id ( self , s ) : <EOL> if DEBUG : <EOL> print self . no , '<STR_LIT>' + tohex ( s ) <EOL> return <NUM_LIT:20> , self . read_peer_id <EOL> def read_peer_id ( self , s ) : <EOL> if DEBUG : <EOL> print self . no , '<STR_LIT>' + make_readable ( s ) <EOL> return <NUM_LIT:4> , self . read_len <EOL> def read_len ( self , s ) : <EOL> l = toint ( s ) <EOL> if l > <NUM_LIT:2> ** <NUM_LIT> : <EOL> print self . no , '<STR_LIT>' + str ( l ) + '<STR_LIT>' + s + '<STR_LIT:)>' <EOL> return l , self . read_message <EOL> def read_message ( self , s ) : <EOL> if not s : <EOL> return <NUM_LIT:4> , self . read_len <EOL> m = s [ <NUM_LIT:0> ] <EOL> if ord ( m ) > <NUM_LIT:8> : <EOL> print self . no , '<STR_LIT>' + str ( ord ( m ) ) <EOL> if m == Connecter . REQUEST : <EOL> if len ( s ) != <NUM_LIT> : <EOL> print self . no , '<STR_LIT>' + str ( len ( s ) ) <EOL> return <NUM_LIT:4> , self . read_len <EOL> index = toint ( s [ <NUM_LIT:1> : <NUM_LIT:5> ] ) <EOL> begin = toint ( s [ <NUM_LIT:5> : <NUM_LIT:9> ] ) <EOL> length = toint ( s [ <NUM_LIT:9> : ] ) <EOL> print self . no , '<STR_LIT>' + str ( index ) + '<STR_LIT>' + str ( begin ) + '<STR_LIT:->' + str ( begin ) + '<STR_LIT:+>' + str ( length ) <EOL> elif m == Connecter . CANCEL : <EOL> if len ( s ) != <NUM_LIT> : <EOL> print self . no , '<STR_LIT>' + str ( len ( s ) ) <EOL> return <NUM_LIT:4> , self . read_len <EOL> index = toint ( s [ <NUM_LIT:1> : <NUM_LIT:5> ] ) <EOL> begin = toint ( s [ <NUM_LIT:5> : <NUM_LIT:9> ] ) <EOL> length = toint ( s [ <NUM_LIT:9> : ] ) <EOL> print self . no , '<STR_LIT>' + str ( index ) + '<STR_LIT>' + str ( begin ) + '<STR_LIT:->' + str ( begin ) + '<STR_LIT:+>' + str ( length ) <EOL> elif m == Connecter . PIECE : <EOL> index = toint ( s [ <NUM_LIT:1> : <NUM_LIT:5> ] ) <EOL> begin = toint ( s [ <NUM_LIT:5> : <NUM_LIT:9> ] ) <EOL> length = len ( s ) - <NUM_LIT:9> <EOL> print self . no , '<STR_LIT>' + str ( index ) + '<STR_LIT>' + str ( begin ) + '<STR_LIT:->' + str ( begin ) + '<STR_LIT:+>' + str ( length ) <EOL> else : <EOL> print self . no , '<STR_LIT>' + str ( ord ( m ) ) + '<STR_LIT>' + str ( len ( s ) ) + '<STR_LIT:)>' <EOL> return <NUM_LIT:4> , self . read_len <EOL> def write ( self , s ) : <EOL> while <NUM_LIT:1> : <EOL> i = self . next_len - self . buffer . tell ( ) <EOL> if i > len ( s ) : <EOL> self . buffer . write ( s ) <EOL> return <EOL> self . buffer . write ( s [ : i ] ) <EOL> s = s [ i : ] <EOL> m = self . buffer . getvalue ( ) <EOL> self . buffer . reset ( ) <EOL> self . buffer . truncate ( ) <EOL> x = self . next_func ( m ) <EOL> self . next_len , self . next_func = x </s>
<s> from types import * <EOL> from cStringIO import StringIO <EOL> def splitLine ( line , COLS = <NUM_LIT> , indent = <NUM_LIT:10> ) : <EOL> indent = "<STR_LIT:U+0020>" * indent <EOL> width = COLS - ( len ( indent ) + <NUM_LIT:1> ) <EOL> if indent and width < <NUM_LIT:15> : <EOL> width = COLS - <NUM_LIT:2> <EOL> indent = "<STR_LIT:U+0020>" <EOL> s = StringIO ( ) <EOL> i = <NUM_LIT:0> <EOL> for word in line . split ( ) : <EOL> if i == <NUM_LIT:0> : <EOL> s . write ( indent + word ) <EOL> i = len ( word ) <EOL> continue <EOL> if i + len ( word ) >= width : <EOL> s . write ( '<STR_LIT:\n>' + indent + word ) <EOL> i = len ( word ) <EOL> continue <EOL> s . write ( '<STR_LIT:U+0020>' + word ) <EOL> i += len ( word ) + <NUM_LIT:1> <EOL> return s . getvalue ( ) <EOL> def formatDefinitions ( options , COLS , presets = { } ) : <EOL> s = StringIO ( ) <EOL> for ( longname , default , doc ) in options : <EOL> s . write ( '<STR_LIT>' + longname + '<STR_LIT>' ) <EOL> default = presets . get ( longname , default ) <EOL> if type ( default ) in ( IntType , LongType ) : <EOL> try : <EOL> default = int ( default ) <EOL> except : <EOL> pass <EOL> if default is not None : <EOL> doc += '<STR_LIT>' + repr ( default ) + '<STR_LIT:)>' <EOL> s . write ( splitLine ( doc , COLS , <NUM_LIT:10> ) ) <EOL> s . write ( '<STR_LIT>' ) <EOL> return s . getvalue ( ) <EOL> def usage ( string ) : <EOL> raise ValueError ( string ) <EOL> def defaultargs ( options ) : <EOL> l = { } <EOL> for ( longname , default , doc ) in options : <EOL> if default is not None : <EOL> l [ longname ] = default <EOL> return l <EOL> def parseargs ( argv , options , minargs = None , maxargs = None , presets = { } ) : <EOL> config = { } <EOL> longkeyed = { } <EOL> for option in options : <EOL> longname , default , doc = option <EOL> longkeyed [ longname ] = option <EOL> config [ longname ] = default <EOL> for longname in presets . keys ( ) : <EOL> config [ longname ] = presets [ longname ] <EOL> options = [ ] <EOL> args = [ ] <EOL> pos = <NUM_LIT:0> <EOL> while pos < len ( argv ) : <EOL> if argv [ pos ] [ : <NUM_LIT:2> ] != '<STR_LIT>' : <EOL> args . append ( argv [ pos ] ) <EOL> pos += <NUM_LIT:1> <EOL> else : <EOL> if pos == len ( argv ) - <NUM_LIT:1> : <EOL> usage ( '<STR_LIT>' ) <EOL> key , value = argv [ pos ] [ <NUM_LIT:2> : ] , argv [ pos + <NUM_LIT:1> ] <EOL> pos += <NUM_LIT:2> <EOL> if not longkeyed . has_key ( key ) : <EOL> usage ( '<STR_LIT>' + key ) <EOL> longname , default , doc = longkeyed [ key ] <EOL> try : <EOL> t = type ( config [ longname ] ) <EOL> if t is NoneType or t is StringType : <EOL> config [ longname ] = value <EOL> elif t in ( IntType , LongType ) : <EOL> config [ longname ] = long ( value ) <EOL> elif t is FloatType : <EOL> config [ longname ] = float ( value ) <EOL> else : <EOL> assert <NUM_LIT:0> <EOL> except ValueError , e : <EOL> usage ( '<STR_LIT>' % ( key , str ( e ) ) ) <EOL> for key , value in config . items ( ) : <EOL> if value is None : <EOL> usage ( "<STR_LIT>" % key ) <EOL> if minargs is not None and len ( args ) < minargs : <EOL> usage ( "<STR_LIT>" % minargs ) <EOL> if maxargs is not None and len ( args ) > maxargs : <EOL> usage ( "<STR_LIT>" % maxargs ) <EOL> return ( config , args ) <EOL> def test_parseargs ( ) : <EOL> assert parseargs ( ( '<STR_LIT:d>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT:e>' , '<STR_LIT>' , '<STR_LIT:3>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT:f>' ) , ( ( '<STR_LIT:a>' , '<STR_LIT:x>' , '<STR_LIT>' ) , ( '<STR_LIT:b>' , <NUM_LIT:1> , '<STR_LIT>' ) , ( '<STR_LIT:c>' , <NUM_LIT> , '<STR_LIT>' ) ) ) == ( { '<STR_LIT:a>' : '<STR_LIT>' , '<STR_LIT:b>' : <NUM_LIT:3> , '<STR_LIT:c>' : <NUM_LIT> } , [ '<STR_LIT:d>' , '<STR_LIT:e>' , '<STR_LIT:f>' ] ) <EOL> assert parseargs ( [ ] , [ ( '<STR_LIT:a>' , '<STR_LIT:x>' , '<STR_LIT>' ) ] ) == ( { '<STR_LIT:a>' : '<STR_LIT:x>' } , [ ] ) <EOL> assert parseargs ( [ '<STR_LIT>' , '<STR_LIT:x>' , '<STR_LIT>' , '<STR_LIT:y>' ] , [ ( '<STR_LIT:a>' , '<STR_LIT>' , '<STR_LIT>' ) ] ) == ( { '<STR_LIT:a>' : '<STR_LIT:y>' } , [ ] ) <EOL> try : <EOL> parseargs ( [ ] , [ ( '<STR_LIT:a>' , '<STR_LIT:x>' , '<STR_LIT>' ) ] ) <EOL> except ValueError : <EOL> pass <EOL> try : <EOL> parseargs ( [ '<STR_LIT>' , '<STR_LIT:x>' ] , [ ] ) <EOL> except ValueError : <EOL> pass <EOL> try : <EOL> parseargs ( [ '<STR_LIT>' ] , [ ( '<STR_LIT:a>' , '<STR_LIT:x>' , '<STR_LIT>' ) ] ) <EOL> except ValueError : <EOL> pass <EOL> try : <EOL> parseargs ( [ ] , [ ] , <NUM_LIT:1> , <NUM_LIT:2> ) <EOL> except ValueError : <EOL> pass <EOL> assert parseargs ( [ '<STR_LIT:x>' ] , [ ] , <NUM_LIT:1> , <NUM_LIT:2> ) == ( { } , [ '<STR_LIT:x>' ] ) <EOL> assert parseargs ( [ '<STR_LIT:x>' , '<STR_LIT:y>' ] , [ ] , <NUM_LIT:1> , <NUM_LIT:2> ) == ( { } , [ '<STR_LIT:x>' , '<STR_LIT:y>' ] ) <EOL> try : <EOL> parseargs ( [ '<STR_LIT:x>' , '<STR_LIT:y>' , '<STR_LIT:z>' ] , [ ] , <NUM_LIT:1> , <NUM_LIT:2> ) <EOL> except ValueError : <EOL> pass <EOL> try : <EOL> parseargs ( [ '<STR_LIT>' , '<STR_LIT>' ] , [ ( '<STR_LIT:a>' , <NUM_LIT:3> , '<STR_LIT>' ) ] ) <EOL> except ValueError : <EOL> pass <EOL> try : <EOL> parseargs ( [ '<STR_LIT>' , '<STR_LIT:z>' ] , [ ( '<STR_LIT:a>' , <NUM_LIT> , '<STR_LIT>' ) ] ) <EOL> except ValueError : <EOL> pass </s>
<s> import datetime <EOL> from south . db import db <EOL> from south . v2 import SchemaMigration <EOL> from django . db import models <EOL> class Migration ( SchemaMigration ) : <EOL> def forwards ( self , orm ) : <EOL> db . add_column ( '<STR_LIT>' , '<STR_LIT>' , <EOL> self . gf ( '<STR_LIT>' ) ( to = orm [ '<STR_LIT>' ] , null = True , blank = True ) , <EOL> keep_default = False ) <EOL> def backwards ( self , orm ) : <EOL> db . delete_column ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> models = { <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:Meta>' : { '<STR_LIT:object_name>' : '<STR_LIT>' } , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:name>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:max_length>' : '<STR_LIT>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" , '<STR_LIT>' : '<STR_LIT:False>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:Meta>' : { '<STR_LIT>' : "<STR_LIT>" , '<STR_LIT>' : "<STR_LIT>" , '<STR_LIT:object_name>' : '<STR_LIT>' } , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT:100>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" } ) , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:name>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' } ) <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:Meta>' : { '<STR_LIT:object_name>' : '<STR_LIT>' } , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT>' } ) , <EOL> '<STR_LIT:email>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" , '<STR_LIT>' : '<STR_LIT:False>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT:False>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT:False>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:password>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" , '<STR_LIT>' : '<STR_LIT:False>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:username>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:max_length>' : '<STR_LIT>' } ) <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:Meta>' : { '<STR_LIT>' : "<STR_LIT>" , '<STR_LIT>' : "<STR_LIT>" , '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : "<STR_LIT>" } , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT:100>' } ) , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT:100>' } ) , <EOL> '<STR_LIT:name>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT:100>' } ) <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:Meta>' : { '<STR_LIT:object_name>' : '<STR_LIT>' } , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:name>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT:100>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:max_length>' : '<STR_LIT:100>' } ) <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:Meta>' : { '<STR_LIT:object_name>' : '<STR_LIT>' } , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:related_name>' : "<STR_LIT>" , '<STR_LIT:to>' : "<STR_LIT>" } ) , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:related_name>' : "<STR_LIT>" , '<STR_LIT:to>' : "<STR_LIT>" } ) <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:Meta>' : { '<STR_LIT:object_name>' : '<STR_LIT>' } , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:description>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:null>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT:False>' } ) , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:name>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT:None>' , '<STR_LIT>' : '<STR_LIT>' } ) <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:Meta>' : { '<STR_LIT:object_name>' : '<STR_LIT>' } , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" , '<STR_LIT:null>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:description>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' } ) , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT:None>' , '<STR_LIT>' : '<STR_LIT>' } ) , <EOL> '<STR_LIT:title>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" , '<STR_LIT>' : '<STR_LIT:False>' } ) <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:Meta>' : { '<STR_LIT:object_name>' : '<STR_LIT>' } , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:null>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT:False>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:name>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:null>' : '<STR_LIT:True>' , '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT:2>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" } ) <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:Meta>' : { '<STR_LIT:object_name>' : '<STR_LIT>' } , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT:False>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT:False>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:description>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:null>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' } ) , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT:1>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:Meta>' : { '<STR_LIT:object_name>' : '<STR_LIT>' } , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT:100>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" , '<STR_LIT:null>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:date>' : ( '<STR_LIT>' , [ ] , { } ) , <EOL> '<STR_LIT:description>' : ( '<STR_LIT>' , [ ] , { } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:null>' : '<STR_LIT:True>' , '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT:2>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT:False>' } ) , <EOL> '<STR_LIT:id>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:primary_key>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT:1>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:null>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:null>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:null>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT:100>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT:False>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT>' : '<STR_LIT:True>' , '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT:None>' , '<STR_LIT>' : '<STR_LIT>' } ) , <EOL> '<STR_LIT:title>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:default>' : '<STR_LIT:False>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT:user>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:to>' : "<STR_LIT>" , '<STR_LIT:null>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:null>' : '<STR_LIT:True>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' , [ ] , { '<STR_LIT:max_length>' : '<STR_LIT>' , '<STR_LIT:blank>' : '<STR_LIT:True>' } ) <EOL> } <EOL> } <EOL> complete_apps = [ '<STR_LIT>' ] </s>
<s> import os <EOL> from collections import namedtuple <EOL> from shutil import rmtree <EOL> from stat import S_IFDIR , S_IFREG , S_IFLNK <EOL> from pygit2 import ( clone_repository , Signature , GIT_SORT_TOPOLOGICAL , <EOL> GIT_FILEMODE_TREE , GIT_STATUS_CURRENT , <EOL> GIT_FILEMODE_LINK , GIT_FILEMODE_BLOB , GIT_BRANCH_REMOTE , <EOL> GIT_BRANCH_LOCAL , GIT_FILEMODE_BLOB_EXECUTABLE ) <EOL> from six import iteritems <EOL> from gitfs . cache import CommitCache <EOL> from gitfs . log import log <EOL> from gitfs . utils . path import split_path_into_components <EOL> from gitfs . utils . commits import CommitsList <EOL> DivergeCommits = namedtuple ( "<STR_LIT>" , [ "<STR_LIT>" , <EOL> "<STR_LIT>" , "<STR_LIT>" ] ) <EOL> class Repository ( object ) : <EOL> def __init__ ( self , repository , commits = None ) : <EOL> self . _repo = repository <EOL> self . commits = commits or CommitCache ( self ) <EOL> self . behind = False <EOL> def __getitem__ ( self , item ) : <EOL> """<STR_LIT>""" <EOL> return self . _repo [ item ] <EOL> def __getattr__ ( self , attr ) : <EOL> """<STR_LIT>""" <EOL> if attr not in self . __dict__ : <EOL> return getattr ( self . _repo , attr ) <EOL> else : <EOL> return self . __dict__ [ attr ] <EOL> def ahead ( self , upstream , branch ) : <EOL> ahead , _ = self . diverge ( upstream , branch ) <EOL> return ahead <EOL> def diverge ( self , upstream , branch ) : <EOL> reference = "<STR_LIT>" . format ( upstream , branch ) <EOL> remote_branch = self . lookup_branch ( reference , GIT_BRANCH_REMOTE ) <EOL> local_branch = self . lookup_branch ( branch , GIT_BRANCH_LOCAL ) <EOL> if remote_branch . target == local_branch . target : <EOL> return False , False <EOL> diverge_commits = self . find_diverge_commits ( local_branch , <EOL> remote_branch ) <EOL> behind = len ( diverge_commits . second_commits ) > <NUM_LIT:0> <EOL> ahead = len ( diverge_commits . first_commits ) > <NUM_LIT:0> <EOL> return ahead , behind <EOL> def checkout ( self , ref , * args , ** kwargs ) : <EOL> result = self . _repo . checkout ( ref , * args , ** kwargs ) <EOL> self . ignore . update ( ) <EOL> status = self . _repo . status ( ) <EOL> for path , status in iteritems ( status ) : <EOL> if status == GIT_STATUS_CURRENT : <EOL> continue <EOL> full_path = self . _full_path ( path ) <EOL> if path not in self . _repo . index : <EOL> if path not in self . ignore : <EOL> try : <EOL> os . unlink ( full_path ) <EOL> except OSError : <EOL> rmtree ( <EOL> full_path , <EOL> onerror = lambda function , fpath , excinfo : log . info ( <EOL> "<STR_LIT>" , fpath <EOL> ) <EOL> ) <EOL> continue <EOL> stats = self . get_git_object_default_stats ( ref , path ) <EOL> current_stat = os . lstat ( full_path ) <EOL> if stats [ '<STR_LIT>' ] != current_stat . st_mode : <EOL> os . chmod ( full_path , current_stat . st_mode ) <EOL> self . _repo . index . add ( self . _sanitize ( path ) ) <EOL> return result <EOL> def _sanitize ( self , path ) : <EOL> if path is not None and path . startswith ( "<STR_LIT:/>" ) : <EOL> path = path [ <NUM_LIT:1> : ] <EOL> return path <EOL> def push ( self , upstream , branch , credentials ) : <EOL> """<STR_LIT>""" <EOL> remote = self . get_remote ( upstream ) <EOL> remote . push ( [ "<STR_LIT>" % ( branch ) ] , callbacks = credentials ) <EOL> def fetch ( self , upstream , branch_name , credentials ) : <EOL> """<STR_LIT>""" <EOL> remote = self . get_remote ( upstream ) <EOL> remote . fetch ( callbacks = credentials ) <EOL> _ , behind = self . diverge ( upstream , branch_name ) <EOL> self . behind = behind <EOL> return behind <EOL> def commit ( self , message , author , commiter , parents = None , ref = "<STR_LIT>" ) : <EOL> """<STR_LIT>""" <EOL> status = self . _repo . status ( ) <EOL> if status == { } : <EOL> return None <EOL> author = Signature ( author [ <NUM_LIT:0> ] , author [ <NUM_LIT:1> ] ) <EOL> commiter = Signature ( commiter [ <NUM_LIT:0> ] , commiter [ <NUM_LIT:1> ] ) <EOL> tree = self . _repo . index . write_tree ( ) <EOL> self . _repo . index . write ( ) <EOL> if parents is None : <EOL> parents = [ self . _repo . revparse_single ( ref ) . id ] <EOL> return self . _repo . create_commit ( ref , author , commiter , message , <EOL> tree , parents ) <EOL> @ classmethod <EOL> def clone ( cls , remote_url , path , branch = None , credentials = None ) : <EOL> """<STR_LIT>""" <EOL> repo = clone_repository ( remote_url , path , checkout_branch = branch , <EOL> callbacks = credentials ) <EOL> repo . checkout_head ( ) <EOL> return cls ( repo ) <EOL> def _is_searched_entry ( self , entry_name , searched_entry , path_components ) : <EOL> """<STR_LIT>""" <EOL> return ( entry_name == searched_entry and <EOL> len ( path_components ) == <NUM_LIT:1> and <EOL> entry_name == path_components [ <NUM_LIT:0> ] ) <EOL> def _get_git_object ( self , tree , obj_name , path_components , modifier ) : <EOL> """<STR_LIT>""" <EOL> git_obj = None <EOL> for entry in tree : <EOL> if self . _is_searched_entry ( entry . name , obj_name , path_components ) : <EOL> return modifier ( entry ) <EOL> elif entry . filemode == GIT_FILEMODE_TREE : <EOL> git_obj = self . _get_git_object ( self . _repo [ entry . id ] , obj_name , <EOL> path_components [ <NUM_LIT:1> : ] , modifier ) <EOL> if git_obj : <EOL> return git_obj <EOL> return git_obj <EOL> def get_git_object_type ( self , tree , path ) : <EOL> """<STR_LIT>""" <EOL> path_components = split_path_into_components ( path ) <EOL> try : <EOL> return self . _get_git_object ( tree , path_components [ - <NUM_LIT:1> ] , <EOL> path_components , <EOL> lambda entry : entry . filemode ) <EOL> except : <EOL> return GIT_FILEMODE_TREE <EOL> def get_git_object ( self , tree , path ) : <EOL> """<STR_LIT>""" <EOL> path_components = split_path_into_components ( path ) <EOL> return self . _get_git_object ( tree , path_components [ - <NUM_LIT:1> ] , path_components , <EOL> lambda entry : self . _repo [ entry . id ] ) <EOL> def get_git_object_default_stats ( self , ref , path ) : <EOL> types = { <EOL> GIT_FILEMODE_LINK : { <EOL> '<STR_LIT>' : S_IFLNK | <NUM_LIT> , <EOL> } , GIT_FILEMODE_TREE : { <EOL> '<STR_LIT>' : S_IFDIR | <NUM_LIT> , <EOL> '<STR_LIT>' : <NUM_LIT:2> <EOL> } , GIT_FILEMODE_BLOB : { <EOL> '<STR_LIT>' : S_IFREG | <NUM_LIT> , <EOL> } , GIT_FILEMODE_BLOB_EXECUTABLE : { <EOL> '<STR_LIT>' : S_IFREG | <NUM_LIT> , <EOL> } , <EOL> } <EOL> if path == "<STR_LIT:/>" : <EOL> return types [ GIT_FILEMODE_TREE ] <EOL> obj_type = self . get_git_object_type ( ref , path ) <EOL> if obj_type is None : <EOL> return obj_type <EOL> stats = types [ obj_type ] <EOL> if obj_type in [ GIT_FILEMODE_BLOB , GIT_FILEMODE_BLOB_EXECUTABLE ] : <EOL> stats [ '<STR_LIT>' ] = self . get_blob_size ( ref , path ) <EOL> return stats <EOL> def get_blob_size ( self , tree , path ) : <EOL> """<STR_LIT>""" <EOL> return self . get_git_object ( tree , path ) . size <EOL> def get_blob_data ( self , tree , path ) : <EOL> """<STR_LIT>""" <EOL> return self . get_git_object ( tree , path ) . data <EOL> def get_commit_dates ( self ) : <EOL> """<STR_LIT>""" <EOL> return list ( self . commits . keys ( ) ) <EOL> def get_commits_by_date ( self , date ) : <EOL> """<STR_LIT>""" <EOL> return list ( map ( str , self . commits [ date ] ) ) <EOL> def walk_branches ( self , sort , * branches ) : <EOL> """<STR_LIT>""" <EOL> iterators = [ self . _repo . walk ( branch . target , sort ) <EOL> for branch in branches ] <EOL> stop_iteration = [ False for branch in branches ] <EOL> commits = [ ] <EOL> for iterator in iterators : <EOL> try : <EOL> commit = next ( iterator ) <EOL> except StopIteration : <EOL> commit = None <EOL> commits . append ( commit ) <EOL> yield ( commit for commit in commits ) <EOL> while not all ( stop_iteration ) : <EOL> for index , iterator in enumerate ( iterators ) : <EOL> try : <EOL> commit = next ( iterator ) <EOL> commits [ index ] = commit <EOL> except StopIteration : <EOL> stop_iteration [ index ] = True <EOL> if not all ( stop_iteration ) : <EOL> yield ( commit for commit in commits ) <EOL> def remote_head ( self , upstream , branch ) : <EOL> ref = "<STR_LIT>" % ( upstream , branch ) <EOL> remote = self . _repo . lookup_branch ( ref , GIT_BRANCH_REMOTE ) <EOL> return remote . get_object ( ) <EOL> def get_remote ( self , name ) : <EOL> """<STR_LIT>""" <EOL> remote = [ remote for remote in self . _repo . remotes <EOL> if remote . name == name ] <EOL> if not remote : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> return remote [ <NUM_LIT:0> ] <EOL> def _full_path ( self , partial ) : <EOL> if partial . startswith ( "<STR_LIT:/>" ) : <EOL> partial = partial [ <NUM_LIT:1> : ] <EOL> return os . path . join ( self . _repo . workdir , partial ) <EOL> def find_diverge_commits ( self , first_branch , second_branch ) : <EOL> """<STR_LIT>""" <EOL> common_parent = None <EOL> first_commits = CommitsList ( ) <EOL> second_commits = CommitsList ( ) <EOL> walker = self . walk_branches ( GIT_SORT_TOPOLOGICAL , <EOL> first_branch , second_branch ) <EOL> for first_commit , second_commit in walker : <EOL> if ( first_commit in second_commits or <EOL> second_commit in first_commits ) : <EOL> break <EOL> if first_commit not in first_commits : <EOL> first_commits . append ( first_commit ) <EOL> if second_commit not in second_commits : <EOL> second_commits . append ( second_commit ) <EOL> if second_commit . hex == first_commit . hex : <EOL> break <EOL> try : <EOL> index = second_commits . index ( first_commit ) <EOL> except ValueError : <EOL> pass <EOL> else : <EOL> second_commits = second_commits [ : index ] <EOL> common_parent = first_commit <EOL> try : <EOL> index = first_commits . index ( second_commit ) <EOL> except ValueError : <EOL> pass <EOL> else : <EOL> first_commits = first_commits [ : index ] <EOL> common_parent = second_commit <EOL> return DivergeCommits ( common_parent , first_commits , second_commits ) </s>
<s> from datetime import datetime <EOL> from mock import MagicMock , call <EOL> from pygit2 import GIT_SORT_TIME <EOL> from gitfs . cache . commits import Commit , CommitCache <EOL> class TestCommit ( object ) : <EOL> def test_commit ( self ) : <EOL> commit = Commit ( <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT:1> ) <EOL> new_commit = Commit ( <NUM_LIT:2> , <NUM_LIT:2> , "<STR_LIT>" ) <EOL> assert new_commit > commit <EOL> assert repr ( new_commit ) == "<STR_LIT>" <EOL> class TestCommitCache ( object ) : <EOL> def test_cache ( self ) : <EOL> mocked_repo = MagicMock ( ) <EOL> mocked_commit = MagicMock ( ) <EOL> mocked_repo . lookup_reference ( ) . resolve ( ) . target = "<STR_LIT>" <EOL> mocked_repo . walk . return_value = [ mocked_commit ] <EOL> mocked_commit . commit_time = <NUM_LIT> <EOL> mocked_commit . hex = '<STR_LIT>' <EOL> cache = CommitCache ( mocked_repo ) <EOL> cache . update ( ) <EOL> cache [ '<STR_LIT>' ] = Commit ( <NUM_LIT:1> , <NUM_LIT:1> , "<STR_LIT>" ) <EOL> assert sorted ( cache . keys ( ) ) == [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> asserted_time = datetime . fromtimestamp ( mocked_commit . commit_time ) <EOL> asserted_time = "<STR_LIT>" . format ( asserted_time . hour , asserted_time . minute , <EOL> asserted_time . second ) <EOL> assert repr ( cache [ '<STR_LIT>' ] ) == '<STR_LIT>' % asserted_time <EOL> del cache [ '<STR_LIT>' ] <EOL> for commit_date in cache : <EOL> assert commit_date == '<STR_LIT>' <EOL> mocked_repo . lookup_reference . has_calls ( [ call ( "<STR_LIT>" ) ] ) <EOL> mocked_repo . walk . assert_called_once_with ( "<STR_LIT>" , GIT_SORT_TIME ) <EOL> assert mocked_repo . lookup_reference ( ) . resolve . call_count == <NUM_LIT:2> </s>
<s> import pytest <EOL> import datetime as dt <EOL> from mock import MagicMock <EOL> from gitfs . utils . strptime import TimeParser <EOL> from gitfs . utils import strptime <EOL> class TestDateTimeUtils ( object ) : <EOL> def test_strptime ( self ) : <EOL> date = dt . date ( <NUM_LIT> , <NUM_LIT:8> , <NUM_LIT> ) <EOL> datetime = dt . datetime ( <NUM_LIT> , <NUM_LIT:8> , <NUM_LIT> , <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) <EOL> assert strptime ( "<STR_LIT>" , "<STR_LIT>" ) == date <EOL> assert strptime ( "<STR_LIT>" , "<STR_LIT>" , <EOL> to_datetime = True ) == datetime <EOL> date = dt . date ( <NUM_LIT> , <NUM_LIT:8> , <NUM_LIT:30> ) <EOL> datetime = dt . datetime ( <NUM_LIT> , <NUM_LIT:8> , <NUM_LIT:30> , <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> ) <EOL> assert strptime ( "<STR_LIT>" , "<STR_LIT>" ) == date <EOL> assert strptime ( "<STR_LIT>" , "<STR_LIT>" , <EOL> to_datetime = True ) == datetime <EOL> date = dt . date ( <NUM_LIT> , <NUM_LIT:1> , <NUM_LIT:1> ) <EOL> datetime = dt . datetime ( <NUM_LIT> , <NUM_LIT:1> , <NUM_LIT:1> , <NUM_LIT> , <NUM_LIT:30> ) <EOL> assert strptime ( "<STR_LIT>" , "<STR_LIT>" ) == date <EOL> assert strptime ( "<STR_LIT>" , "<STR_LIT>" , <EOL> to_datetime = True ) == datetime <EOL> with pytest . raises ( ValueError ) : <EOL> strptime ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> def test_time_parser_match_with_value_error ( self ) : <EOL> mocked_pattern = MagicMock ( ) <EOL> mocked_pattern . match . return_value = False <EOL> parser = TimeParser ( "<STR_LIT>" ) <EOL> parser . pattern = mocked_pattern <EOL> with pytest . raises ( ValueError ) : <EOL> parser . match ( "<STR_LIT>" ) <EOL> mocked_pattern . match . assert_called_once_with ( "<STR_LIT>" ) </s>
<s> from __future__ import unicode_literals <EOL> from django . db import migrations <EOL> import jsonfield . fields <EOL> class Migration ( migrations . Migration ) : <EOL> dependencies = [ <EOL> ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> ] <EOL> operations = [ <EOL> migrations . AddField ( <EOL> model_name = '<STR_LIT>' , <EOL> name = '<STR_LIT>' , <EOL> field = jsonfield . fields . JSONField ( null = True , blank = True ) , <EOL> ) , <EOL> migrations . AddField ( <EOL> model_name = '<STR_LIT>' , <EOL> name = '<STR_LIT>' , <EOL> field = jsonfield . fields . JSONField ( null = True , blank = True ) , <EOL> ) , <EOL> migrations . AddField ( <EOL> model_name = '<STR_LIT>' , <EOL> name = '<STR_LIT>' , <EOL> field = jsonfield . fields . JSONField ( null = True , blank = True ) , <EOL> ) , <EOL> ] </s>
<s> from zipa import api_github_com as github <EOL> repos = github . orgs . django . repos <EOL> for repo in repos [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] : <EOL> print repo . name </s>
<s> import supybot . conf as conf <EOL> import supybot . registry as registry <EOL> from supybot . i18n import PluginInternationalization , internationalizeDocstring <EOL> _ = PluginInternationalization ( '<STR_LIT>' ) <EOL> def configure ( advanced ) : <EOL> from supybot . questions import expect , anything , something , yn <EOL> conf . registerPlugin ( '<STR_LIT>' , True ) <EOL> Alias = conf . registerPlugin ( '<STR_LIT>' ) <EOL> conf . registerGroup ( Alias , '<STR_LIT>' ) <EOL> conf . registerGroup ( Alias , '<STR_LIT>' ) <EOL> conf . registerGlobalValue ( Alias , '<STR_LIT>' , <EOL> registry . String ( r'<STR_LIT>' , _ ( """<STR_LIT>""" ) ) ) </s>
<s> import supybot . conf as conf <EOL> import supybot . registry as registry <EOL> try : <EOL> from supybot . i18n import PluginInternationalization <EOL> from supybot . i18n import internationalizeDocstring <EOL> _ = PluginInternationalization ( '<STR_LIT>' ) <EOL> except : <EOL> _ = lambda x : x <EOL> internationalizeDocstring = lambda x : x <EOL> def configure ( advanced ) : <EOL> from supybot . questions import expect , anything , something , yn <EOL> conf . registerPlugin ( '<STR_LIT>' , True ) <EOL> Conditional = conf . registerPlugin ( '<STR_LIT>' ) </s>
<s> import supybot . conf as conf <EOL> import supybot . registry as registry <EOL> from supybot . i18n import PluginInternationalization , internationalizeDocstring <EOL> _ = PluginInternationalization ( '<STR_LIT>' ) <EOL> Filter = conf . registerPlugin ( '<STR_LIT>' ) <EOL> conf . registerGroup ( Filter , '<STR_LIT>' ) <EOL> conf . registerGlobalValue ( Filter . spellit , <EOL> '<STR_LIT>' , registry . Boolean ( True , _ ( """<STR_LIT>""" ) ) ) <EOL> conf . registerGlobalValue ( Filter . spellit , <EOL> '<STR_LIT>' , registry . Boolean ( True , _ ( """<STR_LIT>""" ) ) ) <EOL> conf . registerGlobalValue ( Filter . spellit , <EOL> '<STR_LIT>' , registry . Boolean ( True , _ ( """<STR_LIT>""" ) ) ) <EOL> conf . registerGroup ( Filter , '<STR_LIT>' ) <EOL> conf . registerChannelValue ( Filter . shrink , '<STR_LIT>' , <EOL> registry . PositiveInteger ( <NUM_LIT:4> , _ ( """<STR_LIT>""" ) ) ) <EOL> def configure ( advanced ) : <EOL> from supybot . questions import expect , anything , something , yn <EOL> conf . registerPlugin ( '<STR_LIT>' , True ) </s>
<s> import supybot . conf as conf <EOL> import supybot . registry as registry <EOL> from supybot . i18n import PluginInternationalization , internationalizeDocstring <EOL> _ = PluginInternationalization ( '<STR_LIT>' ) <EOL> def configure ( advanced ) : <EOL> from supybot . questions import expect , anything , something , yn <EOL> conf . registerPlugin ( '<STR_LIT>' , True ) <EOL> Karma = conf . registerPlugin ( '<STR_LIT>' ) <EOL> conf . registerChannelValue ( Karma , '<STR_LIT>' , <EOL> registry . Boolean ( False , _ ( """<STR_LIT>""" ) ) ) <EOL> conf . registerChannelValue ( Karma , '<STR_LIT>' , <EOL> registry . SpaceSeparatedListOfStrings ( [ '<STR_LIT>' ] , _ ( """<STR_LIT>""" ) ) ) <EOL> conf . registerChannelValue ( Karma , '<STR_LIT>' , <EOL> registry . SpaceSeparatedListOfStrings ( [ '<STR_LIT>' ] , _ ( """<STR_LIT>""" ) ) ) <EOL> conf . registerChannelValue ( Karma , '<STR_LIT>' , <EOL> registry . Boolean ( False , _ ( """<STR_LIT>""" ) ) ) <EOL> conf . registerChannelValue ( Karma , '<STR_LIT>' , <EOL> registry . Integer ( <NUM_LIT:3> , _ ( """<STR_LIT>""" ) ) ) <EOL> conf . registerChannelValue ( Karma , '<STR_LIT>' , <EOL> registry . Integer ( <NUM_LIT> , _ ( """<STR_LIT>""" ) ) ) <EOL> conf . registerChannelValue ( Karma , '<STR_LIT>' , <EOL> registry . Boolean ( False , _ ( """<STR_LIT>""" ) ) ) <EOL> conf . registerChannelValue ( Karma , '<STR_LIT>' , <EOL> registry . Boolean ( True , _ ( """<STR_LIT>""" ) ) ) <EOL> conf . registerChannelValue ( Karma , '<STR_LIT>' , <EOL> registry . Boolean ( False , _ ( """<STR_LIT>""" ) ) ) </s>
<s> """<STR_LIT>""" <EOL> import supybot <EOL> import supybot . world as world <EOL> __version__ = "<STR_LIT>" <EOL> __author__ = supybot . authors . strike <EOL> __contributors__ = { } <EOL> from . import config <EOL> from . import plugin <EOL> from imp import reload <EOL> reload ( plugin ) <EOL> if world . testing : <EOL> from . import test <EOL> Class = plugin . Class <EOL> configure = config . configure </s>
<s> """<STR_LIT>""" <EOL> import supybot <EOL> import supybot . world as world <EOL> __version__ = "<STR_LIT>" <EOL> __author__ = supybot . authors . jemfinch <EOL> __contributors__ = { } <EOL> from . import config <EOL> from . import plugin <EOL> from imp import reload <EOL> reload ( plugin ) <EOL> if world . testing : <EOL> from . import test <EOL> Class = plugin . Class <EOL> configure = config . configure </s>
<s> """<STR_LIT>""" <EOL> import supybot <EOL> import supybot . world as world <EOL> __version__ = "<STR_LIT>" <EOL> __author__ = supybot . authors . jemfinch <EOL> __contributors__ = { } <EOL> from . import config <EOL> from . import plugin <EOL> from imp import reload <EOL> reload ( plugin ) <EOL> if world . testing : <EOL> from . import test <EOL> Class = plugin . Class <EOL> configure = config . configure </s>
<s> """<STR_LIT>""" <EOL> import supybot <EOL> import supybot . world as world <EOL> __version__ = "<STR_LIT>" <EOL> __author__ = supybot . authors . jemfinch <EOL> __contributors__ = { } <EOL> from . import config <EOL> from . import plugin <EOL> from imp import reload <EOL> reload ( plugin ) <EOL> if world . testing : <EOL> from . import test <EOL> Class = plugin . Class <EOL> configure = config . configure </s>
<s> """<STR_LIT>""" <EOL> import supybot <EOL> import supybot . world as world <EOL> __version__ = "<STR_LIT>" <EOL> __author__ = supybot . authors . jemfinch <EOL> __contributors__ = { } <EOL> __url__ = '<STR_LIT>' <EOL> from . import config <EOL> from . import plugin <EOL> from imp import reload <EOL> reload ( plugin ) <EOL> if world . testing : <EOL> from . import test <EOL> Class = plugin . Class <EOL> configure = config . configure </s>
<s> """<STR_LIT>""" <EOL> from __future__ import division <EOL> import os <EOL> import time <EOL> import errno <EOL> import select <EOL> import socket <EOL> from . . import ( conf , drivers , log , utils , world ) <EOL> from . . utils import minisix <EOL> from . . utils . str import decode_raw_line <EOL> try : <EOL> import ssl <EOL> SSLError = ssl . SSLError <EOL> except : <EOL> drivers . log . debug ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> class SSLError ( Exception ) : <EOL> pass <EOL> class SocketDriver ( drivers . IrcDriver , drivers . ServersMixin ) : <EOL> _instances = [ ] <EOL> _selecting = [ False ] <EOL> def __init__ ( self , irc ) : <EOL> self . _instances . append ( self ) <EOL> assert irc is not None <EOL> self . irc = irc <EOL> drivers . IrcDriver . __init__ ( self , irc ) <EOL> drivers . ServersMixin . __init__ ( self , irc ) <EOL> self . conn = None <EOL> self . _attempt = - <NUM_LIT:1> <EOL> self . servers = ( ) <EOL> self . eagains = <NUM_LIT:0> <EOL> self . inbuffer = b'<STR_LIT>' <EOL> self . outbuffer = '<STR_LIT>' <EOL> self . zombie = False <EOL> self . connected = False <EOL> self . writeCheckTime = None <EOL> self . nextReconnectTime = None <EOL> self . resetDelay ( ) <EOL> if self . networkGroup . get ( '<STR_LIT>' ) . value and '<STR_LIT>' not in globals ( ) : <EOL> drivers . log . error ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> self . ssl = False <EOL> else : <EOL> self . ssl = self . networkGroup . get ( '<STR_LIT>' ) . value <EOL> self . connect ( ) <EOL> def getDelay ( self ) : <EOL> ret = self . currentDelay <EOL> self . currentDelay = min ( self . currentDelay * <NUM_LIT:2> , <EOL> conf . supybot . drivers . maxReconnectWait ( ) ) <EOL> return ret <EOL> def resetDelay ( self ) : <EOL> self . currentDelay = <NUM_LIT> <EOL> def _getNextServer ( self ) : <EOL> oldServer = getattr ( self , '<STR_LIT>' , None ) <EOL> server = drivers . ServersMixin . _getNextServer ( self ) <EOL> if self . currentServer != oldServer : <EOL> self . resetDelay ( ) <EOL> return server <EOL> def _handleSocketError ( self , e ) : <EOL> if e . args [ <NUM_LIT:0> ] != <NUM_LIT:11> or self . eagains > <NUM_LIT> : <EOL> drivers . log . disconnect ( self . currentServer , e ) <EOL> if self in self . _instances : <EOL> self . _instances . remove ( self ) <EOL> try : <EOL> self . conn . close ( ) <EOL> except : <EOL> pass <EOL> self . connected = False <EOL> self . scheduleReconnect ( ) <EOL> else : <EOL> log . debug ( '<STR_LIT>' , self . eagains ) <EOL> self . eagains += <NUM_LIT:1> <EOL> def _sendIfMsgs ( self ) : <EOL> if not self . connected : <EOL> return <EOL> if not self . zombie : <EOL> msgs = [ self . irc . takeMsg ( ) ] <EOL> while msgs [ - <NUM_LIT:1> ] is not None : <EOL> msgs . append ( self . irc . takeMsg ( ) ) <EOL> del msgs [ - <NUM_LIT:1> ] <EOL> self . outbuffer += '<STR_LIT>' . join ( map ( str , msgs ) ) <EOL> if self . outbuffer : <EOL> try : <EOL> if minisix . PY2 : <EOL> sent = self . conn . send ( self . outbuffer ) <EOL> else : <EOL> sent = self . conn . send ( self . outbuffer . encode ( ) ) <EOL> self . outbuffer = self . outbuffer [ sent : ] <EOL> self . eagains = <NUM_LIT:0> <EOL> except socket . error as e : <EOL> self . _handleSocketError ( e ) <EOL> if self . zombie and not self . outbuffer : <EOL> self . _reallyDie ( ) <EOL> @ classmethod <EOL> def _select ( cls ) : <EOL> if cls . _selecting [ <NUM_LIT:0> ] : <EOL> return <EOL> try : <EOL> cls . _selecting [ <NUM_LIT:0> ] = True <EOL> for inst in cls . _instances : <EOL> if not inst . connected or ( minisix . PY3 and inst . conn . _closed ) or ( minisix . PY2 and <EOL> inst . conn . _sock . __class__ is socket . _closedsocket ) : <EOL> cls . _instances . remove ( inst ) <EOL> elif inst . conn . fileno ( ) == - <NUM_LIT:1> : <EOL> inst . reconnect ( ) <EOL> if not cls . _instances : <EOL> return <EOL> rlist , wlist , xlist = select . select ( [ x . conn for x in cls . _instances ] , <EOL> [ ] , [ ] , conf . supybot . drivers . poll ( ) ) <EOL> for instance in cls . _instances : <EOL> if instance . conn in rlist : <EOL> instance . _read ( ) <EOL> except select . error as e : <EOL> if e . args [ <NUM_LIT:0> ] != errno . EINTR : <EOL> raise <EOL> finally : <EOL> cls . _selecting [ <NUM_LIT:0> ] = False <EOL> for instance in cls . _instances : <EOL> if instance . irc and not instance . irc . zombie : <EOL> instance . _sendIfMsgs ( ) <EOL> def run ( self ) : <EOL> now = time . time ( ) <EOL> if self . nextReconnectTime is not None and now > self . nextReconnectTime : <EOL> self . reconnect ( ) <EOL> elif self . writeCheckTime is not None and now > self . writeCheckTime : <EOL> self . _checkAndWriteOrReconnect ( ) <EOL> if not self . connected : <EOL> time . sleep ( conf . supybot . drivers . poll ( ) ) <EOL> return <EOL> self . _sendIfMsgs ( ) <EOL> self . _select ( ) <EOL> def _read ( self ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> self . inbuffer += self . conn . recv ( <NUM_LIT> ) <EOL> self . eagains = <NUM_LIT:0> <EOL> lines = self . inbuffer . split ( b'<STR_LIT:\n>' ) <EOL> self . inbuffer = lines . pop ( ) <EOL> for line in lines : <EOL> line = decode_raw_line ( line ) <EOL> msg = drivers . parseMsg ( line ) <EOL> if msg is not None and self . irc is not None : <EOL> self . irc . feedMsg ( msg ) <EOL> except socket . timeout : <EOL> pass <EOL> except SSLError as e : <EOL> if e . args [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> pass <EOL> else : <EOL> self . _handleSocketError ( e ) <EOL> return <EOL> except socket . error as e : <EOL> self . _handleSocketError ( e ) <EOL> return <EOL> if self . irc and not self . irc . zombie : <EOL> self . _sendIfMsgs ( ) <EOL> def connect ( self , ** kwargs ) : <EOL> self . reconnect ( reset = False , ** kwargs ) <EOL> def reconnect ( self , wait = False , reset = True ) : <EOL> self . _attempt += <NUM_LIT:1> <EOL> self . nextReconnectTime = None <EOL> if self . connected : <EOL> drivers . log . reconnect ( self . irc . network ) <EOL> if self in self . _instances : <EOL> self . _instances . remove ( self ) <EOL> try : <EOL> self . conn . shutdown ( socket . SHUT_RDWR ) <EOL> except : <EOL> pass <EOL> self . conn . close ( ) <EOL> self . connected = False <EOL> if reset : <EOL> drivers . log . debug ( '<STR_LIT>' , self . irc ) <EOL> self . irc . reset ( ) <EOL> else : <EOL> drivers . log . debug ( '<STR_LIT>' , self . irc ) <EOL> if wait : <EOL> self . scheduleReconnect ( ) <EOL> return <EOL> self . server = self . _getNextServer ( ) <EOL> network_config = getattr ( conf . supybot . networks , self . irc . network ) <EOL> socks_proxy = network_config . socksproxy ( ) <EOL> try : <EOL> if socks_proxy : <EOL> import socks <EOL> except ImportError : <EOL> log . error ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> socks_proxy = '<STR_LIT>' <EOL> if socks_proxy : <EOL> address = self . server [ <NUM_LIT:0> ] <EOL> else : <EOL> try : <EOL> address = utils . net . getAddressFromHostname ( self . server [ <NUM_LIT:0> ] , <EOL> attempt = self . _attempt ) <EOL> except ( socket . gaierror , socket . error ) as e : <EOL> drivers . log . connectError ( self . currentServer , e ) <EOL> self . scheduleReconnect ( ) <EOL> return <EOL> port = self . server [ <NUM_LIT:1> ] <EOL> drivers . log . connect ( self . currentServer ) <EOL> try : <EOL> self . conn = utils . net . getSocket ( address , port = port , <EOL> socks_proxy = socks_proxy , <EOL> vhost = conf . supybot . protocols . irc . vhost ( ) , <EOL> vhostv6 = conf . supybot . protocols . irc . vhostv6 ( ) , <EOL> ) <EOL> except socket . error as e : <EOL> drivers . log . connectError ( self . currentServer , e ) <EOL> self . scheduleReconnect ( ) <EOL> return <EOL> self . conn . settimeout ( max ( <NUM_LIT:10> , conf . supybot . drivers . poll ( ) * <NUM_LIT:10> ) ) <EOL> try : <EOL> self . conn . connect ( ( address , port ) ) <EOL> if network_config . ssl ( ) : <EOL> self . starttls ( ) <EOL> elif not network_config . requireStarttls ( ) : <EOL> drivers . log . warning ( ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> % self . irc . network ) <EOL> def setTimeout ( ) : <EOL> self . conn . settimeout ( conf . supybot . drivers . poll ( ) ) <EOL> conf . supybot . drivers . poll . addCallback ( setTimeout ) <EOL> setTimeout ( ) <EOL> self . connected = True <EOL> self . resetDelay ( ) <EOL> except socket . error as e : <EOL> if e . args [ <NUM_LIT:0> ] == <NUM_LIT> : <EOL> now = time . time ( ) <EOL> when = now + <NUM_LIT> <EOL> whenS = log . timestamp ( when ) <EOL> drivers . log . debug ( '<STR_LIT>' <EOL> '<STR_LIT>' , whenS ) <EOL> self . writeCheckTime = when <EOL> else : <EOL> drivers . log . connectError ( self . currentServer , e ) <EOL> self . scheduleReconnect ( ) <EOL> return <EOL> self . _instances . append ( self ) <EOL> def _checkAndWriteOrReconnect ( self ) : <EOL> self . writeCheckTime = None <EOL> drivers . log . debug ( '<STR_LIT>' ) <EOL> ( _ , w , _ ) = select . select ( [ ] , [ self . conn ] , [ ] , <NUM_LIT:0> ) <EOL> if w : <EOL> drivers . log . debug ( '<STR_LIT>' ) <EOL> self . connected = True <EOL> self . resetDelay ( ) <EOL> else : <EOL> drivers . log . connectError ( self . currentServer , '<STR_LIT>' ) <EOL> self . reconnect ( ) <EOL> def scheduleReconnect ( self ) : <EOL> when = time . time ( ) + self . getDelay ( ) <EOL> if not world . dying : <EOL> drivers . log . reconnect ( self . irc . network , when ) <EOL> if self . nextReconnectTime : <EOL> drivers . log . error ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> self . nextReconnectTime = when <EOL> def die ( self ) : <EOL> if self in self . _instances : <EOL> self . _instances . remove ( self ) <EOL> self . zombie = True <EOL> if self . nextReconnectTime is not None : <EOL> self . nextReconnectTime = None <EOL> if self . writeCheckTime is not None : <EOL> self . writeCheckTime = None <EOL> drivers . log . die ( self . irc ) <EOL> def _reallyDie ( self ) : <EOL> if self . conn is not None : <EOL> self . conn . close ( ) <EOL> drivers . IrcDriver . die ( self ) <EOL> def name ( self ) : <EOL> return '<STR_LIT>' % ( self . __class__ . __name__ , self . irc ) <EOL> def starttls ( self ) : <EOL> assert '<STR_LIT>' in globals ( ) <EOL> network_config = getattr ( conf . supybot . networks , self . irc . network ) <EOL> certfile = network_config . certfile ( ) <EOL> if not certfile : <EOL> certfile = conf . supybot . protocols . irc . certfile ( ) <EOL> if not certfile : <EOL> certfile = None <EOL> elif not os . path . isfile ( certfile ) : <EOL> drivers . log . warning ( '<STR_LIT>' % <EOL> certfile ) <EOL> certfile = None <EOL> verifyCertificates = conf . supybot . protocols . ssl . verifyCertificates ( ) <EOL> if not verifyCertificates : <EOL> drivers . log . warning ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> try : <EOL> self . conn = utils . net . ssl_wrap_socket ( self . conn , <EOL> logger = drivers . log , hostname = self . server [ <NUM_LIT:0> ] , <EOL> certfile = certfile , <EOL> verify = verifyCertificates , <EOL> trusted_fingerprints = network_config . ssl . serverFingerprints ( ) , <EOL> ca_file = network_config . ssl . authorityCertificate ( ) , <EOL> ) <EOL> except getattr ( ssl , '<STR_LIT>' , None ) as e : <EOL> drivers . log . error ( ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> % ( self . irc . network , e . args [ <NUM_LIT:0> ] ) ) <EOL> raise ssl . SSLError ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> except ssl . SSLError as e : <EOL> drivers . log . error ( ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> % ( self . irc . network , e . args [ <NUM_LIT:1> ] ) ) <EOL> raise ssl . SSLError ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> Driver = SocketDriver </s>
<s> import sys <EOL> import types <EOL> import fnmatch <EOL> import threading <EOL> def universalImport ( * names ) : <EOL> """<STR_LIT>""" <EOL> f = sys . _getframe ( <NUM_LIT:1> ) <EOL> for name in names : <EOL> try : <EOL> ret = __import__ ( name , f . f_globals ) <EOL> except ImportError : <EOL> continue <EOL> else : <EOL> if '<STR_LIT:.>' in name : <EOL> parts = name . split ( '<STR_LIT:.>' ) [ <NUM_LIT:1> : ] <EOL> while parts : <EOL> ret = getattr ( ret , parts [ <NUM_LIT:0> ] ) <EOL> del parts [ <NUM_LIT:0> ] <EOL> return ret <EOL> raise ImportError ( '<STR_LIT:U+002C>' . join ( names ) ) <EOL> def changeFunctionName ( f , name , doc = None ) : <EOL> if doc is None : <EOL> doc = f . __doc__ <EOL> if hasattr ( f , '<STR_LIT>' ) : <EOL> closure = f . __closure__ <EOL> else : <EOL> closure = f . func_closure <EOL> newf = types . FunctionType ( f . __code__ , f . __globals__ , name , <EOL> f . __defaults__ , closure ) <EOL> newf . __doc__ = doc <EOL> return newf <EOL> class Object ( object ) : <EOL> def __ne__ ( self , other ) : <EOL> return not self == other <EOL> class MetaSynchronized ( type ) : <EOL> METHODS = '<STR_LIT>' <EOL> LOCK = '<STR_LIT>' <EOL> def __new__ ( cls , name , bases , dict ) : <EOL> sync = set ( ) <EOL> for base in bases : <EOL> if hasattr ( base , MetaSynchronized . METHODS ) : <EOL> sync . update ( getattr ( base , MetaSynchronized . METHODS ) ) <EOL> if MetaSynchronized . METHODS in dict : <EOL> sync . update ( dict [ MetaSynchronized . METHODS ] ) <EOL> if sync : <EOL> def synchronized ( f ) : <EOL> def g ( self , * args , ** kwargs ) : <EOL> lock = getattr ( self , MetaSynchronized . LOCK ) <EOL> lock . acquire ( ) <EOL> try : <EOL> f ( self , * args , ** kwargs ) <EOL> finally : <EOL> lock . release ( ) <EOL> return changeFunctionName ( g , f . __name__ , f . __doc__ ) <EOL> for attr in sync : <EOL> if attr in dict : <EOL> dict [ attr ] = synchronized ( dict [ attr ] ) <EOL> original__init__ = dict . get ( '<STR_LIT>' ) <EOL> def __init__ ( self , * args , ** kwargs ) : <EOL> if not hasattr ( self , MetaSynchronized . LOCK ) : <EOL> setattr ( self , MetaSynchronized . LOCK , threading . RLock ( ) ) <EOL> if original__init__ : <EOL> original__init__ ( self , * args , ** kwargs ) <EOL> else : <EOL> super ( newclass , self ) . __init__ ( * args , ** kwargs ) <EOL> dict [ '<STR_LIT>' ] = __init__ <EOL> newclass = super ( MetaSynchronized , cls ) . __new__ ( cls , name , bases , dict ) <EOL> return newclass <EOL> Synchronized = MetaSynchronized ( '<STR_LIT>' , ( ) , { } ) <EOL> def glob2re ( g ) : <EOL> return fnmatch . translate ( g ) [ : - <NUM_LIT:7> ] <EOL> _debug_software_name = '<STR_LIT>' <EOL> _debug_software_version = None <EOL> def collect_extra_debug_data ( ) : <EOL> """<STR_LIT>""" <EOL> data = '<STR_LIT>' <EOL> try : <EOL> tb = sys . exc_info ( ) [ <NUM_LIT:2> ] <EOL> stack = [ ] <EOL> while tb : <EOL> stack . append ( tb . tb_frame ) <EOL> tb = tb . tb_next <EOL> finally : <EOL> del tb <EOL> if _debug_software_version : <EOL> data += '<STR_LIT>' % ( _debug_software_name , _debug_software_version ) <EOL> else : <EOL> data += '<STR_LIT>' % _debug_software_name <EOL> data += '<STR_LIT>' <EOL> for frame in stack : <EOL> data += '<STR_LIT>' <EOL> data += ( '<STR_LIT>' % ( frame . f_code . co_name , <EOL> frame . f_code . co_filename , <EOL> frame . f_lineno ) ) <EOL> frame_locals = frame . f_locals <EOL> for inspected in ( '<STR_LIT>' , '<STR_LIT>' ) : <EOL> if inspected in frame_locals : <EOL> if hasattr ( frame_locals [ inspected ] , '<STR_LIT>' ) and frame_locals [ inspected ] . __dict__ : <EOL> for ( key , value ) in frame_locals [ inspected ] . __dict__ . items ( ) : <EOL> frame_locals [ '<STR_LIT>' % ( inspected , key ) ] = value <EOL> for key , value in frame_locals . items ( ) : <EOL> if key == '<STR_LIT>' : <EOL> continue <EOL> data += ( '<STR_LIT>' % key ) <EOL> try : <EOL> data += repr ( value ) + '<STR_LIT:\n>' <EOL> except : <EOL> data += '<STR_LIT>' <EOL> data += '<STR_LIT:\n>' <EOL> data += '<STR_LIT>' <EOL> data += '<STR_LIT>' <EOL> data += '<STR_LIT>' <EOL> data += '<STR_LIT:\n>' <EOL> return data </s>
<s> import sys , os <EOL> extensions = [ ] <EOL> templates_path = [ '<STR_LIT>' ] <EOL> source_suffix = '<STR_LIT>' <EOL> master_doc = '<STR_LIT:index>' <EOL> project = u'<STR_LIT>' <EOL> copyright = u'<STR_LIT>' <EOL> version = '<STR_LIT>' <EOL> release = '<STR_LIT>' <EOL> exclude_patterns = [ '<STR_LIT>' ] <EOL> pygments_style = '<STR_LIT>' <EOL> html_theme = '<STR_LIT>' <EOL> html_static_path = [ '<STR_LIT>' ] <EOL> htmlhelp_basename = '<STR_LIT>' <EOL> latex_elements = { <EOL> } <EOL> latex_documents = [ <EOL> ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , <EOL> u'<STR_LIT>' , '<STR_LIT>' ) , <EOL> ] <EOL> man_pages = [ <EOL> ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , <EOL> [ u'<STR_LIT>' ] , <NUM_LIT:1> ) <EOL> ] <EOL> texinfo_documents = [ <EOL> ( '<STR_LIT:index>' , '<STR_LIT>' , u'<STR_LIT>' , <EOL> u'<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' ) , <EOL> ] </s>
<s> try : <EOL> from django . conf . urls import patterns , url <EOL> except ImportError : <EOL> from django . conf . urls . defaults import patterns , url <EOL> urlpatterns = patterns ( '<STR_LIT>' , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = '<STR_LIT>' ) , <EOL> url ( r'<STR_LIT>' , '<STR_LIT>' , name = '<STR_LIT>' ) , <EOL> ) </s>
<s> """<STR_LIT>""" <EOL> from django . http import * <EOL> from django . core import serializers <EOL> from django . core . exceptions import ValidationError , SuspiciousOperation , ObjectDoesNotExist <EOL> from django . db import IntegrityError , connection , transaction <EOL> from django . shortcuts import render_to_response <EOL> from django . core . urlresolvers import reverse <EOL> from django . core . context_processors import csrf <EOL> from django . contrib . comments . models import Comment <EOL> from django . contrib . comments . forms import CommentForm <EOL> from django . contrib . contenttypes . models import ContentType <EOL> from django . contrib . auth . decorators import login_required , user_passes_test <EOL> from django . contrib . sessions . models import Session <EOL> from django . contrib . sessions . backends . db import SessionStore <EOL> from django . contrib . gis . geos . collections import MultiPolygon <EOL> from django . contrib . gis . geos import GEOSGeometry <EOL> from django . contrib . gis . gdal import * <EOL> from django . contrib . gis . gdal . libgdal import lgdal <EOL> from django . contrib . sites . models import Site <EOL> from django . contrib import humanize <EOL> from django . template import loader , Context as DjangoContext , RequestContext <EOL> from django . utils import simplejson as json , translation <EOL> from django . utils . translation import ugettext as _ , ungettext as _n <EOL> from django . template . defaultfilters import slugify , force_escape <EOL> from django . conf import settings <EOL> from tagging . utils import parse_tag_input <EOL> from tagging . models import Tag , TaggedItem <EOL> from datetime import datetime , time , timedelta <EOL> from decimal import * <EOL> from functools import wraps <EOL> from redistricting . calculators import * <EOL> from redistricting . models import * <EOL> from redistricting . tasks import * <EOL> import random , string , math , types , copy , time , threading , traceback , os <EOL> import commands , sys , tempfile , csv , hashlib , inflect , logging <EOL> import ModestMaps <EOL> from PIL import Image , ImageChops , ImageMath <EOL> import urllib , urllib2 <EOL> from xhtml2pdf . pisa import CreatePDF <EOL> import StringIO <EOL> logger = logging . getLogger ( __name__ ) <EOL> UNASSIGNED_DISTRICT_ID = <NUM_LIT:0> <EOL> def using_unique_session ( u ) : <EOL> """<STR_LIT>""" <EOL> if u . is_anonymous ( ) or u . is_superuser : <EOL> return True <EOL> sessions = Session . objects . all ( ) <EOL> count = <NUM_LIT:0> <EOL> for session in sessions : <EOL> try : <EOL> decoded = session . get_decoded ( ) <EOL> if '<STR_LIT>' in decoded and decoded [ '<STR_LIT>' ] == u . id : <EOL> if '<STR_LIT>' in decoded and decoded [ '<STR_LIT>' ] < datetime . now ( ) : <EOL> Session . objects . filter ( session_key = session . session_key ) . delete ( ) <EOL> else : <EOL> count += <NUM_LIT:1> <EOL> except SuspiciousOperation : <EOL> logger . debug ( "<STR_LIT>" , session . session_key ) <EOL> for session in sessions : <EOL> try : <EOL> decoded = session . get_decoded ( ) <EOL> if '<STR_LIT>' in decoded and decoded [ '<STR_LIT>' ] == u . id : <EOL> websession = SessionStore ( session_key = session . session_key ) <EOL> websession [ '<STR_LIT:count>' ] = count <EOL> websession . save ( ) <EOL> except SuspiciousOperation : <EOL> logger . debug ( "<STR_LIT>" , session . session_key ) <EOL> return ( count <= <NUM_LIT:1> ) <EOL> def unique_session_or_json_redirect ( function ) : <EOL> """<STR_LIT>""" <EOL> def decorator ( request , * args , ** kwargs ) : <EOL> def return_nonunique_session_result ( ) : <EOL> status = { '<STR_LIT:success>' : False } <EOL> status [ '<STR_LIT:message>' ] = _ ( <EOL> "<STR_LIT>" ) <EOL> status [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> if not using_unique_session ( request . user ) : <EOL> return return_nonunique_session_result ( ) <EOL> else : <EOL> return function ( request , * args , ** kwargs ) <EOL> return wraps ( function ) ( decorator ) <EOL> def is_session_available ( req ) : <EOL> """<STR_LIT>""" <EOL> if req . user . is_superuser or req . user . is_staff : <EOL> return True <EOL> sessions = Session . objects . filter ( expire_date__gt = datetime . now ( ) ) <EOL> count = <NUM_LIT:0> <EOL> for session in sessions : <EOL> try : <EOL> decoded = session . get_decoded ( ) <EOL> if ( not req . user . is_anonymous ( ) ) and '<STR_LIT>' in decoded and decoded [ '<STR_LIT>' ] > datetime . now ( ) : <EOL> count += <NUM_LIT:1> <EOL> except SuspiciousOperation : <EOL> logger . debug ( "<STR_LIT>" , session . session_key ) <EOL> avail = count < settings . CONCURRENT_SESSIONS <EOL> req . session [ '<STR_LIT>' ] = avail <EOL> return avail <EOL> def note_session_activity ( req ) : <EOL> """<STR_LIT>""" <EOL> window = timedelta ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , settings . SESSION_TIMEOUT ) <EOL> req . session [ '<STR_LIT>' ] = datetime . now ( ) + window <EOL> @ login_required <EOL> def unloadplan ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> status = { '<STR_LIT:success>' : False } <EOL> ps = Plan . objects . filter ( pk = planid ) <EOL> if len ( ps ) > <NUM_LIT:0> : <EOL> p = ps [ <NUM_LIT:0> ] <EOL> if not can_copy ( request . user , p ) : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) % { '<STR_LIT:user>' : request . user . username } <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> if settings . MAX_UNDOS_AFTER_EDIT > <NUM_LIT:0> : <EOL> p . purge_beyond_nth_step ( settings . MAX_UNDOS_AFTER_EDIT ) <EOL> status [ '<STR_LIT:success>' ] = True <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> @ login_required <EOL> @ unique_session_or_json_redirect <EOL> def copyplan ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> if not is_plan_ready ( planid ) : <EOL> return HttpResponseRedirect ( '<STR_LIT:/>' ) <EOL> status = { '<STR_LIT:success>' : False } <EOL> p = Plan . objects . get ( pk = planid ) <EOL> if not can_copy ( request . user , p ) : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" "<STR_LIT>" % { '<STR_LIT:username>' : request . user . username } ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> newname = p . name + "<STR_LIT:U+0020>" + str ( random . random ( ) ) <EOL> if ( request . method == "<STR_LIT:POST>" ) : <EOL> newname = request . POST [ "<STR_LIT:name>" ] [ <NUM_LIT:0> : <NUM_LIT:200> ] <EOL> shared = request . POST . get ( "<STR_LIT>" , False ) <EOL> plan_copy = Plan . objects . filter ( name = newname , owner = request . user , legislative_body = p . legislative_body ) <EOL> if len ( plan_copy ) > <NUM_LIT:0> : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> plan_copy = Plan ( name = newname , owner = request . user , is_shared = shared , legislative_body = p . legislative_body , processing_state = ProcessingState . READY ) <EOL> plan_copy . create_unassigned = False <EOL> plan_copy . save ( ) <EOL> districts = p . get_districts_at_version ( p . version , include_geom = True ) <EOL> for district in districts : <EOL> district_copy = copy . copy ( district ) <EOL> district_copy . id = None <EOL> district_copy . version = <NUM_LIT:0> <EOL> district_copy . is_locked = False <EOL> district_copy . plan = plan_copy <EOL> try : <EOL> district_copy . save ( ) <EOL> except Exception as inst : <EOL> status [ "<STR_LIT:message>" ] = _ ( "<STR_LIT>" ) <EOL> status [ "<STR_LIT>" ] = inst . message <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> district_copy . clone_relations_from ( district ) <EOL> data = serializers . serialize ( "<STR_LIT>" , [ plan_copy ] ) <EOL> return HttpResponse ( data , mimetype = '<STR_LIT:application/json>' ) <EOL> @ login_required <EOL> @ unique_session_or_json_redirect <EOL> def scoreplan ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> status = { '<STR_LIT:success>' : False } <EOL> plan = Plan . objects . get ( pk = planid ) <EOL> criterion = ValidationCriteria . objects . filter ( legislative_body = plan . legislative_body ) <EOL> status [ '<STR_LIT:success>' ] = True <EOL> for criteria in criterion : <EOL> try : <EOL> score = ComputedPlanScore . compute ( criteria . function , plan ) <EOL> except : <EOL> logger . debug ( traceback . format_exc ( ) ) <EOL> if not score or not score [ '<STR_LIT:value>' ] : <EOL> status [ '<STR_LIT:success>' ] = False <EOL> status [ '<STR_LIT:message>' ] = '<STR_LIT>' % ( criteria . get_short_label ( ) , criteria . get_long_description ( ) or criteria . function . get_long_description ( ) ) <EOL> break <EOL> if status [ '<STR_LIT:success>' ] : <EOL> status [ '<STR_LIT:success>' ] = True <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> plan . is_valid = True <EOL> plan . save ( ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> def get_user_info ( user ) : <EOL> """<STR_LIT>""" <EOL> if user . is_anonymous ( ) : <EOL> return None <EOL> profile = user . get_profile ( ) <EOL> return { <EOL> '<STR_LIT:username>' : user . username , <EOL> '<STR_LIT:email>' : user . email , <EOL> '<STR_LIT>' : profile . pass_hint , <EOL> '<STR_LIT>' : user . first_name , <EOL> '<STR_LIT>' : user . last_name , <EOL> '<STR_LIT>' : profile . organization , <EOL> '<STR_LIT:id>' : user . id <EOL> } <EOL> def commonplan ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> plan = Plan . objects . filter ( id = planid ) <EOL> if plan . count ( ) == <NUM_LIT:1> : <EOL> plan = plan [ <NUM_LIT:0> ] <EOL> plan . edited = getutc ( plan . edited ) <EOL> levels = plan . legislative_body . get_geolevels ( ) <EOL> districts = plan . get_districts_at_version ( plan . version , include_geom = False ) <EOL> editable = can_edit ( request . user , plan ) <EOL> default_demo = plan . legislative_body . get_default_subject ( ) <EOL> max_dists = plan . legislative_body . max_districts <EOL> body_member_short_label = plan . legislative_body . get_short_label ( ) <EOL> body_member_long_label = plan . legislative_body . get_label ( ) <EOL> body_members = plan . legislative_body . get_members_label ( ) <EOL> reporting_template = '<STR_LIT>' % plan . legislative_body . name if not plan . is_community ( ) else None <EOL> index = body_member_short_label . find ( '<STR_LIT>' ) <EOL> if index >= <NUM_LIT:0> : <EOL> body_member_short_label = body_member_short_label [ <NUM_LIT:0> : index ] <EOL> index = body_member_long_label . find ( '<STR_LIT>' ) <EOL> if index >= <NUM_LIT:0> : <EOL> body_member_long_label = body_member_long_label [ <NUM_LIT:0> : index ] <EOL> if not editable and not can_view ( request . user , plan ) : <EOL> plan = { } <EOL> tags = [ ] <EOL> calculator_reports = [ ] <EOL> else : <EOL> tags = Tag . objects . filter ( name__startswith = '<STR_LIT>' ) . order_by ( '<STR_LIT:id>' ) . values_list ( '<STR_LIT:name>' , flat = True ) <EOL> tags = map ( lambda x : x [ <NUM_LIT:5> : ] , tags ) <EOL> calculator_reports = [ ] <EOL> if settings . REPORTS_ENABLED == '<STR_LIT>' : <EOL> report_displays = ScoreDisplay . objects . filter ( name = "<STR_LIT>" % plan . legislative_body . name ) <EOL> if len ( report_displays ) > <NUM_LIT:0> : <EOL> calculator_reports = map ( lambda p : { <EOL> '<STR_LIT:title>' : p . __unicode__ ( ) , <EOL> '<STR_LIT>' : map ( lambda f : { <EOL> '<STR_LIT:label>' : f . get_label ( ) , <EOL> '<STR_LIT:id>' : f . id <EOL> } , p . score_functions . all ( ) . filter ( selectable_bodies = plan . legislative_body ) ) <EOL> } , report_displays [ <NUM_LIT:0> ] . scorepanel_set . all ( ) . order_by ( '<STR_LIT>' ) ) <EOL> else : <EOL> plan = { } <EOL> levels = list ( ) <EOL> districts = { } <EOL> editable = False <EOL> default_demo = None <EOL> max_dists = <NUM_LIT:0> <EOL> body_member_short_label = '<STR_LIT>' <EOL> body_member_long_label = _ ( '<STR_LIT>' ) + '<STR_LIT:U+0020>' <EOL> body_members = _n ( '<STR_LIT>' , '<STR_LIT>' , <NUM_LIT:2> ) <EOL> reporting_template = None <EOL> tags = [ ] <EOL> calculator_reports = [ ] <EOL> demos = Subject . objects . all ( ) . order_by ( '<STR_LIT>' ) [ <NUM_LIT:0> : <NUM_LIT:3> ] <EOL> layers = [ ] <EOL> snaplayers = [ ] <EOL> if len ( levels ) > <NUM_LIT:0> : <EOL> study_area_extent = list ( levels [ <NUM_LIT:0> ] . geounit_set . extent ( field_name = '<STR_LIT>' ) ) <EOL> else : <EOL> for lb in LegislativeBody . objects . all ( ) : <EOL> biglevel = lb . get_geolevels ( ) [ <NUM_LIT:0> ] <EOL> if biglevel . geounit_set . count ( ) > <NUM_LIT:0> : <EOL> study_area_extent = biglevel . geounit_set . extent ( field_name = '<STR_LIT>' ) <EOL> break <EOL> for level in levels : <EOL> snaplayers . append ( { <EOL> '<STR_LIT>' : level . id , <EOL> '<STR_LIT>' : level . name , <EOL> '<STR_LIT>' : '<STR_LIT>' + level . name , <EOL> '<STR_LIT>' : level . get_long_description ( ) , <EOL> '<STR_LIT>' : level . min_zoom <EOL> } ) <EOL> default_selected = False <EOL> for demo in demos : <EOL> isdefault = str ( ( not default_demo is None ) and ( demo . id == default_demo . id ) ) . lower ( ) <EOL> if isdefault == '<STR_LIT:true>' : <EOL> default_selected = True <EOL> layers . append ( { <EOL> '<STR_LIT:id>' : demo . id , <EOL> '<STR_LIT:text>' : demo . get_short_label ( ) , <EOL> '<STR_LIT:value>' : demo . name , <EOL> '<STR_LIT>' : isdefault , <EOL> '<STR_LIT>' : str ( demo . is_displayed ) . lower ( ) <EOL> } ) <EOL> if default_demo and not default_selected : <EOL> layers . insert ( <NUM_LIT:0> , { <EOL> '<STR_LIT:id>' : default_demo . id , <EOL> '<STR_LIT:text>' : default_demo . get_short_label ( ) , <EOL> '<STR_LIT:value>' : default_demo . name , <EOL> '<STR_LIT>' : str ( True ) . lower ( ) , <EOL> '<STR_LIT>' : str ( default_demo . is_displayed ) . lower ( ) <EOL> } ) <EOL> if '<STR_LIT>' in settings . __members__ : <EOL> mapserver_protocol = settings . MAP_SERVER_PROTOCOL <EOL> else : <EOL> mapserver_protocol = '<STR_LIT>' <EOL> short_label = body_member_short_label . strip ( ) . lower ( ) <EOL> long_label = body_member_long_label . strip ( ) . lower ( ) <EOL> has_regions = Region . objects . all ( ) . count ( ) > <NUM_LIT:1> <EOL> bodies = LegislativeBody . objects . all ( ) . order_by ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> l_bodies = [ b for b in bodies if b in [ sd . legislative_body for sd in ScoreDisplay . objects . filter ( is_page = True ) ] ] <EOL> try : <EOL> loader . get_template ( reporting_template ) <EOL> except : <EOL> reporting_template = None <EOL> return RequestContext ( request , { <EOL> '<STR_LIT>' : bodies , <EOL> '<STR_LIT>' : has_regions , <EOL> '<STR_LIT>' : l_bodies , <EOL> '<STR_LIT>' : plan , <EOL> '<STR_LIT>' : districts , <EOL> '<STR_LIT>' : settings . MAP_SERVER , <EOL> '<STR_LIT>' : mapserver_protocol , <EOL> '<STR_LIT>' : settings . BASE_MAPS , <EOL> '<STR_LIT>' : settings . MAP_SERVER_NS , <EOL> '<STR_LIT>' : settings . MAP_SERVER_NSHREF , <EOL> '<STR_LIT>' : settings . FEATURE_LIMIT , <EOL> '<STR_LIT>' : settings . ADJACENCY , <EOL> '<STR_LIT>' : settings . CONVEX_CHOROPLETH , <EOL> '<STR_LIT>' : layers , <EOL> '<STR_LIT>' : snaplayers , <EOL> '<STR_LIT>' : UNASSIGNED_DISTRICT_ID , <EOL> '<STR_LIT>' : request . user . username != '<STR_LIT>' and request . user . username != '<STR_LIT>' , <EOL> '<STR_LIT>' : settings . DEBUG and request . user . is_staff , <EOL> '<STR_LIT>' : get_user_info ( request . user ) , <EOL> '<STR_LIT>' : editable , <EOL> '<STR_LIT>' : max_dists + <NUM_LIT:1> , <EOL> '<STR_LIT>' : settings . GA_ACCOUNT , <EOL> '<STR_LIT>' : settings . GA_DOMAIN , <EOL> '<STR_LIT>' : short_label , <EOL> '<STR_LIT>' : long_label , <EOL> '<STR_LIT>' : body_members , <EOL> '<STR_LIT>' : reporting_template , <EOL> '<STR_LIT>' : study_area_extent , <EOL> '<STR_LIT>' : len ( ScoreDisplay . objects . filter ( is_page = True ) ) > <NUM_LIT:0> , <EOL> '<STR_LIT>' : json . dumps ( calculator_reports ) , <EOL> '<STR_LIT>' : ( '<STR_LIT>' in settings . __members__ ) , <EOL> '<STR_LIT>' : tags , <EOL> '<STR_LIT>' : Site . objects . get_current ( ) , <EOL> '<STR_LIT>' : _ ( "<STR_LIT>" ) if ( plan and plan . is_community ( ) ) else _ ( "<STR_LIT>" ) , <EOL> '<STR_LIT>' : translation . get_language ( ) , <EOL> '<STR_LIT>' : settings . LANGUAGES <EOL> } ) <EOL> def is_plan_ready ( planid ) : <EOL> """<STR_LIT>""" <EOL> planid = int ( planid ) <EOL> return planid == <NUM_LIT:0> or len ( Plan . objects . filter ( id = planid , processing_state = ProcessingState . READY ) ) > <NUM_LIT:0> <EOL> @ user_passes_test ( using_unique_session ) <EOL> def viewplan ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> if not is_session_available ( request ) or not is_plan_ready ( planid ) : <EOL> return HttpResponseRedirect ( '<STR_LIT:/>' ) <EOL> if not request . user . is_anonymous ( ) and ( int ( planid ) == <NUM_LIT:0> ) and ( settings . MAX_UNDOS_AFTER_EDIT > <NUM_LIT:0> ) : <EOL> for p in Plan . objects . filter ( owner = request . user ) : <EOL> p . purge_beyond_nth_step ( settings . MAX_UNDOS_AFTER_EDIT ) <EOL> return render_to_response ( '<STR_LIT>' , commonplan ( request , planid ) ) <EOL> @ user_passes_test ( using_unique_session ) <EOL> def editplan ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> if request . user . is_anonymous ( ) or not is_session_available ( request ) or not is_plan_ready ( planid ) : <EOL> return HttpResponseRedirect ( '<STR_LIT:/>' ) <EOL> cfg = commonplan ( request , planid ) <EOL> if cfg [ '<STR_LIT>' ] == False : <EOL> return HttpResponseRedirect ( '<STR_LIT>' % planid ) <EOL> plan = Plan . objects . get ( id = planid , owner = request . user ) <EOL> cfg [ '<STR_LIT>' ] = len ( cfg [ '<STR_LIT>' ] ) > plan . legislative_body . max_districts <EOL> cfg [ '<STR_LIT>' ] = plan . get_available_districts ( ) <EOL> if settings . MAX_UNDOS_AFTER_EDIT > <NUM_LIT:0> : <EOL> plan . purge_beyond_nth_step ( settings . MAX_UNDOS_AFTER_EDIT ) <EOL> return render_to_response ( '<STR_LIT>' , cfg ) <EOL> @ user_passes_test ( using_unique_session ) <EOL> def printplan ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> if not is_session_available ( request ) : <EOL> return HttpResponseRedirect ( '<STR_LIT:/>' ) <EOL> cfg = commonplan ( request , planid ) <EOL> sha = hashlib . sha1 ( ) <EOL> sha . update ( str ( planid ) + str ( datetime . now ( ) ) ) <EOL> cfg [ '<STR_LIT>' ] = '<STR_LIT>' % sha . hexdigest ( ) <EOL> cfg [ '<STR_LIT>' ] = '<STR_LIT>' % request . META [ '<STR_LIT>' ] <EOL> if request . method == '<STR_LIT:POST>' : <EOL> if not '<STR_LIT>' in request . REQUEST or not '<STR_LIT>' in request . REQUEST or not '<STR_LIT>' in request . REQUEST or not '<STR_LIT>' in request . REQUEST or not '<STR_LIT>' in request . REQUEST : <EOL> logger . warning ( '<STR_LIT>' ) <EOL> return HttpResponseRedirect ( '<STR_LIT>' ) <EOL> height = <NUM_LIT> * <NUM_LIT:2> <EOL> if '<STR_LIT>' in request . REQUEST : <EOL> height = int ( request . REQUEST [ '<STR_LIT>' ] ) * <NUM_LIT:2> <EOL> width = <NUM_LIT> * <NUM_LIT:2> <EOL> if '<STR_LIT:width>' in request . REQUEST : <EOL> width = int ( request . REQUEST [ '<STR_LIT:width>' ] ) * <NUM_LIT:2> <EOL> opacity = <NUM_LIT> <EOL> if '<STR_LIT>' in request . REQUEST : <EOL> opacity = float ( request . REQUEST [ '<STR_LIT>' ] ) <EOL> full_legend = json . loads ( request . REQUEST [ '<STR_LIT>' ] ) <EOL> cfg [ '<STR_LIT>' ] = request . REQUEST [ '<STR_LIT>' ] <EOL> cfg [ '<STR_LIT>' ] = request . REQUEST [ '<STR_LIT>' ] <EOL> cfg [ '<STR_LIT>' ] = request . REQUEST [ '<STR_LIT>' ] <EOL> cfg [ '<STR_LIT>' ] = request . REQUEST [ '<STR_LIT>' ] <EOL> cfg [ '<STR_LIT>' ] = full_legend [ '<STR_LIT>' ] <EOL> cfg [ '<STR_LIT>' ] = full_legend [ '<STR_LIT>' ] <EOL> cfg [ '<STR_LIT>' ] = full_legend [ '<STR_LIT>' ] <EOL> cfg [ '<STR_LIT>' ] = full_legend [ '<STR_LIT>' ] <EOL> cfg [ '<STR_LIT>' ] = Plan . objects . get ( id = int ( request . REQUEST [ '<STR_LIT>' ] ) ) <EOL> cfg [ '<STR_LIT>' ] = datetime . now ( ) <EOL> bbox = request . REQUEST [ '<STR_LIT>' ] . split ( '<STR_LIT:U+002C>' ) <EOL> pt1 = Point ( float ( bbox [ <NUM_LIT:0> ] ) , float ( bbox [ <NUM_LIT:1> ] ) , srid = <NUM_LIT> ) <EOL> pt1 . transform ( SpatialReference ( '<STR_LIT>' ) ) <EOL> ll = ModestMaps . Geo . Location ( pt1 . y , pt1 . x ) <EOL> pt2 = Point ( float ( bbox [ <NUM_LIT:2> ] ) , float ( bbox [ <NUM_LIT:3> ] ) , srid = <NUM_LIT> ) <EOL> pt2 . transform ( SpatialReference ( '<STR_LIT>' ) ) <EOL> ur = ModestMaps . Geo . Location ( pt2 . y , pt2 . x ) <EOL> dims = ModestMaps . Core . Point ( width , height ) <EOL> provider = ModestMaps . OpenStreetMap . Provider ( ) <EOL> basemap = ModestMaps . mapByExtent ( provider , ll , ur , dims ) <EOL> fullImg = basemap . draw ( ) <EOL> provider = ModestMaps . WMS . Provider ( cfg [ '<STR_LIT>' ] , { <EOL> '<STR_LIT>' : cfg [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : '<STR_LIT:true>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : <NUM_LIT> , <EOL> '<STR_LIT>' : <NUM_LIT> <EOL> } ) <EOL> overlayImg = ModestMaps . mapByExtent ( provider , ll , ur , dims ) . draw ( ) <EOL> maskImg = ImageChops . invert ( overlayImg ) <EOL> provider = ModestMaps . WMS . Provider ( cfg [ '<STR_LIT>' ] , { <EOL> '<STR_LIT>' : cfg [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : '<STR_LIT:false>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : request . REQUEST [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : <NUM_LIT> , <EOL> '<STR_LIT>' : <NUM_LIT> <EOL> } ) <EOL> overlayImg = Image . blend ( overlayImg , ModestMaps . mapByExtent ( provider , ll , ur , dims ) . draw ( ) , <NUM_LIT:0.5> ) <EOL> fullImg = Image . composite ( fullImg , Image . blend ( fullImg , overlayImg , opacity ) , maskImg ) <EOL> provider = ModestMaps . WMS . Provider ( cfg [ '<STR_LIT>' ] , { <EOL> '<STR_LIT>' : cfg [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : '<STR_LIT:true>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : request . REQUEST [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : <NUM_LIT> , <EOL> '<STR_LIT>' : <NUM_LIT> <EOL> } ) <EOL> overlayImg = ModestMaps . mapByExtent ( provider , ll , ur , dims ) . draw ( ) <EOL> maskImg = ImageChops . invert ( overlayImg ) <EOL> fullImg = Image . composite ( fullImg , Image . blend ( fullImg , overlayImg , opacity ) , maskImg ) <EOL> fullImg . save ( settings . WEB_TEMP + ( '<STR_LIT>' % sha . hexdigest ( ) ) , '<STR_LIT>' , quality = <NUM_LIT:100> ) <EOL> t = loader . get_template ( '<STR_LIT>' ) <EOL> page = t . render ( DjangoContext ( cfg ) ) <EOL> result = StringIO . StringIO ( ) <EOL> CreatePDF ( page , result , show_error_as_pdf = True ) <EOL> response = HttpResponse ( result . getvalue ( ) , mimetype = '<STR_LIT>' ) <EOL> response [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> return response <EOL> else : <EOL> return HttpResponseRedirect ( '<STR_LIT>' ) <EOL> @ login_required <EOL> @ unique_session_or_json_redirect <EOL> def createplan ( request ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> status = { '<STR_LIT:success>' : False } <EOL> if request . method == "<STR_LIT:POST>" : <EOL> name = request . POST [ '<STR_LIT:name>' ] [ <NUM_LIT:0> : <NUM_LIT:200> ] <EOL> body = LegislativeBody . objects . get ( id = int ( request . POST [ '<STR_LIT>' ] ) ) <EOL> plan = Plan ( name = name , owner = request . user , legislative_body = body , processing_state = ProcessingState . READY ) <EOL> try : <EOL> plan . save ( ) <EOL> status = serializers . serialize ( "<STR_LIT>" , [ plan ] ) <EOL> except : <EOL> status = { '<STR_LIT:success>' : False , '<STR_LIT:message>' : _ ( "<STR_LIT>" ) } <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> @ unique_session_or_json_redirect <EOL> def uploadfile ( request ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> if request . user . is_anonymous ( ) : <EOL> return HttpResponseRedirect ( '<STR_LIT:/>' ) <EOL> status = commonplan ( request , <NUM_LIT:0> ) <EOL> status [ '<STR_LIT>' ] = True <EOL> status [ '<STR_LIT>' ] = True <EOL> index_file = request . FILES . get ( '<STR_LIT>' , False ) <EOL> if not index_file : <EOL> status [ '<STR_LIT>' ] = False <EOL> return render_to_response ( '<STR_LIT>' , status ) <EOL> else : <EOL> filename = index_file . name <EOL> if index_file . size > settings . MAX_UPLOAD_SIZE : <EOL> logger . error ( '<STR_LIT>' ) <EOL> status [ '<STR_LIT>' ] = False <EOL> return render_to_response ( '<STR_LIT>' , status ) <EOL> if not filename . endswith ( ( '<STR_LIT>' , '<STR_LIT>' ) ) : <EOL> logger . error ( '<STR_LIT>' ) <EOL> status [ '<STR_LIT>' ] = False <EOL> elif request . POST [ '<STR_LIT>' ] == '<STR_LIT>' : <EOL> logger . error ( '<STR_LIT>' ) <EOL> status [ '<STR_LIT>' ] = False <EOL> else : <EOL> try : <EOL> dest = tempfile . NamedTemporaryFile ( mode = '<STR_LIT>' , delete = False ) <EOL> for chunk in request . FILES [ '<STR_LIT>' ] . chunks ( ) : <EOL> dest . write ( chunk ) <EOL> dest . close ( ) <EOL> if request . FILES [ '<STR_LIT>' ] . name . endswith ( '<STR_LIT>' ) : <EOL> os . rename ( dest . name , '<STR_LIT>' % ( dest . name , '<STR_LIT>' ) ) <EOL> filename = '<STR_LIT>' % ( dest . name , '<STR_LIT>' ) <EOL> else : <EOL> filename = dest . name <EOL> except Exception as ex : <EOL> logger . error ( '<STR_LIT>' ) <EOL> logger . error ( '<STR_LIT>' , ex ) <EOL> status [ '<STR_LIT>' ] = False <EOL> return render_to_response ( '<STR_LIT>' , status ) <EOL> DistrictIndexFile . index2plan . delay ( request . POST [ '<STR_LIT>' ] , request . POST [ '<STR_LIT>' ] , filename , owner = request . user , template = False , purge = True , email = request . POST [ '<STR_LIT>' ] , language = translation . get_language ( ) ) <EOL> return render_to_response ( '<STR_LIT>' , status ) <EOL> def generate_report_hash ( qdict ) : <EOL> """<STR_LIT>""" <EOL> params = qdict . get ( '<STR_LIT>' , '<STR_LIT:U+0020>' ) + qdict . get ( '<STR_LIT>' , '<STR_LIT:U+0020>' ) + qdict . get ( '<STR_LIT>' , '<STR_LIT:U+0020>' ) + qdict . get ( '<STR_LIT>' , '<STR_LIT:U+0020>' ) + qdict . get ( '<STR_LIT>' , '<STR_LIT>' ) + qdict . get ( '<STR_LIT>' , '<STR_LIT:U+0020>' ) + qdict . get ( '<STR_LIT>' , '<STR_LIT:U+0020>' ) + qdict . get ( '<STR_LIT>' , '<STR_LIT:U+0020>' ) + qdict . get ( '<STR_LIT>' , '<STR_LIT:U+0020>' ) <EOL> sha = hashlib . sha1 ( ) <EOL> sha . update ( params ) <EOL> return sha . hexdigest ( ) <EOL> @ unique_session_or_json_redirect <EOL> def getreport ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> status = { '<STR_LIT:success>' : False } <EOL> try : <EOL> plan = Plan . objects . get ( pk = planid ) <EOL> except : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> if not can_view ( request . user , plan ) : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> if not settings . REPORTS_ENABLED is None : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> if request . method != '<STR_LIT:POST>' : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> stamp = request . POST . get ( '<STR_LIT>' , generate_report_hash ( request . POST ) ) <EOL> rptstatus = PlanReport . checkreport ( planid , stamp ) <EOL> if rptstatus == '<STR_LIT>' : <EOL> status = { <EOL> '<STR_LIT:success>' : True , <EOL> '<STR_LIT:url>' : PlanReport . getreport ( planid , stamp ) , <EOL> '<STR_LIT>' : <NUM_LIT:0> , <EOL> '<STR_LIT:message>' : _ ( '<STR_LIT>' ) , <EOL> '<STR_LIT>' : stamp <EOL> } <EOL> elif rptstatus == '<STR_LIT>' : <EOL> status = { <EOL> '<STR_LIT:success>' : True , <EOL> '<STR_LIT:url>' : reverse ( getreport , args = [ planid ] ) , <EOL> '<STR_LIT>' : <NUM_LIT:10> , <EOL> '<STR_LIT:message>' : _ ( '<STR_LIT>' ) , <EOL> '<STR_LIT>' : stamp <EOL> } <EOL> elif rptstatus == '<STR_LIT>' : <EOL> status = { <EOL> '<STR_LIT:success>' : True , <EOL> '<STR_LIT:url>' : reverse ( getreport , args = [ planid ] ) , <EOL> '<STR_LIT>' : <NUM_LIT:10> , <EOL> '<STR_LIT:message>' : _ ( '<STR_LIT>' ) , <EOL> '<STR_LIT>' : stamp <EOL> } <EOL> req = { <EOL> '<STR_LIT>' : request . POST . get ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> '<STR_LIT>' : request . POST . get ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> '<STR_LIT>' : request . POST . getlist ( '<STR_LIT>' ) , <EOL> '<STR_LIT>' : request . POST . get ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> '<STR_LIT>' : request . POST . get ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> '<STR_LIT>' : request . POST . get ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> '<STR_LIT>' : request . POST . get ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> '<STR_LIT>' : request . POST . get ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> '<STR_LIT>' : request . POST . get ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> } <EOL> PlanReport . markpending ( planid , stamp ) <EOL> PlanReport . createreport . delay ( planid , stamp , req , language = translation . get_language ( ) ) <EOL> else : <EOL> status [ '<STR_LIT:message>' ] = _ ( <EOL> '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> @ unique_session_or_json_redirect <EOL> def getcalculatorreport ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> status = { '<STR_LIT:success>' : False } <EOL> try : <EOL> plan = Plan . objects . get ( pk = planid ) <EOL> except : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> if not can_view ( request . user , plan ) : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> if request . method != '<STR_LIT:POST>' : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> function_ids = request . POST . get ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> sha = hashlib . sha1 ( ) <EOL> sha . update ( function_ids ) <EOL> stamp = request . POST . get ( '<STR_LIT>' , sha . hexdigest ( ) ) <EOL> rptstatus = CalculatorReport . checkreport ( planid , stamp ) <EOL> if rptstatus == '<STR_LIT>' : <EOL> status = { <EOL> '<STR_LIT:success>' : True , <EOL> '<STR_LIT:url>' : CalculatorReport . getreport ( planid , stamp ) , <EOL> '<STR_LIT>' : <NUM_LIT:0> , <EOL> '<STR_LIT:message>' : _ ( '<STR_LIT>' ) , <EOL> '<STR_LIT>' : stamp <EOL> } <EOL> elif rptstatus == '<STR_LIT>' : <EOL> status = { <EOL> '<STR_LIT:success>' : True , <EOL> '<STR_LIT:url>' : reverse ( getcalculatorreport , args = [ planid ] ) , <EOL> '<STR_LIT>' : <NUM_LIT:5> , <EOL> '<STR_LIT:message>' : _ ( '<STR_LIT>' ) , <EOL> '<STR_LIT>' : stamp <EOL> } <EOL> elif rptstatus == '<STR_LIT>' : <EOL> status = { <EOL> '<STR_LIT:success>' : True , <EOL> '<STR_LIT:url>' : reverse ( getcalculatorreport , args = [ planid ] ) , <EOL> '<STR_LIT>' : <NUM_LIT:5> , <EOL> '<STR_LIT:message>' : _ ( '<STR_LIT>' ) , <EOL> '<STR_LIT>' : stamp <EOL> } <EOL> req = { '<STR_LIT>' : function_ids } <EOL> CalculatorReport . markpending ( planid , stamp ) <EOL> CalculatorReport . createcalculatorreport . delay ( planid , stamp , req , language = translation . get_language ( ) ) <EOL> else : <EOL> status [ '<STR_LIT:message>' ] = _ ( <EOL> '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> @ login_required <EOL> @ unique_session_or_json_redirect <EOL> def newdistrict ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> status = { '<STR_LIT:success>' : False } <EOL> if len ( request . REQUEST . items ( ) ) >= <NUM_LIT:3> : <EOL> plan = Plan . objects . get ( pk = planid , owner = request . user ) <EOL> if '<STR_LIT>' in request . REQUEST : <EOL> geolevel = request . REQUEST [ '<STR_LIT>' ] <EOL> else : <EOL> geolevel = None <EOL> if '<STR_LIT>' in request . REQUEST : <EOL> geounit_ids = string . split ( request . REQUEST [ '<STR_LIT>' ] , '<STR_LIT:|>' ) <EOL> else : <EOL> geounit_ids = None <EOL> if '<STR_LIT>' in request . REQUEST : <EOL> district_id = int ( request . REQUEST [ '<STR_LIT>' ] ) <EOL> else : <EOL> district_id = None <EOL> if '<STR_LIT>' in request . REQUEST : <EOL> district_short = request . REQUEST [ '<STR_LIT>' ] [ <NUM_LIT:0> : <NUM_LIT:10> ] <EOL> elif not district_id is None : <EOL> district_short = plan . legislative_body . get_short_label ( ) % { '<STR_LIT>' : district_id } <EOL> else : <EOL> district_short = None <EOL> if '<STR_LIT>' in request . REQUEST : <EOL> district_long = request . REQUEST [ '<STR_LIT>' ] [ <NUM_LIT:0> : <NUM_LIT> ] <EOL> elif not district_id is None : <EOL> district_long = plan . legislative_body . get_label ( ) % { '<STR_LIT>' : district_id } <EOL> else : <EOL> district_long = None <EOL> if '<STR_LIT:version>' in request . REQUEST : <EOL> version = request . REQUEST [ '<STR_LIT:version>' ] <EOL> else : <EOL> version = plan . version <EOL> if geolevel and geounit_ids and district_id : <EOL> try : <EOL> fixed = plan . add_geounits ( ( district_id , district_short , district_long , ) , geounit_ids , geolevel , version ) <EOL> district = plan . district_set . filter ( district_id = district_id , short_label = district_short , long_label = district_long ) [ <NUM_LIT:0> ] <EOL> if plan . legislative_body . multi_members_allowed : <EOL> district . num_members = plan . legislative_body . min_multi_district_members <EOL> district . save ( ) <EOL> ct = ContentType . objects . get ( app_label = '<STR_LIT>' , model = '<STR_LIT>' ) <EOL> if '<STR_LIT>' in request . POST and request . POST [ '<STR_LIT>' ] != '<STR_LIT>' : <EOL> comment = Comment ( <EOL> object_pk = district . id , <EOL> content_type = ct , <EOL> site_id = Site . objects . get_current ( ) . id , <EOL> user_name = request . user . username , <EOL> user_email = request . user . email , <EOL> comment = request . POST [ '<STR_LIT>' ] ) <EOL> comment . save ( ) <EOL> if len ( request . REQUEST . getlist ( '<STR_LIT>' ) ) > <NUM_LIT:0> : <EOL> strtags = request . REQUEST . getlist ( '<STR_LIT>' ) <EOL> for strtag in strtags : <EOL> if strtag == '<STR_LIT>' : <EOL> continue <EOL> if strtag . count ( '<STR_LIT:U+0020>' ) > <NUM_LIT:0> : <EOL> strtag = '<STR_LIT>' % strtag <EOL> else : <EOL> strtag = '<STR_LIT>' % strtag <EOL> Tag . objects . add_tag ( district , strtag ) <EOL> status [ '<STR_LIT:success>' ] = True <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> plan = Plan . objects . get ( pk = planid , owner = request . user ) <EOL> status [ '<STR_LIT>' ] = getutc ( plan . edited ) . isoformat ( ) <EOL> status [ '<STR_LIT>' ] = district_id <EOL> status [ '<STR_LIT:version>' ] = plan . version <EOL> except ValidationError : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> except Exception , ex : <EOL> logger . warn ( '<STR_LIT>' ) <EOL> logger . debug ( '<STR_LIT>' , ex ) <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> else : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> @ login_required <EOL> @ unique_session_or_json_redirect <EOL> @ transaction . commit_manually <EOL> def add_districts_to_plan ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> status = { '<STR_LIT:success>' : False } <EOL> try : <EOL> plan = Plan . objects . get ( pk = planid ) <EOL> except : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> if not can_edit ( request . user , plan ) : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> district_list = request . POST . getlist ( '<STR_LIT>' ) <EOL> if len ( district_list ) == <NUM_LIT:0> : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> else : <EOL> districts = District . objects . filter ( id__in = district_list ) <EOL> version = int ( request . POST . get ( '<STR_LIT:version>' , None ) ) <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' '<STR_LIT>' ) % { '<STR_LIT>' : len ( districts ) } <EOL> allowed_districts = plan . get_available_districts ( version = version ) <EOL> if len ( districts ) > allowed_districts : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' '<STR_LIT>' ) % { '<STR_LIT>' : allowed_districts } <EOL> try : <EOL> results = plan . paste_districts ( districts , version = version ) <EOL> transaction . commit ( ) <EOL> status [ '<STR_LIT:success>' ] = True <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) % { '<STR_LIT>' : len ( results ) } <EOL> status [ '<STR_LIT:version>' ] = plan . version <EOL> except Exception as ex : <EOL> transaction . rollback ( ) <EOL> status [ '<STR_LIT:message>' ] = str ( ex ) <EOL> status [ '<STR_LIT>' ] = traceback . format_exc ( ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> @ login_required <EOL> @ unique_session_or_json_redirect <EOL> @ transaction . commit_manually <EOL> def assign_district_members ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> status = { '<STR_LIT:success>' : False } <EOL> try : <EOL> plan = Plan . objects . get ( pk = planid ) <EOL> except : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> if not can_edit ( request . user , plan ) : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> leg_bod = plan . legislative_body <EOL> if ( not leg_bod . multi_members_allowed ) : <EOL> status [ '<STR_LIT:message>' ] = _ ( <EOL> '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> districts = request . POST . getlist ( '<STR_LIT>' ) <EOL> counts = request . POST . getlist ( '<STR_LIT>' ) <EOL> version = int ( request . POST . get ( '<STR_LIT:version>' , None ) ) <EOL> try : <EOL> changed = <NUM_LIT:0> <EOL> for i in range ( <NUM_LIT:0> , len ( districts ) ) : <EOL> id = int ( districts [ i ] ) <EOL> count = int ( counts [ i ] ) <EOL> district = District . objects . filter ( plan = plan , district_id = id , version__lte = version ) . order_by ( '<STR_LIT:version>' ) . reverse ( ) [ <NUM_LIT:0> ] <EOL> if district . num_members != count : <EOL> if ( changed == <NUM_LIT:0> ) : <EOL> if version != plan . version : <EOL> plan . purge ( after = version ) <EOL> plan . version = plan . version + <NUM_LIT:1> <EOL> plan . save ( ) <EOL> plan . update_num_members ( district , count ) <EOL> changed += <NUM_LIT:1> <EOL> transaction . commit ( ) <EOL> status [ '<STR_LIT:success>' ] = True <EOL> status [ '<STR_LIT:version>' ] = plan . version <EOL> status [ '<STR_LIT>' ] = changed <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' <EOL> '<STR_LIT>' ) % { '<STR_LIT>' : changed } <EOL> except Exception , ex : <EOL> transaction . rollback ( ) <EOL> status [ '<STR_LIT:message>' ] = str ( ex ) <EOL> status [ '<STR_LIT>' ] = traceback . format_exc ( ) <EOL> logger . warn ( '<STR_LIT>' ) <EOL> logger . debug ( '<STR_LIT>' , ex ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> @ login_required <EOL> @ unique_session_or_json_redirect <EOL> def combine_districts ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> status = { '<STR_LIT:success>' : False } <EOL> try : <EOL> plan = Plan . objects . get ( pk = planid ) <EOL> except : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> if not can_edit ( request . user , plan ) : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> version = int ( request . POST . get ( '<STR_LIT:version>' , plan . version ) ) <EOL> from_id = int ( request . POST . get ( '<STR_LIT>' , - <NUM_LIT:1> ) ) <EOL> to_id = int ( request . POST . get ( '<STR_LIT>' , None ) ) <EOL> try : <EOL> all_districts = plan . get_districts_at_version ( version , include_geom = True ) <EOL> from_districts = filter ( lambda d : True if d . district_id == from_id else False , all_districts ) <EOL> to_district = filter ( lambda d : True if d . district_id == to_id else False , all_districts ) [ <NUM_LIT:0> ] <EOL> locked = to_district . is_locked <EOL> for district in from_districts : <EOL> if district . is_locked : <EOL> locked = True <EOL> if locked : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> result = plan . combine_districts ( to_district , from_districts , version = version ) <EOL> if result [ <NUM_LIT:0> ] == True : <EOL> status [ '<STR_LIT:success>' ] = True <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> status [ '<STR_LIT:version>' ] = result [ <NUM_LIT:1> ] <EOL> except Exception , ex : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> status [ '<STR_LIT>' ] = traceback . format_exc ( ) <EOL> logger . warn ( '<STR_LIT>' ) <EOL> logger . debug ( '<STR_LIT>' , ex ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> @ login_required <EOL> @ unique_session_or_json_redirect <EOL> def fix_unassigned ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> status = { '<STR_LIT:success>' : False } <EOL> try : <EOL> plan = Plan . objects . get ( pk = planid ) <EOL> except : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> if not can_edit ( request . user , plan ) : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> try : <EOL> version = int ( request . POST . get ( '<STR_LIT:version>' , plan . version ) ) <EOL> result = plan . fix_unassigned ( version ) <EOL> status [ '<STR_LIT:success>' ] = result [ <NUM_LIT:0> ] <EOL> status [ '<STR_LIT:message>' ] = result [ <NUM_LIT:1> ] <EOL> status [ '<STR_LIT:version>' ] = plan . version <EOL> except Exception , ex : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> status [ '<STR_LIT>' ] = traceback . format_exc ( ) <EOL> logger . warn ( '<STR_LIT>' ) <EOL> logger . debug ( '<STR_LIT>' , ex ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> @ unique_session_or_json_redirect <EOL> def get_splits ( request , planid , otherid , othertype ) : <EOL> """<STR_LIT>""" <EOL> otherid = int ( otherid ) <EOL> status = { '<STR_LIT:success>' : False } <EOL> try : <EOL> plan = Plan . objects . get ( pk = planid ) <EOL> except : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> if not can_view ( request . user , plan ) : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> version = int ( request . REQUEST [ '<STR_LIT:version>' ] if '<STR_LIT:version>' in request . REQUEST else plan . version ) <EOL> try : <EOL> if othertype == '<STR_LIT>' : <EOL> try : <EOL> otherplan = Plan . objects . get ( pk = otherid ) <EOL> except : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> if not can_view ( request . user , otherplan ) : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> otherversion = int ( request . REQUEST [ '<STR_LIT>' ] if '<STR_LIT>' in request . REQUEST else otherplan . version ) <EOL> splits = plan . find_plan_splits ( otherplan , version , otherversion ) <EOL> elif othertype == '<STR_LIT>' : <EOL> splits = plan . find_geolevel_splits ( otherid , version ) <EOL> else : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) % { '<STR_LIT>' : othertype } <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> split_word = _ ( '<STR_LIT>' ) if len ( splits ) == <NUM_LIT:1> else inflect . engine ( ) . plural ( _ ( '<STR_LIT>' ) ) <EOL> status [ '<STR_LIT:success>' ] = True <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) % { '<STR_LIT>' : len ( splits ) , '<STR_LIT>' : split_word } <EOL> status [ '<STR_LIT>' ] = splits <EOL> status [ '<STR_LIT>' ] = list ( set ( [ i [ <NUM_LIT:0> ] for i in splits ] ) ) <EOL> status [ '<STR_LIT>' ] = list ( set ( [ i [ <NUM_LIT:1> ] for i in splits ] ) ) <EOL> except Exception , ex : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> status [ '<STR_LIT>' ] = traceback . format_exc ( ) <EOL> logger . warn ( '<STR_LIT>' ) <EOL> logger . debug ( '<STR_LIT>' , ex ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> def get_processing_status ( request ) : <EOL> """<STR_LIT>""" <EOL> status = { '<STR_LIT:success>' : False } <EOL> plan_ids = request . REQUEST . getlist ( '<STR_LIT>' ) <EOL> if len ( plan_ids ) == <NUM_LIT:0> : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> else : <EOL> statuses = { } <EOL> for p in Plan . objects . filter ( id__in = plan_ids ) : <EOL> statuses [ str ( p . id ) ] = p . get_processing_state_display ( ) <EOL> status [ '<STR_LIT:success>' ] = True <EOL> status [ '<STR_LIT:message>' ] = statuses <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> def get_splits_report ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> try : <EOL> plan = Plan . objects . get ( pk = planid ) <EOL> except : <EOL> return HttpResponse ( _ ( '<STR_LIT>' ) , mimetype = '<STR_LIT>' ) <EOL> if not using_unique_session ( request . user ) or not can_view ( request . user , plan ) : <EOL> return HttpResponseForbidden ( ) <EOL> version = int ( request . REQUEST [ '<STR_LIT:version>' ] if '<STR_LIT:version>' in request . REQUEST else plan . version ) <EOL> inverse = request . REQUEST [ '<STR_LIT>' ] == '<STR_LIT:true>' if '<STR_LIT>' in request . REQUEST else False <EOL> extended = request . REQUEST [ '<STR_LIT>' ] == '<STR_LIT:true>' if '<STR_LIT>' in request . REQUEST else False <EOL> layers = request . REQUEST . getlist ( '<STR_LIT>' ) <EOL> if len ( layers ) == <NUM_LIT:0> : <EOL> return HttpResponse ( _ ( '<STR_LIT>' ) , mimetype = '<STR_LIT>' ) <EOL> try : <EOL> report = loader . get_template ( '<STR_LIT>' ) <EOL> html = '<STR_LIT>' <EOL> for layer in layers : <EOL> my_context = { '<STR_LIT>' : extended } <EOL> my_context . update ( plan . compute_splits ( layer , version = version , inverse = inverse , extended = extended ) ) <EOL> last_item = layer is layers [ - <NUM_LIT:1> ] <EOL> community_info = plan . get_community_type_info ( layer , version = version , inverse = inverse , include_counts = last_item ) <EOL> if community_info is not None : <EOL> my_context . update ( community_info ) <EOL> calc_context = DjangoContext ( my_context ) <EOL> html += report . render ( calc_context ) <EOL> if not last_item : <EOL> html += '<STR_LIT>' <EOL> return HttpResponse ( html , mimetype = '<STR_LIT>' ) <EOL> except Exception , ex : <EOL> logger . warn ( '<STR_LIT>' ) <EOL> logger . debug ( '<STR_LIT>' , ex ) <EOL> return HttpResponse ( str ( ex ) , mimetype = '<STR_LIT>' ) <EOL> @ login_required <EOL> @ unique_session_or_json_redirect <EOL> def addtodistrict ( request , planid , districtid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> status = { '<STR_LIT:success>' : False } <EOL> if len ( request . REQUEST . items ( ) ) >= <NUM_LIT:2> : <EOL> try : <EOL> geolevel = request . REQUEST [ "<STR_LIT>" ] <EOL> geounit_ids = string . split ( request . REQUEST [ "<STR_LIT>" ] , "<STR_LIT:|>" ) <EOL> plan = Plan . objects . get ( pk = planid , owner = request . user ) <EOL> except : <EOL> status [ '<STR_LIT>' ] = traceback . format_exc ( ) <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> if '<STR_LIT:version>' in request . REQUEST : <EOL> version = request . REQUEST [ '<STR_LIT:version>' ] <EOL> else : <EOL> version = plan . version <EOL> try : <EOL> fixed = plan . add_geounits ( districtid , geounit_ids , geolevel , version ) <EOL> status [ '<STR_LIT:success>' ] = True ; <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) % { '<STR_LIT>' : fixed } <EOL> status [ '<STR_LIT>' ] = fixed <EOL> plan = Plan . objects . get ( pk = planid , owner = request . user ) <EOL> status [ '<STR_LIT>' ] = getutc ( plan . edited ) . isoformat ( ) <EOL> status [ '<STR_LIT:version>' ] = plan . version <EOL> except Exception , ex : <EOL> status [ '<STR_LIT>' ] = traceback . format_exc ( ) <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> logger . warn ( '<STR_LIT>' ) <EOL> logger . debug ( '<STR_LIT>' , ex ) <EOL> else : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> @ unique_session_or_json_redirect <EOL> @ login_required <EOL> def setdistrictlock ( request , planid , district_id ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> status = { '<STR_LIT:success>' : False } <EOL> if request . method != '<STR_LIT:POST>' : <EOL> return HttpResponseForbidden ( ) <EOL> lock = request . POST . get ( '<STR_LIT>' ) . lower ( ) == '<STR_LIT:true>' <EOL> version = request . POST . get ( '<STR_LIT:version>' ) <EOL> if lock == None : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> elif version == None : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> try : <EOL> plan = Plan . objects . get ( pk = planid ) <EOL> district = plan . district_set . filter ( district_id = district_id , version__lte = version ) . order_by ( '<STR_LIT:version>' ) . reverse ( ) [ <NUM_LIT:0> ] <EOL> except ObjectDoesNotExist : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> if plan . owner != request . user : <EOL> return HttpResponseForbidden ( ) <EOL> district . is_locked = lock <EOL> district . save ( ) <EOL> status [ '<STR_LIT:success>' ] = True <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) % { '<STR_LIT>' : _ ( '<STR_LIT>' ) if lock else _ ( '<STR_LIT>' ) } <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> @ unique_session_or_json_redirect <EOL> def getdistricts ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> status = { '<STR_LIT:success>' : False } <EOL> plan = Plan . objects . filter ( id = planid ) <EOL> if plan . count ( ) == <NUM_LIT:1> : <EOL> plan = plan [ <NUM_LIT:0> ] <EOL> if '<STR_LIT:version>' in request . REQUEST : <EOL> version = int ( request . REQUEST [ '<STR_LIT:version>' ] ) <EOL> else : <EOL> version = plan . version <EOL> districts = plan . get_districts_at_version ( version , include_geom = False ) <EOL> status [ '<STR_LIT>' ] = [ ] <EOL> status [ '<STR_LIT>' ] = plan . legislative_body . max_districts - len ( districts ) + <NUM_LIT:1> <EOL> max_version = max ( [ d . version for d in districts ] ) <EOL> can_undo = max_version > plan . min_version <EOL> for district in districts : <EOL> status [ '<STR_LIT>' ] . append ( { <EOL> '<STR_LIT:id>' : district . district_id , <EOL> '<STR_LIT>' : '<STR_LIT:U+0020>' . join ( map ( _ , district . short_label . split ( '<STR_LIT:U+0020>' ) ) ) , <EOL> '<STR_LIT>' : '<STR_LIT:U+0020>' . join ( map ( _ , district . long_label . split ( '<STR_LIT:U+0020>' ) ) ) , <EOL> '<STR_LIT:version>' : district . version <EOL> } ) <EOL> status [ '<STR_LIT>' ] = can_undo <EOL> status [ '<STR_LIT:success>' ] = True <EOL> else : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> def simple_district_versioned ( request , planid , district_ids = None ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> status = { '<STR_LIT:type>' : '<STR_LIT>' } <EOL> plan = Plan . objects . filter ( id = planid ) <EOL> if plan . count ( ) == <NUM_LIT:1> : <EOL> plan = plan [ <NUM_LIT:0> ] <EOL> if '<STR_LIT>' in request . REQUEST : <EOL> version = request . REQUEST [ '<STR_LIT>' ] <EOL> else : <EOL> version = plan . version <EOL> subject_id = None <EOL> if '<STR_LIT>' in request . REQUEST : <EOL> subject_id = request . REQUEST [ '<STR_LIT>' ] <EOL> elif plan . legislative_body . get_default_subject ( ) : <EOL> subject_id = plan . legislative_body . get_default_subject ( ) . id <EOL> geolevel = plan . legislative_body . get_geolevels ( ) [ <NUM_LIT:0> ] . id <EOL> if '<STR_LIT>' in request . REQUEST : <EOL> geolevel = int ( request . REQUEST [ '<STR_LIT>' ] ) <EOL> if '<STR_LIT>' in request . REQUEST : <EOL> district_ids = request . REQUEST [ '<STR_LIT>' ] <EOL> if len ( district_ids ) > <NUM_LIT:0> : <EOL> district_ids = district_ids . split ( '<STR_LIT:U+002C>' ) <EOL> else : <EOL> district_ids = [ ] <EOL> if subject_id : <EOL> bbox = None <EOL> if '<STR_LIT>' in request . REQUEST : <EOL> bbox = request . REQUEST [ '<STR_LIT>' ] <EOL> bbox = tuple ( map ( lambda x : float ( x ) , bbox . split ( '<STR_LIT:U+002C>' ) ) ) <EOL> else : <EOL> bbox = plan . district_set . all ( ) . extent ( field_name = '<STR_LIT>' ) <EOL> status [ '<STR_LIT>' ] = plan . get_wfs_districts ( version , subject_id , bbox , geolevel , district_ids ) <EOL> else : <EOL> status [ '<STR_LIT>' ] = [ ] <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> else : <EOL> status [ '<STR_LIT>' ] = [ ] <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> def get_unlocked_simple_geometries ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> status = { '<STR_LIT:type>' : '<STR_LIT>' } <EOL> plan = Plan . objects . filter ( id = planid ) <EOL> if plan . count ( ) == <NUM_LIT:1> : <EOL> plan = plan [ <NUM_LIT:0> ] <EOL> version = request . POST . get ( '<STR_LIT>' , plan . version ) <EOL> geolevel = request . POST . get ( '<STR_LIT>' , plan . legislative_body . get_geolevels ( ) [ <NUM_LIT:0> ] . id ) <EOL> geom = request . POST . get ( '<STR_LIT>' , None ) <EOL> if geom is not None : <EOL> try : <EOL> wkt = request . POST . get ( '<STR_LIT>' , None ) <EOL> geom = GEOSGeometry ( wkt ) <EOL> except GEOSException : <EOL> wkt = request . REQUEST [ '<STR_LIT>' ] . replace ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> wkt = wkt . replace ( '<STR_LIT>' , '<STR_LIT:(>' ) . replace ( '<STR_LIT>' , '<STR_LIT:)>' ) <EOL> try : <EOL> geom = GEOSGeometry ( wkt ) <EOL> except GEOSException : <EOL> geom = None <EOL> selection = Q ( geom__intersects = geom ) <EOL> districts = [ d . id for d in plan . get_districts_at_version ( version , include_geom = True ) if d . is_locked ] <EOL> locked = District . objects . filter ( id__in = districts ) . collect ( ) <EOL> locked_buffered = locked . simplify ( <NUM_LIT:100> , True ) . buffer ( <NUM_LIT:100> ) if locked else None <EOL> filtered = Geolevel . objects . get ( id = geolevel ) . geounit_set . filter ( selection ) <EOL> features = [ ] <EOL> for feature in filtered : <EOL> geom = feature . simple <EOL> if locked and geom . intersects ( locked_buffered ) : <EOL> if feature . geom . within ( locked ) : <EOL> continue <EOL> if feature . geom . overlaps ( locked ) : <EOL> geom = geom . difference ( locked_buffered ) <EOL> features . append ( { <EOL> '<STR_LIT:id>' : '<STR_LIT>' % feature . id , <EOL> '<STR_LIT>' : json . loads ( geom . json ) , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:name>' : feature . name , <EOL> '<STR_LIT>' : geolevel , <EOL> '<STR_LIT:id>' : feature . id <EOL> } <EOL> } ) <EOL> status [ '<STR_LIT>' ] = features <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> else : <EOL> status [ '<STR_LIT>' ] = [ ] <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> else : <EOL> status [ '<STR_LIT>' ] = [ ] <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> @ unique_session_or_json_redirect <EOL> def get_statistics ( request , planid ) : <EOL> note_session_activity ( request ) <EOL> status = { '<STR_LIT:success>' : False } <EOL> try : <EOL> plan = Plan . objects . get ( pk = planid ) <EOL> except : <EOL> status [ '<STR_LIT:message>' ] = _ ( <EOL> "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' , status = <NUM_LIT> ) <EOL> if '<STR_LIT:version>' in request . REQUEST : <EOL> try : <EOL> version = int ( request . REQUEST [ '<STR_LIT:version>' ] ) <EOL> except : <EOL> version = plan . version <EOL> else : <EOL> version = plan . version <EOL> try : <EOL> display = ScoreDisplay . objects . get ( legislative_body = plan . legislative_body , name = "<STR_LIT>" % plan . legislative_body . name ) <EOL> except : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> status [ '<STR_LIT>' ] = traceback . format_exc ( ) <EOL> if '<STR_LIT>' in request . REQUEST : <EOL> try : <EOL> display = ScoreDisplay . objects . get ( pk = request . POST [ '<STR_LIT>' ] ) <EOL> except : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> status [ '<STR_LIT>' ] = traceback . format_exc ( ) <EOL> else : <EOL> logger . warn ( '<STR_LIT>' ) <EOL> logger . warn ( str ( request . POST ) ) <EOL> try : <EOL> html = display . render ( plan , request , version = version ) <EOL> return HttpResponse ( html , mimetype = '<STR_LIT>' ) <EOL> except Exception , ex : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> status [ '<STR_LIT>' ] = traceback . format_exc ( ) <EOL> logger . warn ( "<STR_LIT>" ) <EOL> logger . debug ( '<STR_LIT>' , ex ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' , status = <NUM_LIT> ) <EOL> def getutc ( t ) : <EOL> """<STR_LIT>""" <EOL> t_tuple = t . timetuple ( ) <EOL> t_seconds = time . mktime ( t_tuple ) <EOL> return t . utcfromtimestamp ( t_seconds ) <EOL> @ unique_session_or_json_redirect <EOL> def getdistrictfilestatus ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> status = { '<STR_LIT:success>' : False } <EOL> plan = Plan . objects . get ( pk = planid ) <EOL> if not can_copy ( request . user , plan ) : <EOL> return HttpResponseForbidden ( ) <EOL> try : <EOL> is_shape = '<STR_LIT:type>' in request . REQUEST and request . REQUEST [ '<STR_LIT:type>' ] == '<STR_LIT>' <EOL> file_status = DistrictFile . get_file_status ( plan , shape = is_shape ) <EOL> status [ '<STR_LIT:success>' ] = True <EOL> status [ '<STR_LIT:status>' ] = file_status <EOL> except Exception as ex : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> status [ '<STR_LIT>' ] = ex <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> @ unique_session_or_json_redirect <EOL> def getdistrictfile ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> plan = Plan . objects . get ( pk = planid ) <EOL> if not can_copy ( request . user , plan ) : <EOL> return HttpResponseForbidden ( ) <EOL> is_shape = '<STR_LIT:type>' in request . REQUEST and request . REQUEST [ '<STR_LIT:type>' ] == '<STR_LIT>' <EOL> file_status = DistrictFile . get_file_status ( plan , shape = is_shape ) <EOL> if file_status == '<STR_LIT>' : <EOL> if is_shape : <EOL> archive = DistrictShapeFile . plan2shape ( plan ) <EOL> else : <EOL> archive = DistrictIndexFile . plan2index ( plan ) <EOL> response = HttpResponse ( open ( archive . name ) . read ( ) , content_type = '<STR_LIT>' ) <EOL> response [ '<STR_LIT>' ] = '<STR_LIT>' % plan . get_friendly_name ( ) <EOL> else : <EOL> if is_shape : <EOL> DistrictShapeFile . plan2shape . delay ( plan ) <EOL> else : <EOL> DistrictIndexFile . plan2index . delay ( plan ) <EOL> response = HttpResponse ( _ ( '<STR_LIT>' <EOL> '<STR_LIT>' ) ) <EOL> return response <EOL> @ unique_session_or_json_redirect <EOL> def emaildistrictindexfile ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> if request . method != '<STR_LIT:POST>' : <EOL> return HttpResponseForbidden ( ) <EOL> plan = Plan . objects . get ( pk = planid ) <EOL> if not can_copy ( request . user , plan ) : <EOL> return HttpResponseForbidden ( ) <EOL> DistrictIndexFile . emailfile . delay ( plan , request . user , request . POST , translation . get_language ( ) ) <EOL> return HttpResponse ( json . dumps ( { <EOL> '<STR_LIT:success>' : True , <EOL> '<STR_LIT:message>' : _ ( '<STR_LIT>' ) } ) , <EOL> mimetype = '<STR_LIT:application/json>' ) <EOL> def getvalidplans ( leg_body , owner = None ) : <EOL> """<STR_LIT>""" <EOL> pfilter = Q ( legislative_body = leg_body ) & Q ( is_valid = True ) <EOL> if owner is not None : <EOL> pfilter = pfilter & Q ( owner = owner ) <EOL> return list ( Plan . objects . filter ( pfilter ) ) <EOL> def getleaderboarddisplay ( leg_body , owner_filter ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> return ScoreDisplay . objects . get ( name = "<STR_LIT>" % ( leg_body . name , owner_filter ) ) <EOL> except : <EOL> return None <EOL> def getleaderboard ( request ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> if not using_unique_session ( request . user ) : <EOL> return HttpResponseForbidden ( ) <EOL> owner_filter = request . REQUEST [ '<STR_LIT>' ] <EOL> body_pk = int ( request . REQUEST [ '<STR_LIT>' ] ) ; <EOL> leg_body = LegislativeBody . objects . get ( pk = body_pk ) <EOL> display = getleaderboarddisplay ( leg_body , owner_filter ) <EOL> if display is None : <EOL> return HttpResponse ( _ ( '<STR_LIT>' ) , mimetype = '<STR_LIT>' ) <EOL> plans = getvalidplans ( leg_body , request . user if owner_filter == '<STR_LIT>' else None ) <EOL> try : <EOL> html = display . render ( plans , request ) <EOL> return HttpResponse ( html , mimetype = '<STR_LIT>' ) <EOL> except Exception , ex : <EOL> logger . warn ( '<STR_LIT>' ) <EOL> logger . debug ( '<STR_LIT>' , ex ) <EOL> return HttpResponse ( str ( ex ) , mimetype = '<STR_LIT>' ) <EOL> def getleaderboardcsv ( request ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> if not using_unique_session ( request . user ) : <EOL> return HttpResponseForbidden ( ) <EOL> owner_filter = request . REQUEST [ '<STR_LIT>' ] <EOL> body_pk = int ( request . REQUEST [ '<STR_LIT>' ] ) ; <EOL> leg_body = LegislativeBody . objects . get ( pk = body_pk ) <EOL> plans = getvalidplans ( leg_body , request . user if owner_filter == '<STR_LIT>' else None ) <EOL> display = getleaderboarddisplay ( leg_body , owner_filter ) <EOL> plans = getvalidplans ( leg_body , request . user if owner_filter == '<STR_LIT>' else None ) <EOL> panels = display . scorepanel_set . all ( ) . order_by ( '<STR_LIT>' ) <EOL> try : <EOL> response = HttpResponse ( mimetype = '<STR_LIT>' ) <EOL> response [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> writer = csv . writer ( response ) <EOL> writer . writerow ( [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] + [ p . __unicode__ ( ) for p in panels ] ) <EOL> for plan in plans : <EOL> row = [ plan . id , plan . name , plan . owner . username ] <EOL> for panel in panels : <EOL> function = panel . score_functions . all ( ) [ <NUM_LIT:0> ] <EOL> score = ComputedPlanScore . compute ( function , plan ) <EOL> row . append ( score [ '<STR_LIT:value>' ] ) <EOL> writer . writerow ( row ) <EOL> return response <EOL> except Exception , ex : <EOL> logger . warn ( "<STR_LIT>" ) <EOL> logger . debug ( '<STR_LIT>' , ex ) <EOL> return HttpResponse ( str ( ex ) , mimetype = '<STR_LIT>' ) <EOL> def getplans ( request ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> if not using_unique_session ( request . user ) : <EOL> return HttpResponseForbidden ( ) <EOL> if request . method == '<STR_LIT:POST>' : <EOL> page = int ( request . POST . get ( '<STR_LIT>' , <NUM_LIT:1> ) ) <EOL> rows = int ( request . POST . get ( '<STR_LIT>' , <NUM_LIT:10> ) ) <EOL> sidx = request . POST . get ( '<STR_LIT>' , '<STR_LIT:id>' ) <EOL> sord = request . POST . get ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> owner_filter = request . POST . get ( '<STR_LIT>' ) ; <EOL> body_pk = request . POST . get ( '<STR_LIT>' ) ; <EOL> body_pk = int ( body_pk ) if body_pk else body_pk ; <EOL> search = request . POST . get ( '<STR_LIT>' , False ) ; <EOL> search_string = request . POST . get ( '<STR_LIT>' , '<STR_LIT>' ) ; <EOL> is_community = request . POST . get ( '<STR_LIT>' , False ) == '<STR_LIT:true>' ; <EOL> else : <EOL> return HttpResponseForbidden ( ) <EOL> end = page * rows <EOL> start = end - rows <EOL> if owner_filter == '<STR_LIT>' : <EOL> available = Q ( is_template = True ) <EOL> elif owner_filter == '<STR_LIT>' : <EOL> available = Q ( is_shared = True ) <EOL> elif owner_filter == '<STR_LIT>' : <EOL> if request . user . is_anonymous ( ) : <EOL> return HttpResponseForbidden ( ) <EOL> else : <EOL> available = Q ( owner__exact = request . user ) <EOL> elif owner_filter == '<STR_LIT>' : <EOL> available = Q ( is_template = True ) | Q ( is_shared = True ) <EOL> if not request . user . is_anonymous ( ) : <EOL> available = available | Q ( owner__exact = request . user ) <EOL> else : <EOL> return HttpResponseBadRequest ( _ ( "<STR_LIT>" ) ) <EOL> not_creating = ~ Q ( processing_state = ProcessingState . CREATING ) & ~ Q ( processing_state = ProcessingState . UNKNOWN ) <EOL> if sidx . startswith ( '<STR_LIT>' ) : <EOL> sidx = sidx [ len ( '<STR_LIT>' ) : ] <EOL> if sidx == '<STR_LIT>' : <EOL> sidx = '<STR_LIT>' <EOL> if sidx == '<STR_LIT>' : <EOL> sidx = '<STR_LIT>' <EOL> if sord == '<STR_LIT>' : <EOL> sidx = '<STR_LIT:->' + sidx <EOL> if search : <EOL> search_filter = Q ( name__icontains = search_string ) | Q ( description__icontains = search_string ) | Q ( owner__username__icontains = search_string ) <EOL> else : <EOL> search_filter = None <EOL> if body_pk : <EOL> body_filter = Q ( legislative_body = body_pk ) <EOL> all_plans = Plan . objects . filter ( available , not_creating , body_filter , search_filter ) . order_by ( sidx ) <EOL> else : <EOL> community_filter = Q ( legislative_body__is_community = is_community ) <EOL> all_plans = Plan . objects . filter ( available , not_creating , search_filter , community_filter ) . order_by ( sidx ) <EOL> if all_plans . count ( ) > <NUM_LIT:0> : <EOL> total_pages = math . ceil ( all_plans . count ( ) / float ( rows ) ) <EOL> else : <EOL> total_pages = <NUM_LIT:1> <EOL> plans = all_plans [ start : end ] <EOL> plans_list = list ( ) <EOL> for plan in plans : <EOL> plans_list . append ( { <EOL> '<STR_LIT>' : plan . id , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:name>' : plan . name , <EOL> '<STR_LIT:description>' : plan . description , <EOL> '<STR_LIT>' : time . mktime ( plan . edited . timetuple ( ) ) , <EOL> '<STR_LIT>' : plan . is_template , <EOL> '<STR_LIT>' : plan . is_shared , <EOL> '<STR_LIT>' : plan . owner . username , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : can_edit ( request . user , plan ) , <EOL> '<STR_LIT>' : plan . legislative_body . get_long_description ( ) , <EOL> '<STR_LIT>' : plan . get_processing_state_display ( ) <EOL> } <EOL> } ) <EOL> json_response = "<STR_LIT>" % ( total_pages , page , len ( all_plans ) , json . dumps ( plans_list ) ) <EOL> return HttpResponse ( json_response , mimetype = '<STR_LIT:application/json>' ) <EOL> def get_shared_districts ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> if not using_unique_session ( request . user ) : <EOL> return HttpResponseForbidden ( ) <EOL> if request . method == '<STR_LIT:POST>' : <EOL> page = int ( request . POST . get ( '<STR_LIT>' , <NUM_LIT:1> ) ) <EOL> rows = int ( request . POST . get ( '<STR_LIT>' , <NUM_LIT:10> ) ) <EOL> else : <EOL> return HttpResponseForbidden ( ) <EOL> end = page * rows <EOL> start = end - rows <EOL> try : <EOL> plan = Plan . objects . get ( pk = planid ) <EOL> if not can_copy ( request . user , plan ) : <EOL> return HttpResponseForbidden ( ) <EOL> all_districts = plan . get_districts_at_version ( plan . version , include_geom = False ) <EOL> except : <EOL> plan = None <EOL> all_districts = ( ) <EOL> if len ( all_districts ) > <NUM_LIT:0> : <EOL> total_pages = math . ceil ( len ( all_districts ) / float ( rows ) ) <EOL> else : <EOL> total_pages = <NUM_LIT:1> <EOL> districts = all_districts [ start : end ] <EOL> districts_list = list ( ) <EOL> for district in districts : <EOL> if not district . is_unassigned : <EOL> districts_list . append ( { <EOL> '<STR_LIT>' : district . id , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : district . short_label , <EOL> '<STR_LIT>' : district . long_label , <EOL> '<STR_LIT>' : district . district_id , <EOL> } <EOL> } ) <EOL> json_response = "<STR_LIT>" % ( total_pages , page , len ( all_districts ) , json . dumps ( districts_list ) ) <EOL> return HttpResponse ( json_response , mimetype = '<STR_LIT:application/json>' ) <EOL> @ login_required <EOL> @ unique_session_or_json_redirect <EOL> def editplanattributes ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> status = { '<STR_LIT:success>' : False } <EOL> if request . method != '<STR_LIT:POST>' : <EOL> return HttpResponseNotAllowed ( [ '<STR_LIT:POST>' ] ) <EOL> new_name = request . POST . get ( '<STR_LIT:name>' , None ) <EOL> new_description = request . POST . get ( '<STR_LIT:description>' , '<STR_LIT>' ) <EOL> if not planid or not ( new_name or new_description ) : <EOL> return HttpResponseBadRequest ( <EOL> _ ( '<STR_LIT>' ) ) <EOL> plan = Plan . objects . filter ( pk = planid , owner = request . user ) <EOL> if plan . count ( ) == <NUM_LIT:1> : <EOL> plan = plan [ <NUM_LIT:0> ] <EOL> if not new_name is None : <EOL> plan . name = new_name <EOL> plan . description = new_description <EOL> try : <EOL> plan . save ( ) <EOL> status [ '<STR_LIT:success>' ] = True <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> except Exception , ex : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> status [ '<STR_LIT>' ] = ex <EOL> logger . warn ( '<STR_LIT>' ) <EOL> logger . debug ( '<STR_LIT>' , ex ) <EOL> else : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> @ login_required <EOL> @ unique_session_or_json_redirect <EOL> def deleteplan ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> status = { '<STR_LIT:success>' : False } <EOL> if request . method != '<STR_LIT:POST>' : <EOL> return HttpResponseNotAllowed ( [ '<STR_LIT:POST>' ] ) <EOL> if not planid : <EOL> return HttpResponseBadRequest ( _ ( '<STR_LIT>' ) ) <EOL> plan = Plan . objects . filter ( pk = planid , owner = request . user ) <EOL> if plan . count ( ) == <NUM_LIT:1> : <EOL> plan = plan [ <NUM_LIT:0> ] <EOL> try : <EOL> plan . delete ( ) <EOL> status [ '<STR_LIT:success>' ] = True <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> except Exception , ex : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> status [ '<STR_LIT>' ] = ex <EOL> logger . warn ( '<STR_LIT>' ) <EOL> logger . debug ( '<STR_LIT>' , ex ) <EOL> else : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> @ login_required <EOL> @ unique_session_or_json_redirect <EOL> def reaggregateplan ( request , planid ) : <EOL> """<STR_LIT>""" <EOL> note_session_activity ( request ) <EOL> status = { '<STR_LIT:success>' : False } <EOL> if request . method != '<STR_LIT:POST>' : <EOL> return HttpResponseNotAllowed ( [ '<STR_LIT:POST>' ] ) <EOL> if not planid : <EOL> return HttpResponseBadRequest ( _ ( '<STR_LIT>' ) ) <EOL> plan = Plan . objects . filter ( pk = planid , owner = request . user ) <EOL> if plan . count ( ) == <NUM_LIT:1> : <EOL> plan = plan [ <NUM_LIT:0> ] <EOL> try : <EOL> reaggregate_plan . delay ( plan . id ) <EOL> plan . processing_state = ProcessingState . REAGGREGATING <EOL> plan . save ( ) <EOL> status [ '<STR_LIT:success>' ] = True <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> except Exception , ex : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> status [ '<STR_LIT>' ] = ex <EOL> logger . warn ( '<STR_LIT>' ) <EOL> logger . debug ( '<STR_LIT>' , ex ) <EOL> else : <EOL> status [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> def get_health ( request ) : <EOL> def num_users ( minutes ) : <EOL> users = <NUM_LIT:0> <EOL> for session in Session . objects . all ( ) : <EOL> try : <EOL> decoded = session . get_decoded ( ) <EOL> except : <EOL> session . delete ( ) <EOL> continue <EOL> if '<STR_LIT>' in decoded : <EOL> activity_delta = decoded [ '<STR_LIT>' ] - timedelta ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , settings . SESSION_TIMEOUT ) <EOL> if activity_delta > ( datetime . now ( ) - timedelta ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , minutes ) ) : <EOL> users += <NUM_LIT:1> <EOL> return users <EOL> try : <EOL> result = _ ( '<STR_LIT>' ) % { '<STR_LIT:time>' : datetime . now ( ) } <EOL> result += _ ( '<STR_LIT>' ) % { '<STR_LIT>' : Plan . objects . all ( ) . count ( ) } <EOL> result += _ ( '<STR_LIT>' ) % { '<STR_LIT>' : Session . objects . all ( ) . count ( ) , <EOL> '<STR_LIT>' : settings . CONCURRENT_SESSIONS } <EOL> result += _ ( '<STR_LIT>' ) % { '<STR_LIT>' : num_users ( <NUM_LIT:10> ) } <EOL> space = os . statvfs ( '<STR_LIT>' ) <EOL> result += _ ( '<STR_LIT>' ) % { '<STR_LIT>' : ( ( space . f_bsize * space . f_bavail ) / ( <NUM_LIT> * <NUM_LIT> ) ) } <EOL> result += _ ( '<STR_LIT>' ) % { '<STR_LIT>' : commands . getoutput ( '<STR_LIT>' ) } <EOL> return HttpResponse ( result , mimetype = '<STR_LIT>' ) <EOL> except : <EOL> return HttpResponse ( _ ( "<STR_LIT>" ) % traceback . format_exc ( ) ) <EOL> def statistics_sets ( request , planid ) : <EOL> result = { '<STR_LIT:success>' : False } <EOL> plan = Plan . objects . filter ( id = planid ) <EOL> if plan . count ( ) == <NUM_LIT:0> : <EOL> result [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> return HttpResponse ( json . dumps ( result ) , mimetype = '<STR_LIT:application/json>' ) <EOL> else : <EOL> plan = plan [ <NUM_LIT:0> ] <EOL> if request . method == '<STR_LIT:GET>' : <EOL> sets = [ ] <EOL> scorefunctions = [ ] <EOL> user_functions = ScoreFunction . objects . filter ( selectable_bodies = plan . legislative_body ) . order_by ( '<STR_LIT:name>' ) <EOL> for f in user_functions : <EOL> if '<STR_LIT>' not in f . name . lower ( ) and '<STR_LIT>' not in f . name . lower ( ) : <EOL> scorefunctions . append ( { '<STR_LIT:id>' : f . id , '<STR_LIT:name>' : force_escape ( f . get_label ( ) ) } ) <EOL> result [ '<STR_LIT>' ] = scorefunctions <EOL> admin_display_names = [ <EOL> "<STR_LIT>" % plan . legislative_body . name , <EOL> ] <EOL> if plan . legislative_body . is_community : <EOL> admin_display_names . append ( "<STR_LIT>" % <EOL> plan . legislative_body . name ) <EOL> else : <EOL> admin_display_names . append ( "<STR_LIT>" % <EOL> plan . legislative_body . name ) <EOL> admin_displays = ScoreDisplay . objects . filter ( <EOL> owner__is_superuser = True , <EOL> legislative_body = plan . legislative_body , <EOL> name__in = admin_display_names <EOL> ) <EOL> for admin_display in admin_displays : <EOL> sets . append ( { <EOL> '<STR_LIT:id>' : admin_display . id , <EOL> '<STR_LIT:name>' : force_escape ( admin_display . get_label ( ) ) , <EOL> '<STR_LIT>' : [ ] , <EOL> '<STR_LIT>' : False <EOL> } ) <EOL> try : <EOL> user_displays = ScoreDisplay . objects . filter ( <EOL> owner = request . user , <EOL> legislative_body = plan . legislative_body , <EOL> is_page = False ) . order_by ( '<STR_LIT:title>' ) <EOL> result [ '<STR_LIT>' ] = len ( user_displays ) <EOL> for display in user_displays : <EOL> functions = [ ] <EOL> for panel in display . scorepanel_set . all ( ) : <EOL> if panel . type == '<STR_LIT>' : <EOL> functions = map ( lambda x : x . id , panel . score_functions . all ( ) ) <EOL> if len ( functions ) == <NUM_LIT:0> : <EOL> result [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) % { '<STR_LIT>' : panel } <EOL> sets . append ( { '<STR_LIT:id>' : display . id , '<STR_LIT:name>' : force_escape ( display . __unicode__ ( ) ) , '<STR_LIT>' : functions , '<STR_LIT>' : display . owner == request . user } ) <EOL> except Exception , ex : <EOL> result [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) % { '<STR_LIT:user>' : request . user } <EOL> logger . warn ( '<STR_LIT>' ) <EOL> logger . debug ( '<STR_LIT>' , ex ) <EOL> result [ '<STR_LIT>' ] = sets <EOL> result [ '<STR_LIT:success>' ] = True <EOL> elif request . method == '<STR_LIT:POST>' and '<STR_LIT>' in request . POST : <EOL> try : <EOL> display = ScoreDisplay . objects . get ( pk = request . REQUEST . get ( '<STR_LIT:id>' , - <NUM_LIT:1> ) ) <EOL> result [ '<STR_LIT>' ] = { '<STR_LIT:name>' : force_escape ( display . __unicode__ ( ) ) , '<STR_LIT:id>' : display . id } <EOL> qset = display . scorepanel_set . all ( ) <EOL> for panel in qset : <EOL> if panel . displays . count ( ) == <NUM_LIT:1> : <EOL> panel . delete ( ) <EOL> display . delete ( ) <EOL> result [ '<STR_LIT:success>' ] = True <EOL> except Exception , ex : <EOL> result [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> result [ '<STR_LIT>' ] = traceback . format_exc ( ) <EOL> logger . warn ( "<STR_LIT>" ) <EOL> logger . debug ( '<STR_LIT>' , ex ) <EOL> elif request . method == '<STR_LIT:POST>' : <EOL> def validate_num ( user , limit = <NUM_LIT:3> ) : <EOL> return ScoreDisplay . objects . filter ( owner = user , legislative_body = plan . legislative_body , is_page = False ) . count ( ) < limit <EOL> if '<STR_LIT>' in request . POST : <EOL> functions = request . POST . getlist ( '<STR_LIT>' ) <EOL> functions = map ( lambda x : int ( x ) , functions ) <EOL> try : <EOL> display = ScoreDisplay . objects . get ( title = request . POST . get ( '<STR_LIT:name>' ) , owner = request . user ) <EOL> display = display . copy_from ( display = display , functions = functions ) <EOL> except : <EOL> limit = <NUM_LIT:3> <EOL> if validate_num ( request . user , limit ) : <EOL> demo = ScoreDisplay . objects . filter ( <EOL> owner__is_superuser = True , <EOL> legislative_body = plan . legislative_body , <EOL> is_page = False , <EOL> title = "<STR_LIT>" <EOL> ) <EOL> for disp in demo : <EOL> has_comments = False <EOL> for pnl in disp . scorepanel_set . all ( ) : <EOL> for fn in pnl . score_functions . all ( ) : <EOL> has_comments = has_comments or fn . calculator . endswith ( '<STR_LIT>' ) <EOL> if not has_comments : <EOL> demo = disp <EOL> break <EOL> display = ScoreDisplay ( ) <EOL> display = display . copy_from ( display = demo , title = request . POST . get ( '<STR_LIT:name>' ) , owner = request . user , functions = functions ) <EOL> result [ '<STR_LIT>' ] = True <EOL> else : <EOL> result [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) % { '<STR_LIT>' : limit } <EOL> result [ '<STR_LIT:error>' ] = '<STR_LIT>' <EOL> return HttpResponse ( json . dumps ( result ) , mimetype = '<STR_LIT:application/json>' ) <EOL> result [ '<STR_LIT>' ] = { '<STR_LIT:name>' : force_escape ( display . __unicode__ ( ) ) , '<STR_LIT:id>' : display . id , '<STR_LIT>' : functions , '<STR_LIT>' : display . owner == request . user } <EOL> result [ '<STR_LIT:success>' ] = True <EOL> else : <EOL> result [ '<STR_LIT:message>' ] = _ ( "<STR_LIT>" ) <EOL> return HttpResponse ( json . dumps ( result ) , mimetype = '<STR_LIT:application/json>' ) <EOL> def purge_plan_clear_cache ( district , version ) : <EOL> """<STR_LIT>""" <EOL> district . plan . purge ( after = version ) <EOL> district . plan . version = version <EOL> district . plan . save ( ) <EOL> cache = district . computeddistrictscore_set . filter ( function__calculator__endswith = '<STR_LIT>' ) <EOL> cache . delete ( ) <EOL> @ unique_session_or_json_redirect <EOL> def district_info ( request , planid , district_id ) : <EOL> """<STR_LIT>""" <EOL> status = { '<STR_LIT:success>' : False } <EOL> plan = Plan . objects . filter ( id = planid ) <EOL> if plan . count ( ) == <NUM_LIT:0> : <EOL> status [ '<STR_LIT:message>' ] = _ ( '<STR_LIT>' ) <EOL> else : <EOL> plan = plan [ <NUM_LIT:0> ] <EOL> version = plan . version <EOL> if '<STR_LIT:version>' in request . REQUEST : <EOL> try : <EOL> version = int ( request . REQUEST [ '<STR_LIT:version>' ] ) <EOL> version = min ( plan . version , int ( version ) ) <EOL> except : <EOL> pass <EOL> district_id = int ( district_id ) <EOL> district = plan . get_districts_at_version ( version , include_geom = False ) <EOL> district = filter ( lambda d : d . district_id == district_id , district ) <EOL> if request . method == '<STR_LIT:POST>' : <EOL> district = plan . district_set . get ( id = request . POST [ '<STR_LIT>' ] ) <EOL> district . short_label = request . POST [ '<STR_LIT>' ] [ <NUM_LIT:0> : <NUM_LIT:10> ] <EOL> district . long_label = request . POST [ '<STR_LIT>' ] [ <NUM_LIT:0> : <NUM_LIT> ] <EOL> if district . version < version : <EOL> district_copy = copy . copy ( district ) <EOL> district_copy . id = None <EOL> district_copy . version = version <EOL> district_copy . save ( ) <EOL> district_copy . clone_relations_from ( district ) <EOL> district = district_copy <EOL> else : <EOL> district . save ( ) <EOL> has_comment = '<STR_LIT>' in request . POST and request . POST [ '<STR_LIT>' ] != '<STR_LIT>' <EOL> if has_comment : <EOL> ct = ContentType . objects . get ( app_label = '<STR_LIT>' , model = '<STR_LIT>' ) <EOL> Comment . objects . filter ( object_pk = district . id , content_type = ct ) . delete ( ) <EOL> comment = Comment ( <EOL> object_pk = district . id , <EOL> content_type = ct , <EOL> site_id = Site . objects . get_current ( ) . id , <EOL> user_name = request . user . username , <EOL> user_email = request . user . email , <EOL> comment = request . POST [ '<STR_LIT>' ] ) <EOL> comment . save ( ) <EOL> else : <EOL> district . save ( ) <EOL> tset = Tag . objects . get_for_object ( district ) . filter ( name__startswith = '<STR_LIT:type>' ) <EOL> TaggedItem . objects . filter ( tag__in = tset , object_id = district . id ) . delete ( ) <EOL> purge_plan_clear_cache ( district , version ) <EOL> if len ( request . REQUEST . getlist ( '<STR_LIT>' ) ) > <NUM_LIT:0> : <EOL> strtags = request . REQUEST . getlist ( '<STR_LIT>' ) <EOL> for strtag in strtags : <EOL> if strtag == '<STR_LIT>' : <EOL> continue <EOL> if strtag . count ( '<STR_LIT:U+0020>' ) > <NUM_LIT:0> : <EOL> strtag = '<STR_LIT>' % strtag <EOL> else : <EOL> strtag = '<STR_LIT>' % strtag <EOL> Tag . objects . add_tag ( district , strtag ) <EOL> status [ '<STR_LIT:version>' ] = version <EOL> status [ '<STR_LIT:success>' ] = True <EOL> return HttpResponse ( json . dumps ( status ) , mimetype = '<STR_LIT:application/json>' ) <EOL> def plan_feed ( request ) : <EOL> feed = loader . get_template ( '<STR_LIT>' ) <EOL> plans = Plan . objects . all ( ) . order_by ( '<STR_LIT>' ) [ <NUM_LIT:0> : <NUM_LIT:10> ] <EOL> geolevel = plans [ <NUM_LIT:0> ] . legislative_body . get_geolevels ( ) [ <NUM_LIT:0> ] <EOL> extent = geolevel . geounit_set . collect ( ) . extent <EOL> if extent [ <NUM_LIT:2> ] - extent [ <NUM_LIT:0> ] > extent [ <NUM_LIT:3> ] - extent [ <NUM_LIT:1> ] : <EOL> width = <NUM_LIT> <EOL> height = int ( <NUM_LIT> * ( extent [ <NUM_LIT:3> ] - extent [ <NUM_LIT:1> ] ) / ( extent [ <NUM_LIT:2> ] - extent [ <NUM_LIT:0> ] ) ) <EOL> else : <EOL> width = int ( <NUM_LIT> * ( extent [ <NUM_LIT:2> ] - extent [ <NUM_LIT:0> ] ) / ( extent [ <NUM_LIT:3> ] - extent [ <NUM_LIT:1> ] ) ) <EOL> height = <NUM_LIT> <EOL> mapserver = settings . MAP_SERVER if settings . MAP_SERVER != '<STR_LIT>' else request . META [ '<STR_LIT>' ] <EOL> context = { <EOL> '<STR_LIT>' : plans , <EOL> '<STR_LIT>' : mapserver , <EOL> '<STR_LIT>' : settings . MAP_SERVER_NS , <EOL> '<STR_LIT>' : extent , <EOL> '<STR_LIT:width>' : width , <EOL> '<STR_LIT>' : height <EOL> } <EOL> xml = feed . render ( DjangoContext ( context ) ) <EOL> return HttpResponse ( xml , mimetype = '<STR_LIT>' ) <EOL> def share_feed ( request ) : <EOL> feed = loader . get_template ( '<STR_LIT>' ) <EOL> plans = Plan . objects . filter ( is_shared = True ) . order_by ( '<STR_LIT>' ) [ <NUM_LIT:0> : <NUM_LIT:10> ] <EOL> if plans . count ( ) < <NUM_LIT:0> : <EOL> geolevel = plans [ <NUM_LIT:0> ] . legislative_body . get_geolevels ( ) [ <NUM_LIT:0> ] <EOL> extent = geolevel . geounit_set . collect ( ) . extent <EOL> if extent [ <NUM_LIT:2> ] - extent [ <NUM_LIT:0> ] > extent [ <NUM_LIT:3> ] - extent [ <NUM_LIT:1> ] : <EOL> width = <NUM_LIT> <EOL> height = int ( <NUM_LIT> * ( extent [ <NUM_LIT:3> ] - extent [ <NUM_LIT:1> ] ) / ( extent [ <NUM_LIT:2> ] - extent [ <NUM_LIT:0> ] ) ) <EOL> else : <EOL> width = int ( <NUM_LIT> * ( extent [ <NUM_LIT:2> ] - extent [ <NUM_LIT:0> ] ) / ( extent [ <NUM_LIT:3> ] - extent [ <NUM_LIT:1> ] ) ) <EOL> height = <NUM_LIT> <EOL> else : <EOL> extent = ( <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , <NUM_LIT:0> , ) <EOL> width = <NUM_LIT:1> <EOL> height = <NUM_LIT:1> <EOL> mapserver = settings . MAP_SERVER if settings . MAP_SERVER != '<STR_LIT>' else request . META [ '<STR_LIT>' ] <EOL> context = { <EOL> '<STR_LIT>' : plans , <EOL> '<STR_LIT>' : mapserver , <EOL> '<STR_LIT>' : settings . MAP_SERVER_NS , <EOL> '<STR_LIT>' : extent , <EOL> '<STR_LIT:width>' : width , <EOL> '<STR_LIT>' : height <EOL> } <EOL> xml = feed . render ( DjangoContext ( context ) ) <EOL> return HttpResponse ( xml , mimetype = '<STR_LIT>' ) </s>
<s> url = '<STR_LIT>' <EOL> from functools import ( partial , reduce , wraps , <EOL> cmp_to_key ) <EOL> from functools import ( partial , reduce , wraps , <EOL> cmp_to_key ) <EOL> a = <NUM_LIT:1> <EOL> if a == None : <EOL> pass </s>
<s> DSIZE = <NUM_LIT:4> <EOL> SIZE = <NUM_LIT> <EOL> a_offset = <NUM_LIT:1> * <NUM_LIT> * <NUM_LIT> <EOL> b_offset = <NUM_LIT:2> * <NUM_LIT> * <NUM_LIT> <EOL> iochannel = CoramIoChannel ( idx = <NUM_LIT:0> , datawidth = <NUM_LIT:32> ) <EOL> mem0 = CoramMemory ( idx = <NUM_LIT:0> , datawidth = <NUM_LIT:8> * DSIZE , size = SIZE ) <EOL> mem1 = CoramMemory ( idx = <NUM_LIT:1> , datawidth = <NUM_LIT:8> * DSIZE , size = SIZE ) <EOL> mem2 = CoramMemory ( idx = <NUM_LIT:2> , datawidth = <NUM_LIT:8> * DSIZE , size = SIZE ) <EOL> mem3 = CoramMemory ( idx = <NUM_LIT:3> , datawidth = <NUM_LIT:8> * DSIZE , size = SIZE ) <EOL> mem_d0 = CoramMemory ( idx = <NUM_LIT:4> , datawidth = <NUM_LIT:8> * DSIZE , size = SIZE ) <EOL> mem_d1 = CoramMemory ( idx = <NUM_LIT:5> , datawidth = <NUM_LIT:8> * DSIZE , size = SIZE ) <EOL> channel = CoramChannel ( idx = <NUM_LIT:0> , datawidth = <NUM_LIT:8> * DSIZE ) <EOL> def st_set_mesh_size ( mesh_size ) : <EOL> channel . write ( mesh_size ) <EOL> def st_step ( mesh_size , read_start , write_start ) : <EOL> read_page = <NUM_LIT:3> <EOL> write_page = <NUM_LIT:0> <EOL> read_addr = read_start <EOL> mem0 . write ( <NUM_LIT:0> , read_addr , mesh_size ) <EOL> read_addr += mesh_size * DSIZE <EOL> mem1 . write ( <NUM_LIT:0> , read_addr , mesh_size ) <EOL> read_addr += mesh_size * DSIZE <EOL> mem2 . write ( <NUM_LIT:0> , read_addr , mesh_size ) <EOL> read_addr += mesh_size * DSIZE <EOL> write_addr = write_start + mesh_size * DSIZE + DSIZE <EOL> for i in range ( mesh_size - <NUM_LIT:2> ) : <EOL> hot_spot = <NUM_LIT:1> if i == <NUM_LIT:0> else <NUM_LIT:0> <EOL> pos = ( ( hot_spot << <NUM_LIT:6> ) | <EOL> ( ( <NUM_LIT> << write_page ) << <NUM_LIT:4> ) | <EOL> ( <NUM_LIT> << read_page ) ) <EOL> mem0 . wait ( ) <EOL> mem1 . wait ( ) <EOL> mem2 . wait ( ) <EOL> mem3 . wait ( ) <EOL> channel . write ( pos ) <EOL> if read_page == <NUM_LIT:0> : <EOL> mem0 . write_nonblocking ( <NUM_LIT:0> , read_addr , mesh_size ) <EOL> elif read_page == <NUM_LIT:1> : <EOL> mem1 . write_nonblocking ( <NUM_LIT:0> , read_addr , mesh_size ) <EOL> elif read_page == <NUM_LIT:2> : <EOL> mem2 . write_nonblocking ( <NUM_LIT:0> , read_addr , mesh_size ) <EOL> elif read_page == <NUM_LIT:3> : <EOL> mem3 . write_nonblocking ( <NUM_LIT:0> , read_addr , mesh_size ) <EOL> read_page = <NUM_LIT:0> if read_page == <NUM_LIT:3> else read_page + <NUM_LIT:1> <EOL> read_addr += mesh_size * DSIZE <EOL> channel . read ( ) <EOL> mem_d0 . wait ( ) <EOL> mem_d1 . wait ( ) <EOL> if write_page == <NUM_LIT:0> : <EOL> mem_d0 . read_nonblocking ( <NUM_LIT:1> , write_addr , mesh_size - <NUM_LIT:2> ) <EOL> elif write_page == <NUM_LIT:1> : <EOL> mem_d1 . read_nonblocking ( <NUM_LIT:1> , write_addr , mesh_size - <NUM_LIT:2> ) <EOL> write_addr += mesh_size * DSIZE <EOL> write_page = <NUM_LIT:0> if write_page == <NUM_LIT:1> else write_page + <NUM_LIT:1> <EOL> mem_d0 . wait ( ) <EOL> mem_d1 . wait ( ) <EOL> def st_computation ( num_iter , mesh_size ) : <EOL> for i in range ( num_iter / <NUM_LIT:2> ) : <EOL> st_step ( mesh_size , a_offset , b_offset ) <EOL> st_step ( mesh_size , b_offset , a_offset ) <EOL> def st_sum ( mesh_size ) : <EOL> check_sum = <NUM_LIT:0> <EOL> read_addr = a_offset <EOL> for i in range ( mesh_size ) : <EOL> mem0 . write ( <NUM_LIT:0> , read_addr , mesh_size ) <EOL> init_sum = <NUM_LIT:1> if i == <NUM_LIT:0> else <NUM_LIT:0> <EOL> calc_sum = <NUM_LIT:1> <EOL> pos = ( init_sum << <NUM_LIT:8> ) | ( calc_sum << <NUM_LIT:7> ) <EOL> channel . write ( pos ) <EOL> read_addr += mesh_size * DSIZE <EOL> check_sum = channel . read ( ) <EOL> channel . write ( <NUM_LIT:0> ) <EOL> return check_sum <EOL> def st_main ( ) : <EOL> global a_offset <EOL> global b_offset <EOL> mesh_size = iochannel . read ( ) <EOL> print ( "<STR_LIT>" % mesh_size ) <EOL> num_iter = iochannel . read ( ) <EOL> print ( "<STR_LIT>" % num_iter ) <EOL> a_offset = iochannel . read ( ) <EOL> print ( "<STR_LIT>" % a_offset ) <EOL> b_offset = iochannel . read ( ) <EOL> print ( "<STR_LIT>" % b_offset ) <EOL> print ( "<STR_LIT>" ) <EOL> st_set_mesh_size ( mesh_size ) <EOL> print ( "<STR_LIT>" ) <EOL> st_computation ( num_iter , mesh_size ) <EOL> print ( "<STR_LIT>" ) <EOL> check_sum = st_sum ( mesh_size ) <EOL> iochannel . write ( check_sum ) <EOL> while True : <EOL> st_main ( ) </s>
<s> DSIZE = <NUM_LIT:4> <EOL> SIZE = <NUM_LIT> <EOL> a_offset = <NUM_LIT:1> * <NUM_LIT> * <NUM_LIT> <EOL> b_offset = <NUM_LIT:2> * <NUM_LIT> * <NUM_LIT> <EOL> iochannel = CoramIoChannel ( idx = <NUM_LIT:0> , datawidth = <NUM_LIT:32> ) <EOL> mem0 = CoramMemory ( idx = <NUM_LIT:0> , datawidth = <NUM_LIT:8> * DSIZE , size = SIZE ) <EOL> mem1 = CoramMemory ( idx = <NUM_LIT:1> , datawidth = <NUM_LIT:8> * DSIZE , size = SIZE ) <EOL> mem2 = CoramMemory ( idx = <NUM_LIT:2> , datawidth = <NUM_LIT:8> * DSIZE , size = SIZE ) <EOL> mem_d0 = CoramMemory ( idx = <NUM_LIT:4> , datawidth = <NUM_LIT:8> * DSIZE , size = SIZE ) <EOL> channel = CoramChannel ( idx = <NUM_LIT:0> , datawidth = <NUM_LIT:8> * DSIZE ) <EOL> def st_set_mesh_size ( mesh_size ) : <EOL> channel . write ( mesh_size ) <EOL> def st_step ( mesh_size , read_start , write_start ) : <EOL> read_page = <NUM_LIT:0> <EOL> read_addr = read_start <EOL> mem0 . write ( <NUM_LIT:0> , read_addr , mesh_size ) <EOL> read_addr += mesh_size * DSIZE <EOL> mem1 . write ( <NUM_LIT:0> , read_addr , mesh_size ) <EOL> read_addr += mesh_size * DSIZE <EOL> mem2 . write ( <NUM_LIT:0> , read_addr , mesh_size ) <EOL> read_addr += mesh_size * DSIZE <EOL> write_addr = write_start + mesh_size * DSIZE + DSIZE <EOL> for i in range ( mesh_size - <NUM_LIT:2> ) : <EOL> hot_spot = <NUM_LIT:1> if i == <NUM_LIT:0> else <NUM_LIT:0> <EOL> pos = hot_spot <EOL> mem0 . wait ( ) <EOL> mem1 . wait ( ) <EOL> mem2 . wait ( ) <EOL> channel . write ( pos ) <EOL> channel . read ( ) <EOL> if read_page == <NUM_LIT:0> : <EOL> mem0 . write_nonblocking ( <NUM_LIT:0> , read_addr , mesh_size ) <EOL> elif read_page == <NUM_LIT:1> : <EOL> mem1 . write_nonblocking ( <NUM_LIT:0> , read_addr , mesh_size ) <EOL> elif read_page == <NUM_LIT:2> : <EOL> mem2 . write_nonblocking ( <NUM_LIT:0> , read_addr , mesh_size ) <EOL> read_page = <NUM_LIT:0> if read_page == <NUM_LIT:2> else read_page + <NUM_LIT:1> <EOL> read_addr += mesh_size * DSIZE <EOL> mem_d0 . read_nonblocking ( <NUM_LIT:1> , write_addr , mesh_size - <NUM_LIT:2> ) <EOL> write_addr += mesh_size * DSIZE <EOL> mem_d0 . wait ( ) <EOL> def st_computation ( num_iter , mesh_size ) : <EOL> for i in range ( num_iter / <NUM_LIT:2> ) : <EOL> st_step ( mesh_size , a_offset , b_offset ) <EOL> st_step ( mesh_size , b_offset , a_offset ) <EOL> def st_sum ( mesh_size ) : <EOL> check_sum = <NUM_LIT:0> <EOL> read_addr = a_offset <EOL> for i in range ( mesh_size ) : <EOL> mem0 . write ( <NUM_LIT:0> , read_addr , mesh_size ) <EOL> init_sum = <NUM_LIT:1> if i == <NUM_LIT:0> else <NUM_LIT:0> <EOL> calc_sum = <NUM_LIT:1> <EOL> pos = ( init_sum << <NUM_LIT:2> ) | ( calc_sum << <NUM_LIT:1> ) <EOL> channel . write ( pos ) <EOL> read_addr += mesh_size * DSIZE <EOL> check_sum = channel . read ( ) <EOL> channel . write ( <NUM_LIT> ) <EOL> return check_sum <EOL> def st_main ( ) : <EOL> global a_offset <EOL> global b_offset <EOL> mesh_size = iochannel . read ( ) <EOL> print ( "<STR_LIT>" % mesh_size ) <EOL> num_iter = iochannel . read ( ) <EOL> print ( "<STR_LIT>" % num_iter ) <EOL> a_offset = iochannel . read ( ) <EOL> print ( "<STR_LIT>" % a_offset ) <EOL> b_offset = iochannel . read ( ) <EOL> print ( "<STR_LIT>" % b_offset ) <EOL> print ( "<STR_LIT>" ) <EOL> st_set_mesh_size ( mesh_size ) <EOL> print ( "<STR_LIT>" ) <EOL> st_computation ( num_iter , mesh_size ) <EOL> print ( "<STR_LIT>" ) <EOL> check_sum = st_sum ( mesh_size ) <EOL> iochannel . write ( check_sum ) <EOL> while True : <EOL> st_main ( ) </s>
<s> from __future__ import absolute_import <EOL> from __future__ import print_function <EOL> import re <EOL> import sys <EOL> import os <EOL> def getRamId ( oid , sid ) : <EOL> if <NUM_LIT:0> <= sid and sid <= <NUM_LIT> : <EOL> return <NUM_LIT:0> <EOL> if <NUM_LIT:32> <= sid and sid <= <NUM_LIT> : <EOL> return <NUM_LIT:1> <EOL> if <NUM_LIT:64> <= sid and sid <= <NUM_LIT> : <EOL> return <NUM_LIT:2> <EOL> if <NUM_LIT> <= sid and sid <= <NUM_LIT> : <EOL> return <NUM_LIT:3> <EOL> def getRamSubId ( oid , sid ) : <EOL> if <NUM_LIT:0> <= sid and sid <= <NUM_LIT> : <EOL> return sid <EOL> if <NUM_LIT:32> <= sid and sid <= <NUM_LIT> : <EOL> return sid - <NUM_LIT:32> <EOL> if <NUM_LIT:64> <= sid and sid <= <NUM_LIT> : <EOL> return sid - <NUM_LIT:64> <EOL> if <NUM_LIT> <= sid and sid <= <NUM_LIT> : <EOL> return sid - <NUM_LIT> <EOL> def getChannelId ( oid , sid ) : <EOL> return oid <EOL> def getChannelSubId ( oid , sid ) : <EOL> return sid <EOL> def getRegisterId ( oid , sid ) : <EOL> return oid <EOL> def getRegisterSubId ( oid , sid ) : <EOL> return sid <EOL> def main ( ) : <EOL> f = open ( sys . argv [ <NUM_LIT:1> ] , '<STR_LIT:r>' ) <EOL> lines = f . readlines ( ) <EOL> output = [ ] <EOL> p_thread = re . compile ( '<STR_LIT>' ) <EOL> p_thread_id = re . compile ( '<STR_LIT>' ) <EOL> p_object_id = re . compile ( '<STR_LIT>' ) <EOL> p_width = re . compile ( '<STR_LIT>' ) <EOL> p_depth = re . compile ( '<STR_LIT>' ) <EOL> p_indexwidth = re . compile ( '<STR_LIT>' ) <EOL> p_logdepth = re . compile ( '<STR_LIT>' ) <EOL> p_sub_id = re . compile ( '<STR_LIT>' ) <EOL> module_name = None <EOL> thread_name = None <EOL> thread_id = None <EOL> object_id = None <EOL> sub_id = None <EOL> width = None <EOL> indexwidth = None <EOL> depth = None <EOL> mode = False <EOL> sub_id_num = None <EOL> sub_id_base = None <EOL> buffer = [ ] <EOL> print ( "<STR_LIT>" ) <EOL> for line in lines : <EOL> if not mode : <EOL> m = p_thread . match ( line ) <EOL> if m : <EOL> thread_name = re . match ( '<STR_LIT>' , m . group ( <NUM_LIT:2> ) ) . group ( <NUM_LIT:1> ) <EOL> module_name = re . search ( '<STR_LIT>' , line ) . group ( <NUM_LIT:1> ) <EOL> mode = True <EOL> buffer = [ ] <EOL> buffer . append ( line ) <EOL> continue <EOL> else : <EOL> m = p_thread_id . match ( line ) <EOL> if m : <EOL> tid_str = m . group ( <NUM_LIT:2> ) [ <NUM_LIT:1> : - <NUM_LIT:1> ] <EOL> thread_id = re . match ( '<STR_LIT>' , tid_str ) . group ( <NUM_LIT:2> ) <EOL> buffer . append ( line ) <EOL> continue <EOL> m = p_object_id . match ( line ) <EOL> if m : <EOL> oid_str = m . group ( <NUM_LIT:2> ) [ <NUM_LIT:1> : - <NUM_LIT:1> ] <EOL> object_id = re . match ( '<STR_LIT>' , oid_str ) . group ( <NUM_LIT:2> ) <EOL> buffer . append ( line ) <EOL> continue <EOL> m = p_width . match ( line ) <EOL> if m : <EOL> width_str = m . group ( <NUM_LIT:2> ) <EOL> width = re . match ( '<STR_LIT>' , width_str ) . group ( <NUM_LIT:1> ) <EOL> buffer . append ( line ) <EOL> continue <EOL> m = p_depth . match ( line ) <EOL> if m : <EOL> depth_str = m . group ( <NUM_LIT:2> ) <EOL> depth = re . match ( '<STR_LIT>' , depth_str ) . group ( <NUM_LIT:1> ) <EOL> buffer . append ( line ) <EOL> continue <EOL> m = p_indexwidth . match ( line ) <EOL> if m : <EOL> indexwidth_str = m . group ( <NUM_LIT:2> ) <EOL> indexwidth = re . match ( '<STR_LIT>' , indexwidth_str ) . group ( <NUM_LIT:1> ) <EOL> buffer . append ( line ) <EOL> continue <EOL> m = p_logdepth . match ( line ) <EOL> if m : <EOL> logdepth_str = m . group ( <NUM_LIT:2> ) <EOL> logdepth = re . match ( '<STR_LIT>' , logdepth_str ) . group ( <NUM_LIT:1> ) <EOL> buffer . append ( line ) <EOL> continue <EOL> m = p_sub_id . match ( line ) <EOL> if m : <EOL> sid_str = m . group ( <NUM_LIT:2> ) <EOL> sub_id_m = re . search ( '<STR_LIT>' , sid_str ) <EOL> sub_id = sub_id_m . group ( <NUM_LIT:0> ) <EOL> sub_id_num = sub_id_m . group ( <NUM_LIT:2> ) <EOL> sub_id_base = ( <NUM_LIT:10> if sub_id_m . group ( <NUM_LIT:1> ) . count ( "<STR_LIT>" ) > <NUM_LIT:0> else <EOL> <NUM_LIT:16> if sub_id_m . group ( <NUM_LIT:1> ) . count ( "<STR_LIT>" ) > <NUM_LIT:0> else <EOL> <NUM_LIT:2> if sub_id_m . group ( <NUM_LIT:1> ) . count ( "<STR_LIT>" ) > <NUM_LIT:0> else <EOL> <NUM_LIT:10> ) <EOL> buffer . append ( line ) <EOL> continue <EOL> if mode : <EOL> print ( "<STR_LIT>" % module_name ) <EOL> print ( "<STR_LIT>" % '<STR_LIT>' . join ( ( thread_name [ : - <NUM_LIT:1> ] , '<STR_LIT:_>' , thread_id , '<STR_LIT:">' ) ) ) <EOL> print ( "<STR_LIT>" % thread_id ) <EOL> if module_name . count ( '<STR_LIT>' ) > <NUM_LIT:0> : <EOL> print ( "<STR_LIT>" % getRamId ( int ( object_id ) , int ( sub_id_num , sub_id_base ) ) ) <EOL> if module_name . count ( '<STR_LIT>' ) > <NUM_LIT:0> : <EOL> print ( "<STR_LIT>" % getChannelId ( int ( object_id ) , int ( sub_id_num , sub_id_base ) ) ) <EOL> if module_name . count ( '<STR_LIT>' ) > <NUM_LIT:0> : <EOL> print ( "<STR_LIT>" % getRegisterId ( int ( object_id ) , int ( sub_id_num , sub_id_base ) ) ) <EOL> if module_name . count ( '<STR_LIT>' ) > <NUM_LIT:0> : <EOL> print ( "<STR_LIT>" % getRamSubId ( int ( object_id ) , int ( sub_id_num , sub_id_base ) ) ) <EOL> if module_name . count ( '<STR_LIT>' ) > <NUM_LIT:0> : <EOL> print ( "<STR_LIT>" % '<STR_LIT:0>' ) <EOL> if module_name . count ( '<STR_LIT>' ) > <NUM_LIT:0> : <EOL> print ( "<STR_LIT>" % '<STR_LIT:0>' ) <EOL> print ( "<STR_LIT>" % indexwidth ) <EOL> print ( "<STR_LIT>" % width ) <EOL> print ( "<STR_LIT>" % thread_name ) <EOL> print ( '<STR_LIT>' . join ( buffer [ <NUM_LIT:1> : ] ) ) <EOL> mode = False <EOL> print ( line , end = '<STR_LIT>' ) <EOL> main ( ) </s>
<s> from __future__ import absolute_import <EOL> from __future__ import print_function <EOL> import sys <EOL> import os <EOL> from optparse import OptionParser <EOL> sys . path . insert ( <NUM_LIT:0> , os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) ) <EOL> import pyverilog . utils . version <EOL> from pyverilog . dataflow . dataflow_analyzer import VerilogDataflowAnalyzer <EOL> def main ( ) : <EOL> INFO = "<STR_LIT>" <EOL> VERSION = pyverilog . utils . version . VERSION <EOL> USAGE = "<STR_LIT>" <EOL> def showVersion ( ) : <EOL> print ( INFO ) <EOL> print ( VERSION ) <EOL> print ( USAGE ) <EOL> sys . exit ( ) <EOL> optparser = OptionParser ( ) <EOL> optparser . add_option ( "<STR_LIT>" , "<STR_LIT>" , action = "<STR_LIT:store_true>" , dest = "<STR_LIT>" , <EOL> default = False , help = "<STR_LIT>" ) <EOL> optparser . add_option ( "<STR_LIT>" , "<STR_LIT>" , dest = "<STR_LIT>" , action = "<STR_LIT>" , <EOL> default = [ ] , help = "<STR_LIT>" ) <EOL> optparser . add_option ( "<STR_LIT>" , dest = "<STR_LIT>" , action = "<STR_LIT>" , <EOL> default = [ ] , help = "<STR_LIT>" ) <EOL> optparser . add_option ( "<STR_LIT>" , "<STR_LIT>" , dest = "<STR_LIT>" , <EOL> default = "<STR_LIT>" , help = "<STR_LIT>" ) <EOL> optparser . add_option ( "<STR_LIT>" , action = "<STR_LIT:store_true>" , dest = "<STR_LIT>" , <EOL> default = False , help = "<STR_LIT>" ) <EOL> optparser . add_option ( "<STR_LIT>" , action = "<STR_LIT:store_true>" , dest = "<STR_LIT>" , <EOL> default = False , help = "<STR_LIT>" ) <EOL> ( options , args ) = optparser . parse_args ( ) <EOL> filelist = args <EOL> if options . showversion : <EOL> showVersion ( ) <EOL> for f in filelist : <EOL> if not os . path . exists ( f ) : raise IOError ( "<STR_LIT>" + f ) <EOL> if len ( filelist ) == <NUM_LIT:0> : <EOL> showVersion ( ) <EOL> analyzer = VerilogDataflowAnalyzer ( filelist , options . topmodule , <EOL> noreorder = options . noreorder , <EOL> nobind = options . nobind , <EOL> preprocess_include = options . include , <EOL> preprocess_define = options . define ) <EOL> analyzer . generate ( ) <EOL> directives = analyzer . get_directives ( ) <EOL> print ( '<STR_LIT>' ) <EOL> for dr in sorted ( directives , key = lambda x : str ( x ) ) : <EOL> print ( dr ) <EOL> instances = analyzer . getInstances ( ) <EOL> print ( '<STR_LIT>' ) <EOL> for module , instname in sorted ( instances , key = lambda x : str ( x [ <NUM_LIT:1> ] ) ) : <EOL> print ( ( module , instname ) ) <EOL> if options . nobind : <EOL> print ( '<STR_LIT>' ) <EOL> signals = analyzer . getSignals ( ) <EOL> for sig in signals : <EOL> print ( sig ) <EOL> print ( '<STR_LIT>' ) <EOL> consts = analyzer . getConsts ( ) <EOL> for con in consts : <EOL> print ( con ) <EOL> else : <EOL> terms = analyzer . getTerms ( ) <EOL> print ( '<STR_LIT>' ) <EOL> for tk , tv in sorted ( terms . items ( ) , key = lambda x : str ( x [ <NUM_LIT:0> ] ) ) : <EOL> print ( tv . tostr ( ) ) <EOL> binddict = analyzer . getBinddict ( ) <EOL> print ( '<STR_LIT>' ) <EOL> for bk , bv in sorted ( binddict . items ( ) , key = lambda x : str ( x [ <NUM_LIT:0> ] ) ) : <EOL> for bvi in bv : <EOL> print ( bvi . tostr ( ) ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> main ( ) </s>
<s> from __future__ import absolute_import <EOL> from __future__ import print_function <EOL> import sys <EOL> import os <EOL> from pyverilog . dataflow . dataflow import * <EOL> def replaceUndefined ( tree , termname ) : <EOL> if tree is None : return DFTerminal ( termname ) <EOL> if isinstance ( tree , DFUndefined ) : return DFTerminal ( termname ) <EOL> if isinstance ( tree , DFConstant ) : return tree <EOL> if isinstance ( tree , DFEvalValue ) : return tree <EOL> if isinstance ( tree , DFTerminal ) : return tree <EOL> if isinstance ( tree , DFBranch ) : <EOL> condnode = replaceUndefined ( tree . condnode , termname ) <EOL> truenode = replaceUndefined ( tree . truenode , termname ) <EOL> falsenode = replaceUndefined ( tree . falsenode , termname ) <EOL> return DFBranch ( condnode , truenode , falsenode ) <EOL> if isinstance ( tree , DFOperator ) : <EOL> nextnodes = [ ] <EOL> for n in tree . nextnodes : <EOL> nextnodes . append ( replaceUndefined ( n , termname ) ) <EOL> return DFOperator ( tuple ( nextnodes ) , tree . operator ) <EOL> if isinstance ( tree , DFPartselect ) : <EOL> msb = replaceUndefined ( tree . msb , termname ) <EOL> lsb = replaceUndefined ( tree . lsb , termname ) <EOL> var = replaceUndefined ( tree . var , termname ) <EOL> return DFPartselect ( var , msb , lsb ) <EOL> if isinstance ( tree , DFPointer ) : <EOL> ptr = replaceUndefined ( tree . ptr , termname ) <EOL> var = replaceUndefined ( tree . var , termname ) <EOL> return DFPointer ( var , ptr ) <EOL> if isinstance ( tree , DFConcat ) : <EOL> nextnodes = [ ] <EOL> for n in tree . nextnodes : <EOL> nextnodes . append ( replaceUndefined ( n , termname ) ) <EOL> return DFConcat ( tuple ( nextnodes ) ) <EOL> raise DefinitionError ( '<STR_LIT>' % ( str ( type ( tree ) ) , str ( tree ) ) ) </s>
<s> from __future__ import absolute_import <EOL> from __future__ import print_function <EOL> import os <EOL> import sys <EOL> from pyverilog . dataflow . dataflow_analyzer import VerilogDataflowAnalyzer <EOL> from pyverilog . dataflow . optimizer import VerilogDataflowOptimizer <EOL> from pyverilog . controlflow . controlflow_analyzer import VerilogControlflowAnalyzer <EOL> codedir = os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) ) + '<STR_LIT>' <EOL> expected = """<STR_LIT>""" <EOL> def test ( ) : <EOL> filelist = [ codedir + '<STR_LIT>' ] <EOL> topmodule = '<STR_LIT>' <EOL> noreorder = False <EOL> nobind = False <EOL> include = None <EOL> define = None <EOL> analyzer = VerilogDataflowAnalyzer ( filelist , topmodule , <EOL> noreorder = noreorder , <EOL> nobind = nobind , <EOL> preprocess_include = include , <EOL> preprocess_define = define ) <EOL> analyzer . generate ( ) <EOL> directives = analyzer . get_directives ( ) <EOL> instances = analyzer . getInstances ( ) <EOL> terms = analyzer . getTerms ( ) <EOL> binddict = analyzer . getBinddict ( ) <EOL> optimizer = VerilogDataflowOptimizer ( terms , binddict ) <EOL> optimizer . resolveConstant ( ) <EOL> c_analyzer = VerilogControlflowAnalyzer ( topmodule , terms , <EOL> binddict , <EOL> resolved_terms = optimizer . getResolvedTerms ( ) , <EOL> resolved_binddict = optimizer . getResolvedBinddict ( ) , <EOL> constlist = optimizer . getConstlist ( ) <EOL> ) <EOL> output = [ ] <EOL> for tk in sorted ( c_analyzer . resolved_terms . keys ( ) , key = lambda x : str ( x ) ) : <EOL> tree = c_analyzer . makeTree ( tk ) <EOL> output . append ( str ( tk ) + '<STR_LIT>' + tree . tocode ( ) ) <EOL> rslt = '<STR_LIT:\n>' . join ( output ) + '<STR_LIT:\n>' <EOL> print ( rslt ) <EOL> assert ( expected == rslt ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> test ( ) </s>
<s> from __future__ import absolute_import <EOL> from __future__ import print_function <EOL> import dataflow_example <EOL> expected_verilog = """<STR_LIT>""" <EOL> def test ( ) : <EOL> test_module = dataflow_example . mkTest ( ) <EOL> code = test_module . to_verilog ( ) <EOL> from pyverilog . vparser . parser import VerilogParser <EOL> from pyverilog . ast_code_generator . codegen import ASTCodeGenerator <EOL> parser = VerilogParser ( ) <EOL> expected_ast = parser . parse ( expected_verilog ) <EOL> codegen = ASTCodeGenerator ( ) <EOL> expected_code = codegen . visit ( expected_ast ) <EOL> assert ( expected_code == code ) </s>
<s> from __future__ import absolute_import <EOL> from __future__ import print_function <EOL> import sys <EOL> import os <EOL> sys . path . insert ( <NUM_LIT:0> , os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) ) ) <EOL> from veriloggen import * <EOL> def mkLed ( ) : <EOL> m = Module ( '<STR_LIT>' ) <EOL> interval = m . Parameter ( '<STR_LIT>' , <NUM_LIT:16> ) <EOL> clk = m . Input ( '<STR_LIT>' ) <EOL> rst = m . Input ( '<STR_LIT>' ) <EOL> led = m . OutputReg ( '<STR_LIT>' , <NUM_LIT:8> , initval = <NUM_LIT:0> ) <EOL> count = m . Reg ( '<STR_LIT:count>' , <NUM_LIT:32> , initval = <NUM_LIT:0> ) <EOL> seq = Seq ( m , '<STR_LIT>' , clk , rst ) <EOL> seq . add ( Systask ( '<STR_LIT>' , '<STR_LIT>' , led , count ) ) <EOL> seq . add ( count ( count + <NUM_LIT:1> ) , cond = count < interval - <NUM_LIT:1> ) <EOL> seq . add ( count ( <NUM_LIT:0> ) , cond = count == interval - <NUM_LIT:1> ) <EOL> seq . add ( led ( led + <NUM_LIT:1> ) , cond = count == interval - <NUM_LIT:1> ) <EOL> seq . make_always ( ) <EOL> return m <EOL> def mkTest ( ) : <EOL> m = Module ( '<STR_LIT:test>' ) <EOL> led = mkLed ( ) <EOL> params = m . copy_params ( led ) <EOL> ports = m . copy_sim_ports ( led ) <EOL> clk = ports [ '<STR_LIT>' ] <EOL> rst = ports [ '<STR_LIT>' ] <EOL> uut = m . Instance ( led , '<STR_LIT>' , <EOL> params = m . connect_params ( led ) , <EOL> ports = m . connect_ports ( led ) ) <EOL> simulation . setup_clock ( m , clk , hperiod = <NUM_LIT:5> ) <EOL> init = simulation . setup_reset ( m , rst , m . make_reset ( ) , period = <NUM_LIT:100> ) <EOL> init . add ( <EOL> Delay ( <NUM_LIT:1000> ) , <EOL> Systask ( '<STR_LIT>' ) , <EOL> ) <EOL> return m <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> test = mkTest ( ) <EOL> verilog = test . to_verilog ( ) <EOL> print ( verilog ) </s>
<s> from __future__ import absolute_import <EOL> from __future__ import print_function <EOL> import sys <EOL> import os <EOL> sys . path . insert ( <NUM_LIT:0> , os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) ) ) ) <EOL> from veriloggen import * <EOL> def mkLed ( ) : <EOL> m = Module ( '<STR_LIT>' ) <EOL> width = m . Parameter ( '<STR_LIT>' , <NUM_LIT:8> ) <EOL> clk = m . Input ( '<STR_LIT>' ) <EOL> rst = m . Input ( '<STR_LIT>' ) <EOL> led = m . OutputReg ( '<STR_LIT>' , width ) <EOL> count = m . Reg ( '<STR_LIT:count>' , <NUM_LIT:32> ) <EOL> m . Always ( Posedge ( clk ) ) ( <EOL> If ( rst ) ( <EOL> count ( <NUM_LIT:0> ) <EOL> ) . Else ( <EOL> count ( Cond ( count == <NUM_LIT> , <NUM_LIT:0> , count + <NUM_LIT:1> ) ) <EOL> ) ) <EOL> m . Always ( Posedge ( clk ) ) ( <EOL> If ( rst ) ( <EOL> led ( <NUM_LIT:0> ) <EOL> ) . Else ( <EOL> led ( Cond ( count == <NUM_LIT> - <NUM_LIT:1> , led + <NUM_LIT:1> , led ) ) <EOL> ) ) <EOL> return m <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> led = mkLed ( ) <EOL> verilog = led . to_verilog ( '<STR_LIT>' ) <EOL> print ( verilog ) </s>
<s> from __future__ import absolute_import <EOL> from __future__ import print_function <EOL> import sys <EOL> import os <EOL> sys . path . insert ( <NUM_LIT:0> , os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) ) ) ) ) <EOL> from veriloggen import * <EOL> def mkSub ( ) : <EOL> m = Module ( '<STR_LIT>' ) <EOL> clk = m . Input ( '<STR_LIT>' ) <EOL> rst = m . Input ( '<STR_LIT>' ) <EOL> count = m . OutputReg ( '<STR_LIT:count>' , <NUM_LIT:32> ) <EOL> m . Always ( Posedge ( clk ) ) ( <EOL> If ( rst ) ( <EOL> count ( <NUM_LIT:0> ) <EOL> ) . Else ( <EOL> If ( count == <NUM_LIT> ) ( <EOL> count ( <NUM_LIT:0> ) <EOL> ) . Else ( <EOL> count ( count + <NUM_LIT:1> ) <EOL> ) <EOL> ) ) <EOL> return m <EOL> def mkLed ( ) : <EOL> m = Module ( '<STR_LIT>' ) <EOL> width = m . Parameter ( '<STR_LIT>' , <NUM_LIT:8> ) <EOL> clk = m . Input ( '<STR_LIT>' ) <EOL> rst = m . Input ( '<STR_LIT>' ) <EOL> led = m . OutputReg ( '<STR_LIT>' , width ) <EOL> count = m . Wire ( '<STR_LIT:count>' , <NUM_LIT:32> ) <EOL> sub = mkSub ( ) <EOL> m . Instance ( sub , '<STR_LIT>' , m . connect_params ( sub ) , m . connect_ports ( sub ) ) <EOL> m . Always ( Posedge ( clk ) ) ( <EOL> If ( rst ) ( <EOL> led ( <NUM_LIT:0> ) <EOL> ) . Else ( <EOL> If ( count == <NUM_LIT> ) ( <EOL> led ( led + <NUM_LIT:1> ) <EOL> ) <EOL> ) ) <EOL> inst_sub = m . Reg ( '<STR_LIT>' , <NUM_LIT:32> ) <EOL> return m <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> try : <EOL> led = mkLed ( ) <EOL> except ValueError as e : <EOL> print ( e . args [ <NUM_LIT:0> ] ) <EOL> print ( '<STR_LIT>' ) <EOL> sys . exit ( ) <EOL> raise ValueError ( "<STR_LIT>" ) </s>
<s> from __future__ import absolute_import <EOL> from __future__ import print_function <EOL> import sys <EOL> import os <EOL> sys . path . insert ( <NUM_LIT:0> , os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) ) ) ) <EOL> from veriloggen import * <EOL> def mkLed ( ) : <EOL> m = Module ( '<STR_LIT>' ) <EOL> width = m . Parameter ( '<STR_LIT>' , <NUM_LIT:8> ) <EOL> clk = m . Input ( '<STR_LIT>' ) <EOL> rst = m . Input ( '<STR_LIT>' ) <EOL> led = m . OutputReg ( '<STR_LIT>' , width ) <EOL> count = m . Reg ( '<STR_LIT:count>' , <NUM_LIT:32> ) <EOL> m . Always ( Posedge ( clk ) ) ( <EOL> If ( rst ) ( <EOL> count ( <NUM_LIT:0> ) <EOL> ) . Else ( <EOL> If ( count == <NUM_LIT> ) ( <EOL> count ( <NUM_LIT:0> ) <EOL> ) . Else ( <EOL> count ( count + <NUM_LIT:1> ) <EOL> ) <EOL> ) ) <EOL> m . Always ( Posedge ( clk ) ) ( <EOL> If ( rst ) ( <EOL> led ( <NUM_LIT:0> ) <EOL> ) . Else ( <EOL> If ( count == <NUM_LIT> - <NUM_LIT:1> ) ( <EOL> led ( led + <NUM_LIT:1> ) , <EOL> SingleStatement ( SystemTask ( '<STR_LIT>' , '<STR_LIT>' , led ) ) <EOL> ) <EOL> ) ) <EOL> return m <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> led = mkLed ( ) <EOL> verilog = led . to_verilog ( ) <EOL> print ( verilog ) </s>
<s> from __future__ import absolute_import <EOL> from __future__ import print_function <EOL> import sys <EOL> import os <EOL> sys . path . insert ( <NUM_LIT:0> , os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) ) ) ) ) <EOL> from veriloggen import * <EOL> import veriloggen . dataflow as dataflow <EOL> def mkMain ( ) : <EOL> x = dataflow . Variable ( '<STR_LIT>' , valid = '<STR_LIT>' , ready = '<STR_LIT>' , point = <NUM_LIT:8> ) <EOL> y = dataflow . Variable ( '<STR_LIT>' , valid = '<STR_LIT>' , ready = '<STR_LIT>' , point = <NUM_LIT:4> ) <EOL> z = x * y <EOL> z . output ( '<STR_LIT>' , valid = '<STR_LIT>' , ready = '<STR_LIT>' ) <EOL> df = dataflow . Dataflow ( z ) <EOL> m = df . to_module ( '<STR_LIT>' ) <EOL> return m <EOL> def mkTest ( ) : <EOL> m = Module ( '<STR_LIT:test>' ) <EOL> main = mkMain ( ) <EOL> params = m . copy_params ( main ) <EOL> ports = m . copy_sim_ports ( main ) <EOL> clk = ports [ '<STR_LIT>' ] <EOL> rst = ports [ '<STR_LIT>' ] <EOL> xdata = ports [ '<STR_LIT>' ] <EOL> xvalid = ports [ '<STR_LIT>' ] <EOL> xready = ports [ '<STR_LIT>' ] <EOL> ydata = ports [ '<STR_LIT>' ] <EOL> yvalid = ports [ '<STR_LIT>' ] <EOL> yready = ports [ '<STR_LIT>' ] <EOL> zdata = ports [ '<STR_LIT>' ] <EOL> zvalid = ports [ '<STR_LIT>' ] <EOL> zready = ports [ '<STR_LIT>' ] <EOL> xdata_orig = m . RegLike ( ports [ '<STR_LIT>' ] , name = '<STR_LIT>' , initval = <NUM_LIT:0> ) <EOL> ydata_orig = m . RegLike ( ports [ '<STR_LIT>' ] , name = '<STR_LIT>' , initval = <NUM_LIT:0> ) <EOL> zdata_orig = m . WireLike ( ports [ '<STR_LIT>' ] , name = '<STR_LIT>' ) <EOL> m . Always ( ) ( xdata ( fixed . to_fixed ( xdata_orig , <NUM_LIT:8> ) ) ) <EOL> m . Always ( ) ( ydata ( fixed . to_fixed ( ydata_orig , <NUM_LIT:4> ) ) ) <EOL> m . Assign ( zdata_orig ( fixed . fixed_to_int ( zdata , <NUM_LIT:8> ) ) ) <EOL> uut = m . Instance ( main , '<STR_LIT>' , <EOL> params = m . connect_params ( main ) , <EOL> ports = m . connect_ports ( main ) ) <EOL> reset_done = m . Reg ( '<STR_LIT>' , initval = <NUM_LIT:0> ) <EOL> reset_stmt = [ ] <EOL> reset_stmt . append ( reset_done ( <NUM_LIT:0> ) ) <EOL> reset_stmt . append ( xdata ( <NUM_LIT:0> ) ) <EOL> reset_stmt . append ( xvalid ( <NUM_LIT:0> ) ) <EOL> reset_stmt . append ( ydata ( <NUM_LIT:0> ) ) <EOL> reset_stmt . append ( yvalid ( <NUM_LIT:0> ) ) <EOL> reset_stmt . append ( zready ( <NUM_LIT:0> ) ) <EOL> reset_stmt . append ( xdata_orig ( <NUM_LIT:0> ) ) <EOL> reset_stmt . append ( ydata_orig ( <NUM_LIT:0> ) ) <EOL> simulation . setup_waveform ( m , uut , xdata_orig , ydata_orig , zdata_orig ) <EOL> simulation . setup_clock ( m , clk , hperiod = <NUM_LIT:5> ) <EOL> init = simulation . setup_reset ( m , rst , reset_stmt , period = <NUM_LIT:100> ) <EOL> nclk = simulation . next_clock <EOL> init . add ( <EOL> Delay ( <NUM_LIT:1000> ) , <EOL> reset_done ( <NUM_LIT:1> ) , <EOL> nclk ( clk ) , <EOL> Delay ( <NUM_LIT> ) , <EOL> Systask ( '<STR_LIT>' ) , <EOL> ) <EOL> def send ( name , data , valid , ready , step = <NUM_LIT:1> , waitnum = <NUM_LIT:10> ) : <EOL> fsm = FSM ( m , name + '<STR_LIT>' , clk , rst ) <EOL> count = m . TmpReg ( <NUM_LIT:32> , initval = <NUM_LIT:0> ) <EOL> fsm . add ( valid ( <NUM_LIT:0> ) ) <EOL> fsm . goto_next ( cond = reset_done ) <EOL> for _ in range ( waitnum ) : <EOL> fsm . goto_next ( ) <EOL> fsm . add ( valid ( <NUM_LIT:1> ) ) <EOL> fsm . goto_next ( ) <EOL> fsm . add ( data ( data + step ) , cond = ready ) <EOL> fsm . add ( count . inc ( ) , cond = ready ) <EOL> fsm . add ( valid ( <NUM_LIT:0> ) , cond = AndList ( count == <NUM_LIT:5> , ready ) ) <EOL> fsm . goto_next ( cond = AndList ( count == <NUM_LIT:5> , ready ) ) <EOL> for _ in range ( waitnum ) : <EOL> fsm . goto_next ( ) <EOL> fsm . add ( valid ( <NUM_LIT:1> ) ) <EOL> fsm . add ( data ( data + step ) , cond = ready ) <EOL> fsm . add ( count . inc ( ) , cond = ready ) <EOL> fsm . add ( valid ( <NUM_LIT:0> ) , cond = AndList ( count == <NUM_LIT:10> , ready ) ) <EOL> fsm . goto_next ( cond = AndList ( count == <NUM_LIT:10> , ready ) ) <EOL> fsm . make_always ( ) <EOL> def receive ( name , data , valid , ready , waitnum = <NUM_LIT:10> ) : <EOL> fsm = FSM ( m , name + '<STR_LIT>' , clk , rst ) <EOL> fsm . add ( ready ( <NUM_LIT:0> ) ) <EOL> fsm . goto_next ( cond = reset_done ) <EOL> fsm . goto_next ( ) <EOL> yinit = fsm . current ( ) <EOL> fsm . add ( ready ( <NUM_LIT:1> ) , cond = valid ) <EOL> fsm . goto_next ( cond = valid ) <EOL> for i in range ( waitnum ) : <EOL> fsm . add ( ready ( <NUM_LIT:0> ) ) <EOL> fsm . goto_next ( ) <EOL> fsm . goto ( yinit ) <EOL> fsm . make_always ( ) <EOL> send ( '<STR_LIT:x>' , xdata_orig , xvalid , xready , step = <NUM_LIT:1> , waitnum = <NUM_LIT:10> ) <EOL> send ( '<STR_LIT:y>' , ydata_orig , yvalid , yready , step = <NUM_LIT:1> , waitnum = <NUM_LIT:20> ) <EOL> receive ( '<STR_LIT:z>' , zdata , zvalid , zready , waitnum = <NUM_LIT:50> ) <EOL> m . Always ( Posedge ( clk ) ) ( <EOL> If ( reset_done ) ( <EOL> If ( AndList ( xvalid , xready ) ) ( <EOL> Systask ( '<STR_LIT>' , '<STR_LIT>' , xdata_orig ) <EOL> ) , <EOL> If ( AndList ( yvalid , yready ) ) ( <EOL> Systask ( '<STR_LIT>' , '<STR_LIT>' , ydata_orig ) <EOL> ) , <EOL> If ( AndList ( zvalid , zready ) ) ( <EOL> Systask ( '<STR_LIT>' , '<STR_LIT>' , zdata_orig ) <EOL> ) <EOL> ) <EOL> ) <EOL> return m <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> test = mkTest ( ) <EOL> verilog = test . to_verilog ( '<STR_LIT>' ) <EOL> print ( verilog ) <EOL> sim = simulation . Simulator ( test ) <EOL> rslt = sim . run ( ) <EOL> print ( rslt ) </s>
<s> from __future__ import absolute_import <EOL> from __future__ import print_function <EOL> import dataflow_mul <EOL> expected_verilog = """<STR_LIT>""" <EOL> def test ( ) : <EOL> test_module = dataflow_mul . mkTest ( ) <EOL> code = test_module . to_verilog ( ) <EOL> from pyverilog . vparser . parser import VerilogParser <EOL> from pyverilog . ast_code_generator . codegen import ASTCodeGenerator <EOL> parser = VerilogParser ( ) <EOL> expected_ast = parser . parse ( expected_verilog ) <EOL> codegen = ASTCodeGenerator ( ) <EOL> expected_code = codegen . visit ( expected_ast ) <EOL> assert ( expected_code == code ) </s>
<s> from __future__ import absolute_import <EOL> from __future__ import print_function <EOL> import sys <EOL> import os <EOL> sys . path . insert ( <NUM_LIT:0> , os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) ) ) ) ) <EOL> from veriloggen import * <EOL> def mkLed ( ) : <EOL> m = Module ( '<STR_LIT>' ) <EOL> clk = m . Input ( '<STR_LIT>' ) <EOL> rst = m . Input ( '<STR_LIT>' ) <EOL> valid = m . OutputReg ( '<STR_LIT>' , initval = <NUM_LIT:0> ) <EOL> count = m . Reg ( '<STR_LIT:count>' , width = <NUM_LIT:32> , initval = <NUM_LIT:0> ) <EOL> up = m . Wire ( '<STR_LIT>' ) <EOL> down = m . Wire ( '<STR_LIT>' ) <EOL> m . Assign ( up ( <NUM_LIT:1> ) ) <EOL> m . Assign ( down ( <NUM_LIT:0> ) ) <EOL> fsm = FSM ( m , '<STR_LIT>' , clk , rst ) <EOL> for i in range ( <NUM_LIT:4> ) : <EOL> fsm . goto_next ( ) <EOL> c = count >= <NUM_LIT:16> <EOL> fsm . add ( valid ( up ) , cond = c , keep = <NUM_LIT:3> , eager_val = True , lazy_cond = True ) <EOL> fsm . add ( valid ( down ) , cond = c , delay = <NUM_LIT:3> , eager_val = True , lazy_cond = True ) <EOL> fsm . goto_next ( cond = c ) <EOL> for i in range ( <NUM_LIT:8> ) : <EOL> fsm . goto_next ( ) <EOL> c = count >= <NUM_LIT:32> <EOL> for i in range ( <NUM_LIT:8> ) : <EOL> fsm . add ( valid ( up ) , cond = c , delay = <NUM_LIT:1> , keep = <NUM_LIT:3> , eager_val = True , lazy_cond = True ) <EOL> fsm . add ( valid ( down ) , cond = c , delay = <NUM_LIT:4> , eager_val = True , lazy_cond = True ) <EOL> fsm . goto_next ( cond = c ) <EOL> fsm . make_always ( reset = [ count . reset ( ) ] , body = [ count ( count + <NUM_LIT:1> ) ] ) <EOL> return m <EOL> def mkTest ( ) : <EOL> m = Module ( '<STR_LIT:test>' ) <EOL> clk = m . Reg ( '<STR_LIT>' ) <EOL> rst = m . Reg ( '<STR_LIT>' ) <EOL> valid = m . Wire ( '<STR_LIT>' ) <EOL> uut = m . Instance ( mkLed ( ) , '<STR_LIT>' , <EOL> ports = ( ( '<STR_LIT>' , clk ) , ( '<STR_LIT>' , rst ) , ( '<STR_LIT>' , valid ) ) ) <EOL> simulation . setup_waveform ( m , uut ) <EOL> simulation . setup_clock ( m , clk , hperiod = <NUM_LIT:5> ) <EOL> init = simulation . setup_reset ( m , rst , period = <NUM_LIT:100> ) <EOL> init . add ( <EOL> Delay ( <NUM_LIT:1000> ) , <EOL> Systask ( '<STR_LIT>' ) , <EOL> ) <EOL> return m <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> test = mkTest ( ) <EOL> verilog = test . to_verilog ( '<STR_LIT>' ) <EOL> print ( verilog ) </s>
<s> from __future__ import absolute_import <EOL> from __future__ import print_function <EOL> import pipeline_draw_graph <EOL> expected_verilog = """<STR_LIT>""" <EOL> def test ( ) : <EOL> test_module = pipeline_draw_graph . mkTest ( ) <EOL> code = test_module . to_verilog ( ) <EOL> from pyverilog . vparser . parser import VerilogParser <EOL> from pyverilog . ast_code_generator . codegen import ASTCodeGenerator <EOL> parser = VerilogParser ( ) <EOL> expected_ast = parser . parse ( expected_verilog ) <EOL> codegen = ASTCodeGenerator ( ) <EOL> expected_code = codegen . visit ( expected_ast ) <EOL> assert ( expected_code == code ) </s>
<s> from __future__ import absolute_import <EOL> from __future__ import print_function <EOL> import sys <EOL> import os <EOL> sys . path . insert ( <NUM_LIT:0> , os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) ) ) ) ) <EOL> from veriloggen import * <EOL> def mkLed ( ) : <EOL> m = Module ( '<STR_LIT>' ) <EOL> interval = m . Parameter ( '<STR_LIT>' , <NUM_LIT:16> ) <EOL> clk = m . Input ( '<STR_LIT>' ) <EOL> rst = m . Input ( '<STR_LIT>' ) <EOL> led = m . OutputReg ( '<STR_LIT>' , <NUM_LIT:8> , initval = <NUM_LIT:0> ) <EOL> count = m . Reg ( '<STR_LIT:count>' , <NUM_LIT:32> , initval = <NUM_LIT:0> ) <EOL> seq = Seq ( m , '<STR_LIT>' , clk , rst ) <EOL> seq . add ( Systask ( '<STR_LIT>' , '<STR_LIT>' , led , count ) ) <EOL> seq . add ( count ( count + <NUM_LIT:1> ) , cond = count < interval - <NUM_LIT:1> ) <EOL> seq . add ( count ( <NUM_LIT:0> ) , cond = count == interval - <NUM_LIT:1> ) <EOL> seq . add ( led ( led + <NUM_LIT:1> ) , cond = count == interval - <NUM_LIT:1> ) <EOL> seq . make_always ( ) <EOL> return m <EOL> def mkTest ( ) : <EOL> m = Module ( '<STR_LIT:test>' ) <EOL> led = mkLed ( ) <EOL> params = m . copy_params ( led ) <EOL> ports = m . copy_sim_ports ( led ) <EOL> clk = ports [ '<STR_LIT>' ] <EOL> rst = ports [ '<STR_LIT>' ] <EOL> uut = m . Instance ( led , '<STR_LIT>' , <EOL> params = m . connect_params ( led ) , <EOL> ports = m . connect_ports ( led ) ) <EOL> simulation . setup_clock ( m , clk , hperiod = <NUM_LIT:5> ) <EOL> init = simulation . setup_reset ( m , rst , m . make_reset ( ) , period = <NUM_LIT:100> ) <EOL> init . add ( <EOL> Delay ( <NUM_LIT:1000> ) , <EOL> Systask ( '<STR_LIT>' ) , <EOL> ) <EOL> return m <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> test = mkTest ( ) <EOL> verilog = test . to_verilog ( ) <EOL> print ( verilog ) </s>
<s> from __future__ import absolute_import <EOL> from __future__ import print_function <EOL> import read_verilog_module_str <EOL> expected_verilog = """<STR_LIT>""" <EOL> def test ( ) : <EOL> test_module = read_verilog_module_str . mkTop ( ) <EOL> code = test_module . to_verilog ( ) <EOL> from pyverilog . vparser . parser import VerilogParser <EOL> from pyverilog . ast_code_generator . codegen import ASTCodeGenerator <EOL> parser = VerilogParser ( ) <EOL> expected_ast = parser . parse ( expected_verilog ) <EOL> codegen = ASTCodeGenerator ( ) <EOL> expected_code = codegen . visit ( expected_ast ) <EOL> assert ( expected_code == code ) </s>
<s> from __future__ import absolute_import <EOL> from __future__ import print_function <EOL> import veriloggen . core . vtypes as vtypes <EOL> import veriloggen . core . module as module <EOL> def mkMultiplierCore ( index , lwidth = <NUM_LIT:32> , rwidth = <NUM_LIT:32> , lsigned = True , rsigned = True , depth = <NUM_LIT:6> ) : <EOL> retwidth = lwidth + rwidth <EOL> m = module . Module ( '<STR_LIT>' % index ) <EOL> clk = m . Input ( '<STR_LIT>' ) <EOL> update = m . Input ( '<STR_LIT>' ) <EOL> a = m . Input ( '<STR_LIT:a>' , lwidth ) <EOL> b = m . Input ( '<STR_LIT:b>' , rwidth ) <EOL> c = m . Output ( '<STR_LIT:c>' , retwidth ) <EOL> _a = m . Reg ( '<STR_LIT>' , lwidth , signed = lsigned ) <EOL> _b = m . Reg ( '<STR_LIT>' , rwidth , signed = rsigned ) <EOL> tmpval = [ m . Reg ( '<STR_LIT>' % i , retwidth , signed = True ) for i in range ( depth - <NUM_LIT:1> ) ] <EOL> rslt = m . Wire ( '<STR_LIT>' , retwidth , signed = True ) <EOL> __a = _a <EOL> __b = _b <EOL> if not lsigned : <EOL> __a = vtypes . SystemTask ( '<STR_LIT>' , vtypes . Cat ( vtypes . Int ( <NUM_LIT:0> , width = <NUM_LIT:1> ) , _a ) ) <EOL> if not rsigned : <EOL> __b = vtypes . SystemTask ( '<STR_LIT>' , vtypes . Cat ( vtypes . Int ( <NUM_LIT:0> , width = <NUM_LIT:1> ) , _b ) ) <EOL> m . Assign ( rslt ( __a * __b ) ) <EOL> m . Assign ( c ( tmpval [ depth - <NUM_LIT:2> ] ) ) <EOL> m . Always ( vtypes . Posedge ( clk ) ) ( <EOL> vtypes . If ( update ) ( <EOL> _a ( a ) , <EOL> _b ( b ) , <EOL> tmpval [ <NUM_LIT:0> ] ( rslt ) , <EOL> [ tmpval [ i ] ( tmpval [ i - <NUM_LIT:1> ] ) for i in range ( <NUM_LIT:1> , depth - <NUM_LIT:1> ) ] <EOL> ) ) <EOL> return m <EOL> def mkMultiplier ( index , lwidth = <NUM_LIT:32> , rwidth = <NUM_LIT:32> , lsigned = True , rsigned = True , depth = <NUM_LIT:6> ) : <EOL> if lwidth < <NUM_LIT:0> : raise ValueError ( "<STR_LIT>" ) <EOL> if rwidth < <NUM_LIT:0> : raise ValueError ( "<STR_LIT>" ) <EOL> if depth < <NUM_LIT:2> : raise ValueError ( "<STR_LIT>" ) <EOL> retwidth = lwidth + rwidth <EOL> mult = mkMultiplierCore ( index , lwidth , rwidth , lsigned , rsigned , depth ) <EOL> m = module . Module ( '<STR_LIT>' % index ) <EOL> clk = m . Input ( '<STR_LIT>' ) <EOL> rst = m . Input ( '<STR_LIT>' ) <EOL> update = m . Input ( '<STR_LIT>' ) <EOL> enable = m . Input ( '<STR_LIT>' ) <EOL> valid = m . Output ( '<STR_LIT>' ) <EOL> a = m . Input ( '<STR_LIT:a>' , lwidth ) <EOL> b = m . Input ( '<STR_LIT:b>' , rwidth ) <EOL> c = m . Output ( '<STR_LIT:c>' , retwidth ) <EOL> valid_reg = [ m . Reg ( '<STR_LIT>' % i ) for i in range ( depth ) ] <EOL> m . Assign ( valid ( valid_reg [ depth - <NUM_LIT:1> ] ) ) <EOL> m . Always ( vtypes . Posedge ( clk ) ) ( <EOL> vtypes . If ( rst ) ( <EOL> [ valid_reg [ i ] ( <NUM_LIT:0> ) for i in range ( depth ) ] <EOL> ) . Else ( <EOL> vtypes . If ( update ) ( <EOL> valid_reg [ <NUM_LIT:0> ] ( enable ) , <EOL> [ valid_reg [ i ] ( valid_reg [ i - <NUM_LIT:1> ] ) for i in range ( <NUM_LIT:1> , depth ) ] <EOL> ) <EOL> ) ) <EOL> ports = [ ( '<STR_LIT>' , clk ) , ( '<STR_LIT>' , update ) , ( '<STR_LIT:a>' , a ) , ( '<STR_LIT:b>' , b ) , ( '<STR_LIT:c>' , c ) ] <EOL> m . Instance ( mult , '<STR_LIT>' , ports = ports ) <EOL> return m <EOL> index_count = <NUM_LIT:0> <EOL> def get_mul ( lwidth = <NUM_LIT:32> , rwidth = <NUM_LIT:32> , lsigned = True , rsigned = True , depth = <NUM_LIT:6> ) : <EOL> global index_count <EOL> mul = mkMultiplier ( index_count , lwidth , rwidth , lsigned , rsigned , depth ) <EOL> index_count += <NUM_LIT:1> <EOL> return mul <EOL> def reset ( ) : <EOL> global index_count <EOL> index_count = <NUM_LIT:0> </s>
<s> from pymysql import OperationalError , Warning <EOL> from pymysql . tests import base <EOL> import os <EOL> import warnings <EOL> __all__ = [ "<STR_LIT>" ] <EOL> class TestLoadLocal ( base . PyMySQLTestCase ) : <EOL> def test_no_file ( self ) : <EOL> """<STR_LIT>""" <EOL> conn = self . connections [ <NUM_LIT:0> ] <EOL> c = conn . cursor ( ) <EOL> c . execute ( "<STR_LIT>" ) <EOL> try : <EOL> self . assertRaises ( <EOL> OperationalError , <EOL> c . execute , <EOL> ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> ) <EOL> finally : <EOL> c . execute ( "<STR_LIT>" ) <EOL> c . close ( ) <EOL> def test_load_file ( self ) : <EOL> """<STR_LIT>""" <EOL> conn = self . connections [ <NUM_LIT:0> ] <EOL> c = conn . cursor ( ) <EOL> c . execute ( "<STR_LIT>" ) <EOL> filename = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ ) ) , <EOL> '<STR_LIT:data>' , <EOL> '<STR_LIT>' ) <EOL> try : <EOL> c . execute ( <EOL> ( "<STR_LIT>" + <EOL> "<STR_LIT>" ) . format ( filename ) <EOL> ) <EOL> c . execute ( "<STR_LIT>" ) <EOL> self . assertEqual ( <NUM_LIT> , c . fetchone ( ) [ <NUM_LIT:0> ] ) <EOL> finally : <EOL> c . execute ( "<STR_LIT>" ) <EOL> def test_load_warnings ( self ) : <EOL> """<STR_LIT>""" <EOL> conn = self . connections [ <NUM_LIT:0> ] <EOL> c = conn . cursor ( ) <EOL> c . execute ( "<STR_LIT>" ) <EOL> filename = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ ) ) , <EOL> '<STR_LIT:data>' , <EOL> '<STR_LIT>' ) <EOL> try : <EOL> with warnings . catch_warnings ( record = True ) as w : <EOL> warnings . simplefilter ( '<STR_LIT>' ) <EOL> c . execute ( <EOL> ( "<STR_LIT>" + <EOL> "<STR_LIT>" ) . format ( filename ) <EOL> ) <EOL> self . assertEqual ( w [ <NUM_LIT:0> ] . category , Warning ) <EOL> self . assertTrue ( "<STR_LIT>" in str ( w [ - <NUM_LIT:1> ] . message ) ) <EOL> finally : <EOL> c . execute ( "<STR_LIT>" ) <EOL> c . close ( ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> import unittest <EOL> unittest . main ( ) </s>
<s> from __future__ import print_function <EOL> from time import time <EOL> import subprocess <EOL> import random <EOL> import numpy <EOL> STEP = <NUM_LIT:1000> * <NUM_LIT:100> <EOL> SCALE = <NUM_LIT:0.1> <EOL> NI_NTIMES = <NUM_LIT:1> <EOL> MROW = <NUM_LIT:1000> * <NUM_LIT> <EOL> COLDCACHE = <NUM_LIT:5> <EOL> WARMCACHE = <NUM_LIT:5> <EOL> READ_TIMES = <NUM_LIT:10> <EOL> rdm_cod = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> prec = <NUM_LIT:6> <EOL> def get_nrows ( nrows_str ) : <EOL> if nrows_str . endswith ( "<STR_LIT:k>" ) : <EOL> return int ( float ( nrows_str [ : - <NUM_LIT:1> ] ) * <NUM_LIT:1000> ) <EOL> elif nrows_str . endswith ( "<STR_LIT:m>" ) : <EOL> return int ( float ( nrows_str [ : - <NUM_LIT:1> ] ) * <NUM_LIT:1000> * <NUM_LIT:1000> ) <EOL> elif nrows_str . endswith ( "<STR_LIT:g>" ) : <EOL> return int ( float ( nrows_str [ : - <NUM_LIT:1> ] ) * <NUM_LIT:1000> * <NUM_LIT:1000> * <NUM_LIT:1000> ) <EOL> else : <EOL> raise ValueError ( <EOL> "<STR_LIT>" ) <EOL> class DB ( object ) : <EOL> def __init__ ( self , nrows , rng , userandom ) : <EOL> global step , scale <EOL> self . step = STEP <EOL> self . scale = SCALE <EOL> self . rng = rng <EOL> self . userandom = userandom <EOL> self . filename = '<STR_LIT:->' . join ( [ rdm_cod [ userandom ] , nrows ] ) <EOL> self . nrows = get_nrows ( nrows ) <EOL> def get_db_size ( self ) : <EOL> sout = subprocess . Popen ( "<STR_LIT>" % self . filename , shell = True , <EOL> stdout = subprocess . PIPE ) . stdout <EOL> line = [ l for l in sout ] [ <NUM_LIT:0> ] <EOL> return int ( line . split ( ) [ <NUM_LIT:0> ] ) <EOL> def print_mtime ( self , t1 , explain ) : <EOL> mtime = time ( ) - t1 <EOL> print ( "<STR_LIT>" % explain , round ( mtime , <NUM_LIT:6> ) ) <EOL> print ( "<STR_LIT>" , round ( ( self . nrows / <NUM_LIT> ) / mtime , <NUM_LIT:6> ) ) <EOL> def print_qtime ( self , colname , ltimes ) : <EOL> qtime1 = ltimes [ <NUM_LIT:0> ] <EOL> qtime2 = ltimes [ - <NUM_LIT:1> ] <EOL> print ( "<STR_LIT>" % colname , round ( qtime1 , <NUM_LIT:6> ) ) <EOL> print ( "<STR_LIT>" , round ( ( self . nrows / ( MROW ) ) / qtime1 , <NUM_LIT:6> ) ) <EOL> print ( "<STR_LIT>" % colname , round ( qtime2 , <NUM_LIT:6> ) ) <EOL> print ( "<STR_LIT>" , round ( ( self . nrows / ( MROW ) ) / qtime2 , <NUM_LIT:6> ) ) <EOL> def norm_times ( self , ltimes ) : <EOL> "<STR_LIT>" <EOL> lmean = ltimes . mean ( ) <EOL> lstd = ltimes . std ( ) <EOL> ntimes = ltimes [ ltimes < lmean + lstd ] <EOL> nmean = ntimes . mean ( ) <EOL> nstd = ntimes . std ( ) <EOL> return nmean , nstd <EOL> def print_qtime_idx ( self , colname , ltimes , repeated , verbose ) : <EOL> if repeated : <EOL> r = "<STR_LIT>" <EOL> else : <EOL> r = "<STR_LIT>" <EOL> ltimes = numpy . array ( ltimes ) <EOL> ntimes = len ( ltimes ) <EOL> qtime1 = ltimes [ <NUM_LIT:0> ] <EOL> ctimes = ltimes [ <NUM_LIT:1> : COLDCACHE ] <EOL> cmean , cstd = self . norm_times ( ctimes ) <EOL> wtimes = ltimes [ WARMCACHE : ] <EOL> wmean , wstd = self . norm_times ( wtimes ) <EOL> if verbose : <EOL> print ( "<STR_LIT>" , ctimes ) <EOL> print ( "<STR_LIT>" % <EOL> numpy . histogram ( wtimes ) ) <EOL> print ( "<STR_LIT>" % ( r , colname ) , <EOL> round ( qtime1 , prec ) ) <EOL> print ( "<STR_LIT>" % ( r , colname ) , <EOL> round ( cmean , prec ) , "<STR_LIT>" , round ( cstd , prec ) ) <EOL> print ( "<STR_LIT>" % ( r , colname ) , <EOL> round ( wmean , prec ) , "<STR_LIT>" , round ( wstd , prec ) ) <EOL> def print_db_sizes ( self , init , filled , indexed ) : <EOL> table_size = ( filled - init ) / <NUM_LIT> <EOL> indexes_size = ( indexed - filled ) / <NUM_LIT> <EOL> print ( "<STR_LIT>" , round ( table_size , <NUM_LIT:3> ) ) <EOL> print ( "<STR_LIT>" , round ( indexes_size , <NUM_LIT:3> ) ) <EOL> print ( "<STR_LIT>" , round ( table_size + indexes_size , <NUM_LIT:3> ) ) <EOL> def fill_arrays ( self , start , stop ) : <EOL> arr_f8 = numpy . arange ( start , stop , dtype = '<STR_LIT>' ) <EOL> arr_i4 = numpy . arange ( start , stop , dtype = '<STR_LIT>' ) <EOL> if self . userandom : <EOL> arr_f8 += numpy . random . normal ( <NUM_LIT:0> , stop * self . scale , <EOL> size = stop - start ) <EOL> arr_i4 = numpy . array ( arr_f8 , dtype = '<STR_LIT>' ) <EOL> return arr_i4 , arr_f8 <EOL> def create_db ( self , dtype , kind , optlevel , verbose ) : <EOL> self . con = self . open_db ( remove = <NUM_LIT:1> ) <EOL> self . create_table ( self . con ) <EOL> init_size = self . get_db_size ( ) <EOL> t1 = time ( ) <EOL> self . fill_table ( self . con ) <EOL> table_size = self . get_db_size ( ) <EOL> self . print_mtime ( t1 , '<STR_LIT>' ) <EOL> self . index_db ( dtype , kind , optlevel , verbose ) <EOL> indexes_size = self . get_db_size ( ) <EOL> self . print_db_sizes ( init_size , table_size , indexes_size ) <EOL> self . close_db ( self . con ) <EOL> def index_db ( self , dtype , kind , optlevel , verbose ) : <EOL> if dtype == "<STR_LIT:int>" : <EOL> idx_cols = [ '<STR_LIT>' ] <EOL> elif dtype == "<STR_LIT:float>" : <EOL> idx_cols = [ '<STR_LIT>' ] <EOL> else : <EOL> idx_cols = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> for colname in idx_cols : <EOL> t1 = time ( ) <EOL> self . index_col ( self . con , colname , kind , optlevel , verbose ) <EOL> self . print_mtime ( t1 , '<STR_LIT>' % colname ) <EOL> def query_db ( self , niter , dtype , onlyidxquery , onlynonidxquery , <EOL> avoidfscache , verbose , inkernel ) : <EOL> self . con = self . open_db ( ) <EOL> if dtype == "<STR_LIT:int>" : <EOL> reg_cols = [ '<STR_LIT>' ] <EOL> idx_cols = [ '<STR_LIT>' ] <EOL> elif dtype == "<STR_LIT:float>" : <EOL> reg_cols = [ '<STR_LIT>' ] <EOL> idx_cols = [ '<STR_LIT>' ] <EOL> else : <EOL> reg_cols = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> idx_cols = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> if avoidfscache : <EOL> rseed = int ( numpy . random . randint ( self . nrows ) ) <EOL> else : <EOL> rseed = <NUM_LIT> <EOL> numpy . random . seed ( rseed ) <EOL> base = numpy . random . randint ( self . nrows ) <EOL> if not onlyidxquery : <EOL> for colname in reg_cols : <EOL> ltimes = [ ] <EOL> random . seed ( rseed ) <EOL> for i in range ( NI_NTIMES ) : <EOL> t1 = time ( ) <EOL> results = self . do_query ( self . con , colname , base , inkernel ) <EOL> ltimes . append ( time ( ) - t1 ) <EOL> if verbose : <EOL> print ( "<STR_LIT>" , results ) <EOL> self . print_qtime ( colname , ltimes ) <EOL> self . close_db ( self . con ) <EOL> self . con = self . open_db ( ) <EOL> if not onlynonidxquery : <EOL> for colname in idx_cols : <EOL> ltimes = [ ] <EOL> numpy . random . seed ( rseed ) <EOL> rndbase = numpy . random . randint ( self . nrows , size = niter ) <EOL> for i in range ( niter ) : <EOL> base = rndbase [ i ] <EOL> t1 = time ( ) <EOL> results = self . do_query ( self . con , colname , base , inkernel ) <EOL> ltimes . append ( time ( ) - t1 ) <EOL> if verbose : <EOL> print ( "<STR_LIT>" , results ) <EOL> self . print_qtime_idx ( colname , ltimes , False , verbose ) <EOL> self . close_db ( self . con ) <EOL> self . con = self . open_db ( ) <EOL> ltimes = [ ] <EOL> self . close_db ( self . con ) <EOL> self . con = self . open_db ( ) <EOL> self . close_db ( self . con ) <EOL> def close_db ( self , con ) : <EOL> con . close ( ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> import sys <EOL> import getopt <EOL> try : <EOL> import psyco <EOL> psyco_imported = <NUM_LIT:1> <EOL> except : <EOL> psyco_imported = <NUM_LIT:0> <EOL> usage = """<STR_LIT>""" % sys . argv [ <NUM_LIT:0> ] <EOL> try : <EOL> opts , pargs = getopt . getopt ( <EOL> sys . argv [ <NUM_LIT:1> : ] , '<STR_LIT>' ) <EOL> except : <EOL> sys . stderr . write ( usage ) <EOL> sys . exit ( <NUM_LIT:1> ) <EOL> usepytables = <NUM_LIT:0> <EOL> usepostgres = <NUM_LIT:0> <EOL> verbose = <NUM_LIT:0> <EOL> doprofile = <NUM_LIT:0> <EOL> dokprofile = <NUM_LIT:0> <EOL> usepsyco = <NUM_LIT:0> <EOL> userandom = <NUM_LIT:0> <EOL> docreate = <NUM_LIT:0> <EOL> optlevel = <NUM_LIT:0> <EOL> kind = "<STR_LIT>" <EOL> docompress = <NUM_LIT:0> <EOL> complib = "<STR_LIT>" <EOL> doquery = False <EOL> onlyidxquery = False <EOL> onlynonidxquery = False <EOL> inkernel = True <EOL> avoidfscache = <NUM_LIT:0> <EOL> rng = [ - <NUM_LIT:1000> , - <NUM_LIT:1000> ] <EOL> repeatquery = <NUM_LIT:0> <EOL> repeatvalue = <NUM_LIT:0> <EOL> krows = '<STR_LIT>' <EOL> niter = READ_TIMES <EOL> dtype = "<STR_LIT:all>" <EOL> datadir = "<STR_LIT>" <EOL> for option in opts : <EOL> if option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> usepytables = <NUM_LIT:1> <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> usepostgres = <NUM_LIT:1> <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> verbose = <NUM_LIT:1> <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> doprofile = <NUM_LIT:1> <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> dokprofile = <NUM_LIT:1> <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> usepsyco = <NUM_LIT:1> <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> userandom = <NUM_LIT:1> <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT:-c>' : <EOL> docreate = <NUM_LIT:1> <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> doquery = True <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> doquery = True <EOL> onlyidxquery = True <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> doquery = True <EOL> onlynonidxquery = True <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> doquery = True <EOL> onlynonidxquery = True <EOL> inkernel = False <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> avoidfscache = <NUM_LIT:1> <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> docompress = int ( option [ <NUM_LIT:1> ] ) <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> complib = option [ <NUM_LIT:1> ] <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> rng = [ int ( i ) for i in option [ <NUM_LIT:1> ] . split ( "<STR_LIT:U+002C>" ) ] <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> niter = int ( option [ <NUM_LIT:1> ] ) <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> krows = option [ <NUM_LIT:1> ] <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> datadir = option [ <NUM_LIT:1> ] <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> optlevel = int ( option [ <NUM_LIT:1> ] ) <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> if option [ <NUM_LIT:1> ] in ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) : <EOL> kind = option [ <NUM_LIT:1> ] <EOL> else : <EOL> print ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> sys . exit ( <NUM_LIT:1> ) <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> if option [ <NUM_LIT:1> ] in ( '<STR_LIT:int>' , '<STR_LIT:float>' ) : <EOL> dtype = option [ <NUM_LIT:1> ] <EOL> else : <EOL> print ( "<STR_LIT>" ) <EOL> sys . exit ( <NUM_LIT:1> ) <EOL> elif option [ <NUM_LIT:0> ] == '<STR_LIT>' : <EOL> repeatquery = <NUM_LIT:1> <EOL> repeatvalue = int ( option [ <NUM_LIT:1> ] ) <EOL> if not usepytables and not usepostgres : <EOL> print ( "<STR_LIT>" ) <EOL> print ( "<STR_LIT>" ) <EOL> print ( "<STR_LIT>" ) <EOL> sys . exit ( <NUM_LIT:1> ) <EOL> if usepytables : <EOL> from pytables_backend import PyTables_DB <EOL> db = PyTables_DB ( krows , rng , userandom , datadir , <EOL> docompress , complib , kind , optlevel ) <EOL> elif usepostgres : <EOL> from postgres_backend import Postgres_DB <EOL> db = Postgres_DB ( krows , rng , userandom ) <EOL> if not avoidfscache : <EOL> numpy . random . seed ( <NUM_LIT:20> ) <EOL> if verbose : <EOL> if userandom : <EOL> print ( "<STR_LIT>" ) <EOL> if onlyidxquery : <EOL> print ( "<STR_LIT>" ) <EOL> if psyco_imported and usepsyco : <EOL> psyco . bind ( db . create_db ) <EOL> psyco . bind ( db . query_db ) <EOL> if docreate : <EOL> if verbose : <EOL> print ( "<STR_LIT>" % krows ) <EOL> db . create_db ( dtype , kind , optlevel , verbose ) <EOL> if doquery : <EOL> print ( "<STR_LIT>" % niter ) <EOL> if doprofile : <EOL> import pstats <EOL> import cProfile as prof <EOL> prof . run ( <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' ) <EOL> stats = pstats . Stats ( '<STR_LIT>' ) <EOL> stats . strip_dirs ( ) <EOL> stats . sort_stats ( '<STR_LIT:time>' , '<STR_LIT>' ) <EOL> if verbose : <EOL> stats . print_stats ( ) <EOL> else : <EOL> stats . print_stats ( <NUM_LIT:20> ) <EOL> elif dokprofile : <EOL> from cProfile import Profile <EOL> import lsprofcalltree <EOL> prof = Profile ( ) <EOL> prof . run ( <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> kcg = lsprofcalltree . KCacheGrind ( prof ) <EOL> ofile = open ( '<STR_LIT>' , '<STR_LIT:w>' ) <EOL> kcg . output ( ofile ) <EOL> ofile . close ( ) <EOL> elif doprofile : <EOL> import hotshot <EOL> import hotshot . stats <EOL> prof = hotshot . Profile ( "<STR_LIT>" ) <EOL> benchtime , stones = prof . run ( <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> prof . close ( ) <EOL> stats = hotshot . stats . load ( "<STR_LIT>" ) <EOL> stats . strip_dirs ( ) <EOL> stats . sort_stats ( '<STR_LIT:time>' , '<STR_LIT>' ) <EOL> stats . print_stats ( <NUM_LIT:20> ) <EOL> else : <EOL> db . query_db ( niter , dtype , onlyidxquery , onlynonidxquery , <EOL> avoidfscache , verbose , inkernel ) <EOL> if repeatquery : <EOL> db . rng = [ <NUM_LIT:1> , <NUM_LIT:1> ] <EOL> if verbose : <EOL> print ( "<STR_LIT>" , db . rng ) <EOL> db . query_db ( niter , dtype , onlyidxquery , onlynonidxquery , <EOL> avoidfscache , verbose , inkernel ) <EOL> for i in range ( repeatvalue ) : <EOL> for j in ( <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:5> ) : <EOL> rng = j * <NUM_LIT:10> ** i <EOL> db . rng = [ - rng / <NUM_LIT:2> , rng / <NUM_LIT:2> ] <EOL> if verbose : <EOL> print ( "<STR_LIT>" , db . rng ) <EOL> db . query_db ( niter , dtype , onlyidxquery , onlynonidxquery , <EOL> avoidfscache , verbose , inkernel ) </s>
<s> """<STR_LIT>""" <EOL> import matplotlib as mpl <EOL> from pylab import * <EOL> KB_ = <NUM_LIT> <EOL> MB_ = <NUM_LIT> * KB_ <EOL> GB_ = <NUM_LIT> * MB_ <EOL> NCHUNKS = <NUM_LIT> <EOL> linewidth = <NUM_LIT:2> <EOL> markers = [ '<STR_LIT:s>' , '<STR_LIT:o>' , '<STR_LIT:v>' , '<STR_LIT>' , '<STR_LIT:+>' , '<STR_LIT:x>' , '<STR_LIT:>>' , '<STR_LIT:<>' , '<STR_LIT:.>' , '<STR_LIT:U+002C>' ] <EOL> markersize = <NUM_LIT:8> <EOL> def get_values ( filename ) : <EOL> f = open ( filename ) <EOL> values = { "<STR_LIT>" : [ ] , "<STR_LIT>" : [ ] } <EOL> for line in f : <EOL> if line . startswith ( '<STR_LIT>' ) : <EOL> tmp = line . split ( '<STR_LIT>' ) [ <NUM_LIT:1> ] <EOL> nthreads , size , elsize , sbits , codec , shuffle = [ i for i in tmp . split ( '<STR_LIT:U+002CU+0020>' ) ] <EOL> nthreads , size , elsize , sbits = map ( int , ( nthreads , size , elsize , sbits ) ) <EOL> values [ "<STR_LIT:size>" ] = size * NCHUNKS / MB_ ; <EOL> values [ "<STR_LIT>" ] = elsize ; <EOL> values [ "<STR_LIT>" ] = sbits ; <EOL> values [ "<STR_LIT>" ] = codec <EOL> values [ "<STR_LIT>" ] = shuffle <EOL> ( ratios , speedsw , speedsr ) = ( [ ] , [ ] , [ ] ) <EOL> values [ nthreads ] = ( ratios , speedsw , speedsr ) <EOL> elif line . startswith ( '<STR_LIT>' ) : <EOL> tmp = line . split ( '<STR_LIT:U+002C>' ) [ <NUM_LIT:1> ] <EOL> memcpyw = float ( tmp . split ( '<STR_LIT:U+0020>' ) [ <NUM_LIT:1> ] ) <EOL> values [ "<STR_LIT>" ] . append ( memcpyw ) <EOL> elif line . startswith ( '<STR_LIT>' ) : <EOL> tmp = line . split ( '<STR_LIT:U+002C>' ) [ <NUM_LIT:1> ] <EOL> memcpyr = float ( tmp . split ( '<STR_LIT:U+0020>' ) [ <NUM_LIT:1> ] ) <EOL> values [ "<STR_LIT>" ] . append ( memcpyr ) <EOL> elif line . startswith ( '<STR_LIT>' ) : <EOL> tmp = line . split ( '<STR_LIT:U+002C>' ) [ <NUM_LIT:1> ] <EOL> speedw = float ( tmp . split ( '<STR_LIT:U+0020>' ) [ <NUM_LIT:1> ] ) <EOL> ratio = float ( line . split ( '<STR_LIT::>' ) [ - <NUM_LIT:1> ] ) <EOL> speedsw . append ( speedw ) <EOL> ratios . append ( ratio ) <EOL> elif line . startswith ( '<STR_LIT>' ) : <EOL> tmp = line . split ( '<STR_LIT:U+002C>' ) [ <NUM_LIT:1> ] <EOL> speedr = float ( tmp . split ( '<STR_LIT:U+0020>' ) [ <NUM_LIT:1> ] ) <EOL> speedsr . append ( speedr ) <EOL> if "<STR_LIT:OK>" not in line : <EOL> print "<STR_LIT>" <EOL> f . close ( ) <EOL> return nthreads , values <EOL> def show_plot ( plots , yaxis , legends , gtitle , xmax = None ) : <EOL> xlabel ( '<STR_LIT>' ) <EOL> ylabel ( '<STR_LIT>' ) <EOL> title ( gtitle ) <EOL> xlim ( <NUM_LIT:0> , xmax ) <EOL> ylim ( <NUM_LIT:0> , None ) <EOL> grid ( True ) <EOL> legend ( [ p [ <NUM_LIT:0> ] for p in plots <EOL> if not isinstance ( p , mpl . lines . Line2D ) ] , <EOL> legends , loc = "<STR_LIT>" ) <EOL> if outfile : <EOL> print "<STR_LIT>" , outfile <EOL> savefig ( outfile , dpi = <NUM_LIT:64> ) <EOL> else : <EOL> show ( ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> from optparse import OptionParser <EOL> usage = "<STR_LIT>" <EOL> compress_title = '<STR_LIT>' <EOL> decompress_title = '<STR_LIT>' <EOL> yaxis = '<STR_LIT>' <EOL> parser = OptionParser ( usage = usage ) <EOL> parser . add_option ( '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> dest = '<STR_LIT>' , <EOL> help = ( '<STR_LIT>' <EOL> '<STR_LIT>' ) ) <EOL> parser . add_option ( '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> dest = '<STR_LIT:title>' , <EOL> help = '<STR_LIT>' , ) <EOL> parser . add_option ( '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> dest = '<STR_LIT>' , <EOL> help = '<STR_LIT>' , ) <EOL> parser . add_option ( '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> dest = '<STR_LIT>' , <EOL> help = '<STR_LIT>' , <EOL> default = None ) <EOL> parser . add_option ( '<STR_LIT>' , '<STR_LIT>' , action = '<STR_LIT:store_true>' , <EOL> dest = '<STR_LIT>' , <EOL> help = '<STR_LIT>' , <EOL> default = False ) <EOL> parser . add_option ( '<STR_LIT>' , '<STR_LIT>' , action = '<STR_LIT:store_true>' , <EOL> dest = '<STR_LIT>' , <EOL> help = '<STR_LIT>' , <EOL> default = False ) <EOL> parser . add_option ( '<STR_LIT:-c>' , '<STR_LIT>' , action = '<STR_LIT:store_true>' , <EOL> dest = '<STR_LIT>' , <EOL> help = '<STR_LIT>' , <EOL> default = False ) <EOL> ( options , args ) = parser . parse_args ( ) <EOL> if len ( args ) == <NUM_LIT:0> : <EOL> parser . error ( "<STR_LIT>" ) <EOL> elif len ( args ) > <NUM_LIT:1> : <EOL> parser . error ( "<STR_LIT>" ) <EOL> else : <EOL> pass <EOL> if options . report and options . outfile : <EOL> parser . error ( "<STR_LIT>" ) <EOL> if options . dspeed and options . cspeed : <EOL> parser . error ( "<STR_LIT>" ) <EOL> elif options . cspeed : <EOL> options . dspeed = False <EOL> plot_title = compress_title <EOL> else : <EOL> options . dspeed = True <EOL> plot_title = decompress_title <EOL> filename = args [ <NUM_LIT:0> ] <EOL> cspeed = options . cspeed <EOL> dspeed = options . dspeed <EOL> if options . outfile : <EOL> outfile = options . outfile <EOL> elif options . report : <EOL> if cspeed : <EOL> outfile = filename [ : filename . rindex ( '<STR_LIT:.>' ) ] + '<STR_LIT>' <EOL> else : <EOL> outfile = filename [ : filename . rindex ( '<STR_LIT:.>' ) ] + '<STR_LIT>' <EOL> else : <EOL> outfile = None <EOL> plots = [ ] <EOL> legends = [ ] <EOL> nthreads , values = get_values ( filename ) <EOL> if options . limit : <EOL> thread_range = eval ( options . limit ) <EOL> else : <EOL> thread_range = range ( <NUM_LIT:1> , nthreads + <NUM_LIT:1> ) <EOL> if options . title : <EOL> plot_title = options . title <EOL> else : <EOL> plot_title += "<STR_LIT>" % values <EOL> gtitle = plot_title <EOL> for nt in thread_range : <EOL> ( ratios , speedw , speedr ) = values [ nt ] <EOL> if cspeed : <EOL> speed = speedw <EOL> else : <EOL> speed = speedr <EOL> plot_ = plot ( ratios , speed , linewidth = <NUM_LIT:2> ) <EOL> plots . append ( plot_ ) <EOL> nmarker = nt <EOL> if nt >= len ( markers ) : <EOL> nmarker = nt % len ( markers ) <EOL> setp ( plot_ , marker = markers [ nmarker ] , markersize = markersize , <EOL> linewidth = linewidth ) <EOL> legends . append ( "<STR_LIT>" % nt ) <EOL> if cspeed : <EOL> mean = np . mean ( values [ "<STR_LIT>" ] ) <EOL> message = "<STR_LIT>" <EOL> else : <EOL> mean = np . mean ( values [ "<STR_LIT>" ] ) <EOL> message = "<STR_LIT>" <EOL> plot_ = axhline ( mean , linewidth = <NUM_LIT:3> , linestyle = '<STR_LIT>' , color = '<STR_LIT>' ) <EOL> text ( <NUM_LIT:1.0> , mean + <NUM_LIT:50> , message ) <EOL> plots . append ( plot_ ) <EOL> show_plot ( plots , yaxis , legends , gtitle , xmax = int ( options . xmax ) if <EOL> options . xmax else None ) </s>
<s> import numpy as np <EOL> import tables <EOL> fileh = tables . open_file ( "<STR_LIT>" , mode = "<STR_LIT:w>" , <EOL> title = "<STR_LIT>" ) <EOL> root = fileh . root <EOL> a = np . array ( [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:4> ] , np . int32 ) <EOL> hdfarray = fileh . create_array ( root , '<STR_LIT>' , a , "<STR_LIT>" ) <EOL> hdfarray . attrs . string = "<STR_LIT>" <EOL> hdfarray . attrs . char = "<STR_LIT:1>" <EOL> hdfarray . attrs . int = <NUM_LIT:12> <EOL> hdfarray . attrs . float = <NUM_LIT> <EOL> hdfarray . attrs . object = { "<STR_LIT:a>" : <NUM_LIT> , "<STR_LIT:b>" : <NUM_LIT:1> , "<STR_LIT:c>" : [ <NUM_LIT:1> , <NUM_LIT:2> ] } <EOL> fileh . close ( ) </s>
<s> """<STR_LIT>""" <EOL> import tables <EOL> def setUp ( filename ) : <EOL> fileh = tables . open_file ( filename , mode = "<STR_LIT:w>" , title = "<STR_LIT>" ) <EOL> fileh . create_group ( "<STR_LIT:/>" , "<STR_LIT>" , "<STR_LIT>" ) <EOL> fileh . create_group ( "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) <EOL> fileh . create_array ( "<STR_LIT:/>" , "<STR_LIT>" , [ <NUM_LIT:1> , <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> fileh . enable_undo ( ) <EOL> return fileh <EOL> def tearDown ( fileh ) : <EOL> fileh . disable_undo ( ) <EOL> fileh . close ( ) <EOL> def demo_6times3marks ( ) : <EOL> """<STR_LIT>""" <EOL> fileh = setUp ( "<STR_LIT>" ) <EOL> fileh . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> fileh . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> fileh . mark ( ) <EOL> fileh . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:5> , <NUM_LIT:6> ] , "<STR_LIT>" ) <EOL> fileh . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:6> , <NUM_LIT:7> ] , "<STR_LIT>" ) <EOL> fileh . mark ( ) <EOL> fileh . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:7> , <NUM_LIT:8> ] , "<STR_LIT>" ) <EOL> fileh . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:8> , <NUM_LIT:9> ] , "<STR_LIT>" ) <EOL> fileh . undo ( ) <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> fileh . undo ( ) <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> fileh . undo ( ) <EOL> assert "<STR_LIT>" not in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> fileh . redo ( ) <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> fileh . redo ( ) <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> assert "<STR_LIT>" not in fileh <EOL> fileh . redo ( ) <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" in fileh <EOL> assert "<STR_LIT>" in fileh <EOL> tearDown ( fileh ) <EOL> def demo_manyops ( ) : <EOL> """<STR_LIT>""" <EOL> fileh = setUp ( "<STR_LIT>" ) <EOL> fileh . create_array ( fileh . root , '<STR_LIT>' , [ <NUM_LIT:3> ] , "<STR_LIT>" ) <EOL> fileh . create_group ( fileh . root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> new_node = fileh . copy_node ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> new_node = fileh . copy_children ( '<STR_LIT>' , '<STR_LIT>' , recursive = <NUM_LIT:1> ) <EOL> fileh . rename_node ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> new_node = fileh . copy_node ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> fileh . remove_node ( '<STR_LIT>' ) <EOL> fileh . undo ( ) <EOL> assert '<STR_LIT>' not in fileh <EOL> assert '<STR_LIT>' not in fileh <EOL> assert '<STR_LIT>' not in fileh <EOL> assert '<STR_LIT>' not in fileh <EOL> assert '<STR_LIT>' not in fileh <EOL> assert '<STR_LIT>' in fileh <EOL> fileh . redo ( ) <EOL> assert '<STR_LIT>' in fileh <EOL> assert '<STR_LIT>' in fileh <EOL> assert '<STR_LIT>' in fileh <EOL> assert '<STR_LIT>' not in fileh <EOL> assert fileh . root . agroup . anarray3 is new_node <EOL> assert '<STR_LIT>' not in fileh <EOL> assert '<STR_LIT>' not in fileh <EOL> tearDown ( fileh ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> demo_6times3marks ( ) <EOL> demo_manyops ( ) </s>
<s> """<STR_LIT>""" <EOL> from __future__ import absolute_import <EOL> import warnings <EOL> import functools <EOL> from . registry import class_name_dict , class_id_dict <EOL> from . exceptions import ( ClosedNodeError , NodeError , UndoRedoWarning , <EOL> PerformanceWarning ) <EOL> from . path import join_path , split_path , isvisiblepath <EOL> from . utils import lazyattr <EOL> from . undoredo import move_to_shadow <EOL> from . attributeset import AttributeSet , NotLoggedAttributeSet <EOL> import six <EOL> __docformat__ = '<STR_LIT>' <EOL> """<STR_LIT>""" <EOL> def _closedrepr ( oldmethod ) : <EOL> """<STR_LIT>""" <EOL> @ functools . wraps ( oldmethod ) <EOL> def newmethod ( self ) : <EOL> if not self . _v_isopen : <EOL> cmod = self . __class__ . __module__ <EOL> cname = self . __class__ . __name__ <EOL> addr = hex ( id ( self ) ) <EOL> return '<STR_LIT>' % ( cmod , cname , addr ) <EOL> return oldmethod ( self ) <EOL> return newmethod <EOL> class MetaNode ( type ) : <EOL> """<STR_LIT>""" <EOL> def __new__ ( class_ , name , bases , dict_ ) : <EOL> for mname in [ '<STR_LIT>' , '<STR_LIT>' ] : <EOL> if mname in dict_ : <EOL> dict_ [ mname ] = _closedrepr ( dict_ [ mname ] ) <EOL> return type . __new__ ( class_ , name , bases , dict_ ) <EOL> def __init__ ( class_ , name , bases , dict_ ) : <EOL> super ( MetaNode , class_ ) . __init__ ( name , bases , dict_ ) <EOL> class_name_dict [ class_ . __name__ ] = class_ <EOL> cid = getattr ( class_ , '<STR_LIT>' , None ) <EOL> if cid is not None : <EOL> for base in bases : <EOL> pcid = getattr ( base , '<STR_LIT>' , None ) <EOL> if pcid == cid : <EOL> break <EOL> else : <EOL> class_id_dict [ cid ] = class_ <EOL> class Node ( six . with_metaclass ( MetaNode , object ) ) : <EOL> """<STR_LIT>""" <EOL> _AttributeSet = AttributeSet <EOL> def _g_getparent ( self ) : <EOL> "<STR_LIT>" <EOL> ( parentpath , nodename ) = split_path ( self . _v_pathname ) <EOL> return self . _v_file . _get_node ( parentpath ) <EOL> _v_parent = property ( _g_getparent ) <EOL> @ lazyattr <EOL> def _v_attrs ( self ) : <EOL> """<STR_LIT>""" <EOL> return self . _AttributeSet ( self ) <EOL> def _g_gettitle ( self ) : <EOL> "<STR_LIT>" <EOL> if hasattr ( self . _v_attrs , '<STR_LIT>' ) : <EOL> return self . _v_attrs . TITLE <EOL> else : <EOL> return '<STR_LIT>' <EOL> def _g_settitle ( self , title ) : <EOL> self . _v_attrs . TITLE = title <EOL> _v_title = property ( _g_gettitle , _g_settitle ) <EOL> _v_isopen = False <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , parentnode , name , _log = True ) : <EOL> if isinstance ( parentnode , class_name_dict [ '<STR_LIT>' ] ) : <EOL> parentnode = parentnode . dereference ( ) <EOL> self . _v_file = None <EOL> """<STR_LIT>""" <EOL> self . _v_isopen = False <EOL> """<STR_LIT>""" <EOL> self . _v_pathname = None <EOL> """<STR_LIT>""" <EOL> self . _v_name = None <EOL> """<STR_LIT>""" <EOL> self . _v_depth = None <EOL> """<STR_LIT>""" <EOL> self . _v_maxtreedepth = parentnode . _v_file . params [ '<STR_LIT>' ] <EOL> """<STR_LIT>""" <EOL> self . _v__deleting = False <EOL> """<STR_LIT>""" <EOL> self . _v_objectid = None <EOL> """<STR_LIT>""" <EOL> validate = new = self . _v_new <EOL> self . _g_check_group ( parentnode ) <EOL> parentnode . _g_check_open ( ) <EOL> file_ = parentnode . _v_file <EOL> if new : <EOL> file_ . _check_writable ( ) <EOL> if new : <EOL> parentnode . _g_refnode ( self , name , validate ) <EOL> self . _g_set_location ( parentnode , name ) <EOL> try : <EOL> self . _g_new ( parentnode , name , init = True ) <EOL> if new : <EOL> self . _v_objectid = self . _g_create ( ) <EOL> else : <EOL> self . _v_objectid = self . _g_open ( ) <EOL> if new and _log and file_ . is_undo_enabled ( ) : <EOL> self . _g_log_create ( ) <EOL> self . _g_post_init_hook ( ) <EOL> except : <EOL> self . _f_close ( ) <EOL> raise <EOL> def _g_log_create ( self ) : <EOL> self . _v_file . _log ( '<STR_LIT>' , self . _v_pathname ) <EOL> def __del__ ( self ) : <EOL> if not self . _v_isopen : <EOL> return <EOL> self . _v__deleting = True <EOL> try : <EOL> node_manager = self . _v_file . _node_manager <EOL> node_manager . drop_node ( self , check_unregistered = False ) <EOL> finally : <EOL> if self . _v_isopen : <EOL> self . _v__deleting = True <EOL> self . _f_close ( ) <EOL> def _g_pre_kill_hook ( self ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> def _g_create ( self ) : <EOL> """<STR_LIT>""" <EOL> raise NotImplementedError <EOL> def _g_open ( self ) : <EOL> """<STR_LIT>""" <EOL> raise NotImplementedError <EOL> def _g_check_open ( self ) : <EOL> """<STR_LIT>""" <EOL> if not self . _v_isopen : <EOL> raise ClosedNodeError ( "<STR_LIT>" ) <EOL> assert self . _v_file . isopen , "<STR_LIT>" <EOL> def _g_set_location ( self , parentnode , name ) : <EOL> """<STR_LIT>""" <EOL> file_ = parentnode . _v_file <EOL> parentdepth = parentnode . _v_depth <EOL> self . _v_file = file_ <EOL> self . _v_isopen = True <EOL> root_uep = file_ . root_uep <EOL> if name . startswith ( root_uep ) : <EOL> assert parentdepth == <NUM_LIT:0> <EOL> if root_uep == "<STR_LIT:/>" : <EOL> self . _v_pathname = name <EOL> else : <EOL> self . _v_pathname = name [ len ( root_uep ) : ] <EOL> _ , self . _v_name = split_path ( name ) <EOL> self . _v_depth = name . count ( "<STR_LIT:/>" ) - root_uep . count ( "<STR_LIT:/>" ) + <NUM_LIT:1> <EOL> else : <EOL> self . _v_name = name <EOL> self . _v_pathname = join_path ( parentnode . _v_pathname , name ) <EOL> self . _v_depth = parentdepth + <NUM_LIT:1> <EOL> if parentdepth >= self . _v_maxtreedepth : <EOL> warnings . warn ( """<STR_LIT>""" <EOL> % ( self . _v_pathname , self . _v_maxtreedepth ) , <EOL> PerformanceWarning ) <EOL> if self . _v_pathname != '<STR_LIT:/>' : <EOL> file_ . _node_manager . cache_node ( self , self . _v_pathname ) <EOL> def _g_update_location ( self , newparentpath ) : <EOL> """<STR_LIT>""" <EOL> oldpath = self . _v_pathname <EOL> newpath = join_path ( newparentpath , self . _v_name ) <EOL> newdepth = newpath . count ( '<STR_LIT:/>' ) <EOL> self . _v_pathname = newpath <EOL> self . _v_depth = newdepth <EOL> if newdepth > self . _v_maxtreedepth : <EOL> warnings . warn ( """<STR_LIT>""" <EOL> % ( self . _v_maxtreedepth , ) , PerformanceWarning ) <EOL> node_manager = self . _v_file . _node_manager <EOL> node_manager . rename_node ( oldpath , newpath ) <EOL> self . _g_update_dependent ( ) <EOL> def _g_del_location ( self ) : <EOL> """<STR_LIT>""" <EOL> node_manager = self . _v_file . _node_manager <EOL> pathname = self . _v_pathname <EOL> if not self . _v__deleting : <EOL> node_manager . drop_from_cache ( pathname ) <EOL> node_manager . registry . pop ( pathname , None ) <EOL> self . _v_file = None <EOL> self . _v_isopen = False <EOL> self . _v_pathname = None <EOL> self . _v_name = None <EOL> self . _v_depth = None <EOL> def _g_post_init_hook ( self ) : <EOL> """<STR_LIT>""" <EOL> pass <EOL> def _g_update_dependent ( self ) : <EOL> """<STR_LIT>""" <EOL> if '<STR_LIT>' in self . __dict__ : <EOL> self . _v_attrs . _g_update_node_location ( self ) <EOL> def _f_close ( self ) : <EOL> """<STR_LIT>""" <EOL> if not self . _v_isopen : <EOL> return <EOL> myDict = self . __dict__ <EOL> if '<STR_LIT>' in myDict : <EOL> self . _v_attrs . _g_close ( ) <EOL> self . _g_del_location ( ) <EOL> myDict . clear ( ) <EOL> self . _v_isopen = False <EOL> def _g_remove ( self , recursive , force ) : <EOL> """<STR_LIT>""" <EOL> parent = self . _v_parent <EOL> parent . _g_unrefnode ( self . _v_name ) <EOL> self . _f_close ( ) <EOL> self . _g_delete ( parent ) <EOL> def _f_remove ( self , recursive = False , force = False ) : <EOL> """<STR_LIT>""" <EOL> self . _g_check_open ( ) <EOL> file_ = self . _v_file <EOL> file_ . _check_writable ( ) <EOL> if file_ . is_undo_enabled ( ) : <EOL> self . _g_remove_and_log ( recursive , force ) <EOL> else : <EOL> self . _g_remove ( recursive , force ) <EOL> def _g_remove_and_log ( self , recursive , force ) : <EOL> file_ = self . _v_file <EOL> oldpathname = self . _v_pathname <EOL> file_ . _log ( '<STR_LIT>' , oldpathname ) <EOL> move_to_shadow ( file_ , oldpathname ) <EOL> def _g_move ( self , newparent , newname ) : <EOL> """<STR_LIT>""" <EOL> oldparent = self . _v_parent <EOL> oldname = self . _v_name <EOL> oldpathname = self . _v_pathname <EOL> newparent . _g_refnode ( self , newname ) <EOL> oldparent . _g_unrefnode ( oldname ) <EOL> self . _g_del_location ( ) <EOL> self . _g_set_location ( newparent , newname ) <EOL> self . _g_new ( newparent , self . _v_name , init = False ) <EOL> self . _v_parent . _g_move_node ( oldparent . _v_objectid , oldname , <EOL> newparent . _v_objectid , newname , <EOL> oldpathname , self . _v_pathname ) <EOL> self . _g_update_dependent ( ) <EOL> def _f_rename ( self , newname , overwrite = False ) : <EOL> """<STR_LIT>""" <EOL> self . _f_move ( newname = newname , overwrite = overwrite ) <EOL> def _f_move ( self , newparent = None , newname = None , <EOL> overwrite = False , createparents = False ) : <EOL> """<STR_LIT>""" <EOL> self . _g_check_open ( ) <EOL> file_ = self . _v_file <EOL> oldparent = self . _v_parent <EOL> oldname = self . _v_name <EOL> if newparent is None and newname is None : <EOL> raise NodeError ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> if newparent is None : <EOL> newparent = oldparent <EOL> if newname is None : <EOL> newname = oldname <EOL> if hasattr ( newparent , '<STR_LIT>' ) : <EOL> newfile = newparent . _v_file <EOL> newpath = newparent . _v_pathname <EOL> elif hasattr ( newparent , '<STR_LIT>' ) : <EOL> newfile = file_ <EOL> newpath = newparent <EOL> else : <EOL> raise TypeError ( "<STR_LIT>" <EOL> % ( newparent , ) ) <EOL> if newfile is not file_ : <EOL> raise NodeError ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> file_ . _check_writable ( ) <EOL> oldpath = oldparent . _v_pathname <EOL> if newpath == oldpath and newname == oldname : <EOL> return <EOL> self . _g_check_not_contains ( newpath ) <EOL> newparent = file_ . _get_or_create_path ( newparent , createparents ) <EOL> self . _g_check_group ( newparent ) <EOL> self . _g_maybe_remove ( newparent , newname , overwrite ) <EOL> oldpathname = self . _v_pathname <EOL> self . _g_move ( newparent , newname ) <EOL> if file_ . is_undo_enabled ( ) : <EOL> self . _g_log_move ( oldpathname ) <EOL> def _g_log_move ( self , oldpathname ) : <EOL> self . _v_file . _log ( '<STR_LIT>' , oldpathname , self . _v_pathname ) <EOL> def _g_copy ( self , newparent , newname , recursive , _log = True , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> raise NotImplementedError <EOL> def _g_copy_as_child ( self , newparent , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> return self . _g_copy ( newparent , self . _v_name , <EOL> recursive = False , _log = False , ** kwargs ) <EOL> def _f_copy ( self , newparent = None , newname = None , <EOL> overwrite = False , recursive = False , createparents = False , <EOL> ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> self . _g_check_open ( ) <EOL> srcfile = self . _v_file <EOL> srcparent = self . _v_parent <EOL> srcname = self . _v_name <EOL> dstparent = newparent <EOL> dstname = newname <EOL> if dstparent is None and dstname is None : <EOL> raise NodeError ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> if dstparent is None : <EOL> dstparent = srcparent <EOL> if dstname is None : <EOL> dstname = srcname <EOL> if hasattr ( dstparent , '<STR_LIT>' ) : <EOL> dstfile = dstparent . _v_file <EOL> dstpath = dstparent . _v_pathname <EOL> elif hasattr ( dstparent , '<STR_LIT>' ) : <EOL> dstfile = srcfile <EOL> dstpath = dstparent <EOL> else : <EOL> raise TypeError ( "<STR_LIT>" <EOL> % ( dstparent , ) ) <EOL> if dstfile is srcfile : <EOL> srcpath = srcparent . _v_pathname <EOL> if dstpath == srcpath and dstname == srcname : <EOL> raise NodeError ( <EOL> "<STR_LIT>" <EOL> % self . _v_pathname ) <EOL> if recursive : <EOL> self . _g_check_not_contains ( dstpath ) <EOL> dstparent = srcfile . _get_or_create_path ( dstparent , createparents ) <EOL> self . _g_check_group ( dstparent ) <EOL> if dstfile is not srcfile and srcfile . is_undo_enabled ( ) : <EOL> warnings . warn ( "<STR_LIT>" <EOL> "<STR_LIT>" , <EOL> UndoRedoWarning ) <EOL> self . _g_maybe_remove ( dstparent , dstname , overwrite ) <EOL> return self . _g_copy ( dstparent , dstname , recursive , ** kwargs ) <EOL> def _f_isvisible ( self ) : <EOL> """<STR_LIT>""" <EOL> self . _g_check_open ( ) <EOL> return isvisiblepath ( self . _v_pathname ) <EOL> def _g_check_group ( self , node ) : <EOL> if not isinstance ( node , class_name_dict [ '<STR_LIT>' ] ) : <EOL> raise TypeError ( "<STR_LIT>" <EOL> % node . _v_pathname ) <EOL> if not isinstance ( node , class_name_dict [ '<STR_LIT>' ] ) : <EOL> raise TypeError ( "<STR_LIT>" <EOL> % node . _v_pathname ) <EOL> def _g_check_not_contains ( self , pathname ) : <EOL> mypathname = self . _v_pathname <EOL> if ( mypathname == '<STR_LIT:/>' <EOL> or pathname == mypathname <EOL> or pathname . startswith ( mypathname + '<STR_LIT:/>' ) ) : <EOL> raise NodeError ( "<STR_LIT>" <EOL> "<STR_LIT>" % mypathname ) <EOL> def _g_maybe_remove ( self , parent , name , overwrite ) : <EOL> if name in parent : <EOL> if not overwrite : <EOL> raise NodeError ( """<STR_LIT>""" % ( parent . _v_pathname , name ) ) <EOL> parent . _f_get_child ( name ) . _f_remove ( True ) <EOL> def _g_check_name ( self , name ) : <EOL> """<STR_LIT>""" <EOL> if name . startswith ( '<STR_LIT>' ) : <EOL> raise ValueError ( <EOL> "<STR_LIT>" % name ) <EOL> def _f_getattr ( self , name ) : <EOL> """<STR_LIT>""" <EOL> return getattr ( self . _v_attrs , name ) <EOL> def _f_setattr ( self , name , value ) : <EOL> """<STR_LIT>""" <EOL> setattr ( self . _v_attrs , name , value ) <EOL> def _f_delattr ( self , name ) : <EOL> """<STR_LIT>""" <EOL> delattr ( self . _v_attrs , name ) <EOL> class NotLoggedMixin : <EOL> _AttributeSet = NotLoggedAttributeSet <EOL> def _g_log_create ( self ) : <EOL> pass <EOL> def _g_log_move ( self , oldpathname ) : <EOL> pass <EOL> def _g_remove_and_log ( self , recursive , force ) : <EOL> self . _g_remove ( recursive , force ) </s>
<s> from __future__ import print_function <EOL> from __future__ import absolute_import <EOL> import warnings <EOL> import tables <EOL> from tables import IsDescription , StringCol , BoolCol , IntCol , FloatCol <EOL> from tables . node import NotLoggedMixin <EOL> from tables . path import join_path <EOL> from tables . tests import common <EOL> from tables . tests . common import unittest <EOL> from tables . tests . common import PyTablesTestCase as TestCase <EOL> from six . moves import range <EOL> class BasicTestCase ( common . TempFileMixin , TestCase ) : <EOL> """<STR_LIT>""" <EOL> _reopen_flag = False <EOL> """<STR_LIT>""" <EOL> def _do_reopen ( self ) : <EOL> if self . _reopen_flag : <EOL> self . _reopen ( '<STR_LIT>' ) <EOL> def setUp ( self ) : <EOL> super ( BasicTestCase , self ) . setUp ( ) <EOL> h5file = self . h5file <EOL> root = h5file . root <EOL> h5file . create_array ( root , '<STR_LIT>' , [ <NUM_LIT:1> , <NUM_LIT:2> ] , title = "<STR_LIT>" ) <EOL> h5file . create_array ( root , '<STR_LIT>' , [ <NUM_LIT:1> ] , "<STR_LIT>" ) <EOL> group = h5file . create_group ( root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> h5file . create_array ( group , '<STR_LIT>' , [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> h5file . create_array ( group , '<STR_LIT>' , [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> h5file . create_group ( root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> h5file . create_group ( group , '<STR_LIT>' , "<STR_LIT>" ) <EOL> def test00_simple ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertEqual ( self . h5file . _curaction , <NUM_LIT:0> ) <EOL> self . assertEqual ( self . h5file . _curmark , <NUM_LIT:0> ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . redo ( ) <EOL> if common . verbose : <EOL> print ( "<STR_LIT>" , self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray . read ( ) , [ <NUM_LIT:3> , <NUM_LIT:4> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . _curaction , <NUM_LIT:1> ) <EOL> self . assertEqual ( self . h5file . _curmark , <NUM_LIT:0> ) <EOL> def test01_twice ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertEqual ( self . h5file . _curaction , <NUM_LIT:0> ) <EOL> self . assertEqual ( self . h5file . _curmark , <NUM_LIT:0> ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray . read ( ) , [ <NUM_LIT:3> , <NUM_LIT:4> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . read ( ) , [ <NUM_LIT:4> , <NUM_LIT:5> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . _curaction , <NUM_LIT:2> ) <EOL> self . assertEqual ( self . h5file . _curmark , <NUM_LIT:0> ) <EOL> def test02_twice2 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . mark ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . _curaction , <NUM_LIT:3> ) <EOL> self . assertEqual ( self . h5file . _curmark , <NUM_LIT:1> ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertEqual ( self . h5file . _curaction , <NUM_LIT:2> ) <EOL> self . assertEqual ( self . h5file . _curmark , <NUM_LIT:1> ) <EOL> self . h5file . undo ( ) <EOL> self . assertEqual ( self . h5file . _curaction , <NUM_LIT:0> ) <EOL> self . assertEqual ( self . h5file . _curmark , <NUM_LIT:0> ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . _do_reopen ( ) <EOL> self . assertEqual ( self . h5file . _curaction , <NUM_LIT:2> ) <EOL> self . assertEqual ( self . h5file . _curmark , <NUM_LIT:1> ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray . read ( ) , [ <NUM_LIT:3> , <NUM_LIT:4> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . read ( ) , [ <NUM_LIT:4> , <NUM_LIT:5> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . _curaction , <NUM_LIT:3> ) <EOL> self . assertEqual ( self . h5file . _curmark , <NUM_LIT:1> ) <EOL> def test03_6times3marks ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % <EOL> self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:5> , <NUM_LIT:6> ] , "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:6> , <NUM_LIT:7> ] , "<STR_LIT>" ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . mark ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:7> , <NUM_LIT:8> ] , "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:8> , <NUM_LIT:9> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . read ( ) , [ <NUM_LIT:3> , <NUM_LIT:4> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . read ( ) , [ <NUM_LIT:4> , <NUM_LIT:5> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray3 . read ( ) , [ <NUM_LIT:5> , <NUM_LIT:6> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray4 . read ( ) , [ <NUM_LIT:6> , <NUM_LIT:7> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray5 . read ( ) , [ <NUM_LIT:7> , <NUM_LIT:8> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray6 . read ( ) , [ <NUM_LIT:8> , <NUM_LIT:9> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray3 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray4 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray5 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray6 . title , "<STR_LIT>" ) <EOL> def test04_6times3marksro ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % <EOL> self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:5> , <NUM_LIT:6> ] , "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:6> , <NUM_LIT:7> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> if common . verbose : <EOL> print ( "<STR_LIT>" , self . h5file . walk_nodes ( ) ) <EOL> self . h5file . mark ( ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:7> , <NUM_LIT:8> ] , "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:8> , <NUM_LIT:9> ] , "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . read ( ) , [ <NUM_LIT:3> , <NUM_LIT:4> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . read ( ) , [ <NUM_LIT:4> , <NUM_LIT:5> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray5 . read ( ) , [ <NUM_LIT:7> , <NUM_LIT:8> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray6 . read ( ) , [ <NUM_LIT:8> , <NUM_LIT:9> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray5 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray6 . title , "<STR_LIT>" ) <EOL> def test05_destructive ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:5> , <NUM_LIT:6> ] , "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . read ( ) , [ <NUM_LIT:3> , <NUM_LIT:4> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . title , "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray3 . read ( ) , [ <NUM_LIT:5> , <NUM_LIT:6> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray3 . title , "<STR_LIT>" ) <EOL> def test05b_destructive ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % <EOL> self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . mark ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:5> , <NUM_LIT:6> ] , "<STR_LIT>" ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . mark ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:6> , <NUM_LIT:7> ] , "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . read ( ) , [ <NUM_LIT:3> , <NUM_LIT:4> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . title , "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray3 . read ( ) , [ <NUM_LIT:5> , <NUM_LIT:6> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray3 . title , "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> def test05c_destructive ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % <EOL> self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:5> , <NUM_LIT:6> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:6> , <NUM_LIT:7> ] , "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . h5file . undo ( ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> def test05d_destructive ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % <EOL> self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . mark ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:5> , <NUM_LIT:6> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:6> , <NUM_LIT:7> ] , "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . undo ( <NUM_LIT:0> ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> def test05e_destructive ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % <EOL> self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:5> , <NUM_LIT:6> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( <NUM_LIT:0> ) <EOL> self . _do_reopen ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> def test05f_destructive ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % <EOL> self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> ] ) <EOL> self . h5file . undo ( ) <EOL> self . _do_reopen ( ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> newarr = self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> ] ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> if not self . _reopen_flag : <EOL> self . assertTrue ( self . h5file . root . newarray is newarr ) <EOL> def test06_totalunwind ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . undo ( <NUM_LIT:0> ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> def test07_totalrewind ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( <NUM_LIT:0> ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . redo ( - <NUM_LIT:1> ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray . read ( ) , [ <NUM_LIT:3> , <NUM_LIT:4> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . read ( ) , [ <NUM_LIT:4> , <NUM_LIT:5> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . title , "<STR_LIT>" ) <EOL> def test08_marknames ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:5> , <NUM_LIT:6> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:6> , <NUM_LIT:7> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( "<STR_LIT>" ) <EOL> self . _do_reopen ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . redo ( "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . undo ( "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . redo ( - <NUM_LIT:1> ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . read ( ) , [ <NUM_LIT:3> , <NUM_LIT:4> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . read ( ) , [ <NUM_LIT:4> , <NUM_LIT:5> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray3 . read ( ) , [ <NUM_LIT:5> , <NUM_LIT:6> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray4 . read ( ) , [ <NUM_LIT:6> , <NUM_LIT:7> ] ) <EOL> def test08_initialmark ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> initmid = self . h5file . get_current_mark ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( initmid ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . redo ( - <NUM_LIT:1> ) <EOL> self . _do_reopen ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray . read ( ) , [ <NUM_LIT:3> , <NUM_LIT:4> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . read ( ) , [ <NUM_LIT:4> , <NUM_LIT:5> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . title , "<STR_LIT>" ) <EOL> def test09_marknames ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( "<STR_LIT>" ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:5> , <NUM_LIT:6> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:6> , <NUM_LIT:7> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( "<STR_LIT>" ) <EOL> with self . assertRaises ( tables . UndoRedoError ) : <EOL> self . h5file . undo ( "<STR_LIT>" ) <EOL> self . h5file . redo ( "<STR_LIT>" ) <EOL> self . _do_reopen ( ) <EOL> with self . assertRaises ( tables . UndoRedoError ) : <EOL> self . h5file . redo ( "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> def test10_goto ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . mark ( "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:5> , <NUM_LIT:6> ] , "<STR_LIT>" ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . mark ( "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:6> , <NUM_LIT:7> ] , "<STR_LIT>" ) <EOL> self . h5file . goto ( "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . goto ( "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . goto ( "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . goto ( - <NUM_LIT:1> ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . read ( ) , [ <NUM_LIT:3> , <NUM_LIT:4> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . read ( ) , [ <NUM_LIT:4> , <NUM_LIT:5> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray3 . read ( ) , [ <NUM_LIT:5> , <NUM_LIT:6> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray4 . read ( ) , [ <NUM_LIT:6> , <NUM_LIT:7> ] ) <EOL> def test10_gotoint ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:4> , <NUM_LIT:5> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( "<STR_LIT>" ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:5> , <NUM_LIT:6> ] , "<STR_LIT>" ) <EOL> self . h5file . mark ( "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:6> , <NUM_LIT:7> ] , "<STR_LIT>" ) <EOL> self . h5file . goto ( <NUM_LIT:1> ) <EOL> self . _do_reopen ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . goto ( <NUM_LIT:0> ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . goto ( <NUM_LIT:3> ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . goto ( <NUM_LIT:2> ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . goto ( - <NUM_LIT:1> ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . read ( ) , [ <NUM_LIT:3> , <NUM_LIT:4> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . read ( ) , [ <NUM_LIT:4> , <NUM_LIT:5> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray3 . read ( ) , [ <NUM_LIT:5> , <NUM_LIT:6> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray4 . read ( ) , [ <NUM_LIT:6> , <NUM_LIT:7> ] ) <EOL> def test11_contiguous ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> m1 = self . h5file . mark ( ) <EOL> m2 = self . h5file . mark ( ) <EOL> self . assertNotEqual ( m1 , m2 ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . undo ( m1 ) <EOL> self . assertEqual ( self . h5file . get_current_mark ( ) , m1 ) <EOL> self . h5file . redo ( m2 ) <EOL> self . assertEqual ( self . h5file . get_current_mark ( ) , m2 ) <EOL> self . h5file . goto ( m1 ) <EOL> self . assertEqual ( self . h5file . get_current_mark ( ) , m1 ) <EOL> self . h5file . goto ( m2 ) <EOL> self . assertEqual ( self . h5file . get_current_mark ( ) , m2 ) <EOL> self . h5file . goto ( - <NUM_LIT:1> ) <EOL> self . _do_reopen ( ) <EOL> self . assertEqual ( self . h5file . get_current_mark ( ) , m2 ) <EOL> self . h5file . goto ( <NUM_LIT:0> ) <EOL> self . assertEqual ( self . h5file . get_current_mark ( ) , <NUM_LIT:0> ) <EOL> def test12_keepMark ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> ] ) <EOL> mid = self . h5file . mark ( ) <EOL> self . assertTrue ( mid is not None ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . undo ( ) <EOL> self . assertEqual ( self . h5file . get_current_mark ( ) , <NUM_LIT:0> ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> def test13_severalEnableDisable ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % <EOL> self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> ] ) <EOL> self . h5file . undo ( ) <EOL> self . _do_reopen ( ) <EOL> self . assertEqual ( self . h5file . get_current_mark ( ) , <NUM_LIT:0> ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . h5file . disable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> ] ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> ] ) <EOL> mid = self . h5file . mark ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> ] ) <EOL> self . h5file . undo ( ) <EOL> self . assertEqual ( self . h5file . get_current_mark ( ) , mid ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . _do_reopen ( ) <EOL> self . h5file . disable_undo ( ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> ] ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> ] ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . h5file . undo ( ) <EOL> self . _do_reopen ( ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . h5file . disable_undo ( ) <EOL> class PersistenceTestCase ( BasicTestCase ) : <EOL> """<STR_LIT>""" <EOL> _reopen_flag = True <EOL> class CreateArrayTestCase ( common . TempFileMixin , TestCase ) : <EOL> """<STR_LIT>""" <EOL> def setUp ( self ) : <EOL> super ( CreateArrayTestCase , self ) . setUp ( ) <EOL> h5file = self . h5file <EOL> root = h5file . root <EOL> h5file . create_array ( root , '<STR_LIT>' , [ <NUM_LIT:1> , <NUM_LIT:2> ] , title = "<STR_LIT>" ) <EOL> h5file . create_array ( root , '<STR_LIT>' , [ <NUM_LIT:1> ] , "<STR_LIT>" ) <EOL> group = h5file . create_group ( root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> h5file . create_array ( group , '<STR_LIT>' , [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> h5file . create_array ( group , '<STR_LIT>' , [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> h5file . create_group ( root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> h5file . create_group ( group , '<STR_LIT>' , "<STR_LIT>" ) <EOL> def test00 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> , <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . read ( ) , [ <NUM_LIT:1> , <NUM_LIT:2> ] ) <EOL> def test01 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> , <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:2> , <NUM_LIT:3> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . read ( ) , [ <NUM_LIT:1> , <NUM_LIT:2> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . read ( ) , [ <NUM_LIT:2> , <NUM_LIT:3> ] ) <EOL> def test02 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> , <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:2> , <NUM_LIT:3> ] , "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray3 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . read ( ) , [ <NUM_LIT:1> , <NUM_LIT:2> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray2 . read ( ) , [ <NUM_LIT:2> , <NUM_LIT:3> ] ) <EOL> self . assertEqual ( self . h5file . root . otherarray3 . read ( ) , [ <NUM_LIT:3> , <NUM_LIT:4> ] ) <EOL> def test03 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> , <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT>' , '<STR_LIT>' , <EOL> [ <NUM_LIT:2> , <NUM_LIT:3> ] , "<STR_LIT>" ) <EOL> self . h5file . create_array ( '<STR_LIT>' , '<STR_LIT>' , <EOL> [ <NUM_LIT:3> , <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . agroup . otherarray2 . title , <EOL> "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . agroup . agroup3 . otherarray3 . title , <EOL> "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . otherarray1 . read ( ) , [ <NUM_LIT:1> , <NUM_LIT:2> ] ) <EOL> self . assertEqual ( self . h5file . root . agroup . otherarray2 . read ( ) , [ <NUM_LIT:2> , <NUM_LIT:3> ] ) <EOL> self . assertEqual ( self . h5file . root . agroup . agroup3 . otherarray3 . read ( ) , <EOL> [ <NUM_LIT:3> , <NUM_LIT:4> ] ) <EOL> class CreateGroupTestCase ( common . TempFileMixin , TestCase ) : <EOL> """<STR_LIT>""" <EOL> def setUp ( self ) : <EOL> super ( CreateGroupTestCase , self ) . setUp ( ) <EOL> h5file = self . h5file <EOL> root = h5file . root <EOL> h5file . create_array ( root , '<STR_LIT>' , [ <NUM_LIT:1> , <NUM_LIT:2> ] , title = "<STR_LIT>" ) <EOL> h5file . create_array ( root , '<STR_LIT>' , [ <NUM_LIT:1> ] , "<STR_LIT>" ) <EOL> group = h5file . create_group ( root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> h5file . create_array ( group , '<STR_LIT>' , [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> h5file . create_array ( group , '<STR_LIT>' , [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> h5file . create_group ( root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> h5file . create_group ( group , '<STR_LIT>' , "<STR_LIT>" ) <EOL> def test00 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_group ( '<STR_LIT:/>' , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . othergroup1 . _v_title , <EOL> "<STR_LIT>" ) <EOL> def test01 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_group ( '<STR_LIT:/>' , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . create_group ( '<STR_LIT:/>' , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . othergroup1 . _v_title , <EOL> "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . othergroup2 . _v_title , <EOL> "<STR_LIT>" ) <EOL> def test02 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_group ( '<STR_LIT:/>' , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . create_group ( '<STR_LIT:/>' , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . create_group ( '<STR_LIT:/>' , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . othergroup1 . _v_title , <EOL> "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . othergroup2 . _v_title , <EOL> "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . othergroup3 . _v_title , <EOL> "<STR_LIT>" ) <EOL> def test03 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_group ( '<STR_LIT:/>' , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . create_group ( <EOL> '<STR_LIT>' , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . create_group ( <EOL> '<STR_LIT>' , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( <EOL> "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . othergroup1 . _v_title , <EOL> "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . othergroup1 . othergroup2 . _v_title , <EOL> "<STR_LIT>" ) <EOL> self . assertEqual ( <EOL> self . h5file . root . othergroup1 . othergroup2 . othergroup3 . _v_title , <EOL> "<STR_LIT>" ) <EOL> minRowIndex = <NUM_LIT:10> <EOL> def populateTable ( where , name ) : <EOL> """<STR_LIT>""" <EOL> class Indexed ( IsDescription ) : <EOL> var1 = StringCol ( itemsize = <NUM_LIT:4> , dflt = b"<STR_LIT>" , pos = <NUM_LIT:1> ) <EOL> var2 = BoolCol ( dflt = <NUM_LIT:0> , pos = <NUM_LIT:2> ) <EOL> var3 = IntCol ( dflt = <NUM_LIT:0> , pos = <NUM_LIT:3> ) <EOL> var4 = FloatCol ( dflt = <NUM_LIT:0> , pos = <NUM_LIT:4> ) <EOL> nrows = minRowIndex <EOL> table = where . _v_file . create_table ( where , name , Indexed , "<STR_LIT>" , <EOL> None , nrows ) <EOL> for i in range ( nrows ) : <EOL> table . row [ '<STR_LIT>' ] = str ( i ) <EOL> table . row [ '<STR_LIT>' ] = i % <NUM_LIT:2> <EOL> table . row [ '<STR_LIT>' ] = i <EOL> table . row [ '<STR_LIT>' ] = float ( nrows - i - <NUM_LIT:1> ) <EOL> table . row . append ( ) <EOL> table . flush ( ) <EOL> indexrows = table . cols . var1 . create_index ( ) <EOL> indexrows = table . cols . var2 . create_index ( ) <EOL> indexrows = table . cols . var3 . create_index ( ) <EOL> if common . verbose : <EOL> print ( "<STR_LIT>" , nrows ) <EOL> print ( "<STR_LIT>" , table . cols . var1 . index . nelements ) <EOL> print ( "<STR_LIT>" , indexrows ) <EOL> class RenameNodeTestCase ( common . TempFileMixin , TestCase ) : <EOL> """<STR_LIT>""" <EOL> def setUp ( self ) : <EOL> super ( RenameNodeTestCase , self ) . setUp ( ) <EOL> h5file = self . h5file <EOL> root = h5file . root <EOL> h5file . create_array ( root , '<STR_LIT>' , [ <NUM_LIT:1> , <NUM_LIT:2> ] , title = "<STR_LIT>" ) <EOL> h5file . create_array ( root , '<STR_LIT>' , [ <NUM_LIT:1> ] , "<STR_LIT>" ) <EOL> group = h5file . create_group ( root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> h5file . create_array ( group , '<STR_LIT>' , [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> h5file . create_array ( group , '<STR_LIT>' , [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> h5file . create_group ( root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> h5file . create_group ( group , '<STR_LIT>' , "<STR_LIT>" ) <EOL> populateTable ( self . h5file . root , '<STR_LIT>' ) <EOL> def test00 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . rename_node ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . agroup2 . _v_title , "<STR_LIT>" ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . agroup3 . _v_title , "<STR_LIT>" ) <EOL> def test01 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . rename_node ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . agroup . _v_title , "<STR_LIT>" ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . agroup3 . _v_title , "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> def test01b ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . rename_node ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . h5file . rename_node ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . agroup . _v_title , "<STR_LIT>" ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . agroup4 . _v_title , "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> def test02 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . rename_node ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . anarray . title , "<STR_LIT>" ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . anarray2 . title , "<STR_LIT>" ) <EOL> def test03 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . rename_node ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> table = self . h5file . root . table <EOL> self . assertTrue ( table . cols . var1 . index is not None ) <EOL> self . assertTrue ( table . cols . var2 . index is not None ) <EOL> self . assertTrue ( table . cols . var3 . index is not None ) <EOL> self . assertTrue ( table . cols . var4 . index is None ) <EOL> self . assertEqual ( table . cols . var1 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( table . cols . var2 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( table . cols . var3 . index . nelements , minRowIndex ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . table . title , "<STR_LIT>" ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . table2 . title , "<STR_LIT>" ) <EOL> table = self . h5file . root . table2 <EOL> self . assertTrue ( table . cols . var1 . index is not None ) <EOL> self . assertTrue ( table . cols . var2 . index is not None ) <EOL> self . assertTrue ( table . cols . var3 . index is not None ) <EOL> self . assertEqual ( table . cols . var1 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( table . cols . var2 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( table . cols . var3 . index . nelements , minRowIndex ) <EOL> self . assertTrue ( table . cols . var4 . index is None ) <EOL> class MoveNodeTestCase ( common . TempFileMixin , TestCase ) : <EOL> """<STR_LIT>""" <EOL> def setUp ( self ) : <EOL> super ( MoveNodeTestCase , self ) . setUp ( ) <EOL> h5file = self . h5file <EOL> root = h5file . root <EOL> h5file . create_array ( root , '<STR_LIT>' , [ <NUM_LIT:1> , <NUM_LIT:2> ] , title = "<STR_LIT>" ) <EOL> h5file . create_array ( root , '<STR_LIT>' , [ <NUM_LIT:1> ] , "<STR_LIT>" ) <EOL> group = h5file . create_group ( root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> h5file . create_array ( group , '<STR_LIT>' , [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> h5file . create_array ( group , '<STR_LIT>' , [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> h5file . create_group ( root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> h5file . create_group ( group , '<STR_LIT>' , "<STR_LIT>" ) <EOL> populateTable ( self . h5file . root , '<STR_LIT>' ) <EOL> def test00 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . move_node ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . anarray . title , "<STR_LIT>" ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . agroup . agroup3 . anarray . title , <EOL> "<STR_LIT>" ) <EOL> def test01 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . move_node ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . agroup . _v_title , "<STR_LIT>" ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . agroup2 . agroup3 . _v_title , <EOL> "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> def test01b ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . move_node ( '<STR_LIT>' , '<STR_LIT:/>' , '<STR_LIT>' ) <EOL> self . h5file . move_node ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . agroup . _v_title , "<STR_LIT>" ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . agroup2 . agroup4 . _v_title , <EOL> "<STR_LIT>" ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> def test02 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . move_node ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . anarray . title , "<STR_LIT>" ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( <EOL> self . h5file . root . agroup2 . anarray2 . title , "<STR_LIT>" ) <EOL> def test03 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . move_node ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> table = self . h5file . root . table <EOL> self . assertTrue ( table . cols . var1 . index is not None ) <EOL> self . assertTrue ( table . cols . var2 . index is not None ) <EOL> self . assertTrue ( table . cols . var3 . index is not None ) <EOL> self . assertTrue ( table . cols . var4 . index is None ) <EOL> self . assertEqual ( table . cols . var1 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( table . cols . var2 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( table . cols . var3 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( self . h5file . root . table . title , "<STR_LIT>" ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . agroup2 . table2 . title , "<STR_LIT>" ) <EOL> table = self . h5file . root . agroup2 . table2 <EOL> self . assertTrue ( table . cols . var1 . index is not None ) <EOL> self . assertTrue ( table . cols . var2 . index is not None ) <EOL> self . assertTrue ( table . cols . var3 . index is not None ) <EOL> self . assertEqual ( table . cols . var1 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( table . cols . var2 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( table . cols . var3 . index . nelements , minRowIndex ) <EOL> self . assertTrue ( table . cols . var4 . index is None ) <EOL> class RemoveNodeTestCase ( common . TempFileMixin , TestCase ) : <EOL> """<STR_LIT>""" <EOL> def setUp ( self ) : <EOL> super ( RemoveNodeTestCase , self ) . setUp ( ) <EOL> h5file = self . h5file <EOL> root = h5file . root <EOL> h5file . create_array ( root , '<STR_LIT>' , [ <NUM_LIT:1> , <NUM_LIT:2> ] , title = "<STR_LIT>" ) <EOL> h5file . create_array ( root , '<STR_LIT>' , [ <NUM_LIT:1> ] , "<STR_LIT>" ) <EOL> group = h5file . create_group ( root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> h5file . create_array ( group , '<STR_LIT>' , [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> h5file . create_array ( group , '<STR_LIT>' , [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> h5file . create_group ( root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> h5file . create_group ( group , '<STR_LIT>' , "<STR_LIT>" ) <EOL> populateTable ( self . h5file . root , '<STR_LIT>' ) <EOL> def test00 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . remove_node ( '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . anarray . title , "<STR_LIT>" ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> def test00b ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . remove_node ( '<STR_LIT>' ) <EOL> self . h5file . remove_node ( '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . anarray . title , "<STR_LIT>" ) <EOL> self . assertEqual ( <EOL> self . h5file . root . agroup . anarray2 . title , "<STR_LIT>" ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> def test00c ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . remove_node ( '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> table = self . h5file . root . table <EOL> self . assertTrue ( table . cols . var1 . index is not None ) <EOL> self . assertTrue ( table . cols . var2 . index is not None ) <EOL> self . assertTrue ( table . cols . var3 . index is not None ) <EOL> self . assertTrue ( table . cols . var4 . index is None ) <EOL> self . assertEqual ( table . cols . var1 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( table . cols . var2 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( table . cols . var3 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( self . h5file . root . table . title , "<STR_LIT>" ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> def test01 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . remove_node ( '<STR_LIT>' , recursive = <NUM_LIT:1> ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . agroup . _v_title , "<STR_LIT>" ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> def test01b ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . remove_node ( '<STR_LIT>' , recursive = <NUM_LIT:1> ) <EOL> self . h5file . remove_node ( '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . agroup . _v_title , "<STR_LIT>" ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> class CopyNodeTestCase ( common . TempFileMixin , TestCase ) : <EOL> """<STR_LIT>""" <EOL> def setUp ( self ) : <EOL> super ( CopyNodeTestCase , self ) . setUp ( ) <EOL> h5file = self . h5file <EOL> root = h5file . root <EOL> h5file . create_array ( root , '<STR_LIT>' , [ <NUM_LIT:1> , <NUM_LIT:2> ] , title = "<STR_LIT>" ) <EOL> h5file . create_array ( root , '<STR_LIT>' , [ <NUM_LIT:1> ] , "<STR_LIT>" ) <EOL> group = h5file . create_group ( root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> h5file . create_array ( group , '<STR_LIT>' , [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> h5file . create_array ( group , '<STR_LIT>' , [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> h5file . create_group ( root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> h5file . create_group ( group , '<STR_LIT>' , "<STR_LIT>" ) <EOL> populateTable ( self . h5file . root , '<STR_LIT>' ) <EOL> def test00_copyLeaf ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> new_node = self . h5file . copy_node ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( self . h5file . root . agroup . agroup3 . anarray is new_node ) <EOL> def test00b_copyTable ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> warnings . filterwarnings ( "<STR_LIT:ignore>" , category = UserWarning ) <EOL> table = self . h5file . copy_node ( <EOL> '<STR_LIT>' , '<STR_LIT>' , propindexes = True ) <EOL> warnings . filterwarnings ( "<STR_LIT:default>" , category = UserWarning ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> table = self . h5file . root . agroup . agroup3 . table <EOL> self . assertEqual ( table . title , "<STR_LIT>" ) <EOL> self . assertTrue ( table . cols . var1 . index is not None ) <EOL> self . assertTrue ( table . cols . var2 . index is not None ) <EOL> self . assertTrue ( table . cols . var3 . index is not None ) <EOL> self . assertEqual ( table . cols . var1 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( table . cols . var2 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( table . cols . var3 . index . nelements , minRowIndex ) <EOL> self . assertTrue ( table . cols . var4 . index is None ) <EOL> self . h5file . undo ( ) <EOL> table = self . h5file . root . table <EOL> self . assertTrue ( table . cols . var1 . index is not None ) <EOL> self . assertTrue ( table . cols . var2 . index is not None ) <EOL> self . assertTrue ( table . cols . var3 . index is not None ) <EOL> self . assertTrue ( table . cols . var4 . index is None ) <EOL> self . assertEqual ( table . cols . var1 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( table . cols . var2 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( table . cols . var3 . index . nelements , minRowIndex ) <EOL> self . assertTrue ( "<STR_LIT>" not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> self . assertTrue ( "<STR_LIT>" in self . h5file ) <EOL> table = self . h5file . root . agroup . agroup3 . table <EOL> self . assertEqual ( table . title , "<STR_LIT>" ) <EOL> self . assertTrue ( table . cols . var1 . index is not None ) <EOL> self . assertTrue ( table . cols . var2 . index is not None ) <EOL> self . assertTrue ( table . cols . var3 . index is not None ) <EOL> self . assertEqual ( table . cols . var1 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( table . cols . var2 . index . nelements , minRowIndex ) <EOL> self . assertEqual ( table . cols . var3 . index . nelements , minRowIndex ) <EOL> self . assertTrue ( table . cols . var4 . index is None ) <EOL> def test01_copyGroup ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> new_node = self . h5file . copy_node ( <EOL> '<STR_LIT>' , newname = '<STR_LIT>' , recursive = True ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( self . h5file . root . acopy is new_node ) <EOL> def test02_copyLeafOverwrite ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % <EOL> self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> oldNode = self . h5file . root . agroup <EOL> new_node = self . h5file . copy_node ( <EOL> '<STR_LIT>' , newname = '<STR_LIT>' , overwrite = True ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( self . h5file . root . agroup is oldNode ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( self . h5file . root . agroup is new_node ) <EOL> def test03_copyChildren ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % <EOL> self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . copy_children ( '<STR_LIT>' , '<STR_LIT>' , recursive = True ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> class ComplexTestCase ( common . TempFileMixin , TestCase ) : <EOL> """<STR_LIT>""" <EOL> def setUp ( self ) : <EOL> super ( ComplexTestCase , self ) . setUp ( ) <EOL> h5file = self . h5file <EOL> root = h5file . root <EOL> h5file . create_array ( root , '<STR_LIT>' , [ <NUM_LIT:1> , <NUM_LIT:2> ] , title = "<STR_LIT>" ) <EOL> h5file . create_array ( root , '<STR_LIT>' , [ <NUM_LIT:1> ] , "<STR_LIT>" ) <EOL> group = h5file . create_group ( root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> h5file . create_array ( group , '<STR_LIT>' , [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> h5file . create_array ( group , '<STR_LIT>' , [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> h5file . create_group ( root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> h5file . create_group ( group , '<STR_LIT>' , "<STR_LIT>" ) <EOL> def test00 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_array ( self . h5file . root , '<STR_LIT>' , <EOL> [ <NUM_LIT:1> ] , "<STR_LIT>" ) <EOL> self . h5file . create_group ( self . h5file . root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> new_node = self . h5file . copy_node ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> new_node = self . h5file . copy_children ( <EOL> '<STR_LIT>' , '<STR_LIT>' , recursive = <NUM_LIT:1> ) <EOL> self . h5file . rename_node ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> new_node = self . h5file . copy_node ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . h5file . remove_node ( '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . assertTrue ( self . h5file . root . agroup . anarray3 is new_node ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> def test01 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . remove_node ( '<STR_LIT>' ) <EOL> self . h5file . create_array ( self . h5file . root , '<STR_LIT>' , <EOL> [ <NUM_LIT:2> ] , "<STR_LIT>" ) <EOL> self . h5file . remove_node ( '<STR_LIT>' ) <EOL> self . h5file . create_array ( self . h5file . root , '<STR_LIT>' , <EOL> [ <NUM_LIT:3> ] , "<STR_LIT>" ) <EOL> self . h5file . remove_node ( '<STR_LIT>' ) <EOL> self . h5file . create_array ( self . h5file . root , '<STR_LIT>' , <EOL> [ <NUM_LIT:4> ] , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . assertEqual ( self . h5file . root . anarray . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . anarray [ : ] , [ <NUM_LIT:1> ] ) <EOL> self . h5file . redo ( ) <EOL> self . assertEqual ( self . h5file . root . anarray . title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . anarray [ : ] , [ <NUM_LIT:4> ] ) <EOL> def test02 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . remove_node ( '<STR_LIT>' ) <EOL> self . h5file . create_group ( self . h5file . root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . remove_node ( '<STR_LIT>' ) <EOL> self . h5file . create_group ( self . h5file . root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . remove_node ( '<STR_LIT>' ) <EOL> self . h5file . create_group ( self . h5file . root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . create_group ( self . h5file . root . agroup2 , '<STR_LIT>' , <EOL> "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . assertEqual ( self . h5file . root . agroup2 . _v_title , "<STR_LIT>" ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertEqual ( self . h5file . root . agroup2 . _v_title , "<STR_LIT>" ) <EOL> self . assertEqual ( self . h5file . root . agroup2 . agroup5 . _v_title , <EOL> "<STR_LIT>" ) <EOL> def test03 ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . remove_node ( '<STR_LIT>' , recursive = <NUM_LIT:1> ) <EOL> self . h5file . create_group ( self . h5file . root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . remove_node ( '<STR_LIT>' ) <EOL> self . h5file . create_group ( self . h5file . root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . remove_node ( '<STR_LIT>' ) <EOL> self . h5file . create_group ( self . h5file . root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . create_group ( self . h5file . root . agroup , '<STR_LIT>' , <EOL> "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . agroup . _v_title , "<STR_LIT>" ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertEqual ( self . h5file . root . agroup . _v_title , "<STR_LIT>" ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertEqual ( <EOL> self . h5file . root . agroup . agroup5 . _v_title , "<STR_LIT>" ) <EOL> def test03b ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> self . h5file . enable_undo ( ) <EOL> self . h5file . create_group ( self . h5file . root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . create_group ( self . h5file . root . agroup3 , '<STR_LIT>' , <EOL> "<STR_LIT>" ) <EOL> self . h5file . remove_node ( '<STR_LIT>' , recursive = <NUM_LIT:1> ) <EOL> self . h5file . create_group ( self . h5file . root , '<STR_LIT>' , "<STR_LIT>" ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . h5file . redo ( ) <EOL> self . assertEqual ( self . h5file . root . agroup3 . _v_title , "<STR_LIT>" ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> class AttributesTestCase ( common . TempFileMixin , TestCase ) : <EOL> """<STR_LIT>""" <EOL> def setUp ( self ) : <EOL> super ( AttributesTestCase , self ) . setUp ( ) <EOL> array = self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> , <NUM_LIT:2> ] ) <EOL> attrs = array . attrs <EOL> attrs . attr_1 = <NUM_LIT:10> <EOL> attrs . attr_2 = <NUM_LIT:20> <EOL> attrs . attr_3 = <NUM_LIT:30> <EOL> def test00_setAttr ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> array = self . h5file . root . array <EOL> attrs = array . attrs <EOL> self . h5file . enable_undo ( ) <EOL> setattr ( attrs , '<STR_LIT>' , <NUM_LIT:0> ) <EOL> self . assertTrue ( '<STR_LIT>' in attrs ) <EOL> self . assertEqual ( attrs . attr_0 , <NUM_LIT:0> ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( '<STR_LIT>' not in attrs ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( '<STR_LIT>' in attrs ) <EOL> self . assertEqual ( attrs . attr_0 , <NUM_LIT:0> ) <EOL> def test01_setAttrExisting ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % <EOL> self . __class__ . __name__ ) <EOL> array = self . h5file . root . array <EOL> attrs = array . attrs <EOL> self . h5file . enable_undo ( ) <EOL> setattr ( attrs , '<STR_LIT>' , <NUM_LIT:11> ) <EOL> self . assertTrue ( '<STR_LIT>' in attrs ) <EOL> self . assertEqual ( attrs . attr_1 , <NUM_LIT:11> ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( '<STR_LIT>' in attrs ) <EOL> self . assertEqual ( attrs . attr_1 , <NUM_LIT:10> ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( '<STR_LIT>' in attrs ) <EOL> self . assertEqual ( attrs . attr_1 , <NUM_LIT:11> ) <EOL> def test02_delAttr ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> array = self . h5file . root . array <EOL> attrs = array . attrs <EOL> self . h5file . enable_undo ( ) <EOL> delattr ( attrs , '<STR_LIT>' ) <EOL> self . assertTrue ( '<STR_LIT>' not in attrs ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( '<STR_LIT>' in attrs ) <EOL> self . assertEqual ( attrs . attr_1 , <NUM_LIT:10> ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( '<STR_LIT>' not in attrs ) <EOL> def test03_copyNodeAttrs ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % <EOL> self . __class__ . __name__ ) <EOL> rattrs = self . h5file . root . _v_attrs <EOL> rattrs . attr_0 = <NUM_LIT:0> <EOL> rattrs . attr_1 = <NUM_LIT:100> <EOL> array = self . h5file . root . array <EOL> attrs = array . attrs <EOL> self . h5file . enable_undo ( ) <EOL> attrs . _f_copy ( self . h5file . root ) <EOL> self . assertEqual ( rattrs . attr_0 , <NUM_LIT:0> ) <EOL> self . assertEqual ( rattrs . attr_1 , <NUM_LIT:10> ) <EOL> self . assertEqual ( rattrs . attr_2 , <NUM_LIT:20> ) <EOL> self . assertEqual ( rattrs . attr_3 , <NUM_LIT:30> ) <EOL> self . h5file . undo ( ) <EOL> self . assertEqual ( rattrs . attr_0 , <NUM_LIT:0> ) <EOL> self . assertEqual ( rattrs . attr_1 , <NUM_LIT:100> ) <EOL> self . assertTrue ( '<STR_LIT>' not in rattrs ) <EOL> self . assertTrue ( '<STR_LIT>' not in rattrs ) <EOL> self . h5file . redo ( ) <EOL> self . assertEqual ( rattrs . attr_0 , <NUM_LIT:0> ) <EOL> self . assertEqual ( rattrs . attr_1 , <NUM_LIT:10> ) <EOL> self . assertEqual ( rattrs . attr_2 , <NUM_LIT:20> ) <EOL> self . assertEqual ( rattrs . attr_3 , <NUM_LIT:30> ) <EOL> def test04_replaceNode ( self ) : <EOL> """<STR_LIT>""" <EOL> if common . verbose : <EOL> print ( '<STR_LIT:\n>' , '<STR_LIT>' * <NUM_LIT:30> ) <EOL> print ( "<STR_LIT>" % self . __class__ . __name__ ) <EOL> array = self . h5file . root . array <EOL> attrs = array . attrs <EOL> self . h5file . enable_undo ( ) <EOL> attrs . attr_1 = <NUM_LIT:11> <EOL> self . h5file . remove_node ( '<STR_LIT>' ) <EOL> arr = self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> ] ) <EOL> arr . attrs . attr_1 = <NUM_LIT:12> <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file . root . array . attrs ) <EOL> self . assertEqual ( self . h5file . root . array . attrs . attr_1 , <NUM_LIT:10> ) <EOL> self . h5file . redo ( ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file . root . array . attrs ) <EOL> self . assertEqual ( self . h5file . root . array . attrs . attr_1 , <NUM_LIT:12> ) <EOL> class NotLoggedTestCase ( common . TempFileMixin , TestCase ) : <EOL> """<STR_LIT>""" <EOL> class NotLoggedArray ( NotLoggedMixin , tables . Array ) : <EOL> pass <EOL> def test00_hierarchy ( self ) : <EOL> """<STR_LIT>""" <EOL> self . h5file . create_group ( '<STR_LIT:/>' , '<STR_LIT>' ) <EOL> self . h5file . enable_undo ( ) <EOL> arr = self . NotLoggedArray ( self . h5file . root , '<STR_LIT:test>' , <EOL> [ <NUM_LIT:1> ] , self . _getMethodName ( ) ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> arr . move ( '<STR_LIT>' ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> arr . remove ( ) <EOL> self . h5file . undo ( ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> def test01_attributes ( self ) : <EOL> """<STR_LIT>""" <EOL> arr = self . NotLoggedArray ( self . h5file . root , '<STR_LIT:test>' , <EOL> [ <NUM_LIT:1> ] , self . _getMethodName ( ) ) <EOL> self . h5file . enable_undo ( ) <EOL> arr . _v_attrs . foo = '<STR_LIT:bar>' <EOL> self . h5file . undo ( ) <EOL> self . assertEqual ( arr . _v_attrs . foo , '<STR_LIT:bar>' ) <EOL> arr . _v_attrs . foo = '<STR_LIT>' <EOL> self . h5file . undo ( ) <EOL> self . assertEqual ( arr . _v_attrs . foo , '<STR_LIT>' ) <EOL> del arr . _v_attrs . foo <EOL> self . h5file . undo ( ) <EOL> self . assertRaises ( AttributeError , getattr , arr . _v_attrs , '<STR_LIT:foo>' ) <EOL> class CreateParentsTestCase ( common . TempFileMixin , TestCase ) : <EOL> """<STR_LIT>""" <EOL> def setUp ( self ) : <EOL> super ( CreateParentsTestCase , self ) . setUp ( ) <EOL> g1 = self . h5file . create_group ( '<STR_LIT:/>' , '<STR_LIT>' ) <EOL> self . h5file . create_group ( g1 , '<STR_LIT>' ) <EOL> def existing ( self , paths ) : <EOL> """<STR_LIT>""" <EOL> return frozenset ( path for path in paths if path in self . h5file ) <EOL> def basetest ( self , doit , pre , post ) : <EOL> pre ( ) <EOL> self . h5file . enable_undo ( ) <EOL> paths = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> for newpath in paths : <EOL> before = self . existing ( paths ) <EOL> doit ( newpath ) <EOL> after = self . existing ( paths ) <EOL> self . assertTrue ( after . issuperset ( before ) ) <EOL> self . h5file . undo ( ) <EOL> post ( newpath ) <EOL> after = self . existing ( paths ) <EOL> self . assertEqual ( after , before ) <EOL> def test00_create ( self ) : <EOL> """<STR_LIT>""" <EOL> def pre ( ) : <EOL> pass <EOL> def doit ( newpath ) : <EOL> self . h5file . create_array ( newpath , '<STR_LIT>' , [ <NUM_LIT:1> ] , createparents = True ) <EOL> self . assertTrue ( join_path ( newpath , '<STR_LIT>' ) in self . h5file ) <EOL> def post ( newpath ) : <EOL> self . assertTrue ( join_path ( newpath , '<STR_LIT>' ) not in self . h5file ) <EOL> self . basetest ( doit , pre , post ) <EOL> def test01_move ( self ) : <EOL> """<STR_LIT>""" <EOL> def pre ( ) : <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> ] ) <EOL> def doit ( newpath ) : <EOL> self . h5file . move_node ( '<STR_LIT>' , newpath , createparents = True ) <EOL> self . assertTrue ( '<STR_LIT>' not in self . h5file ) <EOL> self . assertTrue ( join_path ( newpath , '<STR_LIT>' ) in self . h5file ) <EOL> def post ( newpath ) : <EOL> self . assertTrue ( '<STR_LIT>' in self . h5file ) <EOL> self . assertTrue ( join_path ( newpath , '<STR_LIT>' ) not in self . h5file ) <EOL> self . basetest ( doit , pre , post ) <EOL> def test02_copy ( self ) : <EOL> """<STR_LIT>""" <EOL> def pre ( ) : <EOL> self . h5file . create_array ( '<STR_LIT:/>' , '<STR_LIT>' , [ <NUM_LIT:1> ] ) <EOL> def doit ( newpath ) : <EOL> self . h5file . copy_node ( '<STR_LIT>' , newpath , createparents = True ) <EOL> self . assertTrue ( join_path ( newpath , '<STR_LIT>' ) in self . h5file ) <EOL> def post ( newpath ) : <EOL> self . assertTrue ( join_path ( newpath , '<STR_LIT>' ) not in self . h5file ) <EOL> self . basetest ( doit , pre , post ) <EOL> def test03_copyChildren ( self ) : <EOL> """<STR_LIT>""" <EOL> def pre ( ) : <EOL> g = self . h5file . create_group ( '<STR_LIT:/>' , '<STR_LIT>' ) <EOL> self . h5file . create_array ( g , '<STR_LIT>' , [ <NUM_LIT:1> ] ) <EOL> self . h5file . create_array ( g , '<STR_LIT>' , [ <NUM_LIT:1> ] ) <EOL> def doit ( newpath ) : <EOL> self . h5file . copy_children ( '<STR_LIT>' , newpath , createparents = True ) <EOL> self . assertTrue ( join_path ( newpath , '<STR_LIT>' ) in self . h5file ) <EOL> self . assertTrue ( join_path ( newpath , '<STR_LIT>' ) in self . h5file ) <EOL> def post ( newpath ) : <EOL> self . assertTrue ( join_path ( newpath , '<STR_LIT>' ) not in self . h5file ) <EOL> self . assertTrue ( join_path ( newpath , '<STR_LIT>' ) not in self . h5file ) <EOL> self . basetest ( doit , pre , post ) <EOL> def suite ( ) : <EOL> theSuite = unittest . TestSuite ( ) <EOL> niter = <NUM_LIT:1> <EOL> for n in range ( niter ) : <EOL> theSuite . addTest ( unittest . makeSuite ( BasicTestCase ) ) <EOL> theSuite . addTest ( unittest . makeSuite ( PersistenceTestCase ) ) <EOL> theSuite . addTest ( unittest . makeSuite ( CreateArrayTestCase ) ) <EOL> theSuite . addTest ( unittest . makeSuite ( CreateGroupTestCase ) ) <EOL> theSuite . addTest ( unittest . makeSuite ( RenameNodeTestCase ) ) <EOL> theSuite . addTest ( unittest . makeSuite ( MoveNodeTestCase ) ) <EOL> theSuite . addTest ( unittest . makeSuite ( RemoveNodeTestCase ) ) <EOL> theSuite . addTest ( unittest . makeSuite ( CopyNodeTestCase ) ) <EOL> theSuite . addTest ( unittest . makeSuite ( AttributesTestCase ) ) <EOL> theSuite . addTest ( unittest . makeSuite ( ComplexTestCase ) ) <EOL> theSuite . addTest ( unittest . makeSuite ( NotLoggedTestCase ) ) <EOL> theSuite . addTest ( unittest . makeSuite ( CreateParentsTestCase ) ) <EOL> if common . heavy : <EOL> pass <EOL> return theSuite <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> import sys <EOL> common . parse_argv ( sys . argv ) <EOL> common . print_versions ( ) <EOL> unittest . main ( defaultTest = '<STR_LIT>' ) </s>
<s> """<STR_LIT>""" <EOL> import pylons <EOL> from pylons . controllers import WSGIController <EOL> def get_pylons ( decorator_args ) : <EOL> """<STR_LIT>""" <EOL> if decorator_args : <EOL> controller = decorator_args [ <NUM_LIT:0> ] <EOL> if isinstance ( controller , WSGIController ) : <EOL> return controller . _py_object <EOL> return pylons </s>
<s> import warnings <EOL> from paste . fixture import TestApp <EOL> from paste . registry import RegistryManager <EOL> from __init__ import TestWSGIController <EOL> def make_cache_controller_app ( ) : <EOL> from pylons . testutil import ControllerWrap , SetupCacheGlobal <EOL> from pylons . decorators import jsonify <EOL> from pylons . controllers import WSGIController <EOL> class CacheController ( WSGIController ) : <EOL> @ jsonify <EOL> def test_bad_json ( self ) : <EOL> return [ "<STR_LIT>" ] <EOL> @ jsonify <EOL> def test_bad_json2 ( self ) : <EOL> return ( "<STR_LIT>" , ) <EOL> @ jsonify <EOL> def test_good_json ( self ) : <EOL> return dict ( fred = <NUM_LIT> ) <EOL> environ = { } <EOL> app = ControllerWrap ( CacheController ) <EOL> app = sap = SetupCacheGlobal ( app , environ ) <EOL> app = RegistryManager ( app ) <EOL> app = TestApp ( app ) <EOL> return app , environ <EOL> class TestJsonifyDecorator ( TestWSGIController ) : <EOL> def setUp ( self ) : <EOL> self . app , environ = make_cache_controller_app ( ) <EOL> TestWSGIController . setUp ( self ) <EOL> environ . update ( self . environ ) <EOL> warnings . simplefilter ( '<STR_LIT:error>' , Warning ) <EOL> def tearDown ( self ) : <EOL> warnings . simplefilter ( '<STR_LIT>' , Warning ) <EOL> def test_bad_json ( self ) : <EOL> for action in '<STR_LIT>' , '<STR_LIT>' : <EOL> try : <EOL> response = self . get_response ( action = action ) <EOL> except Warning , msg : <EOL> assert '<STR_LIT>' in msg [ <NUM_LIT:0> ] <EOL> def test_good_json ( self ) : <EOL> response = self . get_response ( action = '<STR_LIT>' ) <EOL> assert '<STR_LIT>' in response <EOL> assert response . header ( '<STR_LIT:Content-Type>' ) == '<STR_LIT>' </s>
<s> """<STR_LIT>""" </s>
<s> import os <EOL> import sys <EOL> from setuptools import setup , find_packages <EOL> here = os . path . abspath ( os . path . dirname ( __file__ ) ) <EOL> if sys . version_info [ <NUM_LIT:0> ] > <NUM_LIT:2> : <EOL> README = open ( os . path . join ( here , '<STR_LIT>' ) , encoding = "<STR_LIT:utf-8>" ) . read ( ) <EOL> CHANGES = open ( os . path . join ( here , '<STR_LIT>' ) , encoding = "<STR_LIT:utf-8>" ) . read ( ) <EOL> else : <EOL> README = open ( os . path . join ( here , '<STR_LIT>' ) ) . read ( ) <EOL> CHANGES = open ( os . path . join ( here , '<STR_LIT>' ) ) . read ( ) <EOL> requires = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> ] <EOL> if ( <NUM_LIT:3> , ) < sys . version_info < ( <NUM_LIT:3> , <NUM_LIT:3> ) : <EOL> requires . extend ( [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> ] ) <EOL> else : <EOL> requires . extend ( [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> ] ) <EOL> try : <EOL> import wsgiref <EOL> except ImportError : <EOL> requires . append ( '<STR_LIT>' ) <EOL> testing_extras = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> docs_extras = [ '<STR_LIT>' , '<STR_LIT>' ] <EOL> setup ( name = '<STR_LIT>' , <EOL> version = '<STR_LIT>' , <EOL> description = '<STR_LIT>' , <EOL> long_description = README + '<STR_LIT>' + CHANGES , <EOL> classifiers = [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ] , <EOL> keywords = '<STR_LIT>' , <EOL> author = "<STR_LIT>" , <EOL> author_email = "<STR_LIT>" , <EOL> maintainer = "<STR_LIT>" , <EOL> maintainer_email = "<STR_LIT>" , <EOL> url = "<STR_LIT>" , <EOL> license = "<STR_LIT>" , <EOL> packages = find_packages ( ) , <EOL> include_package_data = True , <EOL> zip_safe = False , <EOL> install_requires = requires , <EOL> extras_require = { <EOL> '<STR_LIT>' : testing_extras , <EOL> '<STR_LIT>' : docs_extras , <EOL> } , <EOL> tests_require = requires + [ '<STR_LIT>' ] , <EOL> test_suite = "<STR_LIT>" , <EOL> entry_points = """<STR_LIT>""" , <EOL> ) </s>
<s> import cryptacular . bcrypt <EOL> from sqlalchemy import ( <EOL> Table , <EOL> Column , <EOL> ForeignKey , <EOL> ) <EOL> from sqlalchemy . orm import ( <EOL> scoped_session , <EOL> sessionmaker , <EOL> relation , <EOL> backref , <EOL> column_property , <EOL> synonym , <EOL> joinedload , <EOL> ) <EOL> from sqlalchemy . types import ( <EOL> Integer , <EOL> Unicode , <EOL> UnicodeText , <EOL> ) <EOL> from sqlalchemy . sql import func <EOL> from sqlalchemy . ext . declarative import declarative_base <EOL> from zope . sqlalchemy import ZopeTransactionExtension <EOL> from pyramid . security import ( <EOL> Everyone , <EOL> Authenticated , <EOL> Allow , <EOL> ) <EOL> DBSession = scoped_session ( sessionmaker ( extension = ZopeTransactionExtension ( ) ) ) <EOL> Base = declarative_base ( ) <EOL> crypt = cryptacular . bcrypt . BCRYPTPasswordManager ( ) <EOL> def hash_password ( password ) : <EOL> return unicode ( crypt . encode ( password ) ) <EOL> class User ( Base ) : <EOL> """<STR_LIT>""" <EOL> __tablename__ = '<STR_LIT>' <EOL> user_id = Column ( Integer , primary_key = True ) <EOL> username = Column ( Unicode ( <NUM_LIT:20> ) , unique = True ) <EOL> name = Column ( Unicode ( <NUM_LIT:50> ) ) <EOL> email = Column ( Unicode ( <NUM_LIT:50> ) ) <EOL> hits = Column ( Integer , default = <NUM_LIT:0> ) <EOL> misses = Column ( Integer , default = <NUM_LIT:0> ) <EOL> delivered_hits = Column ( Integer , default = <NUM_LIT:0> ) <EOL> delivered_misses = Column ( Integer , default = <NUM_LIT:0> ) <EOL> _password = Column ( '<STR_LIT:password>' , Unicode ( <NUM_LIT> ) ) <EOL> def _get_password ( self ) : <EOL> return self . _password <EOL> def _set_password ( self , password ) : <EOL> self . _password = hash_password ( password ) <EOL> password = property ( _get_password , _set_password ) <EOL> password = synonym ( '<STR_LIT>' , descriptor = password ) <EOL> def __init__ ( self , username , password , name , email ) : <EOL> self . username = username <EOL> self . name = name <EOL> self . email = email <EOL> self . password = password <EOL> @ classmethod <EOL> def get_by_username ( cls , username ) : <EOL> return DBSession . query ( cls ) . filter ( cls . username == username ) . first ( ) <EOL> @ classmethod <EOL> def check_password ( cls , username , password ) : <EOL> user = cls . get_by_username ( username ) <EOL> if not user : <EOL> return False <EOL> return crypt . check ( user . password , password ) <EOL> ideas_tags = Table ( '<STR_LIT>' , Base . metadata , <EOL> Column ( '<STR_LIT>' , Integer , ForeignKey ( '<STR_LIT>' ) ) , <EOL> Column ( '<STR_LIT>' , Integer , ForeignKey ( '<STR_LIT>' ) ) <EOL> ) <EOL> class Tag ( Base ) : <EOL> """<STR_LIT>""" <EOL> __tablename__ = '<STR_LIT>' <EOL> tag_id = Column ( Integer , primary_key = True ) <EOL> name = Column ( Unicode ( <NUM_LIT:50> ) , unique = True , index = True ) <EOL> def __init__ ( self , name ) : <EOL> self . name = name <EOL> @ staticmethod <EOL> def extract_tags ( tags_string ) : <EOL> tags = tags_string . replace ( '<STR_LIT:;>' , '<STR_LIT:U+0020>' ) . replace ( '<STR_LIT:U+002C>' , '<STR_LIT:U+0020>' ) <EOL> tags = [ tag . lower ( ) for tag in tags . split ( ) ] <EOL> tags = set ( tags ) <EOL> return tags <EOL> @ classmethod <EOL> def get_by_name ( cls , tag_name ) : <EOL> tag = DBSession . query ( cls ) . filter ( cls . name == tag_name ) <EOL> return tag . first ( ) <EOL> @ classmethod <EOL> def create_tags ( cls , tags_string ) : <EOL> tags_list = cls . extract_tags ( tags_string ) <EOL> tags = [ ] <EOL> for tag_name in tags_list : <EOL> tag = cls . get_by_name ( tag_name ) <EOL> if not tag : <EOL> tag = Tag ( name = tag_name ) <EOL> DBSession . add ( tag ) <EOL> tags . append ( tag ) <EOL> return tags <EOL> @ classmethod <EOL> def tag_counts ( cls ) : <EOL> query = DBSession . query ( Tag . name , func . count ( '<STR_LIT:*>' ) ) <EOL> return query . join ( '<STR_LIT>' ) . group_by ( Tag . name ) <EOL> voted_users = Table ( '<STR_LIT>' , Base . metadata , <EOL> Column ( '<STR_LIT>' , Integer , ForeignKey ( '<STR_LIT>' ) ) , <EOL> Column ( '<STR_LIT>' , Integer , ForeignKey ( '<STR_LIT>' ) ) <EOL> ) <EOL> class Idea ( Base ) : <EOL> __tablename__ = '<STR_LIT>' <EOL> idea_id = Column ( Integer , primary_key = True ) <EOL> target_id = Column ( Integer , ForeignKey ( '<STR_LIT>' ) ) <EOL> comments = relation ( '<STR_LIT>' , cascade = "<STR_LIT>" , <EOL> backref = backref ( '<STR_LIT:target>' , remote_side = idea_id ) ) <EOL> author_id = Column ( Integer , ForeignKey ( '<STR_LIT>' ) ) <EOL> author = relation ( User , cascade = "<STR_LIT>" , backref = '<STR_LIT>' ) <EOL> title = Column ( UnicodeText ) <EOL> text = Column ( UnicodeText ) <EOL> hits = Column ( Integer , default = <NUM_LIT:0> ) <EOL> misses = Column ( Integer , default = <NUM_LIT:0> ) <EOL> tags = relation ( Tag , secondary = ideas_tags , backref = '<STR_LIT>' ) <EOL> voted_users = relation ( User , secondary = voted_users , lazy = '<STR_LIT>' , <EOL> backref = '<STR_LIT>' ) <EOL> hit_percentage = func . coalesce ( hits / ( hits + misses ) * <NUM_LIT:100> , <NUM_LIT:0> ) <EOL> hit_percentage = column_property ( hit_percentage . label ( '<STR_LIT>' ) ) <EOL> total_votes = column_property ( ( hits + misses ) . label ( '<STR_LIT>' ) ) <EOL> vote_differential = column_property ( <EOL> ( hits - misses ) . label ( '<STR_LIT>' ) <EOL> ) <EOL> @ classmethod <EOL> def get_query ( cls , with_joinedload = True ) : <EOL> query = DBSession . query ( cls ) <EOL> if with_joinedload : <EOL> query = query . options ( joinedload ( '<STR_LIT>' ) , joinedload ( '<STR_LIT>' ) ) <EOL> return query <EOL> @ classmethod <EOL> def get_by_id ( cls , idea_id , with_joinedload = True ) : <EOL> query = cls . get_query ( with_joinedload ) <EOL> return query . filter ( cls . idea_id == idea_id ) . first ( ) <EOL> @ classmethod <EOL> def get_by_tagname ( cls , tag_name , with_joinedload = True ) : <EOL> query = cls . get_query ( with_joinedload ) <EOL> return query . filter ( Idea . tags . any ( name = tag_name ) ) <EOL> @ classmethod <EOL> def ideas_bunch ( cls , order_by , how_many = <NUM_LIT:10> , with_joinedload = True ) : <EOL> query = cls . get_query ( with_joinedload ) . join ( '<STR_LIT>' ) <EOL> query = query . filter ( cls . target == None ) . order_by ( order_by ) <EOL> return query . limit ( how_many ) . all ( ) <EOL> def user_voted ( self , username ) : <EOL> return bool ( self . voted_users . filter_by ( username = username ) . first ( ) ) <EOL> def vote ( self , user , positive ) : <EOL> if positive : <EOL> self . hits += <NUM_LIT:1> <EOL> self . author . hits += <NUM_LIT:1> <EOL> user . delivered_hits += <NUM_LIT:1> <EOL> else : <EOL> self . misses += <NUM_LIT:1> <EOL> self . author . misses += <NUM_LIT:1> <EOL> user . delivered_misses += <NUM_LIT:1> <EOL> self . voted_users . append ( user ) <EOL> class RootFactory ( object ) : <EOL> __acl__ = [ <EOL> ( Allow , Everyone , '<STR_LIT>' ) , <EOL> ( Allow , Authenticated , '<STR_LIT>' ) <EOL> ] <EOL> def __init__ ( self , request ) : <EOL> pass </s>
<s> import json <EOL> import unittest <EOL> from pyramid import testing <EOL> import mock <EOL> class Test_acl_modified ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . request = testing . DummyRequest ( ) <EOL> self . config = testing . setUp ( request = self . request ) <EOL> def tearDown ( self ) : <EOL> testing . tearDown ( ) <EOL> def _callFUT ( self , event ) : <EOL> from . . subscribers import acl_modified <EOL> return acl_modified ( event ) <EOL> @ mock . patch ( '<STR_LIT>' ) <EOL> def test_it ( self , mock_get_auditlog ) : <EOL> from substanced . audit import AuditLog <EOL> self . request . user = Dummy ( { '<STR_LIT>' : <NUM_LIT:1> , '<STR_LIT>' : '<STR_LIT>' } ) <EOL> event = Dummy ( ) <EOL> context = testing . DummyResource ( ) <EOL> auditlog = AuditLog ( ) <EOL> mock_get_auditlog . side_effect = lambda c : auditlog <EOL> context . __oid__ = <NUM_LIT:5> <EOL> event . registry = _makeRegistry ( ) <EOL> event . object = context <EOL> event . old_acl = '<STR_LIT>' <EOL> event . new_acl = '<STR_LIT>' <EOL> self . _callFUT ( event ) <EOL> self . assertEqual ( len ( auditlog ) , <NUM_LIT:1> ) <EOL> entries = list ( auditlog . entries ) <EOL> entry = entries [ <NUM_LIT:0> ] <EOL> self . assertEqual ( entry [ <NUM_LIT:0> ] , <NUM_LIT:0> ) <EOL> self . assertEqual ( entry [ <NUM_LIT:1> ] , <NUM_LIT:0> ) <EOL> self . assertEqual ( entry [ <NUM_LIT:2> ] . name , '<STR_LIT>' ) <EOL> self . assertEqual ( entry [ <NUM_LIT:2> ] . oid , <NUM_LIT:5> ) <EOL> self . assertEqual ( <EOL> json . loads ( entry [ <NUM_LIT:2> ] . payload ) , <EOL> { <EOL> '<STR_LIT:time>' : entry [ <NUM_LIT:2> ] . timestamp , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : { '<STR_LIT>' : <NUM_LIT:1> , '<STR_LIT:name>' : '<STR_LIT>' } , <EOL> '<STR_LIT>' : '<STR_LIT:/>' , <EOL> '<STR_LIT>' : '<STR_LIT>' <EOL> } <EOL> ) <EOL> @ mock . patch ( '<STR_LIT>' ) <EOL> def test_it_nolog ( self , mock_get_auditlog ) : <EOL> mock_get_auditlog . side_effect = lambda c : None <EOL> event = Dummy ( ) <EOL> context = testing . DummyResource ( ) <EOL> context . __oid__ = <NUM_LIT:5> <EOL> event . object = context <EOL> self . assertEqual ( self . _callFUT ( event ) , None ) <EOL> _marker = object ( ) <EOL> class Test_content_added_moved_or_duplicated ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . request = testing . DummyRequest ( ) <EOL> self . config = testing . setUp ( request = self . request ) <EOL> def tearDown ( self ) : <EOL> testing . tearDown ( ) <EOL> def _callFUT ( self , event ) : <EOL> from . . subscribers import content_added_moved_or_duplicated <EOL> return content_added_moved_or_duplicated ( event ) <EOL> @ mock . patch ( '<STR_LIT>' ) <EOL> def test_it_added ( self , mock_get_auditlog ) : <EOL> auditlog = _makeAuditLog ( ) <EOL> mock_get_auditlog . side_effect = lambda c : auditlog <EOL> self . request . user = Dummy ( { '<STR_LIT>' : <NUM_LIT:1> , '<STR_LIT>' : '<STR_LIT>' } ) <EOL> event = _makeEvent ( ) <EOL> self . _callFUT ( event ) <EOL> self . assertEqual ( len ( auditlog ) , <NUM_LIT:1> ) <EOL> entries = list ( auditlog . entries ) <EOL> entry = entries [ <NUM_LIT:0> ] <EOL> self . assertEqual ( entry [ <NUM_LIT:0> ] , <NUM_LIT:0> ) <EOL> self . assertEqual ( entry [ <NUM_LIT:1> ] , <NUM_LIT:0> ) <EOL> self . assertEqual ( entry [ <NUM_LIT:2> ] . name , '<STR_LIT>' ) <EOL> self . assertEqual ( entry [ <NUM_LIT:2> ] . oid , <NUM_LIT:10> ) <EOL> self . assertEqual ( <EOL> json . loads ( entry [ <NUM_LIT:2> ] . payload ) , <EOL> { <EOL> '<STR_LIT>' : '<STR_LIT:/>' , <EOL> '<STR_LIT>' : <NUM_LIT:10> , <EOL> '<STR_LIT:object_name>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : { '<STR_LIT>' : <NUM_LIT:1> , '<STR_LIT:name>' : '<STR_LIT>' } , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:time>' : entry [ <NUM_LIT:2> ] . timestamp , <EOL> '<STR_LIT>' : <NUM_LIT:5> <EOL> } <EOL> ) <EOL> @ mock . patch ( '<STR_LIT>' ) <EOL> def test_it_added_noscribe ( self , mock_get_auditlog ) : <EOL> mock_get_auditlog . side_effect = lambda c : None <EOL> event = _makeEvent ( ) <EOL> self . _callFUT ( event ) <EOL> @ mock . patch ( '<STR_LIT>' ) <EOL> def test_it_moved ( self , mock_get_auditlog ) : <EOL> auditlog = _makeAuditLog ( ) <EOL> mock_get_auditlog . side_effect = lambda c : auditlog <EOL> self . request . user = Dummy ( { '<STR_LIT>' : <NUM_LIT:1> , '<STR_LIT>' : '<STR_LIT>' } ) <EOL> event = _makeEvent ( ) <EOL> event . moving = True <EOL> event . duplicating = None <EOL> self . _callFUT ( event ) <EOL> self . assertEqual ( len ( auditlog ) , <NUM_LIT:1> ) <EOL> entries = list ( auditlog . entries ) <EOL> entry = entries [ <NUM_LIT:0> ] <EOL> self . assertEqual ( entry [ <NUM_LIT:0> ] , <NUM_LIT:0> ) <EOL> self . assertEqual ( entry [ <NUM_LIT:1> ] , <NUM_LIT:0> ) <EOL> self . assertEqual ( entry [ <NUM_LIT:2> ] . name , '<STR_LIT>' ) <EOL> self . assertEqual ( entry [ <NUM_LIT:2> ] . oid , <NUM_LIT:10> ) <EOL> self . assertEqual ( <EOL> json . loads ( entry [ <NUM_LIT:2> ] . payload ) , <EOL> { <EOL> '<STR_LIT>' : '<STR_LIT:/>' , <EOL> '<STR_LIT>' : <NUM_LIT:10> , <EOL> '<STR_LIT:object_name>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : { '<STR_LIT>' : <NUM_LIT:1> , '<STR_LIT:name>' : '<STR_LIT>' } , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:time>' : entry [ <NUM_LIT:2> ] . timestamp , <EOL> '<STR_LIT>' : <NUM_LIT:5> <EOL> } <EOL> ) <EOL> @ mock . patch ( '<STR_LIT>' ) <EOL> def test_it_duplicated ( self , mock_get_auditlog ) : <EOL> auditlog = _makeAuditLog ( ) <EOL> mock_get_auditlog . side_effect = lambda c : auditlog <EOL> self . request . user = Dummy ( { '<STR_LIT>' : <NUM_LIT:1> , '<STR_LIT>' : '<STR_LIT>' } ) <EOL> event = _makeEvent ( ) <EOL> event . moving = None <EOL> event . duplicating = True <EOL> self . _callFUT ( event ) <EOL> self . assertEqual ( len ( auditlog ) , <NUM_LIT:1> ) <EOL> entries = list ( auditlog . entries ) <EOL> entry = entries [ <NUM_LIT:0> ] <EOL> self . assertEqual ( entry [ <NUM_LIT:0> ] , <NUM_LIT:0> ) <EOL> self . assertEqual ( entry [ <NUM_LIT:1> ] , <NUM_LIT:0> ) <EOL> self . assertEqual ( entry [ <NUM_LIT:2> ] . name , '<STR_LIT>' ) <EOL> self . assertEqual ( entry [ <NUM_LIT:2> ] . oid , <NUM_LIT:10> ) <EOL> self . assertEqual ( <EOL> json . loads ( entry [ <NUM_LIT:2> ] . payload ) , <EOL> { <EOL> '<STR_LIT>' : '<STR_LIT:/>' , <EOL> '<STR_LIT>' : <NUM_LIT:10> , <EOL> '<STR_LIT:object_name>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : { '<STR_LIT>' : <NUM_LIT:1> , '<STR_LIT:name>' : '<STR_LIT>' } , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:time>' : entry [ <NUM_LIT:2> ] . timestamp , <EOL> '<STR_LIT>' : <NUM_LIT:5> <EOL> } <EOL> ) <EOL> class Test_content_removed ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . request = testing . DummyRequest ( ) <EOL> self . config = testing . setUp ( request = self . request ) <EOL> def tearDown ( self ) : <EOL> testing . tearDown ( ) <EOL> def _callFUT ( self , event ) : <EOL> from . . subscribers import content_removed <EOL> return content_removed ( event ) <EOL> def test_it_moving ( self ) : <EOL> event = Dummy ( ) <EOL> event . moving = True <EOL> self . assertEqual ( self . _callFUT ( event ) , None ) <EOL> @ mock . patch ( '<STR_LIT>' ) <EOL> def test_it ( self , mock_get_auditlog ) : <EOL> auditlog = _makeAuditLog ( ) <EOL> mock_get_auditlog . side_effect = lambda c : auditlog <EOL> self . request . user = Dummy ( { '<STR_LIT>' : <NUM_LIT:1> , '<STR_LIT>' : '<STR_LIT>' } ) <EOL> event = _makeEvent ( ) <EOL> event . moving = None <EOL> event . duplicating = None <EOL> self . _callFUT ( event ) <EOL> self . assertEqual ( len ( auditlog ) , <NUM_LIT:1> ) <EOL> entries = list ( auditlog . entries ) <EOL> entry = entries [ <NUM_LIT:0> ] <EOL> self . assertEqual ( entry [ <NUM_LIT:0> ] , <NUM_LIT:0> ) <EOL> self . assertEqual ( entry [ <NUM_LIT:1> ] , <NUM_LIT:0> ) <EOL> self . assertEqual ( entry [ <NUM_LIT:2> ] . name , '<STR_LIT>' ) <EOL> self . assertEqual ( entry [ <NUM_LIT:2> ] . oid , <NUM_LIT:10> ) <EOL> self . assertEqual ( <EOL> json . loads ( entry [ <NUM_LIT:2> ] . payload ) , <EOL> { <EOL> '<STR_LIT>' : '<STR_LIT:/>' , <EOL> '<STR_LIT>' : <NUM_LIT:10> , <EOL> '<STR_LIT:object_name>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : { '<STR_LIT>' : <NUM_LIT:1> , '<STR_LIT:name>' : '<STR_LIT>' } , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:time>' : entry [ <NUM_LIT:2> ] . timestamp , <EOL> '<STR_LIT>' : <NUM_LIT:5> <EOL> } <EOL> ) <EOL> class Test_content_modified ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . request = testing . DummyRequest ( ) <EOL> self . config = testing . setUp ( request = self . request ) <EOL> def tearDown ( self ) : <EOL> testing . tearDown ( ) <EOL> def _callFUT ( self , event ) : <EOL> from . . subscribers import content_modified <EOL> return content_modified ( event ) <EOL> @ mock . patch ( '<STR_LIT>' ) <EOL> def test_it_noscribe ( self , mock_get_auditlog ) : <EOL> mock_get_auditlog . side_effect = lambda c : None <EOL> event = Dummy ( ) <EOL> context = testing . DummyResource ( ) <EOL> event . object = context <EOL> self . assertEqual ( self . _callFUT ( event ) , None ) <EOL> @ mock . patch ( '<STR_LIT>' ) <EOL> def test_it ( self , mock_get_auditlog ) : <EOL> auditlog = _makeAuditLog ( ) <EOL> mock_get_auditlog . side_effect = lambda c : auditlog <EOL> self . request . user = Dummy ( { '<STR_LIT>' : <NUM_LIT:1> , '<STR_LIT>' : '<STR_LIT>' } ) <EOL> event = Dummy ( ) <EOL> context = testing . DummyResource ( ) <EOL> context . __oid__ = <NUM_LIT:5> <EOL> event . registry = _makeRegistry ( ) <EOL> event . object = context <EOL> self . _callFUT ( event ) <EOL> self . assertEqual ( len ( auditlog ) , <NUM_LIT:1> ) <EOL> entries = list ( auditlog . entries ) <EOL> entry = entries [ <NUM_LIT:0> ] <EOL> self . assertEqual ( entry [ <NUM_LIT:0> ] , <NUM_LIT:0> ) <EOL> self . assertEqual ( entry [ <NUM_LIT:1> ] , <NUM_LIT:0> ) <EOL> self . assertEqual ( entry [ <NUM_LIT:2> ] . name , '<STR_LIT>' ) <EOL> self . assertEqual ( entry [ <NUM_LIT:2> ] . oid , <NUM_LIT:5> ) <EOL> self . assertEqual ( <EOL> json . loads ( entry [ <NUM_LIT:2> ] . payload ) , <EOL> { <EOL> '<STR_LIT>' : <NUM_LIT:5> , <EOL> '<STR_LIT>' : { '<STR_LIT>' : <NUM_LIT:1> , '<STR_LIT:name>' : '<STR_LIT>' } , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT:/>' , <EOL> '<STR_LIT:time>' : entry [ <NUM_LIT:2> ] . timestamp , <EOL> } , <EOL> ) <EOL> class Test_logged_in ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . request = testing . DummyRequest ( ) <EOL> self . config = testing . setUp ( request = self . request ) <EOL> def tearDown ( self ) : <EOL> testing . tearDown ( ) <EOL> def _callFUT ( self , event ) : <EOL> from . . subscribers import logged_in <EOL> return logged_in ( event ) <EOL> @ mock . patch ( '<STR_LIT>' ) <EOL> def test_it_noscribe ( self , mock_get_auditlog ) : <EOL> mock_get_auditlog . side_effect = lambda c : None <EOL> event = Dummy ( ) <EOL> event . request = Dummy ( ) <EOL> context = testing . DummyResource ( ) <EOL> event . request . context = context <EOL> self . assertEqual ( self . _callFUT ( event ) , None ) <EOL> @ mock . patch ( '<STR_LIT>' ) <EOL> def test_it_user_has_oid ( self , mock_get_auditlog ) : <EOL> auditlog = _makeAuditLog ( ) <EOL> mock_get_auditlog . side_effect = lambda c : auditlog <EOL> event = Dummy ( ) <EOL> event . request = Dummy ( ) <EOL> context = testing . DummyResource ( ) <EOL> event . request . context = context <EOL> user = Dummy ( ) <EOL> user . __oid__ = <NUM_LIT:5> <EOL> event . user = user <EOL> event . login = '<STR_LIT>' <EOL> self . _callFUT ( event ) <EOL> self . assertEqual ( len ( auditlog ) , <NUM_LIT:1> ) <EOL> entries = list ( auditlog . entries ) <EOL> entry = entries [ <NUM_LIT:0> ] <EOL> self . assertEqual ( entry [ <NUM_LIT:0> ] , <NUM_LIT:0> ) <EOL> self . assertEqual ( entry [ <NUM_LIT:1> ] , <NUM_LIT:0> ) <EOL> self . assertEqual ( entry [ <NUM_LIT:2> ] . name , '<STR_LIT>' ) <EOL> self . assertEqual ( entry [ <NUM_LIT:2> ] . oid , None ) <EOL> self . assertEqual ( <EOL> json . loads ( entry [ <NUM_LIT:2> ] . payload ) , <EOL> { <EOL> '<STR_LIT>' : <NUM_LIT:5> , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:time>' : entry [ <NUM_LIT:2> ] . timestamp , <EOL> } , <EOL> ) <EOL> @ mock . patch ( '<STR_LIT>' ) <EOL> def test_it_user_has_no_oid ( self , mock_get_auditlog ) : <EOL> auditlog = _makeAuditLog ( ) <EOL> mock_get_auditlog . side_effect = lambda c : auditlog <EOL> event = Dummy ( ) <EOL> event . request = Dummy ( ) <EOL> context = testing . DummyResource ( ) <EOL> event . request . context = context <EOL> user = Dummy ( ) <EOL> event . user = user <EOL> event . login = '<STR_LIT>' <EOL> self . _callFUT ( event ) <EOL> self . assertEqual ( len ( auditlog ) , <NUM_LIT:1> ) <EOL> entries = list ( auditlog . entries ) <EOL> entry = entries [ <NUM_LIT:0> ] <EOL> self . assertEqual ( entry [ <NUM_LIT:0> ] , <NUM_LIT:0> ) <EOL> self . assertEqual ( entry [ <NUM_LIT:1> ] , <NUM_LIT:0> ) <EOL> self . assertEqual ( entry [ <NUM_LIT:2> ] . name , '<STR_LIT>' ) <EOL> self . assertEqual ( entry [ <NUM_LIT:2> ] . oid , None ) <EOL> self . assertEqual ( <EOL> json . loads ( entry [ <NUM_LIT:2> ] . payload ) , <EOL> { <EOL> '<STR_LIT>' : None , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:time>' : entry [ <NUM_LIT:2> ] . timestamp , <EOL> } , <EOL> ) <EOL> class Test_root_added ( unittest . TestCase ) : <EOL> def _callFUT ( self , event ) : <EOL> from . . subscribers import root_added <EOL> return root_added ( event ) <EOL> @ mock . patch ( '<STR_LIT>' ) <EOL> def test_it ( self , mock_set_auditlog ) : <EOL> event = Dummy ( ) <EOL> root = Dummy ( ) <EOL> def is_set ( _root ) : <EOL> self . assertEqual ( _root , root ) <EOL> mock_set_auditlog . side_effect = is_set <EOL> event . object = root <EOL> self . _callFUT ( event ) <EOL> class Dummy ( object ) : <EOL> def __init__ ( self , kw = None ) : <EOL> if kw : <EOL> self . __dict__ . update ( kw ) <EOL> class DummyContentRegistry ( object ) : <EOL> def typeof ( self , content ) : <EOL> return '<STR_LIT>' <EOL> def _makeAuditLog ( ) : <EOL> from substanced . audit import AuditLog <EOL> auditlog = AuditLog ( ) <EOL> return auditlog <EOL> def _makeRegistry ( ) : <EOL> registry = Dummy ( ) <EOL> registry . content = DummyContentRegistry ( ) <EOL> return registry <EOL> def _makeEvent ( ) : <EOL> event = Dummy ( ) <EOL> event . moving = None <EOL> event . duplicating = None <EOL> event . parent = testing . DummyResource ( ) <EOL> event . parent . __oid__ = <NUM_LIT:10> <EOL> event . name = '<STR_LIT>' <EOL> context = testing . DummyResource ( ) <EOL> context . __oid__ = <NUM_LIT:5> <EOL> context . __parent__ = event . parent <EOL> event . registry = _makeRegistry ( ) <EOL> event . object = context <EOL> event . old_acl = '<STR_LIT>' <EOL> event . new_acl = '<STR_LIT>' <EOL> return event </s>
<s> import unittest <EOL> from pyramid import testing <EOL> class Test_root_factory ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . config = testing . setUp ( ) <EOL> def tearDown ( self ) : <EOL> testing . tearDown ( ) <EOL> def _callFUT ( self , request , transaction , get_connection , evolve_packages ) : <EOL> from . . import root_factory <EOL> return root_factory ( request , transaction , get_connection , <EOL> evolve_packages ) <EOL> def _makeRequest ( self , app_root = None ) : <EOL> request = Dummy ( ) <EOL> request . registry = DummyRegistry ( ) <EOL> request . registry . content = Dummy ( ) <EOL> request . registry . content . create = lambda * arg : app_root <EOL> return request <EOL> def test_without_app_root ( self ) : <EOL> txn = DummyTransaction ( ) <EOL> root = { } <EOL> gc = Dummy_get_connection ( root ) <EOL> ep = DummyFunction ( True ) <EOL> app_root = object ( ) <EOL> request = self . _makeRequest ( app_root ) <EOL> result = self . _callFUT ( request , txn , gc , ep ) <EOL> self . assertEqual ( result , app_root ) <EOL> self . assertTrue ( txn . committed ) <EOL> self . assertTrue ( txn . savepointed ) <EOL> self . assertTrue ( ep . called ) <EOL> def test_with_app_root ( self ) : <EOL> txn = DummyTransaction ( ) <EOL> app_root = object ( ) <EOL> root = { '<STR_LIT>' : app_root } <EOL> gc = Dummy_get_connection ( root ) <EOL> ep = DummyFunction ( True ) <EOL> request = testing . DummyRequest ( ) <EOL> result = self . _callFUT ( request , txn , gc , ep ) <EOL> self . assertEqual ( result , app_root ) <EOL> self . assertFalse ( txn . committed ) <EOL> class Test_includeme ( unittest . TestCase ) : <EOL> def test_it ( self ) : <EOL> from . . import ( <EOL> includeme , <EOL> connection_opened , <EOL> connection_will_close , <EOL> ZODBConnectionOpened , <EOL> ZODBConnectionWillClose , <EOL> ) <EOL> config = DummyConfig ( ) <EOL> includeme ( config ) <EOL> self . assertEqual ( <EOL> config . subscriptions , <EOL> [ ( connection_opened , ZODBConnectionOpened ) , <EOL> ( connection_will_close , ZODBConnectionWillClose ) , <EOL> ] <EOL> ) <EOL> class Test_connection_opened ( unittest . TestCase ) : <EOL> def test_it ( self ) : <EOL> from . . import connection_opened <EOL> event = DummyEvent ( ) <EOL> connection_opened ( event ) <EOL> self . assertEqual ( event . request . _zodb_tx_counts , ( <NUM_LIT:0> , <NUM_LIT:0> ) ) <EOL> class Test_connection_will_close ( unittest . TestCase ) : <EOL> def _callFUT ( self , event , statsd_incr ) : <EOL> from . . import connection_will_close <EOL> return connection_will_close ( event , statsd_incr ) <EOL> def test_no_tx_counts ( self ) : <EOL> event = DummyEvent ( ) <EOL> result = self . _callFUT ( event , None ) <EOL> self . assertEqual ( result , None ) <EOL> def test_with_postitive_tx_counts ( self ) : <EOL> event = DummyEvent ( <NUM_LIT:5> , <NUM_LIT:5> ) <EOL> event . request . _zodb_tx_counts = ( <NUM_LIT:1> , <NUM_LIT:1> ) <EOL> L = [ ] <EOL> def statsd_incr ( name , num , registry = None ) : <EOL> L . append ( ( name , num ) ) <EOL> self . _callFUT ( event , statsd_incr ) <EOL> self . assertEqual ( <EOL> L , <EOL> [ ( '<STR_LIT>' , <NUM_LIT:4> ) , ( '<STR_LIT>' , <NUM_LIT:4> ) ] <EOL> ) <EOL> def test_with_zero_tx_counts ( self ) : <EOL> event = DummyEvent ( <NUM_LIT:1> , <NUM_LIT:1> ) <EOL> event . request . _zodb_tx_counts = ( <NUM_LIT:1> , <NUM_LIT:1> ) <EOL> L = [ ] <EOL> self . _callFUT ( event , None ) <EOL> self . assertEqual ( <EOL> L , <EOL> [ ] <EOL> ) <EOL> class DummyTransaction ( object ) : <EOL> committed = False <EOL> savepointed = False <EOL> def commit ( self ) : <EOL> self . committed = True <EOL> def savepoint ( self ) : <EOL> self . savepointed = True <EOL> class Dummy_get_connection ( object ) : <EOL> def __init__ ( self , root ) : <EOL> self . _root = root <EOL> def root ( self ) : <EOL> return self . _root <EOL> def __call__ ( self , request ) : <EOL> return self <EOL> class DummyFunction ( object ) : <EOL> called = False <EOL> def __init__ ( self , result ) : <EOL> self . result = result <EOL> def __call__ ( self , * args , ** kw ) : <EOL> self . called = True <EOL> self . args = args <EOL> self . kw = kw <EOL> return self . result <EOL> class Dummy ( object ) : <EOL> pass <EOL> class DummyRegistry ( object ) : <EOL> def notify ( self , event ) : <EOL> self . event = event <EOL> class DummyConfig ( object ) : <EOL> def __init__ ( self ) : <EOL> self . subscriptions = [ ] <EOL> def add_subscriber ( self , fn , event_type ) : <EOL> self . subscriptions . append ( ( fn , event_type ) ) <EOL> class DummyConnection ( object ) : <EOL> def __init__ ( self , loads , stores ) : <EOL> self . loads = loads <EOL> self . stores = stores <EOL> def getTransferCounts ( self ) : <EOL> return ( self . loads , self . stores ) <EOL> class DummyEvent ( object ) : <EOL> def __init__ ( self , loads = <NUM_LIT:0> , stores = <NUM_LIT:0> ) : <EOL> self . request = testing . DummyRequest ( ) <EOL> self . conn = DummyConnection ( loads , stores ) </s>
<s> import pkg_resources <EOL> import mimetypes <EOL> import colander <EOL> import deform . schema <EOL> from pyramid . httpexceptions import HTTPFound <EOL> from pyramid . response import Response <EOL> from pyramid . security import NO_PERMISSION_REQUIRED <EOL> from . . form import FormView <EOL> from . . file import ( <EOL> FilePropertiesSchema , <EOL> FileUploadTempStore , <EOL> file_upload_widget , <EOL> file_name_node , <EOL> USE_MAGIC , <EOL> ) <EOL> from . . interfaces import ( <EOL> IFile , <EOL> IFolder , <EOL> ) <EOL> from . . sdi import mgmt_view <EOL> @ mgmt_view ( <EOL> context = IFile , <EOL> name = '<STR_LIT>' , <EOL> permission = '<STR_LIT>' , <EOL> tab_condition = False , <EOL> http_cache = <NUM_LIT:0> , <EOL> ) <EOL> def view_file ( context , request ) : <EOL> return context . get_response ( request = request ) <EOL> @ mgmt_view ( <EOL> context = IFile , <EOL> name = '<STR_LIT>' , <EOL> tab_title = '<STR_LIT>' , <EOL> permission = '<STR_LIT>' <EOL> ) <EOL> def view_tab ( context , request ) : <EOL> return HTTPFound ( location = request . sdiapi . mgmt_path ( context ) ) <EOL> class AddFileSchema ( FilePropertiesSchema ) : <EOL> file = colander . SchemaNode ( <EOL> deform . schema . FileData ( ) , <EOL> widget = file_upload_widget , <EOL> missing = colander . null , <EOL> ) <EOL> @ colander . deferred <EOL> def name_or_file ( node , kw ) : <EOL> def _name_or_file ( node , struct ) : <EOL> if not struct [ '<STR_LIT:file>' ] and not struct [ '<STR_LIT:name>' ] : <EOL> raise colander . Invalid ( node , '<STR_LIT>' ) <EOL> if not struct [ '<STR_LIT:name>' ] : <EOL> filename = struct [ '<STR_LIT:file>' ] . get ( '<STR_LIT:filename>' ) <EOL> if filename : <EOL> name_node = file_name_node . bind ( <EOL> context = kw [ '<STR_LIT>' ] , request = kw [ '<STR_LIT>' ] <EOL> ) <EOL> name_node . validator ( node [ '<STR_LIT:file>' ] , filename ) <EOL> else : <EOL> raise colander . Invalid ( <EOL> node , <EOL> '<STR_LIT>' <EOL> ) <EOL> return _name_or_file <EOL> @ mgmt_view ( <EOL> context = IFolder , <EOL> name = '<STR_LIT>' , <EOL> tab_title = '<STR_LIT>' , <EOL> permission = '<STR_LIT>' , <EOL> renderer = '<STR_LIT>' , <EOL> addable_content = '<STR_LIT>' , <EOL> tab_condition = False <EOL> ) <EOL> class AddFileView ( FormView ) : <EOL> title = '<STR_LIT>' <EOL> schema = AddFileSchema ( validator = name_or_file ) . clone ( ) <EOL> schema [ '<STR_LIT:name>' ] . missing = colander . null <EOL> schema [ '<STR_LIT>' ] . missing = colander . null <EOL> buttons = ( '<STR_LIT>' , ) <EOL> def _makeob ( self , stream , title , mimetype ) : <EOL> return self . request . registry . content . create ( <EOL> '<STR_LIT>' , <EOL> stream = stream , <EOL> mimetype = mimetype , <EOL> title = title , <EOL> ) <EOL> def add_success ( self , appstruct ) : <EOL> name = appstruct [ '<STR_LIT:name>' ] <EOL> title = appstruct [ '<STR_LIT:title>' ] or None <EOL> filedata = appstruct [ '<STR_LIT:file>' ] <EOL> mimetype = appstruct [ '<STR_LIT>' ] or USE_MAGIC <EOL> stream = None <EOL> filename = None <EOL> if filedata : <EOL> filename = filedata [ '<STR_LIT:filename>' ] <EOL> stream = filedata [ '<STR_LIT>' ] <EOL> if stream : <EOL> stream . seek ( <NUM_LIT:0> ) <EOL> else : <EOL> stream = None <EOL> name = name or filename <EOL> fileob = self . _makeob ( stream , title , mimetype ) <EOL> self . context [ name ] = fileob <EOL> tmpstore = FileUploadTempStore ( self . request ) <EOL> tmpstore . clear ( ) <EOL> return HTTPFound ( self . request . sdiapi . mgmt_path ( self . context ) ) <EOL> onepixel = pkg_resources . resource_filename ( <EOL> '<STR_LIT>' , '<STR_LIT>' ) <EOL> @ mgmt_view ( <EOL> name = '<STR_LIT>' , <EOL> tab_condition = False , <EOL> permission = NO_PERMISSION_REQUIRED <EOL> ) <EOL> def preview_image_upload ( request ) : <EOL> uid = request . subpath [ <NUM_LIT:0> ] <EOL> tempstore = FileUploadTempStore ( request ) <EOL> filedata = tempstore . get ( uid , { } ) <EOL> fp = filedata . get ( '<STR_LIT>' ) <EOL> filename = '<STR_LIT>' <EOL> if fp is not None : <EOL> fp . seek ( <NUM_LIT:0> ) <EOL> filename = filedata [ '<STR_LIT:filename>' ] <EOL> mimetype = mimetypes . guess_type ( filename , strict = False ) [ <NUM_LIT:0> ] <EOL> if not mimetype or not mimetype . startswith ( '<STR_LIT>' ) : <EOL> mimetype = '<STR_LIT>' <EOL> fp = open ( onepixel , '<STR_LIT:rb>' ) <EOL> response = Response ( content_type = mimetype , app_iter = fp ) <EOL> return response </s>
<s> import unittest <EOL> from pyramid import testing <EOL> class Test_principal_added ( unittest . TestCase ) : <EOL> def _callFUT ( self , event ) : <EOL> from . . subscribers import principal_added <EOL> return principal_added ( event ) <EOL> def test_event_wo_loading_attr ( self ) : <EOL> event = testing . DummyResource ( ) <EOL> event . object = testing . DummyResource ( ) <EOL> self . assertRaises ( AttributeError , self . _callFUT , event ) <EOL> def test_event_w_loading_True ( self ) : <EOL> event = testing . DummyResource ( loading = True ) <EOL> result = self . _callFUT ( event ) <EOL> self . assertEqual ( result , None ) <EOL> def test_wo_principals_service ( self ) : <EOL> from zope . interface import directlyProvides <EOL> from ... interfaces import IFolder <EOL> event = testing . DummyResource ( loading = False ) <EOL> root = testing . DummyResource ( ) <EOL> directlyProvides ( root , IFolder ) <EOL> event . object = root [ '<STR_LIT>' ] = testing . DummyResource ( ) <EOL> self . assertRaises ( ValueError , self . _callFUT , event ) <EOL> def test_user_not_in_groups ( self ) : <EOL> from ... testing import make_site <EOL> from ... interfaces import IUser <EOL> site = make_site ( ) <EOL> user = testing . DummyResource ( __provides__ = IUser ) <EOL> site [ '<STR_LIT:user>' ] = user <EOL> event = testing . DummyResource ( object = user , loading = False ) <EOL> self . _callFUT ( event ) <EOL> def test_user_in_groups ( self ) : <EOL> from ... testing import make_site <EOL> from ... interfaces import IUser <EOL> site = make_site ( ) <EOL> groups = site [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> groups [ '<STR_LIT:user>' ] = testing . DummyResource ( ) <EOL> user = testing . DummyResource ( __provides__ = IUser ) <EOL> site [ '<STR_LIT:user>' ] = user <EOL> event = testing . DummyResource ( object = user , loading = False ) <EOL> self . assertRaises ( ValueError , self . _callFUT , event ) <EOL> def test_group_not_in_users ( self ) : <EOL> from ... testing import make_site <EOL> site = make_site ( ) <EOL> group = testing . DummyResource ( ) <EOL> site [ '<STR_LIT>' ] = group <EOL> event = testing . DummyResource ( object = group , loading = False ) <EOL> self . _callFUT ( event ) <EOL> def test_group_in_users ( self ) : <EOL> from ... testing import make_site <EOL> site = make_site ( ) <EOL> users = site [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> users [ '<STR_LIT>' ] = testing . DummyResource ( ) <EOL> group = testing . DummyResource ( ) <EOL> site [ '<STR_LIT>' ] = group <EOL> event = testing . DummyResource ( object = group , loading = False ) <EOL> self . assertRaises ( ValueError , self . _callFUT , event ) <EOL> class Test_user_will_be_removed ( unittest . TestCase ) : <EOL> def _callFUT ( self , event ) : <EOL> from . . subscribers import user_will_be_removed <EOL> return user_will_be_removed ( event ) <EOL> def test_loading ( self ) : <EOL> event = testing . DummyResource ( loading = True , moving = None ) <EOL> result = self . _callFUT ( event ) <EOL> self . assertEqual ( result , None ) <EOL> def test_moving ( self ) : <EOL> event = testing . DummyResource ( loading = False , moving = True ) <EOL> result = self . _callFUT ( event ) <EOL> self . assertEqual ( result , None ) <EOL> def test_it ( self ) : <EOL> from ... interfaces import IFolder <EOL> parent = testing . DummyResource ( __provides__ = IFolder ) <EOL> user = testing . DummyResource ( ) <EOL> reset = testing . DummyResource ( ) <EOL> def commit_suicide ( ) : <EOL> reset . committed = True <EOL> reset . commit_suicide = commit_suicide <EOL> objectmap = DummyObjectMap ( ( reset , ) ) <EOL> parent . __objectmap__ = objectmap <EOL> parent [ '<STR_LIT:user>' ] = user <EOL> event = testing . DummyResource ( object = user , loading = False , moving = None ) <EOL> self . _callFUT ( event ) <EOL> self . assertTrue ( reset . committed ) <EOL> def test_it_moving ( self ) : <EOL> event = testing . DummyResource ( object = None , loading = False ) <EOL> event . moving = True <EOL> self . assertEqual ( self . _callFUT ( event ) , None ) <EOL> class Test_user_added ( unittest . TestCase ) : <EOL> def _callFUT ( self , event ) : <EOL> from . . subscribers import user_added <EOL> return user_added ( event ) <EOL> def test_loading ( self ) : <EOL> event = testing . DummyResource ( loading = True ) <EOL> result = self . _callFUT ( event ) <EOL> self . assertEqual ( result , None ) <EOL> def test_it_user_has_no_oid ( self ) : <EOL> user = testing . DummyResource ( ) <EOL> event = testing . DummyResource ( object = user , loading = False ) <EOL> event . registry = DummyRegistry ( ) <EOL> self . assertRaises ( AttributeError , self . _callFUT , event ) <EOL> def test_it ( self ) : <EOL> from pyramid . security import Allow <EOL> user = testing . DummyResource ( ) <EOL> user . __oid__ = <NUM_LIT:1> <EOL> event = testing . DummyResource ( object = user , loading = False ) <EOL> event . registry = DummyRegistry ( ) <EOL> self . _callFUT ( event ) <EOL> self . assertEqual ( <EOL> user . __acl__ , <EOL> [ ( Allow , <NUM_LIT:1> , ( '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> ) ) ] ) <EOL> class Test_acl_maybe_added ( unittest . TestCase ) : <EOL> def _callFUT ( self , event ) : <EOL> from . . subscribers import acl_maybe_added <EOL> return acl_maybe_added ( event ) <EOL> def test_moving ( self ) : <EOL> event = DummyEvent ( moving = True , loading = False ) <EOL> self . assertEqual ( self . _callFUT ( event ) , False ) <EOL> def test_loading ( self ) : <EOL> event = DummyEvent ( moving = None , loading = True ) <EOL> self . assertEqual ( self . _callFUT ( event ) , False ) <EOL> def test_objectmap_is_None ( self ) : <EOL> event = DummyEvent ( moving = None , object = None , loading = False ) <EOL> self . assertEqual ( self . _callFUT ( event ) , None ) <EOL> def test_no_acls ( self ) : <EOL> from substanced . interfaces import IFolder <EOL> resource1 = testing . DummyResource ( __provides__ = IFolder ) <EOL> resource2 = testing . DummyResource ( ) <EOL> resource1 [ '<STR_LIT>' ] = resource2 <EOL> objectmap = DummyObjectMap ( ) <EOL> resource1 . __objectmap__ = objectmap <EOL> event = DummyEvent ( moving = None , object = resource1 , loading = False ) <EOL> self . _callFUT ( event ) <EOL> self . assertEqual ( objectmap . connections , [ ] ) <EOL> def test_with_acls ( self ) : <EOL> from ... interfaces import PrincipalToACLBearing <EOL> from substanced . interfaces import IFolder <EOL> resource1 = testing . DummyResource ( __provides__ = IFolder ) <EOL> resource2 = testing . DummyResource ( ) <EOL> resource1 [ '<STR_LIT>' ] = resource2 <EOL> resource1 . __acl__ = [ ( None , '<STR_LIT>' , None ) , ( None , <NUM_LIT:1> , None ) ] <EOL> resource2 . __acl__ = [ ( None , '<STR_LIT>' , None ) , ( None , <NUM_LIT:2> , None ) ] <EOL> objectmap = DummyObjectMap ( ) <EOL> resource1 . __objectmap__ = objectmap <EOL> event = DummyEvent ( moving = None , object = resource1 , loading = False ) <EOL> self . _callFUT ( event ) <EOL> self . assertEqual ( <EOL> objectmap . connections , <EOL> [ ( <NUM_LIT:2> , resource2 , PrincipalToACLBearing ) , <EOL> ( <NUM_LIT:1> , resource1 , PrincipalToACLBearing ) ] <EOL> ) <EOL> class Test_acl_modified ( unittest . TestCase ) : <EOL> def _callFUT ( self , event ) : <EOL> from . . subscribers import acl_modified <EOL> return acl_modified ( event ) <EOL> def test_objectmap_is_None ( self ) : <EOL> event = DummyEvent ( object = None ) <EOL> self . assertEqual ( self . _callFUT ( event ) , None ) <EOL> def test_gardenpath ( self ) : <EOL> from ... interfaces import PrincipalToACLBearing <EOL> resource = testing . DummyResource ( ) <EOL> objectmap = DummyObjectMap ( ) <EOL> resource . __objectmap__ = objectmap <EOL> event = DummyEvent ( <EOL> object = resource , <EOL> new_acl = [ ( None , '<STR_LIT>' , None ) , ( None , <NUM_LIT:1> , None ) ] , <EOL> old_acl = [ ( None , '<STR_LIT>' , None ) , ( None , <NUM_LIT:2> , None ) ] , <EOL> ) <EOL> self . _callFUT ( event ) <EOL> self . assertEqual ( <EOL> objectmap . connections , <EOL> [ ( <NUM_LIT:1> , resource , PrincipalToACLBearing ) ] <EOL> ) <EOL> self . assertEqual ( <EOL> objectmap . disconnections , <EOL> [ ( <NUM_LIT:2> , resource , PrincipalToACLBearing ) ] <EOL> ) <EOL> class DummyObjectMap ( object ) : <EOL> def __init__ ( self , result = ( ) ) : <EOL> self . result = result <EOL> self . connections = [ ] <EOL> self . disconnections = [ ] <EOL> def targets ( self , object , reftype ) : <EOL> return self . result <EOL> def connect ( self , source , target , reftype ) : <EOL> self . connections . append ( ( source , target , reftype ) ) <EOL> def disconnect ( self , source , target , reftype ) : <EOL> self . disconnections . append ( ( source , target , reftype ) ) <EOL> class DummyEvent ( object ) : <EOL> def __init__ ( self , ** kw ) : <EOL> self . __dict__ . update ( kw ) <EOL> class DummyRegistry ( object ) : <EOL> def subscribers ( self , * arg ) : <EOL> return </s>
<s> from pyramid . httpexceptions import ( <EOL> HTTPForbidden , <EOL> HTTPFound <EOL> ) <EOL> from pyramid . renderers import get_renderer <EOL> from pyramid . session import check_csrf_token <EOL> from pyramid . security import ( <EOL> remember , <EOL> forget , <EOL> Authenticated , <EOL> NO_PERMISSION_REQUIRED , <EOL> ) <EOL> from ... util import get_oid <EOL> from . . import mgmt_view <EOL> from substanced . interfaces import IUserLocator <EOL> from substanced . principal import DefaultUserLocator <EOL> from substanced . event import LoggedIn <EOL> @ mgmt_view ( <EOL> name = '<STR_LIT>' , <EOL> renderer = '<STR_LIT>' , <EOL> tab_condition = False , <EOL> permission = NO_PERMISSION_REQUIRED <EOL> ) <EOL> @ mgmt_view ( <EOL> renderer = '<STR_LIT>' , <EOL> context = HTTPForbidden , <EOL> permission = NO_PERMISSION_REQUIRED , <EOL> tab_condition = False <EOL> ) <EOL> @ mgmt_view ( <EOL> renderer = '<STR_LIT>' , <EOL> context = HTTPForbidden , <EOL> permission = NO_PERMISSION_REQUIRED , <EOL> effective_principals = Authenticated , <EOL> tab_condition = False <EOL> ) <EOL> def login ( context , request ) : <EOL> login_url = request . sdiapi . mgmt_path ( request . context , '<STR_LIT>' ) <EOL> referrer = request . url <EOL> if '<STR_LIT>' in referrer : <EOL> return HTTPForbidden ( ) <EOL> if login_url in referrer : <EOL> referrer = request . sdiapi . mgmt_path ( request . virtual_root ) <EOL> came_from = request . session . setdefault ( '<STR_LIT>' , referrer ) <EOL> login = '<STR_LIT>' <EOL> password = '<STR_LIT>' <EOL> if '<STR_LIT>' in request . params : <EOL> try : <EOL> check_csrf_token ( request ) <EOL> except : <EOL> request . sdiapi . flash ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> else : <EOL> login = request . params [ '<STR_LIT>' ] <EOL> password = request . params [ '<STR_LIT:password>' ] <EOL> adapter = request . registry . queryMultiAdapter ( <EOL> ( context , request ) , <EOL> IUserLocator <EOL> ) <EOL> if adapter is None : <EOL> adapter = DefaultUserLocator ( context , request ) <EOL> user = adapter . get_user_by_login ( login ) <EOL> if user is not None and user . check_password ( password ) : <EOL> request . session . pop ( '<STR_LIT>' , None ) <EOL> headers = remember ( request , get_oid ( user ) ) <EOL> request . registry . notify ( LoggedIn ( login , user , context , request ) ) <EOL> return HTTPFound ( location = came_from , headers = headers ) <EOL> request . sdiapi . flash ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> template = get_renderer ( '<STR_LIT>' <EOL> ) . implementation ( ) <EOL> return dict ( <EOL> url = request . sdiapi . mgmt_path ( request . virtual_root , '<STR_LIT>' ) , <EOL> came_from = came_from , <EOL> login = login , <EOL> password = password , <EOL> login_template = template , <EOL> ) <EOL> @ mgmt_view ( <EOL> name = '<STR_LIT>' , <EOL> tab_condition = False , <EOL> permission = NO_PERMISSION_REQUIRED <EOL> ) <EOL> def logout ( request ) : <EOL> headers = forget ( request ) <EOL> return HTTPFound ( location = request . sdiapi . mgmt_path ( request . context ) , <EOL> headers = headers ) </s>
<s> from venusian . tests . fixtures import categorydecorator <EOL> from venusian . tests . fixtures import categorydecorator2 <EOL> @ categorydecorator ( function = True ) <EOL> def function ( request ) : <EOL> return request <EOL> @ categorydecorator2 ( function = True ) <EOL> def function2 ( request ) : <EOL> return request </s>
<s> import os <EOL> import mimetypes <EOL> mimetypes . add_type ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> mimetypes . add_type ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> from zope . structuredtext import stx2html <EOL> from pyramid . response import Response <EOL> from pyramid . httpexceptions import HTTPFound <EOL> from pyramid . view import render_view_to_response <EOL> from pyramid . view import view_config <EOL> from virginia . models import File <EOL> from virginia . models import Directory <EOL> @ view_config ( context = File ) <EOL> def file_view ( context , request ) : <EOL> dirname , filename = os . path . split ( context . path ) <EOL> name , ext = os . path . splitext ( filename ) <EOL> result = render_view_to_response ( context , request , ext ) <EOL> return result <EOL> @ view_config ( context = Directory ) <EOL> def directory_view ( context , request ) : <EOL> path_info = request . environ [ '<STR_LIT>' ] <EOL> if not path_info . endswith ( '<STR_LIT:/>' ) : <EOL> response = HTTPFound ( location = path_info + '<STR_LIT:/>' ) <EOL> return response <EOL> defaults = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) <EOL> for name in defaults : <EOL> try : <EOL> index = context [ name ] <EOL> except KeyError : <EOL> continue <EOL> return file_view ( index , request ) <EOL> response = Response ( '<STR_LIT>' % context . path ) <EOL> response . content_type = '<STR_LIT>' <EOL> return response <EOL> @ view_config ( context = File , name = '<STR_LIT>' ) <EOL> def structured_text_view ( context , request ) : <EOL> """<STR_LIT>""" <EOL> result = stx2html ( context . source ) <EOL> response = Response ( result ) <EOL> response . content_type = '<STR_LIT>' <EOL> return response <EOL> @ view_config ( context = File , name = '<STR_LIT>' ) <EOL> @ view_config ( context = File , name = '<STR_LIT>' ) <EOL> @ view_config ( context = File , name = '<STR_LIT>' ) <EOL> @ view_config ( context = File , name = '<STR_LIT>' ) <EOL> def raw_view ( context , request ) : <EOL> """<STR_LIT>""" <EOL> response = Response ( context . source ) <EOL> dirname , filename = os . path . split ( context . path ) <EOL> name , ext = os . path . splitext ( filename ) <EOL> mt , encoding = mimetypes . guess_type ( filename ) <EOL> response . content_type = mt or '<STR_LIT>' <EOL> return response </s>
<s> """<STR_LIT>""" <EOL> import os <EOL> import sys <EOL> import unittest <EOL> if not hasattr ( unittest . defaultTestLoader , '<STR_LIT>' ) : <EOL> try : <EOL> import unittest2 as unittest <EOL> except ImportError : <EOL> raise ImportError ( '<STR_LIT>' ) <EOL> def additional_tests ( ) : <EOL> setup_file = sys . modules [ '<STR_LIT:__main__>' ] . __file__ <EOL> setup_dir = os . path . abspath ( os . path . dirname ( setup_file ) ) <EOL> test_dir = os . path . join ( setup_dir , '<STR_LIT>' ) <EOL> test_suite = unittest . defaultTestLoader . discover ( test_dir ) <EOL> blacklist = [ ] <EOL> if '<STR_LIT>' in __file__ : <EOL> blacklist . append ( '<STR_LIT>' ) <EOL> return exclude_tests ( test_suite , blacklist ) <EOL> class SkipCase ( unittest . TestCase ) : <EOL> def skeleton_run_test ( self ) : <EOL> raise unittest . SkipTest ( "<STR_LIT>" ) <EOL> def exclude_tests ( suite , blacklist ) : <EOL> """<STR_LIT>""" <EOL> new_suite = unittest . TestSuite ( ) <EOL> for test_group in suite . _tests : <EOL> for test in test_group : <EOL> if not hasattr ( test , '<STR_LIT>' ) : <EOL> new_suite . addTest ( test ) <EOL> continue <EOL> for subtest in test . _tests : <EOL> method = subtest . _testMethodName <EOL> if method in blacklist : <EOL> setattr ( test , <EOL> method , <EOL> getattr ( SkipCase ( ) , '<STR_LIT>' ) ) <EOL> new_suite . addTest ( test ) <EOL> return new_suite </s>
<s> """<STR_LIT>""" <EOL> from __future__ import unicode_literals <EOL> from __future__ import division <EOL> from __future__ import absolute_import <EOL> from future . utils import surrogateescape <EOL> surrogateescape . register_surrogateescape ( ) <EOL> __version__ = '<STR_LIT>' <EOL> __all__ = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT:message>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> ] <EOL> def message_from_string ( s , * args , ** kws ) : <EOL> """<STR_LIT>""" <EOL> from future . backports . email . parser import Parser <EOL> return Parser ( * args , ** kws ) . parsestr ( s ) <EOL> def message_from_bytes ( s , * args , ** kws ) : <EOL> """<STR_LIT>""" <EOL> from future . backports . email . parser import BytesParser <EOL> return BytesParser ( * args , ** kws ) . parsebytes ( s ) <EOL> def message_from_file ( fp , * args , ** kws ) : <EOL> """<STR_LIT>""" <EOL> from future . backports . email . parser import Parser <EOL> return Parser ( * args , ** kws ) . parse ( fp ) <EOL> def message_from_binary_file ( fp , * args , ** kws ) : <EOL> """<STR_LIT>""" <EOL> from future . backports . email . parser import BytesParser <EOL> return BytesParser ( * args , ** kws ) . parse ( fp ) </s>
<s> '''<STR_LIT>''' <EOL> _builtin_next = next <EOL> _SENTINEL = object ( ) <EOL> def newnext ( iterator , default = _SENTINEL ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> try : <EOL> return iterator . __next__ ( ) <EOL> except AttributeError : <EOL> try : <EOL> return iterator . next ( ) <EOL> except AttributeError : <EOL> raise TypeError ( "<STR_LIT>" . format ( <EOL> iterator . __class__ . __name__ ) ) <EOL> except StopIteration as e : <EOL> if default is _SENTINEL : <EOL> raise e <EOL> else : <EOL> return default <EOL> __all__ = [ '<STR_LIT>' ] </s>
<s> from __future__ import absolute_import <EOL> from future . utils import PY2 <EOL> from sys import * <EOL> if PY2 : <EOL> from __builtin__ import intern </s>
<s> """<STR_LIT>""" <EOL> from collections import Iterable <EOL> from numbers import Integral <EOL> import string <EOL> from future . utils import istext , isbytes , PY3 , with_metaclass <EOL> from future . types import no , issubset <EOL> from future . types . newobject import newobject <EOL> _builtin_bytes = bytes <EOL> if PY3 : <EOL> unicode = str <EOL> class BaseNewBytes ( type ) : <EOL> def __instancecheck__ ( cls , instance ) : <EOL> if cls == newbytes : <EOL> return isinstance ( instance , _builtin_bytes ) <EOL> else : <EOL> return issubclass ( instance . __class__ , cls ) <EOL> class newbytes ( with_metaclass ( BaseNewBytes , _builtin_bytes ) ) : <EOL> """<STR_LIT>""" <EOL> def __new__ ( cls , * args , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> encoding = None <EOL> errors = None <EOL> if len ( args ) == <NUM_LIT:0> : <EOL> return super ( newbytes , cls ) . __new__ ( cls ) <EOL> elif len ( args ) >= <NUM_LIT:2> : <EOL> args = list ( args ) <EOL> if len ( args ) == <NUM_LIT:3> : <EOL> errors = args . pop ( ) <EOL> encoding = args . pop ( ) <EOL> if type ( args [ <NUM_LIT:0> ] ) == newbytes : <EOL> return args [ <NUM_LIT:0> ] <EOL> elif isinstance ( args [ <NUM_LIT:0> ] , _builtin_bytes ) : <EOL> value = args [ <NUM_LIT:0> ] <EOL> elif isinstance ( args [ <NUM_LIT:0> ] , unicode ) : <EOL> try : <EOL> if '<STR_LIT>' in kwargs : <EOL> assert encoding is None <EOL> encoding = kwargs [ '<STR_LIT>' ] <EOL> if '<STR_LIT>' in kwargs : <EOL> assert errors is None <EOL> errors = kwargs [ '<STR_LIT>' ] <EOL> except AssertionError : <EOL> raise TypeError ( '<STR_LIT>' ) <EOL> if encoding is None : <EOL> raise TypeError ( '<STR_LIT>' ) <EOL> newargs = [ encoding ] <EOL> if errors is not None : <EOL> newargs . append ( errors ) <EOL> value = args [ <NUM_LIT:0> ] . encode ( * newargs ) <EOL> elif isinstance ( args [ <NUM_LIT:0> ] , Iterable ) : <EOL> if len ( args [ <NUM_LIT:0> ] ) == <NUM_LIT:0> : <EOL> value = b'<STR_LIT>' <EOL> else : <EOL> try : <EOL> values = [ chr ( x ) for x in args [ <NUM_LIT:0> ] ] <EOL> value = b'<STR_LIT>' . join ( values ) <EOL> except : <EOL> raise ValueError ( '<STR_LIT>' ) <EOL> elif isinstance ( args [ <NUM_LIT:0> ] , Integral ) : <EOL> if args [ <NUM_LIT:0> ] < <NUM_LIT:0> : <EOL> raise ValueError ( '<STR_LIT>' ) <EOL> value = b'<STR_LIT:\x00>' * args [ <NUM_LIT:0> ] <EOL> else : <EOL> value = args [ <NUM_LIT:0> ] <EOL> return super ( newbytes , cls ) . __new__ ( cls , value ) <EOL> def __repr__ ( self ) : <EOL> return '<STR_LIT:b>' + super ( newbytes , self ) . __repr__ ( ) <EOL> def __str__ ( self ) : <EOL> return '<STR_LIT:b>' + "<STR_LIT>" . format ( super ( newbytes , self ) . __str__ ( ) ) <EOL> def __getitem__ ( self , y ) : <EOL> value = super ( newbytes , self ) . __getitem__ ( y ) <EOL> if isinstance ( y , Integral ) : <EOL> return ord ( value ) <EOL> else : <EOL> return newbytes ( value ) <EOL> def __getslice__ ( self , * args ) : <EOL> return self . __getitem__ ( slice ( * args ) ) <EOL> def __contains__ ( self , key ) : <EOL> if isinstance ( key , int ) : <EOL> newbyteskey = newbytes ( [ key ] ) <EOL> elif type ( key ) == newbytes : <EOL> newbyteskey = key <EOL> else : <EOL> newbyteskey = newbytes ( key ) <EOL> return issubset ( list ( newbyteskey ) , list ( self ) ) <EOL> @ no ( unicode ) <EOL> def __add__ ( self , other ) : <EOL> return newbytes ( super ( newbytes , self ) . __add__ ( other ) ) <EOL> @ no ( unicode ) <EOL> def __radd__ ( self , left ) : <EOL> return newbytes ( left ) + self <EOL> @ no ( unicode ) <EOL> def __mul__ ( self , other ) : <EOL> return newbytes ( super ( newbytes , self ) . __mul__ ( other ) ) <EOL> @ no ( unicode ) <EOL> def __rmul__ ( self , other ) : <EOL> return newbytes ( super ( newbytes , self ) . __rmul__ ( other ) ) <EOL> def join ( self , iterable_of_bytes ) : <EOL> errmsg = '<STR_LIT>' <EOL> if isbytes ( iterable_of_bytes ) or istext ( iterable_of_bytes ) : <EOL> raise TypeError ( errmsg . format ( <NUM_LIT:0> , type ( iterable_of_bytes ) ) ) <EOL> for i , item in enumerate ( iterable_of_bytes ) : <EOL> if istext ( item ) : <EOL> raise TypeError ( errmsg . format ( i , type ( item ) ) ) <EOL> return newbytes ( super ( newbytes , self ) . join ( iterable_of_bytes ) ) <EOL> @ classmethod <EOL> def fromhex ( cls , string ) : <EOL> return cls ( string . replace ( '<STR_LIT:U+0020>' , '<STR_LIT>' ) . decode ( '<STR_LIT>' ) ) <EOL> @ no ( unicode ) <EOL> def find ( self , sub , * args ) : <EOL> return super ( newbytes , self ) . find ( sub , * args ) <EOL> @ no ( unicode ) <EOL> def rfind ( self , sub , * args ) : <EOL> return super ( newbytes , self ) . rfind ( sub , * args ) <EOL> @ no ( unicode , ( <NUM_LIT:1> , <NUM_LIT:2> ) ) <EOL> def replace ( self , old , new , * args ) : <EOL> return newbytes ( super ( newbytes , self ) . replace ( old , new , * args ) ) <EOL> def encode ( self , * args ) : <EOL> raise AttributeError ( "<STR_LIT>" ) <EOL> def decode ( self , encoding = '<STR_LIT:utf-8>' , errors = '<STR_LIT:strict>' ) : <EOL> """<STR_LIT>""" <EOL> from future . types . newstr import newstr <EOL> if errors == '<STR_LIT>' : <EOL> from future . utils . surrogateescape import register_surrogateescape <EOL> register_surrogateescape ( ) <EOL> return newstr ( super ( newbytes , self ) . decode ( encoding , errors ) ) <EOL> @ no ( unicode ) <EOL> def startswith ( self , prefix , * args ) : <EOL> return super ( newbytes , self ) . startswith ( prefix , * args ) <EOL> @ no ( unicode ) <EOL> def endswith ( self , prefix , * args ) : <EOL> return super ( newbytes , self ) . endswith ( prefix , * args ) <EOL> @ no ( unicode ) <EOL> def split ( self , sep = None , maxsplit = - <NUM_LIT:1> ) : <EOL> parts = super ( newbytes , self ) . split ( sep , maxsplit ) <EOL> return [ newbytes ( part ) for part in parts ] <EOL> def splitlines ( self , keepends = False ) : <EOL> """<STR_LIT>""" <EOL> parts = super ( newbytes , self ) . splitlines ( keepends ) <EOL> return [ newbytes ( part ) for part in parts ] <EOL> @ no ( unicode ) <EOL> def rsplit ( self , sep = None , maxsplit = - <NUM_LIT:1> ) : <EOL> parts = super ( newbytes , self ) . rsplit ( sep , maxsplit ) <EOL> return [ newbytes ( part ) for part in parts ] <EOL> @ no ( unicode ) <EOL> def partition ( self , sep ) : <EOL> parts = super ( newbytes , self ) . partition ( sep ) <EOL> return tuple ( newbytes ( part ) for part in parts ) <EOL> @ no ( unicode ) <EOL> def rpartition ( self , sep ) : <EOL> parts = super ( newbytes , self ) . rpartition ( sep ) <EOL> return tuple ( newbytes ( part ) for part in parts ) <EOL> @ no ( unicode , ( <NUM_LIT:1> , ) ) <EOL> def rindex ( self , sub , * args ) : <EOL> '''<STR_LIT>''' <EOL> pos = self . rfind ( sub , * args ) <EOL> if pos == - <NUM_LIT:1> : <EOL> raise ValueError ( '<STR_LIT>' ) <EOL> @ no ( unicode ) <EOL> def index ( self , sub , * args ) : <EOL> '''<STR_LIT>''' <EOL> if isinstance ( sub , int ) : <EOL> if len ( args ) == <NUM_LIT:0> : <EOL> start , end = <NUM_LIT:0> , len ( self ) <EOL> elif len ( args ) == <NUM_LIT:1> : <EOL> start = args [ <NUM_LIT:0> ] <EOL> elif len ( args ) == <NUM_LIT:2> : <EOL> start , end = args <EOL> else : <EOL> raise TypeError ( '<STR_LIT>' ) <EOL> return list ( self ) [ start : end ] . index ( sub ) <EOL> if not isinstance ( sub , bytes ) : <EOL> try : <EOL> sub = self . __class__ ( sub ) <EOL> except ( TypeError , ValueError ) : <EOL> raise TypeError ( "<STR_LIT>" ) <EOL> try : <EOL> return super ( newbytes , self ) . index ( sub , * args ) <EOL> except ValueError : <EOL> raise ValueError ( '<STR_LIT>' ) <EOL> def __eq__ ( self , other ) : <EOL> if isinstance ( other , ( _builtin_bytes , bytearray ) ) : <EOL> return super ( newbytes , self ) . __eq__ ( other ) <EOL> else : <EOL> return False <EOL> def __ne__ ( self , other ) : <EOL> if isinstance ( other , _builtin_bytes ) : <EOL> return super ( newbytes , self ) . __ne__ ( other ) <EOL> else : <EOL> return True <EOL> unorderable_err = '<STR_LIT>' <EOL> def __lt__ ( self , other ) : <EOL> if not isbytes ( other ) : <EOL> raise TypeError ( self . unorderable_err . format ( type ( other ) ) ) <EOL> return super ( newbytes , self ) . __lt__ ( other ) <EOL> def __le__ ( self , other ) : <EOL> if not isbytes ( other ) : <EOL> raise TypeError ( self . unorderable_err . format ( type ( other ) ) ) <EOL> return super ( newbytes , self ) . __le__ ( other ) <EOL> def __gt__ ( self , other ) : <EOL> if not isbytes ( other ) : <EOL> raise TypeError ( self . unorderable_err . format ( type ( other ) ) ) <EOL> return super ( newbytes , self ) . __gt__ ( other ) <EOL> def __ge__ ( self , other ) : <EOL> if not isbytes ( other ) : <EOL> raise TypeError ( self . unorderable_err . format ( type ( other ) ) ) <EOL> return super ( newbytes , self ) . __ge__ ( other ) <EOL> def __native__ ( self ) : <EOL> return super ( newbytes , self ) . __str__ ( ) <EOL> def __getattribute__ ( self , name ) : <EOL> """<STR_LIT>""" <EOL> if name in [ '<STR_LIT>' , u'<STR_LIT>' ] : <EOL> raise AttributeError ( "<STR_LIT>" ) <EOL> return super ( newbytes , self ) . __getattribute__ ( name ) <EOL> @ no ( unicode ) <EOL> def rstrip ( self , bytes_to_strip = None ) : <EOL> """<STR_LIT>""" <EOL> return newbytes ( super ( newbytes , self ) . rstrip ( bytes_to_strip ) ) <EOL> @ no ( unicode ) <EOL> def strip ( self , bytes_to_strip = None ) : <EOL> """<STR_LIT>""" <EOL> return newbytes ( super ( newbytes , self ) . strip ( bytes_to_strip ) ) <EOL> def lower ( self ) : <EOL> """<STR_LIT>""" <EOL> return newbytes ( super ( newbytes , self ) . lower ( ) ) <EOL> @ no ( unicode ) <EOL> def upper ( self ) : <EOL> """<STR_LIT>""" <EOL> return newbytes ( super ( newbytes , self ) . upper ( ) ) <EOL> @ classmethod <EOL> @ no ( unicode ) <EOL> def maketrans ( cls , frm , to ) : <EOL> """<STR_LIT>""" <EOL> return newbytes ( string . maketrans ( frm , to ) ) <EOL> __all__ = [ '<STR_LIT>' ] </s>
<s> """<STR_LIT>""" <EOL> from libpasteurize . fixes . fix_division import FixDivision </s>
<s> """<STR_LIT>""" <EOL> from __future__ import unicode_literals <EOL> from lib2to3 import fixer_base <EOL> from lib2to3 . pygram import python_symbols as syms <EOL> from lib2to3 . fixer_util import Name , Call , in_special_context <EOL> from libfuturize . fixer_util import touch_import_top <EOL> replaced_builtins = '''<STR_LIT>''' . split ( ) <EOL> expression = '<STR_LIT:|>' . join ( [ "<STR_LIT>" . format ( name ) for name in replaced_builtins ] ) <EOL> class FixFutureBuiltins ( fixer_base . BaseFix ) : <EOL> BM_compatible = True <EOL> run_order = <NUM_LIT:9> <EOL> PATTERN = """<STR_LIT>""" . format ( expression ) <EOL> def transform ( self , node , results ) : <EOL> name = results [ "<STR_LIT:name>" ] <EOL> touch_import_top ( u'<STR_LIT>' , name . value , node ) </s>
<s> from __future__ import absolute_import <EOL> import sys <EOL> if sys . version_info [ <NUM_LIT:0> ] < <NUM_LIT:3> : <EOL> from Tkinter import * <EOL> else : <EOL> raise ImportError ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) </s>
<s> """<STR_LIT>""" <EOL> from __future__ import print_function , absolute_import <EOL> import pprint <EOL> from subprocess import Popen , PIPE <EOL> import tempfile <EOL> import os <EOL> from future . tests . base import CodeHandler , unittest , skip26 <EOL> class TestPasteurize ( CodeHandler ) : <EOL> """<STR_LIT>""" <EOL> def setUp ( self ) : <EOL> _ , self . textfilename = tempfile . mkstemp ( text = True ) <EOL> super ( TestPasteurize , self ) . setUp ( ) <EOL> def tearDown ( self ) : <EOL> os . unlink ( self . textfilename ) <EOL> @ skip26 <EOL> def test_range_slice ( self ) : <EOL> """<STR_LIT>""" <EOL> code = '''<STR_LIT>''' <EOL> self . unchanged ( code , from3 = True ) <EOL> def test_print ( self ) : <EOL> """<STR_LIT>""" <EOL> code = '''<STR_LIT>''' <EOL> self . unchanged ( code , from3 = True ) <EOL> def test_division ( self ) : <EOL> """<STR_LIT>""" <EOL> code = '''<STR_LIT>''' <EOL> self . unchanged ( code , from3 = True ) <EOL> @ unittest . expectedFailure <EOL> def test_exception_indentation ( self ) : <EOL> """<STR_LIT>""" <EOL> before = '''<STR_LIT>''' <EOL> after = '''<STR_LIT>''' <EOL> self . convert_check ( before , after , from3 = True ) <EOL> @ unittest . expectedFailure <EOL> def test_urllib_request ( self ) : <EOL> """<STR_LIT>""" <EOL> before = """<STR_LIT>""" <EOL> after = """<STR_LIT>""" <EOL> self . convert_check ( before , after , from3 = True ) <EOL> def test_urllib_refactor2 ( self ) : <EOL> before = """<STR_LIT>""" <EOL> after = """<STR_LIT>""" <EOL> def test_correct_exit_status ( self ) : <EOL> """<STR_LIT>""" <EOL> from libpasteurize . main import main <EOL> retcode = main ( [ self . textfilename ] ) <EOL> self . assertTrue ( isinstance ( retcode , int ) ) <EOL> class TestFuturizeAnnotations ( CodeHandler ) : <EOL> @ unittest . expectedFailure <EOL> def test_return_annotations_alone ( self ) : <EOL> before = "<STR_LIT>" <EOL> after = """<STR_LIT>""" <EOL> self . convert_check ( before , after , from3 = True ) <EOL> b = """<STR_LIT>""" <EOL> a = """<STR_LIT>""" <EOL> self . convert_check ( b , a , from3 = True ) <EOL> @ unittest . expectedFailure <EOL> def test_single_param_annotations ( self ) : <EOL> b = "<STR_LIT>" <EOL> a = """<STR_LIT>""" <EOL> self . convert_check ( b , a , from3 = True ) <EOL> b = """<STR_LIT>""" <EOL> a = """<STR_LIT>""" <EOL> self . convert_check ( b , a , from3 = True ) <EOL> def test_multiple_param_annotations ( self ) : <EOL> b = "<STR_LIT>" <EOL> a = "<STR_LIT>" <EOL> self . convert_check ( b , a , from3 = True ) <EOL> b = """<STR_LIT>""" <EOL> a = """<STR_LIT>""" <EOL> self . convert_check ( b , a , from3 = True ) <EOL> def test_mixed_annotations ( self ) : <EOL> b = "<STR_LIT>" <EOL> a = "<STR_LIT>" <EOL> self . convert_check ( b , a , from3 = True ) <EOL> b = """<STR_LIT>""" <EOL> a = """<STR_LIT>""" <EOL> self . convert_check ( b , a , from3 = True ) <EOL> b = "<STR_LIT>" <EOL> a = "<STR_LIT>" <EOL> self . convert_check ( b , a , from3 = True ) <EOL> def test_functions_unchanged ( self ) : <EOL> s = "<STR_LIT>" <EOL> self . unchanged ( s , from3 = True ) <EOL> s = """<STR_LIT>""" <EOL> self . unchanged ( s , from3 = True ) <EOL> s = """<STR_LIT>""" <EOL> self . unchanged ( s , from3 = True ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> unittest . main ( ) </s>
<s> import ast , copy <EOL> from ast_utils import * <EOL> class Inliner : <EOL> def setup_inliner ( self , writer ) : <EOL> self . writer = writer <EOL> self . _with_inline = False <EOL> self . _inline = [ ] <EOL> self . _inline_ids = <NUM_LIT:0> <EOL> self . _inline_breakout = False <EOL> def inline_helper_remap_names ( self , remap ) : <EOL> return "<STR_LIT>" % '<STR_LIT:U+002C>' . join ( remap . values ( ) ) <EOL> def inline_helper_return_id ( self , return_id ) : <EOL> return "<STR_LIT>" % return_id <EOL> def inline_function ( self , node ) : <EOL> name = self . visit ( node . func ) <EOL> fnode = self . _global_functions [ name ] <EOL> fnode = copy . deepcopy ( fnode ) <EOL> finfo = inspect_function ( fnode ) <EOL> remap = { } <EOL> for n in finfo [ '<STR_LIT>' ] : <EOL> if n . id not in finfo [ '<STR_LIT>' ] : continue <EOL> if isinstance ( n . id , ast . Name ) : <EOL> raise RuntimeError <EOL> if n . id not in remap : <EOL> new_name = n . id + '<STR_LIT>' % self . _inline_ids <EOL> remap [ n . id ] = new_name <EOL> self . _inline_ids += <NUM_LIT:1> <EOL> n . id = remap [ n . id ] <EOL> if remap : <EOL> self . writer . write ( self . inline_helper_remap_names ( remap ) ) <EOL> for n in remap : <EOL> if n in finfo [ '<STR_LIT>' ] : <EOL> self . _func_typedefs [ remap [ n ] ] = finfo [ '<STR_LIT>' ] [ n ] <EOL> offset = len ( fnode . args . args ) - len ( fnode . args . defaults ) <EOL> for i , ad in enumerate ( fnode . args . args ) : <EOL> if i < len ( node . args ) : <EOL> ac = self . visit ( node . args [ i ] ) <EOL> else : <EOL> assert fnode . args . defaults <EOL> dindex = i - offset <EOL> ac = self . visit ( fnode . args . defaults [ dindex ] ) <EOL> ad = remap [ self . visit ( ad ) ] <EOL> self . writer . write ( "<STR_LIT>" % ( ad , ac ) ) <EOL> return_id = name + str ( self . _inline_ids ) <EOL> self . _inline . append ( return_id ) <EOL> self . writer . write ( self . inline_helper_return_id ( return_id ) ) <EOL> if True : <EOL> self . _inline_breakout = True <EOL> self . writer . write ( '<STR_LIT>' ) <EOL> self . writer . push ( ) <EOL> for b in fnode . body : <EOL> self . visit ( b ) <EOL> if not len ( finfo [ '<STR_LIT>' ] ) : <EOL> self . writer . write ( '<STR_LIT>' ) <EOL> self . writer . pull ( ) <EOL> else : <EOL> for b in fnode . body : <EOL> self . visit ( b ) <EOL> if self . _inline . pop ( ) != return_id : <EOL> raise RuntimeError <EOL> for n in remap : <EOL> gname = remap [ n ] <EOL> for n in finfo [ '<STR_LIT>' ] : <EOL> if n . id == gname : <EOL> n . id = n <EOL> return '<STR_LIT>' % return_id </s>
<s> import sys <EOL> import ast <EOL> import pythonjs <EOL> class TransformSuperCalls ( ast . NodeVisitor ) : <EOL> def __init__ ( self , node , class_names ) : <EOL> self . _class_names = class_names <EOL> self . visit ( node ) <EOL> def visit_Call ( self , node ) : <EOL> if isinstance ( node . func , ast . Attribute ) and isinstance ( node . func . value , ast . Name ) and node . func . value . id in self . _class_names : <EOL> node . func . attr = '<STR_LIT>' + node . func . attr <EOL> class CollectNames ( ast . NodeVisitor ) : <EOL> def __init__ ( self ) : <EOL> self . _names = [ ] <EOL> def visit_Name ( self , node ) : <EOL> self . _names . append ( node ) <EOL> def collect_names ( node ) : <EOL> a = CollectNames ( ) <EOL> a . visit ( node ) <EOL> return a . _names <EOL> class DartGenerator ( pythonjs . JSGenerator ) : <EOL> def __init__ ( self , requirejs = False , insert_runtime = False ) : <EOL> pythonjs . JSGenerator . __init__ ( self , requirejs = False , insert_runtime = False ) <EOL> self . _classes = dict ( ) <EOL> self . _class_props = dict ( ) <EOL> self . _raw_dict = False <EOL> def visit_With ( self , node ) : <EOL> s = [ ] <EOL> for b in node . body : <EOL> a = self . visit ( b ) <EOL> a = a . replace ( '<STR_LIT>' , '<STR_LIT:\n>' ) <EOL> a = a . strip ( ) [ <NUM_LIT:1> : - <NUM_LIT:2> ] <EOL> s . append ( a ) <EOL> return '<STR_LIT:\n>' . join ( s ) <EOL> def _visit_subscript_ellipsis ( self , node ) : <EOL> name = self . visit ( node . value ) <EOL> return '<STR_LIT>' % name <EOL> def visit_List ( self , node ) : <EOL> return '<STR_LIT>' % '<STR_LIT:U+002CU+0020>' . join ( map ( self . visit , node . elts ) ) <EOL> def visit_Dict ( self , node ) : <EOL> a = [ ] <EOL> for i in range ( len ( node . keys ) ) : <EOL> k = self . visit ( node . keys [ i ] ) <EOL> v = self . visit ( node . values [ i ] ) <EOL> a . append ( '<STR_LIT>' % ( k , v ) ) <EOL> b = '<STR_LIT:U+002C>' . join ( a ) <EOL> if self . _raw_dict : <EOL> return '<STR_LIT>' % b <EOL> else : <EOL> return '<STR_LIT>' % b <EOL> def visit_ClassDef ( self , node ) : <EOL> node . _parents = set ( ) <EOL> out = [ ] <EOL> extends = False <EOL> props = set ( [ '<STR_LIT>' ] ) <EOL> bases = set ( ) <EOL> base_classes = set ( ) <EOL> self . _classes [ node . name ] = node <EOL> self . _class_props [ node . name ] = props <EOL> for decor in node . decorator_list : <EOL> if isinstance ( decor , ast . Call ) : <EOL> props . update ( [ self . visit ( a ) for a in decor . args ] ) <EOL> elif isinstance ( decor , ast . Attribute ) and isinstance ( decor . value , ast . Name ) and decor . value . id == '<STR_LIT>' : <EOL> if decor . attr == '<STR_LIT>' : <EOL> extends = True <EOL> props . add ( '<STR_LIT>' ) <EOL> for name_node in collect_names ( node ) : <EOL> if name_node . id == '<STR_LIT>' : <EOL> name_node . id = '<STR_LIT>' <EOL> else : <EOL> raise SyntaxError <EOL> for base in node . bases : <EOL> n = self . visit ( base ) <EOL> if n == '<STR_LIT:object>' : <EOL> continue <EOL> node . _parents . add ( n ) <EOL> bases . add ( n ) <EOL> if n in self . _class_props : <EOL> props . update ( self . _class_props [ n ] ) <EOL> base_classes . add ( self . _classes [ n ] ) <EOL> else : <EOL> continue <EOL> for p in self . _classes [ n ] . _parents : <EOL> bases . add ( p ) <EOL> props . update ( self . _class_props [ p ] ) <EOL> base_classes . add ( self . _classes [ p ] ) <EOL> if bases : <EOL> if extends : <EOL> assert len ( bases ) == <NUM_LIT:1> <EOL> out . append ( '<STR_LIT>' % ( node . name , '<STR_LIT:U+002C>' . join ( bases ) ) ) <EOL> else : <EOL> out . append ( '<STR_LIT>' % ( node . name , '<STR_LIT:U+002CU+0020>' . join ( bases ) ) ) <EOL> else : <EOL> out . append ( '<STR_LIT>' % node . name ) <EOL> self . push ( ) <EOL> for p in props : <EOL> out . append ( self . indent ( ) + '<STR_LIT>' % p ) <EOL> method_names = set ( ) <EOL> for b in node . body : <EOL> if isinstance ( b , ast . With ) : <EOL> out . append ( self . visit ( b ) ) <EOL> elif isinstance ( b , ast . FunctionDef ) and len ( b . decorator_list ) : <EOL> for name_node in collect_names ( b ) : <EOL> if name_node . id == '<STR_LIT>' : <EOL> name_node . id = '<STR_LIT>' <EOL> b . args . args = b . args . args [ <NUM_LIT:1> : ] <EOL> out . append ( self . visit ( b ) ) <EOL> elif extends : <EOL> if isinstance ( b , ast . FunctionDef ) : <EOL> b . args . args = b . args . args [ <NUM_LIT:1> : ] <EOL> if b . name == node . name : <EOL> args = [ self . visit ( a ) for a in b . args . args ] <EOL> args = '<STR_LIT:U+002C>' . join ( args ) <EOL> out . append ( <EOL> self . indent ( ) + '<STR_LIT>' % ( node . name , args , args ) <EOL> ) <EOL> b . name = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> b . name = '<STR_LIT>' <EOL> b . _prefix = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> b . name = '<STR_LIT>' <EOL> b . _prefix = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> b . name = '<STR_LIT>' <EOL> b . _prefix = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> b . name = '<STR_LIT>' <EOL> b . _prefix = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> b . name = '<STR_LIT>' <EOL> b . _prefix = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> b . name = '<STR_LIT>' <EOL> b . _prefix = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> b . name = '<STR_LIT>' <EOL> b . _prefix = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> b . name = '<STR_LIT>' <EOL> b . _prefix = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> b . name = '<STR_LIT>' <EOL> b . _prefix = '<STR_LIT>' <EOL> line = self . visit ( b ) <EOL> out . append ( line ) <EOL> elif isinstance ( b , ast . FunctionDef ) and b . name == node . name : <EOL> args , kwargs = self . get_args_kwargs_from_funcdef ( b , skip_self = True ) <EOL> kwargs_init = [ '<STR_LIT>' % ( x . split ( '<STR_LIT::>' ) [ <NUM_LIT:0> ] , x . split ( '<STR_LIT::>' ) [ <NUM_LIT:0> ] ) for x in kwargs ] <EOL> b . _prefix = '<STR_LIT>' <EOL> b . name = '<STR_LIT>' <EOL> out . append ( self . visit ( b ) ) <EOL> if args : <EOL> args = '<STR_LIT:U+002C>' . join ( args ) <EOL> if kwargs : <EOL> out . append ( <EOL> self . indent ( ) + '<STR_LIT>' % ( node . name , args , '<STR_LIT:U+002C>' . join ( kwargs ) , node . name , args , '<STR_LIT:U+002C>' . join ( kwargs_init ) ) <EOL> ) <EOL> else : <EOL> out . append ( <EOL> self . indent ( ) + '<STR_LIT>' % ( node . name , args , node . name , args ) <EOL> ) <EOL> elif kwargs : <EOL> out . append ( <EOL> self . indent ( ) + '<STR_LIT>' % ( node . name , '<STR_LIT:U+002C>' . join ( kwargs ) , node . name , '<STR_LIT:U+002C>' . join ( kwargs_init ) ) <EOL> ) <EOL> else : <EOL> out . append ( <EOL> self . indent ( ) + '<STR_LIT>' % ( node . name , node . name ) <EOL> ) <EOL> elif isinstance ( b , ast . FunctionDef ) : <EOL> method_names . add ( b . name ) <EOL> TransformSuperCalls ( b , bases ) <EOL> operator = False <EOL> if b . name == '<STR_LIT>' : <EOL> operator = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> operator = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> operator = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> operator = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> operator = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> operator = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> operator = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> operator = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> operator = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> operator = '<STR_LIT>' <EOL> elif b . name == '<STR_LIT>' : <EOL> operator = '<STR_LIT>' <EOL> args = [ self . visit ( a ) for a in b . args . args ] [ <NUM_LIT:1> : ] <EOL> args = '<STR_LIT:U+002C>' . join ( args ) <EOL> if operator and args : <EOL> out . append ( self . indent ( ) + '<STR_LIT>' % ( operator , args , node . name , b . name , args ) ) <EOL> elif operator : <EOL> out . append ( self . indent ( ) + '<STR_LIT>' % ( operator , node . name , b . name ) ) <EOL> elif args : <EOL> out . append ( self . indent ( ) + '<STR_LIT>' % ( b . name , args , node . name , b . name , args ) ) <EOL> else : <EOL> out . append ( self . indent ( ) + '<STR_LIT>' % ( b . name , node . name , b . name ) ) <EOL> b . _prefix = '<STR_LIT>' <EOL> name = b . name <EOL> b . name = '<STR_LIT>' % name <EOL> out . append ( self . visit ( b ) ) <EOL> b . name = name <EOL> else : <EOL> line = self . visit ( b ) <EOL> if line . startswith ( '<STR_LIT>' ) : <EOL> out . append ( self . indent ( ) + line ) <EOL> else : <EOL> out . append ( line ) <EOL> if not extends and base_classes : <EOL> for bnode in base_classes : <EOL> for b in bnode . body : <EOL> if isinstance ( b , ast . FunctionDef ) : <EOL> if b . name == '<STR_LIT>' : continue <EOL> if b . name in method_names : continue <EOL> args = [ self . visit ( a ) for a in b . args . args ] [ <NUM_LIT:1> : ] <EOL> args = '<STR_LIT:U+002C>' . join ( args ) <EOL> if args : <EOL> out . append ( self . indent ( ) + '<STR_LIT>' % ( b . name , args , bnode . name , b . name , args ) ) <EOL> else : <EOL> out . append ( self . indent ( ) + '<STR_LIT>' % ( b . name , bnode . name , b . name ) ) <EOL> self . pull ( ) <EOL> out . append ( '<STR_LIT:}>' ) <EOL> return '<STR_LIT:\n>' . join ( out ) <EOL> def get_args_kwargs_from_funcdef ( self , node , skip_self = False ) : <EOL> args = [ ] <EOL> kwargs = [ ] <EOL> if skip_self : nargs = node . args . args [ <NUM_LIT:1> : ] <EOL> else : nargs = node . args . args <EOL> offset = len ( nargs ) - len ( node . args . defaults ) <EOL> for i , arg in enumerate ( nargs ) : <EOL> a = arg . id <EOL> dindex = i - offset <EOL> if dindex >= <NUM_LIT:0> and node . args . defaults : <EOL> default_value = self . visit ( node . args . defaults [ dindex ] ) <EOL> kwargs . append ( '<STR_LIT>' % ( a , default_value ) ) <EOL> else : <EOL> args . append ( a ) <EOL> return args , kwargs <EOL> def _visit_for_prep_iter_helper ( self , node , out , iter_name ) : <EOL> out . append ( <EOL> self . indent ( ) + '<STR_LIT>' % ( iter_name , iter_name , iter_name ) <EOL> ) <EOL> def visit_Expr ( self , node ) : <EOL> s = self . visit ( node . value ) <EOL> if isinstance ( node . value , ast . Call ) and isinstance ( node . value . func , ast . Name ) and node . value . func . id == '<STR_LIT>' : <EOL> if s . endswith ( '<STR_LIT:}>' ) and '<STR_LIT>' in s . split ( '<STR_LIT:U+0020>' ) : <EOL> pass <EOL> elif not s . endswith ( '<STR_LIT:;>' ) : <EOL> s += '<STR_LIT:;>' <EOL> elif not s . endswith ( '<STR_LIT:;>' ) : <EOL> s += '<STR_LIT:;>' <EOL> return s <EOL> def visit_Print ( self , node ) : <EOL> args = [ self . visit ( e ) for e in node . values ] <EOL> if len ( args ) > <NUM_LIT:1> : <EOL> s = '<STR_LIT>' % '<STR_LIT:U+002CU+0020>' . join ( args ) <EOL> else : <EOL> s = '<STR_LIT>' % '<STR_LIT:U+002CU+0020>' . join ( args ) <EOL> return s <EOL> def visit_Assign ( self , node ) : <EOL> assert len ( node . targets ) == <NUM_LIT:1> <EOL> target = node . targets [ <NUM_LIT:0> ] <EOL> if isinstance ( target , ast . Tuple ) : <EOL> elts = [ self . visit ( e ) for e in target . elts ] <EOL> if self . indent ( ) : <EOL> return '<STR_LIT>' % ( '<STR_LIT:U+002C>' . join ( elts ) , self . visit ( node . value ) ) <EOL> else : <EOL> return '<STR_LIT>' % ( '<STR_LIT:U+002C>' . join ( elts ) , self . visit ( node . value ) ) <EOL> else : <EOL> target = self . visit ( target ) <EOL> value = self . visit ( node . value ) <EOL> if self . indent ( ) : <EOL> code = '<STR_LIT>' % ( target , value ) <EOL> else : <EOL> code = '<STR_LIT>' % ( target , value ) <EOL> return code <EOL> def _visit_function ( self , node ) : <EOL> getter = False <EOL> setter = False <EOL> args_typedefs = { } <EOL> for decor in node . decorator_list : <EOL> if isinstance ( decor , ast . Name ) and decor . id == '<STR_LIT>' : <EOL> getter = True <EOL> elif isinstance ( decor , ast . Attribute ) and isinstance ( decor . value , ast . Name ) and decor . attr == '<STR_LIT>' : <EOL> setter = True <EOL> elif isinstance ( decor , ast . Call ) and isinstance ( decor . func , ast . Name ) and decor . func . id == '<STR_LIT>' : <EOL> for key in decor . keywords : <EOL> args_typedefs [ key . arg ] = key . value . id <EOL> else : <EOL> raise SyntaxError <EOL> args = [ ] <EOL> oargs = [ ] <EOL> offset = len ( node . args . args ) - len ( node . args . defaults ) <EOL> varargs = False <EOL> varargs_name = None <EOL> for i , arg in enumerate ( node . args . args ) : <EOL> a = arg . id <EOL> if a in args_typedefs : <EOL> a = '<STR_LIT>' % ( args_typedefs [ a ] , a ) <EOL> dindex = i - offset <EOL> if a . startswith ( '<STR_LIT>' ) : <EOL> varargs_name = a . split ( '<STR_LIT>' ) [ - <NUM_LIT:1> ] <EOL> varargs = [ '<STR_LIT>' % n for n in range ( <NUM_LIT:16> ) ] <EOL> args . append ( '<STR_LIT>' % '<STR_LIT:U+002C>' . join ( varargs ) ) <EOL> elif dindex >= <NUM_LIT:0> and node . args . defaults : <EOL> default_value = self . visit ( node . args . defaults [ dindex ] ) <EOL> oargs . append ( '<STR_LIT>' % ( a , default_value ) ) <EOL> else : <EOL> args . append ( a ) <EOL> if oargs : <EOL> args . append ( '<STR_LIT>' % '<STR_LIT:U+002C>' . join ( oargs ) ) <EOL> buffer = self . indent ( ) <EOL> if hasattr ( node , '<STR_LIT>' ) : buffer += node . _prefix + '<STR_LIT:U+0020>' <EOL> if getter : <EOL> buffer += '<STR_LIT>' % node . name <EOL> elif setter : <EOL> buffer += '<STR_LIT>' % ( node . name , '<STR_LIT:U+002CU+0020>' . join ( args ) ) <EOL> else : <EOL> buffer += '<STR_LIT>' % ( node . name , '<STR_LIT:U+002CU+0020>' . join ( args ) ) <EOL> self . push ( ) <EOL> if varargs : <EOL> buffer += '<STR_LIT>' % varargs_name <EOL> for i , n in enumerate ( varargs ) : <EOL> buffer += '<STR_LIT>' % ( n , varargs_name , n ) <EOL> body = list ( ) <EOL> for child in node . body : <EOL> if isinstance ( child , ast . Str ) : <EOL> continue <EOL> else : <EOL> body . append ( self . indent ( ) + self . visit ( child ) ) <EOL> buffer += '<STR_LIT:\n>' . join ( body ) <EOL> self . pull ( ) <EOL> buffer += '<STR_LIT>' % self . indent ( ) <EOL> return buffer <EOL> def visit_Is ( self , node ) : <EOL> return '<STR_LIT>' <EOL> def visit_IsNot ( self , node ) : <EOL> return '<STR_LIT>' <EOL> def visit_NotEq ( self , node ) : <EOL> return '<STR_LIT>' <EOL> def _visit_call_helper ( self , node ) : <EOL> if node . args : <EOL> args = [ self . visit ( e ) for e in node . args ] <EOL> args = '<STR_LIT:U+002CU+0020>' . join ( [ e for e in args if e ] ) <EOL> else : <EOL> args = '<STR_LIT>' <EOL> if isinstance ( node . func , ast . Name ) and node . func . id == '<STR_LIT>' and len ( node . args ) == <NUM_LIT:2> : <EOL> func = '<STR_LIT>' <EOL> else : <EOL> func = self . visit ( node . func ) <EOL> if node . keywords : <EOL> kwargs = '<STR_LIT:U+002C>' . join ( [ '<STR_LIT>' % ( x . arg , self . visit ( x . value ) ) for x in node . keywords ] ) <EOL> if args : <EOL> return '<STR_LIT>' % ( func , '<STR_LIT:U+002C>' . join ( args ) , kwargs ) <EOL> else : <EOL> return '<STR_LIT>' % ( func , kwargs ) <EOL> else : <EOL> return '<STR_LIT>' % ( func , args ) <EOL> def _visit_call_helper_var ( self , node ) : <EOL> args = [ self . visit ( a ) for a in node . args ] <EOL> if self . _function_stack : <EOL> fnode = self . _function_stack [ - <NUM_LIT:1> ] <EOL> rem = [ ] <EOL> for arg in args : <EOL> if arg in fnode . _local_vars : <EOL> rem . append ( arg ) <EOL> else : <EOL> fnode . _local_vars . add ( arg ) <EOL> for arg in rem : <EOL> args . remove ( arg ) <EOL> out = [ ] <EOL> if args : <EOL> out . append ( '<STR_LIT>' + '<STR_LIT:U+002C>' . join ( args ) ) <EOL> if node . keywords : <EOL> for key in node . keywords : <EOL> out . append ( '<STR_LIT>' % ( key . value . id , key . arg ) ) <EOL> return '<STR_LIT:;>' . join ( out ) <EOL> def _visit_call_helper_list ( self , node ) : <EOL> name = self . visit ( node . func ) <EOL> if node . args : <EOL> args = [ self . visit ( e ) for e in node . args ] <EOL> args = '<STR_LIT:U+002CU+0020>' . join ( [ e for e in args if e ] ) <EOL> else : <EOL> args = '<STR_LIT>' <EOL> return '<STR_LIT>' % ( name , args ) <EOL> def _visit_call_helper_numpy_array ( self , node ) : <EOL> simd = { <EOL> '<STR_LIT>' : '<STR_LIT>' <EOL> } <EOL> arg_name = args = None <EOL> direct = False <EOL> if isinstance ( node . args [ <NUM_LIT:0> ] , ast . Name ) : <EOL> arg_name = node . args [ <NUM_LIT:0> ] . id <EOL> else : <EOL> args = '<STR_LIT:U+002C>' . join ( [ self . visit ( a ) for a in node . args [ <NUM_LIT:0> ] . elts ] ) <EOL> if len ( node . args [ <NUM_LIT:0> ] . elts ) == <NUM_LIT:4> : <EOL> direct = True <EOL> if node . keywords : <EOL> for key in node . keywords : <EOL> if key . arg == '<STR_LIT>' : <EOL> if isinstance ( key . value , ast . Attribute ) and key . value . attr in simd : <EOL> if arg_name : <EOL> return '<STR_LIT>' % arg_name <EOL> elif direct : <EOL> return '<STR_LIT>' % ( simd [ key . value . attr ] , args ) <EOL> else : <EOL> return '<STR_LIT>' % args <EOL> else : <EOL> raise NotImplementedError ( '<STR_LIT>' ) <EOL> def _visit_call_helper_instanceof ( self , node ) : <EOL> args = map ( self . visit , node . args ) <EOL> if len ( args ) == <NUM_LIT:2> : <EOL> if args [ <NUM_LIT:1> ] == '<STR_LIT>' : <EOL> args [ <NUM_LIT:1> ] = '<STR_LIT>' <EOL> return '<STR_LIT>' % tuple ( args ) <EOL> else : <EOL> raise SyntaxError ( args ) <EOL> def visit_ExceptHandler ( self , node ) : <EOL> return '<STR_LIT:\n>' . join ( [ self . visit ( n ) for n in node . body ] ) <EOL> def visit_Compare ( self , node ) : <EOL> specials = { <EOL> '<STR_LIT:<>' : '<STR_LIT>' , <EOL> '<STR_LIT:>>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' <EOL> } <EOL> comp = [ ] <EOL> if len ( node . ops ) == <NUM_LIT:0> : <EOL> comp . append ( '<STR_LIT:(>' ) <EOL> comp . append ( self . visit ( node . left ) ) <EOL> comp . append ( '<STR_LIT:)>' ) <EOL> else : <EOL> if self . visit ( node . ops [ <NUM_LIT:0> ] ) in specials : <EOL> pass <EOL> else : <EOL> comp . append ( '<STR_LIT:(>' ) <EOL> comp . append ( self . visit ( node . left ) ) <EOL> comp . append ( '<STR_LIT:)>' ) <EOL> for i in range ( len ( node . ops ) ) : <EOL> op = self . visit ( node . ops [ i ] ) <EOL> if op in specials : <EOL> comp . append ( specials [ op ] + '<STR_LIT>' % self . visit ( node . left ) ) <EOL> else : <EOL> comp . append ( op ) <EOL> if isinstance ( node . comparators [ i ] , ast . BinOp ) : <EOL> comp . append ( '<STR_LIT:(>' ) <EOL> comp . append ( self . visit ( node . comparators [ i ] ) ) <EOL> comp . append ( '<STR_LIT:)>' ) <EOL> else : <EOL> comp . append ( self . visit ( node . comparators [ i ] ) ) <EOL> if op in specials : <EOL> comp . append ( '<STR_LIT:)>' ) <EOL> return '<STR_LIT:U+0020>' . join ( comp ) <EOL> def main ( script ) : <EOL> tree = ast . parse ( script ) <EOL> return DartGenerator ( ) . visit ( tree ) <EOL> def command ( ) : <EOL> scripts = [ ] <EOL> if len ( sys . argv ) > <NUM_LIT:1> : <EOL> for arg in sys . argv [ <NUM_LIT:1> : ] : <EOL> if arg . endswith ( '<STR_LIT>' ) : <EOL> scripts . append ( arg ) <EOL> if len ( scripts ) : <EOL> a = [ ] <EOL> for script in scripts : <EOL> a . append ( open ( script , '<STR_LIT:rb>' ) . read ( ) ) <EOL> data = '<STR_LIT:\n>' . join ( a ) <EOL> else : <EOL> data = sys . stdin . read ( ) <EOL> js = main ( data ) <EOL> print ( js ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> command ( ) </s>
<s> '''<STR_LIT>''' <EOL> from time import time <EOL> from time import sleep <EOL> import threading <EOL> def main ( ) : <EOL> if PYTHON == '<STR_LIT>' : <EOL> pythonjs . configure ( direct_operator = '<STR_LIT:+>' ) <EOL> pass <EOL> starttime = time ( ) <EOL> n = <NUM_LIT> <EOL> seq = [ ] <EOL> cache = [ ] <EOL> w1 = threading . start_webworker ( worker , ( <NUM_LIT:0> , n , seq , cache ) ) <EOL> sleep ( <NUM_LIT:1.0> ) <EOL> testtime = time ( ) - starttime <EOL> primes_per_sec = len ( seq ) * ( <NUM_LIT:1.0> / testtime ) <EOL> print ( primes_per_sec ) <EOL> print ( '<STR_LIT>' % testtime ) <EOL> print ( '<STR_LIT>' ) <EOL> with webworker : <EOL> def worker ( start , end , seq , cache ) : <EOL> print ( '<STR_LIT>' ) <EOL> for i in range ( start , end ) : <EOL> if i in cache : <EOL> pass <EOL> else : <EOL> cache . append ( i ) <EOL> if is_prime ( i ) : <EOL> seq . append ( i ) <EOL> print ( '<STR_LIT>' % i ) <EOL> def is_prime ( n ) : <EOL> hits = <NUM_LIT:0> <EOL> for x in range ( <NUM_LIT:2> , n ) : <EOL> for y in range ( <NUM_LIT:2> , n ) : <EOL> if x * y == n : <EOL> hits += <NUM_LIT:1> <EOL> if hits > <NUM_LIT:1> : <EOL> return False <EOL> return True </s>
<s> """<STR_LIT>""" <EOL> def main ( ) : <EOL> d = { } <EOL> if d : <EOL> err1 = <NUM_LIT:1> <EOL> else : <EOL> err1 = <NUM_LIT:0> <EOL> if { } : <EOL> err2 = <NUM_LIT:1> <EOL> else : <EOL> err2 = <NUM_LIT:0> <EOL> d [ '<STR_LIT:x>' ] = '<STR_LIT>' <EOL> if d : <EOL> err3 = <NUM_LIT:0> <EOL> else : <EOL> err3 = <NUM_LIT:1> <EOL> TestError ( err1 == <NUM_LIT:0> ) <EOL> TestError ( err2 == <NUM_LIT:0> ) <EOL> TestError ( err3 == <NUM_LIT:0> ) </s>
<s> """<STR_LIT>""" <EOL> def main ( ) : <EOL> a = False <EOL> b = False <EOL> if not a : <EOL> b = True <EOL> TestError ( b == True ) <EOL> a = <NUM_LIT:0> <EOL> b = False <EOL> if not a : <EOL> b = True <EOL> TestError ( b == True ) <EOL> a = <NUM_LIT:0.0> <EOL> b = False <EOL> if not a : <EOL> b = True <EOL> TestError ( b == True ) <EOL> a = None <EOL> b = False <EOL> if not a : <EOL> b = True <EOL> TestError ( b == True ) </s>
<s> '''<STR_LIT>''' <EOL> def main ( ) : <EOL> a = range ( <NUM_LIT:10> ) <EOL> TestError ( a [ <NUM_LIT:0> ] == <NUM_LIT:0> ) <EOL> TestError ( a [ <NUM_LIT:1> ] == <NUM_LIT:1> ) <EOL> TestError ( len ( a ) == <NUM_LIT:10> ) <EOL> b = range ( <NUM_LIT:1> , <NUM_LIT:10> ) <EOL> TestError ( b [ <NUM_LIT:0> ] == <NUM_LIT:1> ) <EOL> TestError ( b [ <NUM_LIT:1> ] == <NUM_LIT:2> ) <EOL> TestError ( len ( b ) == <NUM_LIT:9> ) <EOL> c = <NUM_LIT:0> <EOL> for i in range ( <NUM_LIT:10> ) : <EOL> c += <NUM_LIT:1> <EOL> TestError ( c == <NUM_LIT:10> ) <EOL> d = <NUM_LIT:0> <EOL> for i in range ( <NUM_LIT:1> , <NUM_LIT:10> ) : <EOL> d += <NUM_LIT:1> <EOL> TestError ( d == <NUM_LIT:9> ) <EOL> e = <NUM_LIT:0> <EOL> for i in range ( <NUM_LIT:1> , <NUM_LIT:8> + <NUM_LIT:2> ) : <EOL> e += <NUM_LIT:1> <EOL> TestError ( e == <NUM_LIT:9> ) </s>
<s> '''<STR_LIT>''' <EOL> from time import time <EOL> from time import sleep <EOL> import threading <EOL> def main ( ) : <EOL> if PYTHON == '<STR_LIT>' : <EOL> pythonjs . configure ( direct_operator = '<STR_LIT:+>' ) <EOL> pass <EOL> else : <EOL> def l ( f , a ) : threading . _start_new_thread ( f , a ) <EOL> threading . start_webworker = l <EOL> seq = { } <EOL> w1 = threading . start_webworker ( worker , ( seq , '<STR_LIT>' , '<STR_LIT:i>' ) ) <EOL> w2 = threading . start_webworker ( worker , ( seq , '<STR_LIT>' , '<STR_LIT:p>' ) ) <EOL> sleep ( <NUM_LIT:1.0> ) <EOL> TestError ( '<STR_LIT:a>' in seq ) <EOL> TestError ( '<STR_LIT:i>' in seq ) <EOL> print ( '<STR_LIT>' ) <EOL> print ( seq ) <EOL> if PYTHON != '<STR_LIT>' : <EOL> class webworker ( object ) : <EOL> def __enter__ ( self , * args ) : pass <EOL> def __exit__ ( self , * args ) : pass <EOL> webworker = webworker ( ) <EOL> with webworker : <EOL> def worker ( seq , s , break_on ) : <EOL> print ( '<STR_LIT>' ) <EOL> for char in s : <EOL> seq [ char ] = True <EOL> if break_on in seq : <EOL> break <EOL> sleep ( <NUM_LIT:0.1> ) <EOL> print ( '<STR_LIT>' ) <EOL> print ( seq ) </s>
<s> from OpenGL . GL import * <EOL> from OpenGL . GLU import * <EOL> import pygame <EOL> import os . path <EOL> class Material ( object ) : <EOL> def __init__ ( self ) : <EOL> self . name = "<STR_LIT>" <EOL> self . texture_fname = None <EOL> self . texture_id = None <EOL> class FaceGroup ( object ) : <EOL> def __init__ ( self ) : <EOL> self . tri_indices = [ ] <EOL> self . material_name = "<STR_LIT>" <EOL> class Model3D ( object ) : <EOL> def __init__ ( self ) : <EOL> self . vertices = [ ] <EOL> self . tex_coords = [ ] <EOL> self . normals = [ ] <EOL> self . materials = { } <EOL> self . face_groups = [ ] <EOL> self . display_list_id = None <EOL> def __del__ ( self ) : <EOL> self . free_resources ( ) <EOL> def free_resources ( self ) : <EOL> if self . display_list_id is not None : <EOL> glDeleteLists ( self . display_list_id , <NUM_LIT:1> ) <EOL> self . display_list_id = None <EOL> for material in self . materials . values ( ) : <EOL> if material . texture_id is not None : <EOL> glDeleteTextures ( material . texture_id ) <EOL> self . materials . clear ( ) <EOL> del self . vertices [ : ] <EOL> del self . tex_coords [ : ] <EOL> del self . normals [ : ] <EOL> del self . face_groups [ : ] <EOL> def read_obj ( self , fname ) : <EOL> current_face_group = None <EOL> file_in = open ( fname ) <EOL> for line in file_in : <EOL> words = line . split ( ) <EOL> command = words [ <NUM_LIT:0> ] <EOL> data = words [ <NUM_LIT:1> : ] <EOL> if command == '<STR_LIT>' : <EOL> model_path = os . path . split ( fname ) [ <NUM_LIT:0> ] <EOL> mtllib_path = os . path . join ( model_path , data [ <NUM_LIT:0> ] ) <EOL> self . read_mtllib ( mtllib_path ) <EOL> elif command == '<STR_LIT:v>' : <EOL> x , y , z = data <EOL> vertex = ( float ( x ) , float ( y ) , float ( z ) ) <EOL> self . vertices . append ( vertex ) <EOL> elif command == '<STR_LIT>' : <EOL> s , t = data <EOL> tex_coord = ( float ( s ) , float ( t ) ) <EOL> self . tex_coords . append ( tex_coord ) <EOL> elif command == '<STR_LIT>' : <EOL> x , y , z = data <EOL> normal = ( float ( x ) , float ( y ) , float ( z ) ) <EOL> self . normals . append ( normal ) <EOL> elif command == '<STR_LIT>' : <EOL> current_face_group = FaceGroup ( ) <EOL> current_face_group . material_name = data [ <NUM_LIT:0> ] <EOL> self . face_groups . append ( current_face_group ) <EOL> elif command == '<STR_LIT:f>' : <EOL> assert len ( data ) == <NUM_LIT:3> , "<STR_LIT>" <EOL> for word in data : <EOL> vi , ti , ni = word . split ( '<STR_LIT:/>' ) <EOL> indices = ( int ( vi ) - <NUM_LIT:1> , int ( ti ) - <NUM_LIT:1> , int ( ni ) - <NUM_LIT:1> ) <EOL> current_face_group . tri_indices . append ( indices ) <EOL> for material in self . materials . values ( ) : <EOL> model_path = os . path . split ( fname ) [ <NUM_LIT:0> ] <EOL> texture_path = os . path . join ( model_path , material . texture_fname ) <EOL> texture_surface = pygame . image . load ( texture_path ) <EOL> texture_data = pygame . image . tostring ( texture_surface , '<STR_LIT>' , True ) <EOL> material . texture_id = glGenTextures ( <NUM_LIT:1> ) <EOL> glBindTexture ( GL_TEXTURE_2D , material . texture_id ) <EOL> glTexParameteri ( GL_TEXTURE_2D , <EOL> GL_TEXTURE_MAG_FILTER , <EOL> GL_LINEAR ) <EOL> glTexParameteri ( GL_TEXTURE_2D , <EOL> GL_TEXTURE_MIN_FILTER , <EOL> GL_LINEAR_MIPMAP_LINEAR ) <EOL> glPixelStorei ( GL_UNPACK_ALIGNMENT , <NUM_LIT:1> ) <EOL> width , height = texture_surface . get_rect ( ) . size <EOL> gluBuild2DMipmaps ( GL_TEXTURE_2D , <EOL> <NUM_LIT:3> , <EOL> width , <EOL> height , <EOL> GL_RGB , <EOL> GL_UNSIGNED_BYTE , <EOL> texture_data ) <EOL> def read_mtllib ( self , mtl_fname ) : <EOL> file_mtllib = open ( mtl_fname ) <EOL> for line in file_mtllib : <EOL> words = line . split ( ) <EOL> command = words [ <NUM_LIT:0> ] <EOL> data = words [ <NUM_LIT:1> : ] <EOL> if command == '<STR_LIT>' : <EOL> material = Material ( ) <EOL> material . name = data [ <NUM_LIT:0> ] <EOL> self . materials [ data [ <NUM_LIT:0> ] ] = material <EOL> elif command == '<STR_LIT>' : <EOL> material . texture_fname = data [ <NUM_LIT:0> ] <EOL> def draw ( self ) : <EOL> vertices = self . vertices <EOL> tex_coords = self . tex_coords <EOL> normals = self . normals <EOL> for face_group in self . face_groups : <EOL> material = self . materials [ face_group . material_name ] <EOL> glBindTexture ( GL_TEXTURE_2D , material . texture_id ) <EOL> glBegin ( GL_TRIANGLES ) <EOL> for vi , ti , ni in face_group . tri_indices : <EOL> glTexCoord2fv ( tex_coords [ ti ] ) <EOL> glNormal3fv ( normals [ ni ] ) <EOL> glVertex3fv ( vertices [ vi ] ) <EOL> glEnd ( ) <EOL> def draw_quick ( self ) : <EOL> if self . display_list_id is None : <EOL> self . display_list_id = glGenLists ( <NUM_LIT:1> ) <EOL> glNewList ( self . display_list_id , GL_COMPILE ) <EOL> self . draw ( ) <EOL> glEndList ( ) <EOL> glCallList ( self . display_list_id ) </s>
<s> def saturate_color ( color ) : <EOL> red , green , blue = color <EOL> red = min ( red , <NUM_LIT:255> ) <EOL> green = min ( green , <NUM_LIT:255> ) <EOL> blue = min ( blue , <NUM_LIT:255> ) <EOL> return red , green , blue </s>
<s> import pygame <EOL> from pygame . locals import * <EOL> from sys import exit <EOL> from gameobjects . vector2 import Vector2 <EOL> picture_file = '<STR_LIT>' <EOL> pygame . init ( ) <EOL> screen = pygame . display . set_mode ( ( <NUM_LIT> , <NUM_LIT> ) , <NUM_LIT:0> , <NUM_LIT:32> ) <EOL> picture = pygame . image . load ( picture_file ) . convert ( ) <EOL> picture_pos = Vector2 ( <NUM_LIT:0> , <NUM_LIT:0> ) <EOL> scroll_speed = <NUM_LIT> <EOL> clock = pygame . time . Clock ( ) <EOL> joystick = None <EOL> if pygame . joystick . get_count ( ) > <NUM_LIT:0> : <EOL> joystick = pygame . joystick . Joystick ( <NUM_LIT:0> ) <EOL> joystick . init ( ) <EOL> if joystick is None : <EOL> print ( "<STR_LIT>" ) <EOL> pygame . quit ( ) <EOL> exit ( ) <EOL> while True : <EOL> for event in pygame . event . get ( ) : <EOL> if event . type == QUIT : <EOL> pygame . quit ( ) <EOL> exit ( ) <EOL> scroll_direction = Vector2 ( * joystick . get_hat ( <NUM_LIT:0> ) ) <EOL> scroll_direction . normalize ( ) <EOL> screen . fill ( ( <NUM_LIT:255> , <NUM_LIT:255> , <NUM_LIT:255> ) ) <EOL> screen . blit ( picture , ( - picture_pos . x , picture_pos . y ) ) <EOL> time_passed = clock . tick ( ) <EOL> time_passed_seconds = time_passed / <NUM_LIT> <EOL> picture_pos += scroll_direction * scroll_speed * time_passed_seconds <EOL> pygame . display . update ( ) </s>
<s> __all__ = [ <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' <EOL> ] <EOL> __version__ = "<STR_LIT>" </s>
<s> """<STR_LIT>""" <EOL> import os <EOL> from setuptools import setup , find_packages <EOL> THISDIR = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> os . chdir ( THISDIR ) <EOL> VERSION = open ( "<STR_LIT>" ) . readline ( ) . strip ( ) <EOL> HOMEPAGE = "<STR_LIT>" <EOL> DOWNLOAD_BASEURL = "<STR_LIT>" <EOL> DOWNLOAD_URL = DOWNLOAD_BASEURL + "<STR_LIT>" % VERSION <EOL> setup ( <EOL> name = "<STR_LIT>" , <EOL> version = VERSION , <EOL> description = ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> long_description = open ( "<STR_LIT>" ) . read ( ) , <EOL> keywords = ( <EOL> "<STR_LIT>" <EOL> "<STR_LIT>" <EOL> ) , <EOL> author = "<STR_LIT>" , <EOL> author_email = "<STR_LIT>" , <EOL> url = HOMEPAGE , <EOL> download_url = DOWNLOAD_URL , <EOL> packages = find_packages ( ) , <EOL> classifiers = [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ] , <EOL> install_requires = [ "<STR_LIT>" , "<STR_LIT>" ] , <EOL> ) </s>
<s> from __future__ import unicode_literals <EOL> from django . db import migrations , models <EOL> class Migration ( migrations . Migration ) : <EOL> dependencies = [ <EOL> ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> ] <EOL> operations = [ <EOL> migrations . AddField ( <EOL> model_name = '<STR_LIT:user>' , <EOL> name = '<STR_LIT>' , <EOL> field = models . BooleanField ( default = False ) , <EOL> ) , <EOL> ] </s>
<s> from __future__ import unicode_literals <EOL> from django . db import models , migrations <EOL> from django . conf import settings <EOL> import utils . models <EOL> class Migration ( migrations . Migration ) : <EOL> dependencies = [ <EOL> migrations . swappable_dependency ( settings . AUTH_USER_MODEL ) , <EOL> ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> ] <EOL> operations = [ <EOL> migrations . CreateModel ( <EOL> name = '<STR_LIT>' , <EOL> fields = [ <EOL> ( '<STR_LIT:id>' , models . AutoField ( verbose_name = '<STR_LIT>' , serialize = False , auto_created = True , primary_key = True ) ) , <EOL> ( '<STR_LIT>' , models . IntegerField ( default = <NUM_LIT:0> ) ) , <EOL> ( '<STR_LIT>' , models . IntegerField ( default = <NUM_LIT:0> ) ) , <EOL> ( '<STR_LIT>' , models . IntegerField ( default = <NUM_LIT:0> ) ) , <EOL> ( '<STR_LIT>' , utils . models . JsonField ( default = { } ) ) , <EOL> ( '<STR_LIT>' , models . ForeignKey ( to = '<STR_LIT>' ) ) , <EOL> ( '<STR_LIT:user>' , models . ForeignKey ( to = settings . AUTH_USER_MODEL ) ) , <EOL> ] , <EOL> ) , <EOL> ] </s>
<s> import os <EOL> import judger <EOL> WA = <NUM_LIT:1> <EOL> AC = <NUM_LIT:0> <EOL> SPJ_ERROR = - <NUM_LIT:1> <EOL> def file_exists ( path ) : <EOL> return os . path . exists ( path ) <EOL> def spj ( path , max_cpu_time , max_memory , in_path , user_out_path ) : <EOL> if file_exists ( in_path ) and file_exists ( user_out_path ) : <EOL> result = judger . run ( path = path , in_file = in_path , out_file = "<STR_LIT>" , <EOL> max_cpu_time = max_cpu_time , max_memory = max_memory , <EOL> args = [ in_path , user_out_path ] , env = [ "<STR_LIT>" + os . environ . get ( "<STR_LIT>" , "<STR_LIT>" ) ] , <EOL> use_sandbox = True , use_nobody = True ) <EOL> if result [ "<STR_LIT>" ] == <NUM_LIT:0> and result [ "<STR_LIT>" ] in [ AC , WA , SPJ_ERROR ] : <EOL> result [ "<STR_LIT>" ] = result [ "<STR_LIT>" ] <EOL> else : <EOL> result [ "<STR_LIT>" ] = SPJ_ERROR <EOL> return result <EOL> else : <EOL> raise ValueError ( "<STR_LIT>" ) </s>
<s> from __future__ import unicode_literals <EOL> from django . db import models , migrations <EOL> class Migration ( migrations . Migration ) : <EOL> dependencies = [ <EOL> ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> ] <EOL> operations = [ <EOL> migrations . RemoveField ( <EOL> model_name = '<STR_LIT>' , <EOL> name = '<STR_LIT>' , <EOL> ) , <EOL> ] </s>
<s> from django . http import HttpResponse <EOL> from utils . captcha import Captcha <EOL> def show_captcha ( request ) : <EOL> return HttpResponse ( Captcha ( request ) . display ( ) , content_type = "<STR_LIT>" ) </s>
<s> """<STR_LIT>""" <EOL> import time <EOL> import numpy as np <EOL> def _print_after_skip ( skip , it = None , dist = None , etime = None ) : <EOL> if it is None : <EOL> msg = "<STR_LIT>" . format ( i = "<STR_LIT>" , <EOL> d = "<STR_LIT>" , <EOL> t = "<STR_LIT>" ) <EOL> print ( msg ) <EOL> print ( "<STR_LIT:->" * len ( msg ) ) <EOL> return <EOL> if it % skip == <NUM_LIT:0> : <EOL> if etime is None : <EOL> print ( "<STR_LIT>" . format ( it = it , d = dist ) ) <EOL> else : <EOL> msg = "<STR_LIT>" <EOL> print ( msg . format ( i = it , d = dist , t = etime ) ) <EOL> return <EOL> def compute_fixed_point ( T , v , error_tol = <NUM_LIT> , max_iter = <NUM_LIT:50> , verbose = <NUM_LIT:1> , <EOL> print_skip = <NUM_LIT:5> , * args , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> iterate = <NUM_LIT:0> <EOL> error = error_tol + <NUM_LIT:1> <EOL> if verbose : <EOL> start_time = time . time ( ) <EOL> _print_after_skip ( print_skip , it = None ) <EOL> while iterate < max_iter and error > error_tol : <EOL> new_v = T ( v , * args , ** kwargs ) <EOL> iterate += <NUM_LIT:1> <EOL> error = np . max ( np . abs ( new_v - v ) ) <EOL> if verbose : <EOL> etime = time . time ( ) - start_time <EOL> _print_after_skip ( print_skip , iterate , error , etime ) <EOL> try : <EOL> v [ : ] = new_v <EOL> except TypeError : <EOL> v = new_v <EOL> return v </s>
<s> raise ImportError ( "<STR_LIT>" ) </s>
<s> """<STR_LIT>""" <EOL> import sys <EOL> import os <EOL> import unittest <EOL> import numpy as np <EOL> from scipy . linalg import LinAlgError <EOL> from numpy . testing import assert_allclose <EOL> from quantecon . lqcontrol import LQ <EOL> from quantecon . robustlq import RBLQ <EOL> class TestRBLQControl ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> a_0 = <NUM_LIT:100> <EOL> a_1 = <NUM_LIT:0.5> <EOL> rho = <NUM_LIT> <EOL> sigma_d = <NUM_LIT> <EOL> beta = <NUM_LIT> <EOL> c = <NUM_LIT:2> <EOL> gamma = <NUM_LIT> <EOL> theta = <NUM_LIT> <EOL> ac = ( a_0 - c ) / <NUM_LIT> <EOL> R = np . array ( [ [ <NUM_LIT:0> , ac , <NUM_LIT:0> ] , <EOL> [ ac , - a_1 , <NUM_LIT:0.5> ] , <EOL> [ <NUM_LIT:0.> , <NUM_LIT:0.5> , <NUM_LIT:0> ] ] ) <EOL> R = - R <EOL> Q = gamma / <NUM_LIT:2> <EOL> A = np . array ( [ [ <NUM_LIT:1.> , <NUM_LIT:0.> , <NUM_LIT:0.> ] , <EOL> [ <NUM_LIT:0.> , <NUM_LIT:1.> , <NUM_LIT:0.> ] , <EOL> [ <NUM_LIT:0.> , <NUM_LIT:0.> , rho ] ] ) <EOL> B = np . array ( [ [ <NUM_LIT:0.> ] , <EOL> [ <NUM_LIT:1.> ] , <EOL> [ <NUM_LIT:0.> ] ] ) <EOL> C = np . array ( [ [ <NUM_LIT:0.> ] , <EOL> [ <NUM_LIT:0.> ] , <EOL> [ sigma_d ] ] ) <EOL> self . rblq_test = RBLQ ( Q , R , A , B , C , beta , theta ) <EOL> self . lq_test = LQ ( Q , R , A , B , C , beta ) <EOL> self . Fr , self . Kr , self . Pr = self . rblq_test . robust_rule ( ) <EOL> def tearDown ( self ) : <EOL> del self . rblq_test <EOL> def test_robust_rule_vs_simple ( self ) : <EOL> rblq = self . rblq_test <EOL> Fr , Kr , Pr = self . Fr , self . Kr , self . Pr <EOL> Fs , Ks , Ps = rblq . robust_rule_simple ( P_init = Pr , tol = <NUM_LIT> ) <EOL> assert_allclose ( Fr , Fs , rtol = <NUM_LIT> ) <EOL> assert_allclose ( Kr , Ks , rtol = <NUM_LIT> ) <EOL> assert_allclose ( Pr , Ps , rtol = <NUM_LIT> ) <EOL> def test_f2k_and_k2f ( self ) : <EOL> rblq = self . rblq_test <EOL> Fr , Kr , Pr = self . Fr , self . Kr , self . Pr <EOL> K_f2k , P_f2k = rblq . F_to_K ( Fr ) <EOL> F_k2f , P_k2f = rblq . K_to_F ( Kr ) <EOL> assert_allclose ( K_f2k , Kr , rtol = <NUM_LIT> ) <EOL> assert_allclose ( F_k2f , Fr , rtol = <NUM_LIT> ) <EOL> assert_allclose ( P_f2k , P_k2f , rtol = <NUM_LIT> ) <EOL> def test_evaluate_F ( self ) : <EOL> rblq = self . rblq_test <EOL> Fr , Kr , Pr = self . Fr , self . Kr , self . Pr <EOL> Kf , Pf , df , Of , of = rblq . evaluate_F ( Fr ) <EOL> assert_allclose ( Pf , Pr ) <EOL> assert_allclose ( Kf , Kr ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> suite = unittest . TestLoader ( ) . loadTestsFromTestCase ( TestRBLQControl ) <EOL> unittest . TextTestRunner ( verbosity = <NUM_LIT:2> , stream = sys . stderr ) . run ( suite ) </s>
<s> '''<STR_LIT>''' <EOL> import tables as pt <EOL> fileName = "<STR_LIT>" <EOL> h5f = [ ] <EOL> group = [ ] <EOL> table = [ ] <EOL> opened = False <EOL> ctr = float ( <NUM_LIT:0.0> ) <EOL> class AlphaDataModelClass ( pt . IsDescription ) : <EOL> symbol = pt . StringCol ( <NUM_LIT:30> ) <EOL> exchange = pt . StringCol ( <NUM_LIT:10> ) <EOL> alphaValue = pt . Float32Col ( ) <EOL> timestamp = pt . Time64Col ( ) <EOL> def __init__ ( self ) : <EOL> print "<STR_LIT>" <EOL> def openFile ( newFileName ) : <EOL> '''<STR_LIT>''' <EOL> global fileName , h5f , group , table , opened , ctr <EOL> ctr = float ( <NUM_LIT:0.0> ) <EOL> if newFileName is None : <EOL> print "<STR_LIT>" <EOL> else : <EOL> if ( len ( newFileName ) > <NUM_LIT:0> ) : <EOL> fileName = str ( newFileName ) <EOL> else : <EOL> print "<STR_LIT>" <EOL> if not opened : <EOL> h5f = pt . openFile ( str ( fileName ) , mode = "<STR_LIT:w>" ) <EOL> group = h5f . createGroup ( "<STR_LIT:/>" , '<STR_LIT>' ) <EOL> table = h5f . createTable ( group , '<STR_LIT>' , AlphaDataModelClass ) <EOL> opened = True <EOL> else : <EOL> print "<STR_LIT>" <EOL> def addRow ( currSymbol , currExchange , currAlphaVal , currTS ) : <EOL> '''<STR_LIT>''' <EOL> global ctr <EOL> if opened : <EOL> ctr = ctr + <NUM_LIT:1> <EOL> row = table . row <EOL> row [ '<STR_LIT>' ] = currSymbol <EOL> row [ '<STR_LIT>' ] = currExchange <EOL> row [ '<STR_LIT>' ] = currAlphaVal <EOL> row [ '<STR_LIT>' ] = currTS <EOL> row . append ( ) <EOL> if ( ctr == <NUM_LIT> ) : <EOL> ctr = <NUM_LIT:0> <EOL> table . flush ( ) <EOL> else : <EOL> print "<STR_LIT>" <EOL> raise IOError <EOL> def closeFile ( ) : <EOL> '''<STR_LIT>''' <EOL> table . flush ( ) <EOL> h5f . close ( ) <EOL> print str ( fileName ) + "<STR_LIT>" <EOL> opened = False </s>
<s> '''<STR_LIT>''' <EOL> import numpy as np <EOL> import pickle as pkl <EOL> import qstkutil . utils as utils <EOL> import os <EOL> import dircache <EOL> import time <EOL> import sys <EOL> def main ( ) : <EOL> print "<STR_LIT>" + str ( time . strftime ( "<STR_LIT>" ) ) <EOL> try : <EOL> rootdir = os . environ [ '<STR_LIT>' ] <EOL> except KeyError : <EOL> print "<STR_LIT>" <EOL> fileExtensionToRemove = "<STR_LIT>" <EOL> listOfInputPaths = list ( ) <EOL> listOfInputPaths . append ( rootdir + "<STR_LIT>" ) <EOL> listOfInputPaths . append ( rootdir + "<STR_LIT>" ) <EOL> listOfInputPaths . append ( rootdir + "<STR_LIT>" ) <EOL> listOfOutputPaths = list ( ) <EOL> listOfOutputPaths . append ( rootdir + "<STR_LIT>" ) <EOL> listOfOutputPaths . append ( rootdir + "<STR_LIT>" ) <EOL> listOfOutputPaths . append ( rootdir + "<STR_LIT>" ) <EOL> for path in listOfOutputPaths : <EOL> if not ( os . access ( path , os . F_OK ) ) : <EOL> os . makedirs ( path ) <EOL> utils . clean_paths ( listOfOutputPaths ) <EOL> if ( len ( listOfInputPaths ) != len ( listOfOutputPaths ) ) : <EOL> print "<STR_LIT>" <EOL> sys . exit ( "<STR_LIT>" ) <EOL> path_ctr = - <NUM_LIT:1> ; <EOL> use_cols = range ( <NUM_LIT:1> , <NUM_LIT:7> + <NUM_LIT:1> ) <EOL> for path in listOfInputPaths : <EOL> path_ctr = path_ctr + <NUM_LIT:1> ; <EOL> stocks_at_this_path = dircache . listdir ( str ( path ) ) <EOL> filtered_names = filter ( lambda x : ( str ( x ) . find ( str ( fileExtensionToRemove ) ) > - <NUM_LIT:1> ) , stocks_at_this_path ) <EOL> filtered_names = map ( lambda x : ( x . partition ( str ( fileExtensionToRemove ) ) [ <NUM_LIT:0> ] ) , filtered_names ) <EOL> stock_ctr = - <NUM_LIT:1> <EOL> for stock in filtered_names : <EOL> stock_ctr = stock_ctr + <NUM_LIT:1> <EOL> print "<STR_LIT>" + str ( path + stock ) <EOL> stock_data = np . loadtxt ( path + stock + "<STR_LIT>" , np . float , None , "<STR_LIT:U+002C>" , None , <NUM_LIT:1> , use_cols ) <EOL> stock_data_shape = stock_data . shape <EOL> f = open ( listOfOutputPaths [ path_ctr ] + filtered_names [ stock_ctr ] + "<STR_LIT>" , "<STR_LIT:wb>" ) <EOL> pkl . dump ( stock_data , f , - <NUM_LIT:1> ) <EOL> f . close ( ) <EOL> print "<STR_LIT>" + str ( time . strftime ( "<STR_LIT>" ) ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> main ( ) </s>
<s> '''<STR_LIT>''' <EOL> import cPickle <EOL> import sys <EOL> from pandas import DataMatrix <EOL> import datetime as dt <EOL> import random <EOL> import qstkutil . DataAccess as da <EOL> import qstkutil . qsdateutil as du <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> print "<STR_LIT>" + sys . argv [ <NUM_LIT:1> ] + "<STR_LIT>" + sys . argv [ <NUM_LIT:2> ] <EOL> symbols = list ( [ '<STR_LIT>' ] ) <EOL> t = map ( int , sys . argv [ <NUM_LIT:1> ] . split ( '<STR_LIT:->' ) ) <EOL> startday = dt . datetime ( t [ <NUM_LIT:2> ] , t [ <NUM_LIT:0> ] , t [ <NUM_LIT:1> ] ) <EOL> t = map ( int , sys . argv [ <NUM_LIT:2> ] . split ( '<STR_LIT:->' ) ) <EOL> endday = dt . datetime ( t [ <NUM_LIT:2> ] , t [ <NUM_LIT:0> ] , t [ <NUM_LIT:1> ] ) <EOL> timeofday = dt . timedelta ( hours = <NUM_LIT:16> ) <EOL> timestamps = du . getNYSEdays ( startday , endday , timeofday ) <EOL> dataobj = da . DataAccess ( '<STR_LIT>' ) <EOL> historic = dataobj . get_data ( timestamps , symbols , "<STR_LIT>" ) <EOL> alloc_val = random . random ( ) <EOL> alloc = DataMatrix ( index = [ historic . index [ <NUM_LIT:0> ] ] , data = [ alloc_val ] , columns = symbols ) <EOL> for date in range ( <NUM_LIT:1> , len ( historic . index ) ) : <EOL> alloc_val = <NUM_LIT:1> <EOL> alloc = alloc . append ( DataMatrix ( index = [ historic . index [ date ] ] , data = [ alloc_val ] , columns = [ symbols [ <NUM_LIT:0> ] ] ) ) <EOL> alloc [ '<STR_LIT>' ] = <NUM_LIT:1> - alloc [ symbols [ <NUM_LIT:0> ] ] <EOL> output = open ( sys . argv [ <NUM_LIT:3> ] , "<STR_LIT:wb>" ) <EOL> cPickle . dump ( alloc , output ) </s>
<s> '''<STR_LIT>''' <EOL> import QSTK . qstkutil . DataAccess as da <EOL> import tables as pt <EOL> import numpy as np <EOL> from itertools import izip <EOL> import time <EOL> import dircache <EOL> def getStocks ( listOfPaths ) : <EOL> listOfStocks = list ( ) <EOL> print "<STR_LIT>" <EOL> fileExtensionToRemove = "<STR_LIT>" <EOL> for path in listOfPaths : <EOL> stocksAtThisPath = list ( ) <EOL> stocksAtThisPath = dircache . listdir ( str ( path ) ) <EOL> stocksAtThisPath = filter ( lambda x : ( str ( x ) . find ( str ( fileExtensionToRemove ) ) > - <NUM_LIT:1> ) , stocksAtThisPath ) <EOL> stocksAtThisPath = map ( lambda x : ( x . partition ( str ( fileExtensionToRemove ) ) [ <NUM_LIT:0> ] ) , stocksAtThisPath ) <EOL> for stock in stocksAtThisPath : <EOL> listOfStocks . append ( stock ) <EOL> return listOfStocks <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> print "<STR_LIT>" <EOL> dataItemsList = [ ] <EOL> dataItemsList . append ( '<STR_LIT>' ) <EOL> listOfStocks = list ( ) <EOL> listOfPaths = list ( ) <EOL> listOfPaths . append ( "<STR_LIT>" ) <EOL> listOfStocks = getStocks ( listOfPaths ) <EOL> alpha = da . DataAccess ( True , listOfPaths , "<STR_LIT>" , "<STR_LIT>" , True , listOfStocks ) <EOL> tslist = list ( alpha . getTimestampArray ( ) ) <EOL> listOfTS = alpha . getTimestampArray ( ) <EOL> for stock in [ "<STR_LIT>" ] : <EOL> alphaList = alpha . getStockDataList ( stock , '<STR_LIT>' ) <EOL> ctr = <NUM_LIT:0> <EOL> for val in alphaList : <EOL> print "<STR_LIT>" + str ( stock ) + "<STR_LIT>" + str ( val ) + "<STR_LIT>" + str ( listOfTS [ ctr ] ) <EOL> ctr += <NUM_LIT:1> <EOL> print "<STR_LIT>" </s>
<s> import unittest <EOL> import collections_and_iterators <EOL> """<STR_LIT>""" <EOL> class TestObjectMethods ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . singleLinkList = collections_and_iterators . SinglyLinkedList ( ) <EOL> self . singleLinkListData = collections_and_iterators . SinglyLinkedList ( ) <EOL> self . singleLinkListData . append ( "<STR_LIT>" ) <EOL> self . singleLinkListData . append ( "<STR_LIT>" ) <EOL> self . singleLinkListData . append ( "<STR_LIT>" ) <EOL> self . doubleLinkList = collections_and_iterators . DoublyLinkedList ( ) <EOL> self . doubleLinkListData = collections_and_iterators . DoublyLinkedList ( ) <EOL> self . doubleLinkListData . append ( "<STR_LIT>" ) <EOL> self . doubleLinkListData . append ( "<STR_LIT>" ) <EOL> self . doubleLinkListData . append ( "<STR_LIT>" ) <EOL> def test_empty_single_list ( self ) : <EOL> self . assertEqual ( <NUM_LIT:0> , self . singleLinkList . size ) <EOL> self . assertIsNone ( self . singleLinkList . head ) <EOL> self . assertIsNone ( self . singleLinkList . cursor ) <EOL> def test_contains_success ( self ) : <EOL> self . assertTrue ( "<STR_LIT>" in self . singleLinkListData ) <EOL> self . assertTrue ( "<STR_LIT>" in self . singleLinkListData ) <EOL> self . assertTrue ( "<STR_LIT>" in self . singleLinkListData ) <EOL> def test_contains_failure ( self ) : <EOL> self . assertFalse ( "<STR_LIT>" in self . singleLinkListData ) <EOL> self . assertFalse ( "<STR_LIT>" in self . singleLinkListData ) <EOL> def test_append_success ( self ) : <EOL> self . assertEqual ( "<STR_LIT>" , self . singleLinkListData [ <NUM_LIT:0> ] ) <EOL> self . assertEqual ( "<STR_LIT>" , self . singleLinkListData [ <NUM_LIT:1> ] ) <EOL> self . assertEqual ( "<STR_LIT>" , self . singleLinkListData [ <NUM_LIT:2> ] ) <EOL> def test_append_failure ( self ) : <EOL> with self . assertRaises ( IndexError ) : <EOL> self . singleLinkListData [ <NUM_LIT:3> ] <EOL> self . singleLinkListData . append ( "<STR_LIT>" ) <EOL> self . assertEqual ( "<STR_LIT>" , self . singleLinkListData [ <NUM_LIT:3> ] ) <EOL> def test_getitem_success ( self ) : <EOL> self . assertEqual ( "<STR_LIT>" , self . singleLinkListData . __getitem__ ( <NUM_LIT:0> ) ) <EOL> self . assertEqual ( "<STR_LIT>" , self . singleLinkListData . __getitem__ ( <NUM_LIT:1> ) ) <EOL> self . assertEqual ( "<STR_LIT>" , self . singleLinkListData . __getitem__ ( <NUM_LIT:2> ) ) <EOL> def test_getitem_failure ( self ) : <EOL> with self . assertRaises ( IndexError ) : <EOL> self . singleLinkListData . __getitem__ ( <NUM_LIT:3> ) <EOL> self . singleLinkListData . __getitem__ ( - <NUM_LIT:3> ) <EOL> def test_setitem_success ( self ) : <EOL> self . assertEqual ( "<STR_LIT>" , self . singleLinkListData [ <NUM_LIT:0> ] ) <EOL> self . singleLinkListData [ <NUM_LIT:0> ] = "<STR_LIT>" <EOL> self . assertEqual ( "<STR_LIT>" , self . singleLinkListData [ <NUM_LIT:0> ] ) <EOL> def test_setitem_failure ( self ) : <EOL> with self . assertRaises ( IndexError ) : <EOL> self . singleLinkListData [ <NUM_LIT:5> ] = "<STR_LIT>" <EOL> self . singleLinkListData [ - <NUM_LIT:1> ] = "<STR_LIT>" <EOL> def test_empty_double_list ( self ) : <EOL> self . assertEqual ( <NUM_LIT:0> , self . doubleLinkList . size ) <EOL> self . assertIsNone ( self . doubleLinkList . head ) <EOL> self . assertIsNone ( self . doubleLinkList . cursor ) <EOL> def test_insert_success ( self ) : <EOL> self . assertEqual ( "<STR_LIT>" , self . doubleLinkListData [ <NUM_LIT:0> ] ) <EOL> self . assertEqual ( "<STR_LIT>" , self . doubleLinkListData [ <NUM_LIT:1> ] ) <EOL> self . assertEqual ( "<STR_LIT>" , self . doubleLinkListData [ <NUM_LIT:2> ] ) <EOL> self . doubleLinkListData . insert ( "<STR_LIT>" , <NUM_LIT:0> ) <EOL> self . assertEqual ( "<STR_LIT>" , self . doubleLinkListData [ <NUM_LIT:0> ] ) <EOL> self . assertEqual ( "<STR_LIT>" , self . doubleLinkListData [ <NUM_LIT:1> ] ) <EOL> self . assertEqual ( "<STR_LIT>" , self . doubleLinkListData [ <NUM_LIT:2> ] ) <EOL> self . assertEqual ( "<STR_LIT>" , self . doubleLinkListData [ <NUM_LIT:3> ] ) <EOL> self . doubleLinkListData . insert ( "<STR_LIT>" , <NUM_LIT:2> ) <EOL> self . assertEqual ( "<STR_LIT>" , self . doubleLinkListData [ <NUM_LIT:0> ] ) <EOL> self . assertEqual ( "<STR_LIT>" , self . doubleLinkListData [ <NUM_LIT:1> ] ) <EOL> self . assertEqual ( "<STR_LIT>" , self . doubleLinkListData [ <NUM_LIT:2> ] ) <EOL> self . assertEqual ( "<STR_LIT>" , self . doubleLinkListData [ <NUM_LIT:3> ] ) <EOL> self . assertEqual ( "<STR_LIT>" , self . doubleLinkListData [ <NUM_LIT:4> ] ) <EOL> def test_insert_fauilure ( self ) : <EOL> pass <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> unittest . main ( verbosity = <NUM_LIT:2> ) </s>
<s> """<STR_LIT>""" <EOL> import re <EOL> from itertools import chain <EOL> from textwrap import dedent <EOL> from jedi . evaluate . cache import memoize_default <EOL> from jedi . parser import Parser <EOL> from jedi . common import indent_block <EOL> DOCSTRING_PARAM_PATTERNS = [ <EOL> r'<STR_LIT>' , <EOL> r'<STR_LIT>' , <EOL> ] <EOL> DOCSTRING_RETURN_PATTERNS = [ <EOL> re . compile ( r'<STR_LIT>' , re . M ) , <EOL> re . compile ( r'<STR_LIT>' , re . M ) , <EOL> ] <EOL> REST_ROLE_PATTERN = re . compile ( r'<STR_LIT>' ) <EOL> @ memoize_default ( None , evaluator_is_first_arg = True ) <EOL> def follow_param ( evaluator , param ) : <EOL> func = param . parent_function <EOL> param_str = _search_param_in_docstr ( func . raw_doc , str ( param . get_name ( ) ) ) <EOL> return _evaluate_for_statement_string ( evaluator , param_str , param . get_parent_until ( ) ) <EOL> def _search_param_in_docstr ( docstr , param_str ) : <EOL> """<STR_LIT>""" <EOL> patterns = [ re . compile ( p % re . escape ( param_str ) ) <EOL> for p in DOCSTRING_PARAM_PATTERNS ] <EOL> for pattern in patterns : <EOL> match = pattern . search ( docstr ) <EOL> if match : <EOL> return _strip_rst_role ( match . group ( <NUM_LIT:1> ) ) <EOL> return None <EOL> def _strip_rst_role ( type_str ) : <EOL> """<STR_LIT>""" <EOL> match = REST_ROLE_PATTERN . match ( type_str ) <EOL> if match : <EOL> return match . group ( <NUM_LIT:1> ) <EOL> else : <EOL> return type_str <EOL> def _evaluate_for_statement_string ( evaluator , string , module ) : <EOL> code = dedent ( """<STR_LIT>""" ) <EOL> if string is None : <EOL> return [ ] <EOL> for element in re . findall ( '<STR_LIT>' , string ) : <EOL> string = '<STR_LIT>' % element + string <EOL> p = Parser ( code % indent_block ( string ) , no_docstr = True ) <EOL> pseudo_cls = p . module . subscopes [ <NUM_LIT:0> ] <EOL> try : <EOL> stmt = pseudo_cls . statements [ - <NUM_LIT:1> ] <EOL> except IndexError : <EOL> return [ ] <EOL> pseudo_cls . parent = module <EOL> definitions = evaluator . eval_statement ( stmt ) <EOL> it = ( evaluator . execute ( d ) for d in definitions ) <EOL> return list ( chain . from_iterable ( it ) ) or definitions <EOL> @ memoize_default ( None , evaluator_is_first_arg = True ) <EOL> def find_return_types ( evaluator , func ) : <EOL> def search_return_in_docstr ( code ) : <EOL> for p in DOCSTRING_RETURN_PATTERNS : <EOL> match = p . search ( code ) <EOL> if match : <EOL> return _strip_rst_role ( match . group ( <NUM_LIT:1> ) ) <EOL> type_str = search_return_in_docstr ( func . raw_doc ) <EOL> return _evaluate_for_statement_string ( evaluator , type_str , func . get_parent_until ( ) ) </s>
<s> """<STR_LIT>""" <EOL> from __future__ import absolute_import <EOL> import unittest <EOL> class Assertions ( unittest . TestCase ) : <EOL> pass </s>
<s> from jedi import parser <EOL> from jedi . _compatibility import u <EOL> try : <EOL> import unittest2 as unittest <EOL> except ImportError : <EOL> import unittest <EOL> class TokenTest ( unittest . TestCase ) : <EOL> def test_end_pos_one_line ( self ) : <EOL> parsed = parser . Parser ( u ( '''<STR_LIT>''' ) ) <EOL> tok = parsed . module . subscopes [ <NUM_LIT:0> ] . statements [ <NUM_LIT:0> ] . _token_list [ <NUM_LIT:2> ] <EOL> self . assertEqual ( tok . end_pos , ( <NUM_LIT:3> , <NUM_LIT> ) ) <EOL> def test_end_pos_multi_line ( self ) : <EOL> parsed = parser . Parser ( u ( '''<STR_LIT>''' ) ) <EOL> tok = parsed . module . subscopes [ <NUM_LIT:0> ] . statements [ <NUM_LIT:0> ] . _token_list [ <NUM_LIT:2> ] <EOL> self . assertEqual ( tok . end_pos , ( <NUM_LIT:4> , <NUM_LIT:11> ) ) </s>
<s> from types import FunctionType <EOL> from rdflib . graph import ConjunctiveGraph <EOL> from rdflib . graph import Graph <EOL> from rdflib . term import BNode <EOL> from rdflib . term import Literal <EOL> from rdflib . term import URIRef <EOL> from rdflib . term import Variable <EOL> from rdflib . namespace import NamespaceManager <EOL> from rdfextras . sparql import _questChar <EOL> from rdfextras . sparql import SPARQLError <EOL> from rdflib . util import check_object <EOL> from rdflib . util import check_subject <EOL> __all__ = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> class SPARQLGraph ( object ) : <EOL> """<STR_LIT>""" <EOL> SPARQL_DATASET = <NUM_LIT:0> <EOL> NAMED_GRAPH = <NUM_LIT:1> <EOL> __slots__ = ( "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" ) <EOL> def __init__ ( self , graph , graphVariable = None , dSCompliance = False ) : <EOL> assert not graphVariable or graphVariable [ <NUM_LIT:0> ] != '<STR_LIT:?>' , repr ( graphVariable ) <EOL> self . graphVariable = graphVariable <EOL> self . DAWG_DATASET_COMPLIANCE = dSCompliance <EOL> self . graphKind = None <EOL> if graph is not None : <EOL> self . graph = graph <EOL> if isinstance ( graph , ConjunctiveGraph ) : <EOL> self . graphKind = self . SPARQL_DATASET <EOL> self . identifier = graph . default_context . identifier <EOL> else : <EOL> self . graphKind = self . NAMED_GRAPH <EOL> self . identifier = graph . identifier <EOL> def setupGraph ( self , store , graphKind = None ) : <EOL> gKind = graphKind and graphKind or self . graphKind <EOL> self . graph = gKind ( store , self . identifier ) <EOL> def __reduce__ ( self ) : <EOL> return ( SPARQLGraph , <EOL> ( None , <EOL> self . graphVariable , <EOL> self . DAWG_DATASET_COMPLIANCE ) , <EOL> self . __getstate__ ( ) ) <EOL> def __getstate__ ( self ) : <EOL> return ( self . graphVariable , <EOL> self . DAWG_DATASET_COMPLIANCE , <EOL> self . identifier ) <EOL> def __setstate__ ( self , arg ) : <EOL> gVar , flag , identifier = arg <EOL> self . graphVariable = gVar <EOL> self . DAWG_DATASET_COMPLIANCE = flag <EOL> self . identifier = identifier <EOL> def _clusterForward ( self , seed , Cluster ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> for ( p , o ) in self . graph . predicate_objects ( seed ) : <EOL> if not ( seed , p , o ) in Cluster . graph : <EOL> Cluster . add ( ( seed , p , o ) ) <EOL> self . _clusterForward ( p , Cluster ) <EOL> self . _clusterForward ( o , Cluster ) <EOL> except : <EOL> pass <EOL> def clusterForward ( self , seed , Cluster = None ) : <EOL> """<STR_LIT>""" <EOL> if Cluster == None : <EOL> Cluster = SPARQLGraph ( ) <EOL> check_subject ( seed ) <EOL> self . _clusterForward ( seed , Cluster ) <EOL> return Cluster <EOL> def _clusterBackward ( self , seed , Cluster ) : <EOL> """<STR_LIT>""" <EOL> try : <EOL> for ( s , p ) in self . graph . subject_predicates ( seed ) : <EOL> if not ( s , p , seed ) in Cluster . graph : <EOL> Cluster . add ( ( s , p , seed ) ) <EOL> self . _clusterBackward ( s , Cluster ) <EOL> self . _clusterBackward ( p , Cluster ) <EOL> except : <EOL> pass <EOL> def clusterBackward ( self , seed , Cluster = None ) : <EOL> """<STR_LIT>""" <EOL> if Cluster == None : <EOL> Cluster = SPARQLGraph ( ) <EOL> check_object ( seed ) <EOL> self . _clusterBackward ( seed , Cluster ) <EOL> return Cluster <EOL> def cluster ( self , seed ) : <EOL> """<STR_LIT>""" <EOL> raise "<STR_LIT>" <EOL> return self . clusterBackward ( seed ) + self . clusterForward ( seed ) <EOL> """<STR_LIT>""" <EOL> def _createResource ( v ) : <EOL> """<STR_LIT>""" <EOL> if isinstance ( v , Literal ) or isinstance ( v , BNode ) or isinstance ( v , URIRef ) : <EOL> return v <EOL> else : <EOL> return Literal ( v ) <EOL> def _isResQuest ( r ) : <EOL> """<STR_LIT>""" <EOL> if r and isinstance ( r , basestring ) and r [ <NUM_LIT:0> ] == _questChar : <EOL> return True <EOL> return False <EOL> class GraphPattern : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , patterns = [ ] ) : <EOL> """<STR_LIT>""" <EOL> self . patterns = [ ] <EOL> self . constraints = [ ] <EOL> self . unbounds = [ ] <EOL> self . bnodes = { } <EOL> if type ( patterns ) == list : <EOL> self . addPatterns ( patterns ) <EOL> elif type ( patterns ) == tuple : <EOL> self . addPattern ( patterns ) <EOL> else : <EOL> raise SPARQLError ( <EOL> "<STR_LIT>" ) <EOL> def _generatePattern ( self , tupl ) : <EOL> """<STR_LIT>""" <EOL> if type ( tupl ) != tuple : <EOL> raise SPARQLError ( <EOL> "<STR_LIT>" % type ( tupl ) ) <EOL> if len ( tupl ) != <NUM_LIT:3> and len ( tupl ) != <NUM_LIT:4> : <EOL> raise SPARQLError ( <EOL> "<STR_LIT>" % len ( tupl ) ) <EOL> if len ( tupl ) == <NUM_LIT:3> : <EOL> ( s , p , o ) = tupl <EOL> f = None <EOL> else : <EOL> ( s , p , o , f ) = tupl <EOL> final = [ ] <EOL> for c in ( s , p , o ) : <EOL> if _isResQuest ( c ) : <EOL> if not c in self . unbounds : <EOL> self . unbounds . append ( c ) <EOL> final . append ( c ) <EOL> elif isinstance ( c , BNode ) : <EOL> final . append ( c ) <EOL> else : <EOL> final . append ( _createResource ( c ) ) <EOL> final . append ( f ) <EOL> return tuple ( final ) <EOL> def addPattern ( self , tupl ) : <EOL> """<STR_LIT>""" <EOL> self . patterns . append ( self . _generatePattern ( tupl ) ) <EOL> def insertPattern ( self , tupl ) : <EOL> """<STR_LIT>""" <EOL> self . patterns . insert ( <NUM_LIT:0> , self . _generatePattern ( tupl ) ) <EOL> def addPatterns ( self , lst ) : <EOL> """<STR_LIT>""" <EOL> for l in lst : <EOL> self . addPattern ( l ) <EOL> def insertPatterns ( self , lst ) : <EOL> """<STR_LIT>""" <EOL> for i in xrange ( len ( lst ) - <NUM_LIT:1> , - <NUM_LIT:1> , - <NUM_LIT:1> ) : <EOL> self . insertPattern ( lst [ i ] ) <EOL> def addConstraint ( self , func ) : <EOL> """<STR_LIT>""" <EOL> if type ( func ) == FunctionType : <EOL> self . constraints . append ( func ) <EOL> else : <EOL> raise SPARQLError ( <EOL> "<STR_LIT>" % type ( func ) ) <EOL> def addConstraints ( self , lst ) : <EOL> """<STR_LIT>""" <EOL> for l in lst : <EOL> self . addConstraint ( l ) <EOL> def construct ( self , tripleStore , bindings ) : <EOL> """<STR_LIT>""" <EOL> localBnodes = { } <EOL> for c in self . bnodes : <EOL> localBnodes [ c ] = BNode ( ) <EOL> def bind ( st ) : <EOL> if _isResQuest ( st ) : <EOL> if st in bindings : <EOL> return bindings [ st ] <EOL> else : <EOL> if isinstance ( self , GraphPattern ) : <EOL> return st <EOL> else : <EOL> return None <EOL> elif isinstance ( st , BNode ) : <EOL> for c in self . bnodes : <EOL> if self . bnodes [ c ] == st : <EOL> return localBnodes [ c ] <EOL> return st <EOL> else : <EOL> return st <EOL> for pattern in self . patterns : <EOL> ( s , p , o , f ) = pattern <EOL> triplet = [ ] <EOL> valid = True <EOL> for res in ( s , p , o ) : <EOL> val = bind ( res ) <EOL> if val != None : <EOL> triplet . append ( val ) <EOL> else : <EOL> valid = False <EOL> break <EOL> if valid : <EOL> tripleStore . add ( tuple ( triplet ) ) <EOL> def __add__ ( self , other ) : <EOL> """<STR_LIT>""" <EOL> retval = GraphPattern ( ) <EOL> retval += self <EOL> retval += other <EOL> return retval <EOL> def __iadd__ ( self , other ) : <EOL> """<STR_LIT>""" <EOL> self . patterns += other . patterns <EOL> self . constraints += other . constraints <EOL> for c in other . unbounds : <EOL> if not c in self . unbounds : <EOL> self . unbounds . append ( c ) <EOL> for c in other . bnodes : <EOL> if not c in self . bnodes : <EOL> self . bnodes [ c ] = other . bnodes [ c ] <EOL> return self <EOL> def __str__ ( self ) : <EOL> return self . __repr__ ( ) <EOL> def isEmpty ( self ) : <EOL> """<STR_LIT>""" <EOL> return len ( self . patterns ) == <NUM_LIT:0> <EOL> class BasicGraphPattern ( GraphPattern ) : <EOL> """<STR_LIT>""" <EOL> def __init__ ( self , patterns = [ ] , prolog = None ) : <EOL> """<STR_LIT>""" <EOL> GraphPattern . __init__ ( self , patterns ) <EOL> self . prolog = prolog <EOL> def canonicalTerm ( self , term ) : <EOL> if isinstance ( term , URIRef ) : <EOL> if self . prolog is not None : <EOL> namespace_manager = NamespaceManager ( Graph ( ) ) <EOL> for prefix , uri in self . prolog . prefixBindings . items ( ) : <EOL> namespace_manager . bind ( prefix , uri , override = False ) <EOL> try : <EOL> prefix , uri , localName = namespace_manager . compute_qname ( term ) <EOL> except : <EOL> return term <EOL> if prefix not in self . prolog . prefixBindings : <EOL> return term <EOL> else : <EOL> return u'<STR_LIT::>' . join ( [ prefix , localName ] ) <EOL> else : <EOL> return term <EOL> elif isinstance ( term , Literal ) : <EOL> return term . n3 ( ) <EOL> elif isinstance ( term , BNode ) : <EOL> return term . n3 ( ) <EOL> else : <EOL> assert isinstance ( term , Variable ) <EOL> return term . n3 ( ) <EOL> def __repr__ ( self ) : <EOL> if self . constraints : <EOL> return "<STR_LIT>" % ( <EOL> '<STR_LIT:U+002C>' . join ( [ '<STR_LIT:U+002C>' . join ( [ <EOL> self . canonicalTerm ( pat [ <NUM_LIT:0> ] ) , <EOL> self . canonicalTerm ( pat [ <NUM_LIT:1> ] ) , <EOL> self . canonicalTerm ( pat [ <NUM_LIT:2> ] ) ] <EOL> ) <EOL> for pat in self . patterns ] ) ) <EOL> else : <EOL> return "<STR_LIT>" % ( <EOL> '<STR_LIT:U+002C>' . join ( [ '<STR_LIT:(>' + '<STR_LIT:U+002C>' . join ( [ <EOL> self . canonicalTerm ( s ) , <EOL> self . canonicalTerm ( p ) , <EOL> self . canonicalTerm ( o ) ] <EOL> ) + '<STR_LIT:)>' <EOL> for s , p , o , f in self . patterns ] ) ) <EOL> retval = "<STR_LIT>" % self . patterns <EOL> retval += "<STR_LIT>" % self . constraints <EOL> retval += "<STR_LIT>" % self . unbounds <EOL> return retval <EOL> def _generatePattern ( self , tupl ) : <EOL> """<STR_LIT>""" <EOL> if type ( tupl ) != tuple : <EOL> raise SPARQLError ( <EOL> "<STR_LIT>" % type ( tupl ) ) <EOL> if len ( tupl ) != <NUM_LIT:3> and len ( tupl ) != <NUM_LIT:4> : <EOL> raise SPARQLError ( <EOL> "<STR_LIT>" % len ( tupl ) ) <EOL> if len ( tupl ) == <NUM_LIT:3> : <EOL> ( s , p , o ) = tupl <EOL> f = None <EOL> else : <EOL> ( s , p , o , f ) = tupl <EOL> final = [ ] <EOL> for c in ( s , p , o ) : <EOL> if isinstance ( c , Variable ) : <EOL> if not c in self . unbounds : <EOL> self . unbounds . append ( c ) <EOL> final . append ( c ) <EOL> elif isinstance ( c , BNode ) : <EOL> final . append ( c ) <EOL> else : <EOL> final . append ( _createResource ( c ) ) <EOL> final . append ( f ) <EOL> return tuple ( final ) <EOL> def fetchTerminalExpression ( self ) : <EOL> yield self <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> from rdfextras . sparql . evaluate import Unbound <EOL> v1 = Variable ( "<STR_LIT:a>" ) <EOL> u1 = Unbound ( "<STR_LIT:a>" ) <EOL> g = BasicGraphPattern ( <EOL> [ ( "<STR_LIT:a>" , "<STR_LIT>" , <NUM_LIT> ) , ( "<STR_LIT>" , "<STR_LIT>" , <NUM_LIT> ) , ( v1 , "<STR_LIT>" , <NUM_LIT> ) , ( u1 , "<STR_LIT>" , <NUM_LIT> ) ] ) <EOL> print g </s>
<s> from rdflib import ConjunctiveGraph , plugin <EOL> from rdflib . store import Store <EOL> from StringIO import StringIO <EOL> import unittest <EOL> """<STR_LIT>""" <EOL> test_data = """<STR_LIT>""" <EOL> test_query = """<STR_LIT>""" <EOL> correct = """<STR_LIT>""" <EOL> test_header_query = """<STR_LIT>""" <EOL> class JSON ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . graph = ConjunctiveGraph ( plugin . get ( '<STR_LIT>' , Store ) ( ) ) <EOL> self . graph . parse ( StringIO ( test_data ) , format = "<STR_LIT>" ) <EOL> def testComma ( self ) : <EOL> """<STR_LIT>""" <EOL> results = self . graph . query ( test_query ) <EOL> result_json = results . serialize ( format = '<STR_LIT>' ) <EOL> self . failUnless ( result_json . find ( correct ) > <NUM_LIT:0> ) <EOL> def testHeader ( self ) : <EOL> """<STR_LIT>""" <EOL> results = self . graph . query ( test_header_query ) <EOL> result_json = results . serialize ( format = '<STR_LIT>' ) <EOL> self . failUnless ( result_json . find ( '<STR_LIT>' ) == - <NUM_LIT:1> ) <EOL> if __name__ == "<STR_LIT:__main__>" : <EOL> unittest . main ( ) </s>
<s> import unittest <EOL> from rdflib import plugin <EOL> from rdflib . namespace import Namespace , RDF , RDFS <EOL> from rdflib . term import URIRef <EOL> from rdflib . store import Store <EOL> from cStringIO import StringIO <EOL> from rdflib import Graph <EOL> import rdflib <EOL> try : <EOL> set <EOL> except NameError : <EOL> from sets import Set as set <EOL> testGraph1N3 = """<STR_LIT>""" <EOL> sparqlQ1 = """<STR_LIT>""" <EOL> sparqlQ2 = """<STR_LIT>""" <EOL> sparqlQ3 = """<STR_LIT>""" <EOL> sparqlQ4 = """<STR_LIT>""" <EOL> class AdvancedTests ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> memStore = plugin . get ( '<STR_LIT>' , Store ) ( ) <EOL> self . testGraph = Graph ( memStore ) <EOL> self . testGraph . parse ( StringIO ( testGraph1N3 ) , format = '<STR_LIT>' ) <EOL> def testNamedGraph ( self ) : <EOL> OWL_NS = Namespace ( "<STR_LIT>" ) <EOL> rt = self . testGraph . query ( sparqlQ4 ) <EOL> self . assertEquals ( set ( rt ) , set ( ( x , ) for x in [ OWL_NS . DatatypeProperty , OWL_NS . ObjectProperty , OWL_NS . OntologyProperty , OWL_NS . Class , OWL_NS . Ontology , OWL_NS . AnnotationProperty , RDF . Property , RDFS . Class ] ) ) <EOL> def testScopedBNodes ( self ) : <EOL> rt = self . testGraph . query ( sparqlQ1 ) <EOL> self . assertEquals ( list ( rt ) [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] , URIRef ( "<STR_LIT>" ) ) <EOL> def testCollectionContentWithinAndWithout ( self ) : <EOL> rt = self . testGraph . query ( sparqlQ3 ) <EOL> self . assertEquals ( list ( rt ) [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] , URIRef ( "<STR_LIT>" ) ) <EOL> def testCollectionAsObject ( self ) : <EOL> rt = self . testGraph . query ( sparqlQ2 ) <EOL> self . assertEquals ( list ( rt ) [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] , URIRef ( "<STR_LIT>" ) ) <EOL> self . assertEquals ( <NUM_LIT:1> , len ( rt ) ) <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> suite = unittest . makeSuite ( AdvancedTests ) <EOL> unittest . TextTestRunner ( verbosity = <NUM_LIT:3> ) . run ( suite ) </s>
<s> from urllib2 import URLError <EOL> try : <EOL> from Ft . Lib import UriException <EOL> except : <EOL> from urllib2 import URLError as UriException <EOL> import unittest <EOL> from rdflib import ConjunctiveGraph , URIRef <EOL> class SPARQLloadContextsTest ( unittest . TestCase ) : <EOL> def test_dSet_parsed_as_URL_raises_Exception ( self ) : <EOL> querystr = """<STR_LIT>""" <EOL> graph = ConjunctiveGraph ( ) <EOL> graph . get_context ( URIRef ( "<STR_LIT>" ) <EOL> ) . parse ( "<STR_LIT>" ) <EOL> self . assertRaises ( ( URLError , UriException ) , <EOL> graph . query , ( querystr ) , loadContexts = False ) <EOL> def test_dSet_parsed_as_context_returns_results ( self ) : <EOL> querystr = """<STR_LIT>""" <EOL> graph = ConjunctiveGraph ( ) <EOL> graph . get_context ( URIRef ( '<STR_LIT>' ) <EOL> ) . parse ( "<STR_LIT>" ) <EOL> r = graph . query ( querystr , loadContexts = True ) <EOL> self . assert_ ( len ( r . bindings ) is not <NUM_LIT:0> ) </s>
<s> """<STR_LIT>""" <EOL> from rdflib import Graph , RDF , RDFS , Literal <EOL> from rdflib . namespace import FOAF <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> g = Graph ( ) <EOL> bob = g . resource ( '<STR_LIT>' ) <EOL> bob . set ( RDF . type , FOAF . Person ) <EOL> bob . set ( FOAF . name , Literal ( "<STR_LIT>" ) ) <EOL> bill = g . resource ( '<STR_LIT>' ) <EOL> bill . add ( RDF . type , FOAF . Person ) <EOL> bill . add ( RDF . type , FOAF . Agent ) <EOL> bill . set ( RDFS . label , Literal ( "<STR_LIT>" ) ) <EOL> bill . add ( FOAF . knows , bob ) <EOL> print "<STR_LIT>" , bill . value ( FOAF . knows ) . value ( FOAF . name ) <EOL> print "<STR_LIT>" , <EOL> for friend in bill [ FOAF . knows ] : <EOL> print friend [ FOAF . name ] . next ( ) , "<STR_LIT:U+0020>" <EOL> print "<STR_LIT>" , <EOL> for friend in bill [ FOAF . knows / FOAF . name ] : <EOL> print friend <EOL> bill [ RDFS . label ] = Literal ( "<STR_LIT>" ) <EOL> print g . serialize ( format = '<STR_LIT>' ) </s>
<s> """<STR_LIT>""" <EOL> from codecs import getreader <EOL> from rdflib . py3compat import b <EOL> from rdflib import ConjunctiveGraph <EOL> from rdflib . plugins . parsers . ntriples import NTriplesParser <EOL> from rdflib . plugins . parsers . ntriples import ParseError <EOL> from rdflib . plugins . parsers . ntriples import r_tail <EOL> from rdflib . plugins . parsers . ntriples import r_wspace <EOL> from rdflib . plugins . parsers . ntriples import r_wspaces <EOL> __all__ = [ '<STR_LIT>' ] <EOL> class NQuadsParser ( NTriplesParser ) : <EOL> def parse ( self , inputsource , sink , ** kwargs ) : <EOL> """<STR_LIT>""" <EOL> assert sink . store . context_aware , ( "<STR_LIT>" <EOL> "<STR_LIT>" ) <EOL> self . sink = ConjunctiveGraph ( store = sink . store , identifier = sink . identifier ) <EOL> source = inputsource . getByteStream ( ) <EOL> if not hasattr ( source , '<STR_LIT>' ) : <EOL> raise ParseError ( "<STR_LIT>" ) <EOL> source = getreader ( '<STR_LIT:utf-8>' ) ( source ) <EOL> self . file = source <EOL> self . buffer = '<STR_LIT>' <EOL> while True : <EOL> self . line = __line = self . readline ( ) <EOL> if self . line is None : <EOL> break <EOL> try : <EOL> self . parseline ( ) <EOL> except ParseError , msg : <EOL> raise ParseError ( "<STR_LIT>" % ( msg , __line ) ) <EOL> return self . sink <EOL> def parseline ( self ) : <EOL> self . eat ( r_wspace ) <EOL> if ( not self . line ) or self . line . startswith ( ( '<STR_LIT:#>' ) ) : <EOL> return <EOL> subject = self . subject ( ) <EOL> self . eat ( r_wspace ) <EOL> predicate = self . predicate ( ) <EOL> self . eat ( r_wspace ) <EOL> obj = self . object ( ) <EOL> self . eat ( r_wspace ) <EOL> context = self . uriref ( ) or self . nodeid ( ) or self . sink . identifier <EOL> self . eat ( r_tail ) <EOL> if self . line : <EOL> raise ParseError ( "<STR_LIT>" ) <EOL> self . sink . get_context ( context ) . add ( ( subject , predicate , obj ) ) </s>
<s> """<STR_LIT>""" <EOL> import codecs <EOL> import csv <EOL> from rdflib import Variable , BNode , URIRef , Literal , py3compat <EOL> from rdflib . query import Result , ResultSerializer , ResultParser <EOL> class CSVResultParser ( ResultParser ) : <EOL> def __init__ ( self ) : <EOL> self . delim = "<STR_LIT:U+002C>" <EOL> def parse ( self , source ) : <EOL> r = Result ( '<STR_LIT>' ) <EOL> if isinstance ( source . read ( <NUM_LIT:0> ) , py3compat . bytestype ) : <EOL> source = codecs . getreader ( '<STR_LIT:utf-8>' ) ( source ) <EOL> reader = csv . reader ( source , delimiter = self . delim ) <EOL> r . vars = [ Variable ( x ) for x in reader . next ( ) ] <EOL> r . bindings = [ ] <EOL> for row in reader : <EOL> r . bindings . append ( self . parseRow ( row , r . vars ) ) <EOL> return r <EOL> def parseRow ( self , row , v ) : <EOL> return dict ( ( var , val ) <EOL> for var , val in zip ( v , [ self . convertTerm ( t ) <EOL> for t in row ] ) if val is not None ) <EOL> def convertTerm ( self , t ) : <EOL> if t == "<STR_LIT>" : <EOL> return None <EOL> if t . startswith ( "<STR_LIT>" ) : <EOL> return BNode ( t ) <EOL> if t . startswith ( "<STR_LIT>" ) or t . startswith ( "<STR_LIT>" ) : <EOL> return URIRef ( t ) <EOL> return Literal ( t ) <EOL> class CSVResultSerializer ( ResultSerializer ) : <EOL> def __init__ ( self , result ) : <EOL> ResultSerializer . __init__ ( self , result ) <EOL> self . delim = "<STR_LIT:U+002C>" <EOL> if result . type != "<STR_LIT>" : <EOL> raise Exception ( <EOL> "<STR_LIT>" ) <EOL> def serialize ( self , stream , encoding = '<STR_LIT:utf-8>' ) : <EOL> if py3compat . PY3 : <EOL> import codecs <EOL> stream = codecs . getwriter ( encoding ) ( stream ) <EOL> out = csv . writer ( stream , delimiter = self . delim ) <EOL> vs = [ self . serializeTerm ( v , encoding ) for v in self . result . vars ] <EOL> out . writerow ( vs ) <EOL> for row in self . result . bindings : <EOL> out . writerow ( [ self . serializeTerm ( <EOL> row . get ( v ) , encoding ) for v in self . result . vars ] ) <EOL> def serializeTerm ( self , term , encoding ) : <EOL> if term is None : <EOL> return "<STR_LIT>" <EOL> if not py3compat . PY3 : <EOL> return term . encode ( encoding ) <EOL> else : <EOL> return term </s>
